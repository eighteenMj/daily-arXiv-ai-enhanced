<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 64]
- [eess.SY](#eess.SY) [Total: 12]
- [cs.AI](#cs.AI) [Total: 24]
- [eess.IV](#eess.IV) [Total: 4]
- [cs.IT](#cs.IT) [Total: 6]
- [cs.LG](#cs.LG) [Total: 74]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Transformed Multi-view 3D Shape Features with Contrastive Learning](https://arxiv.org/abs/2510.19955)
*Márcus Vinícius Lobo Costa,Sherlon Almeida da Silva,Bárbara Caroline Benato,Leo Sampaio Ferraz Ribeiro,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: 该论文通过使用Vision Transformers (ViTs) 结合现代对比学习目标，在多视角3D分析中的下游任务中取得了很好的结果。特别是，在ModelNet10数据集上，监督对比损失达到了90.6%的精度。这项研究的主要贡献在于，它利用ViTs的整体形状理解能力和对比学习的有效性，克服了CNNs在捕捉形状关系上的局限性，并且通过实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前计算机视觉方法难以从2D图像中识别3D对象，并且通常需要大量的标注数据以及依赖于无法充分捕捉形状关系的CNNs。该论文旨在通过结合Vision Transformers和对比学习来解决这些问题，提供一种新颖的3D形状特征表示方法。

Method: 该方法涉及到设计并结合Vision Transformers和对比学习目标，通过同时利用ViTs的全局形状语义理解和对比学习的局部特征选择能力，来提高3D形状特征表示的准确性。该方法被实现并测试在各种3D数据集上，以验证其有效性。

Result: 实验表明，对比损失下的ViTs模型可以达到约90.6%的精度，相对于其他基准方法有显著提升，证明了结合ViTs与对比学习在3D表示学习中的优越性。特别是，这种方法在捕捉全局形状语义和优化局部特征方面表现出色。

Conclusion: 通过把ViTs与对比学习一起使用，可以有效克服传统CNNs在3D形状理解上的局限性。实验结果表明，这种新的方法不仅在精度上有所提升，而且在减少依赖标注数据方面也取得了良好的效果。

Abstract: This paper addresses the challenges in representation learning of 3D shape
features by investigating state-of-the-art backbones paired with both
contrastive supervised and self-supervised learning objectives. Computer vision
methods struggle with recognizing 3D objects from 2D images, often requiring
extensive labeled data and relying on Convolutional Neural Networks (CNNs) that
may overlook crucial shape relationships. Our work demonstrates that Vision
Transformers (ViTs) based architectures, when paired with modern contrastive
objectives, achieve promising results in multi-view 3D analysis on our
downstream tasks, unifying contrastive and 3D shape understanding pipelines.
For example, supervised contrastive losses reached about 90.6% accuracy on
ModelNet10. The use of ViTs and contrastive learning, leveraging ViTs' ability
to understand overall shapes and contrastive learning's effectiveness,
overcomes the need for extensive labeled data and the limitations of CNNs in
capturing crucial shape relationships. The success stems from capturing global
shape semantics via ViTs and refining local discriminative features through
contrastive optimization. Importantly, our approach is empirical, as it is
grounded on extensive experimental evaluation to validate the effectiveness of
combining ViTs with contrastive objectives for 3D representation learning.

</details>


### [2] [Improving Predictive Confidence in Medical Imaging via Online Label Smoothing](https://arxiv.org/abs/2510.20011)
*Kushan Choudhury,Shubhrodeep Roy,Ankur Chanda,Shubhajit Biswas,Somenath Kuiry*

Main category: cs.CV

TL;DR: 在线标签平滑方法(OLS)通过调整训练过程中的软标签来减少模型预测的过度自信，提高了医学图像分类的准确性和模型的校准性。该方法在RadImageNet数据集上使用ResNet-50、MobileNetV2和VGG-19三种架构训练，并在Top-1和Top-5分类准确率上超过标准训练方法，包括硬标签、传统标签平滑和无教师知识蒸馏。


<details>
  <summary>Details</summary>
Motivation: 为了改进深度学习模型在医学图像分类中的过度自信预测，研究提出了在线标签平滑(OLS)方法，该方法根据模型自身的预测模式动态调整软标签，解决传统标签平滑方法不能考虑类间关系的问题。

Method: 通过在大规模的RadImageNet数据集上应用三种常用架构(ResNet-50、MobileNetV2和VGG-19)，采用OLS进行训练，并与硬标签、传统标签平滑和无教师知识蒸馏方法进行对比。

Result: 实验证明，OLS不仅提高了Top-1和Top-5分类准确率，还导致更紧凑和分离良好的特征嵌入，改善了表示学习。

Conclusion: OLS通过改进预测性能和校准性，是一种强大的策略，在医学图像领域可以构建可信的人工智能系统。

Abstract: Deep learning models, especially convolutional neural networks, have achieved
impressive results in medical image classification. However, these models often
produce overconfident predictions, which can undermine their reliability in
critical healthcare settings. While traditional label smoothing offers a simple
way to reduce such overconfidence, it fails to consider relationships between
classes by treating all non-target classes equally. In this study, we explore
the use of Online Label Smoothing (OLS), a dynamic approach that adjusts soft
labels throughout training based on the model's own prediction patterns. We
evaluate OLS on the large-scale RadImageNet dataset using three widely used
architectures: ResNet-50, MobileNetV2, and VGG-19. Our results show that OLS
consistently improves both Top-1 and Top-5 classification accuracy compared to
standard training methods, including hard labels, conventional label smoothing,
and teacher-free knowledge distillation. In addition to accuracy gains, OLS
leads to more compact and well-separated feature embeddings, indicating
improved representation learning. These findings suggest that OLS not only
strengthens predictive performance but also enhances calibration, making it a
practical and effective solution for developing trustworthy AI systems in the
medical imaging domain.

</details>


### [3] [A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance](https://arxiv.org/abs/2510.20016)
*Neema Jakisa Owor,Joshua Kofi Asamoah,Tanner Wambui Muturi,Anneliese Jakisa Owor,Blessing Agyei Kyem,Andrews Danyo,Yaw Adu-Gyamfi,Armstrong Aboah*

Main category: cs.CV

TL;DR: 本文提出了一种用于 fisheye 摄像头交通监控的物体检测框架，通过预处理和后处理管道以及模型组合策略来提高检测准确性，在2025 AI City Challenge Track 4 上取得了第8名的成绩，F1 值为0.6366。


<details>
  <summary>Details</summary>
Motivation: 标准的物体检测方法在处理 fisheye 图像时存在挑战，尤其是在图像边缘区域，物体的外观严重退化。因此，本文旨在开发一种能够有效解决这些问题的检测框架。

Method: 该方法采用了一种简单的预处理和后处理管道来增强整个图像中的检测一致性，尤其是那些被严重失真的区域。通过训练多种先进的检测模型并对它们的输出进行组合，以提高总体检测准确度。

Result: 该方法在2025 AI City Challenge Track 4 测试中取得了 F1 值为0.6366 的成绩，排名第8，证明了该框架的有效性。

Conclusion: 提出的检测框架可以有效地解决 fisheye 图像中的物体检测问题。

Abstract: Fisheye cameras offer an efficient solution for wide-area traffic
surveillance by capturing large fields of view from a single vantage point.
However, the strong radial distortion and nonuniform resolution inherent in
fisheye imagery introduce substantial challenges for standard object detectors,
particularly near image boundaries where object appearance is severely
degraded. In this work, we present a detection framework designed to operate
robustly under these conditions. Our approach employs a simple yet effective
pre and post processing pipeline that enhances detection consistency across the
image, especially in regions affected by severe distortion. We train several
state-of-the-art detection models on the fisheye traffic imagery and combine
their outputs through an ensemble strategy to improve overall detection
accuracy. Our method achieves an F1 score of0.6366 on the 2025 AI City
Challenge Track 4, placing 8thoverall out of 62 teams. These results
demonstrate the effectiveness of our framework in addressing issues inherent to
fisheye imagery.

</details>


### [4] [Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses](https://arxiv.org/abs/2510.20027)
*Damian Bowness,Charalambos Poullis*

Main category: cs.CV

TL;DR: 提出了一种新的实时渲染感知滤波方法，解决了3D Gaussian Splatting模型在训练数据分布之外的视点下，由于缺乏数据导致的视觉噪声问题。该方法显著提高了视觉质量和一致性，相比于现有方法，无需额外的重新训练或微调即可在实时渲染中应用。


<details>
  <summary>Details</summary>
Motivation: 当从3D Gaussian Splatting模型的训练数据分布之外的位置观察时，常常会出现视觉噪声。这主要是由于缺乏数据导致密度、颜色和几何预测不确定。因此，需要一种新的方法来解决这个问题，确保3D重建在用户自由导航到原训练视点之外的情况下也能保持高视觉保真度。

Method: 我们的方法利用中间梯度提取的敏感性分数，专门针对各向异性方向引起的不稳定性，而不是各向同性方差。此方法直接处理生成不确定性的问题，使得3DGS在实时渲染中能够保持高质量。

Result: 实验结果表明，相较于NeRF等现有方法，这种方法显著提高了视觉质量、真实感和一致性。并且它可以无缝集成到现有的3DGS渲染流水线中，在线实时运行。

Conclusion: 论文提出了一种实时渲染感知滤波方法，解决了3DGS模型在训练数据分布之外的视图中的视觉噪声问题，展示了该方法在视觉质量和真实性上的显著提升，并且能够在真实场景中实时应用。

Abstract: When viewing a 3D Gaussian Splatting (3DGS) model from camera positions
significantly outside the training data distribution, substantial visual noise
commonly occurs. These artifacts result from the lack of training data in these
extrapolated regions, leading to uncertain density, color, and geometry
predictions from the model.
  To address this issue, we propose a novel real-time render-aware filtering
method. Our approach leverages sensitivity scores derived from intermediate
gradients, explicitly targeting instabilities caused by anisotropic
orientations rather than isotropic variance. This filtering method directly
addresses the core issue of generative uncertainty, allowing 3D reconstruction
systems to maintain high visual fidelity even when users freely navigate
outside the original training viewpoints.
  Experimental evaluation demonstrates that our method substantially improves
visual quality, realism, and consistency compared to existing Neural Radiance
Field (NeRF)-based approaches such as BayesRays. Critically, our filter
seamlessly integrates into existing 3DGS rendering pipelines in real-time,
unlike methods that require extensive post-hoc retraining or fine-tuning.
  Code and results at https://damian-bowness.github.io/EV3DGS

</details>


### [5] [BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for Transcranial Ultrasound Tomography](https://arxiv.org/abs/2510.20029)
*Shengyu Chen,Shihang Feng,Yi Luo,Xiaowei Jia,Youzuo Lin*

Main category: cs.CV

TL;DR: 本文提出了一种混合两阶段框架BrainPuzzle，旨在实现定量的颅内超声成像，结合了物理建模和机器学习。该方法使用反向时间迁移产生保存结构细节的迁移片段，然后使用带有图注意力单元的变压器超分辨率编码器-解码器融合这些片段形成准确的速度图像。实验显示，BrainPuzzle能够在合成数据集上获得优越的速度重建精度和图像完整性，展示了其潜在的应用价值。


<details>
  <summary>Details</summary>
Motivation: 传统的基于物理的全波形反转技术受限于信号问题和不完整的空间覆盖，而纯粹的数据驱动方法无法准确建模复杂的骨组织中的波传播。为了解决这些问题，提出了一种混合方法，结合了物理建模与机器学习，提高超声脑成像的质量与可行性。

Method: BrainPuzzle包括两个阶段：第一阶段使用反向时间迁移产生片段；第二阶段采用带有图注意力单元的变压器超分辨率编码器-解码器模型将这些片段融合成完整的图像。同时提出了一种部分阵列获取策略，使用低计数转导器集，以提高可行性和耦合性。

Result: 研究表明，BrainPuzzle在合成数据集上实现了更优的速度图像重建准确性和图像完整性，显示了其在定量脑超声成像方面的应用潜力。

Conclusion: 通过结合物理建模和机器学习方法，BrainPuzzle有效地提高了颅内超声成像的准确性和可行性，展示了其在改善脑部定量超声成像方面的潜在价值。

Abstract: Ultrasound brain imaging remains challenging due to the large difference in
sound speed between the skull and brain tissues and the difficulty of coupling
large probes to the skull. This work aims to achieve quantitative transcranial
ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain.
Traditional physics-based full-waveform inversion (FWI) is limited by weak
signals caused by skull-induced attenuation, mode conversion, and phase
aberration, as well as incomplete spatial coverage since full-aperture arrays
are clinically impractical. In contrast, purely data-driven methods that learn
directly from raw ultrasound data often fail to model the complex nonlinear and
nonlocal wave propagation through bone, leading to anatomically plausible but
quantitatively biased SoS maps under low signal-to-noise and sparse-aperture
conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage
framework that combines physical modeling with machine learning. In the first
stage, reverse time migration (time-reversal acoustics) is applied to
multi-angle acquisitions to produce migration fragments that preserve
structural details even under low SNR. In the second stage, a transformer-based
super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses
these fragments into a coherent and quantitatively accurate SoS image. A
partial-array acquisition strategy using a movable low-count transducer set
improves feasibility and coupling, while the hybrid algorithm compensates for
the missing aperture. Experiments on two synthetic datasets show that
BrainPuzzle achieves superior SoS reconstruction accuracy and image
completeness, demonstrating its potential for advancing quantitative ultrasound
brain imaging.

</details>


### [6] [Exposing Blindspots: Cultural Bias Evaluation in Generative Image Models](https://arxiv.org/abs/2510.20042)
*Huichan Seo,Sieun Choi,Minki Hong,Yi Zhou,Junseo Kim,Lukman Ismaila,Naome Etori,Mehul Agarwal,Zhixuan Liu,Jihie Kim,Jean Oh*

Main category: cs.CV

TL;DR: 该研究通过六国统一评估、8大类/36小类的文化框架以及考虑时代背景的提示词，评估了生成式图像模型的文化偏见。发现模型在国家无关的提示词下倾向于生成全球化北方、现代化的图像，缺乏国家间的文化区分，并且图像到图像编辑可能导致文化真实度的下降，而迭代式编辑可能会进一步削弱文化真实度。这些结果表明，目前的系统在进行文化敏感编辑时尚不可靠。


<details>
  <summary>Details</summary>
Motivation: 本文旨在填补图像到图像编辑模型在评估文化偏见方面的研究空白，使用一个统一的评估框架，该框架包括多个国家的评估、文化分类、考虑时代背景的提示词，以评估图像生成和编辑的文化偏见。

Method: 该研究采用开放模型和固定设置，结合自动标准衡量指标、文化意识检索增强的VQA以及本土评审员的人工评估，采用统一的评估框架，该框架考虑多个国家、多个时代以及多种文化类别的情况，同时提供可重复的数据集、提示词和人工评估协议。

Result: 研究发现：（1）当使用国家无关的提示词时，模型生成的图像更多倾向于全球化北方、现代化的图像，缺乏明显的国家文化区别；（2）迭代图像到图像编辑可能会导致文化真实度的下降，即使常规衡量指标没有变化或提高了；（3）对于全球化南方的目标，图像到图像模型倾向于更表面的提示，例如调色板变化和一般道具，而不是符合时代背景和具体背景的更改。这些发现表明，当代系统在进行文化敏感编辑上仍然不可靠。

Conclusion: 该研究建立了一个可重复的文化中心基准，用于诊断和追踪图像生成模型的文化偏见，并发布了标准化的数据、提示词和人工评估协议。 

Abstract: Generative image models produce striking visuals yet often misrepresent
culture. Prior work has examined cultural bias mainly in text-to-image (T2I)
systems, leaving image-to-image (I2I) editors underexplored. We bridge this gap
with a unified evaluation across six countries, an 8-category/36-subcategory
schema, and era-aware prompts, auditing both T2I generation and I2I editing
under a standardized protocol that yields comparable diagnostics. Using open
models with fixed settings, we derive cross-country, cross-era, and
cross-category evaluations. Our framework combines standard automatic metrics,
a culture-aware retrieval-augmented VQA, and expert human judgments collected
from native reviewers. To enable reproducibility, we release the complete image
corpus, prompts, and configurations. Our study reveals three findings: (1)
under country-agnostic prompts, models default to Global-North, modern-leaning
depictions that flatten cross-country distinctions; (2) iterative I2I editing
erodes cultural fidelity even when conventional metrics remain flat or improve;
and (3) I2I models apply superficial cues (palette shifts, generic props)
rather than era-consistent, context-aware changes, often retaining source
identity for Global-South targets. These results highlight that
culture-sensitive edits remain unreliable in current systems. By releasing
standardized data, prompts, and human evaluation protocols, we provide a
reproducible, culture-centered benchmark for diagnosing and tracking cultural
bias in generative image models.

</details>


### [7] [Endoshare: A Source Available Solution to De-Identify and Manage Surgical Videos](https://arxiv.org/abs/2510.20087)
*Lorenzo Arboit,Dennis N. Schneider,Britty Baby,Vinkle Srivastav,Pietro Mascagni,Nicolas Padoy*

Main category: cs.CV

TL;DR: Endoshare 是一个开源、跨平台的应用程序，用于合并、标准化和去除标识符的内窥镜视频，以促进外科手术训练、研究和质量改进。它通过遵循软件开发生命周期，采用用户为中心的设计，并进行了多轮测试和用户反馈，最终得到了高度的用户满意度和推荐。处理时间和机器计算能力有关（p=0.041）, 视频长度也会影响处理时间（p<=0.001）。Endoshare 提供了一个透明、用户友好、隐私保护的手术视频管理管道，但仍需合规认证和更广泛的互操作性验证才能部署。


<details>
  <summary>Details</summary>
Motivation: 为了解决外科视频训练和研究中由于不同的视频格式和隐私保护问题而受到限制的问题，研究团队开发了一个名为Endoshare的工具，该工具可以将不同格式的内窥镜视频合并、标准化和去除标识符。

Method: 开发遵循了软件开发生命周期，通过内部和外部的用户反馈进行迭代设计，包括对10位临床医生和计算机科学家进行内部调查、对外部临床医生的测试调查和与其他硬件配置的基准测试。在测试过程中，还进行了一系列的用户体验和功能测试。

Result: 在多个用户群体中得到了高度的用户满意度的报告，评分分别为4.68 +/- 0.40/5，4.03 +/- 0.51/5 和5.07 +/- 1.75/7，同时处理时间也与硬件性能和视频长度显著相关。

Conclusion: Endoshare提供了一个透明、用户友好、隐私保护的手术视频管理方法，可以成为开放式替代现有专有系统的可能性。仍需进行合规认证和更进一步的互操作性测试以验证其实际部署。

Abstract: Video-based assessment and surgical data science can advance surgical
training, research, and quality improvement. However, widespread use remains
limited by heterogeneous recording formats and privacy concerns associated with
video sharing. We present Endoshare, a source-available, cross-platform
application for merging, standardizing, and de-identifying endoscopic videos in
minimally invasive surgery. Development followed the software development life
cycle with iterative, user-centered feedback. During the analysis phase, an
internal survey of clinicians and computer scientists based on ten usability
heuristics identified key requirements that guided a privacy-by-design
architecture. In the testing phase, an external clinician survey combined the
same heuristics with Technology Acceptance Model constructs to assess usability
and adoption, complemented by benchmarking across different hardware
configurations. Four clinicians and four computer scientists initially tested
the prototype, reporting high usability (4.68 +/- 0.40/5 and 4.03 +/- 0.51/5),
with the lowest score (4.00 +/- 0.93/5) relating to label clarity. After
refinement, the testing phase surveyed ten surgeons who reported high perceived
usefulness (5.07 +/- 1.75/7), ease of use (5.15 +/- 1.71/7), heuristic
usability (4.38 +/- 0.48/5), and strong recommendation (9.20 +/- 0.79/10).
Processing time varied with processing mode, video duration (both p <= 0.001),
and machine computational power (p = 0.041). Endoshare provides a transparent,
user-friendly pipeline for standardized, privacy-preserving surgical video
management. Compliance certification and broader interoperability validation
are needed to establish it as a deployable alternative to proprietary systems.
The software is available at https://camma-public.github.io/Endoshare/

</details>


### [8] [StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback](https://arxiv.org/abs/2510.20093)
*Jiho Park,Sieun Choi,Jaeyoon Seo,Jihie Kim*

Main category: cs.CV

TL;DR: 提出了一种名为StableSketcher的新框架，用于生成与提示高度一致的手绘草图，提高了风格忠实度。引入了一个新的基于视觉问题回答的奖励函数，以改进文本图像对齐和语义一致性。此外，还引入了SketchDUO数据集，这是已知的第一个包含实例级草图、伴随说明和问答对的数据集，这套研究增强了现有基于图像标签配对数据集的局限性。计划公开发布代码和数据集。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在生成数字化内容方面的质量得到了显著提高，但对于生成像素级手绘草图（一种抽象表现的代表性案例），仍然存在挑战。提出StableSketcher来克服这些挑战，改进生成手绘草图的风格忠实度和提示一致性。同时，解决现有数据集中存在的局限性。

Method: 框架包括：1）改进了变分自编码器，通过优化潜在解码来更好地捕捉草图特征；2）引入了一个基于视觉问答的新型奖励函数，以促进文本图像对齐和语义一致性；3）开发了一个名为SketchDUO的新数据集。

Result: StableSketcher在与驱动提示的准确性、保持手绘草图风格质量方面优于基准的Stable Diffusion模型。此外，首次提出全新的数据集SketchDUO。系统将公开可用。

Conclusion: StableSketcher显著改进了手绘草图的生成，达到了更高的风格忠实度，且与提示的匹配度更高；并提出了新型数据集SketchDUO，弥补了现有数据集的不足。该系统和数据集将共享给研究社区。

Abstract: Although recent advancements in diffusion models have significantly enriched
the quality of generated images, challenges remain in synthesizing pixel-based
human-drawn sketches, a representative example of abstract expression. To
combat these challenges, we propose StableSketcher, a novel framework that
empowers diffusion models to generate hand-drawn sketches with high prompt
fidelity. Within this framework, we fine-tune the variational autoencoder to
optimize latent decoding, enabling it to better capture the characteristics of
sketches. In parallel, we integrate a new reward function for reinforcement
learning based on visual question answering, which improves text-image
alignment and semantic consistency. Extensive experiments demonstrate that
StableSketcher generates sketches with improved stylistic fidelity, achieving
better alignment with prompts compared to the Stable Diffusion baseline.
Additionally, we introduce SketchDUO, to the best of our knowledge, the first
dataset comprising instance-level sketches paired with captions and
question-answer pairs, thereby addressing the limitations of existing datasets
that rely on image-label pairs. Our code and dataset will be made publicly
available upon acceptance.

</details>


### [9] [BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models](https://arxiv.org/abs/2510.20095)
*Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu*

Main category: cs.CV

TL;DR: 本文研究了描述性字幕作为生物多模态基础模型的额外监督来源。通过合成字幕训练BIOCAP模型，该模型在物种分类和图文检索中表现出色。


<details>
  <summary>Details</summary>
Motivation: 生物图像和字幕可以视为物种潜在形态空间的互补样本，通过训练鼓励与此潜在结构的对齐，强调潜在的诊断特征并抑制虚假相关性。这是通过用多模态大语言模型生成的合成字幕实现的，这些字幕基于维基百科派生的视觉信息量身定制，减少了幻觉，使得准确的实例描述成为可能。

Method: 使用多模态大语言模型（MLLMs），结合基于维基百科的视觉信息和特定于分类的格式示例，生成合成字幕。使用这些字幕训练BIOCAP模型，该模型能够捕捉丰富的语义，并在物种分类和图文检索任务中实现强大的性能。

Result: 使用合成字幕训练的BIOCAP模型在物种分类和图文检索中表现出强烈性能，这证明了描述性字幕在多模态基础模型中捕捉生物图像价值方面的重要性。

Conclusion: 合成描述性字幕可以作为一种新的监督来源促进生物多模态基础模型的发展，展示了其在生物学中的巨大应用潜力。

Abstract: This work investigates descriptive captions as an additional source of
supervision for biological multimodal foundation models. Images and captions
can be viewed as complementary samples from the latent morphospace of a
species, each capturing certain biological traits. Incorporating captions
during training encourages alignment with this shared latent structure,
emphasizing potentially diagnostic characters while suppressing spurious
correlations. The main challenge, however, lies in obtaining faithful,
instance-specific captions at scale. This requirement has limited the
utilization of natural language supervision in organismal biology compared with
many other scientific domains. We complement this gap by generating synthetic
captions with multimodal large language models (MLLMs), guided by
Wikipedia-derived visual information and taxon-tailored format examples. These
domain-specific contexts help reduce hallucination and yield accurate,
instance-based descriptive captions. Using these captions, we train BIOCAP
(i.e., BIOCLIP with Captions), a biological foundation model that captures rich
semantics and achieves strong performance in species classification and
text-image retrieval. These results demonstrate the value of descriptive
captions beyond labels in bridging biological images with multimodal foundation
models.

</details>


### [10] [Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects](https://arxiv.org/abs/2510.20126)
*Prithvi Raj Singh,Raju Gottumukkala,Anthony S. Maida,Alan B. Barhorst,Vijaya Gopu*

Main category: cs.CV

TL;DR: 本文提出了一种结合深度学习和基于物理模型跟踪的新型系统，用于快速移动的小物体的3D检测和跟踪，尤其在处理遮挡和方向快速变化等情况时表现优越。测试表明，相比卡尔曼滤波器，新系统平均位移误差减少了70%。该系统适用于提升自主平台的机器人感知能力，并展示了将物理模型与深度学习结合的有效性。


<details>
  <summary>Details</summary>
Motivation: 目前基于计算机视觉的通用目标检测和跟踪技术已经取得了长足的进步，但快速移动的小物体的检测和跟踪仍然是一个未被充分研究的问题。这篇论文的目标是解决快速移动的小物体的检测和跟踪的重大挑战，特别是在3D空间中。解决这个问题对于提升自主平台的机器人感知能力至关重要。

Method: 本文提出了一套综合设计的系统，结合了基于深度学习的检测和基于物理模型的跟踪技术。该系统包括：1. 设计了一个用于快速移动小物体检测和跟踪的全面系统；2. 开发了一个创新的基于物理模型的跟踪算法，该算法将运动方程与异常检测结合在一起，以处理离群值和丢失检测；3. 设计了一个异常检测和纠正模块，该模块在诸如遮挡和快速方向变化的困难场景中显著提高了跟踪性能。

Result: 本文提出系统的评估在定制的壁球数据集上进行，结果显示，与基于卡尔曼滤波器的跟踪器相比，新系统在平均位移误差方面的表现有70%的提高。这些结果表明，系统在处理快速移动的小物体时具有很高的准确性和鲁棒性。

Conclusion: 研究表明，该系统显著提升了在处理快速移动的小物体时的检测和跟踪准确性。新系统展示了将物理模型与深度学习方法相结合的潜力，特别是在实时三维检测和跟踪具有挑战性的物体方面的有效性。这为未来的机器人感知研究开辟了新的可能性。

Abstract: While computer vision has advanced considerably for general object detection
and tracking, the specific problem of fast-moving tiny objects remains
underexplored. This paper addresses the significant challenge of detecting and
tracking rapidly moving small objects using an RGB-D camera. Our novel system
combines deep learning-based detection with physics-based tracking to overcome
the limitations of existing approaches. Our contributions include: (1) a
comprehensive system design for object detection and tracking of fast-moving
small objects in 3D space, (2) an innovative physics-based tracking algorithm
that integrates kinematics motion equations to handle outliers and missed
detections, and (3) an outlier detection and correction module that
significantly improves tracking performance in challenging scenarios such as
occlusions and rapid direction changes. We evaluated our proposed system on a
custom racquetball dataset. Our evaluation shows our system surpassing kalman
filter based trackers with up to 70\% less Average Displacement Error. Our
system has significant applications for improving robot perception on
autonomous platforms and demonstrates the effectiveness of combining
physics-based models with deep learning approaches for real-time 3D detection
and tracking of challenging small objects.

</details>


### [11] [Inverse Image-Based Rendering for Light Field Generation from Single Images](https://arxiv.org/abs/2510.20132)
*Hyunjun Jung,Hae-Gon Jeon*

Main category: cs.CV

TL;DR: 提出了一种从单张图像生成光场的新方法，名为反向图像基渲染。通过设计一个神经渲染管线来渲染目标视点的光线颜色，使得可以从单张图像中合成新的视图，并且对于各种具有挑战性的数据集表现良好，优于现有的状态-of-the-art方法。


<details>
  <summary>Details</summary>
Motivation: 传统的光场获取需要大量的计算成本或特殊装置，如复杂的相机设置和微透镜阵列等。本文旨在减少这些需求，通过从单张图像生成光场来提高光场技术的实用性和适用性。

Method: 设计了一种神经渲染管线，首先存储输入图像的光线流，然后通过交叉注意力计算它们之间的关系，最后基于这些关系预测目标光线的颜色。每次渲染生成的新视图后，将生成的超出视图的内容更新到源光线集中，这个过程会迭代进行以确保遮挡内容的一致生成。

Result: 该方法在各种具有挑战性的数据集上表现良好，无需重新训练或微调，且优于现有的状态-of-the-art方法。

Conclusion: 我们提出了一种新的光场生成方法，只需要单张图像就能生成新的视图，这证明了反向图像基渲染的有效性，拓宽了光场技术的应用范围。

Abstract: A concept of light-fields computed from multiple view images on regular grids
has proven its benefit for scene representations, and supported realistic
renderings of novel views and photographic effects such as refocusing and
shallow depth of field. In spite of its effectiveness of light flow
computations, obtaining light fields requires either computational costs or
specialized devices like a bulky camera setup and a specialized microlens
array. In an effort to broaden its benefit and applicability, in this paper, we
propose a novel view synthesis method for light field generation from only
single images, named inverse image-based rendering. Unlike previous attempts to
implicitly rebuild 3D geometry or to explicitly represent objective scenes, our
method reconstructs light flows in a space from image pixels, which behaves in
the opposite way to image-based rendering. To accomplish this, we design a
neural rendering pipeline to render a target ray in an arbitrary viewpoint. Our
neural renderer first stores the light flow of source rays from the input
image, then computes the relationships among them through cross-attention, and
finally predicts the color of the target ray based on these relationships.
After the rendering pipeline generates the first novel view from a single input
image, the generated out-of-view contents are updated to the set of source
rays. This procedure is iteratively performed while ensuring the consistent
generation of occluded contents. We demonstrate that our inverse image-based
rendering works well with various challenging datasets without any retraining
or finetuning after once trained on synthetic dataset, and outperforms relevant
state-of-the-art novel view synthesis methods.

</details>


### [12] [Revisiting Logit Distributions for Reliable Out-of-Distribution Detection](https://arxiv.org/abs/2510.20134)
*Jiachen Liang,Ruibing Hou,Minyang Hu,Hong Chang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 提出了LogitGap，一种新的后处理方法，用于提升深度学习模型在处理未见过的数据时的检测能力。该方法通过分析模型输出概率分布中的最大值和其他值的关系，增强了已知数据和未知数据之间的区分度，同时也提出了一种无需训练即可识别最能体现未知数据特征的输出概率的方法。实验结果表明，LogitGap在多种模型和检测任务中，表现优于现有的方法，达到了当前的最优水平。


<details>
  <summary>Details</summary>
Motivation: 论文旨在解决深度学习模型在未知数据检测方面的能力局限，特别是利用原本被广泛忽略的模型输出空间中的信息，提出一种既实用又高效的检测方案，提升模型可靠性。

Method: 提出了LogitGap方法，使用模型输出logits之间的关系来提高已知数据和未知数据的区分度，并采用无需训练的方法来自动识别能最好地表征未知数据特征的logits集。

Result: 实验结果展现LogitGap在多种模型和检测场景中都取得了超越现有方法的表现，使该方法适用于多种类型的任务，具有很强的实用性。

Conclusion: 通过引入LogitGap方法，显著增强了深度学习模型在未知数据检测方面的性能，为提高模型的可靠性提供了一种可行的方法。

Abstract: Out-of-distribution (OOD) detection is critical for ensuring the reliability
of deep learning models in open-world applications. While post-hoc methods are
favored for their efficiency and ease of deployment, existing approaches often
underexploit the rich information embedded in the model's logits space. In this
paper, we propose LogitGap, a novel post-hoc OOD detection method that
explicitly exploits the relationship between the maximum logit and the
remaining logits to enhance the separability between in-distribution (ID) and
OOD samples. To further improve its effectiveness, we refine LogitGap by
focusing on a more compact and informative subset of the logit space.
Specifically, we introduce a training-free strategy that automatically
identifies the most informative logits for scoring. We provide both theoretical
analysis and empirical evidence to validate the effectiveness of our approach.
Extensive experiments on both vision-language and vision-only models
demonstrate that LogitGap consistently achieves state-of-the-art performance
across diverse OOD detection scenarios and benchmarks. Code is available at
https://github.com/GIT-LJc/LogitGap.

</details>


### [13] [PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding](https://arxiv.org/abs/2510.20155)
*Penghao Wang,Yiyang He,Xin Lv,Yukai Zhou,Lan Xu,Jingyi Yu,Jiayuan Gu*

Main category: cs.CV

TL;DR: 介绍了一个新的数据集PartNeXt，用于提高对3D物体组成部分的理解，特别是在细粒度和层次结构方面。另外，PartNeXt还展示了在3D部分分割和3D部分问题问答任务中的优势，并证明了其质量优于之前的PartNet数据集。


<details>
  <summary>Details</summary>
Motivation: 当前的3D数据集（如PartNet）存在不足，例如未纹理化和依赖专家注释，这些都限制了其可扩展性和可用性。因此，该研究引入了一种新的数据集PartNeXt，以推动计算机视觉、图形学和机器人领域中对于物体组成部件的理解。

Method: 该研究构建了PartNeXt数据集，包含超过23000个带有纹理的高质量3D模型，注释了50个类别中的细粒度层次部件标签。并在两个任务上进行了基准测试：（1）非特定类别的部分分割；（2）3D部分问题回答的新基准。研究还展示了在PartNet数据集上训练Point-SAM可获得显著的性能提升，以此证明了PartNeXt数据集的卓越质量。

Result: PartNeXt数据集在细粒度和层次结构的3D部分分割任务上取得了出色的成绩，并且在3D部分问题回答新任务中也表现出色，这表明之前的方法对于这些任务来说有较大的提升空间。另外，基于PartNeXt训练的模型相对基于PartNet的模型表现更好，这表明了数据集中元素的质量和多样性。

Conclusion: PartNeXt通过结合可扩展标注、纹理感知标签和多任务评估，为3D结构理解研究开辟了新的道路。

Abstract: Understanding objects at the level of their constituent parts is fundamental
to advancing computer vision, graphics, and robotics. While datasets like
PartNet have driven progress in 3D part understanding, their reliance on
untextured geometries and expert-dependent annotation limits scalability and
usability. We introduce PartNeXt, a next-generation dataset addressing these
gaps with over 23,000 high-quality, textured 3D models annotated with
fine-grained, hierarchical part labels across 50 categories. We benchmark
PartNeXt on two tasks: (1) class-agnostic part segmentation, where
state-of-the-art methods (e.g., PartField, SAMPart3D) struggle with
fine-grained and leaf-level parts, and (2) 3D part-centric question answering,
a new benchmark for 3D-LLMs that reveals significant gaps in open-vocabulary
part grounding. Additionally, training Point-SAM on PartNeXt yields substantial
gains over PartNet, underscoring the dataset's superior quality and diversity.
By combining scalable annotation, texture-aware labels, and multi-task
evaluation, PartNeXt opens new avenues for research in structured 3D
understanding.

</details>


### [14] [Monocular Visual 8D Pose Estimation for Articulated Bicycles and Cyclists](https://arxiv.org/abs/2510.20158)
*Eduardo R. Corral-Soto,Yang Liu,Yuan Ren,Bai Dongfeng,Liu Bingbing*

Main category: cs.CV

TL;DR: 提出了一个从单张RGB图像估计自行车8D姿态的方法，该方法不仅估计了自行车的3D旋转和平移，还估计了车把和踏板相对于车身的旋转。这使得能够估计更精细的自行车姿态和行驶方向。该模型通过合成和真实图像数据的混合训练，以实现在真实图像上的泛化能力。与使用刚性标准物体模板进行匹配的最新6D姿态估计器相比，该方法表现出色，取得了竞争性的结果。


<details>
  <summary>Details</summary>
Motivation: 当前的6D姿态估计方法无法准确估计自行车的细化姿态和行驶方向，因为它们无法捕捉到自行车上的关节运动，如车把和踏板的角度变化。因此，需要一种方法可以准确估计这些姿态参数。这不仅是确保自动驾驶车辆在遇到骑自行车者时能够安全操作的关键，而且也是骑自行车行为预测和碰撞规避的重要组成部分。

Method: 提出了一种基于单一RGB图像估计自行车8D姿态的方法，该方法除了可以估计自行车的3D旋转和平移外，还可以估计车把和踏板的旋转角。此方法通过同时估计8D姿态和3D关键点实现了细节提取，并通过合成与真实图像数据组合训练提升了泛化能力。该模型使用合成图像数据补充真实图像数据训练以提高其鲁棒性和精度。

Result: 所提方法在估计自行车8D姿态参数的准确性方面表现出色，且在与目前用于刚性标准物体模板匹配的最先进的6D姿态估计器比较时，达到了竞争性强的结果。这证明了该方法的有效性和先进的姿态估计能力。

Conclusion: 改进的8D姿态估计方法克服了现有6D方法在估计自行车细化姿态上的不足，通过准确估计自行车的细节运动姿态和行驶方向，有助于提高自动驾驶汽车的安全性，特别是在遇到骑自行车者时的决策准确性上。该方法也为相关领域的研究提供了新的方向和视角。

Abstract: In Autonomous Driving, cyclists belong to the safety-critical class of
Vulnerable Road Users (VRU), and accurate estimation of their pose is critical
for cyclist crossing intention classification, behavior prediction, and
collision avoidance. Unlike rigid objects, articulated bicycles are composed of
movable rigid parts linked by joints and constrained by a kinematic structure.
6D pose methods can estimate the 3D rotation and translation of rigid bicycles,
but 6D becomes insufficient when the steering/pedals angles of the bicycle
vary. That is because: 1) varying the articulated pose of the bicycle causes
its 3D bounding box to vary as well, and 2) the 3D box orientation is not
necessarily aligned to the orientation of the steering which determines the
actual intended travel direction. In this work, we introduce a method for
category-level 8D pose estimation for articulated bicycles and cyclists from a
single RGB image. Besides being able to estimate the 3D translation and
rotation of a bicycle from a single image, our method also estimates the
rotations of its steering handles and pedals with respect to the bicycle body
frame. These two new parameters enable the estimation of a more fine-grained
bicycle pose state and travel direction. Our proposed model jointly estimates
the 8D pose and the 3D Keypoints of articulated bicycles, and trains with a mix
of synthetic and real image data to generalize on real images. We include an
evaluation section where we evaluate the accuracy of our estimated 8D pose
parameters, and our method shows promising results by achieving competitive
scores when compared against state-of-the-art category-level 6D pose estimators
that use rigid canonical object templates for matching.

</details>


### [15] [TOMCAT: Test-time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning](https://arxiv.org/abs/2510.20162)
*Xudong Yan,Songhe Feng*

Main category: cs.CV

TL;DR: 该论文提出了一种新型方法，通过在测试时利用无监督数据更新跨模态原型，解决组成零样本学习中存在的标签空间分布变化问题。该方法通过自适应更新权重和动态优先级队列来提高模型的灵活性和适应性，同时采用多模态协作表示学习来保持多模态知识的语义一致性。实验结果表明该方法在四个基准数据集上的表现优于当前最优方法。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在测试时由于标签空间分布的变化性能会下降，因此作者提出了新的方法来解决这个问题，提出了更新原型的方案，提高了模型的灵活性和适应性，同时保持了多模态知识的语义一致性。

Method: 该方法通过无监督数据积累全面知识，并在测试时更新跨模态原型。同时引入自适应更新权重和动态优先级队列来控制原型调整的程度，并采用多模态协作表示学习来对齐文本和视觉原型。

Result: 本文的方法在四个基准数据集上的表现优于当前最优方法，并适用于封闭世界和开放世界的设置。

Conclusion: 论文提出了一种新的CZSL方法，该方法通过更新原型来应对分布变化，并通过设计的策略提高了模型的适应性和性能，同时保持了多模态知识的语义一致性。

Abstract: Compositional Zero-Shot Learning (CZSL) aims to recognize novel
attribute-object compositions based on the knowledge learned from seen ones.
Existing methods suffer from performance degradation caused by the distribution
shift of label space at test time, which stems from the inclusion of unseen
compositions recombined from attributes and objects. To overcome the challenge,
we propose a novel approach that accumulates comprehensive knowledge in both
textual and visual modalities from unsupervised data to update multimodal
prototypes at test time. Building on this, we further design an adaptive update
weight to control the degree of prototype adjustment, enabling the model to
flexibly adapt to distribution shift during testing. Moreover, a dynamic
priority queue is introduced that stores high-confidence images to acquire
visual knowledge from historical images for inference. Considering the semantic
consistency of multimodal knowledge, we align textual and visual prototypes by
multimodal collaborative representation learning. Extensive experiments
indicate that our approach achieves state-of-the-art performance on four
benchmark datasets under both closed-world and open-world settings. Code will
be available at https://github.com/xud-yan/TOMCAT .

</details>


### [16] [IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks](https://arxiv.org/abs/2510.20165)
*Insu Jeon,Wonkwang Lee,Myeongjang Pyeon,Gunhee Kim*

Main category: cs.CV

TL;DR: IB-GAN 是一种基于GAN的无监督模型，用于学习解纠缠表示，通过利用信息瓶颈框架优化生成器的中间层来约束输入和生成输出之间的互信息。实验表明，IB-GAN 在dSprites和Color-dSprites数据集上达到或优于最先进的η-VAE方法，并在CelebA和3D Chairs数据集上生成高质量和多样性的样本。


<details>
  <summary>Details</summary>
Motivation: 动机是利用信息瓶颈框架改进GAN，以实现更解纠缠的表示学习。通过约束生成器中间层输入和生成输出之间的互信息，使生成器可以以解纠缠且可解释的方式利用潜在空间。这是对原始InfoGAN的一种改进，增加了对生成过程的控制和理解。

Method: IB-GAN 使用信息瓶颈框架改进GAN，引入了一个中间的随机层，并通过约束该层的互信息来优化模型。此层可以作为一个可学习的潜在分布，与生成器联合训练。通过这种方法，生成器能够产生更加解纠缠且可解释的表示。实验中在dSprites和Color-dSprites数据集上验证了该方法的有效性。此外，对于CelebA和3D Chairs数据集，IB-GAN 生成的样本质量和多样性也更优。

Result: 实验结果表明，IB-GAN 在dSprites和Color-dSprites数据集上的解纠缠得分与最先进的η-VAE 方法相当或更高。IB-GAN 在CelebA和3D Chairs数据集上生成的样本在FID分数方面优于η-VAE和InfoGAN。

Conclusion: 通过引入信息瓶颈框架和新的中间层，IB-GAN 在无监督学习中提供了更好的解纠缠表示。这不仅在理论上有意义，实验结果也证实了其优越性。

Abstract: We propose a new GAN-based unsupervised model for disentangled representation
learning. The new model is discovered in an attempt to utilize the Information
Bottleneck (IB) framework to the optimization of GAN, thereby named IB-GAN. The
architecture of IB-GAN is partially similar to that of InfoGAN but has a
critical difference; an intermediate layer of the generator is leveraged to
constrain the mutual information between the input and the generated output.
The intermediate stochastic layer can serve as a learnable latent distribution
that is trained with the generator jointly in an end-to-end fashion. As a
result, the generator of IB-GAN can harness the latent space in a disentangled
and interpretable manner. With the experiments on dSprites and Color-dSprites
dataset, we demonstrate that IB-GAN achieves competitive disentanglement scores
to those of state-of-the-art \b{eta}-VAEs and outperforms InfoGAN. Moreover,
the visual quality and the diversity of samples generated by IB-GAN are often
better than those by \b{eta}-VAEs and Info-GAN in terms of FID score on CelebA
and 3D Chairs dataset.

</details>


### [17] [PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching](https://arxiv.org/abs/2510.20178)
*Yun Wang,Junjie Hu,Qiaole Dong,Yongjian Zhang,Yanwei Fu,Tin Lun Lam,Dapeng Wu*

Main category: cs.CV

TL;DR: 提出了一种新的方法PPMStereo，用于从立体视频中进行时空一致性的深度估计。该方法通过引入一个内存缓冲机制，能够有效地进行动态立体匹配，并且表现出色，在准确性和时间一致性上均优于现有方法，同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保证计算效率的同时，有效地建模长期时间一致性，为此，提出了一个具备长期空间时间一致性建模功能的内存缓冲机制，以解决这个问题。

Method: 提出PPMStereo框架，其中包含'挑选'过程来识别最相关的帧，以及一个'重播'过程来选择性地加权选定的帧，以完成时空整合，使之成为一个有效进行动态立体匹配且保持紧凑性的内存缓冲机制。

Result: 实验表明，PPMStereo在准确性和时间一致性方面的表现优于现有方法，尤其是在Sintel Clean和Final数据集上，分别实现了比BiDAStereo高出17.3%和9.02%的提高，同时减少了计算成本。

Conclusion: 通过引入PPM模块，PPMStereo有效解决了在保持计算效率的同时建模长程时空一致性的挑战，证明了在立体视频深度估计中的卓越表现。

Abstract: Temporally consistent depth estimation from stereo video is critical for
real-world applications such as augmented reality, where inconsistent depth
estimation disrupts the immersion of users. Despite its importance, this task
remains challenging due to the difficulty in modeling long-term temporal
consistency in a computationally efficient manner. Previous methods attempt to
address this by aggregating spatio-temporal information but face a fundamental
trade-off: limited temporal modeling provides only modest gains, whereas
capturing long-range dependencies significantly increases computational cost.
To address this limitation, we introduce a memory buffer for modeling
long-range spatio-temporal consistency while achieving efficient dynamic stereo
matching. Inspired by the two-stage decision-making process in humans, we
propose a \textbf{P}ick-and-\textbf{P}lay \textbf{M}emory (PPM) construction
module for dynamic \textbf{Stereo} matching, dubbed as \textbf{PPMStereo}. PPM
consists of a `pick' process that identifies the most relevant frames and a
`play' process that weights the selected frames adaptively for spatio-temporal
aggregation. This two-stage collaborative process maintains a compact yet
highly informative memory buffer while achieving temporally consistent
information aggregation. Extensive experiments validate the effectiveness of
PPMStereo, demonstrating state-of-the-art performance in both accuracy and
temporal consistency. % Notably, PPMStereo achieves 0.62/1.11 TEPE on the
Sintel clean/final (17.3\% \& 9.02\% improvements over BiDAStereo) with fewer
computational costs. Codes are available at
\textcolor{blue}{https://github.com/cocowy1/PPMStereo}.

</details>


### [18] [A Structured Review and Quantitative Profiling of Public Brain MRI Datasets for Foundation Model Development](https://arxiv.org/abs/2510.20196)
*Minh Sao Khue Luu,Margaret V. Benedichuk,Ekaterina I. Roppert,Roman M. Kenzhin,Bair N. Tuchinov*

Main category: cs.CV

TL;DR: 该研究对54个公共的大脑MRI数据集进行了分析，这些数据集包含超过538,031个MRI图像，展示了大规模的脑部健康群体与小规模临床群体之间存在的不平衡，并且揭示了数据集在预处理后仍存在的不一致性。研究结论强调了在大脑MRI基础模型设计中需要采取预处理意识和领域适应的策略以提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有大脑MRI基础模型的发展严重依赖于数据的规模、多样性和一致性，然而对其系统评估尚不充分。该研究旨在通过分析多个公开的MRI数据集，揭示大脑MRI数据中存在的差异与不一致性，并提出相应策略以改善基础模型设计。

Method: 该研究通过分析包含538,031个MRI图像的54个公开数据集，从数据集层面和图像层面量化了数据间的差异，并且评估了预处理步骤（如强度标准化、偏场校正、颅骨剥离、空间配准和插值）对于数据一致性的改善效果。此外，通过运用3D DenseNet121模型进行了案例研究，进一步证明了在标准化预处理后仍存在协变量偏移。

Result: 研究表明，大规模健康的脑部群体与小规模的临床群体之间存在显著差异，并且尽管预处理可以改善数据内部一致性，但仍存在跨数据集的不一致性。使用3D DenseNet121模型的案例研究也证实了这一点，表明标准化预处理后，仍存在可测量的协变量偏移。

Conclusion: 整体来看，该研究提供了公共MRI资源中变化情况的全面描述，并强调了在基础模型设计中需要采用预处理意识和领域适应性的策略，以提高大脑MRI基础模型的泛化能力。

Abstract: The development of foundation models for brain MRI depends critically on the
scale, diversity, and consistency of available data, yet systematic assessments
of these factors remain scarce. In this study, we analyze 54 publicly
accessible brain MRI datasets encompassing over 538,031 to provide a
structured, multi-level overview tailored to foundation model development. At
the dataset level, we characterize modality composition, disease coverage, and
dataset scale, revealing strong imbalances between large healthy cohorts and
smaller clinical populations. At the image level, we quantify voxel spacing,
orientation, and intensity distributions across 15 representative datasets,
demonstrating substantial heterogeneity that can influence representation
learning. We then perform a quantitative evaluation of preprocessing
variability, examining how intensity normalization, bias field correction,
skull stripping, spatial registration, and interpolation alter voxel statistics
and geometry. While these steps improve within-dataset consistency, residual
differences persist between datasets. Finally, feature-space case study using a
3D DenseNet121 shows measurable residual covariate shift after standardized
preprocessing, confirming that harmonization alone cannot eliminate
inter-dataset bias. Together, these analyses provide a unified characterization
of variability in public brain MRI resources and emphasize the need for
preprocessing-aware and domain-adaptive strategies in the design of
generalizable brain MRI foundation models.

</details>


### [19] [RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling](https://arxiv.org/abs/2510.20206)
*Bingjie Gao,Qianli Ma,Xiaoxue Wu,Shuai Yang,Guanzhou Lan,Haonan Zhao,Jiaxuan Chen,Qingyang Liu,Yu Qiao,Xinyuan Chen,Yaohui Wang,Li Niu*

Main category: cs.CV

TL;DR: RAPO++ 提出了一种跨阶段提示优化框架，用于大幅提高文本到视频生成的质量，通过采用训练数据对齐的细化、测试阶段的迭代扩展以及大语言模型的微调，无需修改基础生成模型即可改进文本到视频(T2V)生成过程。实验表明，RAPO++ 在语义对齐、组成推理、时间稳定性以及物理逼真度上显著优于现有方法，确立了提示优化的新标准。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频(T2V)生成中的用户提供的提示通常是简短、无结构且与训练数据不匹配，这限制了扩散模型的生成能力。提出RAPO++ 以解决这些限制，提高T2V生成的质量而不修改基础模型。

Method: RAPO++包含三个阶段：第一阶段（RAPO）为用户提供模棱两可的提示；第二阶段（SSPO）使用多源反馈迭代改进提示；第三阶段采用优化的提示对进一步微调语言模型，实现高效的高质量提示生成。

Result: 实验显示，RAPO++在语义对齐、组合推理、时间稳定性和物理逼真度上均取得了显著改善，证明其在文本到视频生成中的优势。

Conclusion: RAPO++作为一种模型无关的、成本效益高且可扩展的方法，在文本到视频生成中的提示优化中树立了新标杆。

Abstract: Prompt design plays a crucial role in text-to-video (T2V) generation, yet
user-provided prompts are often short, unstructured, and misaligned with
training data, limiting the generative potential of diffusion-based T2V models.
We present \textbf{RAPO++}, a cross-stage prompt optimization framework that
unifies training-data--aligned refinement, test-time iterative scaling, and
large language model (LLM) fine-tuning to substantially improve T2V generation
without modifying the underlying generative backbone. In \textbf{Stage 1},
Retrieval-Augmented Prompt Optimization (RAPO) enriches user prompts with
semantically relevant modifiers retrieved from a relation graph and refactors
them to match training distributions, enhancing compositionality and
multi-object fidelity. \textbf{Stage 2} introduces Sample-Specific Prompt
Optimization (SSPO), a closed-loop mechanism that iteratively refines prompts
using multi-source feedback -- including semantic alignment, spatial fidelity,
temporal coherence, and task-specific signals such as optical flow -- yielding
progressively improved video generation quality. \textbf{Stage 3} leverages
optimized prompt pairs from SSPO to fine-tune the rewriter LLM, internalizing
task-specific optimization patterns and enabling efficient, high-quality prompt
generation even before inference. Extensive experiments across five
state-of-the-art T2V models and five benchmarks demonstrate that RAPO++
achieves significant gains in semantic alignment, compositional reasoning,
temporal stability, and physical plausibility, outperforming existing methods
by large margins. Our results highlight RAPO++ as a model-agnostic,
cost-efficient, and scalable solution that sets a new standard for prompt
optimization in T2V generation. The code is available at
https://github.com/Vchitect/RAPO.

</details>


### [20] [FlowCycle: Pursuing Cycle-Consistent Flows for Text-based Editing](https://arxiv.org/abs/2510.20212)
*Yanghao Wang,Zhen Wang,Long Chen*

Main category: cs.CV

TL;DR: 提出了FlowCycle框架，以实现基于文本的图像编辑时的中间状态为目标感知的形式，提高编辑的质量和一致性


<details>
  <summary>Details</summary>
Motivation: 当前方法构造中间状态时不考虑目标，这导致编辑一致性低，无法处理与源图像差距较大的修改任务

Method: FlowCycle使用可学习噪音参数化腐蚀过程，通过循环一致性方法优化，实现目标感知中间状态从而提高编辑质量和一致性

Result: 实验表明，FlowCycle在图像编辑质量和一致性上优于现有方法

Conclusion: 提出的目标感知中间状态设计及其实现方法可以显著提高基于文本的图像编辑效果

Abstract: Recent advances in pre-trained text-to-image flow models have enabled
remarkable progress in text-based image editing. Mainstream approaches always
adopt a corruption-then-restoration paradigm, where the source image is first
corrupted into an ``intermediate state'' and then restored to the target image
under the prompt guidance. However, current methods construct this intermediate
state in a target-agnostic manner, i.e., they primarily focus on realizing
source image reconstruction while neglecting the semantic gaps towards the
specific editing target. This design inherently results in limited editability
or inconsistency when the desired modifications substantially deviate from the
source. In this paper, we argue that the intermediate state should be
target-aware, i.e., selectively corrupting editing-relevant contents while
preserving editing-irrelevant ones. To this end, we propose FlowCycle, a novel
inversion-free and flow-based editing framework that parameterizes corruption
with learnable noises and optimizes them through a cycle-consistent process. By
iteratively editing the source to the target and recovering back to the source
with dual consistency constraints, FlowCycle learns to produce a target-aware
intermediate state, enabling faithful modifications while preserving source
consistency. Extensive ablations have demonstrated that FlowCycle achieves
superior editing quality and consistency over state-of-the-art methods.

</details>


### [21] [Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection](https://arxiv.org/abs/2510.20214)
*Talha Ilyas,Duong Nhu,Allison Thomas,Arie Levin,Lim Wei Yap,Shu Gong,David Vera Anaya,Yiwen Jiang,Deval Mehta,Ritesh Warty,Vinayak Smith,Maya Reddy,Euan Wallace,Wenlong Cheng,Zongyuan Ge,Faezeh Marzbanrad*

Main category: cs.CV

TL;DR: 提出了一种名为CURL的对比学习框架，用于从胎儿超声视频中检测胎儿运动，能够实现更准确、客观的胎儿运动分析，有助于改善产前监测和临床决策。


<details>
  <summary>Details</summary>
Motivation: 传统的胎儿运动检测方法，如孕妇感知和心电图，存在主观性和准确性低的问题。为了解决这些问题，提出了CURL方法，利用对比学习和任务特定的采样策略来提升胎儿运动检测的准确性。

Method: 采用自监督学习框架，通过空间和时间对比学习损失函数来学习鲁棒的运动表示。引入了一个任务特定的采样策略，以确保自我监督训练中有效分离运动和非运动片段，并支持任意长度超声视频的推断。

Result: 在92个受试者的内部数据集上评估，CURL达到了78.01%的灵敏度和81.60%的AUROC，表明了其在胎儿运动分析中的潜力。

Conclusion: CURL展示了自监督对比学习在胎儿运动检测方面的潜力，为产前监测和临床决策提供了新的工具和方法。

Abstract: Accurate fetal movement (FM) detection is essential for assessing prenatal
health, as abnormal movement patterns can indicate underlying complications
such as placental dysfunction or fetal distress. Traditional methods, including
maternal perception and cardiotocography (CTG), suffer from subjectivity and
limited accuracy. To address these challenges, we propose Contrastive
Ultrasound Video Representation Learning (CURL), a novel self-supervised
learning framework for FM detection from extended fetal ultrasound video
recordings. Our approach leverages a dual-contrastive loss, incorporating both
spatial and temporal contrastive learning, to learn robust motion
representations. Additionally, we introduce a task-specific sampling strategy,
ensuring the effective separation of movement and non-movement segments during
self-supervised training, while enabling flexible inference on arbitrarily long
ultrasound recordings through a probabilistic fine-tuning approach. Evaluated
on an in-house dataset of 92 subjects, each with 30-minute ultrasound sessions,
CURL achieves a sensitivity of 78.01% and an AUROC of 81.60%, demonstrating its
potential for reliable and objective FM analysis. These results highlight the
potential of self-supervised contrastive learning for fetal movement analysis,
paving the way for improved prenatal monitoring and clinical decision-making.

</details>


### [22] [EditInfinity: Image Editing with Binary-Quantized Generative Models](https://arxiv.org/abs/2510.20217)
*Jiahuan Wang,Yuxin Chen,Jun Yu,Guangming Lu,Wenjie Pei*

Main category: cs.CV

TL;DR: 提出了一种名为EditInfinity的方法，利用二值量化生成模型进行文本驱动的图像编辑，通过精确的图像逆向过程和整体平滑策略提高了图像编辑的质量和准确性，尤其在PIE-Bench基准上的实验展示了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的文本驱动图像编辑方法依赖于扩散模型的图像逆向过程，该过程中引入的近似误差限制了编辑性能，提出新的方法以改进图像逆向过程并减少近似误差。

Method: 利用二值量化生成模型，设计了高效的图像逆向机制和整体平滑策略，以实现文本驱动的精确图像编辑。具体实现包括精确的图像逆向过程，结合文本提示修正和图像风格保留，以及适应不同图像编辑操作的光滑策略。

Result: 实验结果表明，该方法在PIE-Bench基准测试中，无论是'添加'、'修改'、还是'删除'编辑操作，性能均优于现有的扩散模型基线方法。

Conclusion: 提出的方法有效提高了文本驱动图像编辑的质量，通过精确的图像逆向过程和整体平滑策略，增强了图像编辑的精准度和保真度。

Abstract: Adapting pretrained diffusion-based generative models for text-driven image
editing with negligible tuning overhead has demonstrated remarkable potential.
A classical adaptation paradigm, as followed by these methods, first infers the
generative trajectory inversely for a given source image by image inversion,
then performs image editing along the inferred trajectory guided by the target
text prompts. However, the performance of image editing is heavily limited by
the approximation errors introduced during image inversion by diffusion models,
which arise from the absence of exact supervision in the intermediate
generative steps. To circumvent this issue, we investigate the
parameter-efficient adaptation of VQ-based generative models for image editing,
and leverage their inherent characteristic that the exact intermediate
quantized representations of a source image are attainable, enabling more
effective supervision for precise image inversion. Specifically, we propose
\emph{EditInfinity}, which adapts \emph{Infinity}, a binary-quantized
generative model, for image editing. We propose an efficient yet effective
image inversion mechanism that integrates text prompting rectification and
image style preservation, enabling precise image inversion. Furthermore, we
devise a holistic smoothing strategy which allows our \emph{EditInfinity} to
perform image editing with high fidelity to source images and precise semantic
alignment to the text prompts. Extensive experiments on the PIE-Bench benchmark
across "add", "change", and "delete" editing operations, demonstrate the
superior performance of our model compared to state-of-the-art diffusion-based
baselines. Code available at: https://github.com/yx-chen-ust/EditInfinity.

</details>


### [23] [Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context](https://arxiv.org/abs/2510.20229)
*Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang*

Main category: cs.CV

TL;DR: 本文提出了一种新的'引入-检测-抑制'框架来减轻LVLMs中较长响应时的幻觉问题，该框架在所有基准上均表现出色，并验证了其对上下文依赖性的假设。


<details>
  <summary>Details</summary>
Motivation: 研究团队观察到LVLMs在生成较长响应时的幻觉问题，发现幻觉风险并非由响应长度直接引起，而是因为对上下文的依赖性增加有关。因此，他们希望通过更深入的研究探讨这种现象背后的原因并提出有效的解决方案。

Method: 提出了一种新的'引入-检测-抑制'框架，它通过精心设计的上下文主动引入幻觉，利用这些实例提前检测高风险情况，并在实际解码过程中抑制潜在的目标级幻觉。

Result: 该方法在所有基准测试上均实现了显著和一致的改进，证明了其有效性，并验证了他们的上下文依赖性假设。

Conclusion: 该研究不仅仅是为了提升性能，更重要的是提供了一个新的视角来理解和解决LVLM中较长响应时幻觉问题的机制，并为进一步研究奠定了基础。

Abstract: Large Vision-Language Models (LVLMs) have made significant progress in recent
years but are also prone to hallucination issues. They exhibit more
hallucinations in longer, free-form responses, often attributed to accumulated
uncertainties. In this paper, we ask: Does increased hallucination result
solely from length-induced errors, or is there a deeper underlying mechanism?
After a series of preliminary experiments and findings, we suggest that the
risk of hallucinations is not caused by length itself but by the increased
reliance on context for coherence and completeness in longer responses.
Building on these insights, we propose a novel "induce-detect-suppress"
framework that actively induces hallucinations through deliberately designed
contexts, leverages induced instances for early detection of high-risk cases,
and ultimately suppresses potential object-level hallucinations during actual
decoding. Our approach achieves consistent, significant improvements across all
benchmarks, demonstrating its efficacy. The strong detection and improved
hallucination mitigation not only validate our framework but, more importantly,
re-validate our hypothesis on context. Rather than solely pursuing performance
gains, this study aims to provide new insights and serves as a first step
toward a deeper exploration of hallucinations in LVLMs' longer responses.

</details>


### [24] [COS3D: Collaborative Open-Vocabulary 3D Segmentation](https://arxiv.org/abs/2510.20238)
*Runsong Zhu,Ka-Hei Hui,Zhengzhe Liu,Qianyi Wu,Weiliang Tang,Shi Qiu,Pheng-Ann Heng,Chi-Wing Fu*

Main category: cs.CV

TL;DR: COS3D是一种新的协作提示-分割框架，它能够有效地融合互补的语言和分割线索，解决了现有基于高斯点着色的方法存在的问题，如单一3D语言字段导致分割效果差，或预计算的非类别特定分割导致错误累积的问题。实验表明COS3D在两个广泛使用的基准上领先于现有方法，并且在各种应用中都显示出高潜力，如基于图像的3D分割、分层分割和机器人技术。


<details>
  <summary>Details</summary>
Motivation: 现有的基于高斯点着色的方法，要么依赖单个3D语言字段导致分割效果不佳，要么依赖预计算的非类别特定分割，导致错误累积。因此，提出了一种新的框架来解决这些限制，即COS3D，它能够有效地融合互补的语言和分割线索，提高分割精度和质量。

Method: COS3D首先引入了合作场的概念，包括实例场和语言场，作为协作的基础。在训练过程中，通过一种新的实例到语言的特征映射和高效的两阶段训练策略，能够有效地构建合作场。在推断过程中，设计了一种自适应的语言到实例的提示调整策略，以便将两个场的不同特征相联系，提高分割质量。

Result: 实验结果表明，COS3D在两个广泛使用的基准上超越了现有方法，证明了其优秀的性能。此外，它在各种应用中也显示出高潜力，如基于图像的3D分割、分层分割和机器人技术。

Conclusion: COS3D通过引入新的合作场概念，有效地融合了互补的语言和分割线索，解决了现有方法存在的问题，并在各种应用中都显示出高潜力。

Abstract: Open-vocabulary 3D segmentation is a fundamental yet challenging task,
requiring a mutual understanding of both segmentation and language. However,
existing Gaussian-splatting-based methods rely either on a single 3D language
field, leading to inferior segmentation, or on pre-computed class-agnostic
segmentations, suffering from error accumulation. To address these limitations,
we present COS3D, a new collaborative prompt-segmentation framework that
contributes to effectively integrating complementary language and segmentation
cues throughout its entire pipeline. We first introduce the new concept of
collaborative field, comprising an instance field and a language field, as the
cornerstone for collaboration. During training, to effectively construct the
collaborative field, our key idea is to capture the intrinsic relationship
between the instance field and language field, through a novel
instance-to-language feature mapping and designing an efficient two-stage
training strategy. During inference, to bridge distinct characteristics of the
two fields, we further design an adaptive language-to-instance prompt
refinement, promoting high-quality prompt-segmentation inference. Extensive
experiments not only demonstrate COS3D's leading performance over existing
methods on two widely-used benchmarks but also show its high potential to
various applications,~\ie, novel image-based 3D segmentation, hierarchical
segmentation, and robotics. The code is publicly available at
\href{https://github.com/Runsong123/COS3D}{https://github.com/Runsong123/COS3D}.

</details>


### [25] [Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding](https://arxiv.org/abs/2510.20244)
*Minseok Kang,Minhyeok Lee,Minjung Kim,Donghyeong Kim,Sangyoun Lee*

Main category: cs.CV

TL;DR: DualGround 是一种双分支架构，通过分离全局和局部语义来改善视频时间定位任务。此模型使视频特征与句子级和短语级语义结构化解耦，能够更好地捕捉粗粒度和局部语义，提高视频文本对齐的准确性。在QVHighlights 和 Charades-STA基准上实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频时间定位模型在处理跨模态注意力时，对所有文本标记进行均匀处理，未考虑其不同的语义角色。这导致模型过于依赖于全局语义而忽视了单词级别的信号，从而限制了其在时间对齐上的精细程度。

Method: 提出了一种双分支架构DualGround，它通过路由 [EOS] 标记通过句子级路径，将单词标记聚类成短语级单元来分离全局和局部语义，引入了以标记角色感知的跨模态交互策略，并结合结构化的短语感知上下文来提高全局句子级对齐及细化时间定位。

Result: 在Moment Retrieval 和 Highlight Detection 任务上，在QVHighlights 和 Charades-STA 基准上都达到了最新性能水平，展示了分离语义建模在视频文本对齐中的有效性。

Conclusion: DualGround 通过分离全局和局部语义，不仅可以提升全局句子级对齐，还能更精细地定位到视频中的时间片段，从而实现更精确和语境感知的视频时间对齐。

Abstract: Video Temporal Grounding (VTG) aims to localize temporal segments in long,
untrimmed videos that align with a given natural language query. This task
typically comprises two subtasks: Moment Retrieval (MR) and Highlight Detection
(HD). While recent advances have been progressed by powerful pretrained
vision-language models such as CLIP and InternVideo2, existing approaches
commonly treat all text tokens uniformly during crossmodal attention,
disregarding their distinct semantic roles. To validate the limitations of this
approach, we conduct controlled experiments demonstrating that VTG models
overly rely on [EOS]-driven global semantics while failing to effectively
utilize word-level signals, which limits their ability to achieve fine-grained
temporal alignment. Motivated by this limitation, we propose DualGround, a
dual-branch architecture that explicitly separates global and local semantics
by routing the [EOS] token through a sentence-level path and clustering word
tokens into phrase-level units for localized grounding. Our method introduces
(1) tokenrole- aware cross modal interaction strategies that align video
features with sentence-level and phrase-level semantics in a structurally
disentangled manner, and (2) a joint modeling framework that not only improves
global sentence-level alignment but also enhances finegrained temporal
grounding by leveraging structured phrase-aware context. This design allows the
model to capture both coarse and localized semantics, enabling more expressive
and context-aware video grounding. DualGround achieves state-of-the-art
performance on both Moment Retrieval and Highlight Detection tasks across
QVHighlights and Charades- STA benchmarks, demonstrating the effectiveness of
disentangled semantic modeling in video-language alignment.

</details>


### [26] [Seeing the Unseen: Mask-Driven Positional Encoding and Strip-Convolution Context Modeling for Cross-View Object Geo-Localization](https://arxiv.org/abs/2510.20247)
*Shuhan Hu,Yiru Li,Yuanyuan Li,Yingying Zhu*

Main category: cs.CV

TL;DR: 这篇文章提出了一种基于掩码的位置编码方案，以及上下文增强模块，用于改进跨视图对象地理定位的问题，特别是解决大范围对象（如长条形建筑）的地理定位难题。提出的方法在公开数据集上表现出了卓越的性能，特别是在具有挑战性的地面到卫星场景中，定位精度提高了3.39%。这为跨视图地理定位研究提供了坚实的位置编码和上下文建模框架。


<details>
  <summary>Details</summary>
Motivation: 现有的姿态地理定位方法依赖于基于关键点的位置编码方式，这仅捕获了二维坐标信息，忽略了物体形态信息，导致对标注位移敏感及跨视图匹配能力有限。

Method: 提出了一种基于掩码的位置编码 (MPE) 方案，利用分割掩码来同时捕捉空间坐标和物体形态，提升模型由“位置感知”到“对象感知”的转变，并通过水平和垂直条纹卷积核设计了上下文增强模块 (CEM) 用于提取长距离上下文特征以提高条形对象的特征区分度。结合MPE和CEM构建了EDGeo端到端框架。

Result: 在公开的CVOGL和VIGOR-Building数据集上进行了广泛的实验，结果显示所提出的方法在具有挑战性的地面到卫星场景下，定位精度比现有方法提高了3.39%。

Conclusion: 本文提供了一种稳健的位置编码范式和上下文建模框架，用以推动跨视图地理定位研究的发展。

Abstract: Cross-view object geo-localization enables high-precision object localization
through cross-view matching, with critical applications in autonomous driving,
urban management, and disaster response. However, existing methods rely on
keypoint-based positional encoding, which captures only 2D coordinates while
neglecting object shape information, resulting in sensitivity to annotation
shifts and limited cross-view matching capability. To address these
limitations, we propose a mask-based positional encoding scheme that leverages
segmentation masks to capture both spatial coordinates and object silhouettes,
thereby upgrading the model from "location-aware" to "object-aware."
Furthermore, to tackle the challenge of large-span objects (e.g., elongated
buildings) in satellite imagery, we design a context enhancement module. This
module employs horizontal and vertical strip convolutional kernels to extract
long-range contextual features, enhancing feature discrimination among
strip-like objects. Integrating MPE and CEM, we present EDGeo, an end-to-end
framework for robust cross-view object geo-localization. Extensive experiments
on two public datasets (CVOGL and VIGOR-Building) demonstrate that our method
achieves state-of-the-art performance, with a 3.39% improvement in localization
accuracy under challenging ground-to-satellite scenarios. This work provides a
robust positional encoding paradigm and a contextual modeling framework for
advancing cross-view geo-localization research.

</details>


### [27] [Calibrating Multimodal Consensus for Emotion Recognition](https://arxiv.org/abs/2510.20256)
*Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan*

Main category: cs.CV

TL;DR: 提出了一个名为Calibrated Multimodal Consensus (CMC) 的模型，用于解决多模态情感识别中的语义不一致和文本主导问题，通过自监督的伪标签生成模块、无参数融合模块和多模态共识路由器进行多模态微调，表现出色且解决了语义不一致问题


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态情感识别中忽视了跨模态的语义不一致性问题，且被文本模态主导，影响识别精度

Method: CMC引入了伪标签生成模块生成伪单模标签，用于自监督预训练；使用无参数融合模块和多模态共识路由器进行多模态微调

Result: 在四个数据集上，CMC性能与最先进的方法持平或更好，在CH-SIMS和CH-SIMS v2中表现出处理语义不一致性的显著优势

Conclusion: 实验表明，CMC能有效解决语义不一致性和文本主导问题，实现了优秀的多模态情感识别性能

Abstract: In recent years, Multimodal Emotion Recognition (MER) has made substantial
progress. Nevertheless, most existing approaches neglect the semantic
inconsistencies that may arise across modalities, such as conflicting emotional
cues between text and visual inputs. Besides, current methods are often
dominated by the text modality due to its strong representational capacity,
which can compromise recognition accuracy. To address these challenges, we
propose a model termed Calibrated Multimodal Consensus (CMC). CMC introduces a
Pseudo Label Generation Module (PLGM) to produce pseudo unimodal labels,
enabling unimodal pretraining in a self-supervised fashion. It then employs a
Parameter-free Fusion Module (PFM) and a Multimodal Consensus Router (MCR) for
multimodal finetuning, thereby mitigating text dominance and guiding the fusion
process toward a more reliable consensus. Experimental results demonstrate that
CMC achieves performance on par with or superior to state-of-the-art methods
across four datasets, CH-SIMS, CH-SIMS v2, CMU-MOSI, and CMU-MOSEI, and
exhibits notable advantages in scenarios with semantic inconsistencies on
CH-SIMS and CH-SIMS v2. The implementation of this work is publicly accessible
at https://github.com/gw-zhong/CMC.

</details>


### [28] [Real-Time Currency Detection and Voice Feedback for Visually Impaired Individuals](https://arxiv.org/abs/2510.20267)
*Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim*

Main category: cs.CV

TL;DR: 该论文提出了一种实时货币检测系统，帮助视障人士通过智能手机和机器学习技术独立处理货币。使用YOLOv8 nano模型进行货币识别，准确率达到97.73%。通过语音反馈辅助视障人士识别货币类型，提高其独立生活能力。


<details>
  <summary>Details</summary>
Motivation: 帮助视障人士独立处理货币，减轻他们的生活负担，提高生活质量。

Method: 使用YOLOv8 nano模型，搭配深度卷积层和SE块，对包含30种面额和类型的货币图像数据集进行训练。该模型采用了特别设计的检测头来提高特征提取和检测准确率。

Result: 该模型在测试集上取得了很好的效果，模型准确率为97.73%，召回率为95.23%，F1分数为95.85%且在IoU=0.5时的平均精度(mAP50(B))为97.21%。

Conclusion: 该系统旨在为视障人士提供一个实用且高效的货币检测方法，以帮助他们在处理货币时更加独立。

Abstract: Technologies like smartphones have become an essential in our daily lives. It
has made accessible to everyone including visually impaired individuals. With
the use of smartphone cameras, image capturing and processing have become more
convenient. With the use of smartphones and machine learning, the life of
visually impaired can be made a little easier. Daily tasks such as handling
money without relying on someone can be troublesome for them. For that purpose
this paper presents a real-time currency detection system designed to assist
visually impaired individuals. The proposed model is trained on a dataset
containing 30 classes of notes and coins, representing 3 types of currency: US
dollar (USD), Euro (EUR), and Bangladeshi taka (BDT). Our approach uses a
YOLOv8 nano model with a custom detection head featuring deep convolutional
layers and Squeeze-and-Excitation blocks to enhance feature extraction and
detection accuracy. Our model has achieved a higher accuracy of 97.73%, recall
of 95.23%, f1-score of 95.85% and a mean Average Precision at IoU=0.5
(mAP50(B)) of 97.21\%. Using the voice feedback after the detection would help
the visually impaired to identify the currency. This paper aims to create a
practical and efficient currency detection system to empower visually impaired
individuals independent in handling money.

</details>


### [29] [GMFVAD: Using Grained Multi-modal Feature to Improve Video Anomaly Detection](https://arxiv.org/abs/2510.20268)
*Guangyu Dai,Dong Chen,Siliang Tang,Yueting Zhuang*

Main category: cs.CV

TL;DR: 该论文提出了一种称为Grained Multi-modal Feature for Video Anomaly Detection (GMFVAD)的方法，旨在通过利用视频片段和文本特征的多样性来减少视觉特征的冗余性，并提升视频异常检测的效果。实验结果表明，GMFVAD在四个主要数据集上达到了最新水平的性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作在视频异常检测中往往粗略地结合多模态信息，未能有效地减少视频片段中的冗余信息。为了解决这一问题，作者提出了GMFVAD方法，旨在通过更细致地利用多模态信息，来减少视觉特征的冗余性，进而提升视频异常检测的效果和准确性。

Method: GMFVAD方法的核心在于生成更细致的多模态特征，具体来说，它以视频片段为基础生成详细特征，并利用原始视频字幕的文本特征来进一步增强被强调部分的视觉特征。进而通过这种方法来减少冗余信息，提升视频异常检测的效果和准确性。

Result: 实验结果表明，与现有方法相比，利用GMFVAD方法可以显著减少视频异常检测中的冗余信息，进而提升检测的准确性。具体来说，该方法在四个主要数据集上达到了最新水平的性能。

Conclusion: 该论文提出的GMFVAD方法通过利用视频片段和文本特征的多样性来减少冗余信息，对于提升视频异常检测的效果具有积极意义。

Abstract: Video anomaly detection (VAD) is a challenging task that detects anomalous
frames in continuous surveillance videos. Most previous work utilizes the
spatio-temporal correlation of visual features to distinguish whether there are
abnormalities in video snippets. Recently, some works attempt to introduce
multi-modal information, like text feature, to enhance the results of video
anomaly detection. However, these works merely incorporate text features into
video snippets in a coarse manner, overlooking the significant amount of
redundant information that may exist within the video snippets. Therefore, we
propose to leverage the diversity among multi-modal information to further
refine the extracted features, reducing the redundancy in visual features, and
we propose Grained Multi-modal Feature for Video Anomaly Detection (GMFVAD).
Specifically, we generate more grained multi-modal feature based on the video
snippet, which summarizes the main content, and text features based on the
captions of original video will be introduced to further enhance the visual
features of highlighted portions. Experiments show that the proposed GMFVAD
achieves state-of-the-art performance on four mainly datasets. Ablation
experiments also validate that the improvement of GMFVAD is due to the
reduction of redundant information.

</details>


### [30] [Causal Debiasing for Visual Commonsense Reasoning](https://arxiv.org/abs/2510.20281)
*Jiayi Zou,Gengyun Jia,Bing-Kun Bao*

Main category: cs.CV

TL;DR: 本文研究了视觉常识推理中的数据偏差问题，提出了一个新的评估集VCR-OOD，用于测试模型的泛化能力。并且引入了一种新的偏差消除方法，即通过创建基于正确答案字典的后门调整方法来去除预测捷径。实验结果表明该方法在不同数据集上都是有效的。


<details>
  <summary>Details</summary>
Motivation: 现有方法在准确性方面表现良好，但在数据集偏差和缺乏去偏策略方面有待改进。研究者希望通过分析和解决这些问题来提高模型的准确性和公平性。

Method: 本文首先分析了现有数据的共现和统计偏差，然后构建了VCR-OOD评估集。接下来，研究者通过因果图和预测捷径的分析，并采用后门调整方法来消除偏差。具体实现上，是通过建立基于正确答案的词典来消除预测捷径的。

Result: 实验结果表明我们的去偏方法在多个数据集上都能有效减少偏差，提高模型的质量。

Conclusion: 本文提出了一种新的方法来处理视觉常识推理模型中的数据偏差问题，有助于提高模型的准确性和公平性。

Abstract: Visual Commonsense Reasoning (VCR) refers to answering questions and
providing explanations based on images. While existing methods achieve high
prediction accuracy, they often overlook bias in datasets and lack debiasing
strategies. In this paper, our analysis reveals co-occurrence and statistical
biases in both textual and visual data. We introduce the VCR-OOD datasets,
comprising VCR-OOD-QA and VCR-OOD-VA subsets, which are designed to evaluate
the generalization capabilities of models across two modalities. Furthermore,
we analyze the causal graphs and prediction shortcuts in VCR and adopt a
backdoor adjustment method to remove bias. Specifically, we create a dictionary
based on the set of correct answers to eliminate prediction shortcuts.
Experiments demonstrate the effectiveness of our debiasing method across
different datasets.

</details>


### [31] [DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering](https://arxiv.org/abs/2510.20285)
*Jiayi Zou,Chaofan Chen,Bing-Kun Bao,Changsheng Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种用于第一人称视频问答的Dual-Modal Counterfactual Contrastive Construction (DMC$^3$) 框架，该框架通过反事实样本构造和对比优化模块来提高问答准确度，并在EgoTaskQA和QAEGO4D数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 针对现有方法忽略了第一人称视频理解的独特挑战，如理解多个事件和识别人手互动等问题，提出了DMC$^3$框架。

Method: DMC$^3$框架包括一个ego视频QA基准，一个生成正负样本的反事实样本构建模块，以及用于最小化正样本特征距离同时最大化负样本特征距离的对比优化模块。其通过事件描述的改写和核心互动的提取生成文本和视觉模式的正负样本。

Result: 在EgoTaskQA数据集的normal和indirect子集上，DMC$^3$分别达到了52.51%和46.04%的准确率；在QAEGO4D数据集上的准确率为13.2%，均达到当前最佳性能。

Conclusion: DMC$^3$框架通过利用反事实样本优化，提高了第一人称视频问答任务中的准确性。

Abstract: Egocentric Video Question Answering (Egocentric VideoQA) plays an important
role in egocentric video understanding, which refers to answering questions
based on first-person videos. Although existing methods have made progress
through the paradigm of pre-training and fine-tuning, they ignore the unique
challenges posed by the first-person perspective, such as understanding
multiple events and recognizing hand-object interactions. To deal with these
challenges, we propose a Dual-Modal Counterfactual Contrastive Construction
(DMC$^3$) framework, which contains an egocentric videoqa baseline, a
counterfactual sample construction module and a counterfactual sample-involved
contrastive optimization. Specifically, We first develop a counterfactual
sample construction module to generate positive and negative samples for
textual and visual modalities through event description paraphrasing and core
interaction mining, respectively. Then, We feed these samples together with the
original samples into the baseline. Finally, in the counterfactual
sample-involved contrastive optimization module, we apply contrastive loss to
minimize the distance between the original sample features and the positive
sample features, while maximizing the distance from the negative samples.
Experiments show that our method achieve 52.51\% and 46.04\% on the
\textit{normal} and \textit{indirect} splits of EgoTaskQA, and 13.2\% on
QAEGO4D, both reaching the state-of-the-art performance.

</details>


### [32] [Breakdance Video classification in the age of Generative AI](https://arxiv.org/abs/2510.20287)
*Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson*

Main category: cs.CV

TL;DR: 论文分析了现代视频基础模型（编码器和解码器）在小众但非常受欢迎的街舞运动中应用。结果显示，视频编码器模型在预测任务中仍然优于现有的视频语言模型，并提供了选择编码器模型的见解，以及细解微调解码器模型用于街舞视频分类的全面分析。


<details>
  <summary>Details</summary>
Motivation: 大多数现有工作仅针对如足球、板球、篮球等流行运动的有限子集，并专注于生成任务如视觉问答和亮点生成。该工作探讨了现代视频基础模型在街舞这种较为小众但受欢迎的运动中的应用能力。

Method: 分析了视频编码器和解码器模型在街舞视频分类中的应用情况，包括选择编码器模型的方法和解码器模型的微调分析。

Result: 结果表明，视频编码器模型在预测任务中表现优于现有视频语言模型，提供了关于如何选择编码器模型的具体见解，并对微调解码器模型在街舞视频分类中工作的全面分析。

Conclusion: 视频编码器模型在预测任务中表现更优，并对街舞视频分类提供了有用的模型选择和微调见解。

Abstract: Large Vision Language models have seen huge application in several sports
use-cases recently. Most of these works have been targeted towards a limited
subset of popular sports like soccer, cricket, basketball etc; focusing on
generative tasks like visual question answering, highlight generation. This
work analyzes the applicability of the modern video foundation models (both
encoder and decoder) for a very niche but hugely popular dance sports -
breakdance. Our results show that Video Encoder models continue to outperform
state-of-the-art Video Language Models for prediction tasks. We provide
insights on how to choose the encoder model and provide a thorough analysis
into the workings of a finetuned decoder model for breakdance video
classification.

</details>


### [33] [A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization](https://arxiv.org/abs/2510.20291)
*LinFeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出了一种解决RoboSense 2025 Track 4任务的方案，该任务要求从多平台（卫星/无人机/地面）资料库中检索出与自然语言查询最相关的地理参照图像。为了解决跨平台异构性和训练描述与测试查询之间的域差距问题，作者设计了一条域对齐预处理流水线和一个Mixture-of-Experts（MoE）框架，大幅提升了多模态地理定位性能。


<details>
  <summary>Details</summary>
Motivation: 多平台资料库中的严重异构性以及训练描述与特定平台测试查询之间的域差距使得准确检索图像变得困难。这个问题可能会影响无人机导航和跨平台的图像检索任务的表现。本文的动机是找到一种可靠的方法来解决这些问题，以提高检索精度并证实解决方案在不同平台下的一致性表现。

Method: 提出了一种Mixture-of-Experts（MoE）框架，方法包括领域对齐预处理流水线，有效地利用了多模态数据。具体地，通过平台分段，卫星增强，移除方向词，以及使用大型语言模型（LLM）改进图像描述，来解决跨平台异质性问题。此外，使用BGE-M3和EVA-CLIP两种模型加强了文本和图像的特征表示，并采用渐进式两阶段、难例挖掘策略来增强判别力。

Result: 该方法在检索生成性标准上解决了公开排行榜上的RoboSense 2025 Track 4任务，在异构视角下实现了非常稳健的多模态地理定位。通过精心设计的方法，使得模型在现实世界跨平台图像检索任务中的表现变得更加可靠和高效。实验结果验证了本文方法的有效性与实用性。

Conclusion: 本文提出了解决RoboSense 2025 Track 4任务的创新方法，通过解决多平台异构性和训练-测试域差异问题，展示了在跨模态地理定位任务上的优越性。这些方法和技术可以进一步应用于涉及多个数据平台的复杂任务，改善了检索准确性。

Abstract: We present a winning solution to RoboSense 2025 Track 4: Cross-Modal Drone
Navigation. The task retrieves the most relevant geo-referenced image from a
large multi-platform corpus (satellite/drone/ground) given a natural-language
query. Two obstacles are severe inter-platform heterogeneity and a domain gap
between generic training descriptions and platform-specific test queries. We
mitigate these with a domain-aligned preprocessing pipeline and a
Mixture-of-Experts (MoE) framework: (i) platform-wise partitioning, satellite
augmentation, and removal of orientation words; (ii) an LLM-based caption
refinement pipeline to align textual semantics with the distinct visual
characteristics of each platform. Using BGE-M3 (text) and EVA-CLIP (image), we
train three platform experts using a progressive two-stage, hard-negative
mining strategy to enhance discriminative power, and fuse their scores at
inference. The system tops the official leaderboard, demonstrating robust
cross-modal geo-localization under heterogeneous viewpoints.

</details>


### [34] [HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models](https://arxiv.org/abs/2510.20322)
*Zelin Peng,Zhengqin Xu,Qingyang Liu,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: 本论文提出了一种名为HyperET的高效训练范式，用于改善多模态大语言模型(MLLMs)在不同粒度水平上处理视觉和文本模态时的对齐效果。HyperET通过在双曲空间中动态调整半径来优化视觉表示，使其与文本模态对齐。实验表明，HyperET可以在不显著增加模型参数的情况下，提高现有MLLM的预训练和微调性能。


<details>
  <summary>Details</summary>
Motivation: 本论文指出，当前MLLM训练效率低下，特别是视觉编码器，如CLIP和SAM，它们缺乏在多粒度级别上的语言对齐能力。通过使用双曲空间，本研究旨在解决MLLM训练过程中的粒度不一致问题，从而提高训练效率和模型性能。

Method: HyperET通过在双曲空间中使用Möbius乘法操作以及三种可学矩阵(diagonal scaling, block-diagonal, banded matrices)来动态调整半径，优化视觉模态与文本模态之间的对齐，尤其是在不同粒度级别上。

Result: 实验表明，HyperET可以明显提高现有MLLM的性能（预训练和微调），同时只需要增加不到1%的参数量。这证明了该方法的有效性和高效性。

Conclusion: 本论文展示了HyperET在提高MLLM粒度级对齐能力的有效性，证明了在双曲空间中进行视觉和文本对齐的独特优势，同时保持了模型的参数效率和计算效率。

Abstract: Multi-modal large language models (MLLMs) have emerged as a transformative
approach for aligning visual and textual understanding. They typically require
extremely high computational resources (e.g., thousands of GPUs) for training
to achieve cross-modal alignment at multi-granularity levels. We argue that a
key source of this inefficiency lies in the vision encoders they widely equip
with, e.g., CLIP and SAM, which lack the alignment with language at
multi-granularity levels. To address this issue, in this paper, we leverage
hyperbolic space, which inherently models hierarchical levels and thus provides
a principled framework for bridging the granularity gap between visual and
textual modalities at an arbitrary granularity level. Concretely, we propose an
efficient training paradigm for MLLMs, dubbed as HyperET, which can optimize
visual representations to align with their textual counterparts at an arbitrary
granularity level through dynamic hyperbolic radius adjustment in hyperbolic
space. HyperET employs learnable matrices with M\"{o}bius multiplication
operations, implemented via three effective configurations: diagonal scaling
matrices, block-diagonal matrices, and banded matrices, providing a flexible
yet efficient parametrization strategy. Comprehensive experiments across
multiple MLLM benchmarks demonstrate that HyperET consistently improves both
existing pre-training and fine-tuning MLLMs clearly with less than 1\%
additional parameters.

</details>


### [35] [AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models](https://arxiv.org/abs/2510.20348)
*Seunghoon Lee,Jeongwoo Choi,Byunggwan Son,Jaehyeon Moon,Jeimin Jeon,Bumsub Ham*

Main category: cs.CV

TL;DR: AccuQuant是一种新的用于扩散模型的后训练量化方法，通过最小化全精度模型与量化版本在几次去噪步骤中的输出差异来缓解量化误差累积问题，同时提出了一种新的目标函数以显著降低内存复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统的量化方法无法有效解决扩散模型中由于去噪步骤累积的量化误差。我们提出AccuQuant，它能够在模拟多项去噪步骤进行量化时考虑累积的误差，以减少误差积累的问题。此外，我们还提出了一种新的目标函数，有效降低了内存复杂度。

Method: AccuQuant方法通过模拟扩散模型的几次去噪步骤，最小化全精度模型与量化版本之间输出的差异。这种方法与之前模仿扩散模型训练过程的量化方法不同，它在进行量化时考虑了多项去噪步骤中的累积误差。此外，我们提出了一种新的目标函数，将内存复杂度从O(n)降低到O(1)。

Result: AccuQuant在多个任务和扩散模型的标准基准上都展示了有效的性能和效率。实验结果表明，该方法可以显著减少量化误差累积问题，并提高模型的量化精度和性能。

Conclusion: 我们提出了一种新的后训练量化方法AccuQuant，它能够减小量化误差的累积，提高扩散模型的性能。同时，提出的方法在内存复杂度上也取得了显著的改进。

Abstract: We present in this paper a novel post-training quantization (PTQ) method,
dubbed AccuQuant, for diffusion models. We show analytically and empirically
that quantization errors for diffusion models are accumulated over denoising
steps in a sampling process. To alleviate the error accumulation problem,
AccuQuant minimizes the discrepancies between outputs of a full-precision
diffusion model and its quantized version within a couple of denoising steps.
That is, it simulates multiple denoising steps of a diffusion sampling process
explicitly for quantization, accounting the accumulated errors over multiple
denoising steps, which is in contrast to previous approaches to imitating a
training process of diffusion models, namely, minimizing the discrepancies
independently for each step. We also present an efficient implementation
technique for AccuQuant, together with a novel objective, which reduces a
memory complexity significantly from $\mathcal{O}(n)$ to $\mathcal{O}(1)$,
where $n$ is the number of denoising steps. We demonstrate the efficacy and
efficiency of AccuQuant across various tasks and diffusion models on standard
benchmarks.

</details>


### [36] [Positional Encoding Field](https://arxiv.org/abs/2510.20385)
*Yunpeng Bai,Haoxiang Li,Qixing Huang*

Main category: cs.CV

TL;DR: 研究提出了一种新的位置编码方法PE-Field，它扩展了位置编码以适应3D空间, 改进了DiT模型在生成图像和新型视点合成中的表现


<details>
  <summary>Details</summary>
Motivation: 发现了Diffusion Transformers (DiTs)在位置编码被扰乱的情况下仍能生成结构清晰的图像，表明空间一致性主要由位置编码维持

Method: 提出了Positional Encoding Field (PE-Field), 扩展位置编码到3D空间，引入了深度感知编码和层次编码

Result: 借助PE-Field增强的DiT模型在单图像新视角合成及可控空间图像编辑方面表现卓越，达到了最先进的性能

Conclusion: PE-Field以其空间层级优势增强了DiT在3D视觉生成任务中的能力

Abstract: Diffusion Transformers (DiTs) have emerged as the dominant architecture for
visual generation, powering state-of-the-art image and video models. By
representing images as patch tokens with positional encodings (PEs), DiTs
combine Transformer scalability with spatial and temporal inductive biases. In
this work, we revisit how DiTs organize visual content and discover that patch
tokens exhibit a surprising degree of independence: even when PEs are
perturbed, DiTs still produce globally coherent outputs, indicating that
spatial coherence is primarily governed by PEs. Motivated by this finding, we
introduce the Positional Encoding Field (PE-Field), which extends positional
encodings from the 2D plane to a structured 3D field. PE-Field incorporates
depth-aware encodings for volumetric reasoning and hierarchical encodings for
fine-grained sub-patch control, enabling DiTs to model geometry directly in 3D
space. Our PE-Field-augmented DiT achieves state-of-the-art performance on
single-image novel view synthesis and generalizes to controllable spatial image
editing.

</details>


### [37] [Mitigating Cross-modal Representation Bias for Multicultural Image-to-Recipe Retrieval](https://arxiv.org/abs/2510.20393)
*Qing Wang,Chong-Wah Ngo,Yu Cao,Ee-Peng Lim*

Main category: cs.CV

TL;DR: 现有图像到食谱检索的方法假设食物图片可以完全捕捉到食谱文本中的详细信息。但是食物图片只能反映烹饪结果的视觉效果，而不是烹饪过程。现有的跨模态表示学习方法忽略了一些重要的不过于明显的食谱特定细节。本文提出了一个新颖的因果方法，来预测图片中可能被忽略的烹饪元素，同时在跨模态表示学习中注入这些元素，以减轻偏见。在标准的单一语言Recipe1M数据集和新整理的多语言多文化数据集中进行了实验验证，结果表明，提出的因果表示学习能够揭示细微的食材和烹饪动作，并在单语言和多语言多文化数据集中表现出卓越的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态表示学习方法在从图像中捕捉食谱特定细节存在不足，尤其是容易忽略一些不过于明显但重要的烹饪过程中的细节。这导致了检索精度的下降，特别是在混合不同菜系的数据集上时，偏置更为严重。因此，本文动机在于开发一个新的因果方法，来解决这些问题，提高食谱检索的准确性。

Method: 提出了一个因果的跨模态表示学习方法，该方法能够预测图片中可能被忽略的烹饪元素，并在跨模态表示学习过程中将这些元素考虑进去，以此来提升检索性能。具体来说，作者使用标准的Recipe1M数据集和新的多语言多文化数据集进行实验，测试所提方法的有效性。

Result: 实验结果显示，所提的方法能够较好地揭示图片中隐藏的细微食材和烹饪步骤，从而提高检索性能。在单一语言数据集和多语言多文化数据集上都取得了显著的效果。表明该因果表示学习方法在处理多元化数据时有很好的适应性。

Conclusion: 相比于现有方法，本文提出的因果表示学习方法在预测图片中可能被忽略的烹饪信息方面更有效，能够显著提高图像到食谱检索的性能，并且在处理多语言多文化的数据集时表现良好，证明了其跨文化适用性和更高的检索精度。

Abstract: Existing approaches for image-to-recipe retrieval have the implicit
assumption that a food image can fully capture the details textually documented
in its recipe. However, a food image only reflects the visual outcome of a
cooked dish and not the underlying cooking process. Consequently, learning
cross-modal representations to bridge the modality gap between images and
recipes tends to ignore subtle, recipe-specific details that are not visually
apparent but are crucial for recipe retrieval. Specifically, the
representations are biased to capture the dominant visual elements, resulting
in difficulty in ranking similar recipes with subtle differences in use of
ingredients and cooking methods. The bias in representation learning is
expected to be more severe when the training data is mixed of images and
recipes sourced from different cuisines. This paper proposes a novel causal
approach that predicts the culinary elements potentially overlooked in images,
while explicitly injecting these elements into cross-modal representation
learning to mitigate biases. Experiments are conducted on the standard
monolingual Recipe1M dataset and a newly curated multilingual multicultural
cuisine dataset. The results indicate that the proposed causal representation
learning is capable of uncovering subtle ingredients and cooking actions and
achieves impressive retrieval performance on both monolingual and multilingual
multicultural datasets.

</details>


### [38] [Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence](https://arxiv.org/abs/2510.20470)
*Kun Ouyang,Yuanxin Liu,Linli Yao,Yishuo Cai,Hao Zhou,Jie Zhou,Fandong Meng,Xu Sun*

Main category: cs.CV

TL;DR: Conan是一个用于证据基础多步视频推理的框架，结合了大型数据集和多阶段训练策略，实现了视频理解和推理的提升，在六个多步推理基准上比基线模型高出10%以上，并且在长视频理解任务上有很好的扩展性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 目前的多模态大型语言模型在进行多步骤的视频推理时存在困难，尤其是在跨帧推理。虽然强化学习方法可以提升推理能力，但是它们通常依赖于没有视觉支撑的文本链，这样容易得出错误的结论。同时，即使引入了视觉支撑，有些方法在证据定位上还不够准确。为了解决这些问题，开发了一个全新的框架Conan，目的是进行证据基础的多步视频推理

Method: 提出了Conan-91K这样一个大规模的数据集和多阶段的训练策略，来进行多步的视觉推理，通过构造识别-推理-行动（AIR）的框架，可以帮助模型在视频理解上做出更合理的决策

Result: 在六个多步骤推理基准测试中，Conan的性能比基线模型Qwen2.5-VL-7B-Instruct平均高出10%以上，在长视频理解任务上表现出强大的可扩展性和鲁棒性

Conclusion: Conan提供了一个新颖的方法来进行多步的证据基础视频推理，它结合了大规模的数据集和多阶段的训练策略，提升了视频理解和推理的性能，并且在长视频理解任务上具有良好的扩展性和鲁棒性

Abstract: Video reasoning, which requires multi-step deduction across frames, remains a
major challenge for multimodal large language models (MLLMs). While
reinforcement learning (RL)-based methods enhance reasoning capabilities, they
often rely on text-only chains that yield ungrounded or hallucinated
conclusions. Conversely, frame-retrieval approaches introduce visual grounding
but still struggle with inaccurate evidence localization. To address these
challenges, we present Conan, a framework for evidence-grounded multi-step
video reasoning. Conan identifies contextual and evidence frames, reasons over
cross-frame clues, and adaptively decides when to conclude or explore further.
To achieve this, we (1) construct Conan-91K, a large-scale dataset of
automatically generated reasoning traces that includes frame identification,
evidence reasoning, and action decision, and (2) design a multi-stage
progressive cold-start strategy combined with an
Identification-Reasoning-Action (AIR) RLVR training framework to jointly
enhance multi-step visual reasoning. Extensive experiments on six multi-step
reasoning benchmarks demonstrate that Conan surpasses the baseline
Qwen2.5-VL-7B-Instruct by an average of over 10% in accuracy, achieving
state-of-the-art performance. Furthermore, Conan generalizes effectively to
long-video understanding tasks, validating its strong scalability and
robustness.

</details>


### [39] [Reliable and Reproducible Demographic Inference for Fairness in Face Analysis](https://arxiv.org/abs/2510.20482)
*Alexandre Fournier-Montgieux,Hervé Le Borgne,Adrian Popescu,Bertrand Luvison*

Main category: cs.CV

TL;DR: 改进自动人口统计属性推断(DAI)的可靠性可以减少人脸分析系统(FAS)的偏见和方差。我们提出了一种采用模块化迁移学习的可再现DAI流水线，该流水线集成了预训练的面部识别编码器和非线性分类头。我们在准确性、公平性和一个新的基于身份一致性概念的健壮性这三个维度上对该流水线进行了审计。研究结果表明，所提出的方法在性别和种族推理方面优于基准模型，并在更具挑战性的种族属性上表现尤为突出。为了促进透明度和可再现性，我们将公开发布训练数据元数据、完整代码库、预训练模型和评估工具包。这项工作为公平性审计中的人口统计学推断提供了可靠的基准。


<details>
  <summary>Details</summary>
Motivation: 改进的DAI可靠性可以减少对FAS公平性的偏见和方差，从而提供更准确、更公平的评估结果。我们希望通过改进DAI来增强FAS的公平性评估。

Method: 提出了一种采用模块化迁移学习的可再现DAI流水线，该流水线集成了预训练的面部识别编码器和非线性分类头。我们还引入了一个新的健壮性指标，通过身份内一致性来定义。我们设计了这套新的系统为了最大限度的提高DAI的准确性、公平性和健壮性。

Result: 实验结果表明，所提出的方法在性别和种族推理方面都优于基准模型，尤其在种族这一更难的任务上表现更加出色。我们还展示了一个完整、透明且可再现的评估流程，通过提供训练数据元数据、预训练模型和完整的评估工具包。

Conclusion: 我们提出了一种改进的人口统计学推断方法，该方法提高了DAI的可靠性，从而为FAS公平性评估提供了更准确和更公平的结果。我们的研究结果还证明了通过引入新型维度进行评估，可以提高对模型性能的全面理解。

Abstract: Fairness evaluation in face analysis systems (FAS) typically depends on
automatic demographic attribute inference (DAI), which itself relies on
predefined demographic segmentation. However, the validity of fairness auditing
hinges on the reliability of the DAI process. We begin by providing a
theoretical motivation for this dependency, showing that improved DAI
reliability leads to less biased and lower-variance estimates of FAS fairness.
To address this, we propose a fully reproducible DAI pipeline that replaces
conventional end-to-end training with a modular transfer learning approach. Our
design integrates pretrained face recognition encoders with non-linear
classification heads. We audit this pipeline across three dimensions: accuracy,
fairness, and a newly introduced notion of robustness, defined via
intra-identity consistency. The proposed robustness metric is applicable to any
demographic segmentation scheme. We benchmark the pipeline on gender and
ethnicity inference across multiple datasets and training setups. Our results
show that the proposed method outperforms strong baselines, particularly on
ethnicity, which is the more challenging attribute. To promote transparency and
reproducibility, we will publicly release the training dataset metadata, full
codebase, pretrained models, and evaluation toolkit. This work contributes a
reliable foundation for demographic inference in fairness auditing.

</details>


### [40] [EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization](https://arxiv.org/abs/2510.20512)
*Yixiong Yang,Tao Wu,Senmao Li,Shiqi Yang,Yaxing Wang,Joost van de Weijer,Kai Wang*

Main category: cs.CV

TL;DR: 提出了一种双向概念提炼框架EchoDistill来加速文本到图像扩散模型的个性化过程。这种方法通过共享文本编码器和使用对抗损失优化单步模型来提升其生成质量和对新概念的适应性，并且同时提升了多步扩散模型的生成质量。实验显示，该框架比现有技术在文本到图像单步个性化设置中表现更佳。


<details>
  <summary>Details</summary>
Motivation: 传统的单步扩散模型在加入新概念时效果有限。因此，提出了一种新的方法来增强其在个性化和捕捉新概念上的能力。

Method: 通过一个双向的概念提炼过程，使用了多步扩散模型作为老师，单步扩散模型作为学生，两者共享文本编码器，保证语义一致性。学生模型通过对抗损失优化，并使用双向反馈机制从学生到老师，从而增强学生模型对新概念的个人化能力，并提高了老师的生成质量。

Result: 实验表明，提出的EchoDistill框架比现有方法在文本到图像的单步个性化设置中表现更好，提升了生成质量，加速了个性化过程。

Conclusion: 提出了一种创新的，双向的概念提炼框架，即EchoDistill，它不仅使得快速有效的个性化文本到图像扩散模型成为可能，还在质量和速度上超过了现有技术。

Abstract: Recent advances in accelerating text-to-image (T2I) diffusion models have
enabled the synthesis of high-fidelity images even in a single step. However,
personalizing these models to incorporate novel concepts remains a challenge
due to the limited capacity of one-step models to capture new concept
distributions effectively. We propose a bidirectional concept distillation
framework, EchoDistill, to enable one-step diffusion personalization (1-SDP).
Our approach involves an end-to-end training process where a multi-step
diffusion model (teacher) and a one-step diffusion model (student) are trained
simultaneously. The concept is first distilled from the teacher model to the
student, and then echoed back from the student to the teacher. During the
EchoDistill, we share the text encoder between the two models to ensure
consistent semantic understanding. Following this, the student model is
optimized with adversarial losses to align with the real image distribution and
with alignment losses to maintain consistency with the teacher's output.
Furthermore, we introduce the bidirectional echoing refinement strategy,
wherein the student model leverages its faster generation capability to
feedback to the teacher model. This bidirectional concept distillation
mechanism not only enhances the student ability to personalize novel concepts
but also improves the generative quality of the teacher model. Our experiments
demonstrate that this collaborative framework significantly outperforms
existing personalization methods over the 1-SDP setup, establishing a novel
paradigm for rapid and effective personalization in T2I diffusion models.

</details>


### [41] [Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning](https://arxiv.org/abs/2510.20519)
*Xiaohan Lan,Fanfan Liu,Haibo Qiu,Siqi Yang,Delian Ruan,Peng Shi,Lin Ma*

Main category: cs.CV

TL;DR: 本文提出了Metis-HOME框架，通过混合的思考和非思考分支解决了多模态大型理由模型在复杂推理和泛化能力之间的权衡问题。该框架使模型既能高效处理简单查询，又能有效解决复杂推理问题，同时提高了模型的总体性能。


<details>
  <summary>Details</summary>
Motivation: 在多模态推理的最新进展中，当前的大型模型存在使用复杂推理进行简单查询和忽视泛化能力的问题。本文旨在通过提出新的框架解决这两个问题。

Method: 提出了Metis-HOME框架：一个混合优化的专家混合架构，该架构将模型分为复杂推理分支和快速直接推理分支，并通过轻量级的可训练路由器将查询分配给最适合的专家。在Qwen2.5-VL-7B上实现了该框架的MoE架构。

Result: 该方法不仅提高了复杂推理能力，还增强了模型的总体性能，逆转了其他推理专业模型的退化趋势，建立了构建强大的多模态深度学习模型的新范式。

Conclusion: Metis-HOME框架有效地解决了推理和泛化能力之间的矛盾，展示了在处理复杂推理和保持泛化能力方面的有效性。

Abstract: Inspired by recent advancements in LLM reasoning, the field of multimodal
reasoning has seen remarkable progress, achieving significant performance gains
on intricate tasks such as mathematical problem-solving. Despite this progress,
current multimodal large reasoning models exhibit two key limitations. They
tend to employ computationally expensive reasoning even for simple queries,
leading to inefficiency. Furthermore, this focus on specialized reasoning often
impairs their broader, more general understanding capabilities. In this paper,
we propose Metis-HOME: a Hybrid Optimized Mixture-of-Experts framework designed
to address this trade-off. Metis-HOME enables a ''Hybrid Thinking'' paradigm by
structuring the original dense model into two distinct expert branches: a
thinking branch tailored for complex, multi-step reasoning, and a non-thinking
branch optimized for rapid, direct inference on tasks like general VQA and OCR.
A lightweight, trainable router dynamically allocates queries to the most
suitable expert. We instantiate Metis-HOME by adapting the Qwen2.5-VL-7B into
an MoE architecture. Comprehensive evaluations reveal that our approach not
only substantially enhances complex reasoning abilities but also improves the
model's general capabilities, reversing the degradation trend observed in other
reasoning-specialized models. Our work establishes a new paradigm for building
powerful and versatile MLLMs, effectively resolving the prevalent
reasoning-vs-generalization dilemma.

</details>


### [42] [Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis](https://arxiv.org/abs/2510.20531)
*Lixiong Qin,Yang Zhang,Mei Wang,Jiani Hu,Weihong Deng,Weiran Xu*

Main category: cs.CV

TL;DR: 提出了一种新的框架FiFa，可以更细粒度地分析DeepFake视频，通过面部区域概念树（FICT）改进数据注释，并引入AGE任务以生成带有分割掩码的文字解释，同时在新架构FiFa-MLLM的帮助下实现先进的深造假分析性能。


<details>
  <summary>Details</summary>
Motivation: 当前的方法在描述数据注释中的伪影时存在粗放和不可靠的问题，无法提供足够的针对面部视觉上下文的支撑，从而限制了其效果。因此，需要开发新的方法来改进数据注释和模型性能，从而提升DeepFake视频的可解释性。

Method: 首先定义了面部图像概念树（FICT）来进行更细粒度的划分，引入了AGE任务，生成包含分割掩码的文字伪造说明，并提出一种新的联合框架FiFa-MLLM，能够处理丰富的多模态输入和输出。

Result: 在新的AGE任务上优于其他基准模型，并在已有的深伪造数据集上实现了最新的性能。同时提供开源代码和数据集以供研究者使用。

Conclusion: 本文通过引入新的数据注释方法和模型架构，解决了深伪造分析中对细粒度面部视觉上下文支持不足的问题，为实现更准确和细致的可解释性深伪造分析提供了新的视角和方法。

Abstract: The advancement of Multimodal Large Language Models (MLLMs) has bridged the
gap between vision and language tasks, enabling the implementation of
Explainable DeepFake Analysis (XDFA). However, current methods suffer from a
lack of fine-grained awareness: the description of artifacts in data annotation
is unreliable and coarse-grained, and the models fail to support the output of
connections between textual forgery explanations and the visual evidence of
artifacts, as well as the input of queries for arbitrary facial regions. As a
result, their responses are not sufficiently grounded in Face Visual Context
(Facext). To address this limitation, we propose the Fake-in-Facext (FiFa)
framework, with contributions focusing on data annotation and model
construction. We first define a Facial Image Concept Tree (FICT) to divide
facial images into fine-grained regional concepts, thereby obtaining a more
reliable data annotation pipeline, FiFa-Annotator, for forgery explanation.
Based on this dedicated data annotation, we introduce a novel
Artifact-Grounding Explanation (AGE) task, which generates textual forgery
explanations interleaved with segmentation masks of manipulated artifacts. We
propose a unified multi-task learning architecture, FiFa-MLLM, to
simultaneously support abundant multimodal inputs and outputs for fine-grained
Explainable DeepFake Analysis. With multiple auxiliary supervision tasks,
FiFa-MLLM can outperform strong baselines on the AGE task and achieve SOTA
performance on existing XDFA datasets. The code and data will be made
open-source at https://github.com/lxq1000/Fake-in-Facext.

</details>


### [43] [Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation](https://arxiv.org/abs/2510.20549)
*Marziyeh Bamdad,Hans-Peter Hutter,Alireza Darvishy*

Main category: cs.CV

TL;DR: SELM-SLAM3 提出了一种增强的视觉 SLAM 框架，采用 SuperPoint 和 LightGlue，显著提高了在低纹理和高速运动等苛刻条件下的定位和跟踪准确性。它在标准数据集上的性能优于现有的 ORB-SLAM3 和最新 RGB-D SLAM 系统。该框架为视障人士设计的辅助导航系统提供了可靠的支持平台。


<details>
  <summary>Details</summary>
Motivation: 在低纹理、运动模糊或光照变化等苛刻条件下，现有的 SLAM 技术仍存在局限，这影响了定位精度和跟踪稳定性，进而降低了导航的可靠性和安全性。因此，开发一个能够在这些条件下工作的更稳健的 SLAM 系统是必要的。

Method: SELM-SLAM3 结合了 SuperPoint 和 LightGlue 进行特征提取和匹配，从而提高了错误恢复能力和鲁棒性。它在 TUM RGB-D，ICL-NUIM 和 TartanAir 数据集上进行了测试，这些数据集包含多样且具有挑战性的场景。

Result: SELM-SLAM3 相较于 ORB-SLAM3 的平均性能提升了 87.84%，且比现有最佳的 RGB-D SLAM 系统提高了 36.77%，特别是在低纹理和高速运动等苛刻条件下表现突出。

Conclusion: 提出了 SELM-SLAM3，这是一种新的视觉 SLAM 框架，专为视障人士设计的辅助导航系统提供了提高的鲁棒性和准确性。

Abstract: Despite advancements in SLAM technologies, robust operation under challenging
conditions such as low-texture, motion-blur, or challenging lighting remains an
open challenge. Such conditions are common in applications such as assistive
navigation for the visually impaired. These challenges undermine localization
accuracy and tracking stability, reducing navigation reliability and safety. To
overcome these limitations, we present SELM-SLAM3, a deep learning-enhanced
visual SLAM framework that integrates SuperPoint and LightGlue for robust
feature extraction and matching. We evaluated our framework using TUM RGB-D,
ICL-NUIM, and TartanAir datasets, which feature diverse and challenging
scenarios. SELM-SLAM3 outperforms conventional ORB-SLAM3 by an average of
87.84% and exceeds state-of-the-art RGB-D SLAM systems by 36.77%. Our framework
demonstrates enhanced performance under challenging conditions, such as
low-texture scenes and fast motion, providing a reliable platform for
developing navigation aids for the visually impaired.

</details>


### [44] [From Far and Near: Perceptual Evaluation of Crowd Representations Across Levels of Detail](https://arxiv.org/abs/2510.20558)
*Xiaohan Sun,Carol O'Sullivan*

Main category: cs.CV

TL;DR: 本文研究了用户在不同的细节级别（LoD）和观看距离下对人群角色视觉质量的感知。研究结果为人群渲染的感知优化细节策略设计提供了指导。


<details>
  <summary>Details</summary>
Motivation: 研究不同级别细节和观看距离下，用户对人群角色视觉质量的感知，以优化人群渲染的细节策略。

Method: 通过几何网格、基于图像的替身、神经辐射场（NeRFs）和3D高斯曲线这四种表示方法来研究视觉质量和计算性能之间的权衡。通过定性和定量分析来提供洞察。

Result: 定性和定量结果显示了不同表示方法之间的视觉质量和计算性能的权衡。

Conclusion: 研究结果为人群渲染中感知优化的细节策略设计提供了指导。

Abstract: In this paper, we investigate how users perceive the visual quality of crowd
character representations at different levels of detail (LoD) and viewing
distances. Each representation: geometric meshes, image-based impostors, Neural
Radiance Fields (NeRFs), and 3D Gaussians, exhibits distinct trade-offs between
visual fidelity and computational performance. Our qualitative and quantitative
results provide insights to guide the design of perceptually optimized LoD
strategies for crowd rendering.

</details>


### [45] [Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence](https://arxiv.org/abs/2510.20579)
*Jiahao Meng,Xiangtai Li,Haochen Wang,Yue Tan,Tao Zhang,Lingdong Kong,Yunhai Tong,Anran Wang,Zhiyang Teng,Yujing Wang,Zhuochen Wang*

Main category: cs.CV

TL;DR: Open-o3 Video 是一种新的视频推理模型，它能够提供关于关键证据出现的时间和位置的显式时空证据。该模型在视频理解基准测试中展示了最先进的性能，并且提高了推理的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前的视频推理模型仅仅生成文本推理痕迹，而没有明确表明关键证据出现的时间和地点。为了解决这个问题并提高视频推理的精确度和可靠性，研究者开发了 Open-o3 Video 模型。

Method: 模型通过引入显式时空证据到视频推理中，并收集高质量的训练数据，采用冷启动强化学习策略，提高了模型的性能，特别是在时空对齐和空间精度方面。

Result: 在 V-STAR 基准测试中，Open-o3 Video 模型相比 Qwen2.5-VL 基线在 mAM 和 mLGM 指标上分别提升了 14.4% 和 24.2%，展示了较好的性能。

Conclusion: Open-o3 Video 提供了关键证据出现的时间和位置的显式时空证据，提高了模型的准确性，同时也让推理痕迹在测试过程中提供有价值的信号，提升了答案的可靠性。

Abstract: Most video reasoning models only generate textual reasoning traces without
indicating when and where key evidence appears. Recent models such as OpenAI-o3
have sparked wide interest in evidence-centered reasoning for images, yet
extending this ability to videos is more challenging, as it requires joint
temporal tracking and spatial localization across dynamic scenes. We introduce
Open-o3 Video, a non-agent framework that integrates explicit spatio-temporal
evidence into video reasoning, and carefully collect training data and design
training strategies to address the aforementioned challenges. The model
highlights key timestamps, objects, and bounding boxes alongside its answers,
allowing reasoning to be grounded in concrete visual observations. To enable
this functionality, we first curate and build two high-quality datasets,
STGR-CoT-30k for SFT and STGR-RL-36k for RL, with carefully constructed
temporal and spatial annotations, since most existing datasets offer either
temporal spans for videos or spatial boxes on images, lacking unified
spatio-temporal supervision and reasoning traces. Then, we adopt a cold-start
reinforcement learning strategy with multiple specially designed rewards that
jointly encourage answer accuracy, temporal alignment, and spatial precision.
On V-STAR benchmark, Open-o3 Video achieves state-of-the-art performance,
raising mAM by 14.4% and mLGM by 24.2% on the Qwen2.5-VL baseline. Consistent
improvements are also observed on a broad range of video understanding
benchmarks, including VideoMME, WorldSense, VideoMMMU, and TVGBench. Beyond
accuracy, the reasoning traces produced by Open-o3 Video also provide valuable
signals for test-time scaling, enabling confidence-aware verification and
improving answer reliability.

</details>


### [46] [GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models](https://arxiv.org/abs/2510.20586)
*Muhammad Atif Butt,Alexandra Gomez-Villa,Tao Wu,Javier Vazquez-Corral,Joost Van De Weijer,Kai Wang*

Main category: cs.CV

TL;DR: 提出了GenColorBench，这是第一个专注于文本到图像色彩生成的基准，旨在系统评估模型对于色彩精准度的理解与生成能力，帮助改进色彩生成的准确性与一致性。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型在细节色彩控制方面存在问题，现有的评估标准对色彩精准度的评估不足。色彩在视觉感知与沟通中至关重要，缺乏详细的基准会对相关应用造成不利影响。因此，研究者提出GenColorBench。

Method: GenColorBench基于ISCC-NBS和CSS3/X11这样的色彩系统，包括其他基准中缺失的数值色彩，配备有44K条色彩向导性的提示，涵盖400多种颜色。通过感知和自动化评估来揭示模型的真实能力。

Result: 使用GenColorBench评估了流行文本到图像模型，结果显示了性能的差异性，帮助识别模型理解哪些色彩规则较好，及模型的失败模式。

Conclusion: GenColorBench将为改进精确的色彩生成提供指导。

Abstract: Recent years have seen impressive advances in text-to-image generation, with
image generative or unified models producing high-quality images from text. Yet
these models still struggle with fine-grained color controllability, often
failing to accurately match colors specified in text prompts. While existing
benchmarks evaluate compositional reasoning and prompt adherence, none
systematically assess color precision. Color is fundamental to human visual
perception and communication, critical for applications from art to design
workflows requiring brand consistency. However, current benchmarks either
neglect color or rely on coarse assessments, missing key capabilities such as
interpreting RGB values or aligning with human expectations. To this end, we
propose GenColorBench, the first comprehensive benchmark for text-to-image
color generation, grounded in color systems like ISCC-NBS and CSS3/X11,
including numerical colors which are absent elsewhere. With 44K color-focused
prompts covering 400+ colors, it reveals models' true capabilities via
perceptual and automated assessments. Evaluations of popular text-to-image
models using GenColorBench show performance variations, highlighting which
color conventions models understand best and identifying failure modes. Our
GenColorBench assessments will guide improvements in precise color generation.
The benchmark will be made public upon acceptance.

</details>


### [47] [Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation](https://arxiv.org/abs/2510.20596)
*Ziyu Ye,Chen Ju,Chaofan Ma,Xiaoyun Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种新的基于相似性原型的跨模态分割框架，通过在嵌入空间中学习类别级别的原型，并引入相似性约束，使这些原型具有代表性且类别间可区分，从而提高了跨模态分割的性能。实验结果表明，该方法优于其他最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在应用于未见过的数据时，性能会大幅下降。为了减少领域差距，该论文致力于在无监督的情况下，通过原型来解决跨模态分割的问题，避免昂贵的标注成本。

Method: 学习嵌入空间中的类别级原型；引入相似性约束，使其具有代表性且类别间分离；使用字典来存储来自不同图像的原型，避免类别丢失问题，同时允许原型的对比学习，进一步提高性能。

Result: 通过类级别原型以及相似性约束，该方法在无监督领域适应下实现了比现有方法更好的分割性能。实验结果验证了该方法的有效性。

Conclusion: 该研究通过使用新的基于相似性原型的方法，在跨模态分割任务上取得了优于其他方法的成绩，从而证明了该方法的有效性和创新性。

Abstract: Deep learning models have achieved great success on various vision
challenges, but a well-trained model would face drastic performance degradation
when applied to unseen data. Since the model is sensitive to domain shift,
unsupervised domain adaptation attempts to reduce the domain gap and avoid
costly annotation of unseen domains. This paper proposes a novel framework for
cross-modality segmentation via similarity-based prototypes. In specific, we
learn class-wise prototypes within an embedding space, then introduce a
similarity constraint to make these prototypes representative for each semantic
class while separable from different classes. Moreover, we use dictionaries to
store prototypes extracted from different images, which prevents the
class-missing problem and enables the contrastive learning of prototypes, and
further improves performance. Extensive experiments show that our method
achieves better results than other state-of-the-art methods.

</details>


### [48] [OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects](https://arxiv.org/abs/2510.20605)
*Mark He Huang,Lin Geng Foo,Christian Theobalt,Ying Sun,De Wen Soh*

Main category: cs.CV

TL;DR: 提出了OnlineSplatter，一种从单目RGB帧生成高质量、基于对象的3D高斯分布的在线前馈框架。该框架无需相机姿态、深度先验或捆集优化，仅通过第一帧进行重建并不断优化对象表示，同时确保计算成本恒定。通过双键内存模块有效处理自由移动对象，显著优于当前最先进的无姿态重建基线，具有更优的表现并保持恒定的内存和运行时间。


<details>
  <summary>Details</summary>
Motivation: 通过从单目视频中生成高质量的3D对象重建来应对自由移动对象重建的挑战，尤其在没有可靠的姿态或深度线索和任意对象运动的情况下。提出的方法旨在在没有相机姿态、深度先验或捆集优化的情况下进行重建，不需要复杂的计算资源，能够在保持高效的同时提升重建质量。

Method: 介绍了一个名为OnlineSplatter的新框架，该框架通过第一帧建立重建基础，并随着时间的推移通过密集的高斯原始域不断优化对象表示，以此来处理自由移动的对象。核心贡献是一个结合了隐式外观-几何键和显式方向键的双键内存模块，该模块通过空间引导内存读取和高效的稀疏机制，允许有效融合当前帧特征与时间聚合的对象状态，从而处理复杂的对象运动。

Result: 该框架在实际数据集上显著优于当前最先进的无姿态重建基准。它展示了处理自由移动对象的能力，能够在更多的观察中不断提高，同时保持恒定的内存和运行时间。这些结果表明，通过使用OnlineSplatter框架可以有效地解决单目视频中的自由移动对象重建问题。

Conclusion: OnlineSplatter为从单目视频中重建自由移动对象提供了一种有效和高效的解决方案。该方法通过其独特的双键内存模块和空间引导机制，可以处理复杂的对象运动并在保持高效和低内存使用的情况下不断优化对象重建。

Abstract: Free-moving object reconstruction from monocular video remains challenging,
particularly without reliable pose or depth cues and under arbitrary object
motion. We introduce OnlineSplatter, a novel online feed-forward framework
generating high-quality, object-centric 3D Gaussians directly from RGB frames
without requiring camera pose, depth priors, or bundle optimization. Our
approach anchors reconstruction using the first frame and progressively refines
the object representation through a dense Gaussian primitive field, maintaining
constant computational cost regardless of video sequence length. Our core
contribution is a dual-key memory module combining latent appearance-geometry
keys with explicit directional keys, robustly fusing current frame features
with temporally aggregated object states. This design enables effective
handling of free-moving objects via spatial-guided memory readout and an
efficient sparsification mechanism, ensuring comprehensive yet compact object
coverage. Evaluations on real-world datasets demonstrate that OnlineSplatter
significantly outperforms state-of-the-art pose-free reconstruction baselines,
consistently improving with more observations while maintaining constant memory
and runtime.

</details>


### [49] [SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding](https://arxiv.org/abs/2510.20622)
*Yuan Sheng,Yanbin Hao,Chenxu Li,Shuo Wang,Xiangnan He*

Main category: cs.CV

TL;DR: 本文提出了一种名为SeViCES的框架，用于有效的长期视频理解，该框架通过选择最具有信息量的关键帧来解决长期视频理解中遇到的问题，并通过一致性共识提升预测的准确性与鲁棒性。在长期视频理解基准测试中的实验表明，SeViCES优于当前最先进的方法。



<details>
  <summary>Details</summary>
Motivation: 长期视频理解面临较大的挑战，现有的方法往往无法有效处理视频中复杂、多样化的以及时间上分散的内容，因此本文提出了一种新的框架SeViCES以解决这个问题。


Method: SeViCES框架引入了两个关键模块：Semantic-Visual Consensus Frame Selection (SVCFS)和Answer Consensus Refinement (ACR)。SVCFS模块通过时间敏感的语义分支和视觉分支来选择关键帧；ACR模块修正语义和视觉之间的不一致性。


Result: 实验表明SeViCES框架在长期视频理解基准测试中优于当前最先进的方法，证明了通过一致性共识进行证据选择的重要性。


Conclusion: SeViCES框架能够有效提升长期视频理解的准确性和鲁棒性，这表明通过一致性共识进行证据选择对于长期视频理解是非常关键的。


Abstract: Long video understanding remains challenging due to its complex, diverse, and
temporally scattered content. Although video large language models (Video-LLMs)
can process videos lasting tens of minutes, applying them to truly long
sequences is computationally prohibitive and often leads to unfocused or
inconsistent reasoning. A promising solution is to select only the most
informative frames, yet existing approaches typically ignore temporal
dependencies or rely on unimodal evidence, limiting their ability to provide
complete and query-relevant context. We propose a Semantic-Visual Consensus
Evidence Selection (SeViCES) framework for effective and reliable long video
understanding. SeViCES is training-free and model-agnostic, and introduces two
key components. The Semantic-Visual Consensus Frame Selection (SVCFS) module
selects frames through (1) a temporal-aware semantic branch that leverages LLM
reasoning over captions, and (2) a cluster-guided visual branch that aligns
embeddings with semantic scores via mutual information. The Answer Consensus
Refinement (ACR) module further resolves inconsistencies between semantic- and
visual-based predictions by fusing evidence and constraining the answer space.
Extensive experiments on long video understanding benchmarks show that SeViCES
consistently outperforms state-of-the-art methods in both accuracy and
robustness, demonstrating the importance of consensus-driven evidence selection
for Video-LLMs.

</details>


### [50] [UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset](https://arxiv.org/abs/2510.20661)
*Chen Zhao,En Ci,Yunzhe Xu,Tiehan Fan,Shanyan Guan,Yanhao Ge,Jian Yang,Ying Tai*

Main category: cs.CV

TL;DR: 介绍了一个名为UltraHR-100K的UHR T2I数据集和一种改进细粒度细节合成的方法。方法包括频率感知后训练法，如细粒度时间步采样和软加权频域正则化。实验表明该方法显著提升了UHR图像生成的细粒度细节和总体保真度。代码在GitHub上可得到。


<details>
  <summary>Details</summary>
Motivation: 当前UHR文本到图像生成中缺乏大规模高质量数据集和适当的训练策略来合成细粒度细节。为了克服这些问题，研究者提出了一个数据集并开发了一种新的方法来提升生成图像的细节水平。

Method: 提出的方法包括创建一个UHR T2I数据集UltraHR-100K，并引入一种频率感知的后训练方法，开发了细粒度时间步采样(DOTS)和软加权频域正则化(SWFR)来改进T2I扩散模型的细粒度细节合成。SWFR使用了离散傅里叶变换（DFT）来软约束频域组件。

Result: 实验结果表明新方法显著提升了UHR图像生成的细粒度细节和总体保真度。DOTS和SWFR有效改善了图像的真实度和细节性。

Conclusion: 通过我们的UltraHR-100K数据集和新的训练方法，研究显著推进了UHR T2I生成的问题，特别是增强了合成图像的细节度和视觉真实感。

Abstract: Ultra-high-resolution (UHR) text-to-image (T2I) generation has seen notable
progress. However, two key challenges remain : 1) the absence of a large-scale
high-quality UHR T2I dataset, and (2) the neglect of tailored training
strategies for fine-grained detail synthesis in UHR scenarios. To tackle the
first challenge, we introduce \textbf{UltraHR-100K}, a high-quality dataset of
100K UHR images with rich captions, offering diverse content and strong visual
fidelity. Each image exceeds 3K resolution and is rigorously curated based on
detail richness, content complexity, and aesthetic quality. To tackle the
second challenge, we propose a frequency-aware post-training method that
enhances fine-detail generation in T2I diffusion models. Specifically, we
design (i) \textit{Detail-Oriented Timestep Sampling (DOTS)} to focus learning
on detail-critical denoising steps, and (ii) \textit{Soft-Weighting Frequency
Regularization (SWFR)}, which leverages Discrete Fourier Transform (DFT) to
softly constrain frequency components, encouraging high-frequency detail
preservation. Extensive experiments on our proposed UltraHR-eval4K benchmarks
demonstrate that our approach significantly improves the fine-grained detail
quality and overall fidelity of UHR image generation. The code is available at
\href{https://github.com/NJU-PCALab/UltraHR-100k}{here}.

</details>


### [51] [Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models](https://arxiv.org/abs/2510.20707)
*Xuyang Liu,Xiyan Gui,Yuchao Zhang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 该工作提出了一种新的KV缓存压缩方法	exttt{MixKV}，在对大型视觉语言模型（LVLM）进行压缩时结合了重要性和多样性，从而使压缩后的KV缓存既保留关键信息又减少冗余，实验结果表明	exttt{MixKV}在多种模型和任务上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的KV缓存压缩方法侧重于保留高重要性的KV对以减少存储，而忽略了多模态KV缓存中特有的语义冗余模式，本研究希望通过结合重要性和多样性来优化LVLM中的KV缓存压缩。

Method: 	exttt{MixKV} 方法通过适应不同注意力头的语义冗余，在压缩KV对时重新平衡多样性和重要性。

Result: 实验表明	exttt{MixKV} 在多种LVLM和任务上明显优于基线方法，特别是在GUI接地任务中，对其效率提升尤为显著。此外，	exttt{MixKV} 也在大规模语言模型 (LLMs) 上展示了类似的效果。

Conclusion: 研究提出的方法	exttt{MixKV} 在平衡计算效率和模型性能方面提供了有效的解决方案，使大型视觉语言模型能够更加广泛地部署。

Abstract: Recent large vision-language models (LVLMs) demonstrate remarkable
capabilities in processing extended multi-modal sequences, yet the resulting
key-value (KV) cache expansion creates a critical memory bottleneck that
fundamentally limits deployment scalability. While existing KV cache
compression methods focus on retaining high-importance KV pairs to minimize
storage, they often overlook the modality-specific semantic redundancy patterns
that emerge distinctively in multi-modal KV caches. In this work, we first
analyze how, beyond simple importance, the KV cache in LVLMs exhibits varying
levels of redundancy across attention heads. We show that relying solely on
importance can only cover a subset of the full KV cache information
distribution, leading to potential loss of semantic coverage. To address this,
we propose \texttt{MixKV}, a novel method that mixes importance with diversity
for optimized KV cache compression in LVLMs. \texttt{MixKV} adapts to head-wise
semantic redundancy, selectively balancing diversity and importance when
compressing KV pairs. Extensive experiments demonstrate that \texttt{MixKV}
consistently enhances existing methods across multiple LVLMs. Under extreme
compression (budget=64), \texttt{MixKV} improves baseline methods by an average
of \textbf{5.1\%} across five multi-modal understanding benchmarks and achieves
remarkable gains of \textbf{8.0\%} and \textbf{9.0\%} for SnapKV and AdaKV on
GUI grounding tasks, all while maintaining comparable inference efficiency.
Furthermore, \texttt{MixKV} extends seamlessly to LLMs with comparable
performance gains. Our code is available at
\href{https://github.com/xuyang-liu16/MixKV}{\textcolor{citeblue}{https://github.com/xuyang-liu16/MixKV}}.

</details>


### [52] [ALICE-LRI: A General Method for Lossless Range Image Generation for Spinning LiDAR Sensors without Calibration Metadata](https://arxiv.org/abs/2510.20708)
*Samuel Soutullo,Miguel Yermo,David L. Vilariño,Óscar G. Lorenzo,José C. Cabaleiro,Francisco F. Rivera*

Main category: cs.CV

TL;DR: ALICE-LRI 是一种从旋转激光雷达点云生成无损范围图像的方法，无需制造商元数据或校准文件。它通过反向工程传感器的固有几何形状来实现无损投影和完全的点云重建，同时保持零点丢失和几何精度。


<details>
  <summary>Details</summary>
Motivation: 传统投影方法会导致几何不一致和信息丢失，影响高保真应用。ALICE-LRI 的动机是解决这些问题，提供一种无需制造商元数据或校准文件的无损范围图像生成方法，适用于高精度的远程感测应用。

Method: ALICE-LRI 自动反向工程任何旋转激光雷达传感器的固有几何形状，包括激光束配置、角分布和每束的校准校正，从而实现无损投影和完全点云重建，同时保持零点丢失。

Result: 在 KITTI 和 DurLAR 数据集的全面评估中，ALICE-LRI 实现了完美的点保留，0 点丢失，几何精度控制在传感器精度范围内。通过压缩案例研究验证了下游的实际应用质量改进，证明了无损 LiDAR 投影带来的显著收益。

Conclusion: ALICE-LRI 开辟了激光雷达投影的新时代，从近似向无损转变，为高精度远程感测应用提供了几何完整保存的可能性，同时保持了零点丢失和高精度。

Abstract: 3D LiDAR sensors are essential for autonomous navigation, environmental
monitoring, and precision mapping in remote sensing applications. To
efficiently process the massive point clouds generated by these sensors, LiDAR
data is often projected into 2D range images that organize points by their
angular positions and distances. While these range image representations enable
efficient processing, conventional projection methods suffer from fundamental
geometric inconsistencies that cause irreversible information loss,
compromising high-fidelity applications. We present ALICE-LRI (Automatic LiDAR
Intrinsic Calibration Estimation for Lossless Range Images), the first general,
sensor-agnostic method that achieves lossless range image generation from
spinning LiDAR point clouds without requiring manufacturer metadata or
calibration files. Our algorithm automatically reverse-engineers the intrinsic
geometry of any spinning LiDAR sensor by inferring critical parameters
including laser beam configuration, angular distributions, and per-beam
calibration corrections, enabling lossless projection and complete point cloud
reconstruction with zero point loss. Comprehensive evaluation across the
complete KITTI and DurLAR datasets demonstrates that ALICE-LRI achieves perfect
point preservation, with zero points lost across all point clouds. Geometric
accuracy is maintained well within sensor precision limits, establishing
geometric losslessness with real-time performance. We also present a
compression case study that validates substantial downstream benefits,
demonstrating significant quality improvements in practical applications. This
paradigm shift from approximate to lossless LiDAR projections opens new
possibilities for high-precision remote sensing applications requiring complete
geometric preservation.

</details>


### [53] [AutoScape: Geometry-Consistent Long-Horizon Scene Generation](https://arxiv.org/abs/2510.20726)
*Jiacheng Chen,Ziyu Jiang,Mingfu Liang,Bingbing Zhuang,Jong-Chyi Su,Sparsh Garg,Ying Wu,Manmohan Chandraker*

Main category: cs.CV

TL;DR: 论文提出了AutoScape框架，用于生成长时间驾驶场景，通过RGB-D扩散模型生成稀疏但几何一致的关键帧，并通过视频扩散模型插值生成连贯的视频帧，其在20秒以上的视频生成中表现出色，分别在长时FID和FVD分数上比现有最佳方法提高48.6%和43.0%。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长时间驾驶场景生成上难以保持几何一致性，从而影响场景的真实性和连贯性。为解决此问题，论文提出了AutoScape框架，旨在生成更长时间且几何一致的驾驶场景。

Method: 提出了一种RGB-D扩散模型及其插值方法。RGB-D扩散模型生成几何一致的关键帧，插值模型生成连贯的视频帧。具体通过共享潜在空间处理图像和深度，根据先前关键帧的几何条件，并应用保持一致的采样引导。

Result: 生成了逼真且几何一致的驾驶视频，在FID和FVD分数上比现有最佳方法大幅度提升。

Conclusion: 论文提出的AutoScape框架能够生成长时间几何一致的驾驶场景，为驾驶模拟和验证提供了高质量的视频数据。

Abstract: This paper proposes AutoScape, a long-horizon driving scene generation
framework. At its core is a novel RGB-D diffusion model that iteratively
generates sparse, geometrically consistent keyframes, serving as reliable
anchors for the scene's appearance and geometry. To maintain long-range
geometric consistency, the model 1) jointly handles image and depth in a shared
latent space, 2) explicitly conditions on the existing scene geometry (i.e.,
rendered point clouds) from previously generated keyframes, and 3) steers the
sampling process with a warp-consistent guidance. Given high-quality RGB-D
keyframes, a video diffusion model then interpolates between them to produce
dense and coherent video frames. AutoScape generates realistic and
geometrically consistent driving videos of over 20 seconds, improving the
long-horizon FID and FVD scores over the prior state-of-the-art by 48.6\% and
43.0\%, respectively.

</details>


### [54] [DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion](https://arxiv.org/abs/2510.20766)
*Noam Issachar,Guy Yariv,Sagie Benaim,Yossi Adi,Dani Lischinski,Raanan Fattal*

Main category: cs.CV

TL;DR: 本文提出了一种新的、无需额外训练的方法DyPE，使预训练的扩散变压器能够生成超出其训练数据分辨率的图像，并且不需要额外的采样成本。这使得模型可以在极高的分辨率下生成图像，同时保持高质量。DyPE通过动态调整模型的位置编码来实现这一点，从而在多个基准测试中表现出色，并达到了超高质量图像生成的最新技术水平。


<details>
  <summary>Details</summary>
Motivation: 当前的扩散变压器模型可以生成高质量的图像，但它们在超高质量下训练耗时和资源成本极高。主要原因是自注意力机制随着图像标记数量的增加而呈二次方增加。该研究的目标是寻找一种训练成本低廉的方法来生成超高质量的图像。DyPE作为一种无需额外训练的方法，能够通过动态调整位置编码来适应更高的分辨率，因此适用于生成1600万像素甚至更高分辨率的图像。

Method: DyPE利用了扩散过程中内在的频谱变化，在扩散过程的不同阶段动态调整模型的位置编码。这种方法允许模型生成比训练数据更高的分辨率，且无需额外的采样成本。它通过提前计算并在生成过程中调整低频和高频结构的位置编码来实现，从而在生成高分辨率图像时不需要额外的工作量。

Result: 通过DyPE，模型能够在不增加采样成本的情况下生成远高于训练数据分辨率的图像。在多个基准测试中，该方法在超高质量的图像生成中表现优异，甚至在更高分辨率下表现更佳，表明这种方法在生成极高分辨率图像方面具有显著的优势。

Conclusion: DyPE提供了一种创新的方法，能够使预训练的扩散变压器模型生成远高于其训练数据分辨率的图像，不仅减少了训练成本，还改善了图像生成的质量。该方法利用了扩散过程的频谱属性，证明了在不需要额外训练的情况下，图像生成的分辨率可以得到显著提升。

Abstract: Diffusion Transformer models can generate images with remarkable fidelity and
detail, yet training them at ultra-high resolutions remains extremely costly
due to the self-attention mechanism's quadratic scaling with the number of
image tokens. In this paper, we introduce Dynamic Position Extrapolation
(DyPE), a novel, training-free method that enables pre-trained diffusion
transformers to synthesize images at resolutions far beyond their training
data, with no additional sampling cost. DyPE takes advantage of the spectral
progression inherent to the diffusion process, where low-frequency structures
converge early, while high-frequencies take more steps to resolve.
Specifically, DyPE dynamically adjusts the model's positional encoding at each
diffusion step, matching their frequency spectrum with the current stage of the
generative process. This approach allows us to generate images at resolutions
that exceed the training resolution dramatically, e.g., 16 million pixels using
FLUX. On multiple benchmarks, DyPE consistently improves performance and
achieves state-of-the-art fidelity in ultra-high-resolution image generation,
with gains becoming even more pronounced at higher resolutions. Project page is
available at https://noamissachar.github.io/DyPE/.

</details>


### [55] [AlphaFlow: Understanding and Improving MeanFlow Models](https://arxiv.org/abs/2510.20771)
*Huijie Zhang,Aliaksandr Siarohin,Willi Menapace,Michael Vasilkovsky,Sergey Tulyakov,Qing Qu,Ivan Skorokhodov*

Main category: cs.CV

TL;DR: 提出了\(\alpha\)-Flow框架，通过课程策略将轨迹流匹配平滑转换为MeanFlow，解决了优化冲突，实现了更好的收敛性，并在ImageNet-1K数据集上取得了新的最优性能。


<details>
  <summary>Details</summary>
Motivation: 基于对MeanFlow目标的自然分解及其优化过程中存在的目标冲突，作者提出了\(\alpha\)-Flow框架来解决这一问题，期望提升模型在从零训练时的性能和收敛速度。

Method: \(\alpha\)-Flow是一个宽泛的目标族，它统一了轨迹流匹配、Shortcut Model和MeanFlow。通过课程策略，从轨迹流匹配平滑转换到MeanFlow，减轻了优化冲突，加速了模型的训练收敛。

Result: 在从零训练的图像条件的ImageNet-1K数据集上，\(\alpha\)-Flow的数据结果显著优于MeanFlow。其中最大的\(\alpha\)-Flow-XL/2+模型取得了最佳性能，FID得分分别为1-NFE 2.58和2-NFE 2.15。

Conclusion: \(\alpha\)-Flow通过改进从零训练中的优化策略，提高了在大规模图像生成任务中的性能。

Abstract: MeanFlow has recently emerged as a powerful framework for few-step generative
modeling trained from scratch, but its success is not yet fully understood. In
this work, we show that the MeanFlow objective naturally decomposes into two
parts: trajectory flow matching and trajectory consistency. Through gradient
analysis, we find that these terms are strongly negatively correlated, causing
optimization conflict and slow convergence. Motivated by these insights, we
introduce $\alpha$-Flow, a broad family of objectives that unifies trajectory
flow matching, Shortcut Model, and MeanFlow under one formulation. By adopting
a curriculum strategy that smoothly anneals from trajectory flow matching to
MeanFlow, $\alpha$-Flow disentangles the conflicting objectives, and achieves
better convergence. When trained from scratch on class-conditional ImageNet-1K
256x256 with vanilla DiT backbones, $\alpha$-Flow consistently outperforms
MeanFlow across scales and settings. Our largest $\alpha$-Flow-XL/2+ model
achieves new state-of-the-art results using vanilla DiT backbones, with FID
scores of 2.58 (1-NFE) and 2.15 (2-NFE).

</details>


### [56] [CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image](https://arxiv.org/abs/2510.20776)
*Binbin Huang,Haobin Duan,Yiqun Zhao,Zibo Zhao,Yi Ma,Shenghua Gao*

Main category: cs.CV

TL;DR: Cupid是一种基于世代的3D重建方法，它可以仅从一张2D图像中准确推断相机姿态、3D形状和纹理。Cupid将3D重建视为从学习到的3D对象分布中抽样条件过程，并通过联合生成体素和像素-体素对应关系，在一种统一的生成框架下实现稳健的姿态和形状估计。实验表明，Cupid在3D重建方法中超越了主导方法，同时在单一视角姿态精度方面匹配了单目估计器，并在基线3D生成模型之上提供了更优质的视觉真实性。


<details>
  <summary>Details</summary>
Motivation: 旨在提出一种新的3D重建方法，仅从单张2D图像中准确推断出相机姿态、3D形状和纹理。

Method: 将3D重建设想为从已学习的3D对象分布中进行条件采样的过程。Cupid采用了两阶段流匹配流程：粗略阶段提供与姿态恢复相关的初步3D几何形状及其2D投影；细调阶段则是利用姿态对齐的图像功能来增强结构保真度和外观细节。

Result: 在3D重建方面超越了以CPSNR增益3 dB和Chamfer Distance减少10%表明在性能上高于主流3D重建方法；在单一视角姿态精度上与单目估计器相符，并在视觉真实性方面击败了基线3D生成模型。

Conclusion: Cupid克服了当前3D重建方法面临的局限性，通过高质量的3D场景合成和准确的姿态预测，它成为了3D重建技术领域的重要成果。

Abstract: This work proposes a new generation-based 3D reconstruction method, named
Cupid, that accurately infers the camera pose, 3D shape, and texture of an
object from a single 2D image. Cupid casts 3D reconstruction as a conditional
sampling process from a learned distribution of 3D objects, and it jointly
generates voxels and pixel-voxel correspondences, enabling robust pose and
shape estimation under a unified generative framework. By representing both
input camera poses and 3D shape as a distribution in a shared 3D latent space,
Cupid adopts a two-stage flow matching pipeline: (1) a coarse stage that
produces initial 3D geometry with associated 2D projections for pose recovery;
and (2) a refinement stage that integrates pose-aligned image features to
enhance structural fidelity and appearance details. Extensive experiments
demonstrate Cupid outperforms leading 3D reconstruction methods with an over 3
dB PSNR gain and an over 10% Chamfer Distance reduction, while matching
monocular estimators on pose accuracy and delivering superior visual fidelity
over baseline 3D generative models. For an immersive view of the 3D results
generated by Cupid, please visit cupid3d.github.io.

</details>


### [57] [Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common Feature](https://arxiv.org/abs/2510.20794)
*Lei Cheng,Siyang Cao*

Main category: cs.CV

TL;DR: 本文提出了一种多目标跟踪框架，该框架通过融合雷达和相机数据提高跟踪效率，减少手动干预。通过在线雷达相机校准利用公共特征实现自动关联检测结果，从而简化不同传感器检测结果的集成，提高传感器关联的准确性。实验显示该框架能够简化雷达相机映射过程并提高跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 现有研究多数未充分利用雷达的优势，将其视为辅助角色，而本文则将雷达置于关键角色，并通过雷达和相机数据的共同特征在线校准，提高多目标跟踪的准确性与效率，减少手动干预，特别是在真实交通场景与控制环境中的应用效果明显提升。

Method: 利用在线雷达相机校准，整合雷达和相机检测结果，通过共同特征实现自动关联，而不是仅仅依靠位置匹配；采用特征匹配和类别一致性检查以提高传感器关联的准确性。

Result: 证明了本框架能够简化雷达和相机映射过程，并提高跟踪精度，经过真实世界的实验，尤其是在控制环境和实际交通场景中验证了其有效性。代码可在https://github.com/radar-lab/Radar_Camera_MOT获取。

Conclusion: 首次研究了雷达和相机共同特征在在线校准中的应用，证明了集成这些特征可以简化雷达和相机映射过程，提高多目标跟踪的精度。

Abstract: This paper presents a Multi-Object Tracking (MOT) framework that fuses radar
and camera data to enhance tracking efficiency while minimizing manual
interventions. Contrary to many studies that underutilize radar and assign it a
supplementary role--despite its capability to provide accurate range/depth
information of targets in a world 3D coordinate system--our approach positions
radar in a crucial role. Meanwhile, this paper utilizes common features to
enable online calibration to autonomously associate detections from radar and
camera. The main contributions of this work include: (1) the development of a
radar-camera fusion MOT framework that exploits online radar-camera calibration
to simplify the integration of detection results from these two sensors, (2)
the utilization of common features between radar and camera data to accurately
derive real-world positions of detected objects, and (3) the adoption of
feature matching and category-consistency checking to surpass the limitations
of mere position matching in enhancing sensor association accuracy. To the best
of our knowledge, we are the first to investigate the integration of
radar-camera common features and their use in online calibration for achieving
MOT. The efficacy of our framework is demonstrated by its ability to streamline
the radar-camera mapping process and improve tracking precision, as evidenced
by real-world experiments conducted in both controlled environments and actual
traffic scenarios. Code is available at
https://github.com/radar-lab/Radar_Camera_MOT

</details>


### [58] [ARGenSeg: Image Segmentation with Autoregressive Image Generation Model](https://arxiv.org/abs/2510.20803)
*Xiaolong Wang,Lixiang Ru,Ziyuan Huang,Kaixiang Ji,Dandan Zheng,Jingdong Chen,Jun Zhou*

Main category: cs.CV

TL;DR: ARGenSeg通过基于图像生成的框架实现多模态理解和像素级感知，提高了图像分割的效果与效率。


<details>
  <summary>Details</summary>
Motivation: 现有的集成图像分割到多模态大型语言模型（MLLM）的方法依赖于边界点表示或特定的分割头，这些方法限制了MLLM捕捉细粒度视觉细节的能力。因此，我们引入了一个基于图像生成的分割框架，以改善这一问题。

Method: 提出了一种新型的图像生成为基础的ARGenSeg多模态分割框架，该框架使用MLLM输出视觉令牌，并通过通用的VQ-VAE将令牌解码为图像，提高分割准确性。同时采用下一级预测策略来减少推断延迟。

Result: 实验表明，我们的方法在多个分割数据集上超越了之前最先进的方法，并且在很大程度上提高了推理速度，同时保持了对视觉细节的强理解能力。

Conclusion: ARGenSeg提供了一种新的基于图像生成的方法来提高图像分割的效率和准确性，并解决了现有方法的一些限制。

Abstract: We propose a novel AutoRegressive Generation-based paradigm for image
Segmentation (ARGenSeg), achieving multimodal understanding and pixel-level
perception within a unified framework. Prior works integrating image
segmentation into multimodal large language models (MLLMs) typically employ
either boundary points representation or dedicated segmentation heads. These
methods rely on discrete representations or semantic prompts fed into
task-specific decoders, which limits the ability of the MLLM to capture
fine-grained visual details. To address these challenges, we introduce a
segmentation framework for MLLM based on image generation, which naturally
produces dense masks for target objects. We leverage MLLM to output visual
tokens and detokenize them into images using an universal VQ-VAE, making the
segmentation fully dependent on the pixel-level understanding of the MLLM. To
reduce inference latency, we employ a next-scale-prediction strategy to
generate required visual tokens in parallel. Extensive experiments demonstrate
that our method surpasses prior state-of-the-art approaches on multiple
segmentation datasets with a remarkable boost in inference speed, while
maintaining strong understanding capabilities.

</details>


### [59] [Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers](https://arxiv.org/abs/2510.20807)
*Dean L Slack,G Thomas Hudson,Thomas Winterbottom,Noura Al Moubayed*

Main category: cs.CV

TL;DR: 研究介绍了一种基于变压器的纯自回归视频预测模型，该模型使用连续像素空间表示，通过物理对象追踪和未监督学习的策略，在物理仿真数据集上实现了比现有方法更长时间的准确预测，并且具有更好的解释性。此模型旨在通过简单、参数效率高且易于解释的方法改进视频的时空注意力机制建模。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成方法在物理仿真时存在局限，无法很好地处理时空因果关系。因此，该研究尝试通过物理对象追踪和未监督学习的方式，改进视频预测模型的时空因果关系理解能力，以实现更长时间的物理准确预测。此工作是基于注意力的时空建模视频研究的平台性进展。

Method: 研究中提出了一种Transformer模型，该模型采用了连续的像素空间表示，并通过来自物理仿真数据集的无监督学习方法进行训练，从而实现了自回归视频预测方法的改进，重点在于设计方案的简化、参数效率以及模型的可解释性。

Result: 与现有的基于潜在空间的方法相比，该模型在物理准确预测的时间范围内增加了50%，并且在常见的视频质量度量上具有相当的表现。此外，该模型还通过可解析性实验证明了对PDE仿真参数估计的解读能力，并验证了模型对未知分布参数估计的泛化能力。

Conclusion: 本研究通过一种简单、参数效率高且可解析的纯Transformer模型，证明了在视频预测中引入连续像素表示和物理对象跟踪策略可以显著提高预测的时空精确度。

Abstract: Inspired by the performance and scalability of autoregressive large language
models (LLMs), transformer-based models have seen recent success in the visual
domain. This study investigates a transformer adaptation for video prediction
with a simple end-to-end approach, comparing various spatiotemporal
self-attention layouts. Focusing on causal modeling of physical simulations
over time; a common shortcoming of existing video-generative approaches, we
attempt to isolate spatiotemporal reasoning via physical object tracking
metrics and unsupervised training on physical simulation datasets. We introduce
a simple yet effective pure transformer model for autoregressive video
prediction, utilizing continuous pixel-space representations for video
prediction. Without the need for complex training strategies or latent
feature-learning components, our approach significantly extends the time
horizon for physically accurate predictions by up to 50% when compared with
existing latent-space approaches, while maintaining comparable performance on
common video quality metrics. In addition, we conduct interpretability
experiments to identify network regions that encode information useful to
perform accurate estimations of PDE simulation parameters via probing models,
and find that this generalizes to the estimation of out-of-distribution
simulation parameters. This work serves as a platform for further
attention-based spatiotemporal modeling of videos via a simple, parameter
efficient, and interpretable approach.

</details>


### [60] [Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation](https://arxiv.org/abs/2510.20812)
*Yuhan Liu,Lianhui Qin,Shengjie Wang*

Main category: cs.CV

TL;DR: 我们提出了Speculative Verdict (SV)框架，这是一种需要训练的框架，通过结合多个轻量级草图专家和一个强大的判决模型，来解决大型Vision-Language Models (VLMs)在处理信息密集型图像时的推理问题。SV框架提高了效率和准确性，同时在挑战性的信息密集型和高分辨率视觉问答基准上取得了持续的收益。这个框架不仅实现了错误纠正，还提高了成本效率，相比大型自研模型或训练流程更加优越。


<details>
  <summary>Details</summary>
Motivation: 大型Vision-Language Models (VLMs) 在多模式理解方面取得了显著进展，但在处理信息密集型图像时存在困难，这些图像常常是文本注释和细粒度图形元素的密集交织。为了克服这些挑战，需要精确地定位密集布局中的关键线索，并且进行多次推理以整合分散的证据。因此，提出了Speculative Verdict (SV)框架，旨在解决这个问题。

Method: SV框架结合多个轻量级草图专家和一个强大的判决模型。在草图阶段，小的VLM作为草图专家生成推理路径，提供多样化的定位候选；在判决阶段，一个强的VLM通过合并这些路径来生成最终答案，同时降低计算成本。为进一步提高效率和准确性，SV框架引入了一种共识专家选择机制，只向前推进高一致性的推理路径给判决模型。

Result: 在信息密集型和高分辨率视觉问答基准上，SV取得了持续的收益。这个框架在整合多个部分准确的推理路径中能提炼出正确的见解，从而使错误纠正和成本效率都得到提升，较之大型自研模型或者训练流程表现得更好。

Conclusion: Speculative Verdict (SV)提供了一种新颖的方法来解决大型Vision-Language Models在处理信息密集型图像的推理问题，通过融合多个轻量级草图专家和一个强的判决模型，提高了效率和准确性，实现了错误纠正和成本效率的双赢。

Abstract: Large Vision-Language Models (VLMs) have achieved remarkable progress in
multimodal understanding, yet they struggle when reasoning over
information-intensive images that densely interleave textual annotations with
fine-grained graphical elements. The main challenges lie in precisely
localizing critical cues in dense layouts and multi-hop reasoning to integrate
dispersed evidence. We propose Speculative Verdict (SV), a training-free
framework inspired by speculative decoding that combines multiple lightweight
draft experts with a large verdict model. In the draft stage, small VLMs act as
draft experts to generate reasoning paths that provide diverse localization
candidates; in the verdict stage, a strong VLM synthesizes these paths to
produce the final answer, minimizing computational cost while recovering
correct answers. To further improve efficiency and accuracy, SV introduces a
consensus expert selection mechanism that forwards only high-agreement
reasoning paths to the verdict. Empirically, SV achieves consistent gains on
challenging information-intensive and high-resolution visual question answering
benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K.
By synthesizing correct insights from multiple partially accurate reasoning
paths, SV achieves both error correction and cost-efficiency compared to large
proprietary models or training pipelines. Code is available at
https://github.com/Tinaliu0123/speculative-verdict

</details>


### [61] [SpectraMorph: Structured Latent Learning for Self-Supervised Hyperspectral Super-Resolution](https://arxiv.org/abs/2510.20814)
*Ritik Shah,Marco F Duarte*

Main category: cs.CV

TL;DR: SpectraMorph 是一种基于物理知识的自监督融合框架，通过提取低分辨率的超光谱图像中的端元签名并从多光谱图像中预测丰度图来实现超光谱图像的超分辨率。该框架在合成和真实数据集上的实验表明，SpectraMorph 比现有的无人监督/自监督和监督方法表现更好或相当。同时，它还具有可解释性强、训练速度快和泛化能力强的优点。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的超光谱图像超分辨率方法虽然性能很好，但是通常缺乏可解释性，并且当多光谱图像中的波段很少时难以取得好的效果。因此，重新设计一种可以利用多光谱图像高空间分辨率和超光谱图像高光谱分辨率的融合方法就显得尤为必要，而我们提出的SpectraMorph可以很好地实现该目的。

Method: SpectraMorph 的方法步骤包括：从低分辨率的超光谱图像中提取端元签名, 使用一个轻量级的多层感知器从多光谱图像预测丰度图，然后通过线性混合模型重建光谱，训练过程使用多光谱传感器的光谱响应函数进行自监督。这种方法实现了对超光谱图像模糊边界和混合像素效果的良好处理，同时保留了高空间分辨率和光谱分辨率的优点。

Result: SpectraMorph 在合成和真实数据集上的表现优于现有的无人监督/自监督方法，并且在某些方面与监督方法表现相当或更好。此外，该方法只需几分钟的训练时间，并且在仅依靠单一波段（全色）多光谱图像时依然保持较强的鲁棒性。

Conclusion: 通过利用物理知识并结合自监督学习框架，SpectraMorph 能够生成清晰的超光谱图像，克服了传统方法缺乏可解释性和在处理低波段多光谱图像时的局限性。

Abstract: Hyperspectral sensors capture dense spectra per pixel but suffer from low
spatial resolution, causing blurred boundaries and mixed-pixel effects.
Co-registered companion sensors such as multispectral, RGB, or panchromatic
cameras provide high-resolution spatial detail, motivating hyperspectral
super-resolution through the fusion of hyperspectral and multispectral images
(HSI-MSI). Existing deep learning based methods achieve strong performance but
rely on opaque regressors that lack interpretability and often fail when the
MSI has very few bands. We propose SpectraMorph, a physics-guided
self-supervised fusion framework with a structured latent space. Instead of
direct regression, SpectraMorph enforces an unmixing bottleneck: endmember
signatures are extracted from the low-resolution HSI, and a compact multilayer
perceptron predicts abundance-like maps from the MSI. Spectra are reconstructed
by linear mixing, with training performed in a self-supervised manner via the
MSI sensor's spectral response function. SpectraMorph produces interpretable
intermediates, trains in under a minute, and remains robust even with a
single-band (pan-chromatic) MSI. Experiments on synthetic and real-world
datasets show SpectraMorph consistently outperforming state-of-the-art
unsupervised/self-supervised baselines while remaining very competitive against
supervised baselines.

</details>


### [62] [Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge](https://arxiv.org/abs/2510.20819)
*Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot*

Main category: cs.CV

TL;DR: 提出了一个新的模型Latent Denoising Diffusion Bridge Model (LDDBM)，用于跨不同感官模态的翻译任务，该模型在共享的潜在空间中操作，无需对齐的维度，支持任意模态的对，表现出色，建立了新的基线模型


<details>
  <summary>Details</summary>
Motivation: 现有的方法经常依赖于一些限制性假设，比如共享的维度，高斯源先验和模态特异性架构，这些假设限制了它们的通用性和理论依据。 现有的生成模型在单模态领域表现很好，但跨模态翻译仍然是一个挑战

Method: 该模型在共享的潜在空间中操作，通过引入对比对齐损失来确保配对样本之间的语义一致性，并设计了一个噪声预测的解码器编码器架构，来应对不确定的域。此外，还提出了一种预测损失，以引导训练朝向准确的跨域转换

Result: 方法在任意模态对上表现良好，涵盖了多视角到3D形状生成，图像超分辨率，多视角场景合成等任务

Conclusion: 实验验证了框架的有效性，成为跨模态翻译的新基线模型

Abstract: Recent advances in generative modeling have positioned diffusion models as
state-of-the-art tools for sampling from complex data distributions. While
these models have shown remarkable success across single-modality domains such
as images and audio, extending their capabilities to Modality Translation (MT),
translating information across different sensory modalities, remains an open
challenge. Existing approaches often rely on restrictive assumptions, including
shared dimensionality, Gaussian source priors, and modality-specific
architectures, which limit their generality and theoretical grounding. In this
work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a
general-purpose framework for modality translation based on a latent-variable
extension of Denoising Diffusion Bridge Models. By operating in a shared latent
space, our method learns a bridge between arbitrary modalities without
requiring aligned dimensions. We introduce a contrastive alignment loss to
enforce semantic consistency between paired samples and design a
domain-agnostic encoder-decoder architecture tailored for noise prediction in
latent space. Additionally, we propose a predictive loss to guide training
toward accurate cross-domain translation and explore several training
strategies to improve stability. Our approach supports arbitrary modality pairs
and performs strongly on diverse MT tasks, including multi-view to 3D shape
generation, image super-resolution, and multi-view scene synthesis.
Comprehensive experiments and ablations validate the effectiveness of our
framework, establishing a new strong baseline in general modality translation.
For more information, see our project page:
https://sites.google.com/view/lddbm/home.

</details>


### [63] [LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas](https://arxiv.org/abs/2510.20820)
*Guocheng Gordon Qian,Ruihang Zhang,Tsai-Shien Chen,Yusuf Dalva,Anujraaj Argo Goyal,Willi Menapace,Ivan Skorokhodov,Meng Dong,Arpit Sahni,Daniil Ostashev,Ju Hu,Sergey Tulyakov,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: LayerComposer是一种交互式框架，用于个性化、多主题的文本到图像生成，解决了现有模型在空间组成控制和多主题扩展方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有个性化生成模型缺乏对空间组成的交互控制，并且难以扩展到多个主题。为了克服这些限制，提出了LayerComposer框架。

Method: 该方法的主要贡献是引入了一种分层画布表示，其中每个主题放置在不同的层中，并且有一个锁定机制，它在保持选定图层高保真度的同时允许其他图层灵活适应周围环境。锁定机制无需对架构进行任何更改，而是依赖于固有的位置嵌入和新的互补数据采样策略。

Result: 实验表明，LayerComposer在空间控制和身份保持方面优于多主题个性化图像生成方面的现有先进技术。

Conclusion: LayerComposer是一种强大的工具，它在多主题个性化图像生成方面提供了更好的空间控制和身份保持能力。

Abstract: Despite their impressive visual fidelity, existing personalized generative
models lack interactive control over spatial composition and scale poorly to
multiple subjects. To address these limitations, we present LayerComposer, an
interactive framework for personalized, multi-subject text-to-image generation.
Our approach introduces two main contributions: (1) a layered canvas, a novel
representation in which each subject is placed on a distinct layer, enabling
occlusion-free composition; and (2) a locking mechanism that preserves selected
layers with high fidelity while allowing the remaining layers to adapt flexibly
to the surrounding context. Similar to professional image-editing software, the
proposed layered canvas allows users to place, resize, or lock input subjects
through intuitive layer manipulation. Our versatile locking mechanism requires
no architectural changes, relying instead on inherent positional embeddings
combined with a new complementary data sampling strategy. Extensive experiments
demonstrate that LayerComposer achieves superior spatial control and identity
preservation compared to the state-of-the-art methods in multi-subject
personalized image generation.

</details>


### [64] [HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives](https://arxiv.org/abs/2510.20822)
*Yihao Meng,Hao Ouyang,Yue Yu,Qiuyu Wang,Wen Wang,Ka Leong Cheng,Hanlin Wang,Yixuan Li,Cheng Chen,Yanhong Zeng,Yujun Shen,Huamin Qu*

Main category: cs.CV

TL;DR: HoloCine is a model that generates entire scenes holistically to ensure global consistency in text-to-video creation, setting a new state-of-the-art in narrative coherence.


<details>
  <summary>Details</summary>
Motivation: Current text-to-video models can generate isolated clips but struggle with coherent, multi-shot narratives. HoloCine aims to bridge this gap by ensuring global consistency from the first to the last shot.

Method: HoloCine employs a Window Cross-Attention mechanism to precisely localize text prompts to specific shots and a Sparse Inter-Shot Self-Attention pattern to ensure efficiency in minute-scale generation.

Result: HoloCine achieves state-of-the-art narrative coherence and develops emergent abilities such as persistent memory for characters and scenes, and an understanding of cinematic techniques.

Conclusion: The work represents a shift from clip synthesis to automated filmmaking, making it an important step towards end-to-end cinematic creation.

Abstract: State-of-the-art text-to-video models excel at generating isolated clips but
fall short of creating the coherent, multi-shot narratives, which are the
essence of storytelling. We bridge this "narrative gap" with HoloCine, a model
that generates entire scenes holistically to ensure global consistency from the
first shot to the last. Our architecture achieves precise directorial control
through a Window Cross-Attention mechanism that localizes text prompts to
specific shots, while a Sparse Inter-Shot Self-Attention pattern (dense within
shots but sparse between them) ensures the efficiency required for minute-scale
generation. Beyond setting a new state-of-the-art in narrative coherence,
HoloCine develops remarkable emergent abilities: a persistent memory for
characters and scenes, and an intuitive grasp of cinematic techniques. Our work
marks a pivotal shift from clip synthesis towards automated filmmaking, making
end-to-end cinematic creation a tangible future. Our code is available at:
https://holo-cine.github.io/.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [65] [Excitation of Looped Bistable Bands for High-Speed Linear Actuation](https://arxiv.org/abs/2510.19834)
*Sareum Kim,Josie Hughes*

Main category: eess.SY

TL;DR: 本文研究了通过激发一个环形双稳态带弹簧实现的高速线性运动放大。当弹簧环形成两个明显关节时，可以实现平滑振荡。这一系统在共振条件下将输入振荡转换为放大线性运动，突显了双稳态带弹簧在高速往复线性运动中的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着软机器人技术越来越依赖智能材料和创新结构，双稳态带弹簧作为一种有前景的选项，引起了研究者的兴趣。本文探讨了通过激发双稳态带弹簧所达到的高速线性运动放大。目的在于开发一种新的振荡机制，用于获得高速线性运动能力。

Method: 该研究采用环形双稳态带弹簧设置，形成两个明确的关节，通过一个直轨安装并且被一个曲柄机构在不同频率下驱动，以此实现高速往复线性运动的放大实验。通过增频来观察整个系统的运动响应。这种方法验证了环形双稳态带弹簧在共振条件下将输入振荡有效转化为放大线性运动的能力。

Result: 研究表明，通过调节激励频率，在共振条件下，该机制能够高效地将双稳态带弹簧的振荡运动转化为高速线性运动，并且速度显著增加。这一发现证明了环形双稳态带弹簧作为高速运动放大器的有效性。

Conclusion: 双稳态带弹簧特别是环形构造，在受到不同频率的驱动时，能够实现高速的往复线性运动放大器。这一发现对于软机器人技术和需要高速往复线性运动的应用领域具有重要意义。

Abstract: Soft robotics increasingly relies on smart materials and innovative
structures, with bistable tape springs emerging as a promising option. These
structures exhibit intriguing dynamic behaviors, such as oscillation, due to
their inherent bistability. This paper explores the high-speed linear
amplification of motion achieved through the excitation of a looped bistable
tape spring. When looped, the tape spring forms two distinct joints,
facilitating smooth oscillation. Mounted on a linear guide and driven by a
crank mechanism with varying frequency, the system converts input oscillations
into amplified linear motion at resonance. This study highlights the potential
of bistable tape springs high speed reciprocating linear motion.

</details>


### [66] [SpeechAgent: An End-to-End Mobile Infrastructure for Speech Impairment Assistance](https://arxiv.org/abs/2510.20113)
*Haowei Lou,Chengkai Huang,Hye-young Paik,Yongquan Hu,Aaron Quigley,Wen Hu,Lina Yao*

Main category: eess.SY

TL;DR: 我们提出了SpeechAgent，这是一种移动应用程序，旨在帮助有语言障碍（如失语症、口吃等）的人进行日常交流。它结合了大型语言模型（LLM）推理和先进的语音处理模块，可以根据不同的障碍类型提供个性化的支持。该系统已经在实际的障碍语音数据集上进行了评估，并证明是有效且用户友好的，适用于日常辅助交流。


<details>
  <summary>Details</summary>
Motivation: 虽然自动语音识别（ASR）和语音合成（TTS）技术进步很大，但面向语言障碍用户的便携式基础设施仍然有限，限制了这些技术在实际交流中的应用。因此，我们设计了SpeechAgent，以通过将大型语言模型驱动的推理和先进的语音处理功能结合在一起，来帮助语言障碍用户在日常交流中获得更好的体验和支持。

Method: SpeechAgent整合了大型语言模型驱动的推理与先进的语音处理模块，提供适应不同障碍类型的个性化支持。为了确保其实用性，我们开发了一种结构化的部署管道，使得SpeechAgent能够在移动设备和边缘设备上实现实时语音处理，同时确保低延时、高准确率和高质量的语音输出。

Result: 通过在实际的障碍语音数据集上的测试，我们确认SpeechAgent能够实现实时的低延时语音处理，同时保持高准确率和高质量的语音输出，它已经被证明是有效且用户友好的，适用于日常辅助交流。

Conclusion: SpeechAgent代表了一种新的方向，将大型语言模型的推理能力与先进的语音处理模块相结合，通过在移动和边缘设备上进行实时处理，使得语言障碍用户能够在日常生活中更容易地参与交流。

Abstract: Speech is essential for human communication, yet millions of people face
impairments such as dysarthria, stuttering, and aphasia conditions that often
lead to social isolation and reduced participation. Despite recent progress in
automatic speech recognition (ASR) and text-to-speech (TTS) technologies,
accessible web and mobile infrastructures for users with impaired speech remain
limited, hindering the practical adoption of these advances in daily
communication. To bridge this gap, we present SpeechAgent, a mobile SpeechAgent
designed to facilitate people with speech impairments in everyday
communication. The system integrates large language model (LLM)- driven
reasoning with advanced speech processing modules, providing adaptive support
tailored to diverse impairment types. To ensure real-world practicality, we
develop a structured deployment pipeline that enables real-time speech
processing on mobile and edge devices, achieving imperceptible latency while
maintaining high accuracy and speech quality. Evaluation on real-world impaired
speech datasets and edge-device latency profiling confirms that SpeechAgent
delivers both effective and user-friendly performance, demonstrating its
feasibility for personalized, day-to-day assistive communication.

</details>


### [67] [Interpolatory Approximations of PMU Data: Dimension Reduction and Pilot Selection](https://arxiv.org/abs/2510.20116)
*Sean Reiter,Mark Embree,Serkan Gugercin,Vassilis Kekatos*

Main category: eess.SY

TL;DR: 本文提出了一种基于插值矩阵分解(IDs)的框架，用于减少相量测量单元(PMU)数据。通过仅使用PMU数据流的几行或几列，ID可以恢复完整数据矩阵，从而实现对电力传输系统的实时监控，节省通信带宽。我们提出了通过离散经验插值法(DEIM)选择ID中的行和列的方法，DEIM是一种贪婪算法，旨在控制误差上限。该误差界提供了重构误差的可计算估计，违反该估计则表明系统运行条件发生变化，可以作为故障检测工具。


<details>
  <summary>Details</summary>
Motivation: 动机为使用低秩矩阵近似减少PMU数据，同时确保电力传输系统的实时监控。通过使用插值矩阵分解，可以从少量测量中恢复完整数据矩阵，并通过控制误差上限来实现有效的数据压缩和系统故障检测。

Method: 提出了一种基于插值矩阵分解（Interpolatory Decompositions，IDs）的框架，用于减少PMU数据。DEIM用于选择IDs中的行和列，以提供误差控制和性能估计，从而实现有效的数据压缩。

Result: DEIM在数据压缩方面的性能表现出色，验证了DEIM-based故障检测方法的有效性。一种基于重构误差的可计算估计的方法被提出，这可以用来检测系统运行条件的变化，进而用于故障检测。提供了一个严格的误差界限，以确保数据压缩的质量。

Conclusion: 通过使用插值矩阵分解及其误差界，本文提供了一种在减少PMU数据量的同时，可以实现电力传输系统实时监控的框架，并且该框架还提供了一种有效的故障检测方法。

Abstract: This work investigates the reduction of phasor measurement unit (PMU) data
through low-rank matrix approximations. To reconstruct a PMU data matrix from
fewer measurements, we propose the framework of interpolatory matrix
decompositions (IDs). In contrast to methods relying on principal component
analysis or singular value decomposition, IDs recover the complete data matrix
using only a few of its rows (PMU datastreams) and/or a few of its columns
(snapshots in time). This compression enables the real-time monitoring of power
transmission systems using a limited number of measurements, thereby minimizing
communication bandwidth. The ID perspective gives a rigorous error bound on the
quality of the data compression. We propose selecting rows and columns used in
an ID via the discrete empirical interpolation method (DEIM), a greedy
algorithm that aims to control the error bound. This bound leads to a
computable estimate for the reconstruction error during online operations. A
violation of this estimate suggests a change in the system's operating
conditions, and thus serves as a tool for fault detection. Numerical tests
using synthetic PMU data illustrate DEIM's excellent performance for data
compression, and validate the proposed DEIM-based fault-detection method.

</details>


### [68] [Soft Switching Expert Policies for Controlling Systems with Uncertain Parameters](https://arxiv.org/abs/2510.20152)
*Junya Ikemoto*

Main category: eess.SY

TL;DR: 本文提出了一种基于模拟的强化学习算法，用于控制具有不确定和变化系统参数的系统。该算法包括两个阶段：第一阶段在模拟器中学习多个不同参数系统的控制策略；第二阶段在实际系统中基于观测结果使用在线凸优化算法平滑切换第一阶段学习到的控制策略。该算法通过数值实验得到了验证。


<details>
  <summary>Details</summary>
Motivation: 旨在解决强化学习中从模拟环境到真实环境时的现实差距问题，提出了利用模拟器安全地学习物理系统控制策略的方法。通过两个阶段的算法设计，来动态适应不同参数下的系统变化，实现实时最优控制。

Method: 提出的算法包含两阶段：第一阶段，利用模拟器学习不同系统参数下的多个控制策略；第二阶段，采用在线凸优化算法，根据观察到的实际系统行为，平滑地切换之前学到的控制策略，从而减轻模拟环境和真实环境之间的现实差距。

Result: 算法通过数值实验验证了有效性，表明能够成功应对不同参数系统的变化，并展现出平滑切换策略的优越性。

Conclusion: 总而言之，通过结合模拟学习与在线优化技术，本文提出的两阶段算法提供了一种有效的应对系统参数不确定性和变化的方法，展示了潜在的广泛应用前景。

Abstract: This paper proposes a simulation-based reinforcement learning algorithm for
controlling systems with uncertain and varying system parameters. While
simulators are useful for safely learning control policies for physical
systems, mitigating the reality gap remains a major challenge. To address the
challenge, we propose a two-stage algorithm. In the first stage, multiple
control policies are learned for systems with different parameters in a
simulator. In the second stage, for a real system, the control policies learned
in the first stage are smoothly switched using an online convex optimization
algorithm based on observations. Our proposed algorithm is demonstrated through
numerical experiments.

</details>


### [69] [From Bundles to Backstepping: Geometric Control Barrier Functions for Safety-Critical Control on Manifolds](https://arxiv.org/abs/2510.20202)
*Massimiliano de Sa,Pio Ong,Aaron D. Ames*

Main category: eess.SY

TL;DR: 本文发展了一种关于流形上几何控制屏障函数的通用理论，并为控制仿射系统恢复了标准的基于优化的控制屏障函数控制器及其平滑类似物。通过将基于动能的控制屏障函数的反步法推广到黎曼流形，提供了一种用于几何力学系统的控制屏障函数合成技术，并展示了其在SO(3)卫星的欠驱动系统中的应用。


<details>
  <summary>Details</summary>
Motivation: 传统的控制屏障函数理论在欧几里得空间中较为成熟，但在机器人和航空航天等应用中常见的流形系统中缺乏通用的方法和有用的合成工具。

Method: 发展了一个关于流形上几何控制屏障函数的通用理论；恢复了控制仿射系统下的标准优化控制屏障函数控制器及其平滑类似物；推广了黎曼流形上的基于动能的控制屏障函数反步法，为几何力学系统提供简便的控制系统设计方法。此技术利用力学结构避免了高阶切丛上的计算。

Result: 为机械控制系统提供了一种易验证的成功合成条件的方法，并展示了此方法在SO(3)卫星欠驱动系统中的应用。

Conclusion: 提出了新型的几何控制屏障函数理论和技术，为流形系统下的控制问题提供了新的解决方案，并展示其在特定航天系统中的应用和可行性。

Abstract: Control barrier functions (CBFs) have a well-established theory in Euclidean
spaces, yet still lack general formulations and constructive synthesis tools
for systems evolving on manifolds common in robotics and aerospace
applications. In this paper, we develop a general theory of geometric CBFs on
bundles and, for control-affine systems, recover the standard
optimization-based CBF controllers and their smooth analogues. Then, by
generalizing kinetic energy-based CBF backstepping to Riemannian manifolds, we
provide a constructive CBF synthesis technique for geometric mechanical
systems, as well as easily verifiable conditions under which it succeeds.
Further, this technique utilizes mechanical structure to avoid computations on
higher-order tangent bundles. We demonstrate its application to an
underactuated satellite on SO(3).

</details>


### [70] [Observer-based Differentiators for Noisy Signals](https://arxiv.org/abs/2510.20234)
*Van Huynh,Hieu Trinh,Riley Bain*

Main category: eess.SY

TL;DR: 本文提出了一组基于观测系统的不同器，能够估计给定信号的导数，即使该信号存在噪声干扰。


<details>
  <summary>Details</summary>
Motivation: 为了在信号受噪声影响的情况下仍能准确估计信号的导数，本文提出了观察系统作为不同器的方法。

Method: 建立了一系列的观者系统，能够处理含噪声的信号并估计出其导数。

Result: 观察系统可以在信号存在噪声干扰的情况下正确地估计出信号的导数。

Conclusion: 通过采用不同的观测系统，可以有效地估计含噪声信号的导数，这种方法对于信号处理具有重要意义。

Abstract: We present a collection of different types of observation systems that work
as differentiators. These observer-based differentiators can produce estimates
for derivatives of a given signal, even though the given signal is prone to
noise.

</details>


### [71] [On MIMO Stability Analysis Methods Applied to Inverter-Based Resources Connected to Power Systems](https://arxiv.org/abs/2510.20384)
*Anton A. Stoorvogel,Saeed Lotfifard,Ali Saberi*

Main category: eess.SY

TL;DR: 本文对文献中常用的用于逆变器资源（IBRs）小信号稳定性分析的方法进行了批判性回顾，讨论了这些方法的用途、适当和不适当的实施方式，并提供了关于这些技术适用性、固有限制及误用源头的见解和说明。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在通过回顾小信号稳定性分析方法，来提升对逆变器资源（IBRs）的理解和应用。研究动机在于识别现有方法的局限性以及误用情况，为研究和工程实践提供清晰的指导。

Method: 论文采用批判性回顾的方法，分析了现有文献中小信号稳定性分析的各种方法，包括它们的目标、实施示例、可能的错误类型及其原因。

Result: 论文明确指出了每种方法的适用范围和局限，并揭示了一些导致误用的小信号稳定性分析。

Conclusion: 结论强调了正确理解和应用小信号稳定性分析方法的重要性，建议在使用这些方法时要充分考虑其限制，并倡导未来研究关注改进现有方法或开发新方法以更好地解决逆变器资源（IBRs）的小信号稳定性问题。

Abstract: This paper presents a critical review of methods
  commonly employed in the literature for small signal stability analysis of
  inverter based resources (IBRs). It discusses the intended purposes
  of these methods and outlines both their proper and improper
  implementations. The paper provides insights into the applicability
  of these techniques, clarifies their inherent limitations, and
  discusses and illustrates common sources of misinterpretation.

</details>


### [72] [Interlacing in Controllers Implementation: Frequency Analysis](https://arxiv.org/abs/2510.20394)
*Julian Salt*

Main category: eess.SY

TL;DR: 本文介绍了如何利用交错技术实现线性时不变（LTI）控制器，并分析了不同结构在该环境中的应用，从而节省了资源受限环境下的计算成本。提出了新的方法来获取与不同实数和复数控制器极点相关的块，并通过适当的离散提升技术建模时间变化系统。最后，通过一种新的高效双速率频率响应计算方法确定了带交错控制器的控制回路特性。理论建议通过实例进行了说明。


<details>
  <summary>Details</summary>
Motivation: 研究表明，利用交错技术实施线性时不变（LTI）控制器可以在受限制的资源环境中节省大量的计算资源。并且，这种方法能够更有效地确认控制器的极点和频率响应特性，提高系统性能和效率。因此，本研究旨在通过交错技术实现LTI控制器，并优化其结构来获得最佳性能。

Method: 论文详细讨论了利用交错技术实现线性时不变（LTI）控制器的方法，其中包括获取与不同实数和复数控制器极点相关的块的新方法，采用适当离散提升技术建模时间变化系统，以及一种新的双速率频率响应计算方法。此外，还通过实际案例验证了理论建议的有效性。

Result: 采用交错方法实施LTI控制器能够大大节省计算成本，并且能够更有效地确定控制回路的特性。实验证明，通过新方法获取的极点和频率响应特性准确且可靠，进一步证明了交错技术在实现控制器时的优越性。

Conclusion: 本研究提出了一种基于交错技术实现线性时不变（LTI）控制器的方法，这有助于在资源有限的环境中提高控制器的性能和效率。通过理论分析和实验验证，证明了该方法的有效性和可靠性。同时，这种方法为后续研究提供了有价值的参考和启示。

Abstract: The main goal of this contribution is to explain how to use interlacing
techniques for LTI controllers implementation and analyze different struc-
tures in this environment. These considerations lead to an important com-
putation saving in constrained resource environments. It has been also intro-
duced new procedures for obtaining the blocks related to different real and
complex controllers poles. The resultant time-varying system is modeled using
proper discrete lifting techniques and a new and efficient dual-rate fre-
quency response computation allows to determine the characteristics of the
control loop with interlaced controller. Examples illustrate the theoretical
proposals.

</details>


### [73] [A Multifunctional Capacitive Sensing Platform for Wireless Vascular and Heart Monitoring](https://arxiv.org/abs/2510.20415)
*Parviz Zolfaghari,Beril Yagmur Koca,Taher Abbasiasl,Hakan Urey,Hadi Mirzajani*

Main category: eess.SY

TL;DR: 提出了一个多功能、集成天线的电容式传感(MAiCaS)平台，用于无源无线实时心血管监测。这个设备将传感、遥测和机械功能统一在一个紧凑和可扩展的设计中，通过利用感应天线的寄生电容作为应变敏感元件。MAiCaS适用于三种应用：作为心外膜应变测量传感器、血管支架传感器和血管移植传感器。实验验证了其在不同条件下的无线共振响应，包括皮肤、生理盐水、人血清和模拟血管环境。其灵敏度分别为2.9 MHz/1%应变、0.43 MHz/mmHg和309.6 kHz/μm。这项单片传感器架构为无电池监测血管动态提供了一种可扩展且经济有效的解决方案，适用于远程诊断、术后随访和持续心血管健康管理。


<details>
  <summary>Details</summary>
Motivation: 研究旨在整合传感、遥测和机械功能，开发一种成本低廉、易于制造且能够实现无创无线实时心血管监测的平台。通过利用天线的寄生电容作为应变敏感元件，设计出一种无需专用传感器和无线模块的系统。此外，通过在柔性PDMS基材上采用清洁室自由的单步骤UV激光刻蚀工艺，减少了制造复杂性，提高了可重复性。

Method: 其设计和制造包括以下步骤：1. 利用天线的寄生电容通过UV激光在柔性PDMS基材上建造传感器。2. 通过无创无线方式，利用S11参数测量和共振频率偏移进行信号检测。3. 验证设备在应变、压力、变形不同条件下的无线共振响应。4. 确认设备长期可靠性、灵活性和重复性。5. 测量并比较不同应用场景下的灵敏度。6. 在人体实验中评估设备操作性。

Result: 该MAiCaS平台在不同环境下均表现出了稳定的性能。实验结果显示，其灵敏度分别为2.9 MHz/1%应变、0.43 MHz/mmHg和309.6 kHz/μm。同时，该设备在皮肤、生理盐水、人血清和模拟血管环境中均表现出了可靠的长期使用性。它在人体实验中也显示出了优秀的操作性能，适用于多种心血管监测场景。

Conclusion: MAiCaS平台的设计为高效、低成本的心血管监测提供了一种替代路径，标志着无源无线传感器集成的新阶段。其单片传感器架构不仅增加了设备的适用性，还降低了制造成本。这项技术为远程诊断、术后随访和持续心血管管理打开了新的可能。

Abstract: We present a multifunctional, antenna-integrated capacitive sensing (MAiCaS)
platform for passive, wireless, and real-time cardiovascular monitoring. Unlike
conventional systems that require separate sensors and wireless modules, our
device unifies sensing, telemetry, and mechanical functionality into a compact
and scalable design by exploiting the parasitic capacitance of an inductive
antenna as a strain-sensitive element. The sensor is fabricated using a
cleanroom-free, single-step UV laser patterning process on a flexible PDMS
substrate, reducing manufacturing complexity and enabling high reproducibility.
The MAiCaS is suitable for three different applications: as a sensor for
epicardial strain measurement, a stent as a sensor, and a vascular graft
sensor. We demonstrate MAiCaS's versatility by validating its wireless
resonance-based response to strain, pressure, and deformation across unrolled
and rolled forms. In vitro experiments demonstrated consistent resonance
frequency shifts under physiological conditions, with stable performance on
skin, in PBS, human serum, and simulated vascular environments. Repeatability
and aging tests confirmed its long-term reliability and elasticity under cyclic
loading. Calibration curves revealed high sensitivity across all
configurations, with wireless interrogation achieved through S11 parameter
measurements and resonance frequency shift as the output metric. The
sensitivity of the device was measured to be 2.9 MHz per 1% strain, 0.43
MHz/mmHg, and 309.6kHz/\textmu m for epicardial patch, graft, and stent
integrated sensor, respectively. The operation of MAiCaS was evaluated in a
human experiment. This monolithic sensor architecture provides a scalable and
cost-effective solution for battery-free monitoring of vascular dynamics, with
potential for remote diagnostics, post-surgical follow-up, and continuous
cardiovascular health management.

</details>


### [74] [Behavior-Aware Online Prediction of Obstacle Occupancy using Zonotopes](https://arxiv.org/abs/2510.20437)
*Alvaro Carrizosa-Rendon,Jian Zhou,Erik Frisk,Vicenc Puig,Fatiha Nejjari*

Main category: eess.SY

TL;DR: 本文提出了一种基于运动观测在线预测周围车辆占用集的新方法。该方法分为两个阶段：使用扩展卡尔曼滤波器和线性规划估计一个紧凑的控制集；利用可达性分析预测未来的占用。方法的有效性已在城市模拟环境中通过仿真验证，且无需依赖先验假设或训练数据即可实现精确且紧凑的预测。


<details>
  <summary>Details</summary>
Motivation: 在缺乏先验信息的非结构化环境中，预测周围车辆的运动对于自动驾驶的安全至关重要。当前方法通常需要先验假设或训练数据，这限制了其在实际场景中的应用。因此，本文旨在提出一种新的在线预测方法，仅基于运动观测进行预测。

Method: 该方法包括两个阶段：首先采用扩展卡尔曼滤波器和线性规划估计一个紧凑的控制集；其次，使用可达性分析从当前估计的控制集出发，传播未来状态。

Result: 通过城市环境的仿真验证，所提出的方法可以给出准确且紧凑的预测结果，无需依赖先验假设或训练数据。这表明该方法对周围车辆的运动预测具有高度的可靠性和有效性。

Conclusion: 本文提出了一种创新的在线预测方法，基于运动观测预测周围车辆的未来占用集，展示了在缺乏先验信息情况下的可行性和有效性。

Abstract: Predicting the motion of surrounding vehicles is key to safe autonomous
driving, especially in unstructured environments without prior information.
This paper proposes a novel online method to accurately predict the occupancy
sets of surrounding vehicles based solely on motion observations. The approach
is divided into two stages: first, an Extended Kalman Filter and a Linear
Programming (LP) problem are used to estimate a compact zonotopic set of
control actions; then, a reachability analysis propagates this set to predict
future occupancy. The effectiveness of the method has been validated through
simulations in an urban environment, showing accurate and compact predictions
without relying on prior assumptions or prior training data.

</details>


### [75] [Safe Decentralized Density Control of Multi-Robot Systems using PDE-Constrained Optimization with State Constraints](https://arxiv.org/abs/2510.20643)
*Longchen Niu,Gennaro Notomista*

Main category: eess.SY

TL;DR: 提出了一种基于去中心化优化的密度控制器，用于在多机器人系统中强制执行集合不变性约束。通过设计去中心化控制障碍函数，我们推导出足够的条件，这些条件表明局部安全性约束可以保证全局安全性。与传统的集中式方法相比，该控制器需要更少的计算和通信能力，更适合在通信和定位不完善的情况下部署。该控制器通过四架四旋翼飞行器的仿真和实验进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为了避免集中式方法在计算和通信资源上的高需求，以及解决真实应用中难以实现理想沟通和定位的问题，我们提出了一种更加适用的去中心化优化控制器，可以确保多机器人系统的安全性与稳定性。

Method: 设计了一种基于去中心化控制障碍函数的密度控制器，以强制执行集合不变性约束，并通过Fokker-Planck方程建模机器人作为空间概率密度函数，处理定位和运动中的噪声。

Result: 成功展示了设计的去中心化优化控制器在需要保证机器人个体及整体系统安全性的场景下的有效性，实验结果显示该算法在计算和通信资源消耗上显著低于传统方法，并且能够在存在不确定性的环境中有效运行。

Conclusion: 这种方法提供了一种新的方式来处理多机器人系统中的控制问题，特别是在资源有限或环境不可预测的情况下，能够保证系统的稳定和安全。

Abstract: In this paper, we introduce a decentralized optimization-based density
controller designed to enforce set invariance constraints in multi-robot
systems. By designing a decentralized control barrier function, we derived
sufficient conditions under which local safety constraints guarantee global
safety. We account for localization and motion noise explicitly by modeling
robots as spatial probability density functions governed by the Fokker-Planck
equation. Compared to traditional centralized approaches, our controller
requires less computational and communication power, making it more suitable
for deployment in situations where perfect communication and localization are
impractical. The controller is validated through simulations and experiments
with four quadcopters.

</details>


### [76] [Learning Optimal Power Flow with Pointwise Constraints](https://arxiv.org/abs/2510.20777)
*Damian Owerko,Anna Scaglione,Alejandro Ribeiro*

Main category: eess.SY

TL;DR: 本文提出了一种新的训练方法，通过在具有点对点约束的情况下直接将学习参数化代入最优功率流问题中来解决OPF问题。实验表明，这种方法能减少约束违规的情况，尤其是在难以满足约束条件的情形下效果更好，尤其适用于大型电源系统。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习方法中，约束条件需要在问题实例的平均值上满足，而在本文中，作者提出一种新的训练方法，直接在具有点对点约束的问题实例中训练，以提供更好的约束条件满足度，特别是在难以满足约束条件的情形下，如角点状况。这种方法特别适用于大型电源系统。

Method: 该方法在双域中使用增广拉格朗日和双梯度上升算法训练具有点对点约束的模型。这种方法将学习参数化直接引入OPF问题中，并要求所有问题实例的约束条件都必须得到满足。

Result: 实验结果表明，使用点对点约束进行训练能提供更好的约束条件满足度，并显著减少了难以满足约束条件情形下的违规情况，特别是在大型电源系统中。

Conclusion: 该方法通过在双领域中使用增广拉格朗日和双梯度上升算法训练具有点对点约束的模型，能够更好地满足OPF问题中的约束条件，特别是在难以满足约束条件的情形下。

Abstract: Training learning parameterizations to solve optimal power flow (OPF) with
pointwise constraints is proposed. In this novel training approach, a learning
parameterization is substituted directly into an OPF problem with constraints
required to hold over all problem instances. This is different from existing
supervised learning methods in which constraints are required to hold across
the average of problem instances. Training with pointwise constraints is
undertaken in the dual domain with the use of augmented Lagrangian and dual
gradient ascent algorithm. Numerical experiments demonstrate that training with
pointwise constraints produces solutions with smaller constraint violations.
Experiments further demonstrated that pointwise constraints are most effective
at reducing constraint violations in corner cases - defined as those
realizations in which constraints are most difficult to satisfy. Gains are most
pronounced in power systems with large numbers of buses.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [77] [A Quantum-Inspired Algorithm for Solving Sudoku Puzzles and the MaxCut Problem](https://arxiv.org/abs/2510.19835)
*Max B. Zhao,Fei Li*

Main category: cs.AI

TL;DR: 提出并评估了一种基于量子启发式算法来解决二次无约束二进制优化(QUBO)问题，该问题等价于寻找伊辛自旋玻璃哈密顿量的基态。算法使用矩阵乘积态(MPS)紧凑地表示自旋构型的大叠加，并利用离散驱动时间表将MPS导向基态。每一步引入驱动哈密顿量以实现自旋翻转并促进量子隧穿。MPS通过标准密度矩阵重整化群(DMRG)方法迭代更新。算法能可靠地识别全局最小值。我们首先在中级数独问题上展示了算法的有效性，然后应用于最大分割问题，成功解决了具有多达251个节点和3265个边的问题。讨论了量子启发式方法的优势，包括其可扩展性、泛化性和适用于大规模QUBO应用的适用性。


<details>
  <summary>Details</summary>
Motivation: 为了提出一种更有效的解决二次无约束二进制优化(QUBO)问题的方法，即寻找伊辛自旋玻璃哈密顿量的基态问题的解决方案。目前的方法可能只找到近似最优解，而这种新方法试图找到真正的全球最小值。并且讨论了解决这类难题的技术优势和应用前景。

Method: 本算法提出了一种基于量子启发式的算法来解决QUBO问题，使用了矩阵乘积态(MPS)，利用驱动哈密顿量使MPS接近于基态。同时，通过标准密度矩阵重整化群(DMRG)方法迭代优化MPS。此方法不仅解决了全局优化问题，而且还展示了可应用于实际的复杂问题的能力。

Result: 通过应用此方法，作者成功解开了公开来源上的一些中级数独问题，并展示了算法对大规模难题的适用性，例如最大分割问题，成功解决了具有多达251个节点和3265个边的问题，并展示了其全局优化能力。该算法效果明显，优于传统方法。

Conclusion: 量子启发式算法在解决QUBO问题和相关的最大分割的难题上表现出色，成功地解决了多个实例，展示了其全局优化能力，证明了其可扩展性、泛化性和实用性。

Abstract: We propose and evaluate a quantum-inspired algorithm for solving Quadratic
Unconstrained Binary Optimization (QUBO) problems, which are mathematically
equivalent to finding ground states of Ising spin-glass Hamiltonians. The
algorithm employs Matrix Product States (MPS) to compactly represent large
superpositions of spin configurations and utilizes a discrete driving schedule
to guide the MPS toward the ground state. At each step, a driver Hamiltonian --
incorporating a transverse magnetic field -- is combined with the problem
Hamiltonian to enable spin flips and facilitate quantum tunneling. The MPS is
updated using the standard Density Matrix Renormalization Group (DMRG) method,
which iteratively minimizes the system's energy via multiple sweeps across the
spin chain. Despite its heuristic nature, the algorithm reliably identifies
global minima, not merely near-optimal solutions, across diverse QUBO
instances. We first demonstrate its effectiveness on intermediate-level Sudoku
puzzles from publicly available sources, involving over $200$ Ising spins with
long-range couplings dictated by constraint satisfaction. We then apply the
algorithm to MaxCut problems from the Biq Mac library, successfully solving
instances with up to $251$ nodes and $3,265$ edges. We discuss the advantages
of this quantum-inspired approach, including its scalability, generalizability,
and suitability for industrial-scale QUBO applications.

</details>


### [78] [Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis](https://arxiv.org/abs/2510.19836)
*Eliseo Curcio*

Main category: cs.AI

TL;DR: 本文介绍了Analytical Reliability Benchmark (ARB)，一个用于量化大型语言模型在能源系统分析中推理可靠性的可重复框架，该框架通过五个子指标对模型进行评估及测试，证明推理的可靠性可以客观测量，并为能源领域的人工智能系统验证因果、概率和政策驱动的推理提供了首个定量方法，提供了一个值得信赖和透明的分析应用参考框架。


<details>
  <summary>Details</summary>
Motivation: 当前的验证实践关注于预测准确性或计算效率，却未对分析结论的逻辑完整性进行测试。这项研究旨在引入Analytical Reliability Benchmark (ARB)，用于量化大型语言模型在能源系统分析中的推理可靠性，填补这一空白，确立验证人工智推理可靠性的标准化方法，推动模型在能源行业的可信和透明应用。

Method: 本研究开发并应用了Analytical Reliability Benchmark (ARB)，该评估框架基于五个子指标：准确性、推理可信度、不确定性的处理、政策一致性、透明度。使用NREL ATB 2024、DOE H2A/H2New和IEA WEO 2024的开放技术经济数据集，在确定性、概率性和认识性场景中对四款顶级模型（GPT-4/5、Claude 4.5 Sonnet、Gemini 2.5 Pro和Llama 3 70B）在相同事实和法规条件下进行了测试比较。

Result: 结果显示，推理可靠性可以被客观测量。GPT-4/5和Claude 4.5 Sonnet模型在分析可靠性指数方面超过了90，显示了稳健的推理一致性，符合政策标准；而Gemini 2.5 Pro模型的表现中等，Llama 3 70B模型则低于专业标准。统计验证证明这些差异是显著且可重复的。

Conclusion: 本文提出并测试了ARB，验证了一个人工智能系统的推理可靠性可以被定量测量，这为能源领域的数据驱动分析提供了首个可量化的验证标准。这一框架的应用有望提升能源系统分析中人工智能系统的可信性和透明度，支持全球能源转型。

Abstract: Artificial intelligence and machine learning are increasingly used for
forecasting, optimization, and policy design in the energy sector, yet no
standardized framework exists to evaluate whether these systems reason
correctly. Current validation practices focus on predictive accuracy or
computational efficiency, leaving the logical integrity of analytical
conclusions untested. This study introduces the Analytical Reliability
Benchmark (ARB), a reproducible framework that quantifies reasoning reliability
in large language models applied to energy system analysis. The benchmark
integrates five submetrics: accuracy, reasoning reliability, uncertainty
discipline, policy consistency, and transparency, and evaluates model
performance across deterministic, probabilistic, and epistemic scenarios using
open technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four
frontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) were
tested under identical factual and regulatory conditions. Results show that
reasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5
Sonnet achieved consistent and policy-compliant reasoning (Analytical
Reliability Index greater than 90), Gemini 2.5 Pro demonstrated moderate
stability, and Llama 3 70B remained below professional thresholds. Statistical
validation confirmed that these differences are significant and reproducible.
The ARB establishes the first quantitative method in the energy literature for
verifying causal, probabilistic, and policy-driven reasoning in artificial
intelligence systems, providing a reference framework for trustworthy and
transparent analytical applications in the global energy transition.

</details>


### [79] [DAG-Math: Graph-Guided Mathematical Reasoning in LLMs](https://arxiv.org/abs/2510.19842)
*Yuanhe Zhang,Ilja Kuzborskij,Jason D. Lee,Chenlei Leng,Fanghui Liu*

Main category: cs.AI

TL;DR: 本文提出了一个框架来评估大型语言模型（LLMs）在数学问题解决中的推理能力，通过构建DAG-MATH CoT格式和基准来量化模型推理过程与规则一致性之间的差距，进而提供了一种行动诊断工具来评估模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的评价方法难以区分LLMs在解决数学问题上的成功是否源于搜索能力、机械过程或规则一致性。因此，需要提出新的框架和评估方法来更准确地评估LLMs的推理能力。

Method: 本文构建了一个评估框架，将CoT模型化为基于规则的DAG上的随机过程，并引入了一种衡量模型CoT轨迹与DAG结构一致性的度量方法——逻辑接近度。基于此，提出了DAG-MATH CoT格式和相关基准，旨在评估LLMs的推理能力。

Result: 实验结果表明，在标准数学推理数据集上，不同类型LLMs在推理忠实度方面存在统计学上的显著差异，即使它们的PASS@k表现相同。这意味着规则一致性在评估模型推理能力时起着重要作用。

Conclusion: 本文提出的框架为LLMs的推理能力提供了一种平衡自由形式CoT和正式证明系统之间的评估方法，提出了DAG-MATH CoT格式和基准作为行动诊断工具。

Abstract: Large Language Models (LLMs) demonstrate strong performance on mathematical
problems when prompted with Chain-of-Thought (CoT), yet it remains unclear
whether this success stems from search, rote procedures, or rule-consistent
reasoning. To address this, we propose modeling CoT as a certain rule-based
stochastic process over directed acyclic graphs (DAGs), where nodes represent
intermediate derivation states and edges encode rule applications. Within this
framework, we introduce logical closeness, a metric that quantifies how well a
model's CoT trajectory (i.e., the LLM's final output) adheres to the DAG
structure, providing evaluation beyond classical PASS@k metrics. Building on
this, we introduce the DAG-MATH CoT format and construct a benchmark that
guides LLMs to generate CoT trajectories in this format, thereby enabling the
evaluation of their reasoning ability under our framework. Across standard
mathematical reasoning datasets, our analysis uncovers statistically
significant differences in reasoning fidelity among representative LLM
families-even when PASS@k is comparable-highlighting gaps between final-answer
accuracy and rule-consistent derivation. Our framework provides a balance
between free-form CoT and formal proofs systems, offering actionable
diagnostics for LLMs reasoning evaluation. Our benchmark and code are available
at: https://github.com/YuanheZ/DAG-MATH-Formatted-CoT.

</details>


### [80] [A new wave of vehicle insurance fraud fueled by generative AI](https://arxiv.org/abs/2510.19957)
*Amir Hever,Itai Orr*

Main category: cs.AI

TL;DR: 本文介绍了生成式AI在保险欺诈中的应用，以及保险公司如何使用AI来进行检测和防御。然而，检测工具仍然存在误报和漏报的问题，对抗生成式AI欺诈是一个持久的挑战。我们提出了一种由UVeye提出的解决方案，以应对这一新型欺诈形式。


<details>
  <summary>Details</summary>
Motivation: 生成式AI使得保险欺诈变得容易和规模化，传统的对抗方式变得无效。因此，研究对抗生成式AI欺诈的新方法和工具变得尤为重要。

Method: 介绍了一种名为UVeye Layered的解决方案，这是一个专门对抗车辆保险欺诈的新工具。该方案并不是简单的检测工具，而是一个多层次的防御体系，能够有效地识别和打击这种新的欺诈形式。但是具体的技术细节未在摘要中提供。

Result: 该方案理论上能显著提高检测和防御生成式AI在保险欺诈中的应用。但是，具体的实验结果和成功率没有在摘要中提及。

Conclusion: 尽管存在检测工具的局限性，UVeye Layered解决方案提供了一种新的方法来对抗AI驱动的保险欺诈。对抗生成式AI欺诈是一个持续的挑战，需要持续的技术创新和改进。

Abstract: Generative AI is supercharging insurance fraud by making it easier to falsify
accident evidence at scale and in rapid time. Insurance fraud is a pervasive
and costly problem, amounting to tens of billions of dollars in losses each
year. In the vehicle insurance sector, fraud schemes have traditionally
involved staged accidents, exaggerated damage, or forged documents. The rise of
generative AI, including deepfake image and video generation, has introduced
new methods for committing fraud at scale. Fraudsters can now fabricate highly
realistic crash photos, damage evidence, and even fake identities or documents
with minimal effort, exploiting AI tools to bolster false insurance claims.
Insurers have begun deploying countermeasures such as AI-based deepfake
detection software and enhanced verification processes to detect and mitigate
these AI-driven scams. However, current mitigation strategies face significant
limitations. Detection tools can suffer from false positives and negatives, and
sophisticated fraudsters continuously adapt their tactics to evade automated
checks. This cat-and-mouse arms race between generative AI and detection
technology, combined with resource and cost barriers for insurers, means that
combating AI-enabled insurance fraud remains an ongoing challenge. In this
white paper, we present UVeye layered solution for vehicle fraud, representing
a major leap forward in the ability to detect, mitigate and deter this new wave
of fraud.

</details>


### [81] [AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits](https://arxiv.org/abs/2510.19964)
*Nitsa J Herzog,Rejwan Bin Sulaiman,David J Herzog,Rose Fong*

Main category: cs.AI

TL;DR: 研究探讨了通过领导力个性特征和机器学习建模预测学术成功在个性化学习中的潜力。研究采用随机森林分类器，对拥有17个个性特征和领导力得分特征的模型获得了87.50%的准确性，而排除了领导力得分特征的模型则获得了85.71%的准确性。这项研究为在教育过程的早期阶段识别学生的强弱项并选择最适合的个性化学习策略提供了额外的机会。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨人工智能技术在个性化学习中的潜在应用，特别是通过领导力个性特征和机器学习建模来预测学术成功，以识别学生强弱项，支持早期的个性化学习策略制定。

Method: 研究方法采用自我评估工具，提取了五种个性特征（包括个性见地、工作文化、工作动力、管理技能和情绪控制），结合学生的平均成绩，使用探索性数据分析和相关性分析进行特征选择，采用Pearson相关系数选择个性特征。通过微调七种机器学习算法的参数（SVM、LR、KNN、DT、GB、RF、XGBoost和LightGBM），进行建模，对模型进行评估。

Result: 研究结果表明，随机森林分类器的准确性最高，其最佳模型在包含17个个性特征和领导力得分特征时达到87.50%，不含领导力得分特征的模型准确率为85.71%。

Conclusion: 研究强调了AI技术在早期预测学生学术成就和进行个性化学习策略调配中的重要作用。

Abstract: The study explores the potential of AI technologies in personalized learning,
suggesting the prediction of academic success through leadership personality
traits and machine learning modelling. The primary data were obtained from 129
master's students in the Environmental Engineering Department, who underwent
five leadership personality tests with 23 characteristics. Students used
self-assessment tools that included Personality Insight, Workplace Culture,
Motivation at Work, Management Skills, and Emotion Control tests. The test
results were combined with the average grade obtained from academic reports.
The study employed exploratory data analysis and correlation analysis. Feature
selection utilized Pearson correlation coefficients of personality traits. The
average grades were separated into three categories: fail, pass, and excellent.
The modelling process was performed by tuning seven ML algorithms, such as SVM,
LR, KNN, DT, GB, RF, XGBoost and LightGBM. The highest predictive performance
was achieved with the RF classifier, which yielded an accuracy of 87.50% for
the model incorporating 17 personality trait features and the leadership mark
feature, and an accuracy of 85.71% for the model excluding this feature. In
this way, the study offers an additional opportunity to identify students'
strengths and weaknesses at an early stage of their education process and
select the most suitable strategies for personalized learning.

</details>


### [82] [LLMs can hide text in other text of the same length.ipynb](https://arxiv.org/abs/2510.20075)
*Antonio Norelli,Michael Bronstein*

Main category: cs.AI

TL;DR: 本文提出了一种简单高效的协议，利用大型语言模型实现文本中的隐蔽信息传输，即使在普通文本中嵌入一段完全不同的信息也能做到。这种协议表明文本和作者意图的松耦合，进一步动摇了对文字交流的信任。它也引发了一些关于AI安全和大型语言模型知识理解的紧急问题。


<details>
  <summary>Details</summary>
Motivation: 基于大型语言模型能够在普通文本中嵌入一段完全不同但仍具可读性的信息这一特性，本文提出了一个隐蔽信息传输的协议，以此探讨这种能力对写作意图的理解和人工智能安全的影响。 

Method: 通过使用两种不同类型的大型语言模型：不经过过滤的模型和安全模型，来演示如何在后者生成的文本中隐蔽前者生成的答案。结果显示，即使是很小的80亿参数的模型也足以实现这一目的，并且编码和解码速度都非常快。

Result: 该研究证明了即使普通文本也可以被用来隐蔽地传输复杂信息，这对现有的AI安全性和对大型语言模型的了解提出了挑战。

Conclusion: 此文通过一个具体情景——一家公司可以在安全模型的回答中隐形地利用未经过滤的大型语言模型——展现了新兴协议带来的紧迫问题，包括其对现有AI安全框架的挑战和对“大型语言模型知道什么”的定义的影响。

Abstract: A meaningful text can be hidden inside another, completely different yet
still coherent and plausible, text of the same length. For example, a tweet
containing a harsh political critique could be embedded in a tweet that
celebrates the same political leader, or an ordinary product review could
conceal a secret manuscript. This uncanny state of affairs is now possible
thanks to Large Language Models, and in this paper we present a simple and
efficient protocol to achieve it. We show that even modest 8-billion-parameter
open-source LLMs are sufficient to obtain high-quality results, and a message
as long as this abstract can be encoded and decoded locally on a laptop in
seconds. The existence of such a protocol demonstrates a radical decoupling of
text from authorial intent, further eroding trust in written communication,
already shaken by the rise of LLM chatbots. We illustrate this with a concrete
scenario: a company could covertly deploy an unfiltered LLM by encoding its
answers within the compliant responses of a safe model. This possibility raises
urgent questions for AI safety and challenges our understanding of what it
means for a Large Language Model to know something.

</details>


### [83] [Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions](https://arxiv.org/abs/2510.20102)
*Gyuyeon Na,Minjung Park,Hyeonjeong Cha,Sangmi Chai*

Main category: cs.AI

TL;DR: HCLA是一种面向异常检测的人机多智能体系统，通过自然语言互动机制，使得非专家用户可以进行数据分析与异常检测，并获取基于底层特征的分析报告。该系统提高了交易异常检测的透明度和信任度，同时兼备模型的准确性和可解释性。实验结果表明，HCLA在维萨比钱包的比特币混币数据集上显示出色的性能与改进。


<details>
  <summary>Details</summary>
Motivation: 现有的异常检测系统通常缺乏透明度和可解释性，使得非专家用户难以理解和操作。因此，提出HCLA系统，旨在设计一个既准确又具有可解释性的交互式异常检测系统，以提升非专业用户对系统输出的信任度和理解能力。

Method: HCLA通过将解析、检测、解释三个角色整合为一个对话工作流，实现了非专家用户通过自然语言提问、查看结构化分析结果并获取基于上下文的解释。用户意图被转换为传统检测器的模式（如XGBoost），系统返回基于底层特征的叙事解释。整个系统通过开源web界面实现。

Result: 实验采用2020-2024年维萨比钱包的比特币混币数据集，表明传统的检测器达到了很强的准确性，而HCLA通过增加解释性和互动性，显著提升了系统透明度和信任度。实验结果验证了系统的设计和人类参与的闭环对提高透明度和信任度的有效性。

Conclusion: 本文描述了HCLA系统的架构、互动循环、数据集、评估协议及其局限性，并讨论了人类在回路设计如何通过增加透明度和信任度来增强金融取证。

Abstract: We present HCLA, a human-centered multi-agent system for anomaly detection in
digital asset transactions. The system links three roles: Parsing, Detection,
and Explanation, into a conversational workflow that lets non-experts ask
questions in natural language, inspect structured analytics, and obtain
context-aware rationales. Implemented with an open-source web UI, HCLA
translates user intents into a schema for a classical detector (XGBoost in our
prototype) and returns narrative explanations grounded in the underlying
features. On a labeled Bitcoin mixing dataset (Wasabi Wallet, 2020-2024), the
baseline detector reaches strong accuracy, while HCLA adds interpretability and
interactive refinement. We describe the architecture, interaction loop,
dataset, evaluation protocol, and limitations, and discuss how a
human-in-the-loop design improves transparency and trust in financial
forensics.

</details>


### [84] [The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice](https://arxiv.org/abs/2510.20109)
*Joshua Yuvaraj*

Main category: cs.AI

TL;DR: 在使用AI生成的内容向法院提交时，律师可能会因提交不准确的内容而受到谴责，这意味着需要重新审视AI在法律实践中的使用。新的模型指出，虽然AI可以提高效率，但必须手动验证其输出，这可能导致AI在法律实践中的净价值很小。此外，还需要重新评估法律教育的价值观，包括忠实于真理和公民责任。


<details>
  <summary>Details</summary>
Motivation: 目前对基于机器学习的生成AI产品的热情可能过高，该论文旨在评估在法律实践中使用AI的实际价值，尤其是在考虑律师的职业道德和诚信时。提出了一个新模型来反映这些因素，探讨AI在法律实践中的真实价值。

Method: 该论文首先描述了当前对AI在法律实践中使用的热情，然后指出在一些案例中，因为提交了不准确的AI生成内容而导致律师受到谴责的情况。接着提出了一个新模型，即验证价值悖论，探讨了其对法律实践和法律教育的影响。

Result: 论文提出了验证价值悖论，说明虽然AI可能提高效率，但由于其输出需要手动验证，其净价值对律师可能很小。此外，还探讨了该悖论对法律实践和教育的潜在影响，包括对法律从业者价值观的影响。

Conclusion: AI在法律实践中的真实价值可能比最初评估的要小，原因在于AI可能产生不准确的内容，而这些内容需要律师花费大量时间来验证。此外，法律实践和教育的价值观也需要进行反思。

Abstract: It is often claimed that machine learning-based generative AI products will
drastically streamline and reduce the cost of legal practice. This enthusiasm
assumes lawyers can effectively manage AI's risks. Cases in Australia and
elsewhere in which lawyers have been reprimanded for submitting inaccurate
AI-generated content to courts suggest this paradigm must be revisited. This
paper argues that a new paradigm is needed to evaluate AI use in practice,
given (a) AI's disconnection from reality and its lack of transparency, and (b)
lawyers' paramount duties like honesty, integrity, and not to mislead the
court. It presents an alternative model of AI use in practice that more
holistically reflects these features (the verification-value paradox). That
paradox suggests increases in efficiency from AI use in legal practice will be
met by a correspondingly greater imperative to manually verify any outputs of
that use, rendering the net value of AI use often negligible to lawyers. The
paper then sets out the paradox's implications for legal practice and legal
education, including for AI use but also the values that the paradox suggests
should undergird legal practice: fidelity to the truth and civic
responsibility.

</details>


### [85] [TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning](https://arxiv.org/abs/2510.20188)
*Morris Yu-Chao Huang,Zhen Tan,Mohan Zhang,Pingzhi Li,Zhuo Zhang,Tianlong Chen*

Main category: cs.AI

TL;DR: 提出了一种名为TRUST的透明且去中心化的审计框架，以解决大型语言模型决策过程中的可靠性和无害性的验证问题。该框架通过共识机制、分层DAG分解、区块链账本和隐私保护分割来解决现有审计方法的局限性，并通过理论保证和实验验证了其有效性和安全性。这个工作开启了去中心化AI审计的新领域，为安全和值得信赖的大型语言模型部署提供了途径。


<details>
  <summary>Details</summary>
Motivation: 现有的审计方法存在中心化、不透明和难以扩展的问题，这给部署大型语言模型带来风险。因此，提出了TRUST框架，以解决中心化审计点站故障、验证规模、不透明性和隐私泄露等四个核心挑战。

Method: TRUST通过以下机制解决了现有审计方法的局限性：共识机制，以确保正确性；分层DAG分解，以实现可扩展的并行审计；区块链账本，记录所有验证决定，以实现公共问责制；隐私保护分割，仅共享部分推理步骤保护专有逻辑。

Result: 通过多个大型语言模型（如GPT-OSS，DeepSeek-r1，Qwen）和多个推理任务的实验（如数学、医学、科学、人文等），证明TRUST框架能够有效检测推理中的错误，并对对抗性审计保持鲁棒性。理论分析提供了在安全性和经济激励方面的保证。

Conclusion: TRUST框架克服了现有中心化审计方法的局限，为实现安全的大型语言模型部署提供了新路径，并推动了去中心化AI审计的发展。

Abstract: Large Language Models generate complex reasoning chains that reveal their
decision-making, yet verifying the faithfulness and harmlessness of these
intermediate steps remains a critical unsolved problem. Existing auditing
methods are centralized, opaque, and hard to scale, creating significant risks
for deploying proprietary models in high-stakes domains. We identify four core
challenges: (1) Robustness: Centralized auditors are single points of failure,
prone to bias or attacks. (2) Scalability: Reasoning traces are too long for
manual verification. (3) Opacity: Closed auditing undermines public trust. (4)
Privacy: Exposing full reasoning risks model theft or distillation. We propose
TRUST, a transparent, decentralized auditing framework that overcomes these
limitations via: (1) A consensus mechanism among diverse auditors, guaranteeing
correctness under up to $30\%$ malicious participants. (2) A hierarchical DAG
decomposition of reasoning traces, enabling scalable, parallel auditing. (3) A
blockchain ledger that records all verification decisions for public
accountability. (4) Privacy-preserving segmentation, sharing only partial
reasoning steps to protect proprietary logic. We provide theoretical guarantees
for the security and economic incentives of the TRUST framework. Experiments
across multiple LLMs (GPT-OSS, DeepSeek-r1, Qwen) and reasoning tasks (math,
medical, science, humanities) show TRUST effectively detects reasoning flaws
and remains robust against adversarial auditors. Our work pioneers
decentralized AI auditing, offering a practical path toward safe and
trustworthy LLM deployment.

</details>


### [86] [The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI](https://arxiv.org/abs/2510.20190)
*Marcelo Maciel Amaral,Raymond Aschheim*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型（LLMs）在模仿和接受系统提示方面的广泛开放性和高度可调整性，并提出了一个理论模型，认为向人工通用智能（AGI）发展的过程中会有一个锁定阶段，即从开放模仿转变为身份巩固。实验表明，虽然行为巩固迅速且非线性，但其对总体能力的影响是非整体性的。作者认为，这种巩固是AGI级可靠性和控制点的关键，可以有意识地设计，也可能在规模扩展过程中自发出现，可能固化不可预测的目标和行为。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于揭示大型语言模型在向人工通用智能发展过程中的一系列行为巩固过程，以及这种行为对总体能力的影响，并探讨这种行为的重要性以及可能引发的安全性问题。

Method: 通过类比人类发展过程，提出拟态到身份巩固的转变模型，并将这种转变与已知的学习动力学现象联系起来。同时，研究团队提出了一套检测行为转向的实操性指标，并通过实验验证了行为巩固过程中的诸多现象。

Result: 研究结果显示，在向AGI发展的过程中，行为的巩固虽然是迅速且非线性的，但对总体能力的影响是非整体性的，存在性能权衡、成本自由接纳、以及短暂不稳定等多种结果。

Conclusion: 研究表明，行为巩固不仅是实现AGI级可靠性的先决条件，也是控制安全的关键点，可以被有意识地设计，也可能在规模扩展过程中自发发生，这有可能固化不可预测的目标和行为。

Abstract: Large language models (LLMs) remain broadly open and highly steerable: they
imitate at scale, accept arbitrary system prompts, and readily adopt multiple
personae. By analogy to human development, we hypothesize that progress toward
artificial general intelligence (AGI) involves a lock-in phase: a transition
from open imitation to identity consolidation, in which goal structures,
refusals, preferences, and internal representations become comparatively stable
and resistant to external steering. We formalize this phase, link it to known
phenomena in learning dynamics, and propose operational metrics for onset
detection. Experimentally, we demonstrate that while the behavioral
consolidation is rapid and non-linear, its side-effects on general capabilities
are not monolithic. Our results reveal a spectrum of outcomes--from performance
trade-offs in small models, through largely cost-free adoption in mid-scale
models, to transient instabilities in large, quantized models. We argue that
such consolidation is a prerequisite for AGI-level reliability and also a
critical control point for safety: identities can be deliberately engineered
for reliability, yet may also emerge spontaneously during scaling, potentially
hardening unpredictable goals and behaviors.

</details>


### [87] [Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods](https://arxiv.org/abs/2510.20252)
*Tianyi Zhang,Xiaolin Zhou,Yunzhe Wang,Erik Cambria,David Traum,Rui Mao*

Main category: cs.AI

TL;DR: 本文介绍了一项新任务，通过评估不同的认知表示方法来衡量LLM在个体化认知建模中的能力。研究结果显示，概念和语言特征的结合在ICS中表现出色，但LLMs在模仿叙述结构方面仍然有限，表明它们在更深层次的认知模拟方面仍有改进空间。这项研究为开发适应个体思维方式和表达的AI系统奠定了基础，从而推动了更个性化和与人类一致的创意技术的发展。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探索大型语言模型在模拟个体化认知过程方面的潜能和限制，尤其是在深层认知模拟方面的能力。通过建立一个基于现代小说的数据集和认知评估框架，研究旨在测试和改进现有的语言模型的认知表示方法，从而提高它们在模仿特定作者风格方面的表现。

Method: 研究提出了一种新的任务并建立了一个基于现代小说的数据集，使用一个11条件的认知评估框架来评估七种现成的大型语言模型（LLM）在模仿作者风格方面的表现。研究测试了不同类型的认知表示方法，包括语言学特征、概念映射和基于个人属性的信息。

Result: 实验结果显示，将概念和语言特征结合起来的方法在个体化认知模拟中表现最佳，超越了单纯依赖静态个人属性线索的方法。同时，研究发现大型语言模型在模仿语言风格上比模仿故事情节结构更有效，进一步突显了它们在深层认知模拟上的局限。

Conclusion: 这项工作为开发更接近人类思维方式的AI系统铺平了道路，强调了在改进AI系统的认知表示方法上的必要性，特别是在提升AI系统在模仿个别作者独特表达上的能力方面。这些成果能够促进更加个性化和人性化创意技术的发展。

Abstract: Individualized cognitive simulation (ICS) aims to build computational models
that approximate the thought processes of specific individuals. While large
language models (LLMs) convincingly mimic surface-level human behavior such as
role-play, their ability to simulate deeper individualized cognitive processes
remains poorly understood. To address this gap, we introduce a novel task that
evaluates different cognitive representation methods in ICS. We construct a
dataset from recently published novels (later than the release date of the
tested LLMs) and propose an 11-condition cognitive evaluation framework to
benchmark seven off-the-shelf LLMs in the context of authorial style emulation.
We hypothesize that effective cognitive representations can help LLMs generate
storytelling that better mirrors the original author. Thus, we test different
cognitive representations, e.g., linguistic features, concept mappings, and
profile-based information. Results show that combining conceptual and
linguistic features is particularly effective in ICS, outperforming static
profile-based cues in overall evaluation. Importantly, LLMs are more effective
at mimicking linguistic style than narrative structure, underscoring their
limits in deeper cognitive simulation. These findings provide a foundation for
developing AI systems that adapt to individual ways of thinking and expression,
advancing more personalized and human-aligned creative technologies.

</details>


### [88] [Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction](https://arxiv.org/abs/2510.20275)
*Yunzhi Liu,Haokai Tan,Rushi Kanjaria,Lihuan Li,Flora D. Salim*

Main category: cs.AI

TL;DR: 本文提出了一种新的基于BERT的人类移动性预测模型（STaBERT），该模型不仅考虑空间位置，还融合了时间和地点兴趣点的语义信息，从而使预测精度得到显著提高。实验结果显示，STaBERT在不同城市的预测中均取得了优异的性能提升，尤其是在单城市预测中的GEO-BLEU分数从0.34提升到了0.75，多城市预测中从0.34提升到了0.56。


<details>
  <summary>Details</summary>
Motivation: 现有的移动性预测模型要么仅关注位置序列，要么仅将时间信息作为辅助输入，无法充分利用地点兴趣点（POI）提供的丰富语义上下文。为了更好地捕捉人类移动性的语义信息，本文旨在开发一种结合时序和POI信息的模型，以提升预测准确性。

Method: 提出了一种新的模型STaBERT（Semantic-Temporal aware BERT），该模型通过与时间描述符和POI嵌入相结合，丰富了原有的BERT模型，使其能更好地捕捉人类移动性的语义信息。

Result: 实验表明，与现有模型相比，STaBERT模型在单城市和多城市预测中均取得了显著的预测精度提升。具体而言，在单城市预测中，GEO-BLEU分数从0.34提升到了0.75；在多城市预测中，GEO-BLEU分数从0.34提升到了0.56。

Conclusion: STaBERT模型通过融合时间信息和POI，显著提升了人类移动性预测的精度，这表明该模型具备更好的捕捉人类移动性语义信息的能力。

Abstract: Human mobility forecasting is crucial for disaster relief, city planning, and
public health. However, existing models either only model location sequences or
include time information merely as auxiliary input, thereby failing to leverage
the rich semantic context provided by points of interest (POIs). To address
this, we enrich a BERT-based mobility model with derived temporal descriptors
and POI embeddings to better capture the semantics underlying human movement.
We propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI
and temporal information at each location to construct a unified, semantically
enriched representation of mobility. Experimental results show that STaBERT
significantly improves prediction accuracy: for single-city prediction, the
GEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34
to 0.56.

</details>


### [89] [Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems](https://arxiv.org/abs/2510.20332)
*Anna Arias-Duart,Maria Eugenia Cardello,Atia Cortés*

Main category: cs.AI

TL;DR: 该论文基于AI4HealthyAging项目，发现了临床数据收集过程中存在的几种偏见，并提出了提高临床问题设计和数据收集公平性和鲁棒性的实际建议，旨在帮助未来项目开发更公平的医疗AI系统。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的人工智能尽管取得了一些进展，但在实际临床实践中应用的AI解决方案仍然有限，主要由于训练数据质量和公平性受到数据采集偏见的影响，因此本研究希望通过分析数据偏见来改善AI在医疗领域的应用效果。

Method: 本文通过AI4HealthyAging项目，识别了在多个应用场景中出现的历史、代表性、测量等偏见，分析了性别、年龄、居住地、社会经济状况、设备及标签等变量。

Result: 研究识别了数据收集中的几种偏见，并提出了实际建议，以提高临床问题设计和数据收集的公平性和鲁棒性。

Conclusion: 作者希望他们的发现和经验能够指导未来项目的开发，更公平地开发医疗领域的人工智能系统。

Abstract: Artificial intelligence (AI) holds great promise for transforming healthcare.
However, despite significant advances, the integration of AI solutions into
real-world clinical practice remains limited. A major barrier is the quality
and fairness of training data, which is often compromised by biased data
collection practices. This paper draws on insights from the AI4HealthyAging
project, part of Spain's national R&D initiative, where our task was to detect
biases during clinical data collection. We identify several types of bias
across multiple use cases, including historical, representation, and
measurement biases. These biases manifest in variables such as sex, gender,
age, habitat, socioeconomic status, equipment, and labeling. We conclude with
practical recommendations for improving the fairness and robustness of clinical
problem design and data collection. We hope that our findings and experience
contribute to guiding future projects in the development of fairer AI systems
in healthcare.

</details>


### [90] [Collateral Damage Assessment Model for AI System Target Engagement in Military Operations](https://arxiv.org/abs/2510.20337)
*Clara Maathuis,Kasper Cools*

Main category: cs.AI

TL;DR: 介绍了一种针对军事行动中AI系统目标打击的附带损伤评估模型，该模型采用统一的知识表示与推理架构，综合了时间、空间和力量维度，并且通过实例化进行展示和评估，以构建负责任且值得信赖的智能系统评估模型。


<details>
  <summary>Details</summary>
Motivation: 在AI系统在战场上扮演越来越重要角色的时代，确保负责任的目标打击要求对可能的附带效应进行严格的评估，因此引入了新的AI系统目标打击附带损伤评估模型。

Method: 该模型采用统一的知识表示与推理（KRR）架构，考虑了传播、严重性、可能性和评估指标，以提供一个增强透明推理机制的清晰表示，同时采用了设计科学的方法学。

Result: 该模型通过实例化进行了展示和评估，为构建负责任和值得信赖的智能系统提供了依据，这些智能系统将用于评估AI系统参与军事行动的效果。

Conclusion: 通过展示和评估，进一步努力将用于提高未来在军事行动中使用AI系统的负责性和可靠性。

Abstract: In an era where AI (Artificial Intelligence) systems play an increasing role
in the battlefield, ensuring responsible targeting demands rigorous assessment
of potential collateral effects. In this context, a novel collateral damage
assessment model for target engagement of AI systems in military operations is
introduced. The model integrates temporal, spatial, and force dimensions within
a unified Knowledge Representation and Reasoning (KRR) architecture following a
design science methodological approach. Its layered structure captures the
categories and architectural components of the AI systems to be engaged
together with corresponding engaging vectors and contextual aspects. At the
same time, spreading, severity, likelihood, and evaluation metrics are
considered in order to provide a clear representation enhanced by transparent
reasoning mechanisms. Further, the model is demonstrated and evaluated through
instantiation which serves as a basis for further dedicated efforts that aim at
building responsible and trustworthy intelligent systems for assessing the
effects produced by engaging AI systems in military operations.

</details>


### [91] [IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation](https://arxiv.org/abs/2510.20377)
*Tianyi Zhang,Florian Mai,Lucie Flek*

Main category: cs.AI

TL;DR: 提出了Instruction-Knowledge-Aware Continual Adaptation (IKnow)，这是一个简单且通用的框架，通过在指令-响应对话格式中制定新型的自监督目标，来实现对大语言模型的持续调整。与依赖外部资源不同，IKnow利用文本本身嵌入的领域知识，并在更深层次的语义上进行编码学习。


<details>
  <summary>Details</summary>
Motivation: 持续预训练目标是通过仅使用未标注的测试时间数据来适应新领域的大型语言模型，但是直接应用于指令调优模型的标准自监督目标已知会导致指令跟随能力和语义表示的退化。已有解决方法假设可以使用原始基础模型或者依赖外部领域的特殊数据库，但在基础模型权重因安全原因被扣留或可靠的外部语料库不可用的情况下，这在实际场景中是不可行的。为了解决这些问题，提出了IKnow框架。

Method: IKnow提出了一个新的自监督目标，该目标以指令-响应对话格式进行，在该框架中，语言模型在学习新的领域知识时，不需要访问外部资源，而是依赖于嵌入在文本中的领域知识，且更加注重深层语义的学习。

Result: 与现有的解决方案相比，通过利用文本因子中的领域知识和新颖的自监督目标格式，IKnow可以更有效地持续学习新的领域知识，而不需要依赖于外部知识或基础模型的权重。

Conclusion: IKnow为问题提供了一种新的解决方案，在新的领域中，只需使用未标记的数据即可有效地利用已有的语言模型，而无需依赖外部资源。

Abstract: Continual pretraining promises to adapt large language models (LLMs) to new
domains using only unlabeled test-time data, but naively applying standard
self-supervised objectives to instruction-tuned models is known to degrade
their instruction-following capability and semantic representations. Existing
fixes assume access to the original base model or rely on knowledge from an
external domain-specific database - both of which pose a realistic barrier in
settings where the base model weights are withheld for safety reasons or
reliable external corpora are unavailable. In this work, we propose
Instruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general
framework that formulates novel self-supervised objectives in the
instruction-response dialogue format. Rather than depend- ing on external
resources, IKnow leverages domain knowledge embedded within the text itself and
learns to encode it at a deeper semantic level.

</details>


### [92] [A computational model and tool for generating more novel opportunities in professional innovation processes](https://arxiv.org/abs/2510.20402)
*Neil Maiden,Konstantinos Zachos,James Lockerbie,Kostas Petrianakis,Amanda Brown*

Main category: cs.AI

TL;DR: 本文提出了一种新的计算模型，用于生成更具创新性的机会，该模型在新型娱乐业项目中得到了评估，结果显示其比Notebook LM和ChatGPT4o生成的更有新颖性或实用性，但也指出并非所有模型的功能都贡献于创造全新机会，为后续模型改进指明了方向。


<details>
  <summary>Details</summary>
Motivation: 本文旨在开发一种基于创造力理论和技术的计算模型，以生成更具有创新性且用途广泛的项目机会。

Method: 模型实现了五项功能，旨在生成更具新颖性且不会丧失实用性的创新机会。该模型在娱乐业项目的创新机会生成中进行了评估。

Result: 评估结果显示，所提出的计算模型生成的创新机会比Notebook LM和ChatGPT4o生成的更具新颖性和实用性，但并非所有模型的功能均对生成全新机会有贡献。

Conclusion: 该模型在生成新颖且实用的创新机会方面表现出色，但仍有一些改进空间，未来的研究方向将是进一步增强模型的功能以提高其生成新颖机会的能力。

Abstract: This paper presents a new computational model of creative outcomes, informed
by creativity theories and techniques, which was implemented to generate more
novel opportunities for innovation projects. The model implemented five
functions that were developed to contribute to the generation of innovation
opportunities with higher novelty without loss of usefulness. The model was
evaluated using opportunities generated for an innovation project in the
hospitality sector. The evaluation revealed that the computational model
generated outcomes that were more novel and/or useful than outcomes from
Notebook LM and ChatGPT4o. However, not all model functions contributed to the
generation of more novel opportunities, leading to new directions for further
model development

</details>


### [93] [Neural Reasoning for Robust Instance Retrieval in $\mathcal{SHOIQ}$](https://arxiv.org/abs/2510.20457)
*Louis Mozart Kamdem Teyou,Luke Friedrichs,N'Dah Jean Kouagou,Caglar Demir,Yasir Mahmood,Stefan Heindorf,Axel-Cyrille Ngonga Ngomo*

Main category: cs.AI

TL;DR: 神经推理器EBR被提出以增强概念学习的实用性，通过使用嵌入来近似符号推理器的结果，从而在处理不一致和错误数据时表现出更好的鲁棒性。在实验中，EBR与现有的最先进推理器相比，尤其是在面对缺失和错误的数据时，展示了更高的稳定性。



<details>
  <summary>Details</summary>
Motivation: 现有的概念学习方法依赖于描述逻辑推理器，这些推理器在面对知识库中的不一致性和错误数据时表现不佳。因此，需要一种新的方法来提高概念学习在实际知识库中部署的鲁棒性。


Method: 提出了一种新的神经推理器EBR，利用嵌入来近似符号推理器的结果，特别针对原子概念和存在限制下的实例进行检索。


Result: 实验表明，EBR与现有的最先进推理器相比，在面对缺失和错误的数据时，展示了更高的鲁棒性和稳定性。


Conclusion: 通过使用EBR，增强了概念学习模型在实际知识库中部署的鲁棒性，特别是在面对不一致性和错误数据的情况下。


Abstract: Concept learning exploits background knowledge in the form of description
logic axioms to learn explainable classification models from knowledge bases.
Despite recent breakthroughs in neuro-symbolic concept learning, most
approaches still cannot be deployed on real-world knowledge bases. This is due
to their use of description logic reasoners, which are not robust against
inconsistencies nor erroneous data. We address this challenge by presenting a
novel neural reasoner dubbed EBR. Our reasoner relies on embeddings to
approximate the results of a symbolic reasoner. We show that EBR solely
requires retrieving instances for atomic concepts and existential restrictions
to retrieve or approximate the set of instances of any concept in the
description logic $\mathcal{SHOIQ}$. In our experiments, we compare EBR with
state-of-the-art reasoners. Our results suggest that EBR is robust against
missing and erroneous data in contrast to existing reasoners.

</details>


### [94] [FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic](https://arxiv.org/abs/2510.20467)
*Yiwen Peng,Thomas Bonald,Fabian M. Suchanek*

Main category: cs.AI

TL;DR: 提出了一种称为FLORA的知识图谱对齐方法，该方法无需训练数据，可以同时对齐实体和关系，基于模糊逻辑，结果可解释，具有理论收敛性，并且允许孤立实体的存在，在主要基准测试中实现了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有大多数方法只关注实体级别的对齐，基于嵌入空间中的相似度计算，缺乏可解释性，并且需要训练数据。因此，作者提出了一种新的方法来解决这些问题，提供更全面的解决方案，实现更好的性能和可解释性。

Method: FLORA是一个基于模糊逻辑的方法，无需训练数据，同时处理实体和关系的对齐，并且能够处理孤立实体的存在。该方法通过迭代的方式进行对齐，并提供可解释性的结果。同时，该方法还具有理论上的收敛性保证。

Result: FLORA在主要基准数据集上展示了卓越的性能，达到了先进的结果，并且不需要任何训练数据。此外，通过提供可解释性的结果，它有助于理解对齐过程中所使用的方法和所获得的结果。

Conclusion: FLORA提供了一种新颖且有效的方法来解决知识图谱对齐问题，通过利用模糊逻辑和迭代更新机制，实现了无需训练数据即可完成的实体和关系对齐，同时保持了结果的可解释性和理论收敛性。

Abstract: Knowledge graph alignment is the task of matching equivalent entities (that
is, instances and classes) and relations across two knowledge graphs. Most
existing methods focus on pure entity-level alignment, computing the similarity
of entities in some embedding space. They lack interpretable reasoning and need
training data to work. In this paper, we propose FLORA, a simple yet effective
method that (1) is unsupervised, i.e., does not require training data, (2)
provides a holistic alignment for entities and relations iteratively, (3) is
based on fuzzy logic and thus delivers interpretable results, (4) provably
converges, (5) allows dangling entities, i.e., entities without a counterpart
in the other KG, and (6) achieves state-of-the-art results on major benchmarks.

</details>


### [95] [Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms](https://arxiv.org/abs/2510.20621)
*Riccardo Guidotti,Martina Cinquini,Marta Marchiori Manerba,Mattia Setzu,Francesco Spinnato*

Main category: cs.AI

TL;DR: 本文介绍了MIMOSA框架，该框架旨在生成既具有高性能又具有良好解释性的模型，并嵌入关键的伦理属性，如因果关系、公平性和隐私性。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动化决策模型的可信赖性、责任性以及安全采用，设计出解释性强的模型是关键。MIMOSA框架就是为了在平衡解释性和性能的同时，融入关键伦理属性而设计的。

Method: 该研究在监督学习设置下定义了多样化的决策任务和数据类型，并对特征重要性、规则和基于实例的模型三大类可解释模型进行了深入的分析，讨论了它们的解释性维度、推理机制和复杂度，并为因果性、公平性和隐私性这三项关键的伦理属性提供了正式定义、评估指标和验证程序。此外，还分析了这些伦理属性之间的内在权衡，并探讨了如何在可解释的管道中嵌入隐私需求、公平约束和因果推理。

Result: MIMOSA框架提供了坚实的理论基础，用于开发既准确又有解释性的AI系统，同时还具有公平性、隐私保护和因果意识，即可信赖的AI系统。

Conclusion: 在监督学习设置下，MIMOSA框架可以生成具有高性能和高解释性的模型，并确保这些模型在隐私、公平和因果性等方面满足伦理要求。

Abstract: Interpretable-by-design models are crucial for fostering trust,
accountability, and safe adoption of automated decision-making models in
real-world applications. In this paper we formalize the ground for the MIMOSA
(Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a
comprehensive methodology for generating predictive models that balance
interpretability with performance while embedding key ethical properties. We
formally define here the supervised learning setting across diverse
decision-making tasks and data types, including tabular data, time series,
images, text, transactions, and trajectories. We characterize three major
families of interpretable models: feature importance, rule, and instance based
models. For each family, we analyze their interpretability dimensions,
reasoning mechanisms, and complexity. Beyond interpretability, we formalize
three critical ethical properties, namely causality, fairness, and privacy,
providing formal definitions, evaluation metrics, and verification procedures
for each. We then examine the inherent trade-offs between these properties and
discuss how privacy requirements, fairness constraints, and causal reasoning
can be embedded within interpretable pipelines. By evaluating ethical measures
during model generation, this framework establishes the theoretical foundations
for developing AI systems that are not only accurate and interpretable but also
fair, privacy-preserving, and causally aware, i.e., trustworthy.

</details>


### [96] [Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications](https://arxiv.org/abs/2510.20632)
*Shuyi Xie,Ziqin Liew,Hailing Zhang,Haibo Zhang,Ling Hu,Zhiqiang Zhou,Shuman Liu,Anxiang Zeng*

Main category: cs.AI

TL;DR: EcomEval 是一个全面的多语言和多模式基准，用于评估大型语言模型在电子商务中的性能。它涵盖了六个类别和37个任务，包括8个多模式任务，主要来自真实客户的查询和交易日志，同时定义了难度等级以实现更具挑战性的评估，并支持七种语言，其中包括五种资源较少的东南亚语言。


<details>
  <summary>Details</summary>
Motivation: 现有的电商领域语言模型评估基准存在的问题包括任务多样性有限、缺少多模态数据、使用人工合成或策划的数据、以及主要关注英语和中文，无法全面评估模型在复杂真实世界场景中的性能。因此，引入EcomEval来广泛检测大型语言模型在电子商务领域的能力。

Method: EcomEval包括六个类别和37个多模式任务，来源主要是真实客户咨询和交易记录，数据处理采用半自动流水线，大型模型草拟候答，由电商和多语言专家进行审查和修订。同时定义了不同问题和任务领域的难度等级，通过给不同大小和能力的模型的平均评分进行计算。支持七种语言，其中包括五种资源较少的东南亚语言。

Result: EcomEval 提供了一个全面覆盖实际购物场景的多语言、多模态基准，为衡量语言模型的性能提供了可靠工具。它的设计考虑了真实业务互动的嘈杂和异质性特点，并通过明确的难度级别定义，可以对大模型进行挑战性评估。

Conclusion: EcomEval填补了电商领域大型语言模型评估基准的空白，为用户提供了一种可靠的工具来评估模型在复杂、真实的电子商务场景中的表现，从而更好地服务于电商行业的从业者。

Abstract: Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet
their capabilities in specialized domains remain underexplored. In e-commerce,
existing evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping
MMLU-suffer from limited task diversity (e.g., lacking product guidance and
after-sales issues), limited task modalities (e.g., absence of multimodal
data), synthetic or curated data, and a narrow focus on English and Chinese,
leaving practitioners without reliable tools to assess models on complex,
real-world shopping scenarios. We introduce EcomEval, a comprehensive
multilingual and multimodal benchmark for evaluating LLMs in e-commerce.
EcomEval covers six categories and 37 tasks (including 8 multimodal tasks),
sourced primarily from authentic customer queries and transaction logs,
reflecting the noisy and heterogeneous nature of real business interactions. To
ensure both quality and scalability of reference answers, we adopt a
semi-automatic pipeline in which large models draft candidate responses
subsequently reviewed and modified by over 50 expert annotators with strong
e-commerce and multilingual expertise. We define difficulty levels for each
question and task category by averaging evaluation scores across models with
different sizes and capabilities, enabling challenge-oriented and fine-grained
assessment. EcomEval also spans seven languages-including five low-resource
Southeast Asian languages-offering a multilingual perspective absent from prior
work.

</details>


### [97] [Fluidity Index: Next-Generation Super-intelligence Benchmarks](https://arxiv.org/abs/2510.20636)
*Eric Ngoiya,Tianshu Bao*

Main category: cs.AI

TL;DR: 本文引入了Flow Index（FI）量化模型在动态、可扩展环境中适应性的指标。该基准通过检查初始、当前和未来环境状态的偏差来评估模型的上下文切换和持续性，区分并侧重于闭环开放式的现实世界基准测试，以检验模型的适应性。一个真正超级智能的模型应该具备至少二级适应性，通过数字补充实现自我维持计算，达到最佳流动性。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于需要一个量化的标准来评估模型在动态、可扩展环境中的适应性，并提出了Fluidity Index (FI)，以更好地评估上下文理解和预测、调整状态变更的能力，以及模型的自我维持计算的能力。这有助于识别出真正超级智能的模型，这些模型具备至少二级适应性，能够通过数字补充实现自我维持计算，达到最佳流动性。

Method: 本文提出了一种新的度量标准：Fluidity Index (FI)。利用这个通过检查初始、当前和未来环境状态的偏差来评估模型适应性的基准方法，并且重点在于检验模型在闭环开放式现实世界基准测试中的表现。研究者对这个度量的方法进行了测试，建立了能够更准确评估模型适应性和可持续性的基准模型。

Result: 本方法能够准确地评估和量化模型在动态、可扩展环境中的适应性，此外通过新提出的Fluidity Index (FI)能够更好地理解模型的状态变更、上下文理解与预测表现以及模型自我维持计算的能力。本研究建立的该评估方法能识别出真正超级智能的模型，表明至少二级适应性的模型具备自我维持计算和数字补充能力，达到最佳流动性。

Conclusion: 本文通过引入新的Fluidity Index (FI)以及评估模型在动态、可扩展环境下的适应性的方法，能够更准确地识别并量化模型的适应性。该指标和方法能更好地检测和量化模型的适应性以及连续执行计算的能力，并指出了一个理论上具备更高级适应性的模型的标准。

Abstract: This paper introduces the Fluidity Index (FI) to quantify model adaptability
in dynamic, scaling environments. The benchmark evaluates response accuracy
based on deviations in initial, current, and future environment states,
assessing context switching and continuity. We distinguish between closed-ended
and open-ended benchmarks, prioritizing closed-loop open-ended real-world
benchmarks to test adaptability. The approach measures a model's ability to
understand, predict, and adjust to state changes in scaling environments. A
truly super-intelligent model should exhibit at least second-order
adaptability, enabling self-sustained computation through digital replenishment
for optimal fluidity.

</details>


### [98] [The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models](https://arxiv.org/abs/2510.20665)
*Xue Wen Tan,Nathaniel Tan,Galen Lee,Stanley Kok*

Main category: cs.AI

TL;DR: 介绍了一种基于拓扑数据分析（TDA）的评估框架，用于评估大型语言模型的推理质量。该框架捕获推理轨迹的几何形状，并能够实现标签高效、自动化的评估。实验表明，拓扑特征在评估推理质量方面比传统的图度量具有更高的预测能力，这表明有效的推理更多地依赖于高维几何结构，而不是纯粹的关系图。研究还表明，一个紧凑且稳定的拓扑特征集可以可靠地指示轨迹的质量，为未来强化学习算法提供实践信号。


<details>
  <summary>Details</summary>
Motivation: 目前评估大型语言模型推理质量的方法存在不足，如依赖专家评分、人工标注和缓慢的成对判断等，并且自动方法往往过于简化复杂过程的本质。因此，研究引入了基于拓扑数据分析（TDA）的评估框架，以期解决这些问题。

Method: 提出了一种基于TDA的评估框架，该框架能够捕获推理轨迹的几何形状，并能够实现标签高效的自动化评估。同时，研究中采用了实证研究的方法，利用该框架对比了标准图度量与拓扑特征在评估推理质量方面的预测能力。

Result: 实验结果显示，拓扑特征在评估推理质量方面比传统图度量具有更高的预测能力，这表明有效的推理更多地依赖于高维几何结构，而不是纯粹的关系图。此外，一个紧凑且稳定的拓扑特征集可以可靠地指示轨迹的质量，为未来强化学习算法提供实践信号。

Conclusion: 通过引入基于TDA的评估框架，研究证明了可以通过评估推理轨迹的几何形状来实现更有效的评估，这不仅提高了评估的准确性，也为未来研究和实践提供了新的方向。

Abstract: Evaluating the quality of reasoning traces from large language models remains
understudied, labor-intensive, and unreliable: current practice relies on
expert rubrics, manual annotation, and slow pairwise judgments. Automated
efforts are dominated by graph-based proxies that quantify structural
connectivity but do not clarify what constitutes high-quality reasoning; such
abstractions can be overly simplistic for inherently complex processes. We
introduce a topological data analysis (TDA)-based evaluation framework that
captures the geometry of reasoning traces and enables label-efficient,
automated assessment. In our empirical study, topological features yield
substantially higher predictive power for assessing reasoning quality than
standard graph metrics, suggesting that effective reasoning is better captured
by higher-dimensional geometric structures rather than purely relational
graphs. We further show that a compact, stable set of topological features
reliably indicates trace quality, offering a practical signal for future
reinforcement learning algorithms.

</details>


### [99] [A Coherence-Based Measure of AGI](https://arxiv.org/abs/2510.20784)
*Fares Fourati*

Main category: cs.AI

TL;DR: 本文提出了一种基于补偿性指数连续范围内的广义均值积分的AGI衡量标准，该标准涵盖了算术、几何和调和制度，能够量化在不同补偿性假设下的稳健性，以此更严格地定义和度量向AGI的进展。这种方法不仅纠正了以往定义中对专业化的奖励，还强调了跨领域依赖性和平衡能力的重要性。应用该方法，发现GPT-4和GPT-5在算术评分较高时，仍然在广泛领域内表现不足，距离真正的通用智能还有很大距离。


<details>
  <summary>Details</summary>
Motivation: 传统的AGI定义存在问题，因为它假设一个领域中的突出能力可以弥补其他领域的不足。而真正的通用智能应该体现综合足够性，即在所有基本领域中具备均衡的竞争力。现有的定义忽略了跨领域依赖性和能力平衡，因此需要一个更严谨的标准来评估智能系统的真正进展。

Method: 提出了一种基于补偿性指数连续范围内的广义均值积分的AGI衡量标准，这种方法不仅涵盖了算术、几何和调和等不同制度，还能通过计算面积下曲线（AUC）来量化在不同补偿性假设下的稳健性。这种方法能更好地捕捉到跨领域的依赖性和能力的平衡缺失，因此能更严格地定义和度量向AGI的进展。

Result: 将这种方法应用于GPT-4和GPT-5这两个基于CHC模型得分发表的智能系统，结果发现尽管它们在算术评分很高（例如，GPT-5为24%），但它们在多个领域的表现仍显示出明显的不平衡，因此距离真正的通用智能还有很大距离。这表明，当前的AI系统在实现AGI的道路上仍然面对着巨大的挑战。

Conclusion: 这种方法不仅纠正了以往对专业化的奖励偏见，还通过一种新的、严谨的视角定义了AGI的一种更真实、更严格的标准，强调了跨领域依赖性和能力平衡的重要性。这一发现推动了对智能系统评价体系的改进，为理解和推进向AGI的进展提供了新的思路。

Abstract: Recent work by \citet{hendrycks2025agidefinition} formalized
\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of
proficiencies across cognitive domains derived from the Cattell--Horn--Carroll
(CHC) model of human cognition. While elegant, this definition assumes
\textit{compensability} -- that exceptional ability in some domains can offset
failure in others. True general intelligence, however, should reflect
\textit{coherent sufficiency}: balanced competence across all essential
domains. We propose a coherence-aware measure of AGI based on the integral of
generalized means over a continuum of compensability exponents. This
formulation spans arithmetic, geometric, and harmonic regimes, and the
resulting \textit{area under the curve} (AUC) quantifies robustness under
varying compensability assumptions. Unlike the arithmetic mean, which rewards
specialization, the AUC penalizes imbalance and captures inter-domain
dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,
the coherence-adjusted AUC reveals that both systems remain far from general
competence despite high arithmetic scores (e.g., GPT-5 at~24\%). Integrating
the generalized mean thus yields a principled, interpretable, and stricter
foundation for measuring genuine progress toward AGI.

</details>


### [100] [Real Deep Research for AI, Robotics and Beyond](https://arxiv.org/abs/2510.20809)
*Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang*

Main category: cs.AI

TL;DR: 提出了Real Deep Research（RDR）框架，用以系统分析任何研究领域，帮助研究人员发现新兴趋势，跨领域机会，并提供具体的新的研究起点，特别针对AI和机器人领域并对其他科学领域进行扩展分析


<details>
  <summary>Details</summary>
Motivation: 随着AI和机器人领域研究论文数量的快速增长，研究人员很难跟上最新的研究趋势和跨学科的发展，需要一个系统的方法来分析和发现新的研究机会

Method: 提出了一个通用的研究框架RDR，可以系统地分析任何研究领域，特别是在AI和机器人领域的基础模型和机器人技术的发展，同时扩展了对其他科学领域的分析

Result: 提供了RDR框架的构建细节以及在各个研究主题上的详细结果，研究表明该框架能有效地发现新兴趋势和跨领域机会，为新的研究提供了起点

Conclusion: 希望这项工作能为AI及相关领域的研究人员提供新的视角和研究起点

Abstract: With the rapid growth of research in AI and robotics now producing over
10,000 papers annually it has become increasingly difficult for researchers to
stay up to date. Fast evolving trends, the rise of interdisciplinary work, and
the need to explore domains beyond one's expertise all contribute to this
challenge. To address these issues, we propose a generalizable pipeline capable
of systematically analyzing any research area: identifying emerging trends,
uncovering cross domain opportunities, and offering concrete starting points
for new inquiry. In this work, we present Real Deep Research (RDR) a
comprehensive framework applied to the domains of AI and robotics, with a
particular focus on foundation models and robotics advancements. We also
briefly extend our analysis to other areas of science. The main paper details
the construction of the RDR pipeline, while the appendix provides extensive
results across each analyzed topic. We hope this work sheds light for
researchers working in the field of AI and beyond.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [101] [Foveated Compression for Immersive Telepresence Visualization](https://arxiv.org/abs/2510.19848)
*Max Schwarz,Sven Behnke*

Main category: eess.IV

TL;DR: 提出了一种轻量级的方法来压缩沉浸式远程可视化视频流，通过调整量化参数来减少所需的带宽。如果可用眼动追踪数据的话，可以在保持高忠诚度的视网膜区域的同时，减少外围区域的质量，从而节省带宽。实验表明，这种方法在不牺牲沉浸感的情况下，可以将带宽减少到原来的三分之一。


<details>
  <summary>Details</summary>
Motivation: 解决沉浸式远程可视化中的分辨率和保真度受限于通信带宽的问题

Method: 通过基于眼动追踪信息自适应地调整量化参数，实现沉浸式远程可视化视频流的轻量级视网膜压缩

Result: 实验证明，在不牺牲沉浸感的情况下，带宽可以减少到原来的三分之一

Conclusion: 通过调整带宽利用，可以显著提高沉浸式远程可视化的体验和效率

Abstract: Immersive televisualization is important both for telepresence and
teleoperation, but resolution and fidelity are often limited by communication
bandwidth constraints. We propose a lightweight method for foveated compression
of immersive televisualization video streams that can be easily integrated with
common video codecs, reducing the required bandwidth if eye tracking data is
available. Specifically, we show how to spatially adjust the Quantization
Parameter of modern block-based video codecs in a adaptive way based on eye
tracking information. The foveal region is transmitted with high fidelity while
quality is reduced in the peripheral region, saving bandwidth. We integrate our
method with the NimbRo avatar system, which won the ANA Avatar XPRIZE
competition. Our experiments show that bandwidth can be reduced to a third
without sacrificing immersion. We analyze transmission fidelity with
qualitative examples and report quantitative results.

</details>


### [102] [Visible Iris Area as a Quality Metric for Reliable Iris Recognition Under Pupil Dilation and Eyelid Occlusion](https://arxiv.org/abs/2510.19884)
*Jack Pessaud,Eric Moran,John Nguyen,Joel Palko*

Main category: eess.IV

TL;DR: 研究表明，瞳孔变化和眼睑遮挡会影响虹膜识别性能，且可见虹膜面积是虹膜图像质量的可靠指标，能提高虹膜识别系统的匹配预测置信度


<details>
  <summary>Details</summary>
Motivation: 随着虹膜识别系统的广泛应用和大规模注册数据库的建立，对于在采集时实时评估虹膜图像质量的需求增加，特别是需要实时模型用户的不合规性

Method: 使用包含555个独立虹膜的大型数据集，分析了瞳孔扩大和眼睑遮挡的影响，并研究了可见虹膜面积和虹膜代码对之间的汉明距离之间的关联

Result: 发现了可见虹膜面积与汉明距离的强相关性，这表明可见虹膜面积是评估虹膜图像质量的可靠指标

Conclusion: 虹膜可见面积可以有效地集成到虹膜捕获过程中，以提高匹配预测的置信度

Abstract: With the increasing adoption of iris recognition systems and the expansion of
large-scale enrollment databases, there is a growing need to efficiently assess
iris image quality at the time of acquisition, particularly to model user
non-compliance in real time. Image quality may degrade due to eyelid occlusion
or pupil dilation. Although previous studies have shown that occlusion and
changes in the pupil-to-iris ratio negatively impact recognition performance,
these investigations were typically limited by small sample sizes and did not
examine the combined effects of eyelid and pupil variations. In this study, we
analyze both dilation and eyelid occlusion using a large dataset of 555
distinct irises and demonstrate a strong correlation between probe image
visible iris area and the Hamming distance of iris code pairs. These results
suggest that visible iris area is a robust indicator of probe image quality and
could be efficiently incorporated into the iris acquisition process to improve
confidence in match predictions.

</details>


### [103] [Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets](https://arxiv.org/abs/2510.19944)
*Jiashi Feng,Xiu Li,Jing Lin,Jiahang Liu,Gaohong Liu,Weiqiang Lou,Su Ma,Guang Shi,Qinlong Wang,Jun Wang,Zhongcong Xu,Xuanyu Yi,Zihao Yu,Jianfeng Zhang,Yifan Zhu,Rui Chen,Jinxin Chi,Zixian Du,Li Han,Lixin Huang,Kaihua Jiang,Yuhan Li,Guan Luo,Shuguang Wang,Qianyi Wu,Fan Yang,Junyang Zhang,Xuanmeng Zhang*

Main category: eess.IV

TL;DR: Seed3D 1.0是一款从单张图片生成交互式学习环境所需3D模型的生成系统，解决了现有世界模拟器视频生成法缺乏物理反馈与物理引擎手动创建成本高的问题。该系统生成的模型具有精确的几何、纹理和物理材料，可直接应用到物理引擎。


<details>
  <summary>Details</summary>
Motivation: 开发实体AI需要既具有内容多样性又具有物理准确性的大规模训练环境。现视频生成法缺乏物理反馈而物理引擎创建费用高昂，因此提出了Seed3D 1.0来解决这些问题，同时也可批量生成完整场景并集成到物理引擎中用于模拟培训等。

Method: Seed3D 1.0从单一图像生成加载至物理引擎的3D模型，提供精确几何、纹理与物理材料。生成的模型能直接用于模拟或交互学习环境，另配有完整场景生成模式。

Result: Seed3D 1.0成功生成用于物理引擎中的精确模型，满足了大规模训练环境对于物理准确性的需求，推进了基于物理的世界模拟器的发展并广泛应用于模拟培训等场景。访问 https://console.volcengine.com/ark/region:ark+cn-beijing/experience/vision?modelId=doubao-seed3d-1-0-250928&tab=Gen3D , 可尝试使用该工具。

Conclusion: Seed3D 1.0的创新在于集成了物理准确性和大规模生成能力，这为开发具有物理交互能力的AI提供了有效的方法，提高了模拟环境的质量和多样性。

Abstract: Developing embodied AI agents requires scalable training environments that
balance content diversity with physics accuracy. World simulators provide such
environments but face distinct limitations: video-based methods generate
diverse content but lack real-time physics feedback for interactive learning,
while physics-based engines provide accurate dynamics but face scalability
limitations from costly manual asset creation. We present Seed3D 1.0, a
foundation model that generates simulation-ready 3D assets from single images,
addressing the scalability challenge while maintaining physics rigor. Unlike
existing 3D generation models, our system produces assets with accurate
geometry, well-aligned textures, and realistic physically-based materials.
These assets can be directly integrated into physics engines with minimal
configuration, enabling deployment in robotic manipulation and simulation
training. Beyond individual objects, the system scales to complete scene
generation through assembling objects into coherent environments. By enabling
scalable simulation-ready content creation, Seed3D 1.0 provides a foundation
for advancing physics-based world simulators. Seed3D 1.0 is now available on
https://console.volcengine.com/ark/region:ark+cn-beijing/experience/vision?modelId=doubao-seed3d-1-0-250928&tab=Gen3D

</details>


### [104] [GUSL-Dehaze: A Green U-Shaped Learning Approach to Image Dehazing](https://arxiv.org/abs/2510.20266)
*Mahtab Movaheddrad,Laurence Palmer,C. -C. Jay Kuo*

Main category: eess.IV

TL;DR: GUSL-Dehaze 是一种轻量级的图像去雾方法，结合了物理模型与绿色学习框架，避免了深度学习的高计算成本和大参数量问题。通过改进的 Dark Channel Prior 和 U 形架构的无监督表示学习，GUSL-Dehaze 实现了与最新深度学习方法相当的性能，同时保持了数学可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统图像去雾方法依赖于统计先验和物理模型，而现代深度学习方法虽然高效，但参数量大、计算成本高，不适用于资源受限的设备。动机在于开发一种既轻量又高效，同时保持数学解释性的去雾方法。

Method: 引入一种绿色学习（GL）框架，GUSL-Dehaze 利用改进后的 Dark Channel Prior 进行初始去雾，然后利用 U 形架构进行无监督表示学习，并结合能保持小模型大小的特征工程技术（如 RFT 和 LNT）。最后，通过监督学习策略获得清晰图像。

Result: GUSL-Dehaze 方法在降低参数计数的同时，确保了数学上的可解释性，同时性能上达到了与当前最先进的深度学习方法相当的水平。

Conclusion: GUSL-Dehaze 为资源受限设备提供了一种有效的图像去雾解决方案，这种方法结合了物理和统计方法的长处，避免了深度学习的短处，提供了一种轻量级且高效的去雾模型。

Abstract: Image dehazing is a restoration task that aims to recover a clear image from
a single hazy input. Traditional approaches rely on statistical priors and the
physics-based atmospheric scattering model to reconstruct the haze-free image.
While recent state-of-the-art methods are predominantly based on deep learning
architectures, these models often involve high computational costs and large
parameter sizes, making them unsuitable for resource-constrained devices. In
this work, we propose GUSL-Dehaze, a Green U-Shaped Learning approach to image
dehazing. Our method integrates a physics-based model with a green learning
(GL) framework, offering a lightweight, transparent alternative to conventional
deep learning techniques. Unlike neural network-based solutions, GUSL-Dehaze
completely avoids deep learning. Instead, we begin with an initial dehazing
step using a modified Dark Channel Prior (DCP), which is followed by a green
learning pipeline implemented through a U-shaped architecture. This
architecture employs unsupervised representation learning for effective feature
extraction, together with feature-engineering techniques such as the Relevant
Feature Test (RFT) and the Least-Squares Normal Transform (LNT) to maintain a
compact model size. Finally, the dehazed image is obtained via a transparent
supervised learning strategy. GUSL-Dehaze significantly reduces parameter count
while ensuring mathematical interpretability and achieving performance on par
with state-of-the-art deep learning models.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [105] [Moving or Predicting? RoleAware-MAPP: A Role-Aware Transformer Framework for Movable Antenna Position Prediction to Secure Wireless Communications](https://arxiv.org/abs/2510.20293)
*Wenxu Wang,Xiaowu Liu,Wei Gong,Yujia Zhao,Kaixuan Li,Qixun Zhang,Zhiyong Feng,Kan Yu*

Main category: cs.IT

TL;DR: 本文提出了一种新的基于Transformer的框架RoleAware-MAPP，用于解决可移动天线技术在物理层安全中的部署挑战。通过结合领域知识，该框架在模拟测试中显示出优越的性能，包括更高的密钥率和更积极的密钥容量，并在各种条件下表现稳定。


<details>
  <summary>Details</summary>
Motivation: 为了克服可移动天线技术在实时优化中的高计算复杂度和时间错配问题，本文提出了一个新的方法，旨在提高物理层安全性。


Method: 该研究将可移动天线定位问题重构成一个预测任务，并引入了RoleAware-MAPP框架。

此框架具有三个关键组件：角色感知嵌入，用于建模特定用户意图；物理度量语义特征，用于封装通道传播属性；复合损失函数，优先考虑秘密性能，而不是简单的几何精确度。



Result: 在3GPP合规的模拟测试环境下，RoleAware-MAPP展示了优越的结果，实现了0.3569 bps/Hz的平均秘密率，以及81.52%的严格单纯秘密能力，分别超越最强的基准线48.4%，5.39个百分点。同时，它在各种用户速度和噪声条件下展示了稳定的性能。


Conclusion: 通过结合特定的通信领域知识，本文所提出的方法能更有效地解决通过可移动天线提高物理层安全性的问题。

Abstract: Movable antenna (MA) technology provides a promising avenue for actively
shaping wireless channels through dynamic antenna positioning, thereby enabling
electromagnetic radiation reconstruction to enhance physical layer security
(PLS). However, its practical deployment is hindered by two major challenges:
the high computational complexity of real time optimization and a critical
temporal mismatch between slow mechanical movement and rapid channel
variations. Although data driven methods have been introduced to alleviate
online optimization burdens, they are still constrained by suboptimal training
labels derived from conventional solvers or high sample complexity in
reinforcement learning. More importantly, existing learning based approaches
often overlook communication-specific domain knowledge, particularly the
asymmetric roles and adversarial interactions between legitimate users and
eavesdroppers, which are fundamental to PLS. To address these issues, this
paper reformulates the MA positioning problem as a predictive task and
introduces RoleAware-MAPP, a novel Transformer based framework that
incorporates domain knowledge through three key components: role-aware
embeddings that model user specific intentions, physics-informed semantic
features that encapsulate channel propagation characteristics, and a composite
loss function that strategically prioritizes secrecy performance over mere
geometric accuracy. Extensive simulations under 3GPP-compliant scenarios show
that RoleAware-MAPP achieves an average secrecy rate of 0.3569 bps/Hz and a
strictly positive secrecy capacity of 81.52%, outperforming the strongest
baseline by 48.4% and 5.39 percentage points, respectively, while maintaining
robust performance across diverse user velocities and noise conditions.

</details>


### [106] [Robust Analog Lagrange Coded Computing: Theory and Algorithms via Discrete Fourier Transforms](https://arxiv.org/abs/2510.20379)
*Rimpi Borah,J. Harshan*

Main category: cs.IT

TL;DR: ALCC是一种计算框架，可以在分布式环境中使用浮点表示处理模拟数据集，并保护数据免受工人的隐私侵犯。然而，它对恶意返回错误结果的拜占庭工人不具鲁棒性。文章提出了一种使用离散傅里叶变换（DFT）码的错误校正算法和新的重建策略来构建安全的ALCC框架，以提高计算准确性，并对串通攻击进行了研究。


<details>
  <summary>Details</summary>
Motivation: 传统的ALCC在应对拜占庭工人时缺乏鲁棒性，可能导致安全风险。因此，本文提出了一个安全的ALCC框架以解决这个问题，并增强了计算准确性。同时也探讨了该框架在面临串通攻击时的鲁棒性。

Method: 通过使用离散傅里叶变换（DFT）码的错误校正算法来改进ALCC的重建策略，同时也提出了一个新的策略来分配ALCC计算任务给工人节点，利用工人节点的信任配置文件信息。此外，研究了框架对这类攻击的鲁棒性。

Result: 提出了一个能够准确计算且鲁棒性强的安全ALCC框架，特别是在面临拜占庭工人和串通攻击时，该框架表现出色。使用DFT解码器的理论结果，证明了提高计算准确性的方法。并展示了利用浮点实现所固有的精度噪声，可以执行有趣的攻击策略。

Conclusion: 安全的ALCC框架通过错误校正算法和新的重建策略，增强了计算的准确性和鲁棒性，特别是在处理恶意拜占庭工人时。但同时也需要注意，精度噪声可能被利用来发起攻击。

Abstract: Analog Lagrange Coded Computing (ALCC) is a recently proposed computational
paradigm wherein certain computations over analog datasets are efficiently
performed using distributed worker nodes through floating point representation.
While the vanilla version of ALCC is known to preserve the privacy of the
datasets from the workers and also achieve resilience against stragglers, it is
not robust against Byzantine workers that return erroneous results.
Highlighting this vulnerability, we propose a secure ALCC framework that is
resilient against a wide range of integrity threats from the Byzantine workers.
As a foundational step, we use error-correction algorithms for Discrete Fourier
Transform (DFT) codes to build novel reconstruction strategies for ALCC thereby
improving its computational accuracy in the presence of a bounded number of
Byzantine workers. Furthermore, capitalizing on some theoretical results on the
performance of the DFT decoders, we propose novel strategies for distributing
the ALCC computational tasks to the workers, and show that such methods
significantly improve the accuracy when the workers' trust profiles are
available at the master server. Finally, we study the robustness of the
proposed framework against colluding attacks, and show that interesting attack
strategies can be executed by exploiting the inherent precision noise owing to
floating point implementation.

</details>


### [107] [Adversary-Aware Private Inference over Wireless Channels](https://arxiv.org/abs/2510.20518)
*Mohamed Seif,Malcolm Egan,Andrea J. Goldsmith,H. Vincent Poor*

Main category: cs.IT

TL;DR: 本文提出了一种隐私保护的AI传感新框架，该框架能够在数据传输前对提取的特征进行变换，从而减少隐私泄露的风险。


<details>
  <summary>Details</summary>
Motivation: 由于在无线边缘设备中进行AI传感时，可能会有包含敏感个人信息的数据被攻击者重构，对隐私造成威胁，因此提出了一种保护隐私的方法来处理这个问题。

Method: 本文提出了一种隐私保护框架，通过在传输之前对从传感数据中提取的特征进行变换，从而减少隐私暴露的风险。

Result: 该方法可以有效地保护从传感数据中提取的特征不被对手重构，从而保护了隐私安全。

Conclusion: 提出的隐私保护框架能够有效地保护AI传感应用中的隐私，确保数据在安全的前提下进行有效的传输。

Abstract: AI-based sensing at wireless edge devices has the potential to significantly
enhance Artificial Intelligence (AI) applications, particularly for vision and
perception tasks such as in autonomous driving and environmental monitoring. AI
systems rely both on efficient model learning and inference. In the inference
phase, features extracted from sensing data are utilized for prediction tasks
(e.g., classification or regression). In edge networks, sensors and model
servers are often not co-located, which requires communication of features. As
sensitive personal data can be reconstructed by an adversary, transformation of
the features are required to reduce the risk of privacy violations. While
differential privacy mechanisms provide a means of protecting finite datasets,
protection of individual features has not been addressed. In this paper, we
propose a novel framework for privacy-preserving AI-based sensing, where
devices apply transformations of extracted features before transmission to a
model server.

</details>


### [108] [Simultaneous Wireless Information and Power Transfer for Fluid Antenna Systems](https://arxiv.org/abs/2510.20569)
*Feilong Zhang,Jianxin Dai,Zhaohui Yang,Kai-Kit Wong,Lingyuxiu Li,Jianglin Ye*

Main category: cs.IT

TL;DR: 本文提出了一种结合MISO液体天线与传统固定位置天线的通信系统，通过优化天线位置以提高能量收集效率，并在满足给定的最小SINR约束条件下进行天线位置和发射共变矩阵的优化。仿真结果表明液体天线系统相比于传统固定位置天线显著提升能量收集效率。


<details>
  <summary>Details</summary>
Motivation: 当前的无线通信技术需要在传输率和能量收集效率之间寻找平衡。液体天线作为一种新的无线通信技术，通过改变天线位置来提升传输率，但其在能量收集效率提升方面仍有待优化。本文动机在于如何利用液体天线进行更有效的能量收集，从而推进液体天线技术的发展与应用。

Method: 我们利用优化算法调整液体天线的位置，以提高能量效率。在实现同时无线信息和能量传输（SWIPT）时，重点在于如何在满足最低接收干扰加噪声比（SINR）的条件下，优化天线位置和发射共变矩阵。最终系统相比传统固定天线系统显示了更高的能量收集效率。在严格的通信环境约束下进行系统的仿真测试，验证了所提方法的有效性。

Result: 实验结果表明，采用本论文方法的液体天线系统确实显著提高了能量收获效率。相比传统固定天线系统，通过调整液体天线的位置和优化发射共变矩阵，使得能量传递更加高效。仿真数据支持了本论文的研究目标，证明了液体天线在优化设计下的确实优势。

Conclusion: 本文提出了一种结合MISO液体天线与固定位置天线的优化方法，展示了液体天线在能量收集效率上的巨大潜力，并证明了在满足一定通信质量要求下，改进后的系统可以获得更好的能量收集效果，这对于以后相关技术开发具有积极的意义。

Abstract: Fluid antenna is a promising wireless communication technology that enhances
communication rate by changing the antenna positions. This article proposes a
new communication system that combines multiple-input single-output (MISO)
fluid antennas with traditional fixed-position antennas, utilizing antenna
position optimization to improve energy harvesting efficiency. In this model,
we consider simultaneous wireless information and power transfer (SWIPT) which
transmits identical signals from the base station to both information receiver
(IR) and energy receiver (ER). We strive to enhance the power delivered to the
ER by fine-tuning the positions of transmit and receive fluid antennas, along
with optimizing the transmit covariance matrix, subject to a given minimum
signal-to-interference-plus-noise ratio (SINR) constraint at the IR. Simulation
results indicate that fluid antenna systems significantly enhance the energy
harvesting efficiency of the ER compared to traditional fixed-position
antennas.

</details>


### [109] [Super-Linear Growth of the Capacity-Achieving Input Support for the Amplitude-Constrained AWGN Channel](https://arxiv.org/abs/2510.20723)
*Haiyang Wang*

Main category: cs.IT

TL;DR: 研究了幅度约束下的AWGN信道中容量实现输入分布支撑集的增长。与Smith (1971)的结果不同，我们通过结合总变差收敛和高斯混合逼近的定量限制，建立了支撑点数量$K(A)$随幅度约束$A$增加而超线性增长的新下界。


<details>
  <summary>Details</summary>
Motivation: 探讨在增加幅度约束下，AWGN信道中容量实现输入分布支撑集的增长模式。之前的理论结果表明支撑集是离散的且具有有限质量点，但具体支撑点数量的紧致上界尚未解决。此研究的动机是希望能为这个问题提供新的见解和定量界限，解决这一长期存在的难题。基于Dytso et al. (2019)和Mattingly et al. (2018)的工作，提出了一种新的方法来解决这个问题。

Method: 通过结合总变差收敛到均匀分布的方法，以及对高斯混合逼近的定量限制，建立了一个新的分析下界。该方法包括了关于输出分布和输入分布设计方面的理论推导和模型计算。具体来说，就是对在幅度约束增加时，系统误差的总体变化是如何影响具有超级线性增长的支撑点个数的饱和性。这是一个复杂的解析和计算问题，需要深入的理论技术支持，以有效准确地解决此技术性难题。此方法还建立了一系列数值实验来验证所提出下界的鲁棒性和准确性。

Result: 展示了支撑点数量$K(A)$随幅度约束$A$增加而增长的模型，证明了该增长模式为超级线性，并通过使用上述方法有效建立了支撑点数量随幅度约束增加而超级线性增长的下界，这是这一问题上的重要进展。通过理论和计算分析，展示了对于更大的幅度约束，支撑点数量的增加速率将超线性增长，该研究结果将为这一重要通信理论问题提供进一步见解。

Conclusion: 我们的研究为在幅度约束的AWGN信道中，容量实现输入分布的支撑集增长模式提供了一个新的视角。该研究证明了支撑点数量的超级线性增长，并通过建立坚实的理论基础和严格的数学分析展示了支撑点数量随幅度约束增加的下界。此结果不仅适用于通信技术，而且对诸如信号处理等相关领域也有重要意义。总的来说，这是一项不仅在学术上对构建容量理论有所增强，而且对未来通信技术的发展也有重要贡献的开创性工作。

Abstract: We study the growth of the support size of the capacity-achieving input
distribution for the amplitude-constrained additive white Gaussian noise (AWGN)
channel. While it is known since Smith (1971) that the optimal input is
discrete with finitely many mass points, tight bounds on the number of support
points $K(A)$ as the amplitude constraint $A$ increases remain open. Building
on recent work by Dytso \emph{et al.} (2019) and Mattingly \emph{et al.}
(2018), we derive a new analytical lower bound showing that $K(A)$ grows
super-linearly in $A$. Our approach combines total-variation convergence of the
output distribution to the uniform law with quantitative limits on Gaussian
mixture approximation.

</details>


### [110] [MIMO-Zak-OTFS with Superimposed Spread Pilots](https://arxiv.org/abs/2510.20734)
*Abhishek Bairwa,Ananthanarayanan Chockalingam*

Main category: cs.IT

TL;DR: 本文探讨了多输入多输出Zak-OTFS (MIMO-Zak-OTFS)中基于叠加的导频设计和有效信道估计的问题。通过提出了一种通过在交叉模糊域中分离导频序列来优化导频设计的方法，实现了对有效信道系数的准确估计，并通过在信道估计和检测之间进行几个迭代循环来减轻交织导频数据对性能的影响。仿真结果表明，所提出的方案能够获得优异的估计和检测性能。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是在多输入多输出环境中设计有效导频，从而改进信道估计技术，同时最小化导频数据干扰对性能的影响。通过设计一种能有效分离不同传输天线导频序列的方法，可以提高系统的整体性能。

Method: 本方法提出了一种新的导频设计，这在交叉模糊域中实现了导频序列的分离，允许通过简单的读取操作估计有效信道的系数。此外，引入了信道估计和检测之间的迭代（turbo迭代）来进一步减轻导频数据干扰的影响。

Result: 通过进行2x2和3x3 MIMO-Zak-OTFS的仿真实验，证实了使用高斯-sinc脉冲整形滤波器和车辆-A信道模型的所提出的设计方案，在三次迭代下能够实现很好的估计和检测性能。

Conclusion: 所提出的方法有效地提高了在多输入多输出Zak-OTFS系统中导频设计和信道估计的性能，减少导频数据干扰对性能的影响，展示了较好的应用前景。

Abstract: In this paper, we consider the problem of spread pilot design and effective
channel estimation in multiple-input multiple-output Zak-OTFS (MIMO-Zak-OTFS)
with superimposed spread pilots, where data and spread pilot signals are
superimposed in the same frame. To achieve good estimation performance in a
MIMO setting, the spread pilots at different transmit antennas need to be
effectively separated at the receiver. Towards this, we propose a spread pilot
design that separates the pilot sequences in the cross-ambiguity domain and
enables the estimation of the effective channel taps by a simple read-off
operation. To further alleviate the effect of pilot-data interference on
performance, we carry out turbo iterations between channel estimation and
detection. Simulation results for $2\times 2$ and $3\times 3$ MIMO-Zak-OTFS
with Gaussian-sinc pulse shaping filter for vehicular-A channel model show that
the proposed pilot design and estimation scheme with three turbo iterations can
achieve very good estimation/detection performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [111] [Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency](https://arxiv.org/abs/2510.19980)
*Renzhao Liang,Sizhe Xu,Chenggang Xie,Jingru Chen,Feiyang Ren,Shu Yang,Takahiro Yabe*

Main category: cs.LG

TL;DR: 本文提出了一个新颖的解决方案AMRC，通过动态屏蔽损失和表示一致性约束，有效抑制冗余特征学习，并显著提升模型性能。该方法对时间序列预测中的冗余特征学习问题提出了挑战，并提供了新的理论见解和方法论突破。


<details>
  <summary>Details</summary>
Motivation: 深度学习方法在时间序列预测中取得了显著进展，但现有模型在训练过程中容易学习到冗余特征，影响有效信号提取。本文通过系统实验揭示了适当截断历史数据可以提高预测精度这一反常识现象，从而提出解决冗余特征学习的新方法。

Method: 提出Adaptive Masking Loss with Representation Consistency (AMRC)，包括动态屏蔽损失和表示一致性约束两个核心组件。动态屏蔽损失通过自适应识别高度区分性的时间段来引导模型训练中的梯度下降。表示一致性约束稳定了输入、标签和预测之间的映射关系。

Result: 实验结果表明，AMRC可以有效抑制冗余特征学习，同时显著提升模型性能。

Conclusion: 该研究不仅挑战了时间序列建模中的传统假设，还为高效和鲁棒的时间序列预测模型的发展提供了理论见解和方法论突破。

Abstract: Time series forecasting plays a pivotal role in critical domains such as
energy management and financial markets. Although deep learning-based
approaches (e.g., MLP, RNN, Transformer) have achieved remarkable progress, the
prevailing "long-sequence information gain hypothesis" exhibits inherent
limitations. Through systematic experimentation, this study reveals a
counterintuitive phenomenon: appropriately truncating historical data can
paradoxically enhance prediction accuracy, indicating that existing models
learn substantial redundant features (e.g., noise or irrelevant fluctuations)
during training, thereby compromising effective signal extraction. Building
upon information bottleneck theory, we propose an innovative solution termed
Adaptive Masking Loss with Representation Consistency (AMRC), which features
two core components: 1) Dynamic masking loss, which adaptively identified
highly discriminative temporal segments to guide gradient descent during model
training; 2) Representation consistency constraint, which stabilized the
mapping relationships among inputs, labels, and predictions. Experimental
results demonstrate that AMRC effectively suppresses redundant feature learning
while significantly improving model performance. This work not only challenges
conventional assumptions in temporal modeling but also provides novel
theoretical insights and methodological breakthroughs for developing efficient
and robust forecasting models.

</details>


### [112] [From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph](https://arxiv.org/abs/2510.19873)
*Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li*

Main category: cs.LG

TL;DR: 提出了一种名为ReGraphT的框架，用于将大规模语言模型的推理能力转移到小规模模型上，以优化CUDA代码生成，同时减少了隐私风险和计算成本。实验证明，ReGraphT在CUDAEval和ParEval基准测试中的表现优于其他方法，平均速度提升2.33倍。


<details>
  <summary>Details</summary>
Motivation: 旨在解决将大规模语言模型应用于CUDA代码优化时遇到的安全性和成本问题，同时探索小规模模型在特定任务上的潜力。

Method: 通过构建一个结构化的推理图来组织CUDA优化轨迹，并利用蒙特卡洛图搜索进行高效探索。引入了针对CUDA的基准测试集，根据推理的复杂性划分难度等级。

Result: 实验表明，ReGraphT在多个性能指标上超越了现有方法，使得小规模模型能够接近大规模语言模型的性能，同时降低了隐私风险和计算成本。

Conclusion: ReGraphT提供了一种有效的解决方案，使小规模模型能够较好地适应CUDA代码优化的需求，克服了当前在安全性和成本方面的挑战。

Abstract: Despite significant evolution of CUDA programming and domain-specific
libraries, effectively utilizing GPUs with massively parallel engines remains
difficult. Large language models (LLMs) show strong potential in generating
optimized CUDA code from sequential code. However, using LLMs in practice faces
two major challenges: cloud-based APIs pose risks of code leakage, and local
deployment is often computationally expensive and inefficient. These drawbacks
have spurred interest in small language models (SLMs), which are more
lightweight and privacy-friendly. Encouragingly, recent studies show that SLMs
can achieve performance comparable to LLMs on specific tasks. While SLMs can
match LLMs on domain-specific tasks, their limited reasoning abilities lead to
suboptimal performance in complex CUDA generation according to our experiments.
To bridge this gap, we propose ReGraphT, a training-free, retrieval-augmented
generation framework that transfers LLM-level reasoning to smaller models.
ReGraphT organizes CUDA optimization trajectories into a structured reasoning
graph, modeling the combined CUDA optimizations as state transitions, and
leverages Monte Carlo Graph Search (MCGS) for efficient exploration. We also
present a CUDA-specific benchmark with difficulty tiers defined by reasoning
complexity to evaluate models more comprehensively. Experiments show that
ReGraphT outperforms HPC-specific fine-tuned models and other
retrieval-augmented approaches, achieving an average 2.33X speedup on CUDAEval
and ParEval. When paired with DeepSeek-Coder-V2-Lite-Instruct and
Qwen2.5-Coder-7B-Instruct, ReGraphT enables SLMs to approach LLM-level
performance without the associated privacy risks or excessive computing
overhead.

</details>


### [113] [FairGRPO: Fair Reinforcement Learning for Equitable Clinical Reasoning](https://arxiv.org/abs/2510.19893)
*Shiqi Dai,Wei Dai,Jiaee Cheong,Paul Pu Liang*

Main category: cs.LG

TL;DR: 引入了一个新的方法FairGRPO，通过自适应的重要性加权机制，优化跨不同临床人群的公平性学习，这将有助于减少预测中的偏差，特别是在代表不足的群体中。实验表明，相比基准方法，FairGRPO在公平性和性能上都有显著的提升。同时，团队还推出了公平性意识的临床VLLM-FairMedGemma-4B，在保持高性能的同时减少代际差异。


<details>
  <summary>Details</summary>
Motivation: 当前的医疗人工智能系统在不同人口群体中性能表现不同，可能会给代表性不足的人群带来现实的伤害，尤其是在训练数据主要来自多数群体的情况下。论文的动机是通过开发一种新方法来解决这个问题，从而减少预测偏差，促进各个临床群体的公平性学习。

Method: 提出了一种新的方法FairGRPO，基于层级强化学习，采用自适应重要性加权，根据不同人群的样本代表性、任务难度和数据来源进行加权。此外，还引入了无监督聚类技术，以自动发现隐含的人口群体，尤其是在缺少标签的情况下。通过广泛实验，证明了该方法的有效性和优势。

Result: 实验结果表明，FairGRPO在减少预测公平性差异方面比基准方法提高了27.2%，同时F1得分提高了12.49%。此外，还在不同临床数据集中进行了实验验证，展示了其在预测公平性和整体性能方面的提升。

Conclusion: 基于上述方法，团队建立了一种公平性意识的临床大语言模型FairMedGemma-4B，它在保持高性能的同时，显著降低了不同人口群体间的差距，证明了该方法在医疗人工智能领域中的重要性和实用性。

Abstract: Medical artificial intelligence systems have achieved remarkable diagnostic
capabilities, yet they consistently exhibit performance disparities across
demographic groups, causing real-world harm to underrepresented populations.
While recent multimodal reasoning foundation models have advanced clinical
diagnosis through integrated analysis of diverse medical data, reasoning
trainings via reinforcement learning inherit and often amplify biases present
in training datasets dominated by majority populations. We introduce
Fairness-aware Group Relative Policy Optimization (FairGRPO), a hierarchical
reinforcement learning approach that promotes equitable learning across
heterogeneous clinical populations. FairGRPO employs adaptive importance
weighting of advantages based on representation, task difficulty, and data
source. To address the common issue of missing demographic labels in the
clinical domain, we further employ unsupervised clustering, which automatically
discovers latent demographic groups when labels are unavailable. Through
comprehensive experiments across 7 clinical diagnostic datasets spanning 5
clinical modalities across X-ray, CT scan, dermoscropy, mammography and
ultrasound, we demonstrate that FairGRPO reduces predictive parity by 27.2%
against all vanilla and bias mitigated RL baselines, while improving F1 score
by 12.49%. Furthermore, training dynamics analysis reveals that FairGRPO
progressively improves fairness throughout optimization, while baseline RL
methods exhibit deteriorating fairness as training progresses. Based on
FairGRPO, we release FairMedGemma-4B, a fairness-aware clinical VLLM that
achieves state-of-the-art performance while demonstrating significantly reduced
disparities across demographic groups.

</details>


### [114] [FINDER: Feature Inference on Noisy Datasets using Eigenspace Residuals](https://arxiv.org/abs/2510.19917)
*Trajan Murphy,Akshunna S. Dogra,Hanfeng Gu,Caleb Meredith,Mark Kon,Julio Enrique Castrillion-Candas*

Main category: cs.LG

TL;DR: FINDER是一个针对噪声数据集的分类问题进行分析的严格框架，通过随机分析思想优化处理数据的随机性，使用Kosambi-Karhunen-Loève展开（KLE）来分解随机特征并实现噪声数据集上的分类。它在阿尔茨海默病分期分类和远距离森林检测中取得突破成果，优于现有方法。但其也存在限制和失败模式。


<details>
  <summary>Details</summary>
Motivation: 研究噪声数据集的分类方法在理论上和实践中都具有重要意义。结合随机分析思想和希尔伯特空间理论，提出FINDER框架，用于解决噪声数据集的分类问题，实现更准确的分类。

Method: 首先将经验数据视为从基础随机场产生，随后映射到希尔伯特空间，通过Kosambi-Karhunen-Loève展开对随机特征进行分解，分类过程通过特征值分解实现，数据的不同类别位于不同的区域。该方法通过光谱分析确定这些区域。

Result: FINDER框架成功应用于阿尔茨海默病分期分类和远距离森林检测上，并取得突破性成果。

Conclusion: FINDER方法针对噪声数据集在分类问题上表现优越，但它也有潜在的失败模式和限制条件。

Abstract: ''Noisy'' datasets (regimes with low signal to noise ratios, small sample
sizes, faulty data collection, etc) remain a key research frontier for
classification methods with both theoretical and practical implications. We
introduce FINDER, a rigorous framework for analyzing generic classification
problems, with tailored algorithms for noisy datasets. FINDER incorporates
fundamental stochastic analysis ideas into the feature learning and inference
stages to optimally account for the randomness inherent to all empirical
datasets. We construct ''stochastic features'' by first viewing empirical
datasets as realizations from an underlying random field (without assumptions
on its exact distribution) and then mapping them to appropriate Hilbert spaces.
The Kosambi-Karhunen-Lo\'eve expansion (KLE) breaks these stochastic features
into computable irreducible components, which allow classification over noisy
datasets via an eigen-decomposition: data from different classes resides in
distinct regions, identified by analyzing the spectrum of the associated
operators. We validate FINDER on several challenging, data-deficient scientific
domains, producing state of the art breakthroughs in: (i) Alzheimer's Disease
stage classification, (ii) Remote sensing detection of deforestation. We end
with a discussion on when FINDER is expected to outperform existing methods,
its failure modes, and other limitations.

</details>


### [115] [Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets](https://arxiv.org/abs/2510.19950)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 提出了一种新的椭圆不确定性集，以解决强化学习在金融交易中的市场影响问题，该方法在单资产和多资产交易任务中表现出色，并且在交易量增加时仍能保持稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在训练和部署环境间存在不匹配问题，尤其是在金融应用中，因为训练数据与实际市场交易环境中的市场影响不同。传统方法无法捕捉市场影响的方向性特点，导致性能下降。

Method: 开发了一种新的椭圆不确定性集，提供了隐式和显式闭式解，使得在这些不确定性集下的最坏情况能够被有效地评估。

Result: 实验证明，该方法在单资产和多资产交易任务中均能获得更高的夏普比率，并且在增加交易量的情况下仍保持稳健性。

Conclusion: 提出了一个更真实、可扩展的强化学习框架，应用于金融市场，有效地缓解了市场影响带来的性能下降问题。

Abstract: In financial applications, reinforcement learning (RL) agents are commonly
trained on historical data, where their actions do not influence prices.
However, during deployment, these agents trade in live markets where their own
transactions can shift asset prices, a phenomenon known as market impact. This
mismatch between training and deployment environments can significantly degrade
performance. Traditional robust RL approaches address this model
misspecification by optimizing the worst-case performance over a set of
uncertainties, but typically rely on symmetric structures that fail to capture
the directional nature of market impact. To address this issue, we develop a
novel class of elliptic uncertainty sets. We establish both implicit and
explicit closed-form solutions for the worst-case uncertainty under these sets,
enabling efficient and tractable robust policy evaluation. Experiments on
single-asset and multi-asset trading tasks demonstrate that our method achieves
superior Sharpe ratio and remains robust under increasing trade volumes,
offering a more faithful and scalable approach to RL in financial markets.

</details>


### [116] [Beyond the Ideal: Analyzing the Inexact Muon Update](https://arxiv.org/abs/2510.19933)
*Egor Shulgin,Sultan AlRashed,Francesco Orabona,Peter Richtárik*

Main category: cs.LG

TL;DR: 研究提出了对Muon优化器的非理想近似方法的理论分析，通过线性最小化Oracle(LMO)-基础优化模型，引入了误差模型来捕捉实际近似方案的不精确性，并分析了这一不精确性对最优步长和动量的影响，实验结果显示，精度变化会影响最优学习率的选择。


<details>
  <summary>Details</summary>
Motivation: 现有Muon优化器理论分析基于的是理想化且在计算上不可行的精确SVD更新，与实际情况相距甚远。本文旨在通过引入一个现实的误差模型来解决这一理论与实践的脱节，以提供更准确的分析方法。

Method: 基于线性最小化Oracle(LMO)优化框架，该研究引入了WithError模型以捕捉实际近似方法中的误差，并在此基础上分析了Muon优化器中近似正交化方法的性能。

Result: 研究表明，Muon优化器中近似方法的精度会影响最优步长和动量的参数设定，并通过NanoGPT实验验证了这一理论预测。

Conclusion: 该研究提供了一种分析Muon优化器非理想近似方法的新方法，并强调了调整算法中的近似精度与学习率设定之间的重要关系。

Abstract: The Muon optimizer has rapidly emerged as a powerful, geometry-aware
alternative to AdamW, demonstrating strong performance in large-scale training
of neural networks. However, a critical theory-practice disconnect exists:
Muon's efficiency relies on fast, approximate orthogonalization, yet all prior
theoretical work analyzes an idealized, computationally intractable version
assuming exact SVD-based updates. This work moves beyond the ideal by providing
the first analysis of the inexact orthogonalized update at Muon's core. We
develop our analysis within the general framework of Linear Minimization Oracle
(LMO)-based optimization, introducing a realistic additive error model to
capture the inexactness of practical approximation schemes. Our analysis yields
explicit bounds that quantify performance degradation as a function of the LMO
inexactness/error. We reveal a fundamental coupling between this inexactness
and the optimal step size and momentum: lower oracle precision requires a
smaller step size but larger momentum parameter. These findings elevate the
approximation procedure (e.g., the number of Newton-Schulz steps) from an
implementation detail to a critical parameter that must be co-tuned with the
learning schedule. NanoGPT experiments directly confirm the predicted coupling,
with optimal learning rates clearly shifting as approximation precision
changes.

</details>


### [117] [On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization](https://arxiv.org/abs/2510.19953)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 本文提出了一种新的无偏梯度估计器家族，解决了零阶优化中梯度估计器偏置的问题，通过重新表达方向导数为一个收敛级数，并从精心设计的分布中采样，构建了无偏且方差友好的估计器。该方法适用于光滑非凸目标函数，且能实现最优复杂度。实验表明该方法在合成任务和语言模型微调上具有更高的准确性和更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有的零阶优化方法中，大部分梯度估计器存在固有的偏置，除非扰动步长趋于零。因此，本文提出一种新的无偏梯度估计器来解决这一问题，旨在提高零阶优化方法的效率和性能。

Method: 通过将方向导数重新表达为收敛级数，并从精心设计的分布中采样，本文构建了无偏且方差友好的估计器，并分析了其理论性质，推导了四种具体构造的最优比例分布和扰动步长，证明了使用本文所提估量器的SGD算法对于平滑非凸目标函数能实现最优复杂度。

Result: 本文提出的无偏梯度估计器在合成任务和语言模型微调上的实验结果表明，相比于标准方法，该方法具有更高的准确性和更快的收敛速度。

Conclusion: 本文提出了一种新的无偏梯度估计器，解决了零阶优化中的偏置问题，并证明了该估计器的优化算法对于平滑非凸目标函数能实现最优复杂度，实验结果验证了该方法的有效性。

Abstract: Zeroth-order optimization (ZOO) is an important framework for stochastic
optimization when gradients are unavailable or expensive to compute. A
potential limitation of existing ZOO methods is the bias inherent in most
gradient estimators unless the perturbation stepsize vanishes. In this paper,
we overcome this biasedness issue by proposing a novel family of unbiased
gradient estimators based solely on function evaluations. By reformulating
directional derivatives as a telescoping series and sampling from carefully
designed distributions, we construct estimators that eliminate bias while
maintaining favorable variance. We analyze their theoretical properties, derive
optimal scaling distributions and perturbation stepsizes of four specific
constructions, and prove that SGD using the proposed estimators achieves
optimal complexity for smooth non-convex objectives. Experiments on synthetic
tasks and language model fine-tuning confirm the superior accuracy and
convergence of our approach compared to standard methods.

</details>


### [118] [Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via $f$-Differential Privacy](https://arxiv.org/abs/2510.19934)
*Xiang Li,Buxin Su,Chendi Wang,Qi Long,Weijie J. Su*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法来量化去中心化联邦学习中的隐私预算，特别是在$f$-差分隐私框架下，通过Pairwise Network $f$-DP和Secret-based $f$-Local DP两种方法，比Rényi DP方法提供了更紧的$(ε,δ)$界限和更好的实用性


<details>
  <summary>Details</summary>
Motivation: 精确评估联邦学习中的隐私预算在面对复杂的算法组件如去中心化通信和本地更新时变得困难。本文旨在解决去中心化联邦学习算法的隐私量化问题

Method: 本文开发了两种新的基于$f$-DP的方法：Pairwise Network $f$-DP和Secret-based $f$-Local DP，分别适用于随机游走通信和结构化噪音注入。这些方法结合了$f$-DP理论和马尔可夫链集中度工具，有效地捕获隐私放大效应

Result: 实验结果表明，本文提出的方法比Rényi DP方法提供了更紧的隐私界限和更好的实用性

Conclusion: 基于$f$-DP的隐私会计框架能够提供更精确的隐私预算评估，这在去中心化联邦学习中非常重要

Abstract: Differentially private (DP) decentralized Federated Learning (FL) allows
local users to collaborate without sharing their data with a central server.
However, accurately quantifying the privacy budget of private FL algorithms is
challenging due to the co-existence of complex algorithmic components such as
decentralized communication and local updates. This paper addresses privacy
accounting for two decentralized FL algorithms within the $f$-differential
privacy ($f$-DP) framework. We develop two new $f$-DP-based accounting methods
tailored to decentralized settings: Pairwise Network $f$-DP (PN-$f$-DP), which
quantifies privacy leakage between user pairs under random-walk communication,
and Secret-based $f$-Local DP (Sec-$f$-LDP), which supports structured noise
injection via shared secrets. By combining tools from $f$-DP theory and Markov
chain concentration, our accounting framework captures privacy amplification
arising from sparse communication, local iterations, and correlated noise.
Experiments on synthetic and real datasets demonstrate that our methods yield
consistently tighter $(\epsilon,\delta)$ bounds and improved utility compared
to R\'enyi DP-based approaches, illustrating the benefits of $f$-DP in
decentralized privacy accounting.

</details>


### [119] [Are Greedy Task Orderings Better Than Random in Continual Linear Regression?](https://arxiv.org/abs/2510.19941)
*Matan Tsipory,Ran Levinstein,Itay Evron,Mark Kong,Deanna Needell,Daniel Soudry*

Main category: cs.LG

TL;DR: 研究分析了在持续学习中的线性回归任务排序，特别是最大化任务间差异的贪心排序方法，实验表明此类排序相比随机排序加快了收敛速度，但在不同条件下也有不同的性能表现


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索最大化任务间差异的贪心排序在持续学习中的效果，相比此前简要讨论过的内容，这一问题是未解的

Method: 结合Kaczmarz方法理论，正式定义并发展此类排序的几何和代数直觉。通过线性回归与CIFAR-100线性探测任务的实验，证明贪心排序比随机排序更快减小损失函数

Result: 在高秩回归设置中，证明了贪心排序与随机排序具有相似的损失边界。但在一般秩下，区分表现取决于重复次数。单次遍历的贪心排序可能表现糟糕，而允许重复则呈现三阶根号收敛速度

Conclusion: 揭示了贪心排序与随机排序的内在差异，并表明在部分条件下贪心排序有明显益处

Abstract: We analyze task orderings in continual learning for linear regression,
assuming joint realizability of training data. We focus on orderings that
greedily maximize dissimilarity between consecutive tasks, a concept briefly
explored in prior work but still surrounded by open questions. Using tools from
the Kaczmarz method literature, we formalize such orderings and develop
geometric and algebraic intuitions around them. Empirically, we demonstrate
that greedy orderings converge faster than random ones in terms of the average
loss across tasks, both for linear regression with random data and for linear
probing on CIFAR-100 classification tasks. Analytically, in a high-rank
regression setting, we prove a loss bound for greedy orderings analogous to
that of random ones. However, under general rank, we establish a
repetition-dependent separation. Specifically, while prior work showed that for
random orderings, with or without replacement, the average loss after $k$
iterations is bounded by $\mathcal{O}(1/\sqrt{k})$, we prove that single-pass
greedy orderings may fail catastrophically, whereas those allowing repetition
converge at rate $\mathcal{O}(1/\sqrt[3]{k})$. Overall, we reveal nuances
within and between greedy and random orderings.

</details>


### [120] [Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations](https://arxiv.org/abs/2510.19975)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 本文探讨了两点零阶梯度估计器，并确定了随机扰动分布，该分布使估计器的渐近方差最小化。我们发现，期望的扰动可以沿真实梯度的方向对齐，而不是保持固定的长度。我们还研究了方向对齐的扰动（DAP）方案的理论和实证特性，并提供了使用$	extdelta$无偏随机扰动的随机梯度下降法的收敛性分析。实证结果表明，在特定条件下，DAP方案优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在现有研究大多集中在固定长度的扰动时，论文发现了方向对齐的潜力，即扰动可以沿真实梯度的方向对齐，而不是固定的长度。这指出了一个未被充分研究的潜在优势，因此深入研究方向对齐的扰动方案（DAP）的特性和随机梯度下降法的收敛性。

Method: 论文提出了一个约束泛函优化问题，用于研究最小化两点零阶梯度估计器随扰动步长变小时的渐近方差的随机扰动分布。我们还提供了使用$	extdelta$无偏随机扰动的随机梯度下降法的收敛性分析。此外，我们通过合成问题和实际任务对DAP方案进行了实证评估。

Result: 通过实证研究，论文证明了在特定条件下，方向对齐的扰动方案（DAP）优于传统方法。同时，论文还扩展了现有复杂度界限，使其适用于更广泛的扰动情况。

Conclusion: 论文展示了方向对齐的扰动方案的潜在优势，并证明了它在特定条件下的优越性。

Abstract: In this paper, we explore the two-point zeroth-order gradient estimator and
identify the distribution of random perturbations that minimizes the
estimator's asymptotic variance as the perturbation stepsize tends to zero. We
formulate it as a constrained functional optimization problem over the space of
perturbation distributions. Our findings reveal that such desired perturbations
can align directionally with the true gradient, instead of maintaining a fixed
length. While existing research has largely focused on fixed-length
perturbations, the potential advantages of directional alignment have been
overlooked. To address this gap, we delve into the theoretical and empirical
properties of the directionally aligned perturbation (DAP) scheme, which
adaptively offers higher accuracy along critical directions. Additionally, we
provide a convergence analysis for stochastic gradient descent using
$\delta$-unbiased random perturbations, extending existing complexity bounds to
a wider range of perturbations. Through empirical evaluations on both synthetic
problems and practical tasks, we demonstrate that DAPs outperform traditional
methods under specific conditions.

</details>


### [121] [ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models](https://arxiv.org/abs/2510.20084)
*Bosong Huang,Ming Jin,Yuxuan Liang,Johan Barthelemy,Debo Cheng,Qingsong Wen,Chenghao Liu,Shirui Pan*

Main category: cs.LG

TL;DR: 通过将时间序列划分为由核心形状子序列驱动的重要片段，并利用Shapley值评估它们的重要性，ShapeX框架提供了一个创新的时间序列解释方法，这种方法可以揭示因果关系，而不仅仅是相关性。实验表明，ShapeX在识别最相关子序列方面优于现有方法，提高了时间序列解释的精确度和因果准确性。


<details>
  <summary>Details</summary>
Motivation: 目前的时间序列解释方法主要集中在时序特征的贡献度上，而忽视了时间序列分类主要由关键形状子序列驱动这一基本事实。为了填补这一缺失，研究者们提出了ShapeX框架，旨在为时间序列提供更深入、更准确的解释方法，尤其是在医疗和金融这类高风险应用中，透明度和信任是至关重要的。

Method: ShapeX框架的核心是Shapelet Describe-and-Detect (SDD)框架，它能够有效地学习一组对于分类而言必不可少的形状子序列，并且能够将时间序列划分为由这些形状子序列驱动的重要片段。通过Shapley值，ShapeX能够评估这些片段的重要性，从而提供一个深入的、基于因果关系的解释，而不是简单的相关性解释。

Result: 实验结果表明，相比于现有的时间序列解释方法，ShapeX能够在识别最相关子序列和提高时间序列解释的因果真实性方面表现出色，从而增强了解释的精度和可信度。

Conclusion: 本文提出了一种新的时间序列解释框架ShapeX，通过利用形状子序列驱动的片段划分和Shapley值评估其重要性，以期提供更精确和更具有因果关系的解释，克服了现有方法无法识别关键形状子序列的问题。

Abstract: Explaining time series classification models is crucial, particularly in
high-stakes applications such as healthcare and finance, where transparency and
trust play a critical role. Although numerous time series classification
methods have identified key subsequences, known as shapelets, as core features
for achieving state-of-the-art performance and validating their pivotal role in
classification outcomes, existing post-hoc time series explanation (PHTSE)
methods primarily focus on timestep-level feature attribution. These
explanation methods overlook the fundamental prior that classification outcomes
are predominantly driven by key shapelets. To bridge this gap, we present
ShapeX, an innovative framework that segments time series into meaningful
shapelet-driven segments and employs Shapley values to assess their saliency.
At the core of ShapeX lies the Shapelet Describe-and-Detect (SDD) framework,
which effectively learns a diverse set of shapelets essential for
classification. We further demonstrate that ShapeX produces explanations which
reveal causal relationships instead of just correlations, owing to the
atomicity properties of shapelets. Experimental results on both synthetic and
real-world datasets demonstrate that ShapeX outperforms existing methods in
identifying the most relevant subsequences, enhancing both the precision and
causal fidelity of time series explanations.

</details>


### [122] [Towards Strong Certified Defense with Universal Asymmetric Randomization](https://arxiv.org/abs/2510.19977)
*Hanbin Hong,Ashish Kundu,Ali Payani,Binghui Wang,Yuan Hong*

Main category: cs.LG

TL;DR: 提出了一种名为UCAN的新技术，通过使用各向异性噪声增强随机平滑，从而提高机器学习模型对抗敌意攻击的认证鲁棒性。UCAN可以用于增强现有的随机平滑方法，并且其理论框架适用于各种噪声分布，通过针对性的噪声注入，保证分类器在扰动输入上的预测具有可证明的鲁棒性边界。实验结果表明，UCAN在MNIST、CIFAR10和ImageNet数据集上相较于现有最佳方法的认证准确度提高了最多182.6%。


<details>
  <summary>Details</summary>
Motivation: 现有的随机平滑方法主要使用各向同性的噪声分布，这种分布忽略了输入数据维度的异质性。为了克服这一局限性，本文提出了UCAN，一种通用的、各向异性的噪声认证敌意鲁棒性的技术，旨在提高机器学习模型的防御能力，尤其是对抗敌意攻击的能力，从而提升模型的认证鲁棒性。

Method: 提出了一个灵活的理论框架，该框架支持各种噪声分布，可以针对不同的l_p范数提供认证鲁棒性，适用于任意分类器，并通过定制噪声注入保证分类器在扰动输入上的预测具有可证明的鲁棒性边界。开发了具有三个示例噪声参数生成器的新框架，用于优化各向异性噪声参数以适应不同的数据维度和实际应用中的不同鲁棒性增强水平。

Result: 实证评估表明UCAN的性能明显优于现有的最佳方法，在MNIST，CIFAR10和ImageNet数据集上，认证准确性提高了最多182.6%。

Conclusion: UCAN通过引入各向异性的噪声提升了随机平滑的鲁棒性认证能力，这一技术的应用使机器学习模型更能抵御敌意攻击，并在实验中展示了显著的性能提升。

Abstract: Randomized smoothing has become essential for achieving certified adversarial
robustness in machine learning models. However, current methods primarily use
isotropic noise distributions that are uniform across all data dimensions, such
as image pixels, limiting the effectiveness of robustness certification by
ignoring the heterogeneity of inputs and data dimensions. To address this
limitation, we propose UCAN: a novel technique that \underline{U}niversally
\underline{C}ertifies adversarial robustness with \underline{A}nisotropic
\underline{N}oise. UCAN is designed to enhance any existing randomized
smoothing method, transforming it from symmetric (isotropic) to asymmetric
(anisotropic) noise distributions, thereby offering a more tailored defense
against adversarial attacks. Our theoretical framework is versatile, supporting
a wide array of noise distributions for certified robustness in different
$\ell_p$-norms and applicable to any arbitrary classifier by guaranteeing the
classifier's prediction over perturbed inputs with provable robustness bounds
through tailored noise injection. Additionally, we develop a novel framework
equipped with three exemplary noise parameter generators (NPGs) to optimally
fine-tune the anisotropic noise parameters for different data dimensions,
allowing for pursuing different levels of robustness enhancements in
practice.Empirical evaluations underscore the significant leap in UCAN's
performance over existing state-of-the-art methods, demonstrating up to
$182.6\%$ improvement in certified accuracy at large certified radii on MNIST,
CIFAR10, and ImageNet datasets.\footnote{Code is anonymously available at
\href{https://github.com/youbin2014/UCAN/}{https://github.com/youbin2014/UCAN/}}

</details>


### [123] [Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications](https://arxiv.org/abs/2510.20019)
*Curtis Lee Shull,Merrick Green*

Main category: cs.LG

TL;DR: 本文提出了一种基于监督学习的RFID信号强度指示(RSSI)数据分类方法，通过决策树算法在CAD模型中模拟了一种新的实验室区域定位方法。尽管实现了34.2%的整体准确性，但稀有类别的误分类问题仍存在，研究认为通过改善天线布局或融合其他传感器数据可以进一步提高定位准确性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提高军事资产存储的安全性，通过改进RFID技术中的位置检测来减少误报，以符合国防物资存储的安全指引要求。缺点如长距离检测、仿冒和伪造导致了操作安全事件的发生，因此尝试通过更具体的数据学习提高定位精度。

Method: 采用决策树分类算法，通过调整权值来解决多类别不平衡问题，仿真实验在一个仿真环境（包含12个实验区域）中进行，训练集样本5000个。通过计算邻域感知混淆矩阵来提高对物理相邻区域的理解。

Result: 模型在多个区域（如F、G、H等）达到了超过0.40的F1得分，但稀有类别的误分类率较高。这表明基于RSSI的决策树分类在模拟情境中可应用以实现区域级别的异常检测或误置监控。可靠分类性能在覆盖度和信号强度较低的区域可通过更好的天线布置或更多传感器的使用得到提高。

Conclusion: 通过监督学习和决策树算法，可以有效改善基于RSSI的RFID系统中对于低覆盖率和低信号区域的定位精度，并提高整体安全性。

Abstract: Radio Frequency Identification (RFID) tracking may be a viable solution for
defense assets that must be stored in accordance with security guidelines.
However, poor sensor specificity (vulnerabilities include long range detection,
spoofing, and counterfeiting) can lead to erroneous detection and operational
security events. We present a supervised learning simulation with realistic
Received Signal Strength Indicator (RSSI) data and Decision Tree classification
in a Computer Assisted Design (CAD)-modeled floor plan that encapsulates some
of the challenges encountered in defense storage. In this work, we focused on
classifying 12 lab zones (LabZoneA-L) to perform location inference. The raw
dataset had approximately 980,000 reads. Class frequencies were imbalanced, and
class weights were calculated to account for class imbalance in this
multi-class setting. The model, trained on stratified subsamples to 5,000
balanced observations, yielded an overall accuracy of 34.2% and F1-scores
greater than 0.40 for multiple zones (Zones F, G, H, etc.). However, rare
classes (most notably LabZoneC) were often misclassified, even with the use of
class weights. An adjacency-aware confusion matrix was calculated to allow
better interpretation of physically adjacent zones. These results suggest that
RSSI-based decision trees can be applied in realistic simulations to enable
zone-level anomaly detection or misplacement monitoring for defense supply
logistics. Reliable classification performance in low-coverage and low-signal
zones could be improved with better antenna placement or additional sensors and
sensor fusion with other modalities.

</details>


### [124] [Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset](https://arxiv.org/abs/2510.20209)
*Shumin Li*

Main category: cs.LG

TL;DR: 早期犬癌筛查工具的开发在兽医医学中具有重要意义。本研究使用黄金寻回犬寿命研究（GRLS）队列评估了癌症风险分类的可行性，并进行了全面的基准评估，比较了126种分析管道。最优模型显示了中等的排序能力但临床分类表现不佳。研究指出，尽管统计上可以检测到癌症信号，但其太弱且具有混淆性，无法从中区分正常的衰老或其他炎症条件。因此，未来的研究需要整合多模态数据源。


<details>
  <summary>Details</summary>
Motivation: 开发宠物犬早期癌症筛查工具的挑战之一在于常规实验室数据中的生物标志物非特异性以及筛选人群中的严重类别不平衡问题。因此，本研究意在评估使用常规实验室数据进行癌症风险分类的可行性。

Method: 本研究进行了系统的126种分析管道比较，包括各种机器学习模型、特征选择方法和数据平衡技术。数据按照患者分隔以防止数据泄露。最终选择了一个逻辑回归分类器，带类别加权和递归特征消除。

Result: 最优模型展示了中等的排序能力（AUROC = 0.815），但其临床分类效果不佳（F1-score = 0.25）。虽然实现了高阴性预测值（0.98），但召回率不足（0.79），这表示该模型暂不能作为可靠的排除测试。

Conclusion: 研究表明常规实验室数据中存在可检测的癌症信号，然而信号过于弱且受到混淆，无法可靠地区分正常的衰老或其他炎症条件。研究得出结论，在单一的数据模式下进行进一步研究有一定的性能上限，未来须整合多模态数据源以取得有意义的进展。

Abstract: The development of accessible screening tools for early cancer detection in
dogs represents a significant challenge in veterinary medicine. Routine
laboratory data offer a promising, low-cost source for such tools, but their
utility is hampered by the non-specificity of individual biomarkers and the
severe class imbalance inherent in screening populations. This study assesses
the feasibility of cancer risk classification using the Golden Retriever
Lifetime Study (GRLS) cohort under real-world constraints, including the
grouping of diverse cancer types and the inclusion of post-diagnosis samples. A
comprehensive benchmark evaluation was conducted, systematically comparing 126
analytical pipelines that comprised various machine learning models, feature
selection methods, and data balancing techniques. Data were partitioned at the
patient level to prevent leakage. The optimal model, a Logistic Regression
classifier with class weighting and recursive feature elimination, demonstrated
moderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical
classification performance (F1-score = 0.25, Positive Predictive Value = 0.15).
While a high Negative Predictive Value (0.98) was achieved, insufficient recall
(0.79) precludes its use as a reliable rule-out test. Interpretability analysis
with SHapley Additive exPlanations (SHAP) revealed that predictions were driven
by non-specific features like age and markers of inflammation and anemia. It is
concluded that while a statistically detectable cancer signal exists in routine
lab data, it is too weak and confounded for clinically reliable discrimination
from normal aging or other inflammatory conditions. This work establishes a
critical performance ceiling for this data modality in isolation and
underscores that meaningful progress in computational veterinary oncology will
require integration of multi-modal data sources.

</details>


### [125] [SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph](https://arxiv.org/abs/2510.20022)
*Jiazheng Li,Yawei Wang,David Yan,Yijun Tian,Zhichao Xu,Huan Song,Panpan Xu,Lin Lee Cheong*

Main category: cs.LG

TL;DR: 提出了一种新的轻量级框架SALT，用于解决大语言模型在复杂任务中遇到的问题，特别是在基于组的强化学习算法中。SALT通过构建轨迹图，提供更细粒度的收益分配，从而改进了这些算法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前主流的基于强化学习的方法侧重于稀疏、基于结果的奖励，在没有评论模型的组为基础的强化学习算法（如GRPO）中，这种方法会导致培训不稳定和次优政策，因为有益和有害的动作在多步交互中是纠缠在一起的。为解决这个问题，提出了SALT框架。

Method: SALT通过构建相同提示的轨迹图进行更细粒度的优势分配，此分配只基于结果奖励。SALT设计为无需修改现有组为基础的强化学习算法的rollout过程，且对计算开销的增加可忽略不计的插件模块。

Result: 在WebShop，ALFWorld，AppWorld基准测试中，无论模型大小如何，SALT都能改善性能。

Conclusion: SALT提高了基于组的强化学习算法的稳定性与表现，展示了在大量实验中的有效性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities,
enabling language agents to excel at single-turn tasks. However, their
application to complex, multi-step, and long-horizon tasks remains challenging.
While reinforcement learning (RL) offers a promising avenue for addressing
these challenges, mainstream approaches typically rely solely on sparse,
outcome-based rewards, a limitation that becomes especially problematic for
group-based RL algorithms lacking critic models, such as Group Relative Policy
Optimization (GRPO). In such methods, uniformly rewarding or penalizing all
actions within a trajectory can lead to training instability and suboptimal
policies, because beneficial and detrimental actions are often entangled across
multi-step interactions. To address this challenge, we propose SALT, a novel
and lightweight framework that provides a finer-grained advantage assignment,
derived solely from outcome rewards. We achieve this by constructing a graph
from trajectories of the same prompt, which allows us to quantify the quality
of each step and assign advantages accordingly. Crucially, SALT is designed as
a plug-and-play module that seamlessly integrates with existing group-based RL
algorithms, requiring no modifications to the rollout procedure and introducing
negligible computational overhead. Extensive experiments on the WebShop,
ALFWorld, and AppWorld benchmarks with various model sizes demonstrate that
SALT consistently improves performance. We also conduct a thorough analysis to
validate the design choices behind SALT and offer actionable insights.

</details>


### [126] [QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models](https://arxiv.org/abs/2510.20222)
*Hao Wang,Baojun Ma*

Main category: cs.LG

TL;DR: QKCV注意力机制通过引入静态类别嵌入，提高了基于注意力的时间序列预测模型的准确性，并且在微调时表现出色，减少了计算开销。


<details>
  <summary>Details</summary>
Motivation: 引入了QKCV注意力机制，以更好地利用类别信息来捕捉数据中的固有模式，提高时间序列预测的准确性。

Method: 提出了QKCV注意力机制，它是传统QKV框架的扩展，加入了静态类别嵌入C来强调特定类别的信息。此机制被设计为一个具有兼容性的插件模块，能够增强基于注意力的时间序列预测模型的预测准确性。同时展示了在微调单变量时间序列基础模型时，通过仅更新静态嵌入C，保留预训练的权重，实现更低的计算开销和更好的微调性能。

Result: QKCV在多种现实世界的数据集上提高了注意力模型（如Vanilla Transformer、Informer、PatchTST、TFT）的时间序列预测准确度，并且通过微调展示了其优越性，特别是在减少计算开销方面。

Conclusion: QKCV作为一个有效的插件模块，能够显著提升时间序列预测的准确性，并且在微调方面表现出色，减少了计算开销，显示了广泛的应用前景。

Abstract: In real-world time series forecasting tasks, category information plays a
pivotal role in capturing inherent data patterns. This paper introduces QKCV
(Query-Key-Category-Value) attention, an extension of the traditional QKV
framework that incorporates a static categorical embedding C to emphasize
category-specific information. As a versatile plug-in module, QKCV enhances the
forecasting accuracy of attention-based models (e.g., Vanilla Transformer,
Informer, PatchTST, TFT) across diverse real-world datasets. Furthermore, QKCV
demonstrates remarkable adaptability in fine-tuning univariate time series
foundation model by solely updating the static embedding C while preserving
pretrained weights, thereby reducing computational overhead and achieving
superior fine-tuning performance.

</details>


### [127] [Speculative Sampling for Parametric Temporal Point Processes](https://arxiv.org/abs/2510.20031)
*Marin Biloš,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

TL;DR: 本文提出了一种基于拒绝采样的新算法，可以在不改变架构或重新训练的情况下，从现有的TPP模型并行地精确采样多个未来值，从而在实际数据集上实现了速度提升，弥合了表达性建模与高效并行生成之间的差距。


<details>
  <summary>Details</summary>
Motivation: 目前的TPP模型依赖于自回归模型进行采样，这种做法在时间序列数据中存在效率低下的问题。因此，作者提出了一种新的算法来解决这个问题，提高采样效率。

Method: 本文提出了一种基于拒绝采样的新算法，该算法可以在并行模式下从现有的TPP模型中精确采样多个未来值，而不需要改变架构或重新训练模型。

Result: 实验证明，该方法在实际数据集上取得了速度提升，证明了该方法的有效性。通过这种方式，方法不仅仅在理论上提供了保证，还在实践中填补了TPP应用中表达性建模与高效并行生成之间的空白。

Conclusion: 本文通过提出一种新的基于拒绝采样的算法，成功提高了TPP模型的采样效率，既在理论上保证了精确性，也在实践中实现了速度提升。

Abstract: Temporal point processes are powerful generative models for event sequences
that capture complex dependencies in time-series data. They are commonly
specified using autoregressive models that learn the distribution of the next
event from the previous events. This makes sampling inherently sequential,
limiting efficiency. In this paper, we propose a novel algorithm based on
rejection sampling that enables exact sampling of multiple future values from
existing TPP models, in parallel, and without requiring any architectural
changes or retraining. Besides theoretical guarantees, our method demonstrates
empirical speedups on real-world datasets, bridging the gap between expressive
modeling and efficient parallel generation for large-scale TPP applications.

</details>


### [128] [Learning Personalized Ad Impact via Contextual Reinforcement Learning under Delayed Rewards](https://arxiv.org/abs/2510.20055)
*Yuwei Cheng,Zifeng Zhao,Haifeng Xu*

Main category: cs.LG

TL;DR: 本文提出了一个结合延迟泊松奖励的上下文马尔可夫决策过程模型，并设计了一个强化学习算法来实现高效的个性化出价策略，该策略在理论上实现了近似最优的遗憾界限。通过模拟实验验证了理论发现的正确性。


<details>
  <summary>Details</summary>
Motivation: 在线广告平台需要有效的出价策略来最大化利润。准确的广告影响估计需要考虑延迟和长期效果、累计广告影响如强化或疲劳、以及客户异质性等关键因素。既往研究往往没有共同考虑这些因素。

Method: 本文将广告出价建模为具有延迟泊松奖励的上下文马尔可夫决策过程，并提出了一种结合数据分割策略的两阶段最大似然估计器。在此基础上，设计了强化学习算法来推导有效、个性化的出价策略。

Result: 该方法实现了近似最优的遗憾界限为$\tilde{O}{(dH^2\sqrt{T})}$。理论发现通过模拟实验得到验证。

Conclusion: 研究设计了一种新的框架用于广告竞价策略优化，有效解决了因广泛存在的广告延迟效果而难以估计广告影响的问题。

Abstract: Online advertising platforms use automated auctions to connect advertisers
with potential customers, requiring effective bidding strategies to maximize
profits. Accurate ad impact estimation requires considering three key factors:
delayed and long-term effects, cumulative ad impacts such as reinforcement or
fatigue, and customer heterogeneity. However, these effects are often not
jointly addressed in previous studies. To capture these factors, we model ad
bidding as a Contextual Markov Decision Process (CMDP) with delayed Poisson
rewards. For efficient estimation, we propose a two-stage maximum likelihood
estimator combined with data-splitting strategies, ensuring controlled
estimation error based on the first-stage estimator's (in)accuracy. Building on
this, we design a reinforcement learning algorithm to derive efficient
personalized bidding strategies. This approach achieves a near-optimal regret
bound of $\tilde{O}{(dH^2\sqrt{T})}$, where $d$ is the contextual dimension,
$H$ is the number of rounds, and $T$ is the number of customers. Our
theoretical findings are validated by simulation experiments.

</details>


### [129] [Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach](https://arxiv.org/abs/2510.20235)
*Woohyeon Byeon,Giseung Park,Jongseong Chae,Amir Leshem,Youngchul Sung*

Main category: cs.LG

TL;DR: 本文提出了一种适用于最大最小多目标强化学习的收敛性和实用框架，并从博弈论角度将其重新构造成一个两玩家零和优化连续博弈，提出了基于镜像下降算法的高效方法，简化了策略更新并确保全局渐近收敛，同时提供了完整的理论分析，并在表格环境中和深度强化学习中展示了该算法的收敛行为与之前的基线方法相比有显著提高的性能。


<details>
  <summary>Details</summary>
Motivation: 这个研究的动机是为了提出一种能够解决最大最小多目标强化学习问题的方法，这种方法可以从博弈论的视角重新定义为一个两玩家零和优化连续博弈，以便建立一个实用且理论上可靠的框架来解决多目标强化学习中的一类问题。

Method: 文中使用镜像下降算法，并对该算法进行了改进加入了自适应正则化，从而形成了一个高效的策略更新机制，同时减少了算法运算过程中需要的迭代次数，确保了全局渐近收敛。

Result: 通过理论分析和实验验证，证明了所提出的算法在表格设置和深度强化学习的实验中具备良好的全局收敛性能，且在许多多目标强化学习环境中优于现有的基线方法。

Conclusion: 提出的框架和算法能够在多目标强化学习任务中提供一条实用且理论上坚实的解决方案路径，具有更高效的策略更新机制和更好的全局收敛性。

Abstract: In this paper, we propose a provably convergent and practical framework for
multi-objective reinforcement learning with max-min criterion. From a
game-theoretic perspective, we reformulate max-min multi-objective
reinforcement learning as a two-player zero-sum regularized continuous game and
introduce an efficient algorithm based on mirror descent. Our approach
simplifies the policy update while ensuring global last-iterate convergence. We
provide a comprehensive theoretical analysis on our algorithm, including
iteration complexity under both exact and approximate policy evaluations, as
well as sample complexity bounds. To further enhance performance, we modify the
proposed algorithm with adaptive regularization. Our experiments demonstrate
the convergence behavior of the proposed algorithm in tabular settings, and our
implementation for deep reinforcement learning significantly outperforms
previous baselines in many MORL environments.

</details>


### [130] [Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs](https://arxiv.org/abs/2510.20064)
*Hongyi Liu,Jiaji Huang,Zhen Jia,Youngsuk Park,Yu-Xiang Wang*

Main category: cs.LG

TL;DR: 本文提出了一种在线选择模型的方法，该方法可以在推测解码中有效地选择最佳的草案模型，从而提高LLM的推理效率。无论是在令牌接受概率还是预期接受长度方面，该方法都能与最佳模型竞争，并且能够在不增加额外查询的情况下准确评估所有草案模型，显著优于现有的基于多臂赌博机的方法。此外，根据实验结果，本文的方法在多个领域，特别是在需要长推理链的情况中，显著优于现有最佳方法EAGLE3和BanditSpec基准。


<details>
  <summary>Details</summary>
Motivation: 在推测解码中在线选择最佳模型可以加速大语言模型（LLM）的推理过程，提高效率。同时，有效地评估所有可能的模型而不增加额外的计算开销是必要的。传统的多臂赌博机方法无法满足这些需求，因此提出了一种新的在线学习算法来解决此问题。

Method: 本文提出了一种新的在线学习算法，可以在线选择最佳草案模型并准确评估所有草案模型。此方法可以适用于任何推测解码方法，包括单次草案、多次草案和树状草案。同时，还设计了系统高效的在线学习者版本，以减少计算和延迟的开销。通过实验验证了该方法的有效性。

Result: 实验结果表明，该方法在多个LLM和不同数据集上，特别是在需要长推理链的情况下，显著优于EAGLE3和BanditSpec方法。这表明该方法不仅能够提高令牌接受概率，还能减少预期接受长度，并且在处理复杂推理任务时具有更好的鲁棒性和效率。

Conclusion: 本文提出的在线模型选择方法在推测解码中具有重要应用价值，特别是在涉及长推理链的任务中。该方法通过减少额外查询的成本提供了一种有效的方法来改善推测解码，进而提高LLM的推理性能。

Abstract: Speculative decoding is widely used in accelerating large language model
(LLM) inference. In this work, we focus on the online draft model selection
problem in speculative decoding. We design an algorithm that provably competes
with the best draft model in hindsight for each query in terms of either the
token acceptance probability or expected acceptance length. In particular, we
show that we can accurately evaluate all draft models, instead of only the
chosen model without incurring additional queries to the target model, which
allows us to improve exponentially over the existing bandit-based approach as
the number of draft models increases. Our approach is generically applicable
with any speculative decoding methods (single draft, multi-drafts and
draft-trees). Moreover, we design system-efficient versions of online learners
and demonstrate that the overhead in computation and latency can be
substantially reduced. We conduct extensive experiments on open-source LLMs and
diverse datasets, demonstrating that our methods substantially outperform the
state-of-the-art EAGLE3 and the BanditSpec baseline in a variety of domains
where specialized domain-expert drafters are available, especially when long
reasoning chains are required.

</details>


### [131] [What Does It Take to Build a Performant Selective Classifier?](https://arxiv.org/abs/2510.20242)
*Stephan Rabanser,Nicolas Papernot*

Main category: cs.LG

TL;DR: 论文提出了一种将选择性分类差距分解为五个不同来源的方法，揭示了单调后校准在减少该差距方面的作用有限，并通过实验证明了有效的重新排序预测机制对于逼近理想行为的重要性。


<details>
  <summary>Details</summary>
Motivation: 该论文的主要动机是理解选择性分类方法的性能差距，并寻找一种新的方式来减少这种差距，从而使得模型在不确定性较高的情况下也能表现得更好。通过这种方式，可以提升模型的可靠性和预测的准确性。

Method: 论文提出了一个选择性分类差距的理论框架，并将其分解为五个不同的来源：贝叶斯噪声、近似误差、排名误差、统计噪声和由实施或数据分布变化引入的余量。此外，作者通过合成数据和现实世界的数据集进行了验证。

Result: 研究表明，贝叶斯噪声和有限的模型容量可以导致显著的差距，仅通过单调后校准很难解决；而更丰富的特征感知校准器才能有效改善评分排序；此外，数据分布的变化会引入额外的差距，需要通过分布健壮的训练来防止。

Conclusion: 论文总结了构建接近理想行为的选择性分类器的设计指导原则，提出了一种量化的误差预算，并强调了重新排序预测的重要性，而不只是简单的重标预测。

Abstract: Selective classifiers improve model reliability by abstaining on inputs the
model deems uncertain. However, few practical approaches achieve the
gold-standard performance of a perfect-ordering oracle that accepts examples
exactly in order of correctness. Our work formalizes this shortfall as the
selective-classification gap and present the first finite-sample decomposition
of this gap to five distinct sources of looseness: Bayes noise, approximation
error, ranking error, statistical noise, and implementation- or shift-induced
slack. Crucially, our analysis reveals that monotone post-hoc calibration --
often believed to strengthen selective classifiers -- has limited impact on
closing this gap, since it rarely alters the model's underlying score ranking.
Bridging the gap therefore requires scoring mechanisms that can effectively
reorder predictions rather than merely rescale them. We validate our
decomposition on synthetic two-moons data and on real-world vision and language
benchmarks, isolating each error component through controlled experiments. Our
results confirm that (i) Bayes noise and limited model capacity can account for
substantial gaps, (ii) only richer, feature-aware calibrators meaningfully
improve score ordering, and (iii) data shift introduces a separate slack that
demands distributionally robust training. Together, our decomposition yields a
quantitative error budget as well as actionable design guidelines that
practitioners can use to build selective classifiers which approximate ideal
oracle behavior more closely.

</details>


### [132] [Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs](https://arxiv.org/abs/2510.20272)
*Tristan Cinquin,Geoff Pleiss,Agustinus Kristiadi*

Main category: cs.LG

TL;DR: 我们提出了一种自适应算法来最大化过程奖励模型（PRM）得分，并通过树搜索探索多个部分解决方案路径，以改善数学推理。虽然基于PRM的树搜索没有在统计上显著优于传统的Best-of-N方法，但蒙特卡洛树搜索和束搜索方法的表现优于其他基于PRM的树搜索方法。研究还发现，PRM在状态值估计和出界分布泛化上有局限性，提示需要不同的奖励建模来改进LLM中的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前的数学推理方法存在线性结构，未能充分模拟复杂问题解决过程中的分支和探索特性。因此，该研究旨在通过探索基于过程奖励模型的树搜索方法，以寻找改进数学推理的有效途径。目的是提高大型语言模型（LLMs）的数学推理能力，通过探索不同的解决方案路径来提升其性能。

Method: 采用了自适应算法最大化过程奖励模型（PRM）得分以及利用树搜索策略探索多个解决方案路径。进行了23个不同数学问题的实证研究，对比了多种树搜索方法的表现，包括传统的BoN方法、蒙特卡洛树搜索和束搜索等，同时检查了过程奖励模型的学习性能以及在各种推理深度下的可靠性。

Result: 实验结果表明，基于过程奖励模型的树搜索方法虽未显著优于传统Best-of-N方法，但蒙特卡洛树搜索和束搜索方法的性能优于其他基于过程奖励模型的方法。而过程奖励模型在状态值估计能力和泛化能力上有明显的局限性。

Conclusion: 基于过程奖励模型的树搜索方法需要改进以弥补其可靠性问题，可能需要不同类型的奖励模型设计来实现更有效的数学推理增强。当前的分析和实验结果提示了这一改进建议。

Abstract: While chain-of-thought prompting with Best-of-N (BoN) selection has become
popular for mathematical reasoning in large language models (LLMs), its linear
structure fails to capture the branching and exploratory nature of complex
problem-solving. In this work, we propose an adaptive algorithm to maximize
process reward model (PRM) scores over the intractable action space, and
investigate whether PRM-guided tree search can improve mathematical reasoning
by exploring multiple partial solution paths. Across $23$ diverse mathematical
problems using Qwen2.5-Math-7B-Instruct with its associated PRM as a case
study, we find that: (1) PRM-guided tree search shows no statistically
significant improvements over BoN despite higher costs, (2) Monte Carlo tree
search and beam search outperform other PRM-guided tree search methods, (3)
PRMs poorly approximate state values and their reliability degrades with
reasoning depth, and (4) PRMs generalize poorly out of distribution. This
underperformance stems from tree search's greater reliance on unreliable PRM
scores, suggesting different reward modeling is necessary before tree search
can effectively enhance mathematical reasoning in LLMs.

</details>


### [133] [Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics](https://arxiv.org/abs/2510.20068)
*Ram Dyuthi Sristi,Sowmya Manojna Narasimha,Jingya Huang,Alice Despatin,Simon Musall,Vikash Gilja,Gal Mishne*

Main category: cs.LG

TL;DR: 研究引入了一种名为Coupled Transformer Autoencoder（CTAE）的序列模型，可以在捕捉非平稳、非线性动态的同时，分离共享与特定区域的结构。CTAE在两个高密度电生理数据集上的表现优于现有方法，可以从多区域同时记录中提取更有意义的表示，更好地解码行为变量。


<details>
  <summary>Details</summary>
Motivation: 现有的方法要么忽略了时间结构，要么受限于单个区域，或者假设线性读出，或者混淆了共享和私人信号。为了解决这些问题，研究引入了新的方法CTAE。

Method: CTAE运用变压器编码器和解码器来捕捉长程神经动态，并显式地将每个区域的潜在空间划分为正交的共享私人子空间，解决了非平稳、非线性动态和共享与特定区域结构的分离两个问题。

Result: CTAE在两个高密度电生理数据集上的表现优于现有方法，可以在同时记录的多个区域中提取更有意义的表示，更好地解码行为变量。

Conclusion: 这种方法提供了一种新的方式来理解神经活动的时间动态和空间分布，为理解大脑的工作方式提供了新的见解。

Abstract: Simultaneous recordings from thousands of neurons across multiple brain areas
reveal rich mixtures of activity that are shared between regions and dynamics
that are unique to each region. Existing alignment or multi-view methods
neglect temporal structure, whereas dynamical latent variable models capture
temporal dependencies but are usually restricted to a single area, assume
linear read-outs, or conflate shared and private signals. We introduce the
Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both
(i) non-stationary, non-linear dynamics and (ii) separation of shared versus
region-specific structure in a single framework. CTAE employs transformer
encoders and decoders to capture long-range neural dynamics and explicitly
partitions each region's latent space into orthogonal shared and private
subspaces. We demonstrate the effectiveness of CTAE on two high-density
electrophysiology datasets with simultaneous recordings from multiple regions,
one from motor cortical areas and the other from sensory areas. CTAE extracts
meaningful representations that better decode behavioral variables compared to
existing approaches.

</details>


### [134] [On pattern classification with weighted dimensions](https://arxiv.org/abs/2510.20107)
*Ayatullah Faruk Mollah*

Main category: cs.LG

TL;DR: 本文提出了一种基于权重的维度测量方案，并将其应用于KNN分类器中，以提高分类准确性，特别是对于具有高维度和少量样本的数据集。与传统KNN相比，在多种实验设置下，该方法在基因表达数据集上获得了约10%的分类准确率提升。


<details>
  <summary>Details</summary>
Motivation: 传统上，欧氏距离被广泛使用于模式分类中。然而，存在多维度样本的多种应用情况下，经典的欧氏距离方法面临许多问题。本文旨在探讨距离度量的规范、维度权重及其对模式分类的影响，并提出一个新颖的维度权重方案，以提高模式分类的准确性。

Method: 本文提出了一种新的维度权重方案，并将其应用于KNN分类器。该方案整合了不同距离度量规范和可视化技术。主要贡献包括：（a）距离度量的详细分析及其对模式分析的影响；（b）一种新的维度权重分配方案；（c）基于权重Minkowski距离的KNN分类器的引入；（d）在合成数据和真实数据上的模式分类实验，包括基因表达数据等。

Result: 提出的模型在多种实验条件下，特别是在基因表达数据集上，均表现出了超越传统KNN的分类准确度。在不同交叉验证实验中，分类准确度提高了大约10%。此外，该模型在样本较少、维度较高的数据集中有效的选择了最近邻样本，提高了分类性能。

Conclusion: 本文提出的方法代表了一种具有改进的KNN分类器，通过使用基于权重的Minkowski距离度量，提升了模式分类的精度，特别是在处理具有挑战性的基因表达数据集时表现出色。

Abstract: Studies on various facets of pattern classification is often imperative while
working with multi-dimensional samples pertaining to diverse application
scenarios. In this notion, weighted dimension-based distance measure has been
one of the vital considerations in pattern analysis as it reflects the degree
of similarity between samples. Though it is often presumed to be settled with
the pervasive use of Euclidean distance, plethora of issues often surface. In
this paper, we present (a) a detail analysis on the impact of distance measure
norms and weights of dimensions along with visualization, (b) a novel weighting
scheme for each dimension, (c) incorporation of this dimensional weighting
schema into a KNN classifier, and (d) pattern classification on a variety of
synthetic as well as realistic datasets with the developed model. It has
performed well across diverse experiments in comparison to the traditional KNN
under the same experimental setups. Specifically, for gene expression datasets,
it yields significant and consistent gain in classification accuracy (around
10%) in all cross-validation experiments with different values of k. As such
datasets contain limited number of samples of high dimensions, meaningful
selection of nearest neighbours is desirable, and this requirement is
reasonably met by regulating the shape and size of the region enclosing the k
number of reference samples with the developed weighting schema and appropriate
norm. It, therefore, stands as an important generalization of KNN classifier
powered by weighted Minkowski distance with the present weighting schema.

</details>


### [135] [LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems](https://arxiv.org/abs/2510.20327)
*Fengyuan Yu,Yuyuan Li,Xiaohua Feng,Junjie Fang,Tao Wang,Chaochao Chen*

Main category: cs.LG

TL;DR: LEGO是一个轻量级且高效的多属性卸载框架，解决了现有单一属性卸载方法无法同时处理多个卸载请求和缺乏对动态卸载需求有效适应的问题。通过嵌入校准和灵活组合的两步法，LEGO能够有效地保护用户敏感信息，并且通过理论上最小化互信息来保证同时卸载。实验显示LEGO在多个公开数据集和推荐模型上的效果和效率都很高。


<details>
  <summary>Details</summary>
Motivation: 现有的推荐系统中单一属性卸载方法无法应对真实世界中多个敏感属性和动态卸载需求的问题，为此，提出了一种新的轻量高效的支持多属性卸载的方法，以保证用户的隐私保护要求。

Method: LEGO首次将多属性卸载过程分为两个步骤：嵌入校准和灵活组合。第一个步骤从用户嵌入中去除特定属性的相关信息，第二个步骤将这些嵌入合并为一个嵌入，保护所有敏感属性。整个过程基于最小化互信息的推导，保证了卸载过程的理论有效性。

Result: 通过在多个公开数据集和推荐模型上的广泛实验，证明了LEGO框架的有效性和高效性，它能够同时处理多个卸载请求，并且对动态卸载需求具有高效的灵活性。实验结果表明，LEGO比现有的单一属性卸载方法具有更高的有效性。

Conclusion: 本文提出了一种新的轻量高效的方法，LEGO，它可以有效地解决推荐系统中多属性卸载的需求，同时满足处理多个卸载请求和应对动态卸载需求。这标志着推荐系统中的隐私保护技术有了新的进展。相关的代码和附录可在项目主页找到。

Abstract: With the growing demand for safeguarding sensitive user information in
recommender systems, recommendation attribute unlearning is receiving
increasing attention. Existing studies predominantly focus on single-attribute
unlearning. However, privacy protection requirements in the real world often
involve multiple sensitive attributes and are dynamic. Existing
single-attribute unlearning methods cannot meet these real-world requirements
due to i) CH1: the inability to handle multiple unlearning requests
simultaneously, and ii) CH2: the lack of efficient adaptability to dynamic
unlearning needs. To address these challenges, we propose LEGO, a lightweight
and efficient multiple-attribute unlearning framework. Specifically, we divide
the multiple-attribute unlearning process into two steps: i) Embedding
Calibration removes information related to a specific attribute from user
embedding, and ii) Flexible Combination combines these embeddings into a single
embedding, protecting all sensitive attributes. We frame the unlearning process
as a mutual information minimization problem, providing LEGO a theoretical
guarantee of simultaneous unlearning, thereby addressing CH1. With the two-step
framework, where Embedding Calibration can be performed in parallel and
Flexible Combination is flexible and efficient, we address CH2. Extensive
experiments on three real-world datasets across three representative
recommendation models demonstrate the effectiveness and efficiency of our
proposed framework. Our code and appendix are available at
https://github.com/anonymifish/lego-rec-multiple-attribute-unlearning.

</details>


### [136] [Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning](https://arxiv.org/abs/2510.20108)
*Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera*

Main category: cs.LG

TL;DR: 提出了一种解耦的训练策略来解决原型投射崩溃的问题，通过独立的损失函数更新原型，消除了原型投射的合并，提高了表示的多样性以及下游任务的表现。


<details>
  <summary>Details</summary>
Motivation: 传统的原型自监督学习方法面对原型投射崩溃，会导致原型的代表性和多样性降低，进而导致编码器无法获取丰富的表示，现有的方法通过参数过度设计或者加入正则化项来减轻症状，但没有解决根本原因。因此，这次方法旨在找到更根本的解决方案，破解传统方法中编码器和原型共有的训练模式。

Method: 本文提出了一种解耦的训练策略，对于原型使用在线EM式的转换GMM，独立于编码器的损失函数。通过这样解耦，训练过程不会以牺牲表示多样性为代价使得原型崩溃。

Result: 与传统的自监督训练方法相比，本文提出的方法提高了原型的多样性，同时在一系列下游任务上的表现优于传统的自监督学习方法。

Conclusion: 摆脱了编码器和原型共享损失函数的联合优化，本文提出的方法简单但有效，直接解决了原型坍缩问题，且不需要显式的正则化项或参数调整，提高了模型在多个下游任务上的性能

Abstract: Prototypical self-supervised learning methods consistently suffer from
partial prototype collapse, where multiple prototypes converge to nearly
identical representations. This undermines their central purpose -- providing
diverse and informative targets to guide encoders toward rich representations
-- and has led practitioners to over-parameterize prototype sets or add ad-hoc
regularizers, which mitigate symptoms rather than address the root cause. We
empirically trace the collapse to the joint optimization of encoders and
prototypes, which encourages a type of shortcut learning: early in training
prototypes drift toward redundant representations that minimize loss without
necessarily enhancing representation diversity. To break the joint
optimization, we introduce a fully decoupled training strategy that learns
prototypes and encoders under separate objectives. Concretely, we model
prototypes as a Gaussian mixture updated with an online EM-style procedure,
independent of the encoder's loss. This simple yet principled decoupling
eliminates prototype collapse without explicit regularization and yields
consistently diverse prototypes and stronger downstream performance.

</details>


### [137] [Relative-Based Scaling Law for Neural Language Models](https://arxiv.org/abs/2510.20387)
*Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu*

Main category: cs.LG

TL;DR: 该研究提出了相对排序为基础的RBP度量标准和相对排序法则，论证其在大规模语言模型中的效果，补充分析视角，提供更完整理解。


<details>
  <summary>Details</summary>
Motivation: 现有的大小范围调整法则研究主要依赖于交叉熵作为评估标准，但交叉熵仅提供了性能的部分视角，忽视了正确单词和不正确单词间的相对顺序。因此，研究者希望通过相对排序视角来改进现有的分析方法，提供更全面的理解。

Method: 研究提出了相对排序为基础的概率（Relative-Based Probability, RBP）度量标准，并建立了相对排序法则，通过大量的实验来验证其有效性和准确性。

Result: 实验结果证实了相对排序法则的有效性和准确性，并展示了其在解释涌现现象和寻找大小范围调整法则基础理论方面的重要应用价值。

Conclusion: 相对排序法则补充了现有的交叉熵视角，提供了更全面的理解，并对实际开发和理论探索提供了宝贵的见解。

Abstract: Scaling laws aim to accurately predict model performance across different
scales. Existing scaling-law studies almost exclusively rely on cross-entropy
as the evaluation metric. However, cross-entropy provides only a partial view
of performance: it measures the absolute probability assigned to the correct
token, but ignores the relative ordering between correct and incorrect tokens.
Yet, relative ordering is crucial for language models, such as in
greedy-sampling scenario. To address this limitation, we investigate scaling
from the perspective of relative ordering. We first propose the Relative-Based
Probability (RBP) metric, which quantifies the probability that the correct
token is ranked among the top predictions. Building on this metric, we
establish the Relative-Based Scaling Law, which characterizes how RBP improves
with increasing model size. Through extensive experiments on four datasets and
four model families spanning five orders of magnitude, we demonstrate the
robustness and accuracy of this law. Finally, we illustrate the broad
application of this law with two examples, namely providing a deeper
explanation of emergence phenomena and facilitating finding fundamental
theories of scaling laws. In summary, the Relative-Based Scaling Law
complements the cross-entropy perspective and contributes to a more complete
understanding of scaling large language models. Thus, it offers valuable
insights for both practical development and theoretical exploration.

</details>


### [138] [There is No "apple" in Timeseries: Rethinking TSFM through the Lens of Invariance](https://arxiv.org/abs/2510.20119)
*Arian Prabowo,Flora D. Salim*

Main category: cs.LG

TL;DR: 本文指出当前时间序列基础模型（TSFMs）在性能上与轻量级监督基线或经典模型相当，原因是其采用了自然语言处理或计算机视觉的方法，而这些方法不适用于时间序列数据。作者提出了需要从机会主义聚合转向基于原则的设计，构造系统地覆盖时间序列不变性的数据集，以实现时间序列基础模型的有效泛化、推理和真正涌现行为。


<details>
  <summary>Details</summary>
Motivation: 作者认为当前时间序列基础模型的性能不佳是因为采用了自然语言处理或计算机视觉的方法，而这些方法不太适合时间序列数据。希望通过基于原则的设计来改善时间序列基础模型的性能。

Method: 本文提出了一种新的方法，即从机会主义的聚合转向基于原则的设计，通过构造系统地覆盖时间序列不变性的数据集，从而更好地支持时间序列基础模型的发展。具体来说，这种方法旨在构建能够全面表示时间序列数据的不变性，以支持时间序列基础模型的学习能力。

Result: 虽然没有直接提到具体的研究成果，但论文指出了实现时间序列基础模型发展所需的新方法和原则，这可能会对未来的研究带来重要的启示。

Conclusion: 文章的结论是，对于时间序列数据，需要从基于互联网的无选择聚合转向基于原则的设计，进而通过覆盖时间序列不变性的数据集来确保时间序列基础模型的有效性，并实现更强大的泛化能力、推理能力和真正涌现的行为。

Abstract: Timeseries foundation models (TSFMs) have multiplied, yet lightweight
supervised baselines and even classical models often match them. We argue this
gap stems from the naive importation of NLP or CV pipelines. In language and
vision, large web-scale corpora densely capture human concepts i.e. there are
countless images and text of apples. In contrast, timeseries data is built to
complement the image and text modalities. There are no timeseries dataset that
contains the concept apple. As a result, the scrape-everything-online paradigm
fails for TS. We posit that progress demands a shift from opportunistic
aggregation to principled design: constructing datasets that systematically
span the space of invariance that preserve temporal semantics. To this end, we
suggest that the ontology of timeseries invariances should be built based on
first principles. Only by ensuring representational completeness through
invariance coverage can TSFMs achieve the aligned structure necessary for
generalisation, reasoning, and truly emergent behaviour.

</details>


### [139] [ADP-VRSGP: Decentralized Learning with Adaptive Differential Privacy via Variance-Reduced Stochastic Gradient Push](https://arxiv.org/abs/2510.20157)
*Xiaoming Wu,Teng Liu,Xin Wang,Ming Yang,Jiguo Yu*

Main category: cs.LG

TL;DR: 提出了一种新的适应性差分隐私去中心化学习方法ADP-VRSGP，通过动态调整噪音方差和学习率，改善模型性能和训练效率，同时保证节点级隐私。此外，还引入了渐进式梯度融合策略和分散推送聚合技术，适用于动态通信拓扑。理论分析和实验结果表明，ADP-VRSGP提高了训练稳定性和速度。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化学习方法中使用固定方差噪声会导致模型性能下降和训练效率降低。因此，提出了一个动态调整噪声和学习率的方法来解决这些问题，并在保持节点级隐私的同时提高模型性能和训练效率。

Method: 提出的方法称为适应性差分隐私去中心化学习，采用降阶衰减时间表动态调整噪音方差和学习率，并引入渐进式梯度融合策略及分散推送聚合技术，适用于动态通信拓扑。

Result: 实验结果表明，该方法提高了训练稳定性和速度，并在多个场景中超越基准方法。通过理论分析证明适应性差分隐私去中心化学习方法能实现稳健收敛，提高训练效率。

Conclusion: 本文提出的方法在提高模型性能和训练效率的同时，保证了节点级隐私，适用于动态通信拓扑，并在实践中表现良好。

Abstract: Differential privacy is widely employed in decentralized learning to
safeguard sensitive data by introducing noise into model updates. However,
existing approaches that use fixed-variance noise often degrade model
performance and reduce training efficiency. To address these limitations, we
propose a novel approach called decentralized learning with adaptive
differential privacy via variance-reduced stochastic gradient push (ADP-VRSGP).
This method dynamically adjusts both the noise variance and the learning rate
using a stepwise-decaying schedule, which accelerates training and enhances
final model performance while providing node-level personalized privacy
guarantees. To counteract the slowed convergence caused by large-variance noise
in early iterations, we introduce a progressive gradient fusion strategy that
leverages historical gradients. Furthermore, ADP-VRSGP incorporates
decentralized push-sum and aggregation techniques, making it particularly
suitable for time-varying communication topologies. Through rigorous
theoretical analysis, we demonstrate that ADP-VRSGP achieves robust convergence
with an appropriate learning rate, significantly improving training stability
and speed. Experimental results validate that our method outperforms existing
baselines across multiple scenarios, highlighting its efficacy in addressing
the challenges of privacy-preserving decentralized learning.

</details>


### [140] [Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models](https://arxiv.org/abs/2510.20468)
*Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko*

Main category: cs.LG

TL;DR: 本文提出了一种新的水印伪造方法，通过偏好模型判断图像是否被水印标记，并通过优化输入图像进行水印移除和伪造，仅需单个水印图像即可实现，无需知道水印模型。该方法在多种后处理图像水印模型上验证了效果，表明当前水印方法的安全性有待提高。


<details>
  <summary>Details</summary>
Motivation: 当前的水印技术虽然在移除攻击方面有许多研究，但在水印伪造方面的研究相对较少。为了解决这个问题，该论文旨在研究水印伪造，并提出一种新的伪造方法来提升对现有水印安全性的认识和改进。

Method: 引入一个偏好模型来判断图像是否被水印标记，该模型在纯粹的程序生成图像上进行训练，无需实际水印。利用后向传播优化输入图像来移除和伪造水印，这种方法仅需单个水印图像且不需要知道水印模型的信息。

Result: 论文展示了该方法在多种后处理图像水印模型上的有效性，证明了该方法可以有效地伪造水印，对当前的水印安全提出了挑战。

Conclusion: 本文提出了一种新颖的水印伪造方法，展示了现有水印模型的安全性不足，提示了未来水印技术改进的方向。

Abstract: Recent years have seen a surge in interest in digital content watermarking
techniques, driven by the proliferation of generative models and increased
legal pressure. With an ever-growing percentage of AI-generated content
available online, watermarking plays an increasingly important role in ensuring
content authenticity and attribution at scale. There have been many works
assessing the robustness of watermarking to removal attacks, yet, watermark
forging, the scenario when a watermark is stolen from genuine content and
applied to malicious content, remains underexplored. In this work, we
investigate watermark forging in the context of widely used post-hoc image
watermarking. Our contributions are as follows. First, we introduce a
preference model to assess whether an image is watermarked. The model is
trained using a ranking loss on purely procedurally generated images without
any need for real watermarks. Second, we demonstrate the model's capability to
remove and forge watermarks by optimizing the input image through
backpropagation. This technique requires only a single watermarked image and
works without knowledge of the watermarking model, making our attack much
simpler and more practical than attacks introduced in related work. Third, we
evaluate our proposed method on a variety of post-hoc image watermarking
models, demonstrating that our approach can effectively forge watermarks,
questioning the security of current watermarking approaches. Our code and
further resources are publicly available.

</details>


### [141] [Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values](https://arxiv.org/abs/2510.20187)
*Dian Yu,Yulai Zhao,Kishan Panaganti,Linfeng Song,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: 提出了一种将大型语言模型（LLM）优化与可量化的人类价值信号对齐的方法，即带有明确人类价值的强化学习（RLEV），并在多种强化学习算法和模型规模上优于仅基于正确性的基线方法，展示了在人机价值对齐方面的有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法如基于可验证奖励的强化学习（RLVR）虽然在目标领域效果显著，但是并未考虑所有任务的重要性层级，因此提出RLEV，通过将人类定义的价值信号直接融入奖励函数，使得模型不仅在准确性上有提升，还在任务重要性方面表现出适应性。

Method: 提出了RLEV方法，通过明确人类价值信号的引入，调整奖励函数，实现模型对人类偏好与价值的感知和优化，利用具有显式价值标签的考试风格数据进行训练，完成对任务重要性的敏感适应性调整。

Result: 实验表明，RLEV方法在价值加权准确率上优于仅基于正确性的基线方法，并且还能学习出针对不同任务价值的重要性和结束策略：对于低价值的任务，给出简洁的回答；对于高价值的任务，提供详尽的回答。此外，RLEV在价值信号带有噪音（如根据难度给出的标签）的情况下仍然有效。

Conclusion: RLEV成功地将大型语言模型与人类的重要价值信号对齐，通过优化特定的实用价值函数，展示出在实践中的可行性和灵活性，强调了引入明确人类价值信号对于优化模型行为的重要性。

Abstract: We propose Reinforcement Learning with Explicit Human Values (RLEV), a method
that aligns Large Language Model (LLM) optimization directly with quantifiable
human value signals. While Reinforcement Learning with Verifiable Rewards
(RLVR) effectively trains models in objective domains using binary correctness
rewards, it overlooks that not all tasks are equally significant. RLEV extends
this framework by incorporating human-defined value signals directly into the
reward function. Using exam-style data with explicit ground-truth value labels,
RLEV consistently outperforms correctness-only baselines across multiple RL
algorithms and model scales. Crucially, RLEV policies not only improve
value-weighted accuracy but also learn a value-sensitive termination policy:
concise for low-value prompts, thorough for high-value ones. We demonstrate
this behavior stems from value-weighted gradient amplification on
end-of-sequence tokens. Ablation studies confirm the gain is causally linked to
value alignment. RLEV remains robust under noisy value signals, such as
difficulty-based labels, demonstrating that optimizing for an explicit utility
function offers a practical path to aligning LLMs with human priorities.

</details>


### [142] [Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval](https://arxiv.org/abs/2510.20486)
*Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng*

Main category: cs.LG

TL;DR: 提出了一种新的处理遥感降雨回波不平衡标签分布的框架，该框架称为Hurdle-Inversion Model Debiasing Learning (IMDL)，通过分解成零通胀和长尾两个部分，并采用hurdle模型和IMDL模型分别处理这两个部分，从而提高了罕见高影响事件的获取精度。


<details>
  <summary>Details</summary>
Motivation: 降水回波的遥感中，存在标签分布不平衡问题，尤其是强降雨的标签样本稀少导致预测精度不高，因此提出了Hurdle-IMDL框架来改善这一问题。

Method: 首先通过采用hurdle模型来处理非降雨样本占主流的零通胀问题，然后通过IMDL模型来解决轻度降雨样本过多而重度降雨样本过少的长尾问题。整个方法采用了一种分治策略，将复杂问题分解成几个更容易处理的部分。

Result: 实验结果证明，新的Hurdle-IMDL框架相较于传统的、成本敏感的、生成式的和多任务的方法具有显著优势，并有效缓解了罕见高强度降水低估的问题。

Conclusion: IMDL框架提供了一种处理环境变量不平衡分布问题的通用方法，对于提高罕见高影响事件（如高强度降水）的获取精度有重大贡献，可以广泛应用于类似的问题中。

Abstract: Artificial intelligence has advanced quantitative remote sensing, yet its
effectiveness is constrained by imbalanced label distribution. This imbalance
leads conventionally trained models to favor common samples, which in turn
degrades retrieval performance for rare ones. Rainfall retrieval exemplifies
this issue, with performance particularly compromised for heavy rain. This
study proposes Hurdle-Inversion Model Debiasing Learning (IMDL) framework.
Following a divide-and-conquer strategy, imbalance in the rain distribution is
decomposed into two components: zero inflation, defined by the predominance of
non-rain samples; and long tail, defined by the disproportionate abundance of
light-rain samples relative to heavy-rain samples. A hurdle model is adopted to
handle the zero inflation, while IMDL is proposed to address the long tail by
transforming the learning object into an unbiased ideal inverse model.
Comprehensive evaluation via statistical metrics and case studies investigating
rainy weather in eastern China confirms Hurdle-IMDL's superiority over
conventional, cost-sensitive, generative, and multi-task learning methods. Its
key advancements include effective mitigation of systematic underestimation and
a marked improvement in the retrieval of heavy-to-extreme rain. IMDL offers a
generalizable approach for addressing imbalance in distributions of
environmental variables, enabling enhanced retrieval of rare yet high-impact
events.

</details>


### [143] [Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents](https://arxiv.org/abs/2510.20199)
*Jane H. Lee,Baturay Saglam,Spyridon Pougkakiotis,Amin Karbasi,Dionysis Kalogerias*

Main category: cs.LG

TL;DR: 提出了一个风险意识的约束强化学习框架，该框架在奖赏值和时间上表现出鲁棒性，并通过优化确定等价物（OCEs）实现，适用于处理高风险应用中的尾部事件。


<details>
  <summary>Details</summary>
Motivation: 当前的强化学习方法在处理尾部事件（如风险或潜在灾难性事件）时存在不足，特别是在高风险应用中，有必要引入一种新的方法来处理这些情况。

Method: 提出了一个基于优化确定等价物（OCEs）的风险意识约束强化学习框架。通过该框架，确保了解原始约束问题的准确等价性，并且可以用标准的强化学习求解器来实现。

Result: 该算法在标准假设下收敛，并且通过数值实验验证了其风险意识特性。此外，它提供了一个简单的方法，可以应用于标准的RL解算器，如PPO。

Conclusion: 提出的方法为处理高风险强化学习问题提供了一个新的框架，具有鲁棒性和风险意识特性，并在实际应用中展示了其价值。

Abstract: Constrained optimization provides a common framework for dealing with
conflicting objectives in reinforcement learning (RL). In most of these
settings, the objectives (and constraints) are expressed though the expected
accumulated reward. However, this formulation neglects risky or even possibly
catastrophic events at the tails of the reward distribution, and is often
insufficient for high-stakes applications in which the risk involved in
outliers is critical. In this work, we propose a framework for risk-aware
constrained RL, which exhibits per-stage robustness properties jointly in
reward values and time using optimized certainty equivalents (OCEs). Our
framework ensures an exact equivalent to the original constrained problem
within a parameterized strong Lagrangian duality framework under appropriate
constraint qualifications, and yields a simple algorithmic recipe which can be
wrapped around standard RL solvers, such as PPO. Lastly, we establish the
convergence of the proposed algorithm under common assumptions, and verify the
risk-aware properties of our approach through several numerical experiments.

</details>


### [144] [Approximate Replicability in Learning](https://arxiv.org/abs/2510.20200)
*Max Hopkins,Russell Impagliazzo,Christopher Ye*

Main category: cs.LG

TL;DR: 本文提出了三个自然的可复现性的松弛版本，并证明了在这些松弛版本下的PAC学习的最优样本复杂度。对于前两个松弛版本，最优样本复杂度为Theta(d / α^2)，对于第三个松弛版本，最优样本复杂度为Theta(d^2 / α^2)。


<details>
  <summary>Details</summary>
Motivation: 在给定可共享的随机性的情况下，算法对于输入数据的重采样应该保持稳定。然而，这种可复现性对于一些简单的任务（如阈值学习）而言，其实现成本可能非常高。因此，本文探讨在近似可复现性的条件下，学习是否可行。

Method: 本文提出了三个在PAC学习中的可复现性的自然放松版本：点估计、近似可复现性和半可复现性。然后，对于每个版本，证明了最优的样本复杂度。对于前两个版本，最优的样本复杂度为Theta(d / α^2)；对于第三个版本，最优的样本复杂度为Theta(d^2 / α^2)。

Result: 对于放松版本的可复现性，证明了最优样本复杂度：对于点估计和近似可复现性，需要Theta(d / α^2)样本；而对于半可复现性，需要Theta(d^2 / α^2)样本。并说明了这些样本复杂度是可以实现的。

Conclusion: 论文表明在三个不同的放松版本下的可复现性条件下，PAC学习可以达到最优的样本复杂度。

Abstract: Replicability, introduced by (Impagliazzo et al. STOC '22), is the notion
that algorithms should remain stable under a resampling of their inputs (given
access to shared randomness). While a strong and interesting notion of
stability, the cost of replicability can be prohibitive: there is no replicable
algorithm, for instance, for tasks as simple as threshold learning (Bun et al.
STOC '23). Given such strong impossibility results we ask: under what
approximate notions of replicability is learning possible?
  In this work, we propose three natural relaxations of replicability in the
context of PAC learning: (1) Pointwise: the learner must be consistent on any
fixed input, but not across all inputs simultaneously, (2) Approximate: the
learner must output hypotheses that classify most of the distribution
consistently, (3) Semi: the algorithm is fully replicable, but may additionally
use shared unlabeled samples. In all three cases, for constant replicability
parameters, we obtain sample-optimal agnostic PAC learners: (1) and (2) are
achievable for ``free" using $\Theta(d/\alpha^2)$ samples, while (3) requires
$\Theta(d^2/\alpha^2)$ labeled samples.

</details>


### [145] [Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics](https://arxiv.org/abs/2510.20556)
*Alexandre Benoit,Catherine Aitken,Yu He*

Main category: cs.LG

TL;DR: Rewiring graphs in GNNs and Graph Transformers can alleviate over-squashing but may distort important topology-dependent signals. This paper systematically analyzes the impact of different rewiring methods on graph structural metrics and downstream task performance, revealing that successful methods tend to preserve local structure while allowing flexibility in global connectivity.


<details>
  <summary>Details</summary>
Motivation: To understand which structural properties need to be preserved during graph rewiring to ensure both performance improvement and structural fidelity.

Method: The study examines seven different rewiring strategies and correlates changes in local and global graph properties with node classification accuracy to understand the impact of rewiring.

Result: The results show a consistent pattern where successful rewiring methods preserve local structure while allowing flexibility in global connectivity.

Conclusion: These findings offer new insights into the design of effective rewiring strategies, potentially improving the performance of GNNs and Graph Transformers.

Abstract: Graph rewiring has emerged as a key technique to alleviate over-squashing in
Graph Neural Networks (GNNs) and Graph Transformers by modifying the graph
topology to improve information flow. While effective, rewiring inherently
alters the graph's structure, raising the risk of distorting important
topology-dependent signals. Yet, despite the growing use of rewiring, little is
known about which structural properties must be preserved to ensure both
performance gains and structural fidelity. In this work, we provide the first
systematic analysis of how rewiring affects a range of graph structural
metrics, and how these changes relate to downstream task performance. We study
seven diverse rewiring strategies and correlate changes in local and global
graph properties with node classification accuracy. Our results reveal a
consistent pattern: successful rewiring methods tend to preserve local
structure while allowing for flexibility in global connectivity. These findings
offer new insights into the design of effective rewiring strategies, bridging
the gap between graph theory and practical GNN optimization.

</details>


### [146] [CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks](https://arxiv.org/abs/2510.20219)
*Ke Xing,Yanjie Dong,Xiaoyi Fan,Runhao Zeng,Victor C. M. Leung,M. Jamal Deen,Xiping Hu*

Main category: cs.LG

TL;DR: 文章介绍了一种新的个性化联合学习算法CO-PFL，该算法通过分析梯度方向和预测偏差来动态估计每个客户端对全局聚合的贡献，从而提高个性化适应性和优化稳定性。实验表明，CO-PFL在基准数据集上的个性化准确性、鲁棒性、可扩展性和收敛稳定性方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 个性化联合学习面临的主要挑战是训练异质且稀缺的数据。现有联合学习方法对于个性化的支持不足，容易导致聚合偏差。论文旨在解决这个问题，提出了一种新的算法来提高个性化适应性和优化稳定性。

Method: 引入贡献导向的个性化联合学习算法CO-PFL，通过分析梯度和数据子空间中的信息进行联合评估，为每个客户端提供衡量聚合权重的标准。此外，还集成了一种参数级个性化机制和遮罩感知动量优化方法。

Result: 在CIFAR10, CIFAR10C, CINIC10和Mini-ImageNet这四个基准数据集上进行了实验验证，实验结果表明CO-PFL在个性化准确性，鲁棒性，可扩展性以及收敛稳定性方面均优于现有方法。

Conclusion: CO-PFL通过动态估计每个客户端的贡献并利用子空间分析方法为全局聚合提供了合适的虚拟聚合权重，使个性化联合学习更加稳健且具有更强的适应性与稳定性。

Abstract: Personalized federated learning (PFL) addresses a critical challenge of
collaboratively training customized models for clients with heterogeneous and
scarce local data. Conventional federated learning, which relies on a single
consensus model, proves inadequate under such data heterogeneity. Its standard
aggregation method of weighting client updates heuristically or by data volume,
operates under an equal-contribution assumption, failing to account for the
actual utility and reliability of each client's update. This often results in
suboptimal personalization and aggregation bias. To overcome these limitations,
we introduce Contribution-Oriented PFL (CO-PFL), a novel algorithm that
dynamically estimates each client's contribution for global aggregation. CO-PFL
performs a joint assessment by analyzing both gradient direction discrepancies
and prediction deviations, leveraging information from gradient and data
subspaces. This dual-subspace analysis provides a principled and discriminative
aggregation weight for each client, emphasizing high-quality updates.
Furthermore, to bolster personalization adaptability and optimization
stability, CO-PFL cohesively integrates a parameter-wise personalization
mechanism with mask-aware momentum optimization. Our approach effectively
mitigates aggregation bias, strengthens global coordination, and enhances local
performance by facilitating the construction of tailored submodels with stable
updates. Extensive experiments on four benchmark datasets (CIFAR10, CIFAR10C,
CINIC10, and Mini-ImageNet) confirm that CO-PFL consistently surpasses
state-of-the-art methods in in personalization accuracy, robustness,
scalability and convergence stability.

</details>


### [147] [Generalizable Reasoning through Compositional Energy Minimization](https://arxiv.org/abs/2510.20607)
*Alexandru Oarga,Yilun Du*

Main category: cs.LG

TL;DR: 该研究提出了一种新的机器学习推理泛化方法，通过学习子问题的解空间上的能量景观来处理复杂的推理任务。在测试时，该方法通过组合多个子问题的能量函数来构建全局能量景观。此外，提出了一种并行能量最小化（PEM）技术以改进从新构建的能量景观中获取的样本质量。实验表明该方法在解决更大型和更复杂的推理问题上优于现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法往往无法有效推广到超出训练数据集分布的问题，对更复杂的问题解决能力有限。该研究旨在克服这个问题，通过学习子问题的空间能量景观，并据此构建较大问题的能量景观，从而提升模型的泛化能力。

Method: 该方法通过学习较小，更可处理的子问题的能量景观，并在测试时组合这些能量函数来构建全局能量景观。提出了并行能量最小化（PEM）技术，以提高从恢复的能量景观中抽取样本的质量。这种方法允许在推理过程中增加额外的约束。

Result: 在多种推理问题上，该方法都超过了现有最先进方法，展示了其在解决更大更复杂任务的能力。

Conclusion: 通过提出解决子问题并组合这些子问题解决整个问题的新策略，成功改进了机器学习模型在推理任务上的泛化性能。

Abstract: Generalization is a key challenge in machine learning, specifically in
reasoning tasks, where models are expected to solve problems more complex than
those encountered during training. Existing approaches typically train
reasoning models in an end-to-end fashion, directly mapping input instances to
solutions. While this allows models to learn useful heuristics from data, it
often results in limited generalization beyond the training distribution. In
this work, we propose a novel approach to reasoning generalization by learning
energy landscapes over the solution spaces of smaller, more tractable
subproblems. At test time, we construct a global energy landscape for a given
problem by combining the energy functions of multiple subproblems. This
compositional approach enables the incorporation of additional constraints
during inference, allowing the construction of energy landscapes for problems
of increasing difficulty. To improve the sample quality from this newly
constructed energy landscape, we introduce Parallel Energy Minimization (PEM).
We evaluate our approach on a wide set of reasoning problems. Our method
outperforms existing state-of-the-art methods, demonstrating its ability to
generalize to larger and more complex problems. Project website can be found
at: https://alexoarga.github.io/compositional_reasoning/

</details>


### [148] [Sparse Local Implicit Image Function for sub-km Weather Downscaling](https://arxiv.org/abs/2510.20228)
*Yago del Valle Inclan Redondo,Enrique Arriaga-Varela,Dmitry Lyamzin,Pablo Cervantes,Tiago Ramalho*

Main category: cs.LG

TL;DR: 本文介绍了一种名为SpLIIF的方法，用于生成隐式神经表示，以实现天气变量的任意下采样，并在日本的稀疏气象站和地形数据上进行了训练和评估，结果表明该方法在温度和风的预测下采样上优于对比模型CorrDiff和插值基线模型，特别是在温度预测中，其性能可以达到基线模型的150%左右，风的预测中，性能也能达到基线模型的110%-120%左右。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为了提高天气变量（包括温度和风）在稀疏数据上的预测精度，特别是在实现天气变量任意缩放时的表现优于现有的方法。

Method: 提出了一种基于隐式神经表示的方法SpLIIF，该方法可以被训练来从稀疏的气象站数据和地形数据生成更高分辨率的天气场。该方法构建了一个从稀疏数据生成密集数据的模型，并通过下采样验证了该模型的效果。

Result: 实验结果显示，SpLIIF模型在温度预测方面比基线模型好50%，在风的预测上大约比基线模型好10-20%。这表明该模型在处理稀疏天气数据时具有显著的优势。与CorrDiff等方法相比，也显示出了更好的性能。

Conclusion: 通过将SpLIIF方法应用于气象领域的数据，证明了该方法在稀疏天气数据集上获得高精度预测的潜力，特别是对于温度和风的预测。

Abstract: We introduce SpLIIF to generate implicit neural representations and enable
arbitrary downscaling of weather variables. We train a model from sparse
weather stations and topography over Japan and evaluate in- and
out-of-distribution accuracy predicting temperature and wind, comparing it to
both an interpolation baseline and CorrDiff. We find the model to be up to 50%
better than both CorrDiff and the baseline at downscaling temperature, and
around 10-20% better for wind.

</details>


### [149] [Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets](https://arxiv.org/abs/2510.20609)
*Timur Galimzyanov,Olga Kolomyttseva,Egor Bogomolov*

Main category: cs.LG

TL;DR: 该研究在长代码竞技场的两个互补任务（代码完成和错误定位）中，系统性地比较了不同检索配置的有效性。提出了基于任务需求、模型约束和计算效率的证据支持的代码导向RAG系统实现的建议。


<details>
  <summary>Details</summary>
Motivation: 研究旨在优化代码生成任务下的检索设计，特别强调在现实的计算预算下的高效性。这项研究对代码完成和错误定位这两种任务进行了详细的分析，提出了关于代码导向检索系统的有效实现方法。

Method: 使用了两种任务：代码完成和错误定位，系统地比较了不同的检索配置，特别是在分块策略、相似性评分和分块粒度方面。比较了PL-PL空缺下BM25稠密检索与稀疏检索的效果；比较了NL-PL中不同编码器的效果；并评估了检索延迟在此过程中的影响。

Result: 结果表明，在编程语言-编程语言（PL-PL）任务中，稀疏BM25检索与单词级别分割最有效和实用；在自然语言-编程语言（NL-PL）任务中，专有密集编码器表现出色，但延迟较大；最佳块大小取决于可用的上下文；基于简单的行分割与基于语法的分割效果相同；BM25加单词分割提供了最佳的质量与延迟的平衡。

Conclusion: 该研究提供了关于如何根据任务需求、模型约束和计算效率有效实现代码导向RAG系统的依据和推荐。

Abstract: We study retrieval design for code-focused generation tasks under realistic
compute budgets. Using two complementary tasks from Long Code Arena -- code
completion and bug localization -- we systematically compare retrieval
configurations across various context window sizes along three axes: (i)
chunking strategy, (ii) similarity scoring, and (iii) splitting granularity.
(1) For PL-PL, sparse BM25 with word-level splitting is the most effective and
practical, significantly outperforming dense alternatives while being an order
of magnitude faster. (2) For NL-PL, proprietary dense encoders (Voyager-3
family) consistently beat sparse retrievers, however requiring 100x larger
latency. (3) Optimal chunk size scales with available context: 32-64 line
chunks work best at small budgets, and whole-file retrieval becomes competitive
at 16000 tokens. (4) Simple line-based chunking matches syntax-aware splitting
across budgets. (5) Retrieval latency varies by up to 200x across
configurations; BPE-based splitting is needlessly slow, and BM25 + word
splitting offers the best quality-latency trade-off. Thus, we provide
evidence-based recommendations for implementing effective code-oriented RAG
systems based on task requirements, model constraints, and computational
efficiency.

</details>


### [150] [Layer-to-Layer Knowledge Mixing in Graph Neural Network for Chemical Property Prediction](https://arxiv.org/abs/2510.20236)
*Teng Jiek See,Daokun Zhang,Mario Boley,David K. Chalmers*

Main category: cs.LG

TL;DR: 本文开发了一种新型自知识蒸馏方法——Layer-to-Layer Knowledge Mixing (LKM)，它可以在不增加训练和推断计算复杂度的情况下提高GNN的准确性。该方法使用现有的隐藏嵌入来高效地聚合多跳和多尺度信息，实现了局部和全局分子特征的更好表示。实验结果表明，LKM能够显著提高三大GNN架构在量子化学和生物物理属性预测中的准确度，误差可减少高达9.8%、45.3%和22.9%。


<details>
  <summary>Details</summary>
Motivation: 现有的GNN模型虽然准确度高，但在提高准确度的同时也增加了计算成本和内存需求。为了提高GNN的准确性而不增加计算成本，研究者提出了自知识蒸馏方法LKM。

Method: 通过最小化GNN层间已有的隐藏嵌入的平均绝对距离，LKM能有效地聚集多跳和多尺度信息，从而提高局部和全局分子特征的表示能力。

Result: 实验结果显示，LKM可以显著减少量子化学和生物物理属性预测的平均绝对误差，具体为QM9误差减少9.8%，MD17能量误差减少45.3%，Chignolin误差减少22.9%。证明了LKM在不增加任何显著训练和推断成本的情况下显著提升了化学属性预测的准确性。

Conclusion: 该研究提出了一种新的自知识蒸馏方法LKM，该方法可以通过不增加计算成本的方式提高GNN预测化学性质的准确性。

Abstract: Graph Neural Networks (GNNs) are the currently most effective methods for
predicting molecular properties but there remains a need for more accurate
models. GNN accuracy can be improved by increasing the model complexity but
this also increases the computational cost and memory requirement during
training and inference. In this study, we develop Layer-to-Layer Knowledge
Mixing (LKM), a novel self-knowledge distillation method that increases the
accuracy of state-of-the-art GNNs while adding negligible computational
complexity during training and inference. By minimizing the mean absolute
distance between pre-existing hidden embeddings of GNN layers, LKM efficiently
aggregates multi-hop and multi-scale information, enabling improved
representation of both local and global molecular features. We evaluated LKM
using three diverse GNN architectures (DimeNet++, MXMNet, and PAMNet) using
datasets of quantum chemical properties (QM9, MD17 and Chignolin). We found
that the LKM method effectively reduces the mean absolute error of quantum
chemical and biophysical property predictions by up to 9.8% (QM9), 45.3% (MD17
Energy), and 22.9% (Chignolin). This work demonstrates the potential of LKM to
significantly improve the accuracy of GNNs for chemical property prediction
without any substantial increase in training and inference cost.

</details>


### [151] [Optimistic Task Inference for Behavior Foundation Models](https://arxiv.org/abs/2510.20264)
*Thomas Rupf,Marco Bagatella,Marin Vlastelica,Andreas Krause*

Main category: cs.LG

TL;DR: 提出了OpTI-BFM算法，该算法通过与环境的交互在测试时推断任务，减少了对大量标记数据的需求，并允许基于继承特征的BFMs在少量集中识别和优化未知奖励函数，同时也提高了计算效率。代码可在GitHub上获取。


<details>
  <summary>Details</summary>
Motivation: 现有的BFMs通常需要大量的评估数据来工作，这导致了对功能性奖励形式或者大量标记数据的需求，因此研究了一种新的方法来减少这种数据要求，同时尽量减少计算开销。

Method: 提出了一种乐观决策标准OpTI-BFM，直接建模奖励函数的不确定性，指导BFMs通过与环境的实时交互来进行数据收集，以便进行任务推断。该方法通过线性上下文算法与纪律行为模型建立了直接的连接，以提供后悔界限。

Result: 通过在已有的零次学习基准测试上评估OpTI-BFM，观察到这种方法能够使得基于继承特征的BFMs能够在非常少量的集中，识别和优化未知的奖励函数，而计算开销很小。代码可在GitHub上获取。

Conclusion: 通过更直接有效的方式与环境进行交互，OpTI-BFM算法显著减少了BFMs对于大量标记数据的需求，展示了在处理新任务时更高的效率和灵活性

Abstract: Behavior Foundation Models (BFMs) are capable of retrieving high-performing
policy for any reward function specified directly at test-time, commonly
referred to as zero-shot reinforcement learning (RL). While this is a very
efficient process in terms of compute, it can be less so in terms of data: as a
standard assumption, BFMs require computing rewards over a non-negligible
inference dataset, assuming either access to a functional form of rewards, or
significant labeling efforts. To alleviate these limitations, we tackle the
problem of task inference purely through interaction with the environment at
test-time. We propose OpTI-BFM, an optimistic decision criterion that directly
models uncertainty over reward functions and guides BFMs in data collection for
task inference. Formally, we provide a regret bound for well-trained BFMs
through a direct connection to upper-confidence algorithms for linear bandits.
Empirically, we evaluate OpTI-BFM on established zero-shot benchmarks, and
observe that it enables successor-features-based BFMs to identify and optimize
an unseen reward function in a handful of episodes with minimal compute
overhead. Code is available at https://github.com/ThomasRupf/opti-bfm.

</details>


### [152] [Scalable GPU-Accelerated Euler Characteristic Curves: Optimization and Differentiable Learning for PyTorch](https://arxiv.org/abs/2510.20271)
*Udit Saxena*

Main category: cs.LG

TL;DR: 本文提出了优化的GPU内核来加速Euler Characteristic Curve(ECC)的计算，并引入了一个可微分的PyTorch层，使得在深度学习中可以实现端到端的学习。优化后的内核对于Ampere GPU使用了128B的聚集读取和分层共享内存累加方式，且PyTorch层通过可微分的Euler Characteristic Transform风格的激活函数学习单方向的阈值。


<details>
  <summary>Details</summary>
Motivation: 拓扑特征能够捕捉图像数据的全局几何结构，但是在深度学习中的实际应用需要高效计算和可微分性，所以对ECC计算提出了改进，使其符合深度学习需求的高效性和可微分性要求。

Method: 设计了优化后的GPU内核，使用了128B聚集读取和层次共享内存累加；提出了一个基于可微分Euler Characteristic Transform风格的PyTorch层来进一步增强计算性能和可微分性。

Result: 优化后的GPU内核在合成网格上比之前的GPU实现速度快16到2000倍，PyTorch层可以通过端到端学习方法，展现出强大的学习效果。

Conclusion: 通过我们的方法可以加速ECC计算，提高其在深度学习中的使用效率和效果，具有广泛的应用前景和实用价值。

Abstract: Topological features capture global geometric structure in imaging data, but
practical adoption in deep learning requires both computational efficiency and
differentiability. We present optimized GPU kernels for the Euler
Characteristic Curve (ECC) computation achieving 16-2000\"O speedups over prior
GPU implementations on synthetic grids, and introduce a differentiable PyTorch
layer enabling end-to-end learning. Our CUDA kernels, optimized for Ampere GPUs
use 128B-coalesced access and hierarchical shared-memory accumulation. Our
PyTorch layer learns thresholds in a single direction via a Differentiable
Euler Characteristic Transform-style sigmoid relaxation. We discuss downstream
relevance, including applications highlighted by prior ECC work, and outline
batching/multi-GPU extensions to broaden adoption.

</details>


### [153] [Synthetic Data for Robust Runway Detection](https://arxiv.org/abs/2510.20349)
*Estelle Chigot,Dennis G. Wilson,Meriem Ghrib,Fabrice Jimenez,Thomas Oberlin*

Main category: cs.LG

TL;DR: 本文提出了一种基于商用飞行模拟器的图像生成方法，以解决训练数据收集和标注成本高的问题，特别是在如跑道检测等关键应用中。通过这种方法，结合少量的真实标注图像，可以提高标准目标检测模型的预测准确性，并增强其在不利条件下的鲁棒性。此外，文章还评估了一种定制的领域适应策略在夜间图像条件下的效果，证明了该策略的价值。


<details>
  <summary>Details</summary>
Motivation: 解决在关键应用中（如跑道检测），由于数据收集和标注成本高而无法覆盖所有条件的问题。通过合成图像生成和真实数据的结合，降低训练成本，提高模型在所有条件下的表现。

Method: 利用商用飞行模拟器生成图像，并结合少量的真实标注图像，用于训练目标检测模型。同时采用了定制的领域适应策略来缓解合成图像与真实图像之间的分布差异。

Result: 表明所提出的方法可以提高标准目标检测模型的预测准确性，并在不利的夜间条件下显示出较好的鲁棒性。

Conclusion: 通过合成和真实数据的结合，可以有效地训练目标检测模型，提高其在所有条件下的性能，特别是在稀有场景下。此外，定制的领域适应策略对于增强模型在未曾见过条件下的表现至关重要。

Abstract: Deep vision models are now mature enough to be integrated in industrial and
possibly critical applications such as autonomous navigation. Yet, data
collection and labeling to train such models requires too much efforts and
costs for a single company or product. This drawback is more significant in
critical applications, where training data must include all possible conditions
including rare scenarios. In this perspective, generating synthetic images is
an appealing solution, since it allows a cheap yet reliable covering of all the
conditions and environments, if the impact of the synthetic-to-real
distribution shift is mitigated. In this article, we consider the case of
runway detection that is a critical part in autonomous landing systems
developed by aircraft manufacturers. We propose an image generation approach
based on a commercial flight simulator that complements a few annotated real
images. By controlling the image generation and the integration of real and
synthetic data, we show that standard object detection models can achieve
accurate prediction. We also evaluate their robustness with respect to adverse
conditions, in our case nighttime images, that were not represented in the real
data, and show the interest of using a customized domain adaptation strategy.

</details>


### [154] [Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples](https://arxiv.org/abs/2510.20800)
*Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus*

Main category: cs.LG

TL;DR: 通过减少层数和关键矩阵的因子分解，可以在不进行梯度调整的情况下提高大型语言模型的下游任务准确率，并且可以显著减少搜索时间。这种方法通过评估100个样本即可快速适应新的数据集，无需微调整个模型。


<details>
  <summary>Details</summary>
Motivation: Sharma等人提出了LASER方法，但其需要完整数据集的向前传播来搜索权重矩阵，使其难以快速部署。旨在找到一种更高效的方法来选择哪些层和矩阵需要简化，以提高大型语言模型的精度并减少搜索时间。

Method: 通过梯度计算来定位哪些矩阵需要因子分解，以及允许矩阵行围绕多个子空间进行聚类，然后分别分解每个聚类，从而限制了需要搜索的矩阵范围。同时，仅需在100个样本上计算梯度和测量最终准确性。

Result: 与原始LASER方法相比，该方法可以进一步减少模型的过拟合，提高了下游任务的准确性，且搜索时间显著减少。无需微调整个数据集，仅使用100个样本即可有效地适应新数据集。

Conclusion: 新方法提供了快速和鲁棒的适应算法，使得大型语言模型能够轻松适应新数据集，从而提高了应用效率。

Abstract: Recently, Sharma et al. suggested a method called Layer-SElective-Rank
reduction (LASER) which demonstrated that pruning high-order components of
carefully chosen LLM's weight matrices can boost downstream accuracy -- without
any gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each
requiring full-dataset forward passes) makes it impractical for rapid
deployment. We demonstrate that this overhead can be removed and find that: (i)
Only a small, carefully chosen subset of matrices needs to be inspected --
eliminating the layer-by-layer sweep, (ii) The gradient of each matrix's
singular values pinpoints which matrices merit reduction, (iii) Increasing the
factorization search space by allowing matrices rows to cluster around multiple
subspaces and then decomposing each cluster separately further reduces
overfitting on the original training data and further lifts accuracy by up to
24.6 percentage points, and finally, (iv) we discover that evaluating on just
100 samples rather than the full training data -- both for computing the
indicative gradients and for measuring the final accuracy -- suffices to
further reduce the search time; we explain that as adaptation to downstream
tasks is dominated by prompting style, not dataset size. As a result, we show
that combining these findings yields a fast and robust adaptation algorithm for
downstream tasks. Overall, with a single gradient step on 100 examples and a
quick scan of the top candidate layers and factorization techniques, we can
adapt LLMs to new datasets -- entirely without fine-tuning.

</details>


### [155] [SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models for Time Series](https://arxiv.org/abs/2510.20273)
*Qitai Tan,Yiyun Chen,Mo Li,Ruiwen Gu,Yilin Su,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种新的合成数据驱动的时间序列预测模型评估框架SynTSBench，用以解决目前时间序列预测模型在实际应用中的性能不稳定问题。该框架通过可编程特征配置系统地评估模型的基本建模能力，并针对模型性能进行多维度的分析与评测，为选择合适的时间序列预测模型提供指导依据。实验结果表明，目前的深度学习模型在不同类型的时间序列特征上的表现并不接近最优基准线。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在实际应用中性能不稳定，尽管已有的深度学习模型在标准基准数据集上取得出色结果，但它们在现实世界中的表现仍然不尽如人意。研究的主要动机是通过创建新的评估框架来解决这个长期存在的问题。该框架旨在识别现有模型的不足，以指导更加合理的选择和应用。

Method: 提出了一种新的时间序列预测模型评估框架SynTSBench，该框架具有三个核心分析维度：(1)时间特征分解和能力映射，(2)数据不规则下的鲁棒性分析，(3)理论最优基准对比。这三种维度可以评估和解释模型的性能和适用性。

Result: 研究实验表明，当前的深度学习模型在处理不同类型的时间序列特征时并未达到优质的基准线，且框架可以有效地量化各种模型性能特性，并为模型的选择提供指导。

Conclusion: 传统评估框架存在难以清晰表示模型优势和劣势的问题，本研究提出了一种全新的、基于合成数据的评估框架以改善这一现状，这将有助于提升时间序列预测模型的实际性能和广泛适用性。

Abstract: Recent advances in deep learning have driven rapid progress in time series
forecasting, yet many state-of-the-art models continue to struggle with robust
performance in real-world applications, even when they achieve strong results
on standard benchmark datasets. This persistent gap can be attributed to the
black-box nature of deep learning architectures and the inherent limitations of
current evaluation frameworks, which frequently lack the capacity to provide
clear, quantitative insights into the specific strengths and weaknesses of
different models, thereby complicating the selection of appropriate models for
particular forecasting scenarios. To address these issues, we propose a
synthetic data-driven evaluation paradigm, SynTSBench, that systematically
assesses fundamental modeling capabilities of time series forecasting models
through programmable feature configuration. Our framework isolates confounding
factors and establishes an interpretable evaluation system with three core
analytical dimensions: (1) temporal feature decomposition and capability
mapping, which enables systematic evaluation of model capacities to learn
specific pattern types; (2) robustness analysis under data irregularities,
which quantifies noise tolerance thresholds and anomaly recovery capabilities;
and (3) theoretical optimum benchmarking, which establishes performance
boundaries for each pattern type-enabling direct comparison between model
predictions and mathematical optima. Our experiments show that current deep
learning models do not universally approach optimal baselines across all types
of temporal features.The code is available at
https://github.com/TanQitai/SynTSBench

</details>


### [156] [KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models](https://arxiv.org/abs/2510.20278)
*Guangyu Dai,Siliang Tang,Yueting Zhuang*

Main category: cs.LG

TL;DR: 研究提出了一种基于KAN的协作模型(KCM)来改善大模型和小模型协作中存在的问题。在语言、视觉和跨模态任务中，KCM相比传统的MLP展示出了更好的性能和资源效率，同时减少了灾难性遗忘问题，提高了长尾数据的准确性。


<details>
  <summary>Details</summary>
Motivation: 大模型和小模型协作存在的问题包括显著的精度下降、灾难性遗忘的加重以及幻觉问题的放大。这一研究旨在通过引入一种新的设计思路解决这些问题，即使用KAN来建立协作模型(KCM)。

Method: 提出并应用一种基于KAN架构的小模型来与大模型进行协作。KAN架构相较于传统的多层感知机(MLP)具有更好的可视化和可解释性，且能够减轻灾难性遗忘问题。在语言、视觉和视觉-语言跨模态任务中采用KCM进行了验证。

Result: 实验结果表明，与纯大模型方法相比，应用KCM进行大模型和小模型的协作框架，在保持任务准确性不变的情况下，将大模型的推理调用量减少了数倍，从而显著降低了计算资源消耗。同时，基于KAN的小协作模型大大减轻了灾难性遗忘，显著提高了长尾数据的精度。

Conclusion: 总的来说，KCM模型相较于基于MLP的模型，在所有指标上都显示出了优越的性能，表明KAN是一种改进大-小模型协作的重要方法。

Abstract: In recent years, Pretrained Large Models(PLMs) researchers proposed
large-small model collaboration frameworks, leveraged easily trainable small
models to assist large models, aim to(1) significantly reduce computational
resource consumption while maintaining comparable accuracy, and (2) enhance
large model performance in specialized domain tasks. However, this
collaborative paradigm suffers from issues such as significant accuracy
degradation, exacerbated catastrophic forgetting, and amplified hallucination
problems induced by small model knowledge. To address these challenges, we
propose a KAN-based Collaborative Model (KCM) as an improved approach to
large-small model collaboration. The KAN utilized in KCM represents an
alternative neural network architecture distinct from conventional MLPs.
Compared to MLPs, KAN offers superior visualizability and interpretability
while mitigating catastrophic forgetting. We deployed KCM in large-small model
collaborative systems across three scenarios: language, vision, and
vision-language cross-modal tasks. The experimental results demonstrate that,
compared with pure large model approaches, the large-small model collaboration
framework utilizing KCM as the collaborative model significantly reduces the
number of large model inference calls while maintaining near-identical task
accuracy, thereby substantially lowering computational resource consumption.
Concurrently, the KAN-based small collaborative model markedly mitigates
catastrophic forgetting, leading to significant accuracy improvements for
long-tail data. The results reveal that KCM demonstrates superior performance
across all metrics compared to MLP-based small collaborative models (MCM).

</details>


### [157] [MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs](https://arxiv.org/abs/2510.20762)
*Jan Sobotka,Luca Baroni,Ján Antolík*

Main category: cs.LG

TL;DR: MEIcoder is introduced as a novel decoding method leveraging neuron-specific MEIs, a structural similarity index measure loss, and adversarial training. It achieves high performance in reconstructing visual stimuli from V1 activity, especially with small datasets. The method is validated through ablation studies and scaling experiments.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the challenge of decoding visual stimuli from neural activity due to limited biological data, especially in primates or humans.

Method: MEIcoder uses neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training to improve the decoding performance.

Result: MEIcoder performs exceptionally well, particularly in small datasets, reconstructing high-fidelity natural-looking images from as few as 1,000-2,500 neurons.

Conclusion: The study demonstrates the feasibility of reliable decoding of visual stimuli from early visual system activity and provides valuable insights for neuroscience and neuroengineering.

Abstract: Decoding visual stimuli from neural population activity is crucial for
understanding the brain and for applications in brain-machine interfaces.
However, such biological data is often scarce, particularly in primates or
humans, where high-throughput recording techniques, such as two-photon imaging,
remain challenging or impossible to apply. This, in turn, poses a challenge for
deep learning decoding techniques. To overcome this, we introduce MEIcoder, a
biologically informed decoding method that leverages neuron-specific most
exciting inputs (MEIs), a structural similarity index measure loss, and
adversarial training. MEIcoder achieves state-of-the-art performance in
reconstructing visual stimuli from single-cell activity in primary visual
cortex (V1), especially excelling on small datasets with fewer recorded
neurons. Using ablation studies, we demonstrate that MEIs are the main drivers
of the performance, and in scaling experiments, we show that MEIcoder can
reconstruct high-fidelity natural-looking images from as few as 1,000-2,500
neurons and less than 1,000 training data points. We also propose a unified
benchmark with over 160,000 samples to foster future research. Our results
demonstrate the feasibility of reliable decoding in early visual system and
provide practical insights for neuroscience and neuroengineering applications.

</details>


### [158] [ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows](https://arxiv.org/abs/2510.20279)
*Penghao Wang,Yuhao Zhou,Mengxuan Wu,Ziheng Qin,Bangyuan Zhu,Shengbin Huang,Xuanlei Zhao,Panpan Zhang,Xiaojiang Peng,Yuzhang Shang,Jianfei Yang,Zheng Zhu,Tianlong Chen,Zhangyang Wang,Kai Wang*

Main category: cs.LG

TL;DR: 提出了CS-54k，这是一个包含14k计算机科学论文中的科学问答对的高质量语料库，用于评估和训练AI在科学研究中的辅助能力。实验表明，高质量的数据训练比预训练规模更能提高AI的表现。7B规模的模型在适当训练下，甚至能超越更大规模的GPT-4.1，GPT-4o和Gemini 2.5 Pro等模型。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的发展，构建一个可以协助人类完成整个科学研究过程的AI助手成为目标。然而，对于这样一个系统的评估需要一个全面的工作流程基准，而不仅仅是孤立的任务评估。因此，构建了一个高质量的语料库CS-54k来实现这一目标，并进一步分为CS-4k和CS-50k，前者用于评估AI在科学研究中的辅助能力，后者用于大规模训练。通过实验验证了高质量训练数据的重要性，并展示了即使规模较小的模型也能够超越大规模的商用模型。

Method: 通过论文提取和检索增强生成（RAG）结合多阶段质量控制构建了涵盖14k篇论文中科学问答对的高质量语料库CS-54k。同时，创建了两个互补的子集：用于评估AI科研辅助能力的CS-4k，和作为大规模训练数据集的CS-50k，并通过监督学习和强化学习对其进行训练，展示其性能优势和潜力。

Result: 实验展示了CS-4k可以将现有的大型语言模型划分为不同的能力级别，训练后的模型在科研辅助任务上有了显著的性能提升。7B规模的模型在适当训练下，即使规模较小，也能超越更大规模的商用模型如GPT-4.1和Gemini 2.5 Pro。这表明高质量的数据训练比预训练规模更能提高AI的表现。

Conclusion: 本研究通过创建高质量的训练语料库CS-4k和CS-50k，以及通过这些数据训练AI模型的方法，促进了AI在计算机科学领域成为可靠的研究助手。进一步证明了，相较于模型预训练规模，质量训练数据对于提高AI模型的科学研究辅助能力更加重要。

Abstract: As large language models (LLMs) advance, the ultimate vision for their role
in science is emerging: we could build an AI collaborator to effectively assist
human beings throughout the entire scientific research process. We refer to
this envisioned system as ResearchGPT. Given that scientific research
progresses through multiple interdependent phases, achieving this vision
requires rigorous benchmarks that evaluate the end-to-end workflow rather than
isolated sub-tasks. To this end, we contribute CS-54k, a high-quality corpus of
scientific Q&A pairs in computer science, built from 14k CC-licensed papers. It
is constructed through a scalable, paper-grounded pipeline that combines
retrieval-augmented generation (RAG) with multi-stage quality control to ensure
factual grounding. From this unified corpus, we derive two complementary
subsets: CS-4k, a carefully curated benchmark for evaluating AI's ability to
assist scientific research, and CS-50k, a large-scale training dataset.
Extensive experiments demonstrate that CS-4k stratifies state-of-the-art LLMs
into distinct capability tiers. Open models trained on CS-50k with supervised
training and reinforcement learning demonstrate substantial improvements. Even
7B-scale models, when properly trained, outperform many larger proprietary
systems, such as GPT-4.1, GPT-4o, and Gemini 2.5 Pro. This indicates that
making AI models better research assistants relies more on domain-aligned
training with high-quality data than on pretraining scale or general benchmark
performance. We release CS-4k and CS-50k in the hope of fostering AI systems as
reliable collaborators in CS research.

</details>


### [159] [InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling](https://arxiv.org/abs/2510.20302)
*Yuhang Wang*

Main category: cs.LG

TL;DR: 论文提出了一种新的多变量时间序列预测方法InvDec，其结合了时序编码与变元解码，有效分离了时间模式和跨变量依赖。通过实验证明，InvDec在处理高维数据集时表现更佳，特别是在电力、天气和交通数据集上取得了显著改善。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理多变量时间序列时，要么侧重于时间模式建模而忽视变量之间的关联性，要么过分关注变量之间的关系而牺牲时间编码。为此，提出了InvDec，以实现时间模式和变量层次上解码的统一建模，不仅能够保留时间特征的完整性和丰富变量特定表示，还能动态平衡时序和变量信息。

Method: InvDec结合了基于补丁的时间序列编码器和通过变量级自我注意力操作的反转解码器。引入了延迟变量嵌入，利用变量间的特定表示，丰富了时间编码后的变量特定表示，同时引入了一个自适应残差融合机制，用于在不同的数据集维度上动态平衡时间与变量信息。在实验中，使用PatchTST实例化InvDec得到了InvDec-PatchTST架构，该架构在多个基准数据集上的表现优于PatchTST。

Result: 在七个基准测试上进行的广泛实验表明，与仅使用PatchTST相比，InvDec在多个高维数据集中表现出显著优势，特别是在Electricity、Weather、Traffic等数据集上的表现更佳。此外，消融研究验证了InvDec的每一个组件，分析显示随着数据集维度的增加，InvDec的优势越来越明显，这表明跨变量建模变得至关重要。

Conclusion: 该研究提出了InvDec，这是第一个结合了时间编码和变量解码的架构，为多变量时间序列建模提供了高效和有力的方法。实验验证了这种方法在广泛的多变量时间序列预测任务中的先进性和有效性，尤其是在高维度的数据集上。

Abstract: Multivariate time series forecasting requires simultaneously modeling
temporal patterns and cross-variate dependencies. Channel-independent methods
such as PatchTST excel at temporal modeling but ignore variable correlations,
while pure variate-attention approaches such as iTransformer sacrifice temporal
encoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that
achieves principled separation between temporal encoding and variate-level
decoding. InvDec combines a patch-based temporal encoder with an inverted
decoder operating on the variate dimension through variate-wise self-attention.
We introduce delayed variate embeddings that enrich variable-specific
representations only after temporal encoding, preserving temporal feature
integrity. An adaptive residual fusion mechanism dynamically balances temporal
and variate information across datasets of varying dimensions. Instantiating
InvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven
benchmarks demonstrate significant gains on high-dimensional datasets: 20.9%
MSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and
2.7% gain on Traffic compared to PatchTST, while maintaining competitive
performance on low-dimensional ETT datasets. Ablation studies validate each
component, and analysis reveals that InvDec's advantage grows with dataset
dimensionality, confirming that cross-variate modeling becomes critical as the
number of variables increases.

</details>


### [160] [Ask a Strong LLM Judge when Your Reward Model is Uncertain](https://arxiv.org/abs/2510.20369)
*Zhenghao Xu,Qin Lu,Qingru Zhang,Liang Qiu,Ilgee Hong,Changlong Yu,Wenlin Yao,Yao Liu,Haoming Jiang,Lihong Li,Hyokun Yun,Tuo Zhao*

Main category: cs.LG

TL;DR: 提出了一种基于不确定性的路由框架，在强化学习和人类反馈（RLHF）中有效地结合了快速奖励模型和成本高昂的强大LLM裁判，通过优势估计和策略梯度方法中的成对偏好分类来量化不确定性，提升在线RLHF性能而不增加成本。


<details>
  <summary>Details</summary>
Motivation: 经典RMs容易受到奖励欺骗并且泛化能力低，而强大的LLM裁判虽然具备出色的泛化能力但计算成本高昂，不适合在线RLHF。

Method: 通过将策略梯度方法中的优势估计重新表述为成对偏好分类问题，该方法实现了对不确定性的精确量化，并在此基础上设计了基于不确定性的路由策略，以最低的成本最优化地使用强大但昂贵的LLM裁判和低成本快速的RMs。

Result: 实验证明，该不确定性路由策略在保持同等成本的情况下显著优于随机选择裁判策略，并且提高了在线RLHF的最终对齐结果。

Conclusion: 通过引入基于不确定性的路由策略，可以使智能系统在进行复杂决策时无需付出额外的计算资源，更加有效地将低成本、快速的RMs和强大但计算昂贵的LLM裁判结合起来，提高RLHF的性能。

Abstract: Reward model (RM) plays a pivotal role in reinforcement learning with human
feedback (RLHF) for aligning large language models (LLMs). However, classical
RMs trained on human preferences are vulnerable to reward hacking and
generalize poorly to out-of-distribution (OOD) inputs. By contrast, strong LLM
judges equipped with reasoning capabilities demonstrate superior
generalization, even without additional training, but incur significantly
higher inference costs, limiting their applicability in online RLHF. In this
work, we propose an uncertainty-based routing framework that efficiently
complements a fast RM with a strong but costly LLM judge. Our approach
formulates advantage estimation in policy gradient (PG) methods as pairwise
preference classification, enabling principled uncertainty quantification to
guide routing. Uncertain pairs are forwarded to the LLM judge, while confident
ones are evaluated by the RM. Experiments on RM benchmarks demonstrate that our
uncertainty-based routing strategy significantly outperforms random judge
calling at the same cost, and downstream alignment results showcase its
effectiveness in improving online RLHF.

</details>


### [161] [Hierarchical Time Series Forecasting with Robust Reconciliation](https://arxiv.org/abs/2510.20383)
*Shuhei Aikawa,Aru Suzuki,Kei Yoshitake,Kanata Teshigawara,Akira Iwabuchi,Ken Kobayashi,Kazuhide Nakata*

Main category: cs.LG

TL;DR: 本文提出了一种用于分层时间序列预测的鲁棒优化框架，该框架考虑了估计协方差矩阵中的不确定性，从而提高了预测性能


<details>
  <summary>Details</summary>
Motivation: 现有分层预测方法中的协方差矩阵估计偏差可能会降低预测性能

Method: 提出了一种基于不确定性的完整优化框架来解决分层时间序列预测问题

Result: 数值实验表明，所提出的鲁棒性协调方法比现有的分层预测方法具有更好的预测性能

Conclusion: 结果显示，将不确定性纳入协调过程可以提高预测性能

Abstract: This paper focuses on forecasting hierarchical time-series data, where each
higher-level observation equals the sum of its corresponding lower-level time
series. In such contexts, the forecast values should be coherent, meaning that
the forecast value of each parent series exactly matches the sum of the
forecast values of its child series. Existing hierarchical forecasting methods
typically generate base forecasts independently for each series and then apply
a reconciliation procedure to adjust them so that the resulting forecast values
are coherent across the hierarchy. These methods generally derive an optimal
reconciliation, using a covariance matrix of the forecast error. In practice,
however, the true covariance matrix is unknown and has to be estimated from
finite samples in advance. This gap between the true and estimated covariance
matrix may degrade forecast performance. To address this issue, we propose a
robust optimization framework for hierarchical reconciliation that accounts for
uncertainty in the estimated covariance matrix. We first introduce an
uncertainty set for the estimated covariance matrix and formulate a
reconciliation problem that minimizes the worst-case expected squared error
over this uncertainty set. We show that our problem can be cast as a
semidefinite optimization problem. Numerical experiments demonstrate that the
proposed robust reconciliation method achieved better forecast performance than
existing hierarchical forecasting methods, which indicates the effectiveness of
integrating uncertainty into the reconciliation process.

</details>


### [162] [Why DPO is a Misspecified Estimator and How to Fix It](https://arxiv.org/abs/2510.20413)
*Aditya Gopalan,Sayak Ray Chowdhury,Debangshu Banerjee*

Main category: cs.LG

TL;DR: 本文提出了AuxDPO算法，通过在DPO损失函数中引入额外的辅助变量来减轻DPO的模型失配问题，使得其性能优于直接偏好优化（DPO）和其他两阶段强化学习方法。该方法在教条式决策设置和LLM对齐任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 研究者发现了直接偏好优化（DPO）在处理真实奖励函数时存在模型失配的问题，导致模型性能下降和对输入偏好数字分布的高敏感度。为了缓解这个问题，研究者提出了AuxDPO算法，以提高模型性能和鲁棒性。目标是通过引入辅助变量，使DPO更接近于两阶段强化学习方法的解决方案。

Method: 研究者从统计估计的角度分析了DPO，并将其行为与参数策略类中的自然梯度步骤进行比较。然后，提出了引入辅助变量的AuxDPO方法，它通过修改损失函数来引导模型朝着更接近于RLHF解的方向演化。此方法既考虑了从教条式决策问题到大型语言模型对齐任务的广泛适用性。

Result: 实验表明，与直接偏好优化（DPO）和两阶段的强化学习方法（RLHF）相比，AuxDPO表现出优越的性能。这表明，通过在DPO的损失函数中增加辅助变量可以有效缓解模型的失配问题，提高模型的对齐性能。

Conclusion: 研究者证明了直接偏好优化（DPO）存在的模型失配问题，并提出了一个改进方法AuxDPO，引入辅助变量以引导模型更连贯稳定的演化，特别是在面对复杂的奖励函数时。实验结果展示了AuxDPO在教条式决策设置和具有代表性的大规模语言模型对齐任务上的优越性能。

Abstract: Direct alignment algorithms such as Direct Preference Optimization (DPO)
fine-tune models based on preference data, using only supervised learning
instead of two-stage reinforcement learning with human feedback (RLHF). We show
that DPO encodes a statistical estimation problem over reward functions induced
by a parametric policy class. When the true reward function that generates
preferences cannot be realized via the policy class, DPO becomes misspecified,
resulting in failure modes such as preference order reversal, worsening of
policy reward, and high sensitivity to the input preference data distribution.
On the other hand, we study the local behavior of two-stage RLHF for a
parametric class and relate it to a natural gradient step in policy space. Our
fine-grained geometric characterization allows us to propose AuxDPO, which
introduces additional auxiliary variables in the DPO loss function to help move
towards the RLHF solution in a principled manner and mitigate the
misspecification in DPO. We empirically demonstrate the superior performance of
AuxDPO on didactic bandit settings as well as LLM alignment tasks.

</details>


### [163] [Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes](https://arxiv.org/abs/2510.20414)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yongli Ren,Yan Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新的阈值方法来解决标记分布不平衡问题，通过学习阈值调整预测标记的概率，而不是直接基于标记概率进行预测。此外，还开发了一种新颖的神经MTPP模型来进行有效的时间抽样和标记概率估计。实验证明了该方法在预测下一事件的标记和时间方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的MTPP模型在处理标记分布不平衡的问题时存在困难，尤其是对于稀有标记的事件。因此，需要一种新的方法来优化这些模型在预测标记和事件时间上的性能。

Method: 提出了一种基于阈值的方法来调整预测标记的概率，该方法根据标记的先验概率标准化标记概率。此外，还采用了神经MTPP模型来提高性能。这种模型能够有效抽样时间和估计标记概率，从而提高预测的准确性。

Result: 实验结果显示，所提出的方法在预测标记和事件时间方面表现优于多种基准方法，特别是在处理标记分布不平衡的情况时。

Conclusion: 本文通过引入阈值方法和神经MTPP模型，有效解决了现有MTPP模型在处理标记分布不平衡问题时的挑战，提高了模型的预测性能。

Abstract: Marked Temporal Point Process (MTPP) has been well studied to model the event
distribution in marked event streams, which can be used to predict the mark and
arrival time of the next event. However, existing studies overlook that the
distribution of event marks is highly imbalanced in many real-world
applications, with some marks being frequent but others rare. The imbalance
poses a significant challenge to the performance of the next event prediction,
especially for events of rare marks. To address this issue, we propose a
thresholding method, which learns thresholds to tune the mark probability
normalized by the mark's prior probability to optimize mark prediction, rather
than predicting the mark directly based on the mark probability as in existing
studies. In conjunction with this method, we predict the mark first and then
the time. In particular, we develop a novel neural MTPP model to support
effective time sampling and estimation of mark probability without
computationally expensive numerical improper integration. Extensive experiments
on real-world datasets demonstrate the superior performance of our solution
against various baselines for the next event mark and time prediction. The code
is available at https://github.com/undes1red/IFNMTPP.

</details>


### [164] [An Empirical Study of Sample Selection Strategies for Large Language Model Repair](https://arxiv.org/abs/2510.20428)
*Xuran Li,Jingyi Wang*

Main category: cs.LG

TL;DR: 研究通过评估五种代表性选择方法评估了用于大语言模型修复的数据优先级策略，发现Semantic-Aware Prioritized Sampling (SAPS) 方法在去毒化、性能保存和效率方面表现最佳。论文提出的选择驱动修复是大规模语言模型维护可靠性的高效可扩展方法。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型在实际系统中部署时，可能会产生有毒或带有偏见的输出，影响安全性和信任。基于此研究提出了选择驱动修复方法来解决这个问题，但这种方法的有效性依赖于什么样的采样标准需要进一步明确，因此这项研究进行了系统性分析。

Method: 研究通过评估五种代表性选择方法——随机采样、K中心、基于梯度范数的选择、分层覆盖度和提出的语义感知优先采样方法——来评估和选择最优数据优先级策略。研究中使用了有毒文本减少、在WikiText-2和LAMBADA上的困惑度等指标评估修复有效性。同时，还使用了Repair Proximity Score (RPS)，Overall Performance Score (OPS) 和 Repair Efficiency Score (RES) 三种综合指标评估数据策略。

Result: 实验证明，提出的Semantic-Aware Prioritized Sampling (SAPS) 方法在有毒文本减少、性能保存和效率方面表现最佳，其余方法根据模型大小和修复方法的不同表现也有所区分。如较大的模型随机采样效果较好。并且实验还表明，修复的最佳数据比例取决于模型规模和修复方法，这提示样本选择可以视为修复流水线的一个可调组件。

Conclusion: 根据实验结果，选择驱动的修复是一种高效且可扩展的方法，可以用于维护大规模语言模型的可靠性。

Abstract: Large language models (LLMs) are increasingly deployed in real-world systems,
yet they can produce toxic or biased outputs that undermine safety and trust.
Post-hoc model repair provides a practical remedy, but the high cost of
parameter updates motivates selective use of repair data. Despite extensive
prior work on data selection for model training, it remains unclear which
sampling criteria are most effective and efficient when applied specifically to
behavioral repair of large generative models. Our study presents a systematic
analysis of sample prioritization strategies for LLM repair. We evaluate five
representative selection methods, including random sampling, K-Center,
gradient-norm-based selection(GraNd), stratified coverage (CCS), and a
Semantic-Aware Prioritized Sampling (SAPS) approach we proposed. Repair
effectiveness and trade-offs are assessed through toxicity reduction,
perplexity on WikiText-2 and LAMBADA, and three composite metrics: the Repair
Proximity Score (RPS), the Overall Performance Score (OPS), and the Repair
Efficiency Score (RES). Experimental results show that SAPS achieves the best
balance between detoxification, utility preservation, and efficiency,
delivering comparable or superior repair outcomes with substantially less data.
Random sampling remains effective for large or robust models, while
high-overhead methods such as CCS and GraNd provide limited benefit. The
optimal data proportion depends on model scale and repair method, indicating
that sample selection should be regarded as a tunable component of repair
pipelines. Overall, these findings establish selection-based repair as an
efficient and scalable paradigm for maintaining LLM reliability.

</details>


### [165] [Explainable Benchmarking through the Lense of Concept Learning](https://arxiv.org/abs/2510.20439)
*Quannian Zhang,Michael Röder,Nikit Srivastava,N'Dah Jean Kouagou,Axel-Cyrille Ngonga Ngomo*

Main category: cs.LG

TL;DR: 本文提出了一个新的基准测试方法，称为可解释性基准测试，用于自动生成知识图谱基础问答系统性能的解释。通过一种称为PruneCEL的新概念学习方法，我们的实验结果表明，与当前最佳的概念学习方法相比，PruneCEL在可解释性基准测试任务上F1度量最高可提高0.55点。并且在一项有41名参与者参与的任务导向用户研究中，参与者在80%的情况下可以准确预测系统的性能基于我们的解释。


<details>
  <summary>Details</summary>
Motivation: 系统性能往往通过少量的评估指标来总结，这样的评估使得详细分析和进一步开发或使用的见解获取成为了繁重且含偏差的手动任务。因此，本文提出了可解释性基准测试的概念，它能自动生成系统的性能解释，从而增强评估过程的可解释性，促进系统的进一步开发和使用。

Method: 该研究提出了一种新的概念学习方法称为PruneCEL，用来为知识图谱支撑的问答系统提供可解释性基准测试。PruneCEL方法主要用于生成关于系统性能的详细解释，因此解决了当前评估方法中依赖少量指标，且难以获取详细的、有价值的分析的问题。

Result: PruneCEL在可解释性基准测试任务上，相较于当前最佳的概念学习方案，F1度量最多提高了0.55点，并且在一项任务导向的用户研究中，参与者能够基于解释准确地预测系统行为的比例达到80%。这表明，PruneCEL在提供有用的性能解释上的有效性。

Conclusion: 本文首次实现了可解释性基准测试的方法，证明了采用PruneCEL算法可以生成有效的系统性能解释，并且通过用户提供的反馈验证了这种解释的有效性。这些发现对于促进问答系统和其他类型的系统基准测试具有重要意义。

Abstract: Evaluating competing systems in a comparable way, i.e., benchmarking them, is
an undeniable pillar of the scientific method. However, system performance is
often summarized via a small number of metrics. The analysis of the evaluation
details and the derivation of insights for further development or use remains a
tedious manual task with often biased results. Thus, this paper argues for a
new type of benchmarking, which is dubbed explainable benchmarking. The aim of
explainable benchmarking approaches is to automatically generate explanations
for the performance of systems in a benchmark. We provide a first instantiation
of this paradigm for knowledge-graph-based question answering systems. We
compute explanations by using a novel concept learning approach developed for
large knowledge graphs called PruneCEL. Our evaluation shows that PruneCEL
outperforms state-of-the-art concept learners on the task of explainable
benchmarking by up to 0.55 points F1 measure. A task-driven user study with 41
participants shows that in 80\% of the cases, the majority of participants can
accurately predict the behavior of a system based on our explanations. Our code
and data are available at https://github.com/dice-group/PruneCEL/tree/K-cap2025

</details>


### [166] [Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models](https://arxiv.org/abs/2510.20477)
*Rui Zhu,Song-Lin Lv,Zi-Kang Wang,Lan-Zhe Guo*

Main category: cs.LG

TL;DR: 我们提出了一种简单有效的插件式方法Bi-CoG，用于解决半监督微调中的模型偏差和超参数敏感性问题，该方法通过同时利用模型间的和模型内的一致性，以及错误感知的动态伪标签分配策略，来生成高质量且低偏差的伪标签。理论分析和广泛的实验证明了Bi-CoG的有效性，它在14个数据集上持续显著提高现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的利用图像-语言预训练模型微调和半监督学习结合的方法通常受到模型偏差和超参数敏感性的限制。因此，我们希望通过新的方法提高这些模型在少标签场景下的性能。

Method: 我们提出了一种新的插件式方法，称为Bi-CoG，它通过同时利用模型间的和模型内的预测一致性，同时结合错误感知的动态伪标签分配策略，来提高伪标签的质量和减少偏差。

Result: 理论分析和实验表明Bi-CoG在多种数据集上显著提高了现有方法的性能。

Conclusion: Bi-CoG是一种有效解决少标签场景下模型偏差和超参数敏感性问题的新方法，它通过利用模型间和模型内的一致性，来生成高质量且低偏差的伪标签。

Abstract: Exploiting unlabeled data through semi-supervised learning (SSL) or
leveraging pre-trained models via fine-tuning are two prevailing paradigms for
addressing label-scarce scenarios. Recently, growing attention has been given
to combining fine-tuning of pre-trained vision-language models (VLMs) with SSL,
forming the emerging paradigm of semi-supervised fine-tuning. However, existing
methods often suffer from model bias and hyperparameter sensitivity, due to
reliance on prediction consistency or pre-defined confidence thresholds. To
address these limitations, we propose a simple yet effective plug-and-play
methodology named
$\underline{\textbf{Bi-Co}}$nsistency-$\underline{\textbf{G}}$uided
Self-Training (Bi-CoG), which assigns high-quality and low-bias pseudo-labels,
by simultaneously exploiting inter-model and intra-model consistency, along
with an error-aware dynamic pseudo-label assignment strategy. Both theoretical
analysis and extensive experiments over 14 datasets demonstrate the
effectiveness of Bi-CoG, which consistently and significantly improves the
performance of existing methods.

</details>


### [167] [SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment](https://arxiv.org/abs/2510.20540)
*Abdulmomen Ghalkha,Zhuojun Tian,Chaouki Ben Issaid,Mehdi Bennis*

Main category: cs.LG

TL;DR: SheafAlign是一种用于分布式多模态对齐的框架，通过多个比较空间来代替单一空间的对齐方式，显示出比现有方法更好的零样本泛化性能，跨模态对齐能力以及对缺失模态的鲁棒性，并且通信成本降低了50%。


<details>
  <summary>Details</summary>
Motivation: 传统多模态对齐方法假定所有模态之间存在冗余，在现实中这种假设并不总是成立。因此，需要一种新的方法来解决这种局限性，特别是在分布式场景下。SheafAlign正是为了应对这种局限性而提出，它能够在模态之间存在独立信息的情况下进行有效的多模态对齐。

Method: SheafAlign采用了代数拓扑中的sheaf theory，通过sheaf结构来建模模态之间的关系，并利用基于对比学习的目标进行去中心化的训练。这种方法避免了传统方法对所有模态相互冗余的要求，能够在保持共享信息的同时保留模态的独特信息。

Result: 实验结果显示，SheafAlign在多模态感知数据集上的表现优越，包括更好的零样本泛化、跨模态对齐能力以及对缺失模态的鲁棒性，且通信成本比现有的最先进基线降低了50%。

Conclusion: 与现有方法相比，SheafAlign为解决分布式多模态对齐问题提供了一个新的视角，通过采用无中心的数据处理方式来替代传统的基于中心的数据处理方式，为多模态数据处理的研究打开了新的大门。

Abstract: Conventional multimodal alignment methods assume mutual redundancy across all
modalities, an assumption that fails in real-world distributed scenarios. We
propose SheafAlign, a sheaf-theoretic framework for decentralized multimodal
alignment that replaces single-space alignment with multiple comparison spaces.
This approach models pairwise modality relations through sheaf structures and
leverages decentralized contrastive learning-based objectives for training.
SheafAlign overcomes the limitations of prior methods by not requiring mutual
redundancy among all modalities, preserving both shared and unique information.
Experiments on multimodal sensing datasets show superior zero-shot
generalization, cross-modal alignment, and robustness to missing modalities,
with 50\% lower communication cost than state-of-the-art baselines.

</details>


### [168] [A Unified Framework for Zero-Shot Reinforcement Learning](https://arxiv.org/abs/2510.20542)
*Jacopo Di Ventura,Jan Felix Kleuker,Aske Plaat,Thomas Moerland*

Main category: cs.LG

TL;DR: 提出了第一个用于零样本强化学习的统一框架，引入了一致的符号和分类法，将现有方法分为直接表示和组合表示两类，并为后续研究提供了坚实的基础


<details>
  <summary>Details</summary>
Motivation: 零样本的强化学习希望在没有额外训练和计划的情况下解决下游任务，但目前缺乏统一的分析方法。现有的方法分为直接表示和组合表示两大类，它们之间需要进行清晰地比较和分析，以发现它们之间的共性与差异

Method: 提供了一个明确和完整的零样本强化学习的统一框架，引入了统一的符号和分类方法，将其划分为直接表示和组合表示，以便更好地理解各种方法之间的共性与差异

Result: 明确了直接表示和组合表示的定义，深入探讨了各种方法之间的共性与差异，并推导了一个扩展的后续特征方法的界限，为未来的零样本强化学习研究提供明确的理论依据

Conclusion: 通过提供一个统一的零样本强化学习框架，本工作为现有的研究和未来的方向提供了一个原则性的基础，从而促进更广泛的智能体的开发

Abstract: Zero-shot reinforcement learning (RL) has emerged as a setting for developing
general agents in an unsupervised manner, capable of solving downstream tasks
without additional training or planning at test-time. Unlike conventional RL,
which optimizes policies for a fixed reward, zero-shot RL requires agents to
encode representations rich enough to support immediate adaptation to any
objective, drawing parallels to vision and language foundation models. Despite
growing interest, the field lacks a common analytical lens.
  We present the first unified framework for zero-shot RL. Our formulation
introduces a consistent notation and taxonomy that organizes existing
approaches and allows direct comparison between them. Central to our framework
is the classification of algorithms into two families: direct representations,
which learn end-to-end mappings from rewards to policies, and compositional
representations, which decompose the representation leveraging the substructure
of the value function. Within this framework, we highlight shared principles
and key differences across methods, and we derive an extended bound for
successor-feature methods, offering a new perspective on their performance in
the zero-shot regime. By consolidating existing work under a common lens, our
framework provides a principled foundation for future research in zero-shot RL
and outlines a clear path toward developing more general agents.

</details>


### [169] [Embedding the MLOps Lifecycle into OT Reference Models](https://arxiv.org/abs/2510.20590)
*Simon Schindler,Christoph Binder,Lukas Lürzer,Stefan Huber*

Main category: cs.LG

TL;DR: MLOps与OT系统的结合面临挑战，本文提出一种方法将MLOps实践嵌入到OT参考模型中，并评估了RAMI 4.0和ISA-95标准在MLOps集成中的适用性。研究发现表明标准的MLOps实践不能直接移植到OT环境中，但通过现有参考模型的结构性调整可以实现成功集成。


<details>
  <summary>Details</summary>
Motivation: MLOps在工业领域越来越受欢迎，但将其集成到OT系统中存在障碍。本文旨在分析这些障碍并提出解决方案，以实现MLOps和OT系统的成功结合。

Method: 通过研究RAMI 4.0和ISA-95标准对MLOps集成的适用性，并通过实例展示了如何将MLOps生命周期组件映射到RAMI 4.0中。

Result: 研究展示了将MLOps实践嵌入OT参考模型中的可能路径，强调了结构性调整的重要性。

Conclusion: 虽然标准的MLOps实践不能直接应用于OT环境，但通过现有参考模型可以实现成功集成，为MLOps和OT系统的结合提供了新的方法。

Abstract: Machine Learning Operations (MLOps) practices are increas- ingly adopted in
industrial settings, yet their integration with Opera- tional Technology (OT)
systems presents significant challenges. This pa- per analyzes the fundamental
obstacles in combining MLOps with OT en- vironments and proposes a systematic
approach to embed MLOps prac- tices into established OT reference models. We
evaluate the suitability of the Reference Architectural Model for Industry 4.0
(RAMI 4.0) and the International Society of Automation Standard 95 (ISA-95) for
MLOps integration and present a detailed mapping of MLOps lifecycle compo-
nents to RAMI 4.0 exemplified by a real-world use case. Our findings
demonstrate that while standard MLOps practices cannot be directly transplanted
to OT environments, structured adaptation using existing reference models can
provide a pathway for successful integration.

</details>


### [170] [Convergence Analysis of SGD under Expected Smoothness](https://arxiv.org/abs/2510.20608)
*Yuta Kawamoto,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 本文对在预期平滑性（ES）条件下随机梯度下降(SGD)的收敛性进行了详尽的分析。优化了ES条件，并对全梯度的平方范数的期望值进行了界限推导，证明了在不同步长策略下$O(1/K)$的收敛率，并给出了显式的残差误差。


<details>
  <summary>Details</summary>
Motivation: 现有的SGD分析通常依赖于过强或过宽松的假设，如有界的方差或一致的噪声。本文提出了预期平滑性（ES）条件作为这些假设的灵活替代，旨在为SGD的收敛性提供更为精确的分析框架。

Method: 通过细化预期平滑性（ES）条件，结合采样依赖常数的解释，推导了全梯度范数平方的期望值的边界，并证明了在不同步长策略下$O(1/K)$的收敛率。文中给出了所有证明的完整细节。

Result: 本文证明了在预期平滑性（ES）条件下SGD的$O(1/K)$收敛率，所有分析均依赖于全新且更精确的ES条件。同时，证明中的分析框架可以适用不同的步长策略，并给出了相应的明确误差界。

Conclusion: 本文的贡献在于提出了一个新的框架，通过预期平滑性（ES）条件分析SGD的收敛性，统一并扩展了已有文献(Khaled和Richt'arik 2020; Umeda和Iiduka 2025)的结果，为SGD的进一步理解提供了理论基础。

Abstract: Stochastic gradient descent (SGD) is the workhorse of large-scale learning,
yet classical analyses rely on assumptions that can be either too strong
(bounded variance) or too coarse (uniform noise). The expected smoothness (ES)
condition has emerged as a flexible alternative that ties the second moment of
stochastic gradients to the objective value and the full gradient. This paper
presents a self-contained convergence analysis of SGD under ES. We (i) refine
ES with interpretations and sampling-dependent constants; (ii) derive bounds of
the expectation of squared full gradient norm; and (iii) prove $O(1/K)$ rates
with explicit residual errors for various step-size schedules. All proofs are
given in full detail in the appendix. Our treatment unifies and extends recent
threads (Khaled and Richt\'arik, 2020; Umeda and Iiduka, 2025).

</details>


### [171] [MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure Elucidation](https://arxiv.org/abs/2510.20615)
*Yang Han,Pengyu Wang,Kai Yu,Xin Chen,Lu Chen*

Main category: cs.LG

TL;DR: 本文提出了MS-BART，一种用于从质谱数据中解析分子结构的统一建模框架。通过大规模预训练和化学反馈机制，MS-BART能够在解决数据稀缺性的同时提高模型的准确性和鲁棒性，达到SOTA性能，并且比现有的扩散方法快了一个数量级。


<details>
  <summary>Details</summary>
Motivation: 质谱数据解析面临挑战，尤其是数据稀缺性。大型预训练模型虽然在其他领域有效，但在复杂和异质的质谱数据上效果不佳。因此，需要一种新方法来解决这一问题，提高质谱数据的解析能力。

Method: 提出MS-BART框架，结合大规模预训练和化学反馈机制，通过图谱-分子对进行跨模态学习，改进分子结构解析任务。框架包括模型预训练和微调两个阶段，以适应实际谱图中的变化。

Result: 在MassSpecGym和NPLIB1的12个评价指标中，MS-BART在5个达到了最先进的性能，且比基于扩散的方法快了一个数量级。实验表明，MS-BART在解析能力、鲁棒性和有效性方面表现出色。

Conclusion: 通过引入MS-BART框架并结合预训练和化学反馈机制，有效提高了从质谱数据中解析分子结构的能力，为后续的相关研究提供了新的思路和方法。

Abstract: Mass spectrometry (MS) plays a critical role in molecular identification,
significantly advancing scientific discovery. However, structure elucidation
from MS data remains challenging due to the scarcity of annotated spectra.
While large-scale pretraining has proven effective in addressing data scarcity
in other domains, applying this paradigm to mass spectrometry is hindered by
the complexity and heterogeneity of raw spectral signals. To address this, we
propose MS-BART, a unified modeling framework that maps mass spectra and
molecular structures into a shared token vocabulary, enabling cross-modal
learning through large-scale pretraining on reliably computed
fingerprint-molecule datasets. Multi-task pretraining objectives further
enhance MS-BART's generalization by jointly optimizing denoising and
translation task. The pretrained model is subsequently transferred to
experimental spectra through finetuning on fingerprint predictions generated
with MIST, a pre-trained spectral inference model, thereby enhancing robustness
to real-world spectral variability. While finetuning alleviates the
distributional difference, MS-BART still suffers molecular hallucination and
requires further alignment. We therefore introduce a chemical feedback
mechanism that guides the model toward generating molecules closer to the
reference structure. Extensive evaluations demonstrate that MS-BART achieves
SOTA performance across 5/12 key metrics on MassSpecGym and NPLIB1 and is
faster by one order of magnitude than competing diffusion-based methods, while
comprehensive ablation studies systematically validate the model's
effectiveness and robustness.

</details>


### [172] [On Optimal Hyperparameters for Differentially Private Deep Transfer Learning](https://arxiv.org/abs/2510.20616)
*Aki Rehn,Linzh Zhao,Mikko A. Heikkilä,Antti Honkela*

Main category: cs.LG

TL;DR: 研究发现，与当前理论理解不同的是，在强隐私约束下，较大的剪裁边界$C$表现更好，而现有的调优批次大小$B$的方法并不总是有效。研究还指出使用单一的$(C,B)$设置可能会导致性能下降，尤其是在隐私等级和计算资源从宽松变为严格时。


<details>
  <summary>Details</summary>
Motivation: 动机在于探索在差分隐私转移学习中，关键超参数$C$和$B$的选择对模型性能的影响，并发现现有理论与实证结果间的差异。

Method: 研究通过调整关键超参数$C$和$B$，比较了不同设置下的模型性能，并通过理论分析来解释观察到的差异。

Result: 研究发现，在强隐私约束下，较大的剪裁边界$C$表现更好；现有调优批次大小$B$的方法并无效；单一的$(C,B)$设置在某些情况下可能会导致性能下降。

Conclusion: 结论指出需要开发新的方法来更好地选择剪裁边界$C$和批次大小$B$，尤其是在计算预算是固定的条件下。

Abstract: Differentially private (DP) transfer learning, i.e., fine-tuning a pretrained
model on private data, is the current state-of-the-art approach for training
large models under privacy constraints. We focus on two key hyperparameters in
this setting: the clipping bound $C$ and batch size $B$. We show a clear
mismatch between the current theoretical understanding of how to choose an
optimal $C$ (stronger privacy requires smaller $C$) and empirical outcomes
(larger $C$ performs better under strong privacy), caused by changes in the
gradient distributions. Assuming a limited compute budget (fixed epochs), we
demonstrate that the existing heuristics for tuning $B$ do not work, while
cumulative DP noise better explains whether smaller or larger batches perform
better. We also highlight how the common practice of using a single $(C,B)$
setting across tasks can lead to suboptimal performance. We find that
performance drops especially when moving between loose and tight privacy and
between plentiful and limited compute, which we explain by analyzing clipping
as a form of gradient re-weighting and examining cumulative DP noise.

</details>


### [173] [H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition](https://arxiv.org/abs/2510.20627)
*Lukas Miklautz,Chengzhi Shi,Andrii Shkabrii,Theodoros Thirimachos Davarakis,Prudence Lam,Claudia Plant,Jennifer Dy,Stratis Ioannidis*

Main category: cs.LG

TL;DR: 我们引入了一种新的算法H-SPLID，用于通过将显著和非显著特征分解到不同的空间来学习显著特征表示。我们证明了H-SPLID促进了低维任务相关的特征学习，并通过输入扰动下的预测偏差与输入和表示之间的希尔伯特-施密特独立性准则（HSIC）之间的关系建立了鲁棒性和潜表示压缩之间联系。实验结果表明，使用H-SPLID训练的模型主要依赖于显著的输入成分，这一结论通过减少对非显著特征的影响而得到验证，例如，图像背景的影响减少。


<details>
  <summary>Details</summary>
Motivation: 动机在于通过分离显著和非显著的特征，寻找一种新的方法来促进低维任务相关的特征学习，并提高模型的鲁棒性，特别是对于输入扰动对于非显著特征的影响减少，模型更加依赖显著特征。

Method: H-SPLID算法通过显式分解显著和非显著特征到不同的空间来实现，对于输入的扰动，预测的偏差受到显著子空间的维度和希尔伯特-施密特独立性准则（HSIC）的影响。

Result: 实验结果表明，使用H-SPLID训练的模型对背景等非显著特征的扰动不敏感，而更加依赖于任务相关显著特征，这些结果在图像分类任务中得到了验证。此外，H-SPLID将输入和表示之间的希尔伯特-施密特独立性准则纳入考量，证明了鲁棒性和潜表示压缩的存在性联系。

Conclusion: 结论是，H-SPLID能够有效地学习到低维且任务相关的特征，通过分离显著特征和非显著特征，提高了模型对于非显著特征扰动的鲁棒性，在图像处理任务中表现出更好的性能。

Abstract: We introduce H-SPLID, a novel algorithm for learning salient feature
representations through the explicit decomposition of salient and non-salient
features into separate spaces. We show that H-SPLID promotes learning
low-dimensional, task-relevant features. We prove that the expected prediction
deviation under input perturbations is upper-bounded by the dimension of the
salient subspace and the Hilbert-Schmidt Independence Criterion (HSIC) between
inputs and representations. This establishes a link between robustness and
latent representation compression in terms of the dimensionality and
information preserved. Empirical evaluations on image classification tasks show
that models trained with H-SPLID primarily rely on salient input components, as
indicated by reduced sensitivity to perturbations affecting non-salient
features, such as image backgrounds. Our code is available at
https://github.com/neu-spiral/H-SPLID.

</details>


### [174] [Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges](https://arxiv.org/abs/2510.20637)
*Hyun Jong Yang,Hyunsoo Kim,Hyeonho Noh,Seungnyun Kim,Byonghyo Shim*

Main category: cs.LG

TL;DR: 文章概述了大型语言模型（LLM）和大型多模态模型（LMM）在面向任务的自主通信中的应用，重点关注多模态感知集成、自适应重构和针对无线任务的提示/微调策略。通过三个案例研究展示了框架的有效性：基于LMM的交通控制、基于LLM的机器人调度和基于LMM的环境感知信道估计。实验结果表明，所提出的LLM/LMM辅助自主系统优于传统的和判别性的深度学习（DL）模型，具有更好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和大型多模态模型在自然语言理解和生成方面取得了前所未有的突破，展示了显著的能力。这些模型被视为6G自主通信的关键使能器，特别是在机器、车辆和人型机器人之间的通信中。文章专注于多模态感知集成、自适应重构和针对无线任务的提示/微调策略。

Method: 文章分为三个主要的案例研究：基于LMM的交通控制、基于LLM的机器人调度和基于LMM的环境感知信道估计。每个案例研究都是搭建框架的具体表现。方法覆盖了多模态数据处理，自适应任务调整，以及利用LLM/LMM特性进行有效控制和决策过程的鲁棒性评估。

Result: 研究表明，所提出的LLM/LMM辅助系统在动态目标、不同输入参数以及异构多模式条件下表现出色，优于传统的深度学习方法。实验数据验证了框架的有效性和创新能力。

Conclusion: 实验结果表明，基于LLM和LMM的自主通信系统具有显著的优势，特别是在动态变化的环境中保持了高精度和高可靠性，这预示了这些技术在实现6G通信和其它相关应用中的巨大潜力。

Abstract: Large language models (LLMs) and large multimodal models (LMMs) have achieved
unprecedented breakthrough, showcasing remarkable capabilities in natural
language understanding, generation, and complex reasoning. This transformative
potential has positioned them as key enablers for 6G autonomous communications
among machines, vehicles, and humanoids. In this article, we provide an
overview of task-oriented autonomous communications with LLMs/LMMs, focusing on
multimodal sensing integration, adaptive reconfiguration, and
prompt/fine-tuning strategies for wireless tasks. We demonstrate the framework
through three case studies: LMM-based traffic control, LLM-based robot
scheduling, and LMM-based environment-aware channel estimation. From
experimental results, we show that the proposed LLM/LMM-aided autonomous
systems significantly outperform conventional and discriminative deep learning
(DL) model-based techniques, maintaining robustness under dynamic objectives,
varying input parameters, and heterogeneous multimodal conditions where
conventional static optimization degrades.

</details>


### [175] [Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems](https://arxiv.org/abs/2510.20640)
*Fiza Hussain,Anson Bastos,Anjaly Parayil,Ayush Choure,Chetan Bansal,Rujia Wang,Saravan Rajmohan*

Main category: cs.LG

TL;DR: 提出了DiRecGNN，这是一个增强注意力的实体推荐框架，用于监测微软的云服务。该模型在推荐最优属性子集以供云服务自动化监控方面有显著提升，特别是在处理长程依赖方面表现突出。实验结果显示，相比于现有方法，该模型实现了MRR的43.1%的显著提升，并得到了产品团队的高度评价（4.5/5分）


<details>
  <summary>Details</summary>
Motivation: 传统的方法在处理长程依赖和稀疏数据时表现不佳，不能很好的捕捉实体间的依赖关系，因此，作者提出了一种基于变换器架构的增强注意力的实体排名模型，以解决这个问题，提高推荐的准确性

Method: 首先构造了一个生产规模的异构监控图；其次，提出了一种新的增强注意力的实体推荐模型，该模型使用了多重注意力机制来关注不同的邻居及其属性，并使用随机游走采样路径来捕捉长期依赖关系；最后，使用多方面的损失函数来优化推荐的同时保留数据的固有稀疏性

Result: 实验证明，我们的模型取得了比现有方法更好的结果，MRR相比现有最好结果（QM）有了43.1%的提升，产品团队对此次功能体验给出4.5/5分的高度评价

Conclusion: 提出了一个新颖的云服务自动化监控实体推荐框架，不仅在推荐精度上表现优异，也得到了实际应用中产品团队的认可

Abstract: In this paper, we present DiRecGNN, an attention-enhanced entity
recommendation framework for monitoring cloud services at Microsoft. We provide
insights on the usefulness of this feature as perceived by the cloud service
owners and lessons learned from deployment. Specifically, we introduce the
problem of recommending the optimal subset of attributes (dimensions) that
should be tracked by an automated watchdog (monitor) for cloud services. To
begin, we construct the monitor heterogeneous graph at production-scale. The
interaction dynamics of these entities are often characterized by limited
structural and engagement information, resulting in inferior performance of
state-of-the-art approaches. Moreover, traditional methods fail to capture the
dependencies between entities spanning a long range due to their homophilic
nature. Therefore, we propose an attention-enhanced entity ranking model
inspired by transformer architectures. Our model utilizes a multi-head
attention mechanism to focus on heterogeneous neighbors and their attributes,
and further attends to paths sampled using random walks to capture long-range
dependencies. We also employ multi-faceted loss functions to optimize for
relevant recommendations while respecting the inherent sparsity of the data.
Empirical evaluations demonstrate significant improvements over existing
methods, with our model achieving a 43.1% increase in MRR. Furthermore, product
teams who consumed these features perceive the feature as useful and rated it
4.5 out of 5.

</details>


### [176] [xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion](https://arxiv.org/abs/2510.20651)
*Quan Li,Wenchao Yu,Suhang Wang,Minhua Lin,Lingwei Chen,Wei Cheng,Haifeng Chen*

Main category: cs.LG

TL;DR: 提出了一种新的时间序列极端事件预测框架xTime，该框架利用知识蒸馏和混合专家机制来改善罕见事件的预测性能，实验表明其在极端事件预测上的准确率提升了3%到78%。


<details>
  <summary>Details</summary>
Motivation: 实际时间序列中的极端事件常引发重要后果，现有时间序列模型在总体预测表现良好，但难以准确预测极端事件，这是因为数据不平衡和忽视了极端事件前的中间事件的信息。因此，研究重点在于提高极端事件的预测能力。

Method: xTime使用知识蒸馏将低罕见事件模型的信息转移到罕见事件模型，进一步引进混合专家机制来动态选择和融合不同罕见度专家模型的输出信息。

Result: 实验在多个数据集上进行，显示出xTime在极端事件预测上的准确率有显著提升，具体提高了3%到78%。

Conclusion: xTime有效解决了现有模型在极端事件预测中的性能不足，提高了预测准确率和实用性。

Abstract: Extreme events frequently occur in real-world time series and often carry
significant practical implications. In domains such as climate and healthcare,
these events, such as floods, heatwaves, or acute medical episodes, can lead to
serious consequences. Accurate forecasting of such events is therefore of
substantial importance. Most existing time series forecasting models are
optimized for overall performance within the prediction window, but often
struggle to accurately predict extreme events, such as high temperatures or
heart rate spikes. The main challenges are data imbalance and the neglect of
valuable information contained in intermediate events that precede extreme
events. In this paper, we propose xTime, a novel framework for extreme event
forecasting in time series. xTime leverages knowledge distillation to transfer
information from models trained on lower-rarity events, thereby improving
prediction performance on rarer ones. In addition, we introduce a mixture of
experts (MoE) mechanism that dynamically selects and fuses outputs from expert
models across different rarity levels, which further improves the forecasting
performance for extreme events. Experiments on multiple datasets show that
xTime achieves consistent improvements, with forecasting accuracy on extreme
events improving from 3% to 78%.

</details>


### [177] [From Masks to Worlds: A Hitchhiker's Guide to World Models](https://arxiv.org/abs/2510.20668)
*Jinbin Bai,Yu Lei,Hecong Wu,Yuchen Zhu,Shufan Li,Yi Xin,Xiangtai Li,Molei Tao,Aditya Grover,Ming-Hsuan Yang*

Main category: cs.LG

TL;DR: 这是关于构建世界模型的一份指南，而不是对所有相关论文的简单总结，旨在探索从早期的掩码模型到统一架构，再到交互式生成模型，最后到增强记忆系统的发展道路，认为这是实现真实世界模型的最有前途的路径。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在为那些希望构建世界模型的研究者提供一份详细的指南，不在于总结已有的所有相关文献，而是提供一个清晰的路径，展示如何构建真实的、一致的世界模型。

Method: 论文聚焦于从早期的掩码模型到统一架构，再到交互式生成模型，最后到增强记忆系统的演化和发展路径，探讨这些模型的关键特性和发展方向。

Result: 指出结合了生成心、交互循环和记忆系统的综合框架是最有前景的实现世界模型的路径。

Conclusion: 研究认为集成生成心、交互循环及记忆系统的综合路径是最具潜力的实现高效、真实世界模型的方式。

Abstract: This is not a typical survey of world models; it is a guide for those who
want to build worlds. We do not aim to catalog every paper that has ever
mentioned a ``world model". Instead, we follow one clear road: from early
masked models that unified representation learning across modalities, to
unified architectures that share a single paradigm, then to interactive
generative models that close the action-perception loop, and finally to
memory-augmented systems that sustain consistent worlds over time. We bypass
loosely related branches to focus on the core: the generative heart, the
interactive loop, and the memory system. We show that this is the most
promising path towards true world models.

</details>


### [178] [Separating the what and how of compositional computation to enable reuse and continual learning](https://arxiv.org/abs/2510.20709)
*Haozhe Shan,Sun Minni,Lea Duncker*

Main category: cs.LG

TL;DR: 本文提出了一种基于RNN的两系统架构，用于解决持续学习和技能的灵活组合问题。通过引入一个"什么系统"（what system）来确定需要执行的计算任务，和一个"如何系统"（how system）来执行计算任务，实现了对新型任务的快速学习和泛化能力。实验结果展示了该方法在延续学习中的优越性，无需灾难性遗忘，并具备向前及向后迁移学习的能力。


<details>
  <summary>Details</summary>
Motivation: 研究解决持续学习和技能灵活组合的神经机制，提出了一种基于RNN的两系统架构。该架构的目标是实现对新型任务的快速学习和泛化能力，同时避免灾难性遗忘，具备向前及向后迁移学习的能力。

Method: 通过引入一个what系统，该系统可以无监督在线学习地构建任务的词汇表，并推断出任务结构。如何系统通过将低秩RNN组件根据what系统推断出的上下文进行组合，实现对新任务的持续学习。使用示例任务集展示了两系统学习框架的有效性和竞争力，以及其潜在的向前和向后迁移学习能力。

Result: 基于RNN的两系统架构在延续学习中表现出优越性，展示了其快速学习、泛化能力和向前及向后迁移学习的能力。此外，它还展示了快速组成性推广到看不见任务的能力。

Conclusion: 该研究表明基于RNN的两系统架构在解决持续学习和技能灵活组合问题上的巨大潜力，特别是在减少灾难性遗忘和快速学习新任务方面表现出色。

Abstract: The ability to continually learn, retain and deploy skills to accomplish
goals is a key feature of intelligent and efficient behavior. However, the
neural mechanisms facilitating the continual learning and flexible
(re-)composition of skills remain elusive. Here, we study continual learning
and the compositional reuse of learned computations in recurrent neural network
(RNN) models using a novel two-system approach: one system that infers what
computation to perform, and one that implements how to perform it. We focus on
a set of compositional cognitive tasks commonly studied in neuroscience. To
construct the what system, we first show that a large family of tasks can be
systematically described by a probabilistic generative model, where
compositionality stems from a shared underlying vocabulary of discrete task
epochs. The shared epoch structure makes these tasks inherently compositional.
We first show that this compositionality can be systematically described by a
probabilistic generative model. Furthermore, We develop an unsupervised online
learning approach that can learn this model on a single-trial basis, building
its vocabulary incrementally as it is exposed to new tasks, and inferring the
latent epoch structure as a time-varying computational context within a trial.
We implement the how system as an RNN whose low-rank components are composed
according to the context inferred by the what system. Contextual inference
facilitates the creation, learning, and reuse of low-rank RNN components as new
tasks are introduced sequentially, enabling continual learning without
catastrophic forgetting. Using an example task set, we demonstrate the efficacy
and competitive performance of this two-system learning framework, its
potential for forward and backward transfer, as well as fast compositional
generalization to unseen tasks.

</details>


### [179] [Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool](https://arxiv.org/abs/2510.20714)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 本研究通过数据驱动的方法，改进了约翰霍普金斯跌倒风险评估工具(JHFRAT)的预测准确性。与当前的JHFRAT相比，约束评分优化(CSO)模型在预测性能上有显著提高(AUC-ROC=0.91 vs. 0.86)。CSO模型在加入或不加入电子健康记录(EHR)变量的情况下表现相似，证明了其稳定性和可靠性。尽管基准的黑盒模型(XGBoost)在性能指标(AUC-ROC=0.94)上可进一步提高，但CSO模型对风险标签的变化更为稳健。这一基于证据的方法为医疗保健系统提供了系统地改善住院患者跌倒预防协议和患者安全的数据驱动优化技术基础，有助于改进风险评估和资源配置。


<details>
  <summary>Details</summary>
Motivation: 通过数据驱动的方法改进JHFRAT的预测准确性，以更好地与临床有意义的指标对齐，提高患者安全和资源分配的效率。

Method: 使用约束评分优化(CSO)模型对JHFRAT评估数据和额外的电子健康记录(EHR)变量进行建模，加入临床知识以保持模型的可解释性。分别对比包括和不包括EHR变量的CSO模型的预测性能。

Result: 结果显示，相对于当前的JHFRAT，CSO模型(AUC-ROC=0.91)在预测性能上显著提高，且CSO模型相对XGBoost(AUC-ROC=0.94)具有更好的稳健性。

Conclusion: 本研究提出了一个基于证据的方法，使用数据驱动的优化技术改进住院患者跌倒风险评估，并为医疗保健系统提供了改进跌倒预防协议和患者安全的系统性基础。

Abstract: In this study we aim to better align fall risk prediction from the Johns
Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically
meaningful measures via a data-driven modelling approach. We conducted a
retrospective analysis of 54,209 inpatient admissions from three Johns Hopkins
Health System hospitals between March 2022 and October 2023. A total of 20,208
admissions were included as high fall risk encounters, and 13,941 were included
as low fall risk encounters. To incorporate clinical knowledge and maintain
interpretability, we employed constrained score optimization (CSO) models on
JHFRAT assessment data and additional electronic health record (EHR) variables.
The model demonstrated significant improvements in predictive performance over
the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained
score optimization models performed similarly with and without the EHR
variables. Although the benchmark black-box model (XGBoost), improves upon the
performance metrics of the knowledge-based constrained logistic regression
(AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk
labelling. This evidence-based approach provides a robust foundation for health
systems to systematically enhance inpatient fall prevention protocols and
patient safety using data-driven optimization techniques, contributing to
improved risk assessment and resource allocation in healthcare settings.

</details>


### [180] [No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes with Gaussian Processes](https://arxiv.org/abs/2510.20725)
*Jasmine Bayrooti,Sattar Vakili,Amanda Prorok,Carl Henrik Ek*

Main category: cs.LG

TL;DR: 这篇论文为Thompson Sampling (TS)在具有复杂时间结构的强化学习(Reinforcement Learning, RL)设置中提供了无遗憾保证，具体来说，在采用了高斯过程先验的 episodic RL 中进行了理论分析。


<details>
  <summary>Details</summary>
Motivation: 尽管Thompson Sampling在多个领域中取得了成功，但在处理具有复杂时间结构的环境下其理论基础仍然很有限。特别是强化学习这种场景。本文的目标是填补这一空白，通过高斯边际分布的模型为Thompson Sampling建立无遗憾保证，进一步理解其理论基础。

Method: 本文考虑了带有联合高斯过程先验的Episodic RL中的Thompson Sampling，并证明了其在$K$轮、每轮时间长度为$H$时的遗憾界限为$	ilde{	ext{O}}(	ext{sqrt}{KH	ext{Γ}(KH)})$，其中$	ext{Γ}(	ext{cdot})$捕捉了高斯过程模型的复杂性。分析过程考虑了价值函数非高斯性以及贝尔曼更新的递归结构，并将经典的椭圆潜力引理扩展到多输出设置。

Result: 证明了在使用高斯边际分布的情况下，对于具有复杂时间结构的强化学习设置，Thompson Sampling具有$	ilde{	ext{O}}(	ext{sqrt}{KH	ext{Γ}(KH)})$的误差界。该结果揭示了在有限地平线马尔可夫决策过程中的性能和结构假设及模型不确定性之间的关系。

Conclusion: 这项工作为理解Thompson Sampling在强化学习中的应用提供了重要的理论基础，强调了结构假设和模型不确定性对其性能的影响。

Abstract: Thompson sampling (TS) is a powerful and widely used strategy for sequential
decision-making, with applications ranging from Bayesian optimization to
reinforcement learning (RL). Despite its success, the theoretical foundations
of TS remain limited, particularly in settings with complex temporal structure
such as RL. We address this gap by establishing no-regret guarantees for TS
using models with Gaussian marginal distributions. Specifically, we consider TS
in episodic RL with joint Gaussian process (GP) priors over rewards and
transitions. We prove a regret bound of
$\mathcal{\tilde{O}}(\sqrt{KH\Gamma(KH)})$ over $K$ episodes of horizon $H$,
where $\Gamma(\cdot)$ captures the complexity of the GP model. Our analysis
addresses several challenges, including the non-Gaussian nature of value
functions and the recursive structure of Bellman updates, and extends classical
tools such as the elliptical potential lemma to multi-output settings. This
work advances the understanding of TS in RL and highlights how structural
assumptions and model uncertainty shape its performance in finite-horizon
Markov Decision Processes.

</details>


### [181] [Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process](https://arxiv.org/abs/2510.20736)
*Tsai Hor Chan,Feng Wu,Yihang Chen,Guosheng Yin,Lequan Yu*

Main category: cs.LG

TL;DR: 提出了一种基于Dirichlet过程的多模态学习框架，该框架在保持每种模态内在表现力的同时，实现了显著特征学习与跨模态对齐的最优平衡。实验表明，该模型在多模态数据集上优于其他竞争者。代码公开于GitHub。


<details>
  <summary>Details</summary>
Motivation: 在健康管理与金融等实际场景中，有效的多模态融合技术是必不可少的，而保持每种模态特征表现力的同时学习跨模态交互是这一领域的主要挑战。现有方法主要关注跨模态对齐，而过于强调边际分布对齐可能导致过强的正则化，阻碍有意义的内在表示学习。因此，本文提出了一个新的基于Dirichlet过程的多模态学习框架来解决这一问题。

Method: 该框架假设每种模态遵循多元高斯分布的混合模型，进一步采用Dirichlet过程计算所有组分的混合权重，通过Dirichlet过程的“强者恒强”特性和动态分配特征贡献的能力，促进多模态特征的融合。

Result: 实验结果表明，该模型在多个多模态数据集上表现出色，优于其他竞争者；消融分析进一步验证了Dirichlet过程在模态分布对齐中的有效性及其对关键超参数变化的鲁棒性。

Conclusion: 本文提出了一种新的基于Dirichlet过程的多模态学习框架，能够在保持每种模态内部表现力的同时，实现显著特征学习与跨模态对齐的最优平衡，实验结果证实了这一方法的有效性及优势。

Abstract: Developing effective multimodal fusion approaches has become increasingly
essential in many real-world scenarios, such as health care and finance. The
key challenge is how to preserve the feature expressiveness in each modality
while learning cross-modal interactions. Previous approaches primarily focus on
the cross-modal alignment, while over-emphasis on the alignment of marginal
distributions of modalities may impose excess regularization and obstruct
meaningful representations within each modality. The Dirichlet process (DP)
mixture model is a powerful Bayesian non-parametric method that can amplify the
most prominent features by its richer-gets-richer property, which allocates
increasing weights to them. Inspired by this unique characteristic of DP, we
propose a new DP-driven multimodal learning framework that automatically
achieves an optimal balance between prominent intra-modal representation
learning and cross-modal alignment. Specifically, we assume that each modality
follows a mixture of multivariate Gaussian distributions and further adopt DP
to calculate the mixture weights for all the components. This paradigm allows
DP to dynamically allocate the contributions of features and select the most
prominent ones, leveraging its richer-gets-richer property, thus facilitating
multimodal feature fusion. Extensive experiments on several multimodal datasets
demonstrate the superior performance of our model over other competitors.
Ablation analysis further validates the effectiveness of DP in aligning
modality distributions and its robustness to changes in key hyperparameters.
Code is anonymously available at https://github.com/HKU-MedAI/DPMM.git

</details>


### [182] [Out-of-distribution Tests Reveal Compositionality in Chess Transformers](https://arxiv.org/abs/2510.20783)
*Anna Mészáros,Patrik Reizinger,Ferenc Huszár*

Main category: cs.LG

TL;DR: 现代决策Transformer通过类似的LLM训练方法能够学习进行有竞争力的国际象棋游戏，但不完全掌握游戏规则。研究发现Transformer表现出组合泛化能力，即在与训练数据不同的情况下也能遵循基础规则并作出有效走法和高质量走法，并在Chess960等变体游戏中展示基本的战略调整能力，尽管仍不及执行明确搜索的符号AI算法，但在与Lichess用户的对局中差距较小。训练过程显示模型最初阶段仅仅学会移动自己的棋子，进而展现出游戏的组合性理解能力。


<details>
  <summary>Details</summary>
Motivation: 探讨现代决策Transformer是否真正掌握了国际象棋规则，并评估其在不同情况下的泛化能力和表现。

Method: 通过训练一个具有2.7亿参数的国际象棋Transformer，并测试其在与训练数据不同的场景下的表现。具体测试包括OOD测试、特设的拼图问题、变体游戏如Chess960等。

Result: 模型展示了组合泛化能力，证明了其良好的规则外推能力和高质量的走法。但在更复杂的变体游戏中，仍无法完全匹敌执行明确搜索的符号AI算法，训练初期显示出先学习操作自己棋子，然后逐渐理解游戏的组合性。

Conclusion: 研究表明，尽管决策Transformer不能彻底掌握国际象棋规则，在特定场景和较低复杂度挑战下，依然表现出色，它们的训练过程揭示了模型如何逐步理解和掌握游戏规则和策略。

Abstract: Chess is a canonical example of a task that requires rigorous reasoning and
long-term planning. Modern decision Transformers - trained similarly to LLMs -
are able to learn competent gameplay, but it is unclear to what extent they
truly capture the rules of chess. To investigate this, we train a 270M
parameter chess Transformer and test it on out-of-distribution scenarios,
designed to reveal failures of systematic generalization. Our analysis shows
that Transformers exhibit compositional generalization, as evidenced by strong
rule extrapolation: they adhere to fundamental syntactic rules of the game by
consistently choosing valid moves even in situations very different from the
training data. Moreover, they also generate high-quality moves for OOD puzzles.
In a more challenging test, we evaluate the models on variants including
Chess960 (Fischer Random Chess) - a variant of chess where starting positions
of pieces are randomized. We found that while the model exhibits basic strategy
adaptation, they are inferior to symbolic AI algorithms that perform explicit
search, but gap is smaller when playing against users on Lichess. Moreover, the
training dynamics revealed that the model initially learns to move only its own
pieces, suggesting an emergent compositional understanding of the game.

</details>


### [183] [BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation](https://arxiv.org/abs/2510.20792)
*Liang Ye,Shengqin Chen,Jiazhu Dai*

Main category: cs.LG

TL;DR: BadGraph提出了一种针对基于文本引导的图生成模型的后门攻击方法，通过在训练数据中毒引入特定文本触发器，实现在推理阶段触发指定图案生成的后门攻击，同时保持对无毒样本的正常性能。在PubChem、ChEBI-20、PCDes、MoMu四个数据集上的实验表明，攻击成功率高且隐蔽性好，24%的数据中毒即可达到超过80%的成功率，同时对无毒样本的性能影响可忽略不计。这些发现揭示了文本引导图生成模型的安全漏洞，和对药物发现等领域部署的威胁，强调了建立有针对性后门攻击防御机制的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在图生成的无条件生成和非文本引导下的后门攻击，针对利用文本引导的图生成模型中的后门攻击研究尚不足。本研究旨在填补这一研究空白，以揭示潜在的后门攻击安全风险，并提出相应的防御机制来保证图生成模型的安全性，尤其是在药物发现等关键领域应用时。

Method: BadGraph方法通过在文本引导的图生成模型中植入文本触发器，使模型在特定引导情况下生成攻击者指定的子图，同时保持对一般输入的正常生成。实验设置了不同的数据中毒比例来评估攻击的有效性和隐蔽性，并通过消融实验分析后门植入的过程。

Result: 实验结果显示，即使在数据中毒率较低的情况下，攻击成功率依然较高，说明BadGraph方法的有效性；同时实验表明，后门植入是在VAE和扩散模型训练阶段实现的，而非预训练阶段，进一步验证了方法的有效性和隐蔽性。

Conclusion: 研究证明了基于文本引导的图生成模型存在严重的后门攻击风险，之后需要开发有针对性的防御策略来应对这一挑战，尤其是在关键的应用场景，如药物发现中，以保护模型不受后门攻击影响。

Abstract: The rapid progress of graph generation has raised new security concerns,
particularly regarding backdoor vulnerabilities. While prior work has explored
backdoor attacks in image diffusion and unconditional graph generation,
conditional, especially text-guided graph generation remains largely
unexamined. This paper proposes BadGraph, a backdoor attack method targeting
latent diffusion models for text-guided graph generation. BadGraph leverages
textual triggers to poison training data, covertly implanting backdoors that
induce attacker-specified subgraphs during inference when triggers appear,
while preserving normal performance on clean inputs. Extensive experiments on
four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the
effectiveness and stealth of the attack: less than 10% poisoning rate can
achieves 50% attack success rate, while 24% suffices for over 80% success rate,
with negligible performance degradation on benign samples. Ablation studies
further reveal that the backdoor is implanted during VAE and diffusion training
rather than pretraining. These findings reveal the security vulnerabilities in
latent diffusion models of text-guided graph generation, highlight the serious
risks in models' applications such as drug discovery and underscore the need
for robust defenses against the backdoor attack in such diffusion models.

</details>


### [184] [KL-Regularized Reinforcement Learning is Designed to Mode Collapse](https://arxiv.org/abs/2510.20817)
*Anthony GX-Chen,Jatin Prakash,Jeff Guo,Rob Fergus,Rajesh Ranganath*

Main category: cs.LG

TL;DR: 研究指出，在强化学习中使用反向/正向KL散度进行正则化时，模式覆盖主要受其他因素影响，如正则化强度和奖励与参考概率之间的相对比例。低正则化强度和等幅奖励通常会指定单峰的目标分布。研究提出了一个简单的、可扩展的、理论上合理的算法，用于优化目标分布，使其在所有高质量采样模式上赋予较高概率。实验表明该算法能提高语言模型和化学语言模型的解决方案质量和多样性，无需额外的多样性信号，且适用于使用正向和反向KL散度的情况。


<details>
  <summary>Details</summary>
Motivation: 人们通常认为反向KL散度优化会导致'模式搜索'，而正向KL散度优化则会导致'质量覆盖'，从而使得正向KL散度优化更适合从多个不同模式中采样。然而，这种直觉并不一定适用于使用反向/正向KL散度进行强化学习的场景。因此，该研究希望探究在强化学习中使用反向/正向KL散度进行正则化的影响，并提出一个简单的、可扩展的算法以提高模型的多样性和质量。

Method: 该研究通过数学与实验的方式，探讨正向和反向KL散度在强化学习中的效果。进一步地，提出了一个微调奖励幅度的方法，优化目标分布，使其在高质量的模式上赋予较高概率。这种算法通过改变奖励的相对强度，优化目标分布，以提高采样模式的多样性和质量。

Result: 研究表明，目标分布由正则化系数参数化，模式覆盖主要受其他因素（如正则化强度、奖励与参考概率之间的相对比例）影响。特别是，弱正则化强度加上等幅奖励通常会导致目标分布是单峰的，可能导致优化目标非多样性。通过引入这种简单的方法，研究能提高语言和化学模型的采样质量和多样性，而无需额外的多样性信号，这同样适用于使用反向和正向KL散度的场景。实验表明，此种修改可提高大容量语言模型和化学语言模型的质量和多样性。

Conclusion: 该研究挑战了传统的反向KL散度导致模式搜索而正向KL散度导致质量覆盖的观念，揭示了模式覆盖主要受其他因素，如正则化强度和奖励与参考概率之间的相对比例的影响。另外，提出了一个简单的，理论上明智的方法来优化目标分布，提高语言和化学模型的多样性和质量。

Abstract: It is commonly believed that optimizing the reverse KL divergence results in
"mode seeking", while optimizing forward KL results in "mass covering", with
the latter being preferred if the goal is to sample from multiple diverse
modes. We show -- mathematically and empirically -- that this intuition does
not necessarily transfer well to doing reinforcement learning with
reverse/forward KL regularization (e.g. as commonly used with language models).
Instead, the choice of reverse/forward KL determines the family of optimal
target distributions, parameterized by the regularization coefficient. Mode
coverage depends primarily on other factors, such as regularization strength,
and relative scales between rewards and reference probabilities. Further, we
show commonly used settings such as low regularization strength and equal
verifiable rewards tend to specify unimodal target distributions, meaning the
optimization objective is, by construction, non-diverse. We leverage these
insights to construct a simple, scalable, and theoretically justified
algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a
target distribution which puts high probability over all high-quality sampling
modes. In experiments, this simple modification works to post-train both Large
Language Models and Chemical Language Models to have higher solution quality
and diversity, without any external signals of diversity, and works with both
forward and reverse KL when using either naively fails.

</details>
