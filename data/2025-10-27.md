<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 60]
- [cs.LG](#cs.LG) [Total: 70]
- [eess.SY](#eess.SY) [Total: 7]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.NI](#cs.NI) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.IT](#cs.IT) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Preventing Shortcuts in Adapter Training via Providing the Shortcuts](https://arxiv.org/abs/2510.20887)
*Anujraaj Argo Goyal,Guocheng Gordon Qian,Huseyin Coskun,Aarush Gupta,Himmy Tam,Daniil Ostashev,Ju Hu,Dhritiman Sagar,Sergey Tulyakov,Kfir Aberman,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: 通过控制辅助模块来消除适配器训练中的混淆因素，可以提高生成质量、多样性和对输入文本的依赖性。这项工作提出了一种简单有效的解决方案：在适配器训练过程中提供我们希望消除的捷径，这些混淆因素会通过辅助模块处理，从而在推理阶段被移除。该方法在面部和全身影像身份注入任务中表现出色，指出了一种新的设计原则：当我们寻求解纠缠表示时，最有效的路径可能是为不应学习的内容建立捷径。


<details>
  <summary>Details</summary>
Motivation: 当前适配器训练过程中存在混淆问题，导致目标属性与偶然因素纠缠，限制了模型泛化能力和对输入文本的依赖性，因此需要寻找一种解决方案来解决这一问题。

Method: 在适配器训练过程中，通过控制辅助模块（如ControlNet或LoRA）来消除混淆因素，使得适配器不再试图内部化这些因素，并在推理阶段移除这些辅助模块。

Result: 该方法在面部和全身影像身份注入任务中显著提高了生成的质量、多样性和对输入文本的依赖性。

Conclusion: 通过为适配器训练提供不应该学习的内容建立捷径，可以在大型模型时代获取解纠缠表示。

Abstract: Adapter-based training has emerged as a key mechanism for extending the
capabilities of powerful foundation image generators, enabling personalized and
stylized text-to-image synthesis. These adapters are typically trained to
capture a specific target attribute, such as subject identity, using
single-image reconstruction objectives. However, because the input image
inevitably contains a mixture of visual factors, adapters are prone to entangle
the target attribute with incidental ones, such as pose, expression, and
lighting. This spurious correlation problem limits generalization and obstructs
the model's ability to adhere to the input text prompt. In this work, we
uncover a simple yet effective solution: provide the very shortcuts we wish to
eliminate during adapter training. In Shortcut-Rerouted Adapter Training,
confounding factors are routed through auxiliary modules, such as ControlNet or
LoRA, eliminating the incentive for the adapter to internalize them. The
auxiliary modules are then removed during inference. When applied to tasks like
facial and full-body identity injection, our approach improves generation
quality, diversity, and prompt adherence. These results point to a general
design principle in the era of large models: when seeking disentangled
representations, the most effective path may be to establish shortcuts for what
should NOT be learned.

</details>


### [2] [Video-As-Prompt: Unified Semantic Control for Video Generation](https://arxiv.org/abs/2510.20888)
*Yuxuan Bian,Xin Chen,Zenan Li,Tiancheng Zhi,Shen Sang,Linjie Luo,Qiang Xu*

Main category: cs.CV

TL;DR: 提出了Video-As-Prompt(VAP)新范式，利用参考视频作为直接语义提示，引导冻结的Video Diffusion Transformer(DiT)，并通过一个即插即用的Mixture-of-Transformers(MoT)专家来增强性能。该方法在语义控制视频生成领域表现出色，达到新的开源方法的最先进水平，实现38.7%的用户偏好率，面对各种下游应用表现出很强的零样本泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成方法存在引入伪影或者非通用化的缺点。目标是通过引入VAP解决该问题，提供一个统一、通用化的视频生成方法

Method: VAP通过一个参考视频作为直接语义提示，引导冻结的Video Diffusion Transformer (DiT)，借助一个即插即用的Mixture-of-Transformers (MoT) 专家增强性能, 这种架构防止灾难性遗忘，依靠时间偏置的位置嵌入消除伪映射先验，实现稳健的上下文检索

Result: VAP不仅创造了新的开源方法SOTA，达到了38.7%的用户偏好率，甚至可以与商业化的特定条件模型相媲美，同时支持各种下游应用

Conclusion: VAP在实现零样本泛化方面取得了显著进展，标志着向通用可控视频生成目的迈进的一大步

Abstract: Unified, generalizable semantic control in video generation remains a
critical open challenge. Existing methods either introduce artifacts by
enforcing inappropriate pixel-wise priors from structure-based controls, or
rely on non-generalizable, condition-specific finetuning or task-specific
architectures. We introduce Video-As-Prompt (VAP), a new paradigm that reframes
this problem as in-context generation. VAP leverages a reference video as a
direct semantic prompt, guiding a frozen Video Diffusion Transformer (DiT) via
a plug-and-play Mixture-of-Transformers (MoT) expert. This architecture
prevents catastrophic forgetting and is guided by a temporally biased position
embedding that eliminates spurious mapping priors for robust context retrieval.
To power this approach and catalyze future research, we built VAP-Data, the
largest dataset for semantic-controlled video generation with over 100K paired
videos across 100 semantic conditions. As a single unified model, VAP sets a
new state-of-the-art for open-source methods, achieving a 38.7% user preference
rate that rivals leading condition-specific commercial models. VAP's strong
zero-shot generalization and support for various downstream applications mark a
significant advance toward general-purpose, controllable video generation.

</details>


### [3] [Generative Point Tracking with Flow Matching](https://arxiv.org/abs/2510.20951)
*Mattie Tesfaldet,Adam W. Harley,Konstantinos G. Derpanis,Derek Nowrouzezahrai,Christopher Pal*

Main category: cs.CV

TL;DR: 介绍了一种名为Generative Point Tracker (GenPT)的新方法，该方法可以生成多模态轨迹，提高了点跟踪的准确度，尤其是在处理遮挡点时表现出色。在PointOdyssey，Dynamic Replica和TAP-Vid基准测试上优于现有技术，并引入TAP-Vid的遮挡变体以进一步测试遮挡点跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有的最先进的判别模型在回归长时轨迹估计方面表现良好，但在不确定性条件下仅能回归到均值，无法捕捉多模态性。为了克服这一限制，提出了GenPT，一种用于建模多模态轨迹的生成框架。GenPT利用了生成能力来改进点轨迹估计。

Method: 提出了GenPT，一个使用新颖流匹配方法训练的生成框架，该方法结合了判别追踪器的逐步细化，窗口依赖性先验以及针对点坐标的方差进度表。在推理过程中使用最佳优先搜索策略对生成的样本进行操作，以提高追踪效果。

Result: 在PointOdyssey，Dynamic Replica和TAP-Vid基准测试上的实验表明，GenPT在处理遮挡点时实现了状态最佳的跟踪准确性，同时在可见点上的跟踪准确性比现有的判别点追踪器竞争性强。通过测试新的TAP-Vid变体，进一步验证了GenPT捕捉多模态性的能力，尤其是处理遮挡点时的表现。

Conclusion: GenPT方法在位点追踪领域展示出强大的能力，特别是在捕捉多模态轨迹方面，它可以处理在遮挡点的情况下追踪任务，展示出比现有技术更优秀的准确性。

Abstract: Tracking a point through a video can be a challenging task due to uncertainty
arising from visual obfuscations, such as appearance changes and occlusions.
Although current state-of-the-art discriminative models excel in regressing
long-term point trajectory estimates -- even through occlusions -- they are
limited to regressing to a mean (or mode) in the presence of uncertainty, and
fail to capture multi-modality. To overcome this limitation, we introduce
Generative Point Tracker (GenPT), a generative framework for modelling
multi-modal trajectories. GenPT is trained with a novel flow matching
formulation that combines the iterative refinement of discriminative trackers,
a window-dependent prior for cross-window consistency, and a variance schedule
tuned specifically for point coordinates. We show how our model's generative
capabilities can be leveraged to improve point trajectory estimates by
utilizing a best-first search strategy on generated samples during inference,
guided by the model's own confidence of its predictions. Empirically, we
evaluate GenPT against the current state of the art on the standard
PointOdyssey, Dynamic Replica, and TAP-Vid benchmarks. Further, we introduce a
TAP-Vid variant with additional occlusions to assess occluded point tracking
performance and highlight our model's ability to capture multi-modality. GenPT
is capable of capturing the multi-modality in point trajectories, which
translates to state-of-the-art tracking accuracy on occluded points, while
maintaining competitive tracking accuracy on visible points compared to extant
discriminative point trackers.

</details>


### [4] [Anisotropic Pooling for LUT-realizable CNN Image Restoration](https://arxiv.org/abs/2510.21437)
*Xi Zhang,Xiaolin Wu*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法，即使用非同质化池化策略来替换传统的均值池化，以改进基于查找表实现的CNN图像恢复方法。实验结果表明，这种方法在感知和数值上都优于现有的基于查找表的CNN方法。


<details>
  <summary>Details</summary>
Motivation: 查找表实现的CNN具有实现竞争性图像质量的同时更快速且资源消耗更低的潜力，而传统的查找表方法通过简单的均值池化来融合查找表结果，这种策略在面对非同质化信号时效果不佳。因此，本文动机在于通过研究和讨论非同质化池化方法来提升现有的查找表实现的CNN图像恢复方法。

Method: 本文提出了使用一般中位数池化来改进当前基于查找表的CNN恢复方法，并进一步提出了一种通过学习每个方向的数据依赖池化系数适应性地加权不同方向像素块贡献的方法。

Result: 实验结果表明，提出的非同质化池化策略在各种恢复基准测试中都实现了比现有查找表实现的CNN方法更好的感知和数值结果。

Conclusion: 通过使用非同质化池化策略，我们可以显著提高基于查找表实现的CNN图像恢复方法的性能。

Abstract: Table look-up realization of image restoration CNNs has the potential of
achieving competitive image quality while being much faster and resource frugal
than the straightforward CNN implementation. The main technical challenge
facing the LUT-based CNN algorithm designers is to manage the table size
without overly restricting the receptive field. The prevailing strategy is to
reuse the table for small pixel patches of different orientations (apparently
assuming a degree of isotropy) and then fuse the look-up results. The fusion is
currently done by average pooling, which we find being ill suited to
anisotropic signal structures. To alleviate the problem, we investigate and
discuss anisotropic pooling methods to replace naive averaging for improving
the performance of the current LUT-realizable CNN restoration methods. First,
we introduce the method of generalized median pooling which leads to measurable
gains over average pooling. We then extend this idea by learning data-dependent
pooling coefficients for each orientation, so that they can adaptively weigh
the contributions of differently oriented pixel patches. Experimental results
on various restoration benchmarks show that our anisotropic pooling strategy
yields both perceptually and numerically superior results compared to existing
LUT-realizable CNN methods.

</details>


### [5] [3DReasonKnee: Advancing Grounded Reasoning in Medical Vision Language Models](https://arxiv.org/abs/2510.20967)
*Sraavya Sambara,Sung Eun Kim,Xiaoman Zhang,Luyang Luo,Shreya Johri,Mohammed Baharoon,Du Hyun Ro,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: 当前的Vision-Language模型在处理3D医学图像时，难以实现精确的解剖区域定位和分步推理，这在实际诊断过程中是至关重要的。为了填补这一空白，研究者们创建了3DReasonKnee——首个用于医学图像的3D定位推理数据集，提供了494k高质量的五元组数据。此数据集不仅可以用于评估模型的定位和诊断准确性，还为多模态医疗AI系统的发展提供了宝贵的资源，推动其向3D、临床一致的决策制定能力发展


<details>
  <summary>Details</summary>
Motivation: 当前的Vision-Language模型在处理3D医学图像时存在着解剖区域定位和分步推理的困难，这限制了它们在实际医疗诊断中的应用。为了提高这些模型的实用性，尤其是为实现临床医生和AI之间的有效协作，提出了开发一个专门针对3D医学图像的定位和推理数据集的需求

Method: 该研究构建了名为3DReasonKnee的数据集，它含有494k个五元组数据，来源于7,970个3D膝部MRI图像。每个五元组包括一个3D MRI图像、一个问题（针对特定解剖区域）、一个定位相关的解剖结构的3D边界框、由临床医生生成的推理步骤，以及结构化的解剖区域严重分级评估

Result: 该数据集通过ReasonKnee-Bench基准测试对五个最先进的Vision-Language模型进行了评估，展现了模型在解剖区域定位和诊断准确性方面的表现。基准测试提供了对模型在3D医学图像上执行定位和严重性评估能力的见解

Conclusion: 3DReasonKnee不仅为评估和改进用于3D医学图像的Vision-Language模型提供了宝贵的资源，而且通过其复杂的注释，体现了骨科医生的诊断专业知识。它为未来多模态医疗AI系统的发展提供了坚实的基础，推动这些系统向更准确、更可靠的决策制定迈进

Abstract: Current Vision-Language Models (VLMs) struggle to ground anatomical regions
in 3D medical images and reason about them in a step-by-step manner, a key
requirement of real-world diagnostic assessment. This ability is essential for
aligning model outputs with the diagnostic workflows clinicians use in
practice, enabling trustworthy clinician-AI collaboration. Existing 3D datasets
provide localization labels, but none support this "grounded reasoning"
ability. To address this gap, we introduce 3DReasonKnee, the first 3D grounded
reasoning dataset for medical images, which provides 494k high-quality
quintuples derived from 7,970 3D knee MRI volumes. Each quintuple includes: (1)
the 3D MRI volume, (2) a diagnostic question targeting a specific anatomical
region (3) a 3D bounding box localizing the relevant anatomical structures, (4)
clinician-generated diagnostic reasoning steps that explicitly detail the 3D
reasoning process, and (5) structured severity assessments for the relevant
anatomical region. The creation and validation of 3DReasonKnee, involving over
450 hours of expert clinician time for manually segmenting MRIs and generating
reasoning chains, ensures its superior quality and clinical relevance. We
establish ReasonKnee-Bench to evaluate localization and diagnostic accuracy,
providing insight into VLM ability to perform grounding and severity assessment
across anatomical regions and diagnostic inquiries. We benchmark five
state-of-the-art VLMs, providing baseline performance for ReasonKnee-Bench. By
providing this unique resource of expert-annotated 3D reasoning pathways,
3DReasonKnee serves as a repository of orthopedic surgeons' diagnostic
expertise and offers a vital testbed for advancing multimodal medical AI
systems towards 3D, clinically aligned, localized decision-making capabilities.
The dataset can be found in:
https://huggingface.co/datasets/rajpurkarlab/3DReasonKnee

</details>


### [6] [Thermal Polarimetric Multi-view Stereo](https://arxiv.org/abs/2510.20972)
*Takahiro Kushida,Kenichiro Tanaka*

Main category: cs.CV

TL;DR: 本文提出了一种利用热偏振线索进行详细3D形状重建的新型方法，该方法不依赖光照和材料特性，展示长波红外(LWIR)极化成像的优势并提出了一种使用多视图热偏振图像恢复详细3D形状的方法，实验结果证明了该方法在透明、半透明和异质物体中表现出色，优于现有技术


<details>
  <summary>Details</summary>
Motivation: 当前技术受到光照和材料性质的限制，本文提出了一种基于热偏振的3D重建方法，无需依赖这些条件，以解决上述问题并实现更高质量的3D重建

Method: 本文提出了一个通用的偏振观测理论，并使用多视图热偏振图象，利用长波红外(LWIR)极化成像技术来恢复细节3D形状

Result: 实验结果表明，该方法在透明、半透明和异质物体上表现出了优秀的3D重建能力，优于现有技术

Conclusion: 这种方法由于其对光照和材料性质的独立性及其在长波红外极化成像中的独特优势，可能对未来3D重建技术产生重大影响

Abstract: This paper introduces a novel method for detailed 3D shape reconstruction
utilizing thermal polarization cues. Unlike state-of-the-art methods, the
proposed approach is independent of illumination and material properties. In
this paper, we formulate a general theory of polarization observation and show
that long-wave infrared (LWIR) polarimetric imaging is free from the
ambiguities that affect visible polarization analyses. Subsequently, we propose
a method for recovering detailed 3D shapes using multi-view thermal
polarimetric images. Experimental results demonstrate that our approach
effectively reconstructs fine details in transparent, translucent, and
heterogeneous objects, outperforming existing techniques.

</details>


### [7] [VESSA: Video-based objEct-centric Self-Supervised Adaptation for Visual Foundation Models](https://arxiv.org/abs/2510.20994)
*Jesimon Barreto,Carlos Caetano,André Araujo,William Robson Schwartz*

Main category: cs.CV

TL;DR: VESSA是一种基于视频的自监督微调方法，用于视觉基础模型在新领域中的适应。它不依赖于标注，通过多视角对象视频中的对象观察来指导模型学习，从而提高模型在下游分类任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于视觉基础模型在领域分布变化和标签稀缺的情况下表现不佳，传统自监督学习方法无法有效提高视觉编码模型的表现。因此，提出一种新的自监督微调方法，使用无标注的多视角对象视频来适应模型。这将使得模型在新领域中表现更好。

Method: VESSA通过自蒸馏范式来进行训练，这种方法需要仔细调整预测头并采用参数高效的适应技术，以防止模型遗忘其预训练的知识进入降级状态。在自蒸馏过程中，模型通过多视角对象观察来学习，从而增强其在各种捕获条件下的稳健性。

Result: 在两个数据集上，3种视觉基础模型在使用VESSA后，下游分类任务中的表现相比基础模型和之前的适应方法都有显著提升。

Conclusion: VESSA通过自监督微调，利用无标注的多视角对象视频，低成本地提高了视觉基础模型在新领域中的表现。

Abstract: Foundation models have advanced computer vision by enabling strong
performance across diverse tasks through large-scale pretraining and supervised
fine-tuning. However, they may underperform in domains with distribution shifts
and scarce labels, where supervised fine-tuning may be infeasible. While
continued self-supervised learning for model adaptation is common for
generative language models, this strategy has not proven effective for
vision-centric encoder models. To address this challenge, we introduce a novel
formulation of self-supervised fine-tuning for vision foundation models, where
the model is adapted to a new domain without requiring annotations, leveraging
only short multi-view object-centric videos. Our method is referred to as
VESSA: Video-based objEct-centric Self-Supervised Adaptation for visual
foundation models. VESSA's training technique is based on a self-distillation
paradigm, where it is critical to carefully tune prediction heads and deploy
parameter-efficient adaptation techniques - otherwise, the model may quickly
forget its pretrained knowledge and reach a degraded state. VESSA benefits
significantly from multi-view object observations sourced from different frames
in an object-centric video, efficiently learning robustness to varied capture
conditions, without the need of annotations. Through comprehensive experiments
with 3 vision foundation models on 2 datasets, VESSA demonstrates consistent
improvements in downstream classification tasks, compared to the base models
and previous adaptation methods. Code is publicly available at
https://github.com/jesimonbarreto/VESSA.

</details>


### [8] [BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies](https://arxiv.org/abs/2510.21000)
*Jiaqi Hu,Hongli Xu,Junwen Huang,Peter KT Yu,Slobodan Ilic,Benjamin Busam*

Main category: cs.CV

TL;DR: 提出了一个标准化的插件化流水线，用于在工业环境中检测未知对象的位置，通过低光图像增强和背景移除提高了检测准确性，减少了假阳性，适用于实际操作中的位姿估计任务，实验表明其效果显著且不增加太多推理负担


<details>
  <summary>Details</summary>
Motivation: 现有6D位姿估计在工业环境下的表现受到遮挡、光线、背景等因素的影响，其检测环节成为瓶颈。因此，论文提出针对未知对象的标准化插件流水线以改善该问题

Method: 基于当前最好的基准模型，通过低光图像增强和根据开放词汇检测引导的背景移除来减少领域偏差和背景噪音，从而提高目标检测的准确性

Result: 实验在真实世界的工业流水线拣选基准数据集上得到验证，结果表明该方法有效且实践可行，可以在不增加太多推理负担的情况下显著提高检测准确性

Conclusion: 提出的方法通过标准化插件流水线解决了现有6D位姿估计工具在工业环境下的检测瓶颈，提高了检测准确性和可靠性，为实际应用提供了强有力的支持

Abstract: Accurate 6D pose estimation is essential for robotic manipulation in
industrial environments. Existing pipelines typically rely on off-the-shelf
object detectors followed by cropping and pose refinement, but their
performance degrades under challenging conditions such as clutter, poor
lighting, and complex backgrounds, making detection the critical bottleneck. In
this work, we introduce a standardized and plug-in pipeline for 2D detection of
unseen objects in industrial settings. Based on current SOTA baselines, our
approach reduces domain shift and background artifacts through low-light image
enhancement and background removal guided by open-vocabulary detection with
foundation models. This design suppresses the false positives prevalent in raw
SAM outputs, yielding more reliable detections for downstream pose estimation.
Extensive experiments on real-world industrial bin-picking benchmarks from BOP
demonstrate that our method significantly boosts detection accuracy while
incurring negligible inference overhead, showing the effectiveness and
practicality of the proposed method.

</details>


### [9] [Deep learning-based automated damage detection in concrete structures using images from earthquake events](https://arxiv.org/abs/2510.21063)
*Abdullah Turer,Yongsheng Bai,Halil Sezen,Alper Yilmaz*

Main category: cs.CV

TL;DR: 该研究提出了一种利用深度学习方法来评估地震后混凝土建筑物和桥梁的结构损伤状况的方法，特别是在检测暴露的钢筋方面。通过使用2023年土耳其地震后收集的图像数据集，研究人员开发了一个自动检测框架，该框架能够识别建筑内外和结构组件，并使用YOLOv11模型来检测裂缝和剥落损伤以及暴露的钢筋。此外，通过另一个经过微调的YOLO模型来区分不同的结构损伤等级，最终实现了快速自动化的损伤检测。这项工作表明，利用图像数据采集、标注和深度学习方法可以在不同的损伤背景下实现快速、可靠的伤害评估。


<details>
  <summary>Details</summary>
Motivation: 地震后结构完整性评估对于公众安全和应急响应至关重要。这种评估需要及时进行，而人工检测往往耗时且可能不准确。因此，利用深度学习方法自动检测结构损伤和钢筋暴露成为研究的重点。这可以帮助快速确定建筑的安全状态，从而加快应急响应的速度和效率。

Method: 该研究提出了一个深度学习框架，利用地震后收集的图像数据集，结合数据增强和微调技术，实现自动化的结构损伤检测。具体来说，使用YOLOv11模型检测裂缝、剥落及暴露钢筋，并通过另一个微调的模型区分不同的损伤等级，从而确立一套自动化和可靠的损伤等级判断系统。

Result: 实验结果表明，所提出的自动检测框架能够有效地识别地震后混凝土结构的损伤情况，帮助评估结构的完整性。该研究证明了通过图像数据采集、标注以及深度学习方式，可以在不同损坏背景中实现实时和可靠的灾害后损伤评估。

Conclusion: 该研究成功地展示了利用深度学习技术进行地震后结构损伤自动评估的可行性。通过开发新的数据集和先进的检测模型，研究人员提供了一种快速且准确评估地震后结构完整性的方法。这不仅为公共安全和应急响应提供了强有力的工具，也为后续深入研究提供了宝贵的数据和方法支持。

Abstract: Timely assessment of integrity of structures after seismic events is crucial
for public safety and emergency response. This study focuses on assessing the
structural damage conditions using deep learning methods to detect exposed
steel reinforcement in concrete buildings and bridges after large earthquakes.
Steel bars are typically exposed after concrete spalling or large flexural or
shear cracks. The amount and distribution of exposed steel reinforcement is an
indication of structural damage and degradation. To automatically detect
exposed steel bars, new datasets of images collected after the 2023 Turkey
Earthquakes were labeled to represent a wide variety of damaged concrete
structures. The proposed method builds upon a deep learning framework, enhanced
with fine-tuning, data augmentation, and testing on public datasets. An
automated classification framework is developed that can be used to identify
inside/outside buildings and structural components. Then, a YOLOv11 (You Only
Look Once) model is trained to detect cracking and spalling damage and exposed
bars. Another YOLO model is finetuned to distinguish different categories of
structural damage levels. All these trained models are used to create a hybrid
framework to automatically and reliably determine the damage levels from input
images. This research demonstrates that rapid and automated damage detection
following disasters is achievable across diverse damage contexts by utilizing
image data collection, annotation, and deep learning approaches.

</details>


### [10] [ZING-3D: Zero-shot Incremental 3D Scene Graphs via Vision-Language Models](https://arxiv.org/abs/2510.21069)
*Pranav Saxena,Jimmy Chiun*

Main category: cs.CV

TL;DR: ZING-3D是一个利用预训练视觉语言模型生成零样本场景图并支持3D几何定位的框架，适用于机器人应用。它利用2D场景图和深度信息生成包含开放式词汇对象及其3D位置、语义和空间关系的丰富表示。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景图生成方法主要集中于单一视角，无法支持增量更新，也没有明确的3D空间定位，限制了其在具身场景中的应用。ZING-3D框架是为了克服这些限制，提供零样本识别，同时支持增量更新和3D空间定位。

Method: ZING-3D框架通过VLM推理生成丰富的2D场景图，再利用深度信息将其定位于3D空间。图中的节点代表开放词汇的对象，它们具有特征、3D位置和语义背景，而边则捕捉了对象间的空间和语义关系及距离。

Result: 实验表明，ZING-3D能够有效地捕捉空间和关系知识，且不需要任务特定的训练。该框架在Replica和HM3D数据集的场景上表现良好。

Conclusion: ZING-3D通过利用丰富的零样本场景图表示和3D几何定位方法，为复杂3D环境的理解和推理提供了一种有效的方法，特别适合机器人应用。

Abstract: Understanding and reasoning about complex 3D environments requires structured
scene representations that capture not only objects but also their semantic and
spatial relationships. While recent works on 3D scene graph generation have
leveraged pretrained VLMs without task-specific fine-tuning, they are largely
confined to single-view settings, fail to support incremental updates as new
observations arrive and lack explicit geometric grounding in 3D space, all of
which are essential for embodied scenarios. In this paper, we propose, ZING-3D,
a framework that leverages the vast knowledge of pretrained foundation models
to enable open-vocabulary recognition and generate a rich semantic
representation of the scene in a zero-shot manner while also enabling
incremental updates and geometric grounding in 3D space, making it suitable for
downstream robotics applications. Our approach leverages VLM reasoning to
generate a rich 2D scene graph, which is grounded in 3D using depth
information. Nodes represent open-vocabulary objects with features, 3D
locations, and semantic context, while edges capture spatial and semantic
relations with inter-object distances. Our experiments on scenes from the
Replica and HM3D dataset show that ZING-3D is effective at capturing spatial
and relational knowledge without the need of task-specific training.

</details>


### [11] [HistRetinex: Optimizing Retinex model in Histogram Domain for Efficient Low-Light Image Enhancement](https://arxiv.org/abs/2510.21100)
*Jingtian Zhao,Xueli Xie,Jianxiang Xi,Xiaogang Yang,Haoxuan Sun*

Main category: cs.CV

TL;DR: 提出了一种基于直方图的Retinex模型（HistRetinex），用于快速的低光图像增强，并在时间性能和视觉效果上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Retinex低光图像增强方法对大尺寸图像处理耗时较长，因此提出一种新的直方图基于的Retinex模型来提高处理速度和效果。

Method: 首先定义了光照直方图、反射直方图和低光图像的直方图之间的关系矩阵，然后基于先验信息和直方图Retinex模型建立了一个新的两级优化模型，并通过求解该模型得到光照直方图和反射直方图的迭代公式，最终通过匹配图像直方图来增强低光图像。

Result: HistRetinex模型能够在时间和视觉效果上胜过现有增强方法，处理1000*664分辨率图像的时间仅为1.86秒，比现有方法快了最多6.67秒。

Conclusion: 通过直方图域扩展的Retinex模型，有效地实现了低光图像的快速增强，其效果和性能都优于现有方法。

Abstract: Retinex-based low-light image enhancement methods are widely used due to
their excellent performance. However, most of them are time-consuming for
large-sized images. This paper extends the Retinex model from the spatial
domain to the histogram domain, and proposes a novel histogram-based Retinex
model for fast low-light image enhancement, named HistRetinex. Firstly, we
define the histogram location matrix and the histogram count matrix, which
establish the relationship among histograms of the illumination, reflectance
and the low-light image. Secondly, based on the prior information and the
histogram-based Retinex model, we construct a novel two-level optimization
model. Through solving the optimization model, we give the iterative formulas
of the illumination histogram and the reflectance histogram, respectively.
Finally, we enhance the low-light image through matching its histogram with the
one provided by HistRetinex. Experimental results demonstrate that the
HistRetinex outperforms existing enhancement methods in both visibility and
performance metrics, while executing 1.86 seconds on 1000*664 resolution
images, achieving a minimum time saving of 6.67 seconds.

</details>


### [12] [PhysVLM-AVR: Active Visual Reasoning for Multimodal Large Language Models in Physical Environments](https://arxiv.org/abs/2510.21111)
*Weijie Zhou,Xuantang Xiong,Yi Peng,Manli Tao,Chaoyang Zhao,Honghui Dong,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: 本文提出了Active Visual Reasoning (AVR) 任务，解决多模态大型语言模型在不完全可见环境中的视觉推理问题。通过CLEVR-AVR模拟基准进行评估，构建了AVR-152k数据集，并开发了在多个测试中表现出色的PhysVLM-AVR模型，提升了信息获取和整合的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型在处理静态、完全可见环境中的视觉推理问题时存在局限。为了使模型能够像人类一样，对不完全可见或受限制的环境进行探索、交互，以获取并整合信息，提出AVR任务来模拟这种行为模式。该任务强调通过一系列物理行动来积极获取信息、进行长时间推理、并根据反馈动态调整策略，反映了高级认知过程。通过该任务的实现，开发了具有出色性能的PhysVLM-AVR模型，以解决当前模型难以积极获取和整合新信息的问题，填补了在积极推理能力上的空白。

Method: 开发了一个新颖的任务框架AVR，包括CLEVR-AVR作为仿真基准，实验设计和测试集。此外，构建一个大型、完善的联合注释数据集AVR-152k来支持模型训练和评估。在此基础上，利用联合语言-视觉模型PhysVLM-AVR实现了多项优化，使其在多个认知任务中展现出色的性能。

Result: 基于AVR任务的实现，开发的PhysVLM-AVR模型在CLEVR-AVR等测试中的表现优于其他前沿模型。这表明该模型不仅在静态环境中的表现优异，而且能够在多轮交互环境中处理动态问题，证明了这种方法的有效性和潜力。相较于现有的嵌入式多模态语言模型，PhysVLM-AVR更能积极寻求和整合信息以提供准确的推理结果，有助于缩小已知模型与人类行为在情境理解上的差距。

Conclusion: AVR任务的引入，展示了在现实世界中的模型如何更加接近人类的主动探索和信息获取过程，为未来的模型研究提供了新的方向。利用PhysVLM-AVR模型能够将推理、感知和行动相结合，实现了一种比现有被动或短视的视觉推理方法更为有效和实用的解决方案。这促进了人工智能系统在理解复杂动态环境下的进步，特别是在需要长期记忆和动态决策的场景中。

Abstract: Visual reasoning in multimodal large language models (MLLMs) has primarily
been studied in static, fully observable settings, limiting their effectiveness
in real-world environments where information is often incomplete due to
occlusion or limited field of view. Humans, in contrast, actively explore and
interact with their environment-moving, examining, and manipulating objects-to
gather information through a closed-loop process integrating perception,
reasoning, and action. Inspired by this human capability, we introduce the
Active Visual Reasoning (AVR) task, extending visual reasoning to partially
observable, interactive environments. AVR necessitates agents to: (1) actively
acquire information via sequential physical actions, (2) integrate observations
across multiple steps for coherent reasoning, and (3) dynamically adjust
decisions based on evolving visual feedback. To rigorously evaluate AVR, we
introduce CLEVR-AVR, a simulation benchmark featuring multi-round interactive
environments designed to assess both reasoning correctness and
information-gathering efficiency. We present AVR-152k, a large-scale dataset
that offers rich Chain-of-Thought (CoT) annotations detailing iterative
reasoning for uncertainty identification, action-conditioned information gain
prediction, and information-maximizing action selection, crucial for training
agents in a higher-order Markov Decision Process. Building on this, we develop
PhysVLM-AVR, an MLLM achieving state-of-the-art performance on CLEVR-AVR,
embodied reasoning (OpenEQA, RoboVQA), and passive visual reasoning (GeoMath,
Geometry30K). Our analysis also reveals that current embodied MLLMs, despite
detecting information incompleteness, struggle to actively acquire and
integrate new information through interaction, highlighting a fundamental gap
in active reasoning capabilities.

</details>


### [13] [SafetyPairs: Isolating Safety Critical Image Features with Counterfactual Image Generation](https://arxiv.org/abs/2510.21120)
*Alec Helbling,Shruti Palaskar,Kundan Krishna,Polo Chau,Leon Gatys,Joseph Yitan Cheng*

Main category: cs.CV

TL;DR: SafetyPairs 是一个生成反事实图像对的框架，其目标是通过细微调整图像来改变其安全标签，从而测试和改进视觉-语言模型在区分细微差别上的能力。同时，SafetyPairs 也被用作增强训练轻量级防护模型的数据增广策略。


<details>
  <summary>Details</summary>
Motivation: 现有的图像安全性数据集过于粗略且模糊，缺乏具体区分安全与非安全的特征。为了系统化研究这一问题，提出了一个框架以生成具有细微改变但安全标签相反的图像对，用于评测和改进模型性能。同时，期望通过这些数据进一步增强模型训练的效率和效果。

Method: 通过图像编辑模型对现有图像进行细微调整，使得安全标签发生变化的同时保持其他无关细节不变。生成这些反事实图像对构成的新基准数据集用来评估模型在区分细微差别方面的性能。同时也利用这些数据提高了训练轻量级防护模型的样例效率。

Result: 构建了一个包含超过 3,020 张图像的新安全基准数据集，涵盖了9个安全分类，可以作为研究细微差别图像安全区分的系统化资源。实验结果显示，利用SafetyPairs 进行模型评测和增强训练均表现出色。

Conclusion: SafetyPairs 不仅是一个有效的基准数据集用于评估视觉-语言模型的性能，同时也是改进模型训练策略的工具。此项研究为提高图像安全性识别准确性提供了新的方向。

Abstract: What exactly makes a particular image unsafe? Systematically differentiating
between benign and problematic images is a challenging problem, as subtle
changes to an image, such as an insulting gesture or symbol, can drastically
alter its safety implications. However, existing image safety datasets are
coarse and ambiguous, offering only broad safety labels without isolating the
specific features that drive these differences. We introduce SafetyPairs, a
scalable framework for generating counterfactual pairs of images, that differ
only in the features relevant to the given safety policy, thus flipping their
safety label. By leveraging image editing models, we make targeted changes to
images that alter their safety labels while leaving safety-irrelevant details
unchanged. Using SafetyPairs, we construct a new safety benchmark, which serves
as a powerful source of evaluation data that highlights weaknesses in
vision-language models' abilities to distinguish between subtly different
images. Beyond evaluation, we find our pipeline serves as an effective data
augmentation strategy that improves the sample efficiency of training
lightweight guard models. We release a benchmark containing over 3,020
SafetyPair images spanning a diverse taxonomy of 9 safety categories, providing
the first systematic resource for studying fine-grained image safety
distinctions.

</details>


### [14] [NoisyGRPO: Incentivizing Multimodal CoT Reasoning via Noise Injection and Bayesian Estimation](https://arxiv.org/abs/2510.21122)
*Longtian Qiu,Shan Ning,Jiaxuan Sun,Xuming He*

Main category: cs.CV

TL;DR: NoisyGRPO是一个通过引入可控噪声到视觉输入以增强探索并使用贝叶斯框架显式建模优势估计过程的多模态强化学习框架。实验表明，NoisyGRPO在标准CoT质量、通用能力和hallucination基准测试中显著提高了小规模MLLMs的泛化能力和鲁棒性，如Qwen2.5-VL 3B。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习框架在增强多模态大语言模型的通用CoT推理能力时，经常难以泛化到训练分布之外。为了解决这个问题，我们需要一个可以更好地探索视觉输入并在此过程中更有效地估算优势的方法，以提高多模态大语言模型的学习效果和泛化能力，特别是在小样本下的表现。

Method: NoisyGRPO通过两个关键方法改进了强化学习训练：(1) 被噪声干扰的探索策略：通过加入高斯噪声到视觉输入来鼓励探索更多的视觉场景；(2) 贝叶斯优势估计：将优势估计建模为一个基于注入噪声和观测轨迹奖励的贝叶斯推断问题，采用一个原则性的方法来计算稳健的轨迹优势后验估计，从而指导多模态大语言模型倾向于视觉基础的轨迹。

Result: 在CoT质量、通用能力和hallucination的基准测试中，NoisyGRPO相较于现有的强化学习框架显著地提升了小规模多模态大语言模型的泛化能力和鲁棒性。模型如Qwen2.5-VL 3B在这方面的性能有了明显的提高。

Conclusion: 通过整合噪声注入探索策略与贝叶斯优势估计，NoisyGRPO为多模态大语言模型在小样本下的强化学习任务提供了一种有效的解决方案。

Abstract: Reinforcement learning (RL) has shown promise in enhancing the general
Chain-of-Thought (CoT) reasoning capabilities of multimodal large language
models (MLLMs). However, when applied to improve general CoT reasoning,
existing RL frameworks often struggle to generalize beyond the training
distribution. To address this, we propose NoisyGRPO, a systematic multimodal RL
framework that introduces controllable noise into visual inputs for enhanced
exploration and explicitly models the advantage estimation process via a
Bayesian framework. Specifically, NoisyGRPO improves RL training by: (1)
\textbf{Noise-Injected Exploration Policy}: Perturbing visual inputs with
Gaussian noise to encourage exploration across a wider range of visual
scenarios; and (2) \textbf{Bayesian Advantage Estimation}: Formulating
advantage estimation as a principled Bayesian inference problem, where the
injected noise level serves as a prior and the observed trajectory reward as
the likelihood. This Bayesian modeling fuses both sources of information to
compute a robust posterior estimate of trajectory advantage, effectively
guiding MLLMs to prefer visually grounded trajectories over noisy ones.
Experiments on standard CoT quality, general capability, and hallucination
benchmarks demonstrate that NoisyGRPO substantially improves generalization and
robustness, especially in RL settings with small-scale MLLMs such as Qwen2.5-VL
3B. The project page is available at
\href{https://artanic30.github.io/project_pages/NoisyGRPO/}{\texttt{https://artanic30.github.io/project\_pages/NoisyGRPO}}.

</details>


### [15] [Digital Contrast CT Pulmonary Angiography Synthesis from Non-contrast CT for Pulmonary Vascular Disease](https://arxiv.org/abs/2510.21140)
*Ying Ming,Yue Lin,Longfei Zhao,Gengwan Li,Zuopeng Tan,Bing Li,Sheng Xie,Wei Song,Qiqi Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于CycleGAN技术的方法，可以从非对比CT扫描图像中生成数字对比CTPA图像，以减少使用对比剂带来的风险。方法在定量和定性评估中表现出比现有技术更好的性能，并且在肺部血管分割和量化任务中也显著改善了NCCT输入的结果


<details>
  <summary>Details</summary>
Motivation: CTPA在诊断肺部血管疾病中是标准，但依赖于碘化对比剂，存在肾毒性和过敏反应的风险，特别是在高风险患者中。鉴于此，研究提出了无需对比剂CTPA生成方案，减少对比剂使用风险

Method: 本文使用了一个基于Cycle-Consistent Generative Adversarial Networks (CycleGAN)的级联合成器来从非对比CT扫描(Non-Contrast CT, NCCT)中生成数字对比CTPA (DCCTPA)图像。该方法使用了410对回顾性的CTPA和NCCT扫描，其中包括来自多个中心的数据，且内部验证了模型的性能和泛化能力

Result: 方法通过定量和定性评估显示出了出色的性能，优于目前最好的方法。此外，该方法在血管分割和量化任务中也表现良好，所有指标都优于NCCT输入的结果

Conclusion: 该研究证明了从NCCT生成DCCTPA的可行性，不仅可以减少对比剂的风险，还展示了较好的图像保真度、有效血管增强和结构保存，为未来无对比剂CTPA的应用打下了基础

Abstract: Computed Tomography Pulmonary Angiography (CTPA) is the reference standard
for diagnosing pulmonary vascular diseases such as Pulmonary Embolism (PE) and
Chronic Thromboembolic Pulmonary Hypertension (CTEPH). However, its reliance on
iodinated contrast agents poses risks including nephrotoxicity and allergic
reactions, particularly in high-risk patients. This study proposes a method to
generate Digital Contrast CTPA (DCCTPA) from Non-Contrast CT (NCCT) scans using
a cascaded synthesizer based on Cycle-Consistent Generative Adversarial
Networks (CycleGAN). Totally retrospective 410 paired CTPA and NCCT scans were
obtained from three centers. The model was trained and validated internally on
249 paired images. Extra dataset that comprising 161 paired images was as test
set for model generalization evaluation and downstream clinical tasks
validation. Compared with state-of-the-art (SOTA) methods, the proposed method
achieved the best comprehensive performance by evaluating quantitative metrics
(For validation, MAE: 156.28, PSNR: 20.71 and SSIM: 0.98; For test, MAE:
165.12, PSNR: 20.27 and SSIM: 0.98) and qualitative visualization,
demonstrating valid vessel enhancement, superior image fidelity and structural
preservation. The approach was further applied to downstream tasks of pulmonary
vessel segmentation and vascular quantification. On the test set, the average
Dice, clDice, and clRecall of artery and vein pulmonary segmentation was 0.70,
0.71, 0.73 and 0.70, 0.72, 0.75 respectively, all markedly improved compared
with NCCT inputs.\@ Inter-class Correlation Coefficient (ICC) for vessel volume
between DCCTPA and CTPA was significantly better than that between NCCT and
CTPA (Average ICC : 0.81 vs 0.70), indicating effective vascular enhancement in
DCCTPA, especially for small vessels.

</details>


### [16] [Towards Physics-informed Spatial Intelligence with Human Priors: An Autonomous Driving Pilot Study](https://arxiv.org/abs/2510.21160)
*Guanlin Wu,Boyan Su,Yang Zhao,Pu Wang,Yichen Lin,Hao Frank Yang*

Main category: cs.CV

TL;DR: 介绍了一种新的结构化空间智能网格（SIG）方案，用于提高基础模型在视觉-空间智能上的表现。SIG通过编码物体布局和物理关系，提供了更准确的空间结构表示，并开发了新的评估指标以量化模型的空间智能能力。实验结果表明，SIG在多模态LLM的场景中带来了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有模型通过文本提示和VQA风格评分来模拟视觉-空间智能（VSI），这种方式忽略了几何关系，容易依赖语言捷径，从而弱化了对真正空间技能的归因。因此，提出了一种新的方案来更精确地表达空间智能，即Spatial Intelligence Grid (SIG)。SIG能够更好地反映场景的真实空间结构。

Method: SIG是一种结构化的网格方案，它明确编码了物体布局、物体之间的关系以及物理基础先验。SIG作为一个补充文本的通道，提供了场景结构的忠实、组合表示，强化了基础模型在形状推理上的能力。基于SIG，开发了新的评估指标，量化了模型的内在VSI，这可以在没有语言知识的情况下全面评估模型的空间能力。

Result: 实验证明了SIG在基础模型中带来了更一致、更稳定、更全面的提升效果。实验中使用的模型为最先进的多模态LLM，如GPT-和Gemini家族模型。在少样本学习任务中，SIG不仅超越了传统的VQA表示，还示范了其作为数据标注和训练方案的潜力。

Conclusion: SIG有效地解决了当前模型在处理空间智能时的局限性，提供了一种更准确、更全面的方式来表达和评估空间智能。同时，相关工作包括发布SIGBench，一个包含1400个真实驾驶场景的数据集，用于进一步研究和验证SIG的有效性。

Abstract: How to integrate and verify spatial intelligence in foundation models remains
an open challenge. Current practice often proxies Visual-Spatial Intelligence
(VSI) with purely textual prompts and VQA-style scoring, which obscures
geometry, invites linguistic shortcuts, and weakens attribution to genuinely
spatial skills. We introduce Spatial Intelligence Grid (SIG): a structured,
grid-based schema that explicitly encodes object layouts, inter-object
relations, and physically grounded priors. As a complementary channel to text,
SIG provides a faithful, compositional representation of scene structure for
foundation-model reasoning. Building on SIG, we derive SIG-informed evaluation
metrics that quantify a model's intrinsic VSI, which separates spatial
capability from language priors. In few-shot in-context learning with
state-of-the-art multimodal LLMs (e.g. GPT- and Gemini-family models), SIG
yields consistently larger, more stable, and more comprehensive gains across
all VSI metrics compared to VQA-only representations, indicating its promise as
a data-labeling and training schema for learning VSI. We also release SIGBench,
a benchmark of 1.4K driving frames annotated with ground-truth SIG labels and
human gaze traces, supporting both grid-based machine VSI tasks and
attention-driven, human-like VSI tasks in autonomous-driving scenarios.

</details>


### [17] [Blockwise Flow Matching: Improving Flow Matching Models For Efficient High-Quality Generation](https://arxiv.org/abs/2510.21167)
*Dogyun Park,Taehoon Lee,Minseok Joo,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 提出了Blockwise Flow Matching (BFM) 帧结构，通过分阶段建模生成轨迹并引入语义特征引导模块，提升了生成质量并降低了推理成本。实验表明，BFM在ImageNet 256x256数据集上比现有的流匹配方法性能更优，推理复杂度提高2.1到4.9倍,生成性能相当。


<details>
  <summary>Details</summary>
Motivation: 解决现有的流匹配模型在不同时间步难以同时捕捉不同信号特征的问题，以及因整个模型反复评估所产生的推理成本问题

Method: 通过将生成轨迹分解成多个时间阶段，使用较小且专精的速度块来建模；同时引入语义特征指导模块，以及轻量级的特征残差近似策略，来提高生成质量和减少推理成本

Result: BFM在ImageNet 256x256数据集上提高了生成性能，加速了2.1到4.9倍，且生成质量保持不变

Conclusion: BFM通过分阶段建模的方式有效提升了生成质量和效率，为高保真的数据生成提供了新的可能

Abstract: Recently, Flow Matching models have pushed the boundaries of high-fidelity
data generation across a wide range of domains. It typically employs a single
large network to learn the entire generative trajectory from noise to data.
Despite their effectiveness, this design struggles to capture distinct signal
characteristics across timesteps simultaneously and incurs substantial
inference costs due to the iterative evaluation of the entire model. To address
these limitations, we propose Blockwise Flow Matching (BFM), a novel framework
that partitions the generative trajectory into multiple temporal segments, each
modeled by smaller but specialized velocity blocks. This blockwise design
enables each block to specialize effectively in its designated interval,
improving inference efficiency and sample quality. To further enhance
generation fidelity, we introduce a Semantic Feature Guidance module that
explicitly conditions velocity blocks on semantically rich features aligned
with pretrained representations. Additionally, we propose a lightweight Feature
Residual Approximation strategy that preserves semantic quality while
significantly reducing inference cost. Extensive experiments on ImageNet
256x256 demonstrate that BFM establishes a substantially improved Pareto
frontier over existing Flow Matching methods, achieving 2.1x to 4.9x
accelerations in inference complexity at comparable generation performance.
Code is available at https://github.com/mlvlab/BFM.

</details>


### [18] [TokenCLIP: Token-wise Prompt Learning for Zero-shot Anomaly Detection](https://arxiv.org/abs/2510.21171)
*Qihang Zhou,Binbin Gao,Guansong Pang,Xin Wang,Jiming Chen,Shibo He*

Main category: cs.CV

TL;DR: TokenCLIP是一种用于细粒度异常学习的动态对齐框架，通过对视觉特征和自适应文本子空间之间的动态分配，提高模型在零样本设置下的异常检测能力。此方法避免了单一文本空间对齐带来的局限性，实现了更为精细且高效的异常捕捉机制。实验结果表明TokenCLIP的有效性和优越性。


<details>
  <summary>Details</summary>
Motivation: 目前用于异常检测的方法通常只会使用单一的文本空间来对齐视觉特征，这在不同对象和领域中难以准确捕捉各式各样的异常语义。因此，作者提出了一种称为TokenCLIP的框架，致力于解决现有方法的不足。

Method: TokenCLIP将单一的文本空间扩展为一组正交子空间，并根据语义相似度来动态分配这些子空间，避免了直接为每个视觉令牌指定独特的文本空间带来的计算开销和优化问题。这种方法不仅减少了计算负担，而且可以通过基于优化传输问题的方式，更准确地匹配视觉特征和语义特征。最后，通过对传输计划应用top-k掩码，能够专门化处理不同的视觉区域的子空间。

Result: TokenCLIP有效地改善了现有方法在零样本对象异常检测中的表现，提高了模型在多样对象与领域中的适应性。实验结果证明了TokenCLIP的优越性。

Conclusion: TokenCLIP通过动态地将每个视觉令牌与一组定制化的文本子空间相结合，从而实现了更为精细的异常检测功能，展示了在未来视觉异常检测领域应用的潜力。

Abstract: Adapting CLIP for anomaly detection on unseen objects has shown strong
potential in a zero-shot manner. However, existing methods typically rely on a
single textual space to align with visual semantics across diverse objects and
domains. The indiscriminate alignment hinders the model from accurately
capturing varied anomaly semantics. We propose TokenCLIP, a token-wise
adaptation framework that enables dynamic alignment between visual and
learnable textual spaces for fine-grained anomaly learning. Rather than mapping
all visual tokens to a single, token-agnostic textual space, TokenCLIP aligns
each token with a customized textual subspace that represents its visual
characteristics. Explicitly assigning a unique learnable textual space to each
token is computationally intractable and prone to insufficient optimization. We
instead expand the token-agnostic textual space into a set of orthogonal
subspaces, and then dynamically assign each token to a subspace combination
guided by semantic affinity, which jointly supports customized and efficient
token-wise adaptation. To this end, we formulate dynamic alignment as an
optimal transport problem, where all visual tokens in an image are transported
to textual subspaces based on semantic similarity. The transport constraints of
OT ensure sufficient optimization across subspaces and encourage them to focus
on different semantics. Solving the problem yields a transport plan that
adaptively assigns each token to semantically relevant subspaces. A top-k
masking is then applied to sparsify the plan and specialize subspaces for
distinct visual regions. Extensive experiments demonstrate the superiority of
TokenCLIP.

</details>


### [19] [KBE-DME: Dynamic Multimodal Evaluation via Knowledge Enhanced Benchmark Evolution](https://arxiv.org/abs/2510.21182)
*Junzhe Zhang,Huixuan Zhang,Xiaojun Wan*

Main category: cs.CV

TL;DR: 提出了一种新的动态多模态评估框架KBE，解决了静态基准测试中存在的数据污染和饱和问题，能够更全面地评估多模态大规模语言模型的能力


<details>
  <summary>Details</summary>
Motivation: 现有静态基准测试存在数据污染和饱和的问题，导致评估结果失真或误导，需要一种更可靠的评估协议

Method: 将问题样本通过图模型表示，提出KBE框架，该框架能通过重建问题和扩展已有问题，生成一个可控且动态演进的基准，以克服数据污染和饱和的问题

Result: 实验表明，KBE能够减轻数据污染和饱和的风险，提供更全面的评估

Conclusion: KBE框架通过引入多模态知识，提供了一个避免数据污染和饱和，可以更准确和全面评估多模态大规模语言模型的方案

Abstract: The rapid progress of multimodal large language models (MLLMs) calls for more
reliable evaluation protocols. Existing static benchmarks suffer from the
potential risk of data contamination and saturation, leading to inflated or
misleading performance evaluations. To address these issues, we first apply
Graph formulation to represent a static or dynamic VQA sample. With the
formulation, we propose Knowledge-enhanced Benchmark Evolution(KBE), a dynamic
multimodal evaluation framework. KBE first analyzes the original static
benchmark, then expands it by integrating multimodal knowledge, transforming
the static benchmark into a controllable, dynamic evolving version. Crucially,
KBE can both reconstruct questions by Re-selecting visual information in the
original image and expand existing questions with external textual knowledge.
It enables difficulty-controllable evaluation by adjusting the degree of
question exploration. Extensive experiments demonstrate that KBE alleviates the
risk of data contamination, data saturation, and provides a more comprehensive
assessment of MLLM capabilities.

</details>


### [20] [3rd Place Solution to ICCV LargeFineFoodAI Retrieval](https://arxiv.org/abs/2510.21198)
*Yang Zhong,Zhiming Wang,Zhaoyang Li,Jinyu Ma,Xiang Li*

Main category: cs.CV

TL;DR: 本文介绍了在Kaggle上ICCV LargeFineFoodAI检索竞赛中获得第三名的解决方案。通过训练四个基础模型并使用加权和的ArcFace和Circle损失函数，然后应用翻译增强（TTA）和集成方法来提高特征表示能力。此外，提出了一种基于扩散和k-互反重排序的新重排序方法。最终，该方法在公共和私人排行榜上分别获得了0.81219和0.81191的mAP@100分数。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在通过使用更有效的模型训练、特征表示增强方法以及重新排序技术，提高在Fine Food图像检索任务中的性能。参赛的目标是在ICCV LargeFineFoodAI检索竞赛中获得前三名的一席之地。

Method: 本论文的方法包括使用加权和的ArcFace和Circle损失训练四个基础模型；然后通过翻译增强（TTA）和集成方法提高特征表示能力；最后，提出了一种基于扩散和k-互反重排序的新重排序方法来改进检索结果。

Result: 最终，该方法在公共排行榜获得了0.81219的mAP@100分数，在私人排行榜获得了0.81191的mAP@100分数，取得了竞赛第三名的好成绩。该结果证明所提出的方法有效且可以在Fine Food图像检索任务中获得很好的性能提升。

Conclusion: 本文提出了一个高效的Fine Food图像检索解决方案，通过模型训练、特征增强和重新排序方法的多个步骤，获得了竞赛的第三名。这表明所提出的技术可以在相同的数据集上产生良好的表现。在未来的工作中，将考虑更复杂的模型和进一步提高检索效果的方法。

Abstract: This paper introduces the 3rd place solution to the ICCV LargeFineFoodAI
Retrieval Competition on Kaggle. Four basic models are independently trained
with the weighted sum of ArcFace and Circle loss, then TTA and Ensemble are
successively applied to improve feature representation ability. In addition, a
new reranking method for retrieval is proposed based on diffusion and
k-reciprocal reranking. Finally, our method scored 0.81219 and 0.81191 mAP@100
on the public and private leaderboard, respectively.

</details>


### [21] [3rd Place Solution to Large-scale Fine-grained Food Recognition](https://arxiv.org/abs/2510.21199)
*Yang Zhong,Yifan Yao,Tong Luo,Youcai Zhang,Yaqian Li*

Main category: cs.CV

TL;DR: 本文描述了我们在Kaggle LargeFineFoodAI-ICCV工作坊识别挑战中的解决方案，通过结合Arcface损失和Circle损失，模型性能得到了提升。我们的方法赢得了比赛的第三名。


<details>
  <summary>Details</summary>
Motivation: 在健康领域，食品分析已经成为热门话题，特别是在细粒度食品识别任务上。为了提高在这个挑战中的性能，本文寻找了一种合适的损失函数组合方法。

Method: 本文使用了Arcface损失和Circle损失的结合，并通过精心调整的配置训练模型，并进行了集成，以获得最终结果。

Result: 我们的方法在Kaggle LargeFineFoodAI-ICCV工作坊识别挑战中取得了第三名的成绩。

Conclusion: 适当的损失函数组合和精心调整的模型训练使我们在细粒度食品识别任务中取得了较好的性能。

Abstract: Food analysis is becoming a hot topic in health area, in which fine-grained
food recognition task plays an important role. In this paper, we describe the
details of our solution to the LargeFineFoodAI-ICCV Workshop-Recognition
challenge held on Kaggle. We find a proper combination of Arcface loss[1] and
Circle loss[9] can bring improvement to the performance. With Arcface and the
combined loss, model was trained with carefully tuned configurations and
ensembled to get the final results. Our solution won the 3rd place in the
competition.

</details>


### [22] [Topology Sculptor, Shape Refiner: Discrete Diffusion Model for High-Fidelity 3D Meshes Generation](https://arxiv.org/abs/2510.21264)
*Kaiyu Song,Hanjiang Lai,Yaqing Zhang,Chuangjian Cai,Yan Pan Kun Yue,Jian Yin*

Main category: cs.CV

TL;DR: Topology Sculptor, Shape Refiner (TSSR) 是一种基于离散扩散模型 (DDMs) 的新方法，用于生成高质量的3D网格。TSSR通过同时生成所有网格标记来提高预测精度和效率，并通过三种创新实现这一点：解耦训练和混合推理，改进的沙漏架构和连接损失。实验表明，TSSR可以生成高质量的艺术家风格的3D网格，能够在$1024^3$的分辨率下实现多达10,000个面的生成。


<details>
  <summary>Details</summary>
Motivation: TSSR的主要动机是通过同时生成所有网格标记来实现高度准确的标记预测，从而实现在并行生成时较高的准确性，优于传统的序列自回归方法。

Method: TSSR 通过如下方式实现方法：1) 解耦训练和混合推理，将DDM生成过程分解为拓扑雕塑阶段和后续的形状细化阶段；2) 改进的沙漏架构，通过双向注意力机制和旋转位置嵌入可以捕捉更丰富的上下文信息；3) 连接损失作为拓扑约束，增强生成3D网格的真实感和保真度。

Result: 在复杂数据集上的实验表明，TSSR可以生成高质量的3D艺术家风格的网格，并能支持高达10,000个面的生成，分辨率可以达到$1024^3$。

Conclusion: TSSR展示了一种生成高质量、艺术家风格3D网格的创新方法，突破了序列自回归方法的局限性，提供了更高效和更准确的生成方式。

Abstract: In this paper, we introduce Topology Sculptor, Shape Refiner (TSSR), a novel
method for generating high-quality, artist-style 3D meshes based on Discrete
Diffusion Models (DDMs). Our primary motivation for TSSR is to achieve highly
accurate token prediction while enabling parallel generation, a significant
advantage over sequential autoregressive methods. By allowing TSSR to "see" all
mesh tokens concurrently, we unlock a new level of efficiency and control. We
leverage this parallel generation capability through three key innovations: 1)
Decoupled Training and Hybrid Inference, which distinctly separates the
DDM-based generation into a topology sculpting stage and a subsequent shape
refinement stage. This strategic decoupling enables TSSR to effectively capture
both intricate local topology and overarching global shape. 2) An Improved
Hourglass Architecture, featuring bidirectional attention enriched by
face-vertex-sequence level Rotational Positional Embeddings (RoPE), thereby
capturing richer contextual information across the mesh structure. 3) A novel
Connection Loss, which acts as a topological constraint to further enhance the
realism and fidelity of the generated meshes. Extensive experiments on complex
datasets demonstrate that TSSR generates high-quality 3D artist-style meshes,
capable of achieving up to 10,000 faces at a remarkable spatial resolution of
$1024^3$. The code will be released at:
https://github.com/psky1111/Tencent-TSSR.

</details>


### [23] [Towards Physically Executable 3D Gaussian for Embodied Navigation](https://arxiv.org/abs/2510.21307)
*Bingchen Miao,Rong Wei,Zhiqi Ge,Xiaoquan sun,Shiqi Gao,Jingzhe Zhu,Renhan Wang,Siliang Tang,Jun Xiao,Rui Tang,Juncheng Li*

Main category: cs.CV

TL;DR: 本文提出了SAGE-3D，一种将3D Gaussian Splatting (3DGS) 升级到可执行且包含语义和物理对齐的环境的方法，使得3DGS能够更好地应用于视觉-语言导航 (VLN)。通过引入语义和物理接口，SAGE-3D解决了3DGS缺失细粒度语义和物理可执行性的缺陷。实验表明，SAGE-3D在VLN任务中表现更好，提高了基线性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D Gaussian Splatting (3DGS) 技术虽然有实时渲染能力，但在视觉-语言导航 (VLN) 中缺乏细粒度语义和物理可执行性，导致难以在实际场景中应用。为此，本文提出一种新的方法，将3DGS升级为一个语义丰富、物理可执行的环境，以填补这个技术瓶颈。

Method: SAGE-3D由两个组件构成：一个是Object-Centric Semantic Grounding，它为3DGS增加了对象级别的细粒度注释；另一个是Physics-Aware Execution Jointing，它将碰撞对象嵌入3DGS并构建丰富的物理接口。此外，作者还发布了InteriorGS和SAGE-Bench，提供更多具有注释的3DGS室内场景数据和基于3DGS的VLN基准和数据集。

Result: 实验结果表明，SAGE-3D在VLN任务中提升了基线性能，特别是在VLN-CE Unseen任务中，性能提高了31%，这表明了其强大的应用价值。

Conclusion: 通过将3D Gaussian Splatting 升级为语义和物理一致的环境，SAGE-3D解决了3DGS在语义和物理上的不足，提高了其在实际应用中的表现。

Abstract: 3D Gaussian Splatting (3DGS), a 3D representation method with photorealistic
real-time rendering capabilities, is regarded as an effective tool for
narrowing the sim-to-real gap. However, it lacks fine-grained semantics and
physical executability for Visual-Language Navigation (VLN). To address this,
we propose SAGE-3D (Semantically and Physically Aligned Gaussian Environments
for 3D Navigation), a new paradigm that upgrades 3DGS into an executable,
semantically and physically aligned environment. It comprises two components:
(1) Object-Centric Semantic Grounding, which adds object-level fine-grained
annotations to 3DGS; and (2) Physics-Aware Execution Jointing, which embeds
collision objects into 3DGS and constructs rich physical interfaces. We release
InteriorGS, containing 1K object-annotated 3DGS indoor scene data, and
introduce SAGE-Bench, the first 3DGS-based VLN benchmark with 2M VLN data.
Experiments show that 3DGS scene data is more difficult to converge, while
exhibiting strong generalizability, improving baseline performance by 31% on
the VLN-CE Unseen task. The data and code will be available soon.

</details>


### [24] [FineRS: Fine-grained Reasoning and Segmentation of Small Objects with Reinforcement Learning](https://arxiv.org/abs/2510.21311)
*Lu Zhang,Jiazuo Yu,Haomiao Xiong,Ping Hu,Yunzhi Zhuge,Huchuan Lu,You He*

Main category: cs.CV

TL;DR: 多模态大型语言模型在处理高分辨率图像中非常小的对象时面临挑战。我们提出了\textsc{FineRS}，一种基于多模态大型语言模型的强化学习框架，用于联合推理和分割高分辨率场景中极小的对象。实验结果表明，该方法在指令引导分割和视觉推理任务上优于现有的多模态大型语言模型方法.


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型在处理高分辨率图像中非常小的对象时面临挑战，尤其是在处理在复杂背景中的超小对象时，因此提出了\textsc{FineRS}来解决这个问题.

Method: \textsc{FineRS}采用了一种粗到细的管道，包含全局语义探索（GSE）和局部感知细化（LPR）两个阶段。GSE执行指令引导推理以生成文本回应和粗略的目标区域，而LPR细化该区域以生成精确的边界框和分割掩码。为进一步联系这两个阶段，我们引入了一种位于指导回顾奖励，使用LPR的输出优化GSE，从而增强粗略区域的探索.

Result: 实验在\textsc{FineRS}-4k和公开数据集上的结果表明，该方法在指令引导分割和视觉推理任务中优于现有的多模态大型语言模型方法.

Conclusion: \textsc{FineRS}在处理高分辨率图像中的极小对象方面表现出了优异的性能，证明了其在指令引导分割和视觉推理任务中的有效性.

Abstract: Multi-modal Large Language Models (MLLMs) have shown remarkable capabilities
across a wide range of vision-language tasks. However, due to the restricted
input resolutions, MLLMs face significant challenges in precisely understanding
and localizing visual details in high-resolution images -- particularly when
dealing with extra-small objects embedded in cluttered contexts. To address
this issue, we propose \textsc{FineRS}, a two-stage MLLM-based reinforcement
learning framework for jointly reasoning and segmenting extremely small objects
within high-resolution scenes. \textsc{FineRS} adopts a coarse-to-fine pipeline
comprising Global Semantic Exploration (GSE) and Localized Perceptual
Refinement (LPR). Specifically, GSE performs instruction-guided reasoning to
generate a textural response and a coarse target region, while LPR refines this
region to produce an accurate bounding box and segmentation mask. To couple the
two stages, we introduce a locate-informed retrospective reward, where LPR's
outputs are used to optimize GSE for more robust coarse region exploration. %
Additionally, we present \textsc{FineRS}-4k, a new dataset for evaluating MLLMs
on attribute-level reasoning and pixel-level segmentation on subtle,
small-scale targets in complex high-resolution scenes. Experimental results on
\textsc{FineRS}-4k and public datasets demonstrate that our method consistently
outperforms state-of-the-art MLLM-based approaches on both instruction-guided
segmentation and visual reasoning tasks.

</details>


### [25] [VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a Unified Concept Set](https://arxiv.org/abs/2510.21323)
*Shufan Shen,Junshu Sun,Qingming Huang,Shuhui Wang*

Main category: cs.CV

TL;DR: VL-SAE 是一种稀疏自编码器，可以将视觉和语言表示解释为统一的概念集合，从而提高视觉语言模型的可解释性和多模态推理能力。实验结果表明VL-SAE增强了视觉语言模型在下游任务上的性能表现，例如零样本图像分类和幻觉消除。该项目的代码位于 https://github.com/ssfgunner/VL-SAE。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言模型已经具备了强大的多模态推理能力，但其中的对齐组件（alignment component）的可解释性仍未被研究，原因在于难以将多模态表示的语义映射到统一的概念集合中。这一问题鼓励我们提出一种新的稀疏自编码器（sparse autoencoder）来解决这一难题，提高模型的透明性和可理解性。

Method: 首先测量多模态表示的语义相似性，我们基于余弦相似性对它们进行显式对齐。接下来，我们构建了一个基于距离的编码器和两个模态特异性的解码器，以确保语义相似表示的激活一致性。我们提出了一个稀疏编码器，该编码器能将视觉-语言表示映射到隐藏激活上。每个隐藏层中的神经元都与语义相似的图像和文本所代表的概念对应，从而使用统一的概念集解释这些表示。为了建立神经元-概念相关性，我们鼓励语义相似表示在自我监督训练过程中展示一致的神经元激活。

Result: 实验表明，VL-SAE在解释和增强视觉-语言对齐方面具备优越的能力。对于解释，可以通过将视觉和语言表示的语义与概念进行比较来理解它们之间的对齐。对于增强，可以通过在概念级别对齐视觉-语言表示来增强对齐，从而提高下游任务（例如零样本图像分类和幻觉消除）的性能。

Conclusion: 这项研究提出了VL-SAE，这是一种稀疏自编码器，可以将视觉和语言表示解释为统一的概念集合，进而提高了视觉语言模型的可解释性和多模态推理能力。同时，该方法也增强了模型在下游任务上的性能表现，对实际应用具有重要意义。

Abstract: The alignment of vision-language representations endows current
Vision-Language Models (VLMs) with strong multi-modal reasoning capabilities.
However, the interpretability of the alignment component remains uninvestigated
due to the difficulty in mapping the semantics of multi-modal representations
into a unified concept set. To address this problem, we propose VL-SAE, a
sparse autoencoder that encodes vision-language representations into its hidden
activations. Each neuron in its hidden layer correlates to a concept
represented by semantically similar images and texts, thereby interpreting
these representations with a unified concept set. To establish the
neuron-concept correlation, we encourage semantically similar representations
to exhibit consistent neuron activations during self-supervised training.
First, to measure the semantic similarity of multi-modal representations, we
perform their alignment in an explicit form based on cosine similarity. Second,
we construct the VL-SAE with a distance-based encoder and two modality-specific
decoders to ensure the activation consistency of semantically similar
representations. Experiments across multiple VLMs (e.g., CLIP, LLaVA)
demonstrate the superior capability of VL-SAE in interpreting and enhancing the
vision-language alignment. For interpretation, the alignment between vision and
language representations can be understood by comparing their semantics with
concepts. For enhancement, the alignment can be strengthened by aligning
vision-language representations at the concept level, contributing to
performance improvements in downstream tasks, including zero-shot image
classification and hallucination elimination. Codes are available at
https://github.com/ssfgunner/VL-SAE.

</details>


### [26] [Morphologically Intelligent Perturbation Prediction with FORM](https://arxiv.org/abs/2510.21337)
*Reed Naidoo,Matt De Vries,Olga Fourkioti,Vicky Bousgouni,Mar Arias-Garcia,Maria Portillo-Malumbres,Chris Bakal*

Main category: cs.CV

TL;DR: 研究提出FORM框架，通过机器学习方法来预测细胞在受到外部刺激后的三维结构变化，以更准确地模拟细胞响应。FORM包括一个通过多通道VQGAN训练的形态编码器和一个基于扩散的扰动轨迹模块。FORM可以在大尺度的数据集上训练，支持无条件形态合成和条件仿真等任务，评估基准MorphoEval量化形态变化。


<details>
  <summary>Details</summary>
Motivation: 现有计算框架受二维限制，难以捕捉细胞形态在扰动下的复杂性。为此，研究提出一种机器学习框架，以准确模拟细胞在三维空间中的响应变化。

Method: FORM框架有两个部分：一个多通道VQGAN训练的形态编码器，用于从细胞形态中学习3D表示，以及一个基于扩散的扰动轨迹模块，用于捕捉形态随扰动条件变化的演化过程。研究使用了包含超过65000个3D细胞体积的大规模数据集进行训练，涵盖多样化的化学和遗传扰动。FORM不仅可以生成条件下的细胞形态，还能预测下游信号活动和组合扰动效果。

Result: 在评估基准MorphoEval的支持下，FORM能够预测信号活动，仿真组合扰动效应，模拟未见过的扰动状态之间的形态动力学转换。该方法已被证明在预测细胞形态变化方面具有高分辨率预测模拟的能力。

Conclusion: FORM和MorphoEval通过高分辨率预测模拟，将形态、扰动和功能联系起来，朝着实现三维虚拟细胞的目标迈进了一步。

Abstract: Understanding how cells respond to external stimuli is a central challenge in
biomedical research and drug development. Current computational frameworks for
modelling cellular responses remain restricted to two-dimensional
representations, limiting their capacity to capture the complexity of cell
morphology under perturbation. This dimensional constraint poses a critical
bottleneck for the development of accurate virtual cell models. Here, we
present FORM, a machine learning framework for predicting perturbation-induced
changes in three-dimensional cellular structure. FORM consists of two
components: a morphology encoder, trained end-to-end via a novel multi-channel
VQGAN to learn compact 3D representations of cell shape, and a diffusion-based
perturbation trajectory module that captures how morphology evolves across
perturbation conditions. Trained on a large-scale dataset of over 65,000
multi-fluorescence 3D cell volumes spanning diverse chemical and genetic
perturbations, FORM supports both unconditional morphology synthesis and
conditional simulation of perturbed cell states. Beyond generation, FORM can
predict downstream signalling activity, simulate combinatorial perturbation
effects, and model morphodynamic transitions between states of unseen
perturbations. To evaluate performance, we introduce MorphoEval, a benchmarking
suite that quantifies perturbation-induced morphological changes in structural,
statistical, and biological dimensions. Together, FORM and MorphoEval work
toward the realisation of the 3D virtual cell by linking morphology,
perturbation, and function through high-resolution predictive simulation.

</details>


### [27] [CT-CLIP: A Multi-modal Fusion Framework for Robust Apple Leaf Disease Recognition in Complex Environments](https://arxiv.org/abs/2510.21346)
*Lemin Liu,Fangchao Hu,Honghua Jiang,Yaru Chen,Limin Liu,Yongliang Qiao*

Main category: cs.CV

TL;DR: 提出了一种名为CT-CLIP的多分支识别框架，结合CNN和Vision Transformer来处理苹果树叶疾病的表型异质性问题，并通过一种自适应特征融合模块来优化局部和全局信息的融合。实验表明，CT-CLIP在不同数据集上的识别准确率分别是97.38%和96.12%，大幅超越了几个基准方法。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统多尺度特征融合方法在处理苹果树叶疾病表型异质性方面的问题，尤其是在病变间显著的差异性，作者提出了一个新的方法来有效应对这一挑战。这项研究特别关注病变的形态和分布多样性以及在复杂背景下的干扰。

Method: 该研究提出了一种多分支识别框架，即CNN-Transformer-CLIP (CT-CLIP)。这个框架通过CNN来提取局部细节特征，通过Vision Transformer来抓取全局的结构关系，并通过一个自适应特征融合模块（AFFM）实现动态特征融合。此外，研究还引入了一个多模态图像-文字学习方法，使用预训练的CLIP权重来实现视觉特征与疾病描述之间的深度对齐。

Result: 实验结果显示，CT-CLIP在公共数据集和自建数据集上的识别准确率分别为97.38%和96.12%，明显优于几个基准方法。

Conclusion: CT-CLIP提高了在复杂环境条件下识别准确率，为农业疾病自动识别提供了创新且实用的解决方案。

Abstract: In complex orchard environments, the phenotypic heterogeneity of different
apple leaf diseases, characterized by significant variation among lesions,
poses a challenge to traditional multi-scale feature fusion methods. These
methods only integrate multi-layer features extracted by convolutional neural
networks (CNNs) and fail to adequately account for the relationships between
local and global features. Therefore, this study proposes a multi-branch
recognition framework named CNN-Transformer-CLIP (CT-CLIP). The framework
synergistically employs a CNN to extract local lesion detail features and a
Vision Transformer to capture global structural relationships. An Adaptive
Feature Fusion Module (AFFM) then dynamically fuses these features, achieving
optimal coupling of local and global information and effectively addressing the
diversity in lesion morphology and distribution. Additionally, to mitigate
interference from complex backgrounds and significantly enhance recognition
accuracy under few-shot conditions, this study proposes a multimodal image-text
learning approach. By leveraging pre-trained CLIP weights, it achieves deep
alignment between visual features and disease semantic descriptions.
Experimental results show that CT-CLIP achieves accuracies of 97.38% and 96.12%
on a publicly available apple disease and a self-built dataset, outperforming
several baseline methods. The proposed CT-CLIP demonstrates strong capabilities
in recognizing agricultural diseases, significantly enhances identification
accuracy under complex environmental conditions, provides an innovative and
practical solution for automated disease recognition in agricultural
applications.

</details>


### [28] [Dynamic Semantic-Aware Correlation Modeling for UAV Tracking](https://arxiv.org/abs/2510.21351)
*Xinyu Zhou,Tongxin Pan,Lingyi Hong,Pinxue Guo,Haijing Guo,Zhaoyu Chen,Kaixun Jiang,Wenqiang Zhang*

Main category: cs.CV

TL;DR: 提出了一种动态语义感知相关模型跟踪框架，用于提高无人机跟踪的精度和鲁棒性。通过结合Transformer的相关图和动态语义相关生成器，提高了搜索区域从模板中提取重要信息的能力。同时设计了一种裁剪方法，实现了速度和精度之间的权衡。实验结果证明了该方法的有效性，在多个无人机跟踪数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机跟踪方法主要强调速度，缺乏对语义认知的探索，这使得在搜索区域中提取模板的准确定位信息变得困难，从而在如相机运动、快速运动和低分辨率等典型挑战下表现不佳。为了应对这一问题，我们提出了一种动态语义感知的新方法。

Method: 框架的核心是一个动态语义相关生成器，结合Transformer提供的相关图，探索语义相关性。提出了提高搜索区域从模板中提取重要信息的能力的方法，同时设计了一种裁剪方法增强跟踪速度。通过这些方法，实现了在速度和精度之间的权衡，达成灵活部署的目标。

Result: 实验证明了该方法的有效性，显著提高了无人机跟踪在多种挑战场景下的精度和鲁棒性。该方法在多个数据集上的表现优于现有方法，达到了竞争性的性能水平。提供开源代码便于研究者使用和验证。

Conclusion: 我们提出了一种新的跟踪框架，通过纳入动态语义关联能力和高效的剪枝技术，不仅在性能上与现有方法相比较，还提供了灵活性以适应不同的计算资源。这表明，这种方法在无人机跟踪的未来研究中具有潜在的应用价值。

Abstract: UAV tracking can be widely applied in scenarios such as disaster rescue,
environmental monitoring, and logistics transportation. However, existing UAV
tracking methods predominantly emphasize speed and lack exploration in semantic
awareness, which hinders the search region from extracting accurate
localization information from the template. The limitation results in
suboptimal performance under typical UAV tracking challenges such as camera
motion, fast motion, and low resolution, etc. To address this issue, we propose
a dynamic semantic aware correlation modeling tracking framework. The core of
our framework is a Dynamic Semantic Relevance Generator, which, in combination
with the correlation map from the Transformer, explore semantic relevance. The
approach enhances the search region's ability to extract important information
from the template, improving accuracy and robustness under the aforementioned
challenges. Additionally, to enhance the tracking speed, we design a pruning
method for the proposed framework. Therefore, we present multiple model
variants that achieve trade-offs between speed and accuracy, enabling flexible
deployment according to the available computational resources. Experimental
results validate the effectiveness of our method, achieving competitive
performance on multiple UAV tracking datasets. The code is available at
https://github.com/zxyyxzz/DSATrack.

</details>


### [29] [Gaze-VLM:Bridging Gaze and VLMs through Attention Regularization for Egocentric Understanding](https://arxiv.org/abs/2510.21356)
*Anupam Pani,Yanchao Yang*

Main category: cs.CV

TL;DR: 此研究提出一种基于视觉语言模型（VLM）的凝视正则化框架，通过训练期间使用人类视觉凝视来增强对未来事件预测和当前活动理解的任务性能。与仅依赖视觉输入或凝视作为辅助输入信号的先前方法不同，该方法在训练过程中仅使用凝视数据，实验结果表明，相较于无凝视正则化的基线模型，其性能有所提高。该工作为现实场景中的辅助机器人和人类-机器协作中的VLM预测能力的增强奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在利用人类视觉凝视的强大信号来提升视觉语言模型（VLM）在未来事件预测和当前活动理解任务中的性能，特别是在辅助机器人和人类-机器协作的应用场景中。

Method: 提出了一个凝视正则化的注意力机制，该机制使模型聚焦点与人类视觉凝视对齐，这种方法灵活且模块化，可应用于多种使用注意力机制的VLM架构。在训练过程中，该方法仅使用凝视数据。

Result: 实验结果显示，相较于无凝视正则化的基线模型，该方法在对未来事件预测的语义预测得分方面提高11，对于当前活动理解则大约提高7分。

Conclusion: 该工作验证了凝视指导训练在提升视觉语言模型（VLM）准确性和鲁棒性中的价值，并为在现实应用场景中利用人类凝视来增强VLM预测能力奠定了基础。

Abstract: Eye gaze offers valuable cues about attention, short-term intent, and future
actions, making it a powerful signal for modeling egocentric behavior. In this
work, we propose a gaze-regularized framework that enhances VLMs for two key
egocentric understanding tasks: fine-grained future event prediction and
current activity understanding. Unlike prior approaches that rely solely on
visual inputs or use gaze as an auxiliary input signal , our method uses gaze
only during training. We introduce a gaze-regularized attention mechanism that
aligns model focus with human visual gaze. This design is flexible and modular,
allowing it to generalize across multiple VLM architectures that utilize
attention. Experimental results show that our approach improves semantic
prediction scores by up to 11 for future event prediction and around 7 for
current activity understanding, compared to the corresponding baseline models
trained without gaze regularization. These results highlight the value of
gaze-guided training in improving the accuracy and robustness of egocentric
VLMs. Overall, this work establishes a foundation for using human gaze to
enhance the predictive capabilities of VLMs in real-world scenarios like
assistive robots and human-machine collaboration. Code and additional
information is available at: https://github.com/anupampani/Gaze-VLM

</details>


### [30] [Why Registration Quality Matters: Enhancing sCT Synthesis with IMPACT-Based Registration](https://arxiv.org/abs/2510.21358)
*Valentin Boussot,Cédric Hémon,Jean-Claude Nunes,Jean-Louis Dillenseger*

Main category: cs.CV

TL;DR: 本文提出了一个用于从MRI和CBCT生成合成CT(sCT)的统一管道，并提出了IMPACT-Synth损失函数和IMPACT注册策略以提高生成图像的解剖学保真度。研究发现IMPACT注册策略在局部测试集上表现更佳，有助于减少注册偏差和提高模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于开发一种能够生成高度解剖学保真度的合成CT图像的方法，特别是在注册过程中减少偏差以提高模型性能和泛化能力。

Method: 使用2.5D U-Net++模型，利用ResNet-34编码器进行训练。训练过程中结合了像素级L1损失和基于SAM和TotalSegmentator的感知损失IMPACT-Synth，优化结构保真度。采用AdamW优化器，每25K步长学习率减半，并且在基于片、标准化、身体掩膜和随机翻转的数据上进行训练。最终结果使用测试时增强和五重整合来改进预测。注册策略也得到了评估，包括Elastix（基于交互信息）和IMPACT（基于特征相似度度量的策略）。

Result: 在局部测试集上，IMPACT注册策略生成的sCT在解剖一致性上要优，MAE值更低并且显示了更真实的解剖结构。然而，在公共验证集上，使用Elastix对齐训练的数据模型表现更好。

Conclusion: 研究结论指出，解剖一致性良好的注册策略有助于在训练和评估过程中减少偏差，从而支持开发具有更强泛化能力的sCT合成模型。

Abstract: We participated in the SynthRAD2025 challenge (Tasks 1 and 2) with a unified
pipeline for synthetic CT (sCT) generation from MRI and CBCT, implemented using
the KonfAI framework. Our model is a 2.5D U-Net++ with a ResNet-34 encoder,
trained jointly across anatomical regions and fine-tuned per region. The loss
function combined pixel-wise L1 loss with IMPACT-Synth, a perceptual loss
derived from SAM and TotalSegmentator to enhance structural fidelity. Training
was performed using AdamW (initial learning rate = 0.001, halved every 25k
steps) on patch-based, normalized, body-masked inputs (320x320 for MRI, 256x256
for CBCT), with random flipping as the only augmentation. No post-processing
was applied. Final predictions leveraged test-time augmentation and five-fold
ensembling. The best model was selected based on validation MAE. Two
registration strategies were evaluated: (i) Elastix with mutual information,
consistent with the challenge pipeline, and (ii) IMPACT, a feature-based
similarity metric leveraging pretrained segmentation networks. On the local
test sets, IMPACT-based registration achieved more accurate and anatomically
consistent alignments than mutual-information-based registration, resulting in
improved sCT synthesis with lower MAE and more realistic anatomical structures.
On the public validation set, however, models trained with Elastix-aligned data
achieved higher scores, reflecting a registration bias favoring alignment
strategies consistent with the evaluation pipeline. This highlights how
registration errors can propagate into supervised learning, influencing both
training and evaluation, and potentially inflating performance metrics at the
expense of anatomical fidelity. By promoting anatomically consistent alignment,
IMPACT helps mitigate this bias and supports the development of more robust and
generalizable sCT synthesis models.

</details>


### [31] [TerraGen: A Unified Multi-Task Layout Generation Framework for Remote Sensing Data Augmentation](https://arxiv.org/abs/2510.21391)
*Datao Tang,Hao Wang,Yudeng Xin,Hui Qiao,Dongsheng Jiang,Yin Li,Zhiheng Yu,Xiangyong Cao*

Main category: cs.CV

TL;DR: TerraGen是一个统一的布局到图像生成框架，旨在为各种高级视觉任务（如检测、分割和提取）灵活、空间可控地合成遥感图像。它引入了地理-空间布局编码器，将边界框和分割掩码输入统一，结合了多尺度注入方案和掩码加权损失，以显式编码空间约束，从全局结构到细粒度细节。同时，建立了首个大型多任务遥感布局生成数据集，包含45k幅图像，并确立了标准化评估协议。实验结果表明，TerraGen可实现最佳的生成图像质量，并且可以作为通用的数据增强生成器，显著提升下游任务性能，展示出强大的跨任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前生成数据增强框架针对每个视觉任务都需要独立训练生成模型，忽略了地理信息和空间约束的建模。为了解决这一问题，这篇论文提出了一种新的框架TerraGen。

Method: TerraGen引入了地理-空间布局编码器，该编码器统一了边界框和分割掩码输入，并结合了多尺度注入方案和掩码加权损失，以显式编码空间约束。此框架旨在生成适合各种高级视觉任务的遥感图像。此外，还建立了首个大型多任务遥感布局生成数据集，包含了45k幅图像。

Result: 实验证明，TerraGen能够生成最佳质量的图像，无论是在多种视觉任务还是数据增强场景中均表现出了强大的性能。并且在完整数据和少量样本场景下均展示了良好的泛化能力。

Conclusion: TerraGen在统一多个视觉任务生成高质量遥感图像方面表现出色，它不仅能够显著提升下游任务的性能，还能在数据增强中展现出强大的跨任务泛化能力。

Abstract: Remote sensing vision tasks require extensive labeled data across multiple,
interconnected domains. However, current generative data augmentation
frameworks are task-isolated, i.e., each vision task requires training an
independent generative model, and ignores the modeling of geographical
information and spatial constraints. To address these issues, we propose
\textbf{TerraGen}, a unified layout-to-image generation framework that enables
flexible, spatially controllable synthesis of remote sensing imagery for
various high-level vision tasks, e.g., detection, segmentation, and extraction.
Specifically, TerraGen introduces a geographic-spatial layout encoder that
unifies bounding box and segmentation mask inputs, combined with a multi-scale
injection scheme and mask-weighted loss to explicitly encode spatial
constraints, from global structures to fine details. Also, we construct the
first large-scale multi-task remote sensing layout generation dataset
containing 45k images and establish a standardized evaluation protocol for this
task. Experimental results show that our TerraGen can achieve the best
generation image quality across diverse tasks. Additionally, TerraGen can be
used as a universal data-augmentation generator, enhancing downstream task
performance significantly and demonstrating robust cross-task generalisation in
both full-data and few-shot scenarios.

</details>


### [32] [Depth-Supervised Fusion Network for Seamless-Free Image Stitching](https://arxiv.org/abs/2510.21396)
*Zhiying Jiang,Ruhao Yan,Zengxi Zhang,Bowei Zhang,Jinyuan Liu*

Main category: cs.CV

TL;DR: 本文提出了一种深度一致性约束无缝图像拼接方法，通过多层次机制和全局深度正则化约束来提高深度差异引起的多视图对齐精度，并通过图计算优化多视图图像融合过程，使拼接更加自然且无缝。同时，还引入了一种重新参数化策略，以优化结构设计，显著提高算法效率。实验表明，该方法性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多视图图像拼接中存在的主要问题是由不同深度引起的显著视差，导致鬼影效应和对齐误差。由此提出了多视图图像对齐和融合过程的新策略来解决这些问题，以实现更准确、自然和无痕的图像拼接结果。

Method: 首先通过多层次机制结合全局深度正则化约束来处理由视差引起的多视图对齐困难；然后，利用图计算找到最优拼接路径，并通过扩散软缝区域来精确定位过渡区域，从而更有效地减少对齐误差，实现更自然的无缝拼接。此外，引入重新参数化策略，优化算法结构以提高效率。

Result: 实验结果表明，所提出的深度一致性约束无缝图像拼接方法在多视图图像对齐和融合过程中，特别是在处理深度差异引起的问题时具有显著优势，且算法效率有所提升。

Conclusion: 与现有图像拼接方法相比，该方法显著改进了由深度差异引起的问题处理效果，并且通过算法结构改进实现了效率提升，展示了应用于多视图图像拼接的良好性能。

Abstract: Image stitching synthesizes images captured from multiple perspectives into a
single image with a broader field of view. The significant variations in object
depth often lead to large parallax, resulting in ghosting and misalignment in
the stitched results. To address this, we propose a
depth-consistency-constrained seamless-free image stitching method. First, to
tackle the multi-view alignment difficulties caused by parallax, a multi-stage
mechanism combined with global depth regularization constraints is developed to
enhance the alignment accuracy of the same apparent target across different
depth ranges. Second, during the multi-view image fusion process, an optimal
stitching seam is determined through graph-based low-cost computation, and a
soft-seam region is diffused to precisely locate transition areas, thereby
effectively mitigating alignment errors induced by parallax and achieving
natural and seamless stitching results. Furthermore, considering the
computational overhead in the shift regression process, a reparameterization
strategy is incorporated to optimize the structural design, significantly
improving algorithm efficiency while maintaining optimal performance. Extensive
experiments demonstrate the superior performance of the proposed method against
the existing methods. Code is available at https://github.com/DLUT-YRH/DSFN.

</details>


### [33] [MUVR: A Multi-Modal Untrimmed Video Retrieval Benchmark with Multi-Level Visual Correspondence](https://arxiv.org/abs/2510.21406)
*Yue Feng,Jinwei Hu,Qijia Lu,Jiawei Niu,Li Tan,Shuo Yuan,Ziyi Yan,Yizhen Jia,Qingzhi He,Shiping Ge,Ethan Q. Chen,Wentong Li,Limin Wang,Jie Qin*

Main category: cs.CV

TL;DR: 提出了一项新的任务：多模态未编辑视频检索(MUVR)，旨在利用多模态查询检索包含相关片段的未编辑视频，以适应长视频平台。MUVR包含三个版本：Base，Filter，QA，分别用以评估检索模型和多模态语言模型在问答格式下的表现。测试数据集包括53000个未编辑视频，1050个查询。测试了三种最先进的视频检索模型，六种基于图像的视觉语言模型，以及十个多模态语言模型。这些实验揭示了当前检索方法和多模态语言模型的一些限制。网址：https://github.com/debby-0527/MUVR。


<details>
  <summary>Details</summary>
Motivation: 视频平台需要一种能够处理长视频和多模态查询的视频检索系统，以提高用户体验。当前的检索系统对于未编辑视频和多模态查询处理能力不足。因此提出MUVR来解决这些问题，提高检索性能。

Method: MUVR设计了一套基于长视频和多模态查询的检索方案，包括基于视屏内容的多层次视觉对应关系，及一系列详细评估指标。测试了三种高级的视频检索模型，六种基于图像的视觉语言模型，以及十个多模态语言模型。这些测试揭示了现有处理未编辑视频和多模态查询能力的局限，并使得进一步改进有了明确的目标和路径。

Result: 测试结果显示，现有的视频检索方法和多模态语言模型在未编辑视频检索和多模态查询处理方面存在明显不足。新设计的MUVR展示了改进的空间，有助于推动相关领域研究的进步。此外，公开的平台和数据集（https://github.com/debby-0527/MUVR）可进一步用于测试其它方法。

Conclusion: MUVR是一种新的视频检索任务，适用于长视频平台。它定义了新的检索需求，评估了现有的处理方法，并指出了未来研究的方向和挑战。其公开的测试集和代码为科研和实际应用提供了重要资源。

Abstract: We propose the Multi-modal Untrimmed Video Retrieval task, along with a new
benchmark (MUVR) to advance video retrieval for long-video platforms. MUVR aims
to retrieve untrimmed videos containing relevant segments using multi-modal
queries. It has the following features: 1) Practical retrieval paradigm: MUVR
supports video-centric multi-modal queries, expressing fine-grained retrieval
needs through long text descriptions, video tag prompts, and mask prompts. It
adopts a one-to-many retrieval paradigm and focuses on untrimmed videos,
tailored for long-video platform applications. 2) Multi-level visual
correspondence: To cover common video categories (e.g., news, travel, dance)
and precisely define retrieval matching criteria, we construct multi-level
visual correspondence based on core video content (e.g., news events, travel
locations, dance moves) which users are interested in and want to retrieve. It
covers six levels: copy, event, scene, instance, action, and others. 3)
Comprehensive evaluation criteria: We develop 3 versions of MUVR (i.e., Base,
Filter, QA). MUVR-Base/Filter evaluates retrieval models, while MUVR-QA
assesses MLLMs in a question-answering format. We also propose a Reranking
Score to evaluate the reranking ability of MLLMs. MUVR consists of 53K
untrimmed videos from the video platform Bilibili, with 1,050 multi-modal
queries and 84K matches. Extensive evaluations of 3 state-of-the-art video
retrieval models, 6 image-based VLMs, and 10 MLLMs are conducted. MUVR reveals
the limitations of retrieval methods in processing untrimmed videos and
multi-modal queries, as well as MLLMs in multi-video understanding and
reranking. Our code and benchmark is available at
https://github.com/debby-0527/MUVR.

</details>


### [34] [Bridging the gap to real-world language-grounded visual concept learning](https://arxiv.org/abs/2510.21412)
*Whie Jung,Semin Kim,Junee Kim,Seunghoon Hong*

Main category: cs.CV

TL;DR: 该工作提出了一种可扩展的框架，能够自适应地识别图像相关的概念轴，并将视觉概念绑定到这些真实世界的轴上。该框架通过优化组合锚定目标，在不同概念轴之间实现独立操作。实验证明了该框架在ImageNet、CelebA-HQ和AFHQ上的编辑能力和组成泛化能力优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有的基于语言的视觉概念学习方法局限于预先定义的颜色和形状等少数基本轴，并且主要在合成数据上进行探索。因此，该工作旨在提出一种能够识别和应用更广泛、更真实世界概念的框架

Method: 通过利用预训练的视觉语言模型和通用提示策略，该框架能够自动识别广泛的图像相关轴并且自适应地将视觉特性绑定到这些轴上。优化组合锚定目标，确保在不干扰其他轴的情况下独立操作

Result: 该方法在ImageNet、CelebA-HQ和AFHQ上展示出强大的编辑能力和组成泛化能力，优于现有的视觉概念学习和文本编辑方法

Conclusion: 本文提出了一种基于通用暗示策略的框架，能够自适应地识别并应用视觉概念，展示了其在真实世界场景中的强大能力，且优于现有的方法

Abstract: Human intelligence effortlessly interprets visual scenes along a rich
spectrum of semantic dimensions. However, existing approaches to
language-grounded visual concept learning are limited to a few predefined
primitive axes, such as color and shape, and are typically explored in
synthetic datasets. In this work, we propose a scalable framework that
adaptively identifies image-related concept axes and grounds visual concepts
along these axes in real-world scenes. Leveraging a pretrained vision-language
model and our universal prompting strategy, our framework identifies a diverse
image-related axes without any prior knowledge. Our universal concept encoder
adaptively binds visual features to the discovered axes without introducing
additional model parameters for each concept. To ground visual concepts along
the discovered axes, we optimize a compositional anchoring objective, which
ensures that each axis can be independently manipulated without affecting
others. We demonstrate the effectiveness of our framework on subsets of
ImageNet, CelebA-HQ, and AFHQ, showcasing superior editing capabilities across
diverse real-world concepts that are too varied to be manually predefined. Our
method also exhibits strong compositional generalization, outperforming
existing visual concept learning and text-based editing methods. The code is
available at https://github.com/whieya/Language-grounded-VCL.

</details>


### [35] [ArtiLatent: Realistic Articulated 3D Object Generation via Structured Latents](https://arxiv.org/abs/2510.21432)
*Honghua Chen,Yushi Lan,Yongwei Chen,Xingang Pan*

Main category: cs.CV

TL;DR: 提出了一种名为ArtiLatent的生成框架，用于合成具有精细几何、准确活动性和逼真外观的人造3D物体。通过联合建模部件几何和活动动力学，该框架能够在统一的潜在空间中生成多样化且物理上合理的样本，并且能够重建逼真的3D形状。实验结果表明，在几何一致性和外观保真度上，该方法优于现有方法，提供了一种合成和操纵活动3D对象的有效解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前生成活动3D物件的方法在几何精度和外观保真度上仍存在局限性，旨在通过综合运用潜在表示和条件外观解码来提升模型合成效果，从而突破这些限制。

Method: 框架首先通过变分自动编码器将部件几何和运动属性嵌入统一的潜在空间，然后训练该空间以实现多样化的物理上合理的样本。通过条件解码，确保了在活动状态下能生成合乎实际的纹理特征，提高视觉的真实性。

Result: 实验显示，基于PartNet-Mobility和ACD数据集的广泛测试证明了ArtiLatent在几何一致性和外观保真度上超越了现有方法，提供了更有效的3D物件合成方法。

Conclusion: ArtiLatent不仅实现了自动化精细几何特征的生成，还解决了如何合成活动物体时保持外观真实度的问题，提供了一种有效的方法来生成和操纵3D对象；也证明了潜在表示结合条件外观解码的好处。

Abstract: We propose ArtiLatent, a generative framework that synthesizes human-made 3D
objects with fine-grained geometry, accurate articulation, and realistic
appearance. Our approach jointly models part geometry and articulation dynamics
by embedding sparse voxel representations and associated articulation
properties, including joint type, axis, origin, range, and part category, into
a unified latent space via a variational autoencoder. A latent diffusion model
is then trained over this space to enable diverse yet physically plausible
sampling. To reconstruct photorealistic 3D shapes, we introduce an
articulation-aware Gaussian decoder that accounts for articulation-dependent
visibility changes (e.g., revealing the interior of a drawer when opened). By
conditioning appearance decoding on articulation state, our method assigns
plausible texture features to regions that are typically occluded in static
poses, significantly improving visual realism across articulation
configurations. Extensive experiments on furniture-like objects from
PartNet-Mobility and ACD datasets demonstrate that ArtiLatent outperforms
existing approaches in geometric consistency and appearance fidelity. Our
framework provides a scalable solution for articulated 3D object synthesis and
manipulation.

</details>


### [36] [OpenHype: Hyperbolic Embeddings for Hierarchical Open-Vocabulary Radiance Fields](https://arxiv.org/abs/2510.21441)
*Lisa Weijler,Sebastian Koch,Fabio Poiesi,Timo Ropinski,Pedro Hermosilla*

Main category: cs.CV

TL;DR: 提出了一种名为OpenHype的新方法，该方法使用连续双曲潜在空间来表示场景层次结构，克服了现有方法的局限性，其在标准基准上的表现优于当前最先进方法，展示了在3D场景理解中的高效性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以通过隐式表示建模3D物体和3D场景的内在层次结构，导致理解和推理效率低下且适应性不足。提出新方法来解决这些问题。

Method: 利用双曲几何中的性质，建立能够自然编码多尺度关系的连续双曲潜在空间，用于表示场景层次结构。通过利用该空间的各个层次的等距距路径进行平滑层次遍历。

Result: 新方法在标准基准上的表现优于当前最先进方法，展示了在3D场景理解中的高效性和适应性，特别是在推理时间和一般化方面有所突破。

Conclusion: OpenHype代表了一种新的途径，用于建模复杂的3D环境的层次结构，能够更好地理解和推理3D场景。

Abstract: Modeling the inherent hierarchical structure of 3D objects and 3D scenes is
highly desirable, as it enables a more holistic understanding of environments
for autonomous agents. Accomplishing this with implicit representations, such
as Neural Radiance Fields, remains an unexplored challenge. Existing methods
that explicitly model hierarchical structures often face significant
limitations: they either require multiple rendering passes to capture
embeddings at different levels of granularity, significantly increasing
inference time, or rely on predefined, closed-set discrete hierarchies that
generalize poorly to the diverse and nuanced structures encountered by agents
in the real world. To address these challenges, we propose OpenHype, a novel
approach that represents scene hierarchies using a continuous hyperbolic latent
space. By leveraging the properties of hyperbolic geometry, OpenHype naturally
encodes multi-scale relationships and enables smooth traversal of hierarchies
through geodesic paths in latent space. Our method outperforms state-of-the-art
approaches on standard benchmarks, demonstrating superior efficiency and
adaptability in 3D scene understanding.

</details>


### [37] [PhysWorld: From Real Videos to World Models of Deformable Objects via Physics-Aware Demonstration Synthesis](https://arxiv.org/abs/2510.21447)
*Yu Yang,Zhilu Zhang,Xiang Zhang,Yihan Zeng,Hui Li,Wangmeng Zuo*

Main category: cs.CV

TL;DR: PhysWorld 是一种利用模拟器合成物理上合理的多样示例以从有限的真实世界视频数据中学习有效世界模型的框架。它构建了一个在MPM模拟器中的物理一致的数字孪生，并通过部分感知的扰动生成多样化的运动模式，从而训练出轻量级的GNN世界模型。这种方法能实现对各种可变形物体进行准确且快速的未来预测，并且在新交互中也表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在有限的真实视频数据下学习物理一致性动态模型（尤其是具有空间变量物理属性的可变形物体）是一个挑战。为了解决这个问题，研究提出了一个新框架PhysWorld来合成多样化的物理上合理数据，以训练效率高的世界模型。

Method: 首先，在MPM模拟器中通过构成模型选择和物理属性的全局到局部优化构建物理一致的数字孪生。随后，对数字孪生应用部分感知扰动，生成多样化的运动模式，进行物理属性的合成。最后，使用这些演示来训练一个嵌有物理属性的轻量级GNN世界模型，以增强其性能和应用场景的广泛性。同时，真实视频可以用来进一步完善物理属性。

Result: PhysWorld 实现了对各种可变形物体的准确且快速的未来预测，并且在新交互中也表现出良好的泛化能力。实验表明，与最新方法PhysTwin相比，它不仅性能具备竞争力，其推理速度还快47倍。

Conclusion: 通过使用模拟器合成物理上合理且多样化的数据，PhysWorld 成功克服了在有限真实数据下学习有效世界模型的挑战，它不仅准确度高、速度快，同时在新场景中泛化性好，提供了一种更有效的学习解决方案。

Abstract: Interactive world models that simulate object dynamics are crucial for
robotics, VR, and AR. However, it remains a significant challenge to learn
physics-consistent dynamics models from limited real-world video data,
especially for deformable objects with spatially-varying physical properties.
To overcome the challenge of data scarcity, we propose PhysWorld, a novel
framework that utilizes a simulator to synthesize physically plausible and
diverse demonstrations to learn efficient world models. Specifically, we first
construct a physics-consistent digital twin within MPM simulator via
constitutive model selection and global-to-local optimization of physical
properties. Subsequently, we apply part-aware perturbations to the physical
properties and generate various motion patterns for the digital twin,
synthesizing extensive and diverse demonstrations. Finally, using these
demonstrations, we train a lightweight GNN-based world model that is embedded
with physical properties. The real video can be used to further refine the
physical properties. PhysWorld achieves accurate and fast future predictions
for various deformable objects, and also generalizes well to novel
interactions. Experiments show that PhysWorld has competitive performance while
enabling inference speeds 47 times faster than the recent state-of-the-art
method, i.e., PhysTwin.

</details>


### [38] [VidSplice: Towards Coherent Video Inpainting via Explicit Spaced Frame Guidance](https://arxiv.org/abs/2510.21461)
*Ming Xie,Junqiu Yu,Qiaole Dong,Xiangyang Xue,Yanwei Fu*

Main category: cs.CV

TL;DR: 我们提出了VidSplice，一个新型视频修复框架，通过引入间隔帧先验和设计CoSpliced模块，提升了视频修复的时空一致性，同时增强了内容的时空连续性。VidSplice在各种视频修复场景中表现优异，并且在前景对齐和运动稳定性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频修复方法使用图象到视频的先验，关注时空一致性，但在严重内容降解时表现不佳。我们旨在通过更好的时空控制来改善这种状态。为此，我们将视频修复任务分为两个子任务：多帧一致图像修复和掩码区域运动传播，以此来提高视频修复的质量。

Method: 我们提出了VidSplice，它利用间隔帧先验和CoSpliced模块进行修复过程，通过扩散机制从第一帧扩散内容到后续参考帧，同时通过精细的上下文控制模块来编码一致的先验并有效约束生成过程中的内容变形。

Result: 实验结果表明，VidSplice在各种视频修复任务中表现出色，特别是在前景对齐和运动稳定性方面超过了现有方法。

Conclusion: 本文提出了一种新颖的视频修复框架VidSplice，通过引入间距帧先验和CoSpliced模块，提高了视频修复任务的时空稳定性和内在线性，从而在生成高质量的修复视频方面取得了显著进展。

Abstract: Recent video inpainting methods often employ image-to-video (I2V) priors to
model temporal consistency across masked frames. While effective in moderate
cases, these methods struggle under severe content degradation and tend to
overlook spatiotemporal stability, resulting in insufficient control over the
latter parts of the video. To address these limitations, we decouple video
inpainting into two sub-tasks: multi-frame consistent image inpainting and
masked area motion propagation. We propose VidSplice, a novel framework that
introduces spaced-frame priors to guide the inpainting process with
spatiotemporal cues. To enhance spatial coherence, we design a CoSpliced Module
to perform first-frame propagation strategy that diffuses the initial frame
content into subsequent reference frames through a splicing mechanism.
Additionally, we introduce a delicate context controller module that encodes
coherent priors after frame duplication and injects the spliced video into the
I2V generative backbone, effectively constraining content distortion during
generation. Extensive evaluations demonstrate that VidSplice achieves
competitive performance across diverse video inpainting scenarios. Moreover,
its design significantly improves both foreground alignment and motion
stability, outperforming existing approaches.

</details>


### [39] [CXR-LanIC: Language-Grounded Interpretable Classifier for Chest X-Ray Diagnosis](https://arxiv.org/abs/2510.21464)
*Yiming Tang,Wenjia Zhong,Rushi Shah,Dianbo Liu*

Main category: cs.CV

TL;DR: CXR-LanIC 是一种新颖的框架，旨在通过任务对齐的模式发现来解决胸部X射线诊断中深度学习模型的解释性问题。该框架通过训练转码器稀疏自编码器，将医学图像表示分解为可解释的视觉模式，并能够提供透明且可验证的激活图库，从而提高临床部署的安全性。CXR-LanIC 在五个关键发现上实现了具有竞争力的诊断准确性，并通过计划进行的大规模多模态模型注释为自然语言解释奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在胸部X射线诊断中取得了显著的准确性，然而，由于预测的黑盒性质，这些模型在临床中的广泛应用仍然受限。临床医生需要透明、可验证的解释来信任自动化诊断并识别潜在的失败模式。

Method: CXR-LanIC 通过训练基于转码器的稀疏自编码器来解决这一可解释性挑战，这些编码器在任务对齐模式上训练，并在 BiomedCLIP 诊断分类器上训练。通过在 MIMIC-CXR 数据集的多模态嵌入上训练100个转码器，我们发现了大约5,000个单语义模式，这些模式涵盖心脏、肺、胸膜、结构、设备和错误类别。每个模式在具有特定放射学特征的图像中显示一致的激活行为。

Result: CXR-LanIC 达到了具有竞争力的诊断准确性，并能够提供自然语言解释的基础。提取的可解释特征来自于针对特定诊断目标训练的分类器，而不是通用的嵌入，这确保了发现的模式与临床决策直接相关，证明了医疗AI系统可以同时准确且可解释。

Conclusion: CXR-LanIC 展示了深度学习模型可以同时达到出色的准确性和解释性，这对更安全的临床部署至关重要。该方法强调了通过自然语言解释来支持医疗AI系统在临床中的应用。

Abstract: Deep learning models have achieved remarkable accuracy in chest X-ray
diagnosis, yet their widespread clinical adoption remains limited by the
black-box nature of their predictions. Clinicians require transparent,
verifiable explanations to trust automated diagnoses and identify potential
failure modes. We introduce CXR-LanIC (Language-Grounded Interpretable
Classifier for Chest X-rays), a novel framework that addresses this
interpretability challenge through task-aligned pattern discovery. Our approach
trains transcoder-based sparse autoencoders on a BiomedCLIP diagnostic
classifier to decompose medical image representations into interpretable visual
patterns. By training an ensemble of 100 transcoders on multimodal embeddings
from the MIMIC-CXR dataset, we discover approximately 5,000 monosemantic
patterns spanning cardiac, pulmonary, pleural, structural, device, and artifact
categories. Each pattern exhibits consistent activation behavior across images
sharing specific radiological features, enabling transparent attribution where
predictions decompose into 20-50 interpretable patterns with verifiable
activation galleries. CXR-LanIC achieves competitive diagnostic accuracy on
five key findings while providing the foundation for natural language
explanations through planned large multimodal model annotation. Our key
innovation lies in extracting interpretable features from a classifier trained
on specific diagnostic objectives rather than general-purpose embeddings,
ensuring discovered patterns are directly relevant to clinical decision-making,
demonstrating that medical AI systems can be both accurate and interpretable,
supporting safer clinical deployment through transparent, clinically grounded
explanations.

</details>


### [40] [ITC-RWKV: Interactive Tissue-Cell Modeling with Recurrent Key-Value Aggregation for Histopathological Subtyping](https://arxiv.org/abs/2510.21479)
*Yating Huang,Qijun Yang,Lintao Xiang,Hujun Yin*

Main category: cs.CV

TL;DR: 我们提出了一种双流架构，结合了宏观尺度组织特征和细胞水平表示。通过一种新颖的聚合模型和双向组织-细胞互动模块，实现了高效的细胞间依赖性和组织-细胞相互作用建模，从而在癌症亚型分类任务上超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有病理学的基础模型虽然能有效捕捉全局组织环境，但缺乏对细胞级别特征的建模，限制了它们在精细任务（如癌症亚型分类）中的准确性。

Method: 该方法包括：(1) 一种双流架构，融合宏观组织特征与细胞表示；(2) 一种基于受容度加权的关键值聚合模型，能以线性复杂度捕获细胞间的相互依赖；(3) 一个双向组织-细胞互动模块，实现局部细胞线索和周围组织环境间的相互注意。

Result: 实验结果表明，所提出的方法在四个不同癌症亚型分类的基准上表现优越。

Conclusion: 结果强调了细粒度计算病理学中表达级别的聚合和组织-细胞相互作用的关键作用。

Abstract: Accurate interpretation of histopathological images demands integration of
information across spatial and semantic scales, from nuclear morphology and
cellular textures to global tissue organization and disease-specific patterns.
Although recent foundation models in pathology have shown strong capabilities
in capturing global tissue context, their omission of cell-level feature
modeling remains a key limitation for fine-grained tasks such as cancer subtype
classification. To address this, we propose a dual-stream architecture that
models the interplay between macroscale tissue features and aggregated cellular
representations. To efficiently aggregate information from large cell sets, we
propose a receptance-weighted key-value aggregation model, a recurrent
transformer that captures inter-cell dependencies with linear complexity.
Furthermore, we introduce a bidirectional tissue-cell interaction module to
enable mutual attention between localized cellular cues and their surrounding
tissue environment. Experiments on four histopathological subtype
classification benchmarks show that the proposed method outperforms existing
models, demonstrating the critical role of cell-level aggregation and
tissue-cell interaction in fine-grained computational pathology.

</details>


### [41] [GRAP-MOT: Unsupervised Graph-based Position Weighted Person Multi-camera Multi-object Tracking in a Highly Congested Space](https://arxiv.org/abs/2510.21482)
*Marek Socha,Michał Marczyk,Aleksander Kempski,Michał Cogiel,Paweł Foszner,Radosław Zawiski,Michał Staniszewski*

Main category: cs.CV

TL;DR: GRAP-MOT是一种新的方法，用于解决封闭区域多摄像机视角下的人体多目标跟踪问题。该方法采用图形加权解决方案，更新每个人的标识标签，结合轨迹和特征来优化识别结果。GRAP-MOT还配备了位置估计模块，提供更精确的位置信息，以提高认别效果。我们在封闭空间的模拟记录和公开数据集上测试了该方法，并建议使用IDF1作为衡量多目标跟踪算法的指标。我们的代码和数据集对公众开放。


<details>
  <summary>Details</summary>
Motivation: 针对多摄像机重叠视场下封闭空间中的频繁遮挡，传统的多目标跟踪方法可能效果不佳。为解决这一问题，本研究旨在提出一种更适合有多摄像机遮挡情况下的多目标跟踪方法，以提高在高峰期封闭空间中的跟踪精度和实用性。因此，GRAP-MOT被设计用于提供更精确的多目标跟踪结果，并且考虑到了人体的位置信息。

Method: GRAP-MOT采用图形加权方案，该方案基于人体特征的跟踪和识别。此外，还引入了位置估计模块以提供更精确的位置信息，改进多目标跟踪问题的解决方法。在选择特征提取、跟踪以及社区搜索等MOT过程中的各个元素时，深究了这些元素，以寻找最佳解决方案。最后，本研究还分析了IDF1相较于MOTA更适用于评价MOT算法的原因。

Result: 通过封闭空间模型以及公共的高密度环境数据集的实际测试结果表明，GRAP-MOT在解决多摄像机重叠视场下的多目标跟踪问题方面具有优势。同时，本研究还推荐了IDF1作为多目标跟踪算法的评价指标，因为该指标能更好地反映MOT算法的性能。

Conclusion: GRAP-MOT提供了一种具有较强鲁棒性的多目标跟踪方法，尤其适合处理封闭区域有重叠摄像机的视频情形。本研究展示了该方法的有效性，并公开了相关数据集和代码，以促进相关研究的发展。此外，本论文建议使用IDF1指标来评价多目标跟踪算法。

Abstract: GRAP-MOT is a new approach for solving the person MOT problem dedicated to
videos of closed areas with overlapping multi-camera views, where person
occlusion frequently occurs. Our novel graph-weighted solution updates a
person's identification label online based on tracks and the person's
characteristic features. To find the best solution, we deeply investigated all
elements of the MOT process, including feature extraction, tracking, and
community search. Furthermore, GRAP-MOT is equipped with a person's position
estimation module, which gives additional key information to the MOT method,
ensuring better results than methods without position data. We tested GRAP-MOT
on recordings acquired in a closed-area model and on publicly available real
datasets that fulfil the requirement of a highly congested space, showing the
superiority of our proposition. Finally, we analyzed existing metrics used to
compare MOT algorithms and concluded that IDF1 is more adequate than MOTA in
such comparisons. We made our code, along with the acquired dataset, publicly
available.

</details>


### [42] [An Automatic Detection Method for Hematoma Features in Placental Abruption Ultrasound Images Based on Few-Shot Learning](https://arxiv.org/abs/2510.21495)
*Xiaoqing Liu,Jitai Han,Hua Yan,Peng Li,Sida Tang,Ying Li,Kaiwen Zhang,Min Yu*

Main category: cs.CV

TL;DR: 提出了基于小样本学习的改进模型EH-YOLOv11n，用于自动检测胎盘超声图像中的血肿特征，提高了检测准确度和抗干扰能力，临床应用价值高。


<details>
  <summary>Details</summary>
Motivation: 传统超声诊断依赖医生经验，存在主观偏见和诊断不一致性的问题，提出EH-YOLOv11n模型以提高胎盘早剥的早期准确诊断率，保障母婴安全。

Method: 通过多维度优化，引入小波卷积和坐标卷积增强频率和空间特征提取，采用级联分组注意力机制抑制超声伪影和遮挡干扰，从而提高边界框定位精度。基于YOLOv11n改进。

Result: 模型的检测准确率为78%，比YOLOv11n提高了2.5%，比YOLOv8提高了13.7%，在精度-召回曲线、置信评分和遮挡场景下表现突出，同时具备高准确性和实时处理能力。

Conclusion: EH-YOLOv11n模型为胎盘早剥的计算机辅助诊断提供了可靠方案，具有显著的临床应用价值。

Abstract: Placental abruption is a severe complication during pregnancy, and its early
accurate diagnosis is crucial for ensuring maternal and fetal safety.
Traditional ultrasound diagnostic methods heavily rely on physician experience,
leading to issues such as subjective bias and diagnostic inconsistencies. This
paper proposes an improved model, EH-YOLOv11n (Enhanced Hemorrhage-YOLOv11n),
based on small-sample learning, aiming to achieve automatic detection of
hematoma features in placental ultrasound images. The model enhances
performance through multidimensional optimization: it integrates wavelet
convolution and coordinate convolution to strengthen frequency and spatial
feature extraction; incorporates a cascaded group attention mechanism to
suppress ultrasound artifacts and occlusion interference, thereby improving
bounding box localization accuracy. Experimental results demonstrate a
detection accuracy of 78%, representing a 2.5% improvement over YOLOv11n and a
13.7% increase over YOLOv8. The model exhibits significant superiority in
precision-recall curves, confidence scores, and occlusion scenarios. Combining
high accuracy with real-time processing, this model provides a reliable
solution for computer-aided diagnosis of placental abruption, holding
significant clinical application value.

</details>


### [43] [GranViT: A Fine-Grained Vision Model With Autoregressive Perception For MLLMs](https://arxiv.org/abs/2510.21501)
*Guanghao Zheng,Bowen Shi,Mingxing Xu,Ruoyu Sun,Peisen Zhao,Zhibo Zhang,Wenrui Dai,Junni Zou,Hongkai Xiong,Xiaopeng Zhang,Qi Tian*

Main category: cs.CV

TL;DR: 我们提出了GranViT，这是一种新型的Vision Transformer，它整合了细粒度特征提取与语义对齐，通过区域级别的自回归训练方法，突破了传统视觉编码器在细粒度感知上的局限性。同时，我们构建了大规模细粒度预训练数据集Gran-29M，并开发了一种新的训练方式，包括预训练-适应框架和自我蒸馏机制，显著提升了细粒度表示的精确性和语言模型与视觉特征的利用效率，取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉编码器存在全局图像表征能力强但忽略了细粒度特征细节的问题，缺乏大规模细粒度注释数据和预训练范式。为了解决这个问题，我们提供了一种新的解决方案，通过引入细粒度特征提取和区域级别自回归训练的视觉编码器。并且构建了一系列大规模数据集来支持这项研究。

Method: 我们将细粒度特征提取和语义对齐与区域级自回归预训练相结合，将细粒度视觉知识转移到语言模型中，提高语言模型在视觉问答和推理中的表现。另外，我们开发了细粒度的预训练及适应框架，引入自我蒸馏机制以强化视觉编码器的区域推理能力。

Result: 实验结果显示，我们的GranViT框架在细粒度识别、多模态VQA和OCR句子理解等任务上都达到了最先进的性能。对比现有视觉编码器，GranViT展示了其优秀的转移性。

Conclusion: 我们提出的GranViT架构在细粒度视觉分析与语义对齐中提供了强大的能力。同时，通过尖端的自我蒸馏和预训练适应框架来设计语言模型，我们实现了突破性的方法来深入语言模型与视觉感知的结合。

Abstract: Vision encoders are indispensable for allowing impressive performance of
Multi-modal Large Language Models (MLLMs) in vision language tasks such as
visual question answering and reasoning. However, existing vision encoders
focus on global image representations but overlook fine-grained regional
analysis. They are limited in fine grained perception due to the scarcity of
fine grained annotated data and the lack of a fine grained pre-training
paradigm. In this paper, we propose GranViT, a novel Vision Transformer that
integrates fine-grained feature extraction with semantic alignment to Large
Language Models (LLMs) via region level autoregressive training. We first
construct Gran-29M, a dataset comprising 2million natural and OCR images paired
with over 180 million high-quality region-level annotations, to enable large
scale fine grained pretraining. Consequently, we develop a
pretraining-adaptation framework along with a self distillation mechanism to
train fine-grained GranViT on Gran-29M. We sufficiently exploit the
fine-grained annotations from Gran-29M to resort to bounding-box-to-caption
regression to enhance localized visual representation of the vision encoder in
the pretraining and caption-to-bounding-box regression to improve vision
feature utilization and localization for LLM in the adaptation. We further
incorporate a self distillation mechanism that imposes explicit localization
constraints on the vision encoder to strengthen its regional reasoning
capability. Extensive experiments show that GranViT surpasses existing vision
encoders and attains strong transferability to varying LLMs. Remarkably, it
achieves state-of-the-art results on fine-grained recognition, multimodal VQA,
and OCR understanding.

</details>


### [44] [Towards a Golden Classifier-Free Guidance Path via Foresight Fixed Point Iterations](https://arxiv.org/abs/2510.21512)
*Kaibo Wang,Jianda Mao,Tong Wu,Yang Xiang*

Main category: cs.CV

TL;DR: 我们提出了Foresight Guidance (FSG)，这是一种新的条件指导方法，它在扩散过程的早期阶段更早地解决更长间隔的子问题，从而提高生成图像的质量和计算效率。实验表明FSG优于现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在理论上对条件引导的理解不一致，导致设计选择受限。因此，我们需要一种统一的视角来改进条件引导机制，从而提高文本到图像生成模型的效果和效率。

Method: 通过提出将条件引导视为固定点迭代的概念，我们确定了一条黄金路径，即在条件和无条件生成下，潜变量产生一致的输出。基于此理论，提出了Foresight Guidance (FSG)，这种方法在早期阶段解决更长间隔的子问题，增加迭代次数。

Result: 实验表明FSG在图像质量和计算效率上都优于现有最佳方法。这说明了新方法的有效性。

Conclusion: 这项工作为条件引导提供了新的视角，并且揭示了适应性设计的潜力，有助于改进文本到图像的扩散模型。

Abstract: Classifier-Free Guidance (CFG) is an essential component of text-to-image
diffusion models, and understanding and advancing its operational mechanisms
remains a central focus of research. Existing approaches stem from divergent
theoretical interpretations, thereby limiting the design space and obscuring
key design choices. To address this, we propose a unified perspective that
reframes conditional guidance as fixed point iterations, seeking to identify a
golden path where latents produce consistent outputs under both conditional and
unconditional generation. We demonstrate that CFG and its variants constitute a
special case of single-step short-interval iteration, which is theoretically
proven to exhibit inefficiency. To this end, we introduce Foresight Guidance
(FSG), which prioritizes solving longer-interval subproblems in early diffusion
stages with increased iterations. Extensive experiments across diverse datasets
and model architectures validate the superiority of FSG over state-of-the-art
methods in both image quality and computational efficiency. Our work offers
novel perspectives for conditional guidance and unlocks the potential of
adaptive design.

</details>


### [45] [Head Pursuit: Probing Attention Specialization in Multimodal Transformers](https://arxiv.org/abs/2510.21518)
*Lorenzo Basile,Valentino Maiorca,Diego Doimo,Francesco Locatello,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 本文研究了文本生成模型中注意力头的特殊化模式，并通过信号处理的角度重新审视了中间激活与最终解码层的关系，发现在语言和视觉-语言任务中，编辑少数注意力头可以有效控制模型输出中特定概念的出现。


<details>
  <summary>Details</summary>
Motivation: 探索文本生成模型中注意力头的特定化模式，以理解其内部机制并提供控制方法。

Method: 通过信号处理的方式重新解释注意模型中中间激活与最终解码层的关系，建立了一种新的分析方法，可以用于评估不同注意力头的相关性。

Result: 发现少量注意力头（约1%）就能显著改变模型输出中特定概念的表现，验证了方法的有效性。

Conclusion: 展示了注意力层内可解释且可控的结构，提供了研究和编辑大规模生成模型的新工具。

Abstract: Language and vision-language models have shown impressive performance across
a wide range of tasks, but their internal mechanisms remain only partly
understood. In this work, we study how individual attention heads in
text-generative models specialize in specific semantic or visual attributes.
Building on an established interpretability method, we reinterpret the practice
of probing intermediate activations with the final decoding layer through the
lens of signal processing. This lets us analyze multiple samples in a
principled way and rank attention heads based on their relevance to target
concepts. Our results show consistent patterns of specialization at the head
level across both unimodal and multimodal transformers. Remarkably, we find
that editing as few as 1% of the heads, selected using our method, can reliably
suppress or enhance targeted concepts in the model output. We validate our
approach on language tasks such as question answering and toxicity mitigation,
as well as vision-language tasks including image classification and captioning.
Our findings highlight an interpretable and controllable structure within
attention layers, offering simple tools for understanding and editing
large-scale generative models.

</details>


### [46] [Sample By Step, Optimize By Chunk: Chunk-Level GRPO For Text-to-Image Generation](https://arxiv.org/abs/2510.21583)
*Yifu Luo,Penghui Du,Bo Li,Sinan Du,Tiantian Zhang,Yongzhe Chang,Kai Wu,Kun Gai,Xueqian Wang*

Main category: cs.CV

TL;DR: 本文提出了一个名为Chunk-GRPO的新方法，它将优化范式从步级别的GRPO（Group Relative Policy Optimization）调整为块级别的优化，提高了基于流匹配的文本到图像生成的准确性和效率。实验显示ChunkGRPO在偏好对齐和图像质量方面都优于原有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的GRPO方法存在优势归因不准确和忽略生成过程中的动态性这两个主要问题。为了改善这些问题，作者提出了一种新的优化策略，即从步级别的优化转变为块级别的优化。

Method: Chunk-GRPO将连续的步骤组合成一个'块'，以捕捉流匹配中的固有动态性。此外，它还引入了一个可选的加权采样策略来提高性能。

Result: 实验结果证明，ChunkGRPO在偏好对齐和图像质量上都取得了优越的结果。这证明了块级别优化对于基于GRPO的方法的可行性。

Conclusion: 本文的主要贡献是提出了Chunk-GRPO，这是一种新的基于块级别的GRPO方法，提高了流匹配在文本到图像生成中的效果。

Abstract: Group Relative Policy Optimization (GRPO) has shown strong potential for
flow-matching-based text-to-image (T2I) generation, but it faces two key
limitations: inaccurate advantage attribution, and the neglect of temporal
dynamics of generation. In this work, we argue that shifting the optimization
paradigm from the step level to the chunk level can effectively alleviate these
issues. Building on this idea, we propose Chunk-GRPO, the first chunk-level
GRPO-based approach for T2I generation. The insight is to group consecutive
steps into coherent 'chunk's that capture the intrinsic temporal dynamics of
flow matching, and to optimize policies at the chunk level. In addition, we
introduce an optional weighted sampling strategy to further enhance
performance. Extensive experiments show that ChunkGRPO achieves superior
results in both preference alignment and image quality, highlighting the
promise of chunk-level optimization for GRPO-based methods.

</details>


### [47] [MATrack: Efficient Multiscale Adaptive Tracker for Real-Time Nighttime UAV Operations](https://arxiv.org/abs/2510.21586)
*Xuzhao Li,Xuchen Li,Shiyu Hu*

Main category: cs.CV

TL;DR: 提出了一种名为MATrack的夜间无人机跟踪系统，它在低光条件下提高了跟踪性能。该系统通过三个核心模块协同工作：多尺度层次融合增强静态和动态模板之间的特征一致性，自适应关键令牌门准确识别复杂背景中的对象信息，夜间模板校准器确保长期序列的稳定跟踪性能。实验表明，MATrack在UAVDark135基准测试中的性能优于当前最佳方法，同时保持实时处理速度。


<details>
  <summary>Details</summary>
Motivation: 夜间无人机跟踪面临低光条件下的视觉感知限制、复杂的背景和频繁的视角变化引起的追踪漂移或失败等问题。现有解决方案如低光增强和领域适应存在视觉失真、计算成本高和未能充分利用物体动态信息等缺点。因此，提出MATrack来解决这些问题，目的是提供稳定的夜间无人机跟踪支持，特别是在关键的机器人应用中，如夜间搜救和边界巡逻。

Method: 该方法设计了一个包含三个核心模块的多尺度自适应系统：多尺度层次融合（MHB）、自适应回调门（AKTG）和夜间模板校准器（NTC）。它们分别处理特征一致性、背景中的物体识别和长期序列中的稳定性能。此方法直接解决了现有技术在夜间应用中的主要挑战，如低分辨率、前景和背景纹理的相似性以及快速频繁的目标模态变化。此外，MATrack兼顾了性能和实时性要求，适用于实际场景使用。

Result: 在UAVDark135基准测试下，MATrack的精度、标准化精度和AUC分别比现有的最先进方法提高了5.9%，5.4%和4.2%。同时，MATrack保持了每秒81帧的速度，证明了其在实际无人机平台上的稳定性和有效性。实验结果表明，MATrack能够显著提高夜间无人机跟踪的性能。另外，该系统还能成功应用到实际的夜间搜救和边界巡逻等关键机器人任务中，充分说明了其稳健性。

Conclusion: MATrack是一个特别设计用于夜间无人机跟踪的多尺度自适应系统，它通过对特征一致性、复杂背景中的物体识别和长时间序列中的稳定性能的优化，解决了现有夜间跟踪解决方案的关键限制。MATrack在UAVDark135基准上的测试结果展示了其相较于当前最先进的方法的性能提升，并且在实际无人机平台上的测试也验证了其可靠性和实用性。因此，MATrack对于夜间关键的机器人任务提供了有价值的解决方案。

Abstract: Nighttime UAV tracking faces significant challenges in real-world robotics
operations. Low-light conditions not only limit visual perception capabilities,
but cluttered backgrounds and frequent viewpoint changes also cause existing
trackers to drift or fail during deployment. To address these difficulties,
researchers have proposed solutions based on low-light enhancement and domain
adaptation. However, these methods still have notable shortcomings in actual
UAV systems: low-light enhancement often introduces visual artifacts, domain
adaptation methods are computationally expensive and existing lightweight
designs struggle to fully leverage dynamic object information. Based on an
in-depth analysis of these key issues, we propose MATrack-a multiscale adaptive
system designed specifically for nighttime UAV tracking. MATrack tackles the
main technical challenges of nighttime tracking through the collaborative work
of three core modules: Multiscale Hierarchy Blende (MHB) enhances feature
consistency between static and dynamic templates. Adaptive Key Token Gate
accurately identifies object information within complex backgrounds. Nighttime
Template Calibrator (NTC) ensures stable tracking performance over long
sequences. Extensive experiments show that MATrack achieves a significant
performance improvement. On the UAVDark135 benchmark, its precision, normalized
precision and AUC surpass state-of-the-art (SOTA) methods by 5.9%, 5.4% and
4.2% respectively, while maintaining a real-time processing speed of 81 FPS.
Further tests on a real-world UAV platform validate the system's reliability,
demonstrating that MATrack can provide stable and effective nighttime UAV
tracking support for critical robotics applications such as nighttime search
and rescue and border patrol.

</details>


### [48] [Restore Text First, Enhance Image Later: Two-Stage Scene Text Image Super-Resolution with Glyph Structure Guidance](https://arxiv.org/abs/2510.21590)
*Minxing Luo,Linlong Fan,Wang Qiushi,Ge Wu,Yiyan Luo,Yuhang Yu,Jinwei Chen,Yaxing Wang,Qingnan Fan,Jian Yang*

Main category: cs.CV

TL;DR: TIGER框架通过"文本优先，图像随后"的范式，在保证图像质量的同时提高了文本的可读性。它贡献了一个带有极端缩放的场景文本数据集UltraZoom-ST，并在实验中展示出领先业界的表现。


<details>
  <summary>Details</summary>
Motivation: 现有生成超分辨率方法在自然图像上表现良好，但在文本上会引入失真，导致图像质量和文本可读性之间的权衡。本文旨在解决这个问题，通过TIGER框架来分离文本重建与图像增强过程，以改进文本和图像质量。

Method: TIGER框架分为两个阶段：第一阶段重建精确的文本结构；第二阶段利用这些文本结构指导整幅图像的超分辨率重建。这种方法确保在文本精准恢复的同时保留整体图像质量。同时作者贡献了一个名为UltraZoom-ST的数据集，该数据集在极高的缩放比例下仍能保持准确的文本识别能力。

Result: 实验结果显示，TIGER框架在保证图像质量的同时，显著提升了文本可读性，超越了现有方法的表现。

Conclusion: TIGER提出的"文本优先，图像随后"的方法有效解决了文本和图像间的质量权衡问题，状态业内领先，具备广泛应用前景。

Abstract: Current generative super-resolution methods show strong performance on
natural images but distort text, creating a fundamental trade-off between image
quality and textual readability. To address this, we introduce \textbf{TIGER}
(\textbf{T}ext-\textbf{I}mage \textbf{G}uided
sup\textbf{E}r-\textbf{R}esolution), a novel two-stage framework that breaks
this trade-off through a \textit{"text-first, image-later"} paradigm.
\textbf{TIGER} explicitly decouples glyph restoration from image enhancement:
it first reconstructs precise text structures and then uses them to guide
subsequent full-image super-resolution. This glyph-to-image guidance ensures
both high fidelity and visual consistency. To support comprehensive training
and evaluation, we also contribute the \textbf{UltraZoom-ST} (UltraZoom-Scene
Text), the first scene text dataset with extreme zoom (\textbf{$\times$14.29}).
Extensive experiments show that \textbf{TIGER} achieves
\textbf{state-of-the-art} performance, enhancing readability while preserving
overall image quality.

</details>


### [49] [S3OD: Towards Generalizable Salient Object Detection with Synthetic Data](https://arxiv.org/abs/2510.21605)
*Orest Kupyn,Hirokatsu Kataoka,Christian Rupprecht*

Main category: cs.CV

TL;DR: 提出了一种通过大规模合成数据生成和基于模糊性意识的架构来显著改进泛化的方法，开发了S3OD数据集，包含超过139,000张高分辨率图像。训练合成数据的模型在跨数据集泛化上减少了20-50%的错误，并且在微调后在DIS和HR-SOD基准测试中达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 昂贵的像素精确注释推动了对关联子任务如DIS和HR-SOD进行单独的模型训练，本文提出一种通过大规模合成数据生成和模糊性感知架构来提高泛化的方法，以解决这一问题。通过构造包含超过139,000张高分辨率图像的S3OD数据集来改进模型性能。

Method: 首先通过多模态扩散管道生成包含139,000多张高分辨率图像的S3OD数据集，并通过迭代框架根据模型性能采样困难类别。然后提出一种多掩码解码器，能够预测多个有效解释来处理显著物体检测中的内在模糊性。

Result: 只在合成数据上训练的模型在跨数据集泛化中减少了20-50%的错误，而微调后的模型在DIS和HR-SOD基准测试中达到了最先进的性能。

Conclusion: 通过大规模合成数据和基于模糊性感知的架构，本文方法能够显著提高模型的泛化性能，并在相关领域达到最先进的水平。

Abstract: Salient object detection exemplifies data-bounded tasks where expensive
pixel-precise annotations force separate model training for related subtasks
like DIS and HR-SOD. We present a method that dramatically improves
generalization through large-scale synthetic data generation and
ambiguity-aware architecture. We introduce S3OD, a dataset of over 139,000
high-resolution images created through our multi-modal diffusion pipeline that
extracts labels from diffusion and DINO-v3 features. The iterative generation
framework prioritizes challenging categories based on model performance. We
propose a streamlined multi-mask decoder that naturally handles the inherent
ambiguity in salient object detection by predicting multiple valid
interpretations. Models trained solely on synthetic data achieve 20-50% error
reduction in cross-dataset generalization, while fine-tuned versions reach
state-of-the-art performance across DIS and HR-SOD benchmarks.

</details>


### [50] [Modest-Align: Data-Efficient Alignment for Vision-Language Models](https://arxiv.org/abs/2510.21606)
*Jiaxiang Liu,Yuan Wang,Jiawei Du,Joey Tianyi Zhou,Mingkun Xu,Zuozhu Liu*

Main category: cs.CV

TL;DR: 跨模态对齐旨在将不同的模态映射到共享的潜在空间中，但在资源有限或低质量数据的情况下，现有的预训练模型容易出现过自信和性能下降的问题。为了克服这些挑战，我们提出了Modest-Align，一种轻量级的对齐框架，通过随机扰动和嵌入平滑两种策略来减少过自信并提高了在嘈杂或弱相关样本上的性能。实验结果表明，Modest-Align在检索任务上超过了最先进的方法，并且使用更少的数据和GPU时间达到了同类表现。


<details>
  <summary>Details</summary>
Motivation: 现有模型在有限资源和低质量数据情况下存在过自信和性能下降的问题，同时对比学习方法依赖单一正对进一步加剧了这些挑战。

Method: 提出了一种新的轻量级对齐框架Modest-Align，该框架采用了随机扰动和嵌入平滑两种策略，以减少过自信，提高模型在嘈杂或弱相关样本上的表现。

Result: 实验表明Modest-Align在多种基准数据集上超过了现有的最佳方法，在检索任务上取得了更强的结果，并且所需的数据量和GPU时间大幅减少。

Conclusion: Modest-Align提供了一种实用且可扩展的解决方法，适用于低资源的实际跨模态对齐问题。

Abstract: Cross-modal alignment aims to map heterogeneous modalities into a shared
latent space, as exemplified by models like CLIP, which benefit from
large-scale image-text pretraining for strong recognition capabilities.
However, when operating in resource-constrained settings with limited or
low-quality data, these models often suffer from overconfidence and degraded
performance due to the prevalence of ambiguous or weakly correlated image-text
pairs. Current contrastive learning approaches, which rely on single positive
pairs, further exacerbate this issue by reinforcing overconfidence on uncertain
samples. To address these challenges, we propose Modest-Align, a lightweight
alignment framework designed for robustness and efficiency. Our approach
leverages two complementary strategies -- Random Perturbation, which introduces
controlled noise to simulate uncertainty, and Embedding Smoothing, which
calibrates similarity distributions in the embedding space. These mechanisms
collectively reduce overconfidence and improve performance on noisy or weakly
aligned samples. Extensive experiments across multiple benchmark datasets
demonstrate that Modest-Align outperforms state-of-the-art methods in retrieval
tasks, achieving competitive results with over 100x less training data and 600x
less GPU time than CLIP. Our method offers a practical and scalable solution
for cross-modal alignment in real-world, low-resource scenarios.

</details>


### [51] [Epipolar Geometry Improves Video Generation Models](https://arxiv.org/abs/2510.21615)
*Orest Kupyn,Fabian Manhardt,Federico Tombari,Christian Rupprecht*

Main category: cs.CV

TL;DR: 本文探索了通过引入单应几何约束来改进现代视频扩散模型的方法，以解决几何不一致、不稳定运动和视觉伪影等问题。通过偏好优化方式，该方法能够高效地执行几何原理而不必进行端到端的差异化。实验表明，这种方法能提供更为稳定的优化信号，优于现代学习度量，并且在多样化的动态视频内容上具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 这些视频生成模型尽管经过大规模训练，但在捕捉视觉内容的基本几何原理上仍然存在不足，进而导致几何不一致性和视觉伪影问题。为了解决这些问题，本文通过引入单应几何约束，来改进现代视频扩散模型。

Method: 我们通过偏好优化方式将扩散模型与配对单应几何约束对齐。这种方式能够在不进行端到端差异化的情况下高效地执行几何原理，直接解决不稳定的摄像机轨迹和几何伪影问题。

Result: 实验显示，经典几何约束提供了比现代学习度量更稳定的优化信号，这在噪声目标阻碍对齐质量的情况下尤其重要。

Conclusion: 通过将数据驱动的深度学习与经典的几何计算机视觉相结合，我们展示了如何生成空间一致的视频，同时不损害视觉质量。

Abstract: Video generation models have progressed tremendously through large latent
diffusion transformers trained with rectified flow techniques. Yet these models
still struggle with geometric inconsistencies, unstable motion, and visual
artifacts that break the illusion of realistic 3D scenes. 3D-consistent video
generation could significantly impact numerous downstream applications in
generation and reconstruction tasks. We explore how epipolar geometry
constraints improve modern video diffusion models. Despite massive training
data, these models fail to capture fundamental geometric principles underlying
visual content. We align diffusion models using pairwise epipolar geometry
constraints via preference-based optimization, directly addressing unstable
camera trajectories and geometric artifacts through mathematically principled
geometric enforcement. Our approach efficiently enforces geometric principles
without requiring end-to-end differentiability. Evaluation demonstrates that
classical geometric constraints provide more stable optimization signals than
modern learned metrics, which produce noisy targets that compromise alignment
quality. Training on static scenes with dynamic cameras ensures high-quality
measurements while the model generalizes effectively to diverse dynamic
content. By bridging data-driven deep learning with classical geometric
computer vision, we present a practical method for generating spatially
consistent videos without compromising visual quality.

</details>


### [52] [DAP-MAE: Domain-Adaptive Point Cloud Masked Autoencoder for Effective Cross-Domain Learning](https://arxiv.org/abs/2510.21635)
*Ziqi Gao,Qiufu Li,Linlin Shen*

Main category: cs.CV

TL;DR: 本文提出了一个名为Domain-Adaptive Point Cloud Masked Autoencoder (DAP-MAE)的方法，用于解决点云数据在多个领域中预训练时所遇到的知识不匹配问题，显著提高了点云分析任务的性能。在一次预训练中，DAP-MAE在四个不同类型的点云分析任务中取得了优异的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的针对点云数据的预训练方法通常难以解决跨域数据的知识不匹配问题，这可能导致点云分析任务表现不佳。

Method: 本文提出了一种名为DAP-MAE的方法，该方法设计了一个异构领域适配器，通过适应模式在预训练阶段学习来自不同领域的点云信息，并在微调阶段使用融合模式以增强点云特征。此外，DAP-MAE还包含了一个领域特征生成器，用于指导将点云特征适应到各种下游任务。

Result: DAP-MAE在一次预训练后，在四个类型的点云分析任务中获得了令人满意的成绩，例如在ScanObjectNN的数据集上达到了95.18%的对象分类准确度和在Bosphorus面部表情识别中的88.45%准确度。

Conclusion: 基于混合领域预训练点云模型往往表现不佳的问题，本文设计了DAP-MAE来改进模型的知识适应性，并提高了其在各种下游任务上的性能。

Abstract: Compared to 2D data, the scale of point cloud data in different domains
available for training, is quite limited. Researchers have been trying to
combine these data of different domains for masked autoencoder (MAE)
pre-training to leverage such a data scarcity issue. However, the prior
knowledge learned from mixed domains may not align well with the downstream 3D
point cloud analysis tasks, leading to degraded performance. To address such an
issue, we propose the Domain-Adaptive Point Cloud Masked Autoencoder (DAP-MAE),
an MAE pre-training method, to adaptively integrate the knowledge of
cross-domain datasets for general point cloud analysis. In DAP-MAE, we design a
heterogeneous domain adapter that utilizes an adaptation mode during
pre-training, enabling the model to comprehensively learn information from
point clouds across different domains, while employing a fusion mode in the
fine-tuning to enhance point cloud features. Meanwhile, DAP-MAE incorporates a
domain feature generator to guide the adaptation of point cloud features to
various downstream tasks. With only one pre-training, DAP-MAE achieves
excellent performance across four different point cloud analysis tasks,
reaching 95.18% in object classification on ScanObjectNN and 88.45% in facial
expression recognition on Bosphorus.

</details>


### [53] [A Dynamic Knowledge Distillation Method Based on the Gompertz Curve](https://arxiv.org/abs/2510.21649)
*Han Yang,Guangjun Qin*

Main category: cs.CV

TL;DR: 本文介绍了一种基于Gompertz成长模型的动态知识蒸馏框架Gompertz-CNN，该框架通过动态调整蒸馏损失权重解决传统方法在捕捉学生模型认知能力演变方面的不足。该框架整合了Wasserstein距离和梯度匹配技术来优化特征级别的差别和反向传播行为的对齐。实验表明，Gompertz-CNN在CIFAR-10和CIFAR-100数据集上比传统方法有显著的性能提升，分别实现了8%和4%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法在捕捉学生模型认知能力增长方面存在局限，使得知识转移效果不理想。为了解决这一问题，文章提出了新的动态知识蒸馏框架Gompertz-CNN，旨在更精确地反映学生模型的学习进展情况。

Method: 本文提出了一种基于Gompertz成长曲线的动态调整蒸馏损失权重策略，结合了Wasserstein距离来衡量特征级别的差异，以及梯度匹配技术来优化模型的反向传播行为，以此来优化知识蒸馏过程。

Result: 实验结果显示，相较于传统的知识蒸馏方法，Gompertz-CNN在CIFAR-10和CIFAR-100数据集上分别获得了8%和4%的准确率提升。

Conclusion: Gompertz-CNN通过采用Gompertz成长模型动态调整蒸馏损失权重，更好地反映了学生模型的学习过程，提升了知识蒸馏的效果。这种方法在实际应用中可以带来更好的性能甚至是更高的准确率。

Abstract: This paper introduces a novel dynamic knowledge distillation framework,
Gompertz-CNN, which integrates the Gompertz growth model into the training
process to address the limitations of traditional knowledge distillation.
Conventional methods often fail to capture the evolving cognitive capacity of
student models, leading to suboptimal knowledge transfer. To overcome this, we
propose a stage-aware distillation strategy that dynamically adjusts the weight
of distillation loss based on the Gompertz curve, reflecting the student's
learning progression: slow initial growth, rapid mid-phase improvement, and
late-stage saturation. Our framework incorporates Wasserstein distance to
measure feature-level discrepancies and gradient matching to align backward
propagation behaviors between teacher and student models. These components are
unified under a multi-loss objective, where the Gompertz curve modulates the
influence of distillation losses over time. Extensive experiments on CIFAR-10
and CIFAR-100 using various teacher-student architectures (e.g., ResNet50 and
MobileNet_v2) demonstrate that Gompertz-CNN consistently outperforms
traditional distillation methods, achieving up to 8% and 4% accuracy gains on
CIFAR-10 and CIFAR-100, respectively.

</details>


### [54] [Group Inertial Poser: Multi-Person Pose and Global Translation from Sparse Inertial Sensors and Ultra-Wideband Ranging](https://arxiv.org/abs/2510.21654)
*Ying Xue,Jiaxi Jiang,Rayan Armani,Dominik Hollidt,Yi-Chi Liao,Christian Holz*

Main category: cs.CV

TL;DR: 本文提出了一种使用稀疏穿戴式惯性传感器和超宽带定位技术来估计人体姿态和全局位置的新方法，提高多人体运动捕捉的准确性。同时，发布了第一个为两人追踪设计的IMU+UWB数据集GIP-DB，并展示其优于前人方法。


<details>
  <summary>Details</summary>
Motivation: 视觉方法由于遮挡和环境干涉的限制，难以精确跟踪人体全身运动。单一惯性传感器跟踪又因缺乏直接空间参考导致精度下降，特别是在追踪多人时。因此，提出一种能精确估计多人.getBodyPose()'s output doesn't need to be parsed in this context, but I'll continue as per the instruction.位置的方法必不可少。

Method: 通过结合超宽带（UWB）测量到的距离和惯性测量单元（IMU）数据，提出了一种多人体姿态估计和全局位置追踪的新方法。该方法分为两步优化，首先估算传感器之间的绝对距离，然后使用这些距离信息进行全局轨迹追踪。研究团队还构建了首个专为两人追踪设计的IMU+UWB数据集GIP-DB。

Result: 实验表明，新方法在合成和真实世界数据上的准确性和鲁棒性均优于前人的最先进技术。

Conclusion: 这项工作展示了超宽带和惯性测量结合在野外多人体运动捕捉上的潜力。同时，通过GIP-DB数据集的建立，为相关研究提供了有价值的资源。

Abstract: Tracking human full-body motion using sparse wearable inertial measurement
units (IMUs) overcomes the limitations of occlusion and instrumentation of the
environment inherent in vision-based approaches. However, purely IMU-based
tracking compromises translation estimates and accurate relative positioning
between individuals, as inertial cues are inherently self-referential and
provide no direct spatial reference for others. In this paper, we present a
novel approach for robustly estimating body poses and global translation for
multiple individuals by leveraging the distances between sparse wearable
sensors - both on each individual and across multiple individuals. Our method
Group Inertial Poser estimates these absolute distances between pairs of
sensors from ultra-wideband ranging (UWB) and fuses them with inertial
observations as input into structured state-space models to integrate temporal
motion patterns for precise 3D pose estimation. Our novel two-step optimization
further leverages the estimated distances for accurately tracking people's
global trajectories through the world. We also introduce GIP-DB, the first
IMU+UWB dataset for two-person tracking, which comprises 200 minutes of motion
recordings from 14 participants. In our evaluation, Group Inertial Poser
outperforms previous state-of-the-art methods in accuracy and robustness across
synthetic and real-world data, showing the promise of IMU+UWB-based multi-human
motion capture in the wild. Code, models, dataset:
https://github.com/eth-siplab/GroupInertialPoser

</details>


### [55] [Long-tailed Species Recognition in the NACTI Wildlife Dataset](https://arxiv.org/abs/2510.21657)
*Zehua Liu,Tilo Burghardt*

Main category: cs.CV

TL;DR: 该研究通过修改PyTorch Wildlife模型，针对长尾分布问题进行了一系列识别方法的实验，并在北美相机陷阱图像数据集上获得了99.40%的Top-1准确率，相较基线有显著提高，展示了更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在北美相机陷阱图像(NACTI)数据集中，物种识别面临严重的长尾分布问题。长尾分布问题导致很多小型或少见物种难以被准确识别，而常见的大型物种被大量识别，导致识别模型性能受到影响。因此，研究提高长尾分布数据集物种识别准确性的方法具有重要意义。此研究旨在通过一系列长尾识别策略解决这一问题，达到提高识别准确率的目的。 

Method: 本研究基于PyTorch Wildlife模型进行改进，使用了多种长尾识别损失函数及敏感正则化策略进行实验，优化了模型的识别能力。此外，在评估不同数据集下的领域变化时，构造了减少偏差的测试集，展示了改进模型在遇到分布变化时的更好性能。

Result: 实验结果表明，该研究在NACTI测试集上取得了99.40%的Top-1准确率，这比使用标准交叉熵损失函数和Adam优化器的方法有显著提高（95.51%精度）。此外，该模型在构建的ENADetection数据集的减少偏差测试集上表现突出，取得了52.55%的准确率，优于使用WCE损失的方法（51.20%）显示了较好的泛化能力。

Conclusion: 研究中，针对长尾识别的问题，采用了多种解决方案进行实验，发现了一系列改进方法，这些方法改善了模型在长尾分布情况下识别物种的效果。然而，该研究还指出，长尾增强策略在遇到严重的域移位或‘尾部’类别中的灾难性崩溃时，表现仍有待进步。

Abstract: As most ''in the wild'' data collections of the natural world, the North
America Camera Trap Images (NACTI) dataset shows severe long-tailed class
imbalance, noting that the largest 'Head' class alone covers >50% of the 3.7M
images in the corpus. Building on the PyTorch Wildlife model, we present a
systematic study of Long-Tail Recognition methodologies for species recognition
on the NACTI dataset covering experiments on various LTR loss functions plus
LTR-sensitive regularisation. Our best configuration achieves 99.40% Top-1
accuracy on our NACTI test data split, substantially improving over a 95.51%
baseline using standard cross-entropy with Adam. This also improves on
previously reported top performance in MLWIC2 at 96.8% albeit using partly
unpublished (potentially different) partitioning, optimiser, and evaluation
protocols. To evaluate domain shifts (e.g. night-time captures, occlusion,
motion-blur) towards other datasets we construct a Reduced-Bias Test set from
the ENA-Detection dataset where our experimentally optimised long-tail enhanced
model achieves leading 52.55% accuracy (up from 51.20% with WCE loss),
demonstrating stronger generalisation capabilities under distribution shift. We
document the consistent improvements of LTR-enhancing scheduler choices in this
NACTI wildlife domain, particularly when in tandem with state-of-the-art LTR
losses. We finally discuss qualitative and quantitative shortcomings that LTR
methods cannot sufficiently address, including catastrophic breakdown for
'Tail' classes under severe domain shift. For maximum reproducibility we
publish all dataset splits, key code, and full network weights.

</details>


### [56] [Self-Supervised Learning of Synapse Types from EM Images](https://arxiv.org/abs/2510.21663)
*Aarav Shetty,Gary B Huang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于电子显微镜图像中突触外观相似性的无监督方法，以分离突触类型，这种方法不需要预先知道突触类型的数量即可自动分类。此方法应用于果蝇的数据上，取得了良好效果，并可能为选择代表性的地面真相提供一种原则性方法，从而覆盖整个突触结构的空间。


<details>
  <summary>Details</summary>
Motivation: 传统的突触分类方法是基于监督方式，需要提前提供各类突触的例子。这种新方法仅依赖于一个假设，即在同一个神经元的附近突触更相似，目的是在无监督情况下分离突触类型。同时，方法可以自动确定突触类型数量，无需预设，有可能提供选择覆盖突触结构空间的地面真理的方法。此研究可以更广泛地应用于生物学领域，如确定某些神经递质所属的突触类型、区分可调节强度的突触与固定强度的突触等。

Method: 该方法基于这样一个原理：同一神经元上的邻近突触更相似，而在不同细胞中随机选择的突触在结构上则可能差异较大。利用这个原理，研究者们在果蝇的数据集上应用这种方法来进行无监督的突触分类。这种方法的主要优点是不需要预先设定突触类型的数量。通过这种自组织的方式，它可以揭示出数据中存在的不同突触类型，同时，这种方法可能还能够提供一种选择跨越所有潜在突触结构的地面真理的原则性方法。

Result: 研究表明，通过这种方法可以在无监督的条件下成功地分离突触类型，且其效果良好。特别地，探测到的突触结构多样性显示了这种方法能够自动确定不同突触类型，并能够覆盖相当的突触结构空间。此外，这种方法还有可能提供一种选择地面真理的原则性方法，这将有助于更好地理解突触结构和功能的多样性及其生物学意义。

Conclusion: 应用基于邻居相似度的无监督学习方法能够有效地分离突触类型并无需预设突触类型数量，这可能对于生物学许多应用具有重要研究和应用价值。

Abstract: Separating synapses into different classes based on their appearance in EM
images has many applications in biology. Examples may include assigning a
neurotransmitter to a particular class, or separating synapses whose strength
can be modulated from those whose strength is fixed. Traditionally, this has
been done in a supervised manner, giving the classification algorithm examples
of the different classes. Here we instead separate synapses into classes based
only on the observation that nearby synapses in the same neuron are likely more
similar than synapses chosen randomly from different cells. We apply our
methodology to data from {\it Drosophila}. Our approach has the advantage that
the number of synapse types does not need to be known in advance. It may also
provide a principled way to select ground-truth that spans the range of synapse
structure.

</details>


### [57] [Foundation Models in Dermatopathology: Skin Tissue Classification](https://arxiv.org/abs/2510.21664)
*Riya Gupta,Yiwei Zong,Dennis H. Murphree*

Main category: cs.CV

TL;DR: 研究评估了两种基础模型UNI和Virchow2作为特征提取器在皮肤病理学WSI分类中的性能。结果显示，Virchow2在大多数情况下优于UNI，特别是用于生成Patch级别的特征。实验还探索了数据增强和图像归一化以增强模型的鲁棒性和泛化能力。研究强调了基础模型在自动化WSI分类中的应用潜力，并为未来构建更强的SLI表示学习铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 研究的目标是评估两种基础模型在皮肤病理学WSI分类中的性能，以便寻找更有效的方法来自动化WSI处理和分类。对比了两个模型的性能，并研究了提高模型鲁棒性和泛化能力的方法。

Method: 生成的WSI在Patch级别使用两种不同的特征提取器（UNI和Virchow2）进行特征提取。然后采用均值聚集策略将Patch级别的特征转化为Slide级别的特征，最后利用这些特征训练三个不同的机器学习分类器（逻辑回归，梯度增强树和随机森林）。评估的指标包括精确率，召回率，真正率，假正率和ROC下的面积（AUROC）。采用数据增强和图像归一化技术提高模型的稳健性和泛化能力。最终结果通过WandB.ai进行追踪和可视化，以提供可重复性和可解释性。

Result: 实验结果显示，使用Virchow2生成的Patch级别特征在相比之下优于UNI，尤其是在训练的几种分类器中的性能。尽管逻辑回归的准确率达到最高90%，但这与实验差异不具有统计学意义。数据增强和图像归一化技术也提高了模型的性能。均值聚集策略为Slide级别的特征提供了可靠的可视化表示。这些实验结果和指标已被WandB.ai追踪和可视化，并为后续研究提供了实证依据。

Conclusion: 研究表明，基础模型如Virchow2在WSI分类中有很好的表现，提供了一个有效且可扩展的方法进行皮肤病理学诊断。该研究还揭示了未来在基于WSI的表示学习方面的潜在方向。

Abstract: The rapid generation of whole-slide images (WSIs) in dermatopathology
necessitates automated methods for efficient processing and accurate
classification. This study evaluates the performance of two foundation models,
UNI and Virchow2, as feature extractors for classifying WSIs into three
diagnostic categories: melanocytic, basaloid, and squamous lesions. Patch-level
embeddings were aggregated into slide-level features using a mean-aggregation
strategy and subsequently used to train multiple machine learning classifiers,
including logistic regression, gradient-boosted trees, and random forest
models. Performance was assessed using precision, recall, true positive rate,
false positive rate, and the area under the receiver operating characteristic
curve (AUROC) on the test set. Results demonstrate that patch-level features
extracted using Virchow2 outperformed those extracted via UNI across most
slide-level classifiers, with logistic regression achieving the highest
accuracy (90%) for Virchow2, though the difference was not statistically
significant. The study also explored data augmentation techniques and image
normalization to enhance model robustness and generalizability. The
mean-aggregation approach provided reliable slide-level feature
representations. All experimental results and metrics were tracked and
visualized using WandB.ai, facilitating reproducibility and interpretability.
This research highlights the potential of foundation models for automated WSI
classification, providing a scalable and effective approach for
dermatopathological diagnosis while paving the way for future advancements in
slide-level representation learning.

</details>


### [58] [WorldGrow: Generating Infinite 3D World](https://arxiv.org/abs/2510.21682)
*Sikuang Li,Chen Yang,Jiemin Fang,Taoran Yi,Jia Lu,Jiazhong Cen,Lingxi Xie,Wei Shen,Qi Tian*

Main category: cs.CV

TL;DR: 我们提出了WorldGrow，一种用于无界3D场景合成的分层框架，它在几何和纹理保真度上表现出色，支持无限场景生成。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在生成无限扩展的3D世界时面临主要挑战，包括视图之间存在几何和外观的一致性问题，以及难以扩展3D隐式表示。因此，我们提出了一种新的框架来解决这些问题，特别是通过利用预训练3D模型中的强大生成先验。

Method: WorldGrow框架包含三个核心组件：训练高质量场景块的数据整理流程，基于3D块的上下文感知场景扩展机制，以及粗到细的生成策略，确保全球布局的合理性和局部几何/纹理保真度。

Result: 在大规模3D-FRONT数据集上，我们的方法在几何重建方面表现出非常出色的结果，并且能够生成具有照片逼真效果和结构一致性的无限场景。

Conclusion: 此次研究成功地展示了生成无限扩展的真实3D环境的潜力，并为未来的场景建模工作提供了基础。

Abstract: We tackle the challenge of generating the infinitely extendable 3D world --
large, continuous environments with coherent geometry and realistic appearance.
Existing methods face key challenges: 2D-lifting approaches suffer from
geometric and appearance inconsistencies across views, 3D implicit
representations are hard to scale up, and current 3D foundation models are
mostly object-centric, limiting their applicability to scene-level generation.
Our key insight is leveraging strong generation priors from pre-trained 3D
models for structured scene block generation. To this end, we propose
WorldGrow, a hierarchical framework for unbounded 3D scene synthesis. Our
method features three core components: (1) a data curation pipeline that
extracts high-quality scene blocks for training, making the 3D structured
latent representations suitable for scene generation; (2) a 3D block inpainting
mechanism that enables context-aware scene extension; and (3) a coarse-to-fine
generation strategy that ensures both global layout plausibility and local
geometric/textural fidelity. Evaluated on the large-scale 3D-FRONT dataset,
WorldGrow achieves SOTA performance in geometry reconstruction, while uniquely
supporting infinite scene generation with photorealistic and structurally
consistent outputs. These results highlight its capability for constructing
large-scale virtual environments and potential for building future world
models.

</details>


### [59] [BachVid: Training-Free Video Generation with Consistent Background and Character](https://arxiv.org/abs/2510.21696)
*Han Yan,Xibin Song,Yifu Wang,Hongdong Li,Pan Ji,Chao Ma*

Main category: cs.CV

TL;DR: BachVid 是一种无需参考图像和额外训练就能生成一致性的视频的方法。通过分析DiT的注意力机制和中间特征，发现它可以提取前景掩码并识别匹配点，该方法生成身份视频并缓存中间变量，然后将其注入新生成视频的相应位置，确保多视频的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有T2V生成方法在生成一致的多个视频时，依赖于参考图像或大量训练，且往往仅解决角色的一致性问题。需要一种新的方法来解决这个问题，只需要生成视频进行推断，而无需参考图像或额外训练。BachVid正是为解决这个问题而引入的方法，它确保了视频角色和背景的一致性。

Method: BachVid 方法通过首先生成一个身份视频，并在生成过程中缓存中间变量，然后在生成新视频时将这些中间变量注入到相应的位置，从而实现了视频一致性。具体来说，它依靠对DiT的注意力机制和中间特征的分析，找到其在去噪过程中提取前景掩码和匹配点的能力。通过这一机制，BachVid在生成多个视频时，保持了前景和背景的一致性。

Result: 实验结果显示，BachVid无需任何额外训练或参考图像即可生成高一致性的视频。与现有方法相比，BachVid呈现出更高的视频一致性。

Conclusion: BachVid为文本到视频生成任务提供了一个创新的解决方案，它不需要参考图像、额外训练就能生成保持角色和背景一致性的多个视频，展示了其在一致视频生成任务中的有效性和效率。

Abstract: Diffusion Transformers (DiTs) have recently driven significant progress in
text-to-video (T2V) generation. However, generating multiple videos with
consistent characters and backgrounds remains a significant challenge. Existing
methods typically rely on reference images or extensive training, and often
only address character consistency, leaving background consistency to
image-to-video models. We introduce BachVid, the first training-free method
that achieves consistent video generation without needing any reference images.
Our approach is based on a systematic analysis of DiT's attention mechanism and
intermediate features, revealing its ability to extract foreground masks and
identify matching points during the denoising process. Our method leverages
this finding by first generating an identity video and caching the intermediate
variables, and then inject these cached variables into corresponding positions
in newly generated videos, ensuring both foreground and background consistency
across multiple videos. Experimental results demonstrate that BachVid achieves
robust consistency in generated videos without requiring additional training,
offering a novel and efficient solution for consistent video generation without
relying on reference images or additional training.

</details>


### [60] [Visual Diffusion Models are Geometric Solvers](https://arxiv.org/abs/2510.21697)
*Nir Goren,Shai Yehezkel,Omer Dahary,Andrey Voynov,Or Patashnik,Daniel Cohen-Or*

Main category: cs.CV

TL;DR: 本文展示了视觉扩散模型可以直接在像素空间中解决几何问题，如内切正方形问题、Steiner树问题和简单多边形问题。通过将问题实例视为图像，模型学习将噪声几何结构转换为正确的配置，从而将几何推理转化为图像生成。这种方法提供了一种解决几何问题的新途径，并指出在图像空间中操作可以为解决各种复杂几何任务提供通用框架。


<details>
  <summary>Details</summary>
Motivation: 传统的几何问题解决方法通常需要专门的架构和领域的特定适应。本文探索了使用标准视觉扩散模型来直接在图像空间中解决几何问题的可能性，这种新的方法可以简化几何问题的解决过程，揭示生成模型与几何问题求解之间的一个令人惊讶的联系。

Method: 将几何问题实例视为图像，训练一个标准的视觉扩散模型，该模型可以将高斯噪声转换为表示近似解决方案的图像。模型学习将噪声几何结构转化为正确的配置，实际上是在像素空间进行几何推理。

Result: 所提出的方法在三个著名的几何问题上均显示出有效性：内切正方形问题，Steiner树问题和简单多边形问题。这种方法表明，在图像空间中操作可以为解决困难的几何任务提供一种通用且实际的框架。

Conclusion: 本文展示了视觉扩散模型在解决几何问题中的潜力，不仅应用于具体的案例，而且为处理更广泛的挑战性几何任务提供了新的视角。这种图像空间中的操作方式标志着一种新的问题求解范式的开始。

Abstract: In this paper we show that visual diffusion models can serve as effective
geometric solvers: they can directly reason about geometric problems by working
in pixel space. We first demonstrate this on the Inscribed Square Problem, a
long-standing problem in geometry that asks whether every Jordan curve contains
four points forming a square. We then extend the approach to two other
well-known hard geometric problems: the Steiner Tree Problem and the Simple
Polygon Problem.
  Our method treats each problem instance as an image and trains a standard
visual diffusion model that transforms Gaussian noise into an image
representing a valid approximate solution that closely matches the exact one.
The model learns to transform noisy geometric structures into correct
configurations, effectively recasting geometric reasoning as image generation.
  Unlike prior work that necessitates specialized architectures and
domain-specific adaptations when applying diffusion to parametric geometric
representations, we employ a standard visual diffusion model that operates on
the visual representation of the problem. This simplicity highlights a
surprising bridge between generative modeling and geometric problem solving.
Beyond the specific problems studied here, our results point toward a broader
paradigm: operating in image space provides a general and practical framework
for approximating notoriously hard problems, and opens the door to tackling a
far wider class of challenging geometric tasks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [61] [Incentivizing Consistent, Effective and Scalable Reasoning Capability in Audio LLMs via Reasoning Process Rewards](https://arxiv.org/abs/2510.20867)
*Jiajun Fan,Roger Ren,Jingyuan Li,Rahul Pandey,Prashanth Gurunath Shivakumar,Ivan Bulyko,Ankur Gandhe,Ge Liu,Yile Gu*

Main category: cs.LG

TL;DR: CESAR (Consistent, Effective, and Scalable Audio Reasoners) is introduced to address the issue of test-time inverse scaling in reasoning processes of Audio Large Language Models, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: The motivation is to solve the problem of test-time inverse scaling, where longer reasoning chains degrade performance in Audio Large Language Models, despite the fact that the issue arises from inadequate training rather than fundamental challenges with reasoning itself.

Method: CESAR employs an online reinforcement learning framework with Group Relative Policy Optimization and a reward suite that incentivizes correctness, format, consistency, structured analytical patterns, causal reasoning, domain-knowledge integration, and calibrated reasoning depth.

Result: CESAR resolves test-time inverse scaling, enhances reasoning quality, and improves multimodal reasoning and perception capabilities; achieving state-of-the-art results on MMAU Test-mini and near-human-level performance on MMSU reasoning tasks.

Conclusion: CESAR establishes a principled method for developing robust and scalable reasoning in Audio LLMs, demonstrating the potential for enhanced reasoning capabilities.

Abstract: The role of reasoning in Audio Large Language Models remains widely
underexplored, as introducing a reasoning process often degrades rather than
improves performance during inference, a phenomenon we term test-time inverse
scaling, where longer reasoning chains yield progressively worse results. We
demonstrate that this stems not from fundamental limitations of reasoning
itself, but from inadequate training: models without proper guidance for the
reasoning process produce hallucinatory, inconsistent reasoning that
accumulates errors over longer chains. To address these challenges, we
introduce CESAR (Consistent, Effective, and Scalable Audio Reasoners), shifting
from outcome verification to rewarding the reasoning process. Our online
reinforcement learning framework employs Group Relative Policy Optimization
with a multi-faceted reward suite that incentivizes not only correctness and
format but also consistency, structured analytical patterns, causal reasoning,
domain-knowledge integration, and calibrated reasoning depth. CESAR resolves
test-time inverse scaling, transforming reasoning from detriments into gains
while revealing model-specific ``reasoning sweet spots", where performance
peaks during test-time scaling. We achieve state-of-the-art results on MMAU
Test-mini, substantially outperforming Gemini 2.5 Pro and GPT-4o Audio, and
near-human-level performance on MMSU reasoning tasks. Through AI-as-judge
evaluations and qualitative comparisons, we provide both quantitative and
qualitative validation of our improved reasoning quality. Importantly, enhanced
reasoning creates synergistic effects, simultaneously improving multimodal
reasoning and perception capabilities. Overall, CESAR establishes a principled
method for developing robust and scalable reasoning in Audio LLMs.

</details>


### [62] [MOBO-OSD: Batch Multi-Objective Bayesian Optimization via Orthogonal Search Directions](https://arxiv.org/abs/2510.20872)
*Lam Ngo,Huong Ha,Jeffrey Chan,Hongyu Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为MOBO-OSD的多目标贝叶斯优化算法，通过解决多个沿正交搜索方向的子问题来生成一系列帕累托最优解，从而实现目标空间的广泛覆盖。同时采用了帕累托前沿估计技术来增加解的密集度，并支持批量优化以加速优化过程。该算法在多项实测中表现优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 尽管单目标优化问题已受到大量研究，多目标优化问题仍然极具挑战性。传统的多目标优化方法可能不能有效地多样性生成帕累托最优解，本研究旨在通过更高效的方式解决这一问题以提升解决方案的多样性和总体性能表现。

Method: 通过沿正交搜索方向（OSD）解决多个约束优化子问题，使用近似凸包的性质定义了多个正交搜索方向，并利用了帕累托前沿估计技术生成邻近区域的解，以增加解的密集度。整个过程能对资源进行有效利用，支持并行函数评估以加速优化过程。此方法实现了对目标空间的广泛覆盖，同时保证了解的多样性和高效性。

Result: 通过综合实验分析，展示了MOBO-OSD在不同维度的合成和真实世界基准函数上的一致性能优越性，测试结果表明此方法显著优于最新的算法。

Conclusion: 研究开发了一种新的多目标贝叶斯优化算法MOBO-OSD，这种算法通过对目标空间实施有效的搜索，能够产生多样性的帕累托最优解集，为处理多目标优化问题提供了一个先进的解决方案。

Abstract: Bayesian Optimization (BO) is a powerful tool for optimizing expensive
black-box objective functions. While extensive research has been conducted on
the single-objective optimization problem, the multi-objective optimization
problem remains challenging. In this paper, we propose MOBO-OSD, a
multi-objective Bayesian Optimization algorithm designed to generate a diverse
set of Pareto optimal solutions by solving multiple constrained optimization
problems, referred to as MOBO-OSD subproblems, along orthogonal search
directions (OSDs) defined with respect to an approximated convex hull of
individual objective minima. By employing a well-distributed set of OSDs,
MOBO-OSD ensures broad coverage of the objective space, enhancing both solution
diversity and hypervolume performance. To further improve the density of the
set of Pareto optimal candidate solutions without requiring an excessive number
of subproblems, we leverage a Pareto Front Estimation technique to generate
additional solutions in the neighborhood of existing solutions. Additionally,
MOBO-OSD supports batch optimization, enabling parallel function evaluations to
accelerate the optimization process when resources are available. Through
extensive experiments and analysis on a variety of synthetic and real-world
benchmark functions with two to six objectives, we demonstrate that MOBO-OSD
consistently outperforms the state-of-the-art algorithms. Our code
implementation can be found at https://github.com/LamNgo1/mobo-osd.

</details>


### [63] [Multimodal Negative Learning](https://arxiv.org/abs/2510.20877)
*Baoquan Gong,Xiyuan Gao,Pengfei Zhu,Qinghua Hu,Bing Cao*

Main category: cs.LG

TL;DR: 本文提出了一种新的学习范式："Learning Not to be"（负学习），旨在解决多模态学习系统中弱模态被强模态压制的问题，通过引入Multimodal Negative Learning (MNL)框架动态引导弱模态以抑制非目标类别来保护其独特信息。实验结果表明该方法在多种基准测试上优于现有方法，提高了模型的鲁棒性和降低了错误率，尤其是在噪声和不平衡场景下效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统的多模态学习方法容易因模态不平衡导致弱模态被强模态压制，导致弱模态的信息得不到充分学习。为了解决这一问题，本文提出了一种新的学习范式。


Method: 首先从鲁棒性角度重新审视了多模态学习，然后提出了Multimodal Negative Learning (MNL)框架，通过让强模态动态引导弱模态以抑制非目标类别来实现保护弱模态独特信息的目标。具体而言，本文提出的MNL方法引入了动态引导机制，通过增加单模态置信度边缘（UCoM）来提高模型的鲁棒性，减少弱模态在噪声和不平衡情况下的错误率。

Result: 本研究方法在多种基准测试中展示了强大的性能，尤其是在面对噪声和模态不平衡的场景时，能够有效提高模型的鲁棒性和减少错误率，证明了该方法的有效性和泛化能力。与此相比，其他方法的性能表现较差。


Conclusion: 本文提出了一种新的多模态学习范式，该范式解决了当前多模态学习方法在处理模态不平衡问题上的不足，通过引入Multimodal Negative Learning (MNL)框架，不仅保护了弱模态的独特信息，而且提高了模型在多场景下的鲁棒性和预测准确性。

Abstract: Multimodal learning systems often encounter challenges related to modality
imbalance, where a dominant modality may overshadow others, thereby hindering
the learning of weak modalities. Conventional approaches often force weak
modalities to align with dominant ones in "Learning to be (the same)" (Positive
Learning), which risks suppressing the unique information inherent in the weak
modalities. To address this challenge, we offer a new learning paradigm:
"Learning Not to be" (Negative Learning). Instead of enhancing weak modalities'
target-class predictions, the dominant modalities dynamically guide the weak
modality to suppress non-target classes. This stabilizes the decision space and
preserves modality-specific information, allowing weak modalities to preserve
unique information without being over-aligned. We proceed to reveal multimodal
learning from a robustness perspective and theoretically derive the Multimodal
Negative Learning (MNL) framework, which introduces a dynamic guidance
mechanism tailored for negative learning. Our method provably tightens the
robustness lower bound of multimodal learning by increasing the Unimodal
Confidence Margin (UCoM) and reduces the empirical error of weak modalities,
particularly under noisy and imbalanced scenarios. Extensive experiments across
multiple benchmarks demonstrate the effectiveness and generalizability of our
approach against competing methods. The code will be available at
https://github.com/BaoquanGong/Multimodal-Negative-Learning.git.

</details>


### [64] [HA-RAG: Hotness-Aware RAG Acceleration via Mixed Precision and Data Placement](https://arxiv.org/abs/2510.20878)
*Danying Ge,Jianhua Gao,Yixue Yang,Weixing Ji*

Main category: cs.LG

TL;DR: 一种称为热感知RAG（HA-RAG）的新系统被提出，用于解决检索增强生成模型中的长上下文处理问题，通过减少磁盘I/O和内存访问开销，提高数据访问效率，同时保持精度几乎不变。与TurboRAG相比，HA-RAG的TTFT时间提升了2.10倍（最多提升10.49倍）


<details>
  <summary>Details</summary>
Motivation: 解决检索增强生成模型（RAG）在使用外部知识库时遇到的长上下文处理挑战，提高数据访问效率，减少内存消耗和推断延迟

Method: 引入了热感知混合精度压缩和加载方法，以及一种热感知数据放置策略，优先将频繁访问的知识值嵌入高速内存，以提高数据访问效率

Result: HA-RAG系统在TTFT时间上平均比TurboRAG快2.10倍（最多快10.49倍），同时几乎保持了原始精度

Conclusion: 通过优化RAG模型中的知识库访问，新方法在提高推断速度和减少内存消耗方面取得了显著成效，适合于需要高效处理大量信息的应用场景

Abstract: Retrieval-Augmented Generation (RAG) improves model output accuracy by
leveraging external knowledge bases, serving as an effective solution to
address hallucination issues and knowledge-update delays in Large Language
Models (LLMs). However, the introduction of external knowledge bases presents
RAG with challenges in long-context processing, significantly increasing memory
consumption and inference latency. Existing research accelerates inference by
precomputing Key and Value (KV) of the knowledge base and loading them
on-demand during inference. Based on the access frequency of different KV
chunks within the external knowledge base, this paper proposes a hotness-aware
RAG (HA-RAG) inference optimization system. First, leveraging the numerical
distribution of KV chunks, we introduce a hotness-aware mixed-precision
compressing and loading method to reduce disk I/O and memory access overhead.
Second, we design a hotness-aware data placement strategy that prioritizes
storing frequently accessed KV chunks in high-speed memory to improve data
access efficiency. Experimental results demonstrate that, compared with
TurboRAG, the proposed HA-RAG achieves an average speedup of 2.10x and maximum
speedup of 10.49x in Time-To-First-Token (TTFT) with negligible accuracy loss.

</details>


### [65] [Global Dynamics of Heavy-Tailed SGDs in Nonconvex Loss Landscape: Characterization and Control](https://arxiv.org/abs/2510.20905)
*Xingyu Wang,Chang-Han Rhee*

Main category: cs.LG

TL;DR: 本文研究了随机梯度下降(SGD)及其变体在全球动态方面的理论理解，并发现通过在训练过程中注入并截断重尾噪声，SGD可以显著避免尖锐局部最小值，提高测试数据上的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有理论研究落后于SGD的广泛应用，特别是在避免尖锐局部最小值方面的能力，为了增强这种能力，需要超越传统的局部收敛分析，理解SGD的全局动态。

Method: 基于Wang和Rhee(2023)的大型偏差和亚稳态分析，开发了一套技术方法来刻画具有重尾特性的SGD的全局动态特性。

Result: 实验和深度学习测试表明，带有梯度截断的重尾SGD可以找到几何形态更平滑的局部最小值，这提高了测试数据上的泛化性能。

Conclusion: 通过在训练过程中注入并截断重尾噪声，SGD能够显著避免尖锐局部最小值，从而改善测试数据上的泛化性能。

Abstract: Stochastic gradient descent (SGD) and its variants enable modern artificial
intelligence. However, theoretical understanding lags far behind their
empirical success. It is widely believed that SGD has a curious ability to
avoid sharp local minima in the loss landscape, which are associated with poor
generalization. To unravel this mystery and further enhance such capability of
SGDs, it is imperative to go beyond the traditional local convergence analysis
and obtain a comprehensive understanding of SGDs' global dynamics. In this
paper, we develop a set of technical machinery based on the recent large
deviations and metastability analysis in Wang and Rhee (2023) and obtain sharp
characterization of the global dynamics of heavy-tailed SGDs. In particular, we
reveal a fascinating phenomenon in deep learning: by injecting and then
truncating heavy-tailed noises during the training phase, SGD can almost
completely avoid sharp minima and achieve better generalization performance for
the test data. Simulation and deep learning experiments confirm our theoretical
prediction that heavy-tailed SGD with gradient clipping finds local minima with
a more flat geometry and achieves better generalization performance.

</details>


### [66] [Learning from Interval Targets](https://arxiv.org/abs/2510.20925)
*Rattana Pukdee,Ziqi Ke,Chirag Gupta*

Main category: cs.LG

TL;DR: 本文研究了区间目标下的回归问题，并提出了新的损失函数和MinMax学习方法来解决仅有上下限信息的情况，通过平滑约束获得良好的性能，取得了最新的研究成果。


<details>
  <summary>Details</summary>
Motivation: 当精确的目标标签难以获得，可能由于内在的不确定性，导致传统回归损失函数无法使用时，势必要研究一种新的区间目标下的回归方法。

Method: 本文提出了一个新的损失函数，该损失函数适用于区间目标，并且基于假设类的平滑性建立了非渐近泛化界，放松了实现性和小歧义度的先前假设。此外，还提出了一种MinMax学习形式：最小化给定区间内最坏情况（最大化）的目标标签。尽管后者中的最大化问题是非凸的，但通过加入平滑约束，可以实现良好的性能。

Result: 通过对真实数据集进行广泛的实验证明，本文的方法能够取得先进水平的结果和性能。

Conclusion: 本文的研究不仅仅是理论上的进展，还通过在真实世界数据集上的实验验证了所提出方法的有效性和优越性，为处理区间目标下的回归问题提供了一个行之有效的解决方案。

Abstract: We study the problem of regression with interval targets, where only upper
and lower bounds on target values are available in the form of intervals. This
problem arises when the exact target label is expensive or impossible to
obtain, due to inherent uncertainties. In the absence of exact targets,
traditional regression loss functions cannot be used. First, we study the
methodology of using a loss functions compatible with interval targets, for
which we establish non-asymptotic generalization bounds based on smoothness of
the hypothesis class that significantly relaxing prior assumptions of
realizability and small ambiguity degree. Second, we propose a novel min-max
learning formulation: minimize against the worst-case (maximized) target labels
within the provided intervals. The maximization problem in the latter is
non-convex, but we show that good performance can be achieved with the
incorporation of smoothness constraints. Finally, we perform extensive
experiments on real-world datasets and show that our methods achieve
state-of-the-art performance.

</details>


### [67] [Cost Minimization for Space-Air-Ground Integrated Multi-Access Edge Computing Systems](https://arxiv.org/abs/2510.21541)
*Weihong Qin,Aimin Wang,Geng Sun,Zemin Sun,Jiacheng Wang,Dusit Niyato,Dong In Kim,Zhu Han*

Main category: cs.LG

TL;DR: 该论文提出了一种分层空间-空气-地面集成多接入边缘计算架构，并通过MADDPG-COCG算法解决了低空经济环境中异构节点协调、实时决策等问题，显著改善了用户体验，相比基准算法，用户设备成本、任务完成延迟和用户设备能量消耗等性能指标有明显提高，但UAV能耗有轻微增加。


<details>
  <summary>Details</summary>
Motivation: 为了在低空经济环境中充分发挥空间-空气-地面集成多接入边缘计算（SAGIN-MEC）的潜力，解决异构节点协调、复杂因素建模、实时决策等问题，提出了MADDPG-COCG算法。

Method: 该方法构建了空间-空气-地面集成多接入边缘计算架构，并设计了UD成本最小化优化问题，然后使用MADDPG算法优化连续时间决策，并使用凸优化和合作博弈技术增强算法，以处理混合和动态变化的决策变量。

Result: 仿真结果显示，相对基准算法，该算法在考虑了用户设备成本、任务完成延迟和用户体验等指标上，表现显著提升，尽管UAV的能量消耗有所增加，但仍具有很好的稳定性和可扩展性。

Conclusion: 该研究提出了MADDPG-COCG算法，有效解决了低空经济环境中的复杂决策问题，显示了该算法在提高用户整体体验方面的巨大潜力。

Abstract: Space-air-ground integrated multi-access edge computing (SAGIN-MEC) provides
a promising solution for the rapidly developing low-altitude economy (LAE) to
deliver flexible and wide-area computing services. However, fully realizing the
potential of SAGIN-MEC in the LAE presents significant challenges, including
coordinating decisions across heterogeneous nodes with different roles,
modeling complex factors such as mobility and network variability, and handling
real-time decision-making under partially observable environment with hybrid
variables. To address these challenges, we first present a hierarchical
SAGIN-MEC architecture that enables the coordination between user devices
(UDs), uncrewed aerial vehicles (UAVs), and satellites. Then, we formulate a UD
cost minimization optimization problem (UCMOP) to minimize the UD cost by
jointly optimizing the task offloading ratio, UAV trajectory planning,
computing resource allocation, and UD association. We show that the UCMOP is an
NP-hard problem. To overcome this challenge, we propose a multi-agent deep
deterministic policy gradient (MADDPG)-convex optimization and coalitional game
(MADDPG-COCG) algorithm. Specifically, we employ the MADDPG algorithm to
optimize the continuous temporal decisions for heterogeneous nodes in the
partially observable SAGIN-MEC system. Moreover, we propose a convex
optimization and coalitional game (COCG) method to enhance the conventional
MADDPG by deterministically handling the hybrid and varying-dimensional
decisions. Simulation results demonstrate that the proposed MADDPG-COCG
algorithm significantly enhances the user-centric performances in terms of the
aggregated UD cost, task completion delay, and UD energy consumption, with a
slight increase in UAV energy consumption, compared to the benchmark
algorithms. Moreover, the MADDPG-COCG algorithm shows superior convergence
stability and scalability.

</details>


### [68] [Meta-Learning for Cross-Task Generalization in Protein Mutation Property Prediction](https://arxiv.org/abs/2510.20943)
*Srivathsan Badrinarayanan,Yue Su,Janghoon Ock,Alan Pham,Sanya Ahuja,Amir Barati Farimani*

Main category: cs.LG

TL;DR: 蛋白质突变对生物功能有深远影响，作者提出了一种基于元学习（MAML）的方法来预测蛋白质突变的性质，并引入一种新的突变编码策略，提高了模型的跨任务泛化能力与训练效率，特别适用于数据量有限的情况下的蛋白质工程应用。


<details>
  <summary>Details</summary>
Motivation: 蛋白质突变对生物功能有深远影响，现有方法在交叉数据集泛化方面存在问题，作者希望引入元学习和新的突变编码策略解决这一问题，提升蛋白质特性预测的准确性和效率，以满足药物发现、蛋白质工程和精确诊断的需求。

Method: 作者提出一种蛋白质突变特性预测的新方法，该方法基于元学习（MAML），并且引入一种通过分隔符将突变直接融入序列背景的新编码策略，使模型能够快速适应新任务，提高跨任务泛化能力，解决现有Transformer模型对突变位置处理不当的问题。

Result: 通过跨三个不同蛋白质突变数据集的评估，该方法相比于传统微调方法在功能性适应性和溶解度任务上分别提高了29%和94%的准确性，并且节省了大量训练时间，显示出更强的跨任务泛化能力和训练效率。

Conclusion: 该研究首次系统性地将元学习应用到蛋白质突变分析中，提出了一种新的突变编码策略，为蛋白质工程中跨域泛化的挑战提供了有效的解决方法，具有重要的理论及实际应用意义。

Abstract: Protein mutations can have profound effects on biological function, making
accurate prediction of property changes critical for drug discovery, protein
engineering, and precision medicine. Current approaches rely on fine-tuning
protein-specific transformers for individual datasets, but struggle with
cross-dataset generalization due to heterogeneous experimental conditions and
limited target domain data. We introduce two key innovations: (1) the first
application of Model-Agnostic Meta-Learning (MAML) to protein mutation property
prediction, and (2) a novel mutation encoding strategy using separator tokens
to directly incorporate mutations into sequence context. We build upon
transformer architectures integrating them with MAML to enable rapid adaptation
to new tasks through minimal gradient steps rather than learning
dataset-specific patterns. Our mutation encoding addresses the critical
limitation where standard transformers treat mutation positions as unknown
tokens, significantly degrading performance. Evaluation across three diverse
protein mutation datasets (functional fitness, thermal stability, and
solubility) demonstrates significant advantages over traditional fine-tuning.
In cross-task evaluation, our meta-learning approach achieves 29% better
accuracy for functional fitness with 65% less training time, and 94% better
accuracy for solubility with 55% faster training. The framework maintains
consistent training efficiency regardless of dataset size, making it
particularly valuable for industrial applications and early-stage protein
design where experimental data is limited. This work establishes a systematic
application of meta-learning to protein mutation analysis and introduces an
effective mutation encoding strategy, offering transformative methodology for
cross-domain generalization in protein engineering.

</details>


### [69] [Safety Assessment in Reinforcement Learning via Model Predictive Control](https://arxiv.org/abs/2510.20955)
*Jeff Pflueger,Michael Everett*

Main category: cs.LG

TL;DR: 提出了一种利用可逆性防止安全问题的方法，仅需查询黑盒动态，无需显式的动态或安全约束知识。实验结果显示该方法在不违反安全性的情况下，训练进度与基线PPO方法相当。


<details>
  <summary>Details</summary>
Motivation: 现有方法提供正式的安全保证通常依赖于对安全规范的详细知识，而难以具体化的安全问题最好通过不变性来表征。该研究旨在提供一种仅需查询黑盒动态即可防止安全问题的方法，从而实现过程中的正式安全保证。

Method: 该方法使用模型预测路径积分控制来检查训练过程中一个学习策略所提动作的安全性。具体而言，它在训练期间使用可逆性作为防止安全问题的手段，仅需黑盒动态查询，无需显式的动态或安全约束知识。

Result: 实验结果显示所建议的算法在所有不安全动作之前成功终止，同时在训练期间实现了与允许违反安全性的基线PPO方法相当的进度。

Conclusion: 通过利用可逆性，可以有效地防止过程中的安全问题，并且仅需查询黑盒动态即可，从而有助于实现正式的安全保证，同时保持良好的训练性能。

Abstract: Model-free reinforcement learning approaches are promising for control but
typically lack formal safety guarantees. Existing methods to shield or
otherwise provide these guarantees often rely on detailed knowledge of the
safety specifications. Instead, this work's insight is that many
difficult-to-specify safety issues are best characterized by invariance.
Accordingly, we propose to leverage reversibility as a method for preventing
these safety issues throughout the training process. Our method uses
model-predictive path integral control to check the safety of an action
proposed by a learned policy throughout training. A key advantage of this
approach is that it only requires the ability to query the black-box dynamics,
not explicit knowledge of the dynamics or safety constraints. Experimental
results demonstrate that the proposed algorithm successfully aborts before all
unsafe actions, while still achieving comparable training progress to a
baseline PPO approach that is allowed to violate safety.

</details>


### [70] [An Ensembled Penalized Federated Learning Framework for Falling People Detection](https://arxiv.org/abs/2510.20960)
*Sizhe Rao,Runqiu Zhang,Sajal Saha,Liang Chen*

Main category: cs.LG

TL;DR: 本文提出了一种名为EPFL（Ensembled Penalized Federated Learning）的框架，用于改进老年人和残疾人的跌倒检测系统，该框架结合了连续学习、个性化建模和新颖的特殊加权聚合策略，旨在提高检测系统的准确性和隐私保护。实验结果表明，该方法在基准数据集上表现优异，召回率为88.31%，F1得分为89.94%。


<details>
  <summary>Details</summary>
Motivation: 现有跌倒检测系统存在泛化能力差、数据隐私保护不足以及难以适应个体行为差异等问题，为此本文提出了一种新的跌倒检测框架EPFL，旨在解决上述问题，提高系统的准确性和实用性，同时保护用户隐私。

Method: EPFL采用了联邦学习技术，结合了连续学习和个人模型调整，并提出一种特殊的加权聚合策略，以利用穿戴设备的传感器数据来检测连续的运动模式，同时通过同态加密和联邦训练保护用户隐私。

Result: 实验结果表明，EPFL在基准跌倒检测数据集上的召回率为88.31%，F1得分为89.94%，显著优于中心化和基线模型，证明了该方法的有效性。

Conclusion: 本文提出的方法提供了一种准确、隐私保护良好的跌倒检测解决方案，具有重要的实际应用价值，可以用于医疗保健环境中的实时跌倒检测，并且具备通过自适应反馈机制持续改进的潜力。

Abstract: Falls among elderly and disabled individuals remain a leading cause of injury
and mortality worldwide, necessitating robust, accurate, and privacy-aware fall
detection systems. Traditional fall detection approaches, whether centralized
or point-wise, often struggle with key challenges such as limited
generalizability, data privacy concerns, and variability in individual movement
behaviors. To address these limitations, we propose EPFL-an Ensembled Penalized
Federated Learning framework that integrates continual learning, personalized
modeling, and a novel Specialized Weighted Aggregation (SWA) strategy. EPFL
leverages wearable sensor data to capture sequential motion patterns while
preserving user privacy through homomorphic encryption and federated training.
Unlike existing federated models, EPFL incorporates both penalized local
training and ensemble-based inference to improve inter-client consistency and
adaptability to behavioral differences. Extensive experiments on a benchmark
fall detection dataset demonstrate the effectiveness of our approach, achieving
a Recall of 88.31 percent and an F1-score of 89.94 percent, significantly
outperforming both centralized and baseline models. This work presents a
scalable, secure, and accurate solution for real-world fall detection in
healthcare settings, with strong potential for continuous improvement via its
adaptive feedback mechanism.

</details>


### [71] [Neural Mutual Information Estimation with Vector Copulas](https://arxiv.org/abs/2510.20968)
*Yanzhi Chen,Zijing Ou,Adrian Weller,Michael U. Gutmann*

Main category: cs.LG

TL;DR: 该论文提出了一种新的估计互信息的方法，通过结合向量 copula 理论，在复杂模型和简化的模型之间取得了平衡，从而在各种数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的互信息估计方法不足之处在于要么采用高度灵活的模型需要大量数据，要么采用过于简化的模型无法捕捉复杂分布。因此，研究提出了一种新的方案来解决这些不足。

Method: 该方法基于最近的向量 copula 理论，提出了一种新的互信息估计方法，介于高度灵活的模型与过于简化的模型之间，以达到复杂性和容量之间的良好平衡。

Result: 在最先进的合成基准测试和不同模态的真实世界数据集上，实验结果验证了所提方法的优势。具体来说，新方法在估计互信息时具有较高的准确性和鲁棒性，能够有效地处理各种复杂分布。

Conclusion: 研究提出了一种新的互信息估计方法，它兼顾了模型的复杂性和效果，能够更有效地估计互信息，适用于各种数据集。

Abstract: Estimating mutual information (MI) is a fundamental task in data science and
machine learning. Existing estimators mainly rely on either highly flexible
models (e.g., neural networks), which require large amounts of data, or overly
simplified models (e.g., Gaussian copula), which fail to capture complex
distributions. Drawing upon recent vector copula theory, we propose a
principled interpolation between these two extremes to achieve a better
trade-off between complexity and capacity. Experiments on state-of-the-art
synthetic benchmarks and real-world data with diverse modalities demonstrate
the advantages of the proposed estimator.

</details>


### [72] [On the accuracy of implicit neural representations for cardiovascular anatomies and hemodynamic fields](https://arxiv.org/abs/2510.20970)
*Jubilee Lee,Daniele E. Schiavazzi*

Main category: cs.LG

TL;DR: 本文评估了最先进的隐式神经表示方法在压缩血管动力场和表示心血管解剖结构方面的性能，并提出了一些缓解谱偏见的方法，实验结果表明，这些方法在实际数据集上取得了显著的压缩比和较低的误差，并且不需要广泛的超参数调整。SIREN、MFN-Gabor和MHE架构表现最好。


<details>
  <summary>Details</summary>
Motivation: 本文旨在评估最新的隐式神经表示方法在压缩血管动力场和表示心血管解剖结构方面的性能，并探索缓解谱偏见的几种策略，从而提高隐式神经表示方法在特定领域的应用精度。

Method: 本文采用先进的隐式神经表示方法，如SIREN、MFN-Gabor和MHE架构，将空间和时间变化的心脏动力场从数值模拟中压缩，并通过符号距离函数表示心血管解剖结构。对于谱偏见问题，本文测试了多种策略，包括特殊激活函数、固定和可调的位置编码以及非线性核的线性组合。

Result: 在有关胸部主动脉的真实动态心动力场数据上，隐式神经表示方法实现了约230的最大压缩比，压差的最大绝对误差为1 mmHg，流速的最大绝对误差为5-10 cm/s。在48种不同的胸部主动脉解剖结构中，隐式神经表示方法与真实数据之间的平均和最大绝对解剖差异分别为0.5 mm和1.6 mm。这三个架构（SIREN、MFN-Gabor和MHE）表现最佳。

Conclusion: 本文展示了隐式神经表示方法在压缩心脏动力场和表示心血管解剖结构方面的能力，并证明了缓解谱偏见的各种策略的有效性。这些结果表明，隐式神经表示方法在特定领域中的应用潜力巨大。

Abstract: Implicit neural representations (INRs, also known as neural fields) have
recently emerged as a powerful framework for knowledge representation,
synthesis, and compression. By encoding fields as continuous functions within
the weights and biases of deep neural networks-rather than relying on voxel- or
mesh-based structured or unstructured representations-INRs offer both
resolution independence and high memory efficiency. However, their accuracy in
domain-specific applications remains insufficiently understood. In this work,
we assess the performance of state-of-the-art INRs for compressing hemodynamic
fields derived from numerical simulations and for representing cardiovascular
anatomies via signed distance functions. We investigate several strategies to
mitigate spectral bias, including specialized activation functions, both fixed
and trainable positional encoding, and linear combinations of nonlinear
kernels. On realistic, space- and time-varying hemodynamic fields in the
thoracic aorta, INRs achieved remarkable compression ratios of up to
approximately 230, with maximum absolute errors of 1 mmHg for pressure and 5-10
cm/s for velocity, without extensive hyperparameter tuning. Across 48 thoracic
aortic anatomies, the average and maximum absolute anatomical discrepancies
were below 0.5 mm and 1.6 mm, respectively. Overall, the SIREN, MFN-Gabor, and
MHE architectures demonstrated the best performance. Source code and data is
available at https://github.com/desResLab/nrf.

</details>


### [73] [L^2M^3OF: A Large Language Multimodal Model for Metal-Organic Frameworks](https://arxiv.org/abs/2510.20976)
*Jiyu Cui,Fang Wu,Haokai Zhao,Minggao Feng,Xenophon Evangelopoulos,Andrew I. Cooper,Yejin Choi*

Main category: cs.LG

TL;DR: 我们引入了L2M3OF，这是一个针对金属有机框架（MOFs）的多模态大型语言模型，它可以整合晶体表示学习与语言理解，处理结构、文本和知识模态。实验表明，尽管使用了更少的参数，L2M3OF在性能预测和知识生成任务上超过了领先的文字基大型语言模型，展示了多模态方法在多孔材料理解中的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言任务中表现出卓越的推理能力，但在科学研究突破方面却相对有限，特别是理解和设计复杂物理现象和功能性材料时，需要多层次的表示方式，仅靠语言难以胜任。为解决这一问题，提出L2M3OF模型，通过多模态融合来提升对材料的理解和设计能力。

Method: L2M3OF采用了预训练的晶体编码器和轻量投影层，将结构信息压缩为token空间，并提高了与语言指令的对齐效率。此外，通过特别构建了结晶材料的结构-性质-知识数据库，以更好地训练和评估模型性能。

Result: 实验结果表明，L2M3OF在性能预测和知识生成任务中超越了现有的基于文本的大型语言模型，突显了多模态方法在理解多孔材料中的重要性。

Conclusion: L2M3OF证明了多模态方法在材料研究中的潜力，为新一代人工智能系统的设计提供了基础。

Abstract: Large language models have demonstrated remarkable reasoning capabilities
across diverse natural language tasks. However, comparable breakthroughs in
scientific discovery are more limited, because understanding complex physical
phenomena demands multifaceted representations far beyond language alone. A
compelling example is the design of functional materials such as MOFs-critical
for a range of impactful applications like carbon capture and hydrogen storage.
Navigating their vast and intricate design space in language-based
representations interpretable by LLMs is challenging due to the numerous
possible three-dimensional atomic arrangements and strict reticular rules of
coordination geometry and topology. Despite promising early results in
LLM-assisted discovery for simpler materials systems, MOF design remains
heavily reliant on tacit human expertise rarely codified in textual information
alone. To overcome this barrier, we introduce L2M3OF, the first multimodal LLM
for MOFs. L2M3OF integrates crystal representation learning with language
understanding to process structural, textual, and knowledge modalities jointly.
L2M3OF employs a pre-trained crystal encoder with a lightweight projection
layer to compress structural information into a token space, enabling efficient
alignment with language instructions. To facilitate training and evaluation, we
curate a structure-property-knowledge database of crystalline materials and
benchmark L2M3OF against state-of-the-art closed-source LLMs such as GPT-5,
Gemini-2.5-Pro and DeepSeek-R1. Experiments show that L2M3OF outperforms
leading text-based closed-source LLMs in property prediction and knowledge
generation tasks, despite using far fewer parameters. These results highlight
the importance of multimodal approaches for porous material understanding and
establish L2M3OF as a foundation for next-generation AI systems in materials
discovery.

</details>


### [74] [Learning Grouped Lattice Vector Quantizers for Low-Bit LLM Compression](https://arxiv.org/abs/2510.20984)
*Xi Zhang,Xiaolin Wu,Jiamang Wang,Weisi Lin*

Main category: cs.LG

TL;DR: 提出了Grouped Lattice Vector Quantization (GLVQ)框架，以提高大语言模型的量化效率，降低计算资源和内存需求，在保持模型精度的同时缩小模型大小。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理时需要大量的计算资源和内存，标准的均匀量化虽然可以减少需求，但会降低性能，特别是在低比特场景下。因此，提出了一种新的量化框架以解决这一问题，使其能够在资源受限的情况下部署大型模型。

Method: 引入Grouped Lattice Vector Quantization (GLVQ)框架，为每一组权重分配一个自定义的晶格代码本，使用学习生成矩阵定义。采用Babai四舍五入法来优化生成矩阵，并在训练过程中近似最邻近晶格点搜索，从而实现稳定优化。训练完成后解码过程包括简单的矩阵向量乘法。

Result: 实验在多个基准上进行，我们的方法相比现有的后训练量化基线，实现了模型大小和准确度之间的更好权衡，显示出其在资源受限下部署大型模型的有效性。

Conclusion: 通过采用Grouped Lattice Vector Quantization (GLVQ)，能够大幅度提升模型的量化效果，在保持精确度的同时减小模型大小，更好地适应资源有限的环境。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities but
typically require extensive computational resources and memory for inference.
Post-training quantization (PTQ) can effectively reduce these demands by
storing weights in lower bit-width formats. However, standard uniform
quantization often leads to notable performance degradation, particularly in
low-bit scenarios. In this work, we introduce a Grouped Lattice Vector
Quantization (GLVQ) framework that assigns each group of weights a customized
lattice codebook, defined by a learnable generation matrix. To address the
non-differentiability of the quantization process, we adopt Babai rounding to
approximate nearest-lattice-point search during training, which enables stable
optimization of the generation matrices. Once trained, decoding reduces to a
simple matrix-vector multiplication, yielding an efficient and practical
quantization pipeline. Experiments on multiple benchmarks show that our
approach achieves a better trade-off between model size and accuracy compared
to existing post-training quantization baselines, highlighting its
effectiveness in deploying large models under stringent resource constraints.
Our source code is available on GitHub repository:
https://github.com/xzhang9308/GLVQ.

</details>


### [75] [GPU Memory Requirement Prediction for Deep Learning Task Based on Bidirectional Gated Recurrent Unit Optimization Transformer](https://arxiv.org/abs/2510.20985)
*Chao Wang,Zhizhao Wen,Ruoxin Zhang,Puyang Xu,Yifan Jiang*

Main category: cs.LG

TL;DR: 本次研究提出了一种基于双向门控循环单元优化的Transformer模型，旨在提高GPU内存资源需求预测的准确性。实验结果表明，该模型在关键评估指标上显著优于传统机器学习方法，特别是在均方误差和均方根误差方面。该模型为改进深度学习任务中的资源调度和管理提供了技术支持和理论依据，提高了计算集群的使用效率。


<details>
  <summary>Details</summary>
Motivation: 当前对准确预测深度学习任务中的GPU内存资源需求的需求日益迫切，研究提出了一个结合双向门控循环单元（BiGRU）优化Transformer架构的深度学习模型，以提高内存需求预测的准确性。

Method: 通过设计精细的对照实验，选择决策树、随机森林、Adaboost和XGBoost四种具有代表性的基本机器学习模型作为基准，验证所提出模型的有效性。

Result: 实验结果显示，所提出的BiGRU优化Transformer模型在均方误差（MSE）、均方根误差（RMSE）、平均绝对误差（MAE）和决定系数（R2）等关键评估指标上表现优异，显著超过传统机器学习基准。

Conclusion: 基于双向门控循环单元优化的Transformer模型成功构建，能在深度学习任务中高效精准地完成GPU内存需求预测任务，显著提高了预测准确性，为改进深度学习任务的资源调度和管理提供了技术支持和理论依据，提高了计算集群的使用效率。

Abstract: In response to the increasingly critical demand for accurate prediction of
GPU memory resources in deep learning tasks, this paper deeply analyzes the
current research status and innovatively proposes a deep learning model that
integrates bidirectional gated recurrent units (BiGRU) to optimize the
Transformer architecture, aiming to improve the accuracy of memory demand
prediction. To verify the effectiveness of the model, a carefully designed
comparative experiment was conducted, selecting four representative basic
machine learning models: decision tree, random forest, Adaboost, and XGBoost as
benchmarks. The detailed experimental results show that the BiGRU Transformer
optimization model proposed in this paper exhibits significant advantages in
key evaluation indicators: in terms of mean square error (MSE) and root mean
square error (RMSE), the model achieves the lowest value among all comparison
models, and its predicted results have the smallest deviation from the actual
values; In terms of mean absolute error (MAE) and coefficient of determination
(R2) indicators, the model also performs well and the results are balanced and
stable, with comprehensive predictive performance far exceeding the benchmark
machine learning methods compared. In summary, the Transformer model based on
bidirectional gated recurrent unit optimization successfully constructed in
this study can efficiently and accurately complete GPU memory demand prediction
tasks in deep learning tasks, and its prediction accuracy has been
significantly improved compared to traditional machine learning methods. This
research provides strong technical support and reliable theoretical basis for
optimizing resource scheduling and management of deep learning tasks, and
improving the utilization efficiency of computing clusters.

</details>


### [76] [AL-CoLe: Augmented Lagrangian for Constrained Learning](https://arxiv.org/abs/2510.20995)
*Ignacio Boero,Ignacio Hounie,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 研究重新审视了增广拉格朗日方法在非凸约束学习问题中的应用，建立了强对偶性结果，并证明了双上升算法能收敛到可行和最优的原始解决方案，并在公平性约束分类任务上展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管大多数现代机器学习模型的参数化是非凸的，拉格朗日对偶性仍然是一种流行的解决约束学习问题的方法。然而，增广拉格朗日方法在此类问题中的探索相对较少，因此研究动机在于探索增广拉格朗日方法在非凸约束学习中的有效性。

Method: 研究建立了在温和条件下非凸约束学习问题的强对偶性结果，证明了双上升算法收敛到可行和最优的原始解决方案，并为该方法提供了PAC风格的泛化保证。

Result: 证明了在公平性约束分类任务中，增广拉格朗日方法的有效性。

Conclusion: 研究通过重新审视增广拉格朗日方法在非凸约束学习问题中的应用，证明了其在非凸约束学习中的强大潜力。

Abstract: Despite the non-convexity of most modern machine learning parameterizations,
Lagrangian duality has become a popular tool for addressing constrained
learning problems. We revisit Augmented Lagrangian methods, which aim to
mitigate the duality gap in non-convex settings while requiring only minimal
modifications, and have remained comparably unexplored in constrained learning
settings. We establish strong duality results under mild conditions, prove
convergence of dual ascent algorithms to feasible and optimal primal solutions,
and provide PAC-style generalization guarantees. Finally, we demonstrate its
effectiveness on fairness constrained classification tasks.

</details>


### [77] [Fair Representation Learning with Controllable High Confidence Guarantees via Adversarial Inference](https://arxiv.org/abs/2510.21017)
*Yuhong Luo,Austin Hoag,Xintong Wang,Philip S. Thomas,Przemyslaw A. Grabowicz*

Main category: cs.LG

TL;DR: 该研究提出了一种新的公平表示学习框架FRG，它能够通过优化的对抗模型，确保学习出的表示在下游任务中的群体差异性被控制在一个用户定义的误差阈值内，并以可控的高概率保持这种公平性保证。实验结果表明，FRG框架在多个数据集上与六种最先进的公平表示学习方法相比，能够一致地控制不公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的一些表示学习方法可能产生不公平的表示，导致在下游任务中对于特定的群体产生不公平。为了解决这个问题，作者提出了一个任务，学习到的表示应该能在保证一定公平性的同时，还能够达到较高的模型性能。相关的公平性保证是每个下游任务中群体差异性由用户定义的误差阈值 ε 控制，并且这种保证是可控的高概率保证。 

Method: 作者提出了一种新的框架FRG（Fair Representation learning with high-confidence Guarantees），该框架通过优化的对抗模型来实现高置信度的公平性保证。通过这种方法，可以确保学习到的表示在各个下游任务中的群体差异性都被控制在一个用户定义值 ε 内，且这种控制是高概率保证的。 

Result: 作者在三个真实数据集上，将FRG与六种最先进的公平表示学习方法进行了比较。实验结果表明，FRG在多个下游任务和模型下，一致地能够达到用户定义的公平性控制误差阈值 ε，显示了显著的优势。 

Conclusion: 这篇论文提出了一个实现高置信度公平性保证的框架FRG，在保护特定群体免受不公平对待的同时，还不会降低模型性能。FRG的应用场景很广泛，适合任何对于下游任务的公平性设定要求较高的情况。

Abstract: Representation learning is increasingly applied to generate representations
that generalize well across multiple downstream tasks. Ensuring fairness
guarantees in representation learning is crucial to prevent unfairness toward
specific demographic groups in downstream tasks. In this work, we formally
introduce the task of learning representations that achieve high-confidence
fairness. We aim to guarantee that demographic disparity in every downstream
prediction remains bounded by a *user-defined* error threshold $\epsilon$, with
*controllable* high probability. To this end, we propose the ***F**air
**R**epresentation learning with high-confidence **G**uarantees (FRG)*
framework, which provides these high-confidence fairness guarantees by
leveraging an optimized adversarial model. We empirically evaluate FRG on three
real-world datasets, comparing its performance to six state-of-the-art fair
representation learning methods. Our results demonstrate that FRG consistently
bounds unfairness across a range of downstream models and tasks.

</details>


### [78] [More Than Memory Savings: Zeroth-Order Optimization Mitigates Forgetting in Continual Learning](https://arxiv.org/abs/2510.21019)
*Wanhao Yu,Zheng Wang,Shuteng Niu,Sen Lin,Li Yang*

Main category: cs.LG

TL;DR: 本文探讨了零阶优化在连续学习中的应用，并提出了一种新的方法ZO-FC，以平衡稳定性和可塑性之间的权衡，同时保持内存效率。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在通过零阶优化解决连续学习中的记忆效率、稳定性和可塑性之间的三难选择问题，特别是当使用可学习分类器时的情况。

Method: 通过理论分析和实验证据，本文调查了零阶优化与连续学习结合的研究，并提出了一种新的方法ZO-FC。该方法使用零阶优化应用于单一的基于适配器的参数高效训练（PEFT）模块，而分类器仍然使用一阶优化。

Result: ZO优化能够帮助减少连续学习中的遗忘问题，但是牺牲了可塑性，特别是在有限训练预算的情况下。实验表明，提出了的ZO-FC方法能够有效地平衡稳定性和可塑性，并在内存效率方面提供实际解决方案。

Conclusion: 这种方法结合了零阶优化的稳定性优势和一阶更新对于新任务特定知识的学习能力，是一种实用且内存高效的解决方案，适用于连续学习的设计问题。

Abstract: Zeroth-order (ZO) optimization has gained attention as a memory-efficient
alternative to first-order (FO) methods, particularly in settings where
gradient computation is expensive or even impractical. Beyond its memory
efficiency, in this work, we investigate ZO optimization for continual learning
(CL) as a novel approach to address the plasticity-stability-efficiency
trilemma. Through theoretical analysis and empirical evidence, we show that ZO
optimization naturally leads to flatter loss landscapes, which in turn reduce
forgetting in CL. However, this stability comes at a cost of plasticity: due to
its imprecise gradient estimates and slower convergence, ZO optimization tends
to be less effective than FO in acquiring new task-specific knowledge,
particularly under constrained training budgets. To better understand this
trade-off, we conduct a holistic evaluation of ZO optimization applied to
various existing CL methods. Our findings reveal that ZO optimization enhances
stability but often undermines plasticity, particularly when used with
learnable classifiers. Motivated by this insight, we propose ZO-FC, a simple
but effective approach that applies ZO optimization to a single adapter-based
PEFT module with FO optimized classifier. This design leverages the stability
benefits of ZO while preserving the adaptability of FO updates with negligible
memory overhead. Experiments demonstrate that ZO-FC achieves an effective
balance between stability and plasticity, offering a practical and
memory-efficient solution for on-device CL.

</details>


### [79] [CIPHER: Scalable Time Series Analysis for Physical Sciences with Application to Solar Wind Phenomena](https://arxiv.org/abs/2510.21022)
*Jasmine R. Kobayashi,Daniela Martin,Valmir P Moraes Filho,Connor O'Brien,Jinsu Hong,Sudeshna Boro Saikia,Hala Lamdouar,Nathan D. Miles,Marcella Scoczynski,Mavis Stone,Sairam Sundaresan,Anna Jungbluth,Andrés Muñoz-Jaramillo,Evangelia Samara,Joseph Gallego*

Main category: cs.LG

TL;DR: CIPHER框架通过结合iSAX压缩和索引，基于密度的聚类(HDBSCAN)以及专家验证，来帮助物理科学中的复杂时间序列进行全面标注，具体在太阳风现象分类中表现良好。


<details>
  <summary>Details</summary>
Motivation: 长久以来，物理科学领域中时间序列的标注和分类面临着专家注解稀缺、昂贵以及经常不一致的问题。为了缓解这些问题，CIPHER被设计来加速大规模的复杂时间序列标注任务。 

Method: CIPHER整合了iSAX进行可解释的压缩和索引，使用基于密度的聚类（HDBSCAN）对重复现象进行分组，并结合了人的循环步骤（专家验证），以实现效率和准确性的提升。在样本标注时，领域科学家将代表样本进行标注，这些注解被传播到各个聚类中，形成系统化、可扩展的分类。

Result: 该框架在太阳风现象识别中表现良好，能够识别出诸如日冕质量抛射和流交互区域等有意义的现象。它表明了一个结合符号表示、无监督学习和专家知识以解决物理科学生物质标签稀缺问题的通用策略。所有使用的代码和配置文件是公开可得的，可支持复制研究。 

Conclusion: CIPHER展示了在物理科学中应对时间序列标注稀缺性时结合不同方法的有效性。它不仅适用于太阳风现象的分类，还可以推广到其他类似的分类任务。

Abstract: Labeling or classifying time series is a persistent challenge in the physical
sciences, where expert annotations are scarce, costly, and often inconsistent.
Yet robust labeling is essential to enable machine learning models for
understanding, prediction, and forecasting. We present the \textit{Clustering
and Indexation Pipeline with Human Evaluation for Recognition} (CIPHER), a
framework designed to accelerate large-scale labeling of complex time series in
physics. CIPHER integrates \textit{indexable Symbolic Aggregate approXimation}
(iSAX) for interpretable compression and indexing, density-based clustering
(HDBSCAN) to group recurring phenomena, and a human-in-the-loop step for
efficient expert validation. Representative samples are labeled by domain
scientists, and these annotations are propagated across clusters to yield
systematic, scalable classifications. We evaluate CIPHER on the task of
classifying solar wind phenomena in OMNI data, a central challenge in space
weather research, showing that the framework recovers meaningful phenomena such
as coronal mass ejections and stream interaction regions. Beyond this case
study, CIPHER highlights a general strategy for combining symbolic
representations, unsupervised learning, and expert knowledge to address label
scarcity in time series across the physical sciences. The code and
configuration files used in this study are publicly available to support
reproducibility.

</details>


### [80] [Elementary, My Dear Watson: Non-Invasive Neural Keyword Spotting in the LibriBrain Dataset](https://arxiv.org/abs/2510.21038)
*Gereon Elvers,Gilad Landau,Oiwi Parker Jones*

Main category: cs.LG

TL;DR: 提出了一种名为Keyword Spotting (KWS) 的中间任务作为一种实际可行且注重隐私的非侵入性脑机接口任务。该任务使用LibriBrain数据集，提供了一个标准化的训练、验证和测试分割，并使用AUPRC作为评估指标，以衡量其性能。初始参考模型在单个消费者级GPU上可训练，并且在未见过的会话中达到了约13倍的基线AUPRC。此任务的探测能力受单词频率和持续时间的影响，并且训练时间越长，性能提升越明显。


<details>
  <summary>Details</summary>
Motivation: 当前的非侵入性脑机接口基准测试集中在相对简单的任务上，如语音检测和音素分类。然而，在像Brain-to-Text这样更高级的任务上，应用级结果还难以实现。因此，提出Keyword Spotting (KWS) 作为介于基础任务和高级任务之间的实际可行且注重隐私的任务，以推动非侵入性脑机接口技术的发展。

Method: 使用了深度的52小时、受试者内部的LibriBrain数据集，提供了标准的训练、验证和测试分割，以实现可重复性基准测试。采用了针对极端类别不平衡的评估协议，具体来说使用了区域下的精度-召回率曲线面积(AUPRC)作为稳健的评估指标，并用每小时固定的假警报数(FA/h)来捕捉用户的体验权衡。提出的参考模型是一种小型的1-D Conv/ResNet模型，使用了焦点损失和top-k池化。该模型可以单卡训练，并可用于进一步的实验研究和数据装载器和Colab教程的更新。

Result: 这个提出的参考模型在未见过的会话中比基线约多13倍的AUPRC。进一步的分析呈现出：(i) 可预测的受试者内部扩展——性能与训练小时数对数线性增加；(ii) 存在系统地影响可检测性的单词级别因素(频率和持续时间)。这表明KWS任务是有应用前景的以及相关的性能提高是由增加的训练时间驱动的。

Conclusion: 本文通过引入Keyword Spotting作为介于基础任务和应用任务之间的实际可行的非侵入性脑机接口任务，使用提供的LibriBrain数据集，展示了这项任务的可行性和实验结果，为脑机接口技术的发展打下了坚实的基础，预示着在非侵入性系统中更好的人类-机器交互的潜力。

Abstract: Non-invasive brain-computer interfaces (BCIs) are beginning to benefit from
large, public benchmarks. However, current benchmarks target relatively simple,
foundational tasks like Speech Detection and Phoneme Classification, while
application-ready results on tasks like Brain-to-Text remain elusive. We
propose Keyword Spotting (KWS) as a practically applicable, privacy-aware
intermediate task. Using the deep 52-hour, within-subject LibriBrain corpus, we
provide standardized train/validation/test splits for reproducible
benchmarking, and adopt an evaluation protocol tailored to extreme class
imbalance. Concretely, we use area under the precision-recall curve (AUPRC) as
a robust evaluation metric, complemented by false alarms per hour (FA/h) at
fixed recall to capture user-facing trade-offs. To simplify deployment and
further experimentation within the research community, we are releasing an
updated version of the pnpl library with word-level dataloaders and Colab-ready
tutorials. As an initial reference model, we present a compact 1-D Conv/ResNet
baseline with focal loss and top-k pooling that is trainable on a single
consumer-class GPU. The reference model achieves approximately 13x the
permutation baseline AUPRC on held-out sessions, demonstrating the viability of
the task. Exploratory analyses reveal: (i) predictable within-subject scaling -
performance improves log-linearly with more training hours - and (ii) the
existence of word-level factors (frequency and duration) that systematically
modulate detectability.

</details>


### [81] [Amortized Active Generation of Pareto Sets](https://arxiv.org/abs/2510.21052)
*Daniel M. Steinberg,Asiri Wijesinghe,Rafael Oliveira,Piotr Koniusz,Cheng Soon Ong,Edwin V. Bonilla*

Main category: cs.LG

TL;DR: 提出了一种新的在线离散黑盒多目标优化框架A-GPS，该框架能够通过生成模型学习帕累托集，同时支持用户偏好的后验条件。该方法利用类别概率估计器预测支配关系，更新生成模型，能够通过偏好方向向量灵活地捕捉用户偏好，从而实现对帕累托集的有效近似，且无需显式计算超体积。实验结果表明，该方法在合成基准和蛋白质设计任务上表现出强大的样本效率和有效的偏好融入能力。


<details>
  <summary>Details</summary>
Motivation: 在线离散黑盒多目标优化任务中，需要动态生成帕累托集，同时支持用户偏好的后验条件，既要避免显式计算复杂的超体积，还要能够灵活地捕捉用户偏好，从而达到高效的帕累托集近似。

Method: 提出的方法A-GPS通过学习帕累托集的生成模型和使用类别概率估计器来预测支配关系，从而能够有条件地更新模型，并根据预先定义的偏好方向向量有效地捕捉用户偏好，通过这种方式，A-GPS能够在每次迭代中简单地更新模型而无需重新训练，使得模型可以沿帕累托前沿进行采样。

Result: 该方法在合成基准数据集和蛋白质设计任务中表现出强大的样本效率和偏好融合能力，避免了计算复杂的超体积，实现了帕累托集高质量的近似。

Conclusion: A-GPS框架通过使用生成模型和类别概率估计器提供了一种灵活、动态和用户友好的多目标优化方法，其能够高效地近似帕累托集，同时通过偏好向量来适应用户的偏好变化。

Abstract: We introduce active generation of Pareto sets (A-GPS), a new framework for
online discrete black-box multi-objective optimization (MOO). A-GPS learns a
generative model of the Pareto set that supports a-posteriori conditioning on
user preferences. The method employs a class probability estimator (CPE) to
predict non-dominance relations and to condition the generative model toward
high-performing regions of the search space. We also show that this
non-dominance CPE implicitly estimates the probability of hypervolume
improvement (PHVI). To incorporate subjective trade-offs, A-GPS introduces
preference direction vectors that encode user-specified preferences in
objective space. At each iteration, the model is updated using both Pareto
membership and alignment with these preference directions, producing an
amortized generative model capable of sampling across the Pareto front without
retraining. The result is a simple yet powerful approach that achieves
high-quality Pareto set approximations, avoids explicit hypervolume
computation, and flexibly captures user preferences. Empirical results on
synthetic benchmarks and protein design tasks demonstrate strong sample
efficiency and effective preference incorporation.

</details>


### [82] [On the Sample Complexity of Differentially Private Policy Optimization](https://arxiv.org/abs/2510.21060)
*Yi He,Xingyu Zhou*

Main category: cs.LG

TL;DR: 本文理论研究了差分隐私政策优化及其样本复杂度，为政策优化定义了一个差分隐私的概念，并分析了政策梯度等算法下的样本复杂度。发现隐私成本通常作为样本复杂度中的低阶项出现，并提供实践中的宝贵见解。



<details>
  <summary>Details</summary>
Motivation: 在政策优化（PO）越来越广泛应用于敏感领域的同时，隐私问题日益凸显。因此，研究差分隐私政策优化及其样本复杂度具有重要意义。


Method: 首先为政策优化定义了一个差分隐私的概念，随后通过统一框架系统地分析了政策梯度等算法下的样本复杂度。


Result: 研究表明，隐私成本通常作为样本复杂度中的低阶项出现，且该研究提供了一些重要的实践见解。这些成果对隐私保护政策优化的实际应用非常宝贵。


Conclusion: 对差分隐私政策优化及其样本复杂度的研究提供了理论和实践上的宝贵信息，有助于提高其在敏感领域的应用安全性。


Abstract: Policy optimization (PO) is a cornerstone of modern reinforcement learning
(RL), with diverse applications spanning robotics, healthcare, and large
language model training. The increasing deployment of PO in sensitive domains,
however, raises significant privacy concerns. In this paper, we initiate a
theoretical study of differentially private policy optimization, focusing
explicitly on its sample complexity. We first formalize an appropriate
definition of differential privacy (DP) tailored to PO, addressing the inherent
challenges arising from on-policy learning dynamics and the subtlety involved
in defining the unit of privacy. We then systematically analyze the sample
complexity of widely-used PO algorithms, including policy gradient (PG),
natural policy gradient (NPG) and more, under DP constraints and various
settings, via a unified framework. Our theoretical results demonstrate that
privacy costs can often manifest as lower-order terms in the sample complexity,
while also highlighting subtle yet important observations in private PO
settings. These offer valuable practical insights for privacy-preserving PO
algorithms.

</details>


### [83] [Scalable Machine Learning Analysis of Parker Solar Probe Solar Wind Data](https://arxiv.org/abs/2510.21066)
*Daniela Martin,Connor O'Brien,Valmir P Moraes Filho,Jinsu Hong,Jasmine R. Kobayashi,Evangelia Samara,Joseph Gallego*

Main category: cs.LG

TL;DR: 我们提出了一种可扩展的机器学习框架，用于分析帕克太阳探测器的太阳风数据。该框架利用Dask进行大规模统计计算，并采用了量子启发式的核密度矩阵方法。我们揭示了内日光层中太阳风速度随距太阳距离增加而增加、质子密度降低以及速度和密度之间的反比关系。该方法为探索复杂的物理数据集提供了可理解且可分布的方法，并促进了大规模原位测量的可重复分析。处理后的数据产品和分析工具也公开提供，以推动未来对太阳风动力学和空间天气预报的研究。


<details>
  <summary>Details</summary>
Motivation: 传统的分析方法难以处理帕克太阳探测器产生的超过150GB的数据集。因此，我们开发了一种基于Dask和量子启发式的核密度矩阵方法的可扩展机器学习框架，以应对这一挑战，并提供对太阳风动力学的深入理解。该框架不仅可以处理大规模数据，还可以提供对太阳风结构在增强和调节极端空间天气现象方面作用的定量见解。

Method: 采用Dask处理大规模数据，并使用量子启发式的核密度矩阵方法来估计太阳风速度、质子密度和质子热速度等关键参数的单变量和双变量分布。同时，设定每个参数的异常阈值，以识别具有特殊特征的太阳风结构。

Result: 研究表明，太阳风速度随距太阳距离增加而增加，质子密度则随距太阳距离增加而减少；并发现了速度和密度之间的反比关系。这些发现提供了对太阳风结构如何影响极端空间天气现象的定量理解。该方法为处理复杂物理数据集提供了一种可靠且可解释的方法论。

Conclusion: 研究展示了如何利用一种新的机器学习框架来理解和分析太阳风数据，这对理解太阳风动力学和空间天气变化具有重要意义。该分析工具及相关数据产品现已公开，以促进更广泛的科学研究。

Abstract: We present a scalable machine learning framework for analyzing Parker Solar
Probe (PSP) solar wind data using distributed processing and the
quantum-inspired Kernel Density Matrices (KDM) method. The PSP dataset
(2018--2024) exceeds 150 GB, challenging conventional analysis approaches. Our
framework leverages Dask for large-scale statistical computations and KDM to
estimate univariate and bivariate distributions of key solar wind parameters,
including solar wind speed, proton density, and proton thermal speed, as well
as anomaly thresholds for each parameter. We reveal characteristic trends in
the inner heliosphere, including increasing solar wind speed with distance from
the Sun, decreasing proton density, and the inverse relationship between speed
and density. Solar wind structures play a critical role in enhancing and
mediating extreme space weather phenomena and can trigger geomagnetic storms;
our analyses provide quantitative insights into these processes. This approach
offers a tractable, interpretable, and distributed methodology for exploring
complex physical datasets and facilitates reproducible analysis of large-scale
in situ measurements. Processed data products and analysis tools are made
publicly available to advance future studies of solar wind dynamics and space
weather forecasting. The code and configuration files used in this study are
publicly available to support reproducibility.

</details>


### [84] [The Virtues of Brevity: Avoid Overthinking in Parallel Test-Time Reasoning](https://arxiv.org/abs/2510.21067)
*Raul Cavalcante Dinardi,Bruno Yamamoto,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: 本文提出了一种简单的策略，即选择最短的答案来提升LLM的预测性能，这种方法在两个具有挑战性的基准测试中表现与复杂的自一致方法相当，但计算开销更低。该策略的有效性源于模型在简洁自信和冗长过度思考两种工作模式间的选择，通过选择最短的答案可以更倾向于简洁自信的工作模式。


<details>
  <summary>Details</summary>
Motivation: 现有策略中，复杂的评分方法增加了计算成本和复杂度，在此基础上，本文提出了选择最短答案这种简单的策略来提升LLM的预测性能，以降低计算开销。

Method: 通过实验验证了选择最短答案的策略在两个具有挑战性的基准测试中表现出与复杂方法相当的性能，同时计算开销降低。文章指出，这种方法的有效性取决于模型在简洁自信和冗长过度思考两种工作模式间的切换，选择最短答案可以促使模型更倾向于简洁自信的工作模式。

Result: 该策略在两个具有挑战性的基准测试中表现与复杂方法相当，计算开销却显著降低，并且这种方法适用于输出平等性不明确的任务。

Conclusion: 选择最短答案的策略提供了Pareto改进，不仅能提升性能，还能降低计算开销，为LLM的预测任务提供了一种简洁有效的解决方案。

Abstract: Reasoning models represent a significant advance in LLM capabilities,
particularly for complex reasoning tasks such as mathematics and coding.
Previous studies confirm that parallel test-time compute-sampling multiple
solutions and selecting the best one-can further enhance the predictive
performance of LLMs. However, strategies in this area often require complex
scoring, thus increasing computational cost and complexity. In this work, we
demonstrate that the simple and counterintuitive heuristic of selecting the
shortest solution is highly effective. We posit that the observed effectiveness
stems from models operating in two distinct regimes: a concise, confident
conventional regime and a verbose overthinking regime characterized by
uncertainty, and we show evidence of a critical point where the overthinking
regime begins to be significant. By selecting the shortest answer, the
heuristic preferentially samples from the conventional regime. We confirm that
this approach is competitive with more complex methods such as self-consistency
across two challenging benchmarks while significantly reducing computational
overhead. The shortest-answer heuristic provides a Pareto improvement over
self-consistency and applies even to tasks where output equality is not well
defined.

</details>


### [85] [DictPFL: Efficient and Private Federated Learning on Encrypted Gradients](https://arxiv.org/abs/2510.21086)
*Jiaqi Xue,Mayank Kumar,Yuzhang Shang,Shangqian Gao,Rui Ning,Mengxin Zheng,Xiaoqian Jiang,Qian Lou*

Main category: cs.LG

TL;DR: DictPFL是一种新的联邦学习框架，通过选择性加密的方式，在保护梯度隐私的同时显著降低了计算和通信的开销，使得基于同态加密的联邦学习在实际应用中变得可行。实验表明，DictPFL相比全加密方案和选择性加密方案，在开销和速度上均有显著优势。


<details>
  <summary>Details</summary>
Motivation: 传统的联邦学习中，梯度共享可能会导致隐私泄露。虽然同态加密可以保护聚合过程，但是其庞大的计算和通信开销使其难以在实际中应用。现有的基于同态加密的联邦学习方法要么采用全加密来实现完全的隐私保护，要么采用部分加密来节约资源，但这也暴露了潜在的安全风险。因此本文提出了DictPFL框架，以实现完全的梯度保护同时尽量减少开销。

Method: DictPFL采用了两个关键模块：分解-部分加密（DePE）与剪枝-最小化加密（PrME）。其中DePE将模型权重分为静态字典和动态更新的查找表两部分，只加密传输中的梯度，不传输和加密静态字典。而PrME则引入了加密感知的剪枝策略，通过历史引导掩码来最小化需要加密的参数数量。

Result: 实验表明，DictPFL相比全加密方案，降低通信成本402-748倍，加速训练28-65倍；而相比于最先进的选择性加密方法，DictPFL则在开销上减少了51-155倍，速度上提升了4-19倍。更惊人的是，DictPFL的运行时间只比传统非加密的联邦学习多出了2倍，证明了基于同态加密的隐私联邦学习在实际部署中的可行性。

Conclusion: DictPFL通过选择性的加密策略，实现了梯度的完全隐私保护，相较于全加密方法和现有的选择性加密方法，大幅降低了通信成本和计算开销，首次证明了基于同态加密的隐私联邦学习具备实际应用价值。

Abstract: Federated Learning (FL) enables collaborative model training across
institutions without sharing raw data. However, gradient sharing still risks
privacy leakage, such as gradient inversion attacks. Homomorphic Encryption
(HE) can secure aggregation but often incurs prohibitive computational and
communication overhead. Existing HE-based FL methods sit at two extremes:
encrypting all gradients for full privacy at high cost, or partially encrypting
gradients to save resources while exposing vulnerabilities. We present DictPFL,
a practical framework that achieves full gradient protection with minimal
overhead. DictPFL encrypts every transmitted gradient while keeping
non-transmitted parameters local, preserving privacy without heavy computation.
It introduces two key modules: Decompose-for-Partial-Encrypt (DePE), which
decomposes model weights into a static dictionary and an updatable lookup
table, only the latter is encrypted and aggregated, while the static dictionary
remains local and requires neither sharing nor encryption; and
Prune-for-Minimum-Encrypt (PrME), which applies encryption-aware pruning to
minimize encrypted parameters via consistent, history-guided masks. Experiments
show that DictPFL reduces communication cost by 402-748$\times$ and accelerates
training by 28-65$\times$ compared to fully encrypted FL, while outperforming
state-of-the-art selective encryption methods by 51-155$\times$ in overhead and
4-19$\times$ in speed. Remarkably, DictPFL's runtime is within 2$\times$ of
plaintext FL, demonstrating for the first time, that HE-based private federated
learning is practical for real-world deployment. The code is publicly available
at https://github.com/UCF-ML-Research/DictPFL.

</details>


### [86] [ESCORT: Efficient Stein-variational and Sliced Consistency-Optimized Temporal Belief Representation for POMDPs](https://arxiv.org/abs/2510.21107)
*Yunuo Zhang,Baiting Luo,Ayan Mukhopadhyay,Gabor Karsai,Abhishek Dubey*

Main category: cs.LG

TL;DR: ESCORT 是一种新颖的框架，用于在高维信念空间中捕捉复杂的多模态分布，特别是在部分可观测的马尔可夫决策过程（POMDPs）中存在高度复杂和多模式的信念分布时。ESCORT 结合了随机梯度变分法(SVGD) 和两个关键创新：了解状态维度之间的相关性并且加入时间一致性约束以保持更新的稳定性和相关的结构。此框架在多个POMDP域和合成多模态分布中表现优异，能够更好地进行信念逼近和决策质量。


<details>
  <summary>Details</summary>
Motivation: 解决标准数学模型无法准确捕捉实际环境中信念分布的复杂性，导致现有的POMDP信念近似方法无法准确表示复杂的不确定性结构，从而导致次优的行为表现的问题。

Method: ESCORT，一个基于粒子的框架，它扩展了SVGD，通过两个创新之处来解决上述问题：理解状态维度之间的依赖性，并在保留相关性结构的同时通过时间一致性约束来稳定更新。使用ESCORT能够更好地建模复杂的多模态分布，而不是像粒子滤波器那样容易退化，或者受固定表示容量限制的参数方法。

Result: ESCORT 在 POMDP 域和合成多模态分布中的各种维度上进行了广泛的评估，证明了其在信念逼近精度和下游决策质量方面优于最先进的方法。

Conclusion: ESCORT 是一个能够准确建模复杂多模态分布的框架，并且在POMDP环境中表现出色，有潜力替代当前的粒子滤波和参数方法。

Abstract: In Partially Observable Markov Decision Processes (POMDPs), maintaining and
updating belief distributions over possible underlying states provides a
principled way to summarize action-observation history for effective
decision-making under uncertainty. As environments grow more realistic, belief
distributions develop complexity that standard mathematical models cannot
accurately capture, creating a fundamental challenge in maintaining
representational accuracy. Despite advances in deep learning and probabilistic
modeling, existing POMDP belief approximation methods fail to accurately
represent complex uncertainty structures such as high-dimensional, multi-modal
belief distributions, resulting in estimation errors that lead to suboptimal
agent behaviors. To address this challenge, we present ESCORT (Efficient
Stein-variational and sliced Consistency-Optimized Representation for Temporal
beliefs), a particle-based framework for capturing complex, multi-modal
distributions in high-dimensional belief spaces. ESCORT extends SVGD with two
key innovations: correlation-aware projections that model dependencies between
state dimensions, and temporal consistency constraints that stabilize updates
while preserving correlation structures. This approach retains SVGD's
attractive-repulsive particle dynamics while enabling accurate modeling of
intricate correlation patterns. Unlike particle filters prone to degeneracy or
parametric methods with fixed representational capacity, ESCORT dynamically
adapts to belief landscape complexity without resampling or restrictive
distributional assumptions. We demonstrate ESCORT's effectiveness through
extensive evaluations on both POMDP domains and synthetic multi-modal
distributions of varying dimensionality, where it consistently outperforms
state-of-the-art methods in terms of belief approximation accuracy and
downstream decision quality.

</details>


### [87] [Distributionally Robust Feature Selection](https://arxiv.org/abs/2510.21113)
*Maitreyi Swaroop,Tamar Krishnamurti,Bryan Wilder*

Main category: cs.LG

TL;DR: 本研究探讨了在多个子人群中同时表现良好的模型中选择有限特征的问题。我们的方法通过连续松弛传统的变量选择方法，并使用一种不需要通过模型训练过程反向传播的噪音机制来解决这个问题。我们通过优化贝叶斯最优预测器的方差，发展了一个不同模型都能适应的框架，以平衡跨人群的下游预测的整体性能。我们在合成数据集和真实世界数据集上进行实验验证了我们的方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在需要对特征进行昂贵收集（例如添加调查问题或物理传感器）的情况下，选择有限的特征以便能够使用所选特征创建高质量的下游模型用于不同人群，这就是研究动机。在成本限制下，如何合理选择特征使模型在多个子人群中能保持高性能是关键问题。

Method: 我们的方法首先通过连续松弛传统变量选择的方式，然后采用不需反向传播的噪音机制的方式来解决问题。我们通过优化贝叶斯最优预测器的方差，来开发一个适用于不同模型的框架，该框架能够在跨人群的下游预测中保持良好的整体性能。这种方法的关键在于其能够在不需要模型训练过程的梯度信息时有效地解决特征选择问题。

Result: 通过实验验证，我们的方法在合成数据集和真实世界数据集上都表现良好，展现出了稳定的选择特征能力和跨不同人群的模型性能。

Conclusion: 研究显示，通过优化贝叶斯最优预测器的方差，我们可以有效地解决具有成本限制条件下的特征选择问题，确保所选特征能够支持跨人群的高质量下游模型的质量和性能。

Abstract: We study the problem of selecting limited features to observe such that
models trained on them can perform well simultaneously across multiple
subpopulations. This problem has applications in settings where collecting each
feature is costly, e.g. requiring adding survey questions or physical sensors,
and we must be able to use the selected features to create high-quality
downstream models for different populations. Our method frames the problem as a
continuous relaxation of traditional variable selection using a noising
mechanism, without requiring backpropagation through model training processes.
By optimizing over the variance of a Bayes-optimal predictor, we develop a
model-agnostic framework that balances overall performance of downstream
prediction across populations. We validate our approach through experiments on
both synthetic datasets and real-world data.

</details>


### [88] [SolarBoost: Distributed Photovoltaic Power Forecasting Amid Time-varying Grid Capacity](https://arxiv.org/abs/2510.21129)
*Linyuan Geng,Linxiao Yang,Xinyue Gu,Liang Sun*

Main category: cs.LG

TL;DR: SolarBoost是一种用于分布式光伏发电系统功率输出预测的新方法，它克服了现有集中式光伏系统方法难以应用于分布式系统的问题，通过建模小电网的聚合功率输出来提高预测准确性，并通过理论分析和实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的集中式光伏系统方法对于分布式光伏发电系统存在挑战，如缺乏电网级数据、装机容量的时空变化、地理变异性和面板多样性，导致难以准确预测。因此，需要一种新的方法来解决这些问题，提高分布式光伏系统的功率输出预测准确性。

Method: SolarBoost方法通过将聚合功率输出建模为小电网输出的组合，每个电网输出由单位输出函数与其容量的乘积表示，从而解耦均匀的单位输出函数与动态容量。提出了一种有效的算法来解决损失函数中的计算瓶颈。这种方法依据电网水平的建模，其优势来自理论分析和实验验证。

Result: SolarBoost在中国多个城市的部署实验中，成功降低了潜在损失，并为电力系统的运行提供了有价值的见解。代码已在GitHub上公开。

Conclusion: 通过理论分析和实验验证，证明了SolarBoost是一种克服分布式光伏系统预测挑战的有效方法，具有显著的技术优势和实际应用价值。

Abstract: This paper presents SolarBoost, a novel approach for forecasting power output
in distributed photovoltaic (DPV) systems. While existing centralized
photovoltaic (CPV) methods are able to precisely model output dependencies due
to uniformity, it is difficult to apply such techniques to DPV systems, as DPVs
face challenges such as missing grid-level data, temporal shifts in installed
capacity, geographic variability, and panel diversity. SolarBoost overcomes
these challenges by modeling aggregated power output as a composite of output
from small grids, where each grid output is modeled using a unit output
function multiplied by its capacity. This approach decouples the homogeneous
unit output function from dynamic capacity for accurate prediction. Efficient
algorithms over an upper-bound approximation are proposed to overcome
computational bottlenecks in loss functions. We demonstrate the superiority of
grid-level modeling via theoretical analysis and experiments. SolarBoost has
been validated through deployment across various cities in China, significantly
reducing potential losses and provides valuable insights for the operation of
power grids. The code for this work is available at
https://github.com/DAMO-DI-ML/SolarBoost.

</details>


### [89] [Cloud-Fog-Edge Collaborative Computing for Sequential MIoT Workflow: A Two-Tier DDPG-Based Scheduling Framework](https://arxiv.org/abs/2510.21135)
*Yuhao Fu,Yinghao Zhang,Yalin Liu,Bishenghui Tao,Junhong Ruan*

Main category: cs.LG

TL;DR: 本文提出了一种基于Two-tier DDPG的调度框架，用于在多层计算环境中最小化医疗物联网工作流的完成时间。实验结果表明，该框架的性能随着工作流复杂度的增加而优于基线方法，展示了其在学习长期策略方面的能力，这对于复杂的大型医疗物联网调度场景至关重要。


<details>
  <summary>Details</summary>
Motivation: 医疗物联网的需求是严格的端到端延迟保证，以支持部署在异构云-雾-边基础设施上的连续健康工作流。调度这些工作流以最小化完成时间是一个NP难问题。为此，作者提出了一种新的调度框架来解决这个问题。

Method: 提出的是一种基于DDPG的两级调度框架，其中全局控制器负责选择计算层（边缘、雾、云端），而特定的本地控制器负责在选定的层内进行节点分配。该框架的目标是最小化工作流的完成时间。

Result: 实验结果证明了所提出方法的有效性，展示了随着工作流复杂度的增加，该方法相对于基线方法的性能提升，表明其在学习长期有效策略方面具有优势。

Conclusion: 该框架的有效性已经通过实验验证，并显示出在处理复杂大规模医疗物联网调度场景中的潜在优势。

Abstract: The Medical Internet of Things (MIoT) demands stringent end-to-end latency
guarantees for sequential healthcare workflows deployed over heterogeneous
cloud-fog-edge infrastructures. Scheduling these sequential workflows to
minimize makespan is an NP-hard problem. To tackle this challenge, we propose a
Two-tier DDPG-based scheduling framework that decomposes the scheduling
decision into a hierarchical process: a global controller performs layer
selection (edge, fog, or cloud), while specialized local controllers handle
node assignment within the chosen layer. The primary optimization objective is
the minimization of the workflow makespan. Experiments results validate our
approach, demonstrating increasingly superior performance over baselines as
workflow complexity rises. This trend highlights the frameworks ability to
learn effective long-term strategies, which is critical for complex,
large-scale MIoT scheduling scenarios.

</details>


### [90] [Uncertainty-Aware Multi-Objective Reinforcement Learning-Guided Diffusion Models for 3D De Novo Molecular Design](https://arxiv.org/abs/2510.21153)
*Lianghong Chen,Dongkyu Eugene Kim,Mike Domaratzki,Pingzhao Hu*

Main category: cs.LG

TL;DR: 本文提出了一种不确定性感知的强化学习框架，用于优化3D分子扩散模型，以实现多目标属性优化，同时提高生成分子的整体质量。该框架在多个基准数据集和扩散模型架构上进行了全面评估，表现优于基线方法，并通过分子动力学模拟和ADMET评估显示出良好的药物特性。结果表明该方法有潜力用于自动化分子设计。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在生成3D分子结构时难以有效控制复杂的多目标约束，本文旨在通过引入不确定性感知的强化学习框架，改善这一问题，提高分子生成的质量和多目标属性优化。

Method: 提出一种利用具有预测不确定性估计的替代模型动态塑造奖励函数的方法，以指导3D分子扩散模型的优化。通过多个数据集和模型架构验证该方法的有效性。

Result: 方法在分子质量及多属性优化方面优于基线方法。并通过分子动力学和ADMET实验验证了生成分子的药物特性和结合稳定性，表现与已知的EGFR抑制剂相当。

Conclusion: 通过RL引导的生成扩散模型，本文展示了在自动化分子设计上的潜力和价值。

Abstract: Designing de novo 3D molecules with desirable properties remains a
fundamental challenge in drug discovery and molecular engineering. While
diffusion models have demonstrated remarkable capabilities in generating
high-quality 3D molecular structures, they often struggle to effectively
control complex multi-objective constraints critical for real-world
applications. In this study, we propose an uncertainty-aware Reinforcement
Learning (RL) framework to guide the optimization of 3D molecular diffusion
models toward multiple property objectives while enhancing the overall quality
of the generated molecules. Our method leverages surrogate models with
predictive uncertainty estimation to dynamically shape reward functions,
facilitating balance across multiple optimization objectives. We
comprehensively evaluate our framework across three benchmark datasets and
multiple diffusion model architectures, consistently outperforming baselines
for molecular quality and property optimization. Additionally, Molecular
Dynamics (MD) simulations and ADMET profiling of top generated candidates
indicate promising drug-like behavior and binding stability, comparable to
known Epidermal Growth Factor Receptor (EGFR) inhibitors. Our results
demonstrate the strong potential of RL-guided generative diffusion models for
advancing automated molecular design.

</details>


### [91] [A Unified Matrix Factorization Framework for Classical and Robust Clustering](https://arxiv.org/abs/2510.21172)
*Angshul Majumdar*

Main category: cs.LG

TL;DR: 本文提出了一种统一的矩阵分解框架，用于经典和鲁棒聚类。该框架基于经典的k-means聚类和矩阵分解之间的等价性，并推导出模糊c-means聚类的矩阵分解解释。为了增强鲁棒性，使用了l1,2范数替代弗罗贝尼乌斯范数。并为标准和鲁棒的聚类设计了交替最小化和迭代重加权最小化算法，所有算法都证明可以收敛到局部最小值。


<details>
  <summary>Details</summary>
Motivation: 基于传统的k-means聚类和矩阵分解之间的联系，本文旨在通过矩阵分解的视角来改进和理解经典聚类方法，并通过引入鲁棒范数来提高聚类的健壮性，特别是对异常值的处理。

Method: 该方法通过重新探讨k-means和矩阵分解之间的等价性，并推导出模糊c-means聚类的矩阵分解公式。进一步，将经典的范数替换为l1,2范数以增加鲁棒性，并开发了对应的优化算法，包括交替最小化和IRLS算法。

Result: 结果表明，所提出的矩阵分解框架不仅可以应用于传统的聚类方法，也可以被轻易地扩展到鲁棒性更强的聚类算法中。提出的算法在理论上被证明是收敛的。通过替代范数的方法提高了聚类的鲁棒性。

Conclusion: 文章通过矩阵分解的角度总结了经典k-means和模糊c-means聚类方法，并证明了这种替代方法可以帮助处理数据集中存在的异常值问题，提高聚类的健壮性。

Abstract: This paper presents a unified matrix factorization framework for classical
and robust clustering. We begin by revisiting the well-known equivalence
between crisp k-means clustering and matrix factorization, following and
rigorously rederiving an unpublished formulation by Bauckhage. Extending this
framework, we derive an analogous matrix factorization interpretation for fuzzy
c-means clustering, which to the best of our knowledge has not been previously
formalized. These reformulations allow both clustering paradigms to be
expressed as optimization problems over factor matrices, thereby enabling
principled extensions to robust variants. To address sensitivity to outliers,
we propose robust formulations for both crisp and fuzzy clustering by replacing
the Frobenius norm with the l1,2-norm, which penalizes the sum of Euclidean
norms across residual columns. We develop alternating minimization algorithms
for the standard formulations and IRLS-based algorithms for the robust
counterparts. All algorithms are theoretically proven to converge to a local
minimum.

</details>


### [92] [A visual big data system for the prediction of weather-related variables: Jordan-Spain case study](https://arxiv.org/abs/2510.21176)
*Shadi Aljawarneh,Juan A. Lara,Muneer Bani Yassein*

Main category: cs.LG

TL;DR: 提出了一种基于大数据和数据挖掘技术的气象数据分析系统，该系统能够处理大量气象数据，并进行预测性任务。系统基于NoSQL数据库存储和分析数据，评估显示其预测性能强劲，专家对其持积极态度。


<details>
  <summary>Details</summary>
Motivation: 气象领域的数据具有高维度、高量级、缺失值频率高等特点，因此需要利用大数据和数据挖掘技术来处理这些数据并提取有用的知识。为了预测气象现象，我们需要一个能够处理大量气象相关数据的系统，该系统可以融合不同的时空数据，进行预测分析。

Method: 该系统收集开放数据并将它们加载到本地NoSQL数据库，对数据进行不同的时间、空间层次的整合，以便利用单变量和多变量的方法，进行预测性分析。对于有大量缺失值的情况，使用邻近站的数据进行训练并进行预测。

Result: 该系统在可用性和预测性能方面进行了评估，获得了整体归一化的均方误差值为0.00013，方向对称性接近0.84；并且，一组领域专家从图形设计之外的各个方面评价都非常高，打出3分以上的平均分，表明该系统获得了积极的反馈。初步结果表明该系统是可行且有效的，可进一步优化和发展。

Conclusion: 该系统利用大数据和数据挖掘技术处理气象相关数据，能够进行预测性分析，结果显示其预测性能优异，是处理此类数据的有效工具，可进一步优化和发展。

Abstract: The Meteorology is a field where huge amounts of data are generated, mainly
collected by sensors at weather stations, where different variables can be
measured. Those data have some particularities such as high volume and
dimensionality, the frequent existence of missing values in some stations, and
the high correlation between collected variables. In this regard, it is crucial
to make use of Big Data and Data Mining techniques to deal with those data and
extract useful knowledge from them that can be used, for instance, to predict
weather phenomena. In this paper, we propose a visual big data system that is
designed to deal with high amounts of weather-related data and lets the user
analyze those data to perform predictive tasks over the considered variables
(temperature and rainfall). The proposed system collects open data and loads
them onto a local NoSQL database fusing them at different levels of temporal
and spatial aggregation in order to perform a predictive analysis using
univariate and multivariate approaches as well as forecasting based on training
data from neighbor stations in cases with high rates of missing values. The
system has been assessed in terms of usability and predictive performance,
obtaining an overall normalized mean squared error value of 0.00013, and an
overall directional symmetry value of nearly 0.84. Our system has been rated
positively by a group of experts in the area (all aspects of the system except
graphic desing were rated 3 or above in a 1-5 scale). The promising preliminary
results obtained demonstrate the validity of our system and invite us to keep
working on this area.

</details>


### [93] [Reducing the Probability of Undesirable Outputs in Language Models Using Probabilistic Inference](https://arxiv.org/abs/2510.21184)
*Stephen Zhao,Aidan Li,Rob Brekelmans,Roger Grosse*

Main category: cs.LG

TL;DR: 介绍了一种新的强化学习训练方法RePULSe，通过额外的训练损失来减少不期望的输出概率，同时保持平均奖励水平。这种方法在实验中表现出更好的期望奖励与不期望输出概率之间的平衡，以及更强的对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了改善当前强化学习方法在减少不期望输出概率同时保持平均奖励水平的缺点，引入了一种新的训练方法。

Method: RePULSe 方法是在标准的强化学习损失基础上增加了一个新的损失，通过学习到的提议来指导采样低奖励的输出，进而减少这些输出的概率。

Result: 实验表明，RePULSe 方法在平均奖励和不期望输出概率之间取得了更好的权衡，并且在对抗性鲁棒性方面也优于标准的强化学习方法和其他替代方案。

Conclusion: RePULSe 方法提供了一种改善强化学习模型表现的技术，特别强调了减少不期望输出的概率，同时维持或甚至提高其在期望任务上的性能，增强了模型的对抗性鲁棒性。

Abstract: Reinforcement learning (RL) has become a predominant technique to align
language models (LMs) with human preferences or promote outputs which are
deemed to be desirable by a given reward function. Standard RL approaches
optimize average reward, while methods explicitly focused on reducing the
probability of undesired outputs typically come at a cost to average-case
performance. To improve this tradeoff, we introduce RePULSe, a new training
method that augments the standard RL loss with an additional loss that uses
learned proposals to guide sampling low-reward outputs, and then reduces those
outputs' probability. We run experiments demonstrating that RePULSe produces a
better tradeoff of expected reward versus the probability of undesired outputs
and is more adversarially robust, compared to standard RL alignment approaches
and alternatives.

</details>


### [94] [PLAN: Proactive Low-Rank Allocation for Continual Learning](https://arxiv.org/abs/2510.21188)
*Xiequn Wang,Zhan Zhuang,Yu Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种新的框架PLAN，通过引入正交基向量和新的选择机制，使得大模型在持续学习过程中更加高效且减少干扰，实验显示PLAN在持续学习基准测试中优于现有方法，建立了新的性能标准。 


<details>
  <summary>Details</summary>
Motivation: 持续学习要求模型在适应新任务时不能忘记过去的知识。为了实现这一目标，PLAN框架通过引入正交基向量和优化策略来最小化与先前学习参数的冲突，从而在持续学习设置中进行有效的微调。 

Method: PLAN框架通过为每个任务引入正交基向量，并通过基于扰动的策略优化这些向量来管理任务特定子空间的分配。此外，它还包含了一种新的选择机制，该机制可以识别并分配对干扰敏感性最小的基础向量。 

Result: 在持续学习基准测试上进行的实证研究显示，PLAN方法始终优于现有的方法，证明了其在利用基础模型的持续学习中的性能优越性。 

Conclusion: PLAN通过其创新的方法在持续学习任务中实现了高效且低干扰的微调，并为大型预训练模型在持续学习中的应用建立了一个新的性能标准。

Abstract: Continual learning (CL) requires models to continuously adapt to new tasks
without forgetting past knowledge. In this work, we propose
\underline{P}roactive \underline{L}ow-rank \underline{A}llocatio\underline{N}
(PLAN), a framework that extends Low-Rank Adaptation (LoRA) to enable efficient
and interference-aware fine-tuning of large pre-trained models in CL settings.
PLAN proactively manages the allocation of task-specific subspaces by
introducing orthogonal basis vectors for each task and optimizing them through
a perturbation-based strategy that minimizes conflicts with previously learned
parameters. Furthermore, PLAN incorporates a novel selection mechanism that
identifies and assigns basis vectors with minimal sensitivity to interference,
reducing the risk of degrading past knowledge while maintaining efficient
adaptation to new tasks. Empirical results on standard CL benchmarks
demonstrate that PLAN consistently outperforms existing methods, establishing a
new state-of-the-art for continual learning with foundation models.

</details>


### [95] [Gen-Review: A Large-scale Dataset of AI-Generated (and Human-written) Peer Reviews](https://arxiv.org/abs/2510.21192)
*Luca Demetrio,Giovanni Apruzzese,Kathrin Grosse,Pavel Laskov,Emil Lupu,Vera Rimmer,Philine Widmer*

Main category: cs.LG

TL;DR: 介绍GenReview，一个包含8.1万篇由大型语言模型（LLM）生成的审稿意见的数据集，用以研究LLM在科学审稿中的应用及其影响。该数据集涵盖了2018年至2025年间ICLR所有提交论文的审稿意见，并与原论文及其原始审稿意见关联，以支持广泛的研究。研究已展示了一些初步成果，如LLM存在偏见、生成的审稿意见可被自动识别、有时不能严格遵循指南以及评分与论文是否被接受不完全一致。


<details>
  <summary>Details</summary>
Motivation: 为了更全面地理解大型语言模型在科学评审中的作用及其影响，需要一个相关的、综合的数据集，这填补了当前研究上的空白。因此，本文介绍了GenReview，这是一个致力于解决上述问题的数据集，通过提供生成81K篇审稿意见的数据，它能够帮助研究者探讨多项重要问题，包括LLM是否带有偏见、它们生成的审稿意见能否被自动鉴别以及它们是否能严格遵循审查指导等。

Method: 通过提供给LLM三种独立的提示（即负面、正面和中立的提示）来生成2018-2025年间ICLR所有论文提交的8.1万篇审稿意见。这些审稿意见与相应的论文及其原始审稿意见链接起来，为深入研究提供了可能。随后，研究者使用这些数据集探讨了多项研究课题，包括LLM生成审稿的偏见、自动检测生成审稿的能力以及遵循指导准则的情况等。结果表明，该数据集确实可以帮助捕获LLM在流水线审查中的各种行为。

Result: 通过对GenReview数据集的探索，研究者发现LLM在其生成的审稿里显示出了偏见，并且LLM生成的审稿意见可以通过算法进行有效识别。此外，还发现了LLM并不总是能严格遵守评审指南，同时，审查意见中的推荐评价仅在推荐接受时与最终决策有一定的吻合。这些发现为未来更深入的研究提供了宝贵的见解。

Conclusion: GenReview利用大型语言模型生成了大量的审稿意见，相对于历史上类似的尝试，它在规模上有了显著的增加。该数据集不仅填补了关于大型语言模型在科学审稿中的作用的研究空白，而且通过总结的初步研究提供了大量的数据和见解，说明这些数据集对科学评审过程的影响具有重要的意义。

Abstract: How does the progressive embracement of Large Language Models (LLMs) affect
scientific peer reviewing? This multifaceted question is fundamental to the
effectiveness -- as well as to the integrity -- of the scientific process.
Recent evidence suggests that LLMs may have already been tacitly used in peer
reviewing, e.g., at the 2024 International Conference of Learning
Representations (ICLR). Furthermore, some efforts have been undertaken in an
attempt to explicitly integrate LLMs in peer reviewing by various editorial
boards (including that of ICLR'25). To fully understand the utility and the
implications of LLMs' deployment for scientific reviewing, a comprehensive
relevant dataset is strongly desirable. Despite some previous research on this
topic, such dataset has been lacking so far. We fill in this gap by presenting
GenReview, the hitherto largest dataset containing LLM-written reviews. Our
dataset includes 81K reviews generated for all submissions to the 2018--2025
editions of the ICLR by providing the LLM with three independent prompts: a
negative, a positive, and a neutral one. GenReview is also linked to the
respective papers and their original reviews, thereby enabling a broad range of
investigations. To illustrate the value of GenReview, we explore a sample of
intriguing research questions, namely: if LLMs exhibit bias in reviewing (they
do); if LLM-written reviews can be automatically detected (so far, they can);
if LLMs can rigorously follow reviewing instructions (not always) and whether
LLM-provided ratings align with decisions on paper acceptance or rejection
(holds true only for accepted papers). GenReview can be accessed at the
following link: https://anonymous.4open.science/r/gen_review.

</details>


### [96] [Online AUC Optimization Based on Second-order Surrogate Loss](https://arxiv.org/abs/2510.21202)
*JunRu Luo,Difei Cheng,Bo Zhang*

Main category: cs.LG

TL;DR: 我们提出了一种基于pairwise hinge loss的新二阶替代损失，并开发了一种高效的在线算法。与其他方法相比，我们的方法能更有效地优化在线AUC性能，并在多个基准数据集上表现出更高的效率和有效性。理论分析表明，我们的方法相较于现有在线AUC优化算法，可以达到更紧的O(ln T)遗憾边界，而不是普通的O(√T)遗憾边界。此外，还通过核方法扩展了提出的框架，用于非线性设置.


<details>
  <summary>Details</summary>
Motivation: 传统的在线AUC优化方法面临挑战，包括pairwise 0/1损失函数的非凸性和不连续性，以及大规模应用中实例存储所带来的记忆成本瓶颈。为了克服这些挑战，本研究提出了一种新的基于二阶统计的替代损失方法。此外，还引入了一种新的直接替代整个积累成对损失的替代损失函数的范式，解决传统方法只能通过近似每个成对0/1损失项来实现的问题。适用于在非线性设置中优化在线AUC性能同时也提出了一个改进的方法，该方法可以通过核技巧扩展到非线性设置中.

Method: 提出一种新的基于pairwise hinge loss的二阶替代损失方法，通过使用训练数据的第一和第二阶统计信息来直接替代整个积累的成对损失。此外，还利用核技巧将框架扩展到非线性设置。通过这种方法，不仅能降低样本存储需求，同时也提高了算法效率。从而克服了传统方法所面临的挑战.

Result: 我们所提出的基于二阶统计的替代损失方法在多个数据集上显示了良好的效率和有效性。理论分析表明，该方法相较于现有算法，可以获得更紧的遗憾边界。实验结果也表明该方法在优化在线AUC性能方面具有显著的优势。此外，对于非线性场景，采用核方法后，同样表现出优异的性能.

Conclusion: 该研究提出了一种新的基于二阶统计的替代损失方法，该方法不仅可以有效解决在线AUC优化中的挑战，还能改善算法的遗憾边界。此外，所提出的方法也适用于非线性场景，并且实验结果表明，该方法在优化在线AUC性能方面具有广泛的适用性和较高的效率与有效性。

Abstract: The Area Under the Curve (AUC) is an important performance metric for
classification tasks, particularly in class-imbalanced scenarios. However,
minimizing the AUC presents significant challenges due to the non-convex and
discontinuous nature of pairwise 0/1 losses, which are difficult to optimize,
as well as the substantial memory cost of instance-wise storage, which creates
bottlenecks in large-scale applications. To overcome these challenges, we
propose a novel second-order surrogate loss based on the pairwise hinge loss,
and develop an efficient online algorithm. Unlike conventional approaches that
approximate each individual pairwise 0/1 loss term with an instance-wise
surrogate function, our approach introduces a new paradigm that directly
substitutes the entire aggregated pairwise loss with a surrogate loss function
constructed from the first- and second-order statistics of the training data.
Theoretically, while existing online AUC optimization algorithms typically
achieve an $\mathcal{O}(\sqrt{T})$ regret bound, our method attains a tighter
$\mathcal{O}(\ln T)$ bound. Furthermore, we extend the proposed framework to
nonlinear settings through a kernel-based formulation. Extensive experiments on
multiple benchmark datasets demonstrate the superior efficiency and
effectiveness of the proposed second-order surrogate loss in optimizing online
AUC performance.

</details>


### [97] [Mitra: Mixed Synthetic Priors for Enhancing Tabular Foundation Models](https://arxiv.org/abs/2510.21204)
*Xiyuan Zhang,Danielle C. Maddix,Junming Yin,Nick Erickson,Abdul Fatir Ansari,Boran Han,Shuai Zhang,Leman Akoglu,Christos Faloutsos,Michael W. Mahoney,Cuixiong Hu,Huzefa Rangwala,George Karypis,Bernie Wang*

Main category: cs.LG

TL;DR: 本文研究了基于in-context learning的表型基础模型的设计原则，并提出了一种名为Mitra的新模型，该模型在分类和回归基准上都优于现有的模型，具有更好的样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有的表型基础模型在使用由合成数据集预训练的模型时，其性能依赖于合成数据集的设计。目前关于合成数据集设计的原则理解尚不清楚。本研究试图填补这个空白，研究设计合成先验的关键属性，使预训练的表型基础模型能够很好地泛化。

Method: 系统地研究和识别了使预训练表型基础模型能够很好地泛化的合成先验的关键属性，基于这些见解，引入了名为Mitra的新模型，该模型是在一群具有多样性和独特性的合成先验的混合数据集上训练的。

Result: 提出的方法和模型Mitra在分类和回归基准上一直优于现有的先进表型基础模型，如TabPFNv2和TabICL，展示了更好的样本效率。

Conclusion: 文章通过研究使表型基础模型能够很好地泛化的合成先验的关键属性，并通过引入模型Mitra证明了该研究的有效性。这种方法和模型可以为未来表型机器学习的发展提供指导。

Abstract: Since the seminal work of TabPFN, research on tabular foundation models
(TFMs) based on in-context learning (ICL) has challenged long-standing
paradigms in machine learning. Without seeing any real-world data, models
pretrained on purely synthetic datasets generalize remarkably well across
diverse datasets, often using only a moderate number of in-context examples.
This shifts the focus in tabular machine learning from model architecture
design to the design of synthetic datasets, or, more precisely, to the prior
distributions that generate them. Yet the guiding principles for prior design
remain poorly understood. This work marks the first attempt to address the gap.
We systematically investigate and identify key properties of synthetic priors
that allow pretrained TFMs to generalize well. Based on these insights, we
introduce Mitra, a TFM trained on a curated mixture of synthetic priors
selected for their diversity, distinctiveness, and performance on real-world
tabular data. Mitra consistently outperforms state-of-the-art TFMs, such as
TabPFNv2 and TabICL, across both classification and regression benchmarks, with
better sample efficiency.

</details>


### [98] [Model Merging with Functional Dual Anchors](https://arxiv.org/abs/2510.21223)
*Kexuan Shi,Yandong Wen,Weiyang Liu*

Main category: cs.LG

TL;DR: 本文提出了一种新的模型合并框架，即功能双锚点（FDAs），该框架通过合成输入来模拟输入-表示空间，从而捕获任务特异性的功能偏移，进而提供了一种比现有参数空间方法更有效和灵活的模型合并方式。


<details>
  <summary>Details</summary>
Motivation: 模型合并是一种有效的方法，用于整合多个微调检查点的知识。但是，现有的模型合并方法在参数空间操作，难以解决参数不一致的问题。为了解决这一问题，提出了FDAs，可以直接捕获任务特定的功能偏移，而不只是结合任务向量，从而提供了一种更优越的模型合并方式。

Method: FDAs是合成输入，这些输入的诱导梯度与任务向量对齐，因此可以捕获相对于预训练模型的任务特定功能性偏移。框架还包括一种合理初始化方案，该方案可以与参数空间模型合并互补。

Result: 实验表明，FDAs在模型合并中表现出色，提供了与现有参数空间方法不同的视角和改进的性能。

Conclusion: FDAs框架为模型合并提供了一种新的解决方案，这种方法更稳健，也在输入-表示空间而不是参数空间中操作，从而解决了参数不一致的问题。

Abstract: Model merging is an efficient post-training strategy for integrating
knowledge from multiple finetuned checkpoints of a shared foundation model.
Existing methods operate in the parameter space, combining task vectors to
mitigate conflicts, but remain constrained by parameter inconsistencies. We
propose Functional Dual Anchors (FDAs), a framework that instead models the
input-representation space. FDAs are synthetic inputs whose induced gradients
align with task vectors, capturing task-specific functional shifts relative to
the pretrained model. This perspective bridges joint multi-task training and
post-hoc merging, offering both robustness and flexibility. We further
introduce a principled initialization scheme and show that FDAs are
complementary to parameter-space model merging. Comprehensive experiments
demonstrate the effectiveness of FDAs in model merging.

</details>


### [99] [Convergence of Stochastic Gradient Langevin Dynamics in the Lazy Training Regime](https://arxiv.org/abs/2510.21245)
*Noah Oberweis,Semih Cayci*

Main category: cs.LG

TL;DR: 该论文对随机梯度兰杰维过程（SGLD）进行了非渐近收敛性分析，在懒惰训练体制下，提出了SGLD在高概率下得到非退化解核和期望下指数收敛到经验风险最小化器的理论，并建立了有限时间与有限宽度下的最优差距界.


<details>
  <summary>Details</summary>
Motivation: 在深度学习中，连续时间模型对优化算法的训练动态提供了重要的见解. 作者旨在建立一种对随机梯度兰杰维过程（SGLD）的非渐近收敛性分析，特别是在懒惰训练体制下.

Method: 通过考虑损失函数基解矩阵的规范性条件，作者研究了SGLD在多种状态相关噪声下的收敛性质.

Result: 研究表明SGLD能够以指数速度收敛到经验风险极小值，同时保持非退化核性质，且作者对收敛速率设置了有限时间与有限宽度的情形下的最优差距界.

Conclusion: 理论分析得到了数值仿真的支持，并在回归任务中得到了验证.

Abstract: Continuous-time models provide important insights into the training dynamics
of optimization algorithms in deep learning. In this work, we establish a
non-asymptotic convergence analysis of stochastic gradient Langevin dynamics
(SGLD), which is an It\^o stochastic differential equation (SDE) approximation
of stochastic gradient descent in continuous time, in the lazy training regime.
We show that, under regularity conditions on the Hessian of the loss function,
SGLD with multiplicative and state-dependent noise (i) yields a non-degenerate
kernel throughout the training process with high probability, and (ii) achieves
exponential convergence to the empirical risk minimizer in expectation, and we
establish finite-time and finite-width bounds on the optimality gap. We
corroborate our theoretical findings with numerical examples in the regression
setting.

</details>


### [100] [Unified Implementations of Recurrent Neural Networks in Multiple Deep Learning Frameworks](https://arxiv.org/abs/2510.21252)
*Francesco Martinuzzi*

Main category: cs.LG

TL;DR: 论文介绍了三个开源库（torchrecurrent，RecurrentLayers.jl 和 LuxRecurrentLayers.jl），这些库提供了统一的框架来构建和扩展RNN模型，包括许多递归单元的实现和更高层次的递归架构，便于自定义和实验。


<details>
  <summary>Details</summary>
Motivation: 由于没有中央库来测试各种RNN变体，并且重新实现各种架构既耗时又容易出错，这限制了可重复性和探索性。因此，此研究介绍了三个开源库，方便研究人员测试和实验不同的RNN架构。

Method: 提出了在Julia和Python中使用的三个开源库——torchrecurrent，RecurrentLayers.jl 和 LuxRecurrentLayers.jl，这些库提供了构建和扩展RNN模型的统一框架，内置机制支持自定义和实验。

Result: 提出了三个易于使用的开源库，便于研究人员快速构建和实验不同的RNN模型，提高了可复制性和探索性。这些库在GitHub上自由提供，并且是MIT许可下的活跃维护项目。

Conclusion: 这三个库提供了一个统一的框架来构建和扩展RNN模型，研究人员可以利用这些库进行自定义和实验，大大提高了研究效率。

Abstract: Recurrent neural networks (RNNs) are a cornerstone of sequence modeling
across various scientific and industrial applications. Owing to their
versatility, numerous RNN variants have been proposed over the past decade,
aiming to improve the modeling of long-term dependencies and to address
challenges such as vanishing and exploding gradients. However, no central
library is available to test these variations, and reimplementing diverse
architectures can be time-consuming and error-prone, limiting reproducibility
and exploration. Here, we introduce three open-source libraries in Julia and
Python that centralize numerous recurrent cell implementations and higher-level
recurrent architectures. torchrecurrent, RecurrentLayers.jl, and
LuxRecurrentLayers.jl offer a consistent framework for constructing and
extending RNN models, providing built-in mechanisms for customization and
experimentation. All packages are available under the MIT license and actively
maintained on GitHub.

</details>


### [101] [PINN Balls: Scaling Second-Order Methods for PINNs with Domain Decomposition and Adaptive Sampling](https://arxiv.org/abs/2510.21262)
*Andrea Bonfanti,Ismael Medina,Roman List,Björn Staeves,Roberto Santana,Marco Ellero*

Main category: cs.LG

TL;DR: 本文提出了一个新的方法PINN Balls，它结合了局部专家混合模型和稀疏编码，能够使用二阶训练方法，同时通过对抗自适应采样保持可扩展性。该方法在科学机器学习领域中比最新的方法更准确，同时具备可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统的数值方法和一阶训练方法在处理部分微分方程时可能存在效率问题，尤其是当模型规模较大时，二阶方法虽然能够提升PINNs的训练效果，但存在内存需求过大的问题。因此，本文旨在提出一个新的方法，即能够使用二阶训练，又可以保持模型的可扩展性，同时具备理论基础。

Method: 该方法使用了局部专家混合模型和稀疏编码技术，这种组合能够减少内存需求，提高训练效率。同时，提出了对抗自适应采样技术，用于调整分解结构以适应不同的PDE和域。方法名为‘PINN Balls’，在保持可扩展性的基础上，能够更好地应用于科学机器学习的场景。

Result: 实验结果表明，提出的‘PINN Balls’模型不仅比现有的SOTA方法在科学机器学习中更准确，而且还能有效地应对大规模模型的挑战，保持运行效率。通过引入对抗自适应采样，该模型能动态地调整其内部结构，使其能够更好地适应不同的PDE和域。

Conclusion: 总结来说，我们提出了一种基于PINN Balls的模型，通过结合局部专家混合模型和稀疏编码，以及对抗自适应采样，提出的方法在科学机器学习领域中提供了更准确的结果，同时保持了大规模模型的可扩展性，具有广阔的应用前景。

Abstract: Recent advances in Scientific Machine Learning have shown that second-order
methods can enhance the training of Physics-Informed Neural Networks (PINNs),
making them a suitable alternative to traditional numerical methods for Partial
Differential Equations (PDEs). However, second-order methods induce large
memory requirements, making them scale poorly with the model size. In this
paper, we define a local Mixture of Experts (MoE) combining the
parameter-efficiency of ensemble models and sparse coding to enable the use of
second-order training. Our model -- \textsc{PINN Balls} -- also features a
fully learnable domain decomposition structure, achieved through the use of
Adversarial Adaptive Sampling (AAS), which adapts the DD to the PDE and its
domain. \textsc{PINN Balls} achieves better accuracy than the state-of-the-art
in scientific machine learning, while maintaining invaluable scalability
properties and drawing from a sound theoretical background.

</details>


### [102] [A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization](https://arxiv.org/abs/2510.21314)
*Xuan Tang,Jichu Li,Difan Zou*

Main category: cs.LG

TL;DR: 本文提出了第一个适应性优化器在浮点量化下的收敛理论框架，并分析了Adam和Muon在不同量化误差下的收敛特性，指出低精度训练的有效性及其限域条件。


<details>
  <summary>Details</summary>
Motivation: 现有的适应性优化器收敛理论假定所有组件都是精确的，并忽视了硬件感知量化，而当前低精度训练的实际效果并未在理论上得到解释。

Method: 构建了一个理论框架来分析在梯度、权重、优化器状态量化下的适应性优化器（如Adam和Muon）的收敛性，详细推导了在平滑非凸目标下的收敛速率，并研究了量化误差的影响。

Result: 证明了在特定条件下，这两个优化器的收敛速率接近其全精度版本，同时，Adam对权重和第二矩量化的敏感性更强，Muon对误差的控制要求更低，可能更加鲁棒。实验结果验证了理论发现。

Conclusion: 本文理论地解释了低精度训练方法的成功，同时指出了实现这种成功所需的条件，进一步推动了这一领域的研究。

Abstract: The rapid scaling of large language models (LLMs) has made low-precision
training essential for reducing memory, improving efficiency, and enabling
larger models and datasets. Existing convergence theories for adaptive
optimizers, however, assume all components are exact and neglect hardware-aware
quantization, leaving open the question of why low-precision training remains
effective. We introduce the first theoretical framework for analyzing the
convergence of adaptive optimizers, including Adam and Muon, under
floating-point quantization of gradients, weights, and optimizer states (e.g.,
moment estimates). Within this framework, we derive convergence rates on smooth
non-convex objectives under standard stochastic gradient assumptions,
explicitly characterizing how quantization errors from different components
affect convergence. We show that both algorithms retain rates close to their
full-precision counterparts provided mantissa length scales only
logarithmically with the number of iterations. Our analysis further reveals
that Adam is highly sensitive to weights and second-moment quantization due to
its reliance on $\beta_2 \to 1$, while Muon requires weaker error control and
is thus potentially more robust. These results narrow the gap between empirical
success and theoretical understanding of low-precision training methods.
Numerical experiments on synthetic and real-world data corroborate our theory.

</details>


### [103] [An Evidence-Based Post-Hoc Adjustment Framework for Anomaly Detection Under Data Contamination](https://arxiv.org/abs/2510.21296)
*Sukanya Patra,Souhaib Ben Taieb*

Main category: cs.LG

TL;DR: 提出了一种测试时适应框架EPHAD，用于增强基于受污染数据集训练的异常检测模型的性能，通过整合由多模态基础模型和经典AD方法获取的证据。


<details>
  <summary>Details</summary>
Motivation: 现有的非监督异常检测方法假设数据集干净，但在实际应用中，数据集往往含有未检测到或标签错误的异常。这些问题限制了现有解决方案的实际应用性，因此提出EPHAD改善此类问题。 

Method: EPHAD框架在测试时间利用多模态基础模型（如CLIP）和经典AD方法（如Latent Outlier Factor）的证据来更新基于受污染数据集训练的异常检测模型的输出。

Result: 通过在各种视觉、表格和工业异常检测数据集上的实验，验证了EPHAD的有效性。同时，进行的消融实验显示了EPHAD对不同异常检测模型和证据对的适应性和鲁棒性。

Conclusion: EPHAD提供了一种强大且灵活的方法来提高异常检测模型的性能，特别是在训练数据污染的情况下。相关代码已经在GitHub公开。

Abstract: Unsupervised anomaly detection (AD) methods typically assume clean training
data, yet real-world datasets often contain undetected or mislabeled anomalies,
leading to significant performance degradation. Existing solutions require
access to the training pipelines, data or prior knowledge of the proportions of
anomalies in the data, limiting their real-world applicability. To address this
challenge, we propose EPHAD, a simple yet effective test-time adaptation
framework that updates the outputs of AD models trained on contaminated
datasets using evidence gathered at test time. Our approach integrates the
prior knowledge captured by the AD model trained on contaminated datasets with
evidence derived from multimodal foundation models like Contrastive
Language-Image Pre-training (CLIP), classical AD methods like the Latent
Outlier Factor or domain-specific knowledge. We illustrate the intuition behind
EPHAD using a synthetic toy example and validate its effectiveness through
comprehensive experiments across eight visual AD datasets, twenty-six tabular
AD datasets, and a real-world industrial AD dataset. Additionally, we conduct
an ablation study to analyse hyperparameter influence and robustness to varying
contamination levels, demonstrating the versatility and robustness of EPHAD
across diverse AD models and evidence pairs. To ensure reproducibility, our
code is publicly available at https://github.com/sukanyapatra1997/EPHAD.

</details>


### [104] [Weak-to-Strong Generalization under Distribution Shifts](https://arxiv.org/abs/2510.21332)
*Myeongho Jeon,Jan Sobotka,Suhwan Choi,Maria Brbić*

Main category: cs.LG

TL;DR: 本文提出了RAVEN框架，该框架能够在分布变化的情况下有效监督强大的模型，通过动态学习弱模型的最优组合来提升性能，结果表明RAVEN在跨分布任务上优于基线，能够自动识别可靠的监督源。


<details>
  <summary>Details</summary>
Motivation: 当前情况是，随着模型变得越来越复杂，人类监督模型的行为可能会变得不可行。而简单的弱到强泛化方法在分布迁移的情况下会失效，这导致了模型效果变差的问题。因此作者提出了RAVEN框架来解决这一问题。

Method: RAVEN框架能够动态地学习弱模型的最优组合以及强大的模型参数，这样的方案有效提升了弱对强的泛化能力。

Result: 实验表明，RAVEN在跨分布任务上优于基线，在一些任务上性能提升了30%以上，在分布内任务上性能与当前现有方法相当或更好，而分派的权重也反映了弱模型的实际准确性。

Conclusion: RAVEN解决方案提升了在分布迁移情况下的弱对强模型监督的有效性，能够自动识别可信的监督源，有效地泛化的能力得到了提高。

Abstract: As future superhuman models become increasingly complex, accurately
supervising their behavior may exceed human capabilities. Recent works have
demonstrated that in such scenarios, weak models can effectively supervise
strong models, a phenomenon known as weak-to-strong generalization. However, we
find that naive weak-to-strong generalization fails under distribution shifts,
often leading to worse performance of the strong model than its weak
supervisors. To address this, we propose RAVEN, a robust weak-to-strong
generalization framework that dynamically learns the optimal combinations of
weak models in addition to parameters of the strong model. We demonstrate the
effectiveness of RAVEN on image classification, text classification, and
preference alignment tasks. RAVEN outperforms alternative baselines by over 30%
on out-of-distribution tasks while matching or surpassing existing methods on
in-distribution tasks. Moreover, our results show that RAVEN assigns higher
weights to more accurate weak models, demonstrating its ability to
automatically identify trustworthy supervision.

</details>


### [105] [$α$-LoRA: Effective Fine-Tuning via Base Model Rescaling](https://arxiv.org/abs/2510.21345)
*Aymane El Firdoussi,El Mahdi Chayti,Mohamed El Amine Seddik,Martin Jaggi*

Main category: cs.LG

TL;DR: 本文提出了一个新的再参数化方法类别，用以提升微调模型的泛化能力。研究通过随机矩阵理论和在高维二元分类设置中的实验，验证了新方法的有效性，并进一步通过微调LLMs的实验验证了其理论结果的正确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高微调模型的泛化能力，特别是当数据样本较少时的情况，本文提出了一种新的再参数化方法类别。现有的方法如Low Rank Adaption (LoRA) 虽然有效，但在特定情况下仍存在改进空间。因此，研究者旨在通过新的方法来增强模型性能。

Method: 通过随机矩阵理论(Random Matrix Theory)分析并设计了一种新的再参数化方法，用于增强模型在高维数据上的二元分类能力。同时还进行了实际实验，包括在大型语言模型中的微调。

Result: 新方法证实了对增强模型泛化能力的有效性，尤其是在样本数据有限的情况下。实验结果表明，该方法能够显著提升模型在各类任务中的表现。

Conclusion: 提出了一个新颖的再参数化方法类别，用于提高微调模型的泛化能力。这种新的方法在理论上和实践上都表现出了对现有技术的改进，是未来模型优化的一个有潜力的方向。

Abstract: Fine-tuning has proven to be highly effective in adapting pre-trained models
to perform better on new desired tasks with minimal data samples. Among the
most widely used approaches are reparameterization methods, which update a
target module by augmenting its frozen weight matrix with an additional
trainable weight matrix. The most prominent example is Low Rank Adaption
(LoRA), which gained significant attention in recent years. In this paper, we
introduce a new class of reparameterization methods for transfer learning,
designed to enhance the generalization ability of fine-tuned models. We
establish the effectiveness of our approach in a high-dimensional binary
classification setting using tools from Random Matrix Theory, and further
validate our theoretical findings through more realistic experiments, such as
fine-tuning LLMs.

</details>


### [106] [Data as a Lever: A Neighbouring Datasets Perspective on Predictive Multiplicity](https://arxiv.org/abs/2510.21303)
*Prakhar Ganesh,Hsiang Hsu,Golnoosh Farnadi*

Main category: cs.LG

TL;DR: 本文提出了一种邻近数据集框架，研究单个数据点差异对模型多重性的影响，发现类间分布重叠较大的邻近数据集多重性较低，挑战了传统观念，并在此基础上扩展到主动学习和数据插补领域，提出了多重性感知的方法。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为，类间分布重叠较大的数据集多重性较高，本文通过研究邻近数据集来挑战这一观点，并探讨其在实际应用中的影响。

Method: 通过引入邻近数据集框架，分析单个数据点差异对模型多重性的影响，并对其原理进行严格证明，然后将其扩展到主动学习和数据插补领域。

Result: 发现类间分布重叠较大的邻近数据集多重性较低，并基于此提出了多重性感知的数据获取策略和数据插补技术。

Conclusion: 研究表明，邻近数据集的类间分布重叠与多重性之间存在着逆相关关系，这一发现对于实践应用中的模型选择和数据处理具有重要意义。

Abstract: Multiplicity -- the existence of distinct models with comparable performance
-- has received growing attention in recent years. While prior work has largely
emphasized modelling choices, the critical role of data in shaping multiplicity
has been comparatively overlooked. In this work, we introduce a neighbouring
datasets framework to examine the most granular case: the impact of a
single-data-point difference on multiplicity. Our analysis yields a seemingly
counterintuitive finding: neighbouring datasets with greater inter-class
distribution overlap exhibit lower multiplicity. This reversal of conventional
expectations arises from a shared Rashomon parameter, and we substantiate it
with rigorous proofs.
  Building on this foundation, we extend our framework to two practical
domains: active learning and data imputation. For each, we establish natural
extensions of the neighbouring datasets perspective, conduct the first
systematic study of multiplicity in existing algorithms, and finally, propose
novel multiplicity-aware methods, namely, multiplicity-aware data acquisition
strategies for active learning and multiplicity-aware data imputation
techniques.

</details>


### [107] [Revisiting Social Welfare in Bandits: UCB is (Nearly) All You Need](https://arxiv.org/abs/2510.21312)
*Dhruv Sarkar,Nishant Pandey,Sayak Ray Chowdhury*

Main category: cs.LG

TL;DR: 本文介绍了一种新的方法来最小化Nash遗憾，这种方法在初始阶段进行均匀探索，随后使用标准的UCB算法，适用于更广泛的奖励分布，包括亚高斯奖励分布。同时，该方法还推广到一类新的公平性度量：p-均值遗憾，并证明了在所有p值下，该方法的遗憾界接近最优值。


<details>
  <summary>Details</summary>
Motivation: 传统的多臂赌博机中的遗憾衡量标准不能公平地评估每个参与者获得的收益，特别是当收益在整个群体中分布时，例如临床试验中的患者。本文旨在解决这个问题，同时将方法扩展到更广泛的奖励分布，引入了p-均值遗憾作为新的公平性度量。

Method: 一种新的方法，首先进行一个初始的均匀探索阶段，然后使用标准的UCB算法，能够处理高斯和亚高斯奖励分布。同时，提出了一种新的遗憾度量p-均值遗憾，这种度量能够保持与Nash遗憾相同的公平性，并证明了该方法在所有p值下近似达到最优遗憾界。

Result: 在两种新的遗憾度量（Nash遗憾和p-均值遗憾）下都证明了该方法的最优性（接近或达到最优），尤其是在处理高斯和亚高斯奖励分布时，展示出方法的广泛适用性。此外，还解决了现有方法不能处理这些奖励分布的问题，提供了一种更为通用的解决方案。

Conclusion: 通过提出一种新的遗憾度量（p-均值遗憾）并证明该度量在一串处理不同公平性要求的方法中的最优性，本文提供了一个新的框架来解决多臂赌博机中与公平性相关的遗憾问题。

Abstract: Regret in stochastic multi-armed bandits traditionally measures the
difference between the highest reward and either the arithmetic mean of
accumulated rewards or the final reward. These conventional metrics often fail
to address fairness among agents receiving rewards, particularly in settings
where rewards are distributed across a population, such as patients in clinical
trials. To address this, a recent body of work has introduced Nash regret,
which evaluates performance via the geometric mean of accumulated rewards,
aligning with the Nash social welfare function known for satisfying fairness
axioms.
  To minimize Nash regret, existing approaches require specialized algorithm
designs and strong assumptions, such as multiplicative concentration
inequalities and bounded, non-negative rewards, making them unsuitable for even
Gaussian reward distributions. We demonstrate that an initial uniform
exploration phase followed by a standard Upper Confidence Bound (UCB) algorithm
achieves near-optimal Nash regret, while relying only on additive Hoeffding
bounds, and naturally extending to sub-Gaussian rewards. Furthermore, we
generalize the algorithm to a broad class of fairness metrics called the
$p$-mean regret, proving (nearly) optimal regret bounds uniformly across all
$p$ values. This is in contrast to prior work, which made extremely restrictive
assumptions on the bandit instances and even then achieved suboptimal regret
bounds.

</details>


### [108] [Assessing the Real-World Utility of Explainable AI for Arousal Diagnostics: An Application-Grounded User Study](https://arxiv.org/abs/2510.21389)
*Stefan Kraft,Andreas Theissler,Vera Wienhausen-Wilke,Gjergji Kasneci,Hendrik Lensch*

Main category: cs.LG

TL;DR: 研究通过用户研究，考察了不同类型的AI辅助系统（黑盒和白盒）以及在不同时间节点（开始评分和后置质量检测）下的效果。研究发现，透明AI辅助系统显著提高了事件级别的准确性，减少了评分时间，且大多数参与者愿意接受该系统。这项工作为AI在临床实践中的集成提供了一条有希望的路径。


<details>
  <summary>Details</summary>
Motivation: 当前AI在生物医学信号解读中的高预测准确度虽然重要，但为了更好地融入临床实践，还需探索如何在临床情境中更可靠地使用这些算法，提升医生的信赖度。这项研究旨在探讨不同类型的AI辅助是如何影响睡眠医学专家评分准确性的，以期找到一种更有效和可信赖的AI辅助方式。

Method: 研究通过开展一个应用导向的用户实验，邀请了8位专业的睡眠医学专家参与。实验中，专家们在三种条件下对多项睡眠图数据中的夜间唤醒事件进行评分：（i）手动评分；（ii）采用黑盒AI辅助；（iii）采用透明白盒AI辅助。并且协助提供可以是在评分开始时也可以作为后置质量检测（QC）的步骤。系统性评估了类型、时间点是如何影响事件级别的评分、与临床最相关的数量化表现、所需时间和用户体验的。

Result: 在与训练AI所用的临床标准对比下，AI和人机合作显著超越了不受辅助的专家表现，同时减少了评分者之间的变异。值得注意的是，作为一种特别的质量检测措施，透明AI辅助比黑盒辅助在事件级别的性能提升了大约30％，并且质量检测时间的增加进一步提高了量化结果。尽管透明和质量检测方式增加了评分时间，而开始时间辅助被认为更快，并且更受参与者欢迎。参与者们大多支持透明度，有7位中的8位表达倾向于接受本系统并愿意在其基础上进行少许或不进行修改。

Conclusion: 在提高准确性的同时，分阶段的透明AI辅助有效地平衡了临床效率和评分时间，为可信赖的AI集成和临床工作流程中用户的接受度提供了有意义的发展路径。

Abstract: Artificial intelligence (AI) systems increasingly match or surpass human
experts in biomedical signal interpretation. However, their effective
integration into clinical practice requires more than high predictive accuracy.
Clinicians must discern \textit{when} and \textit{why} to trust algorithmic
recommendations. This work presents an application-grounded user study with
eight professional sleep medicine practitioners, who score nocturnal arousal
events in polysomnographic data under three conditions: (i) manual scoring,
(ii) black-box (BB) AI assistance, and (iii) transparent white-box (WB) AI
assistance. Assistance is provided either from the \textit{start} of scoring or
as a post-hoc quality-control (\textit{QC}) review. We systematically evaluate
how the type and timing of assistance influence event-level and clinically most
relevant count-based performance, time requirements, and user experience. When
evaluated against the clinical standard used to train the AI, both AI and
human-AI teams significantly outperform unaided experts, with collaboration
also reducing inter-rater variability. Notably, transparent AI assistance
applied as a targeted QC step yields median event-level performance
improvements of approximately 30\% over black-box assistance, and QC timing
further enhances count-based outcomes. While WB and QC approaches increase the
time required for scoring, start-time assistance is faster and preferred by
most participants. Participants overwhelmingly favor transparency, with seven
out of eight expressing willingness to adopt the system with minor or no
modifications. In summary, strategically timed transparent AI assistance
effectively balances accuracy and clinical efficiency, providing a promising
pathway toward trustworthy AI integration and user acceptance in clinical
workflows.

</details>


### [109] [Leverage Unlearning to Sanitize LLMs](https://arxiv.org/abs/2510.21322)
*Antoine Boutet,Lucas Magnana*

Main category: cs.LG

TL;DR: SANI 提出了一种针对预训练语言模型的去记忆化方法，通过擦除和修复阶段，可以有效地移除模型中的敏感信息，同时避免影响模型的整体性能。这种方法特别适用于那些已经花费大量资源在大型数据集上训练模型的组织，可以在分享之前清理模型，保护用户隐私和数据安全。


<details>
  <summary>Details</summary>
Motivation: 在利用预训练大语言模型完成特定任务时，模型可能因为细粒度的数据记忆导致隐私泄露问题。为了去除这种记忆并保护模型的隐私安全性，同时又不需要重新对安全数据集进行昂贵的微调训练，提出了 SANI 方法。

Method: SANI 采用了一种去学习的方法对语言模型进行清理，过程中包含两阶段：首先是通过重置模型末端某些神经元来打破细粒度数据记忆，随后在微调过程中避免再次记忆敏感数据。

Result: 实验结果表明，仅需少数几次额外的去学习迭代，模型就能成功移除直接和间接识别信息，敏感信息的记忆次数大大减少，表明 SANI 对于预训练或专门化医学数据的模型都是有效的。

Conclusion: SANI 是一种简洁实用的技术，能够帮助医疗机构或其他行业在保护重要数据和隐私的同时，分享其基于大型数据集训练后的模型成果。

Abstract: Pre-trained large language models (LLMs) are becoming useful for various
tasks. To improve their performance on certain tasks, it is necessary to
fine-tune them on specific data corpora (e.g., medical reports, business data).
These specialized data corpora may contain sensitive data (e.g., personal or
confidential data) that will be memorized by the model and likely to be
regurgitated during its subsequent use. This memorization of sensitive
information by the model poses a significant privacy or confidentiality issue.
To remove this memorization and sanitize the model without requiring costly
additional fine-tuning on a secured data corpus, we propose SANI. SANI is an
unlearning approach to sanitize language models. It relies on both an erasure
and repair phases that 1) reset certain neurons in the last layers of the model
to disrupt the memorization of fine-grained information, and then 2) fine-tune
the model while avoiding memorizing sensitive information. We comprehensively
evaluate SANI to sanitize both a model fine-tuned and specialized with medical
data by removing directly and indirectly identifiers from the memorization of
the model, and a standard pre-trained model by removing specific terms defined
as confidential information from the model. Results show that with only few
additional epochs of unlearning, the model is sanitized and the number of
regurgitations is drastically reduced. This approach can be particularly useful
for hospitals or other industries that have already spent significant resources
training models on large datasets and wish to sanitize them before sharing.

</details>


### [110] [Large Language Models as Model Organisms for Human Associative Learning](https://arxiv.org/abs/2510.21408)
*Camila Kolling,Vy Ai Vo,Mariya Toneva*

Main category: cs.LG

TL;DR: 该论文研究了大型语言模型(LLM)在关联学习中的表示变化，发现了一个与非单调可塑性假设一致的非单调模式，并且表示分化受到词汇干扰的影响，即新的关联与先前知识的竞争。这些发现表明LLM是研究表示动态和大脑记忆重组原则的强大工具。


<details>
  <summary>Details</summary>
Motivation: 希望探究大型语言模型在关联学习中的表示变化，以验证在生物系统中表示变化的假设，同时利用LLM的可控性来进一步理解这种变化。

Method: 使用大型语言模型(LLL)来适应认知神经科学中的相关学习范式，并调查了六种模型中的表示如何演变。通过调整相关项目的词汇干扰来观察和分析表示变化。

Result: 发现了与非单调可塑性假设一致的非单调模式；表示分化受到词汇干扰的影响，更高词汇干扰会放大表示分化。

Conclusion: 大型语言模型不仅是研究人类学习系统中表示动态的强大工具，也是生成关于大脑记忆重组原则的新假设的一般计算模型。

Abstract: Associative learning--forming links between co-occurring items--is
fundamental to human cognition, reshaping internal representations in complex
ways. Testing hypotheses on how representational changes occur in biological
systems is challenging, but large language models (LLMs) offer a scalable
alternative. Building on LLMs' in-context learning, we adapt a cognitive
neuroscience associative learning paradigm and investigate how representations
evolve across six models. Our initial findings reveal a non-monotonic pattern
consistent with the Non-Monotonic Plasticity Hypothesis, with moderately
similar items differentiating after learning. Leveraging the controllability of
LLMs, we further show that this differentiation is modulated by the overlap of
associated items with the broader vocabulary--a factor we term vocabulary
interference, capturing how new associations compete with prior knowledge. We
find that higher vocabulary interference amplifies differentiation, suggesting
that representational change is influenced by both item similarity and global
competition. Our findings position LLMs not only as powerful tools for studying
representational dynamics in human-like learning systems, but also as
accessible and general computational models for generating new hypotheses about
the principles underlying memory reorganization in the brain.

</details>


### [111] [SCORENF: Score-based Normalizing Flows for Sampling Unnormalized distributions](https://arxiv.org/abs/2510.21330)
*Vikas Kanaujia,Vipul Arora*

Main category: cs.LG

TL;DR: ScoreNF是一种基于归一化流架构的评分学习框架，结合独立MH模块，可以从未归一化的目标分布中进行高效的无偏差采样。与传统采样方法和基于似然的机器学习模型相比，ScoreNF在小型训练集上也能保持高性能，表现出色。该方法在合成分布和高维物理场分布上进行了验证，展示出优秀的采样能力。


<details>
  <summary>Details</summary>
Motivation: 现有采样方法如MCMC存在收敛慢、模式混合效果差等问题；而基于似然的机器学习模型虽然效果好，但依赖大数据集。目标是通过ScoreNF解决这些问题，提高采样效率和质量。

Method: ScoreNF框架将评分模型与归一化流结合，并加入独立MH模块，利用评分模型从未归一化的分布中进行采样。通过这种方式，框架能够有效减少对大规模MCMC数据的依赖，同时还能保持高效的采样性能。此外，还提供了一种评估模式覆盖和模式塌陷的方法。

Result: ScoreNF在2D合成分布和高维物理场分布上进行了测试，结果表明它具有优秀的采样性能，能有效地解决模式覆盖和模式塌陷问题，同时显著降低了对大型数据集的依赖。 

Conclusion: ScoreNF提供了一种新的采样方法，它不仅能提高采样效率，还能有效减少对大型数据集的依赖，是未归一化嵌套概率分布采样的有力工具。

Abstract: Unnormalized probability distributions are central to modeling complex
physical systems across various scientific domains. Traditional sampling
methods, such as Markov Chain Monte Carlo (MCMC), often suffer from slow
convergence, critical slowing down, poor mode mixing, and high autocorrelation.
In contrast, likelihood-based and adversarial machine learning models, though
effective, are heavily data-driven, requiring large datasets and often
encountering mode covering and mode collapse. In this work, we propose ScoreNF,
a score-based learning framework built on the Normalizing Flow (NF)
architecture, integrated with an Independent Metropolis-Hastings (IMH) module,
enabling efficient and unbiased sampling from unnormalized target
distributions. We show that ScoreNF maintains high performance even with small
training ensembles, thereby reducing reliance on computationally expensive
MCMC-generated training data. We also present a method for assessing
mode-covering and mode-collapse behaviours. We validate our method on synthetic
2D distributions (MOG-4 and MOG-8) and the high-dimensional $\phi^4$ lattice
field theory distribution, demonstrating its effectiveness for sampling tasks.

</details>


### [112] [DreamerV3-XP: Optimizing exploration through uncertainty estimation](https://arxiv.org/abs/2510.21418)
*Lukas Bierling,Davide Pasero,Jan-Henrik Bertrand,Kiki Van Gerwen*

Main category: cs.LG

TL;DR: DreamerV3-XP 是 DreamerV3 的一个扩展版本，其通过引入优先级回放缓冲区和基于模型预测奖励分歧的内在奖励来改进探索和学习效率。在稀疏奖励环境下的实验结果表明，DreamerV3-XP 达到了更快的学习速度和更低的动力学模型损失。


<details>
  <summary>Details</summary>
Motivation: DreamerV3-XP 的动机在于提高探索和学习效率，特别是在稀疏奖励的环境下，通过改进回放缓冲区策略和引入基于模型预测奖励分歧的内在奖励机制来实现这一目标。

Method: 方法包括 (i) 引入优先级回放缓冲区，通过回报、重构损失和价值误差对轨迹进行评分；(ii) 利用模型预测奖励的分歧度来生成内在奖励。

Result: 在 Atari100k 和 DeepMind 控制视觉基准任务的子集上，DreamerV3-XP 展示了相比原始 DreamerV3 更快的学习速度和更低的动力学模型损失，特别是在稀疏奖励环境中效果更为显著。

Conclusion: 结论是，通过引入的改进策略，DreamerV3-XP 不仅复现了原始 DreamerV3 的结果，并且在稀疏奖励任务中展示了显著的学习效率提升。

Abstract: We introduce DreamerV3-XP, an extension of DreamerV3 that improves
exploration and learning efficiency. This includes (i) a prioritized replay
buffer, scoring trajectories by return, reconstruction loss, and value error
and (ii) an intrinsic reward based on disagreement over predicted environment
rewards from an ensemble of world models. DreamerV3-XP is evaluated on a subset
of Atari100k and DeepMind Control Visual Benchmark tasks, confirming the
original DreamerV3 results and showing that our extensions lead to faster
learning and lower dynamics model loss, particularly in sparse-reward settings.

</details>


### [113] [Compositional Monte Carlo Tree Diffusion for Extendable Planning](https://arxiv.org/abs/2510.21361)
*Jaesik Yoon,Hyeonseo Cho,Sungjin Ahn*

Main category: cs.LG

TL;DR: 提出了一种新的框架Compositional Monte Carlo Tree Diffusion (C-MCTD)，它从单个轨迹优化提升到对整个计划组合的推理，包括在线合作者、分布式合作者和预计划合作者三个互补组件，以减少搜索复杂性并加速推断


<details>
  <summary>Details</summary>
Motivation: 当前的Monte Carlo Tree Diffusion (MCTD)在生成比训练轨迹更长的计划时，仍然受到局部限制，这是因为MCTD在个体轨迹内搜索，没有全局上下文的访问。因此，需要开发一个能够进行全局感知规划的框架，它能够跨越整个计划组合搜索

Method: C-MCTD引入了三个互补组件：1) 在线合作者，进行全局感知规划；2) 分布式合作者，通过从多个起点的并行探索减少搜索复杂性；3) 预计划合作者，通过利用缓存的计划图加速推断

Result: C-MCTD框架能够提升规划，从个体轨迹的优化提升到整个计划组合的推理。通过三个组件的协作，C-MCTD在减少搜索复杂性的同时，也加速了推断过程

Conclusion: 该研究提出了一种新的框架C-MCTD，它解决了MCTD在生成更长计划时的局限性，通过引入全局感知规划，分布式搜索和预计划推理，从而提升了整个规划过程的有效性和效率

Abstract: Monte Carlo Tree Diffusion (MCTD) integrates diffusion models with structured
tree search to enable effective trajectory exploration through stepwise
reasoning. However, MCTD remains fundamentally limited by training trajectory
lengths. While periodic replanning allows plan concatenation for longer plan
generation, the planning process remains locally confined, as MCTD searches
within individual trajectories without access to global context. We propose
Compositional Monte Carlo Tree Diffusion (C-MCTD), a framework that elevates
planning from individual trajectory optimization to reasoning over complete
plan compositions. C-MCTD introduces three complementary components: (1) Online
Composer, which performs globally-aware planning by searching across entire
plan compositions; (2) Distributed Composer, which reduces search complexity
through parallel exploration from multiple starting points; and (3) Preplan
Composer, which accelerates inference by leveraging cached plan graphs.

</details>


### [114] [Generative Correlation Manifolds: Generating Synthetic Data with Preserved Higher-Order Correlations](https://arxiv.org/abs/2510.21610)
*Jens E. d'Hondt,Wieger R. Punter,Odysseas Papapetrou*

Main category: cs.LG

TL;DR: 该论文引入了生成相关度流形（Generative Correlation Manifolds，GCM）方法，能够通过计算有效地保持数据的相关结构，从简单的成对关系到高阶互动，并探讨了其在隐私保护数据共享、模型训练和模拟中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 数据隐私需求和强大的机器学习模型需求推动了合成数据生成技术的发展，然而当前技术在保留高阶数据相关结构方面存在局限性。该论文的目标是在生成合成数据的同时，有效保留数据的复杂多变量互动关系。

Method: 该论文提出了一种生成相关度流形（GCM）的方法，通过应用目标协方差矩阵的Cholesky分解来生成数据集，这种方法确保生成的数据集准确保留了原始数据集的相关结构。

Result: 生成的相关度流形（GCM）方法通过保持数据的相关结构，可能比当前的方法更具优势。这种方法能够用于隐私保护数据共享、增强模型训练能力和进行复杂的模拟。

Conclusion: 该论文提出了一种创新的方法，通过保持多变量数据互动的相关结构，提高了合成数据的质量。这标志着在隐私保护数据共享，模型训练和模拟等方面潜在的应用方向。

Abstract: The increasing need for data privacy and the demand for robust machine
learning models have fueled the development of synthetic data generation
techniques. However, current methods often succeed in replicating simple
summary statistics but fail to preserve both the pairwise and higher-order
correlation structure of the data that define the complex, multi-variable
interactions inherent in real-world systems. This limitation can lead to
synthetic data that is superficially realistic but fails when used for
sophisticated modeling tasks. In this white paper, we introduce Generative
Correlation Manifolds (GCM), a computationally efficient method for generating
synthetic data. The technique uses Cholesky decomposition of a target
correlation matrix to produce datasets that, by mathematical proof, preserve
the entire correlation structure -- from simple pairwise relationships to
higher-order interactions -- of the source dataset. We argue that this method
provides a new approach to synthetic data generation with potential
applications in privacy-preserving data sharing, robust model training, and
simulation.

</details>


### [115] [FairImagen: Post-Processing for Bias Mitigation in Text-to-Image Models](https://arxiv.org/abs/2510.21363)
*Zihao Fu,Ryan Brown,Shun Shao,Kai Rawal,Eoin Delaney,Chris Russell*

Main category: cs.LG

TL;DR: FairImagen 是一种后处理去偏框架，通过操作提示嵌入来减少文本到图像生成模型中的社会偏见，同时保持图像质量和提示忠实度。它使用了Fair主成分分析和其他技术来实现这一目标，并在各种情况下表现出了优越性。


<details>
  <summary>Details</summary>
Motivation: 文本到图像的生成模型（如Stable Diffusion）在从自然语言提示生成高质量、多样化的图像方面表现出色。但是，这些模型常常复制和放大社会偏见，特别是在性别和种族等人口统计特征方面。为了减轻这些问题，引入了FairImagen这一框架，旨在不需要重新训练或修改基础生成模型的情况下减少偏见。

Method: FairImagen 使用Fair主成分分析将基于CLIP的输入嵌入投影到一个子空间中，这个子空间在最小化特定群体信息的同时保留语义内容。此外，它还使用经验噪音注入来进一步增强去偏效果，并提出了一种统一的跨人口统计特征投影方法，可以同时在多个特征上进行去偏。

Result: 在广泛的实验中，包括针对性别、种族和交叉人口统计特征的情况，FairImagen 显示出显著的去偏效果，尽管在图像质量和提示忠实度方面略有妥协。与其他后处理方法相比，该框架表现更优，提供了简单的、可扩展的、不受模型限制的解决方案，使文本到图像的生成更加公平。

Conclusion: FairImagen 作为一种减少文本到图像模型中社会偏见的去偏框架，通过对提示嵌入的精确操作，实现了在不附加复杂成本或大规模修改模型的情况下提高生成公平性的目标。

Abstract: Text-to-image diffusion models, such as Stable Diffusion, have demonstrated
remarkable capabilities in generating high-quality and diverse images from
natural language prompts. However, recent studies reveal that these models
often replicate and amplify societal biases, particularly along demographic
attributes like gender and race. In this paper, we introduce FairImagen
(https://github.com/fuzihaofzh/FairImagen), a post-hoc debiasing framework that
operates on prompt embeddings to mitigate such biases without retraining or
modifying the underlying diffusion model. Our method integrates Fair Principal
Component Analysis to project CLIP-based input embeddings into a subspace that
minimizes group-specific information while preserving semantic content. We
further enhance debiasing effectiveness through empirical noise injection and
propose a unified cross-demographic projection method that enables simultaneous
debiasing across multiple demographic attributes. Extensive experiments across
gender, race, and intersectional settings demonstrate that FairImagen
significantly improves fairness with a moderate trade-off in image quality and
prompt fidelity. Our framework outperforms existing post-hoc methods and offers
a simple, scalable, and model-agnostic solution for equitable text-to-image
generation.

</details>


### [116] [Few-Shot Knowledge Distillation of LLMs With Counterfactual Explanations](https://arxiv.org/abs/2510.21631)
*Faisal Hamman,Pasan Dissanayake,Yanjun Fu,Sanghamitra Dutta*

Main category: cs.LG

TL;DR: 提出了一种新的知识蒸馏策略CoD，通过系统地引入反事实解释，解决了任务意识蒸馏在样本较少时的表现问题。CoD在少数样本情况下表现出色，并且只需要比基线方法一半的数据量就能提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有任务意识知识蒸馏方法需要大量数据，但在实践中获得这些数据可能困难和昂贵。本研究旨在解决这个问题，通过引入一种新的知识蒸馏策略CoD，该策略使用反事实解释，以更少的数据量进行有效的知识传输。

Method: CoD策略通过在蒸馏过程中加入反事实解释来实现知识迁移。反事实解释指的是那些能够通过最小的扰动来改变教师模型预测的输入。我们证明了这种方法通过从统计学和几何学的角度提供理论保障，能有效地利用边界附近的样本点来改进参数估计，帮助学生模型更好地模仿教师模型的决策边界。

Result: 实验结果表明，CoD在使用较少样本时的表现优于标准蒸馏方法，尤其是在少量样本情况下效果显著。值得注意的是，CoD只需要基线方法一半的数据量加上其对应的反事实解释就提高了性能。

Conclusion: 通过引入反事实解释(CFEs)，CoD策略能够更有效地进行任务意识知识蒸馏，特别是在样本量有限的情况下。这种新方法不仅减少了对大量数据的需求，还提高了知识蒸馏的效果。

Abstract: Knowledge distillation is a promising approach to transfer capabilities from
complex teacher models to smaller, resource-efficient student models that can
be deployed easily, particularly in task-aware scenarios. However, existing
methods of task-aware distillation typically require substantial quantities of
data which may be unavailable or expensive to obtain in many practical
scenarios. In this paper, we address this challenge by introducing a novel
strategy called Counterfactual-explanation-infused Distillation CoD for
few-shot task-aware knowledge distillation by systematically infusing
counterfactual explanations. Counterfactual explanations (CFEs) refer to inputs
that can flip the output prediction of the teacher model with minimum
perturbation. Our strategy CoD leverages these CFEs to precisely map the
teacher's decision boundary with significantly fewer samples. We provide
theoretical guarantees for motivating the role of CFEs in distillation, from
both statistical and geometric perspectives. We mathematically show that CFEs
can improve parameter estimation by providing more informative examples near
the teacher's decision boundary. We also derive geometric insights on how CFEs
effectively act as knowledge probes, helping the students mimic the teacher's
decision boundaries more effectively than standard data. We perform experiments
across various datasets and LLMs to show that CoD outperforms standard
distillation approaches in few-shot regimes (as low as 8-512 samples). Notably,
CoD only uses half of the original samples used by the baselines, paired with
their corresponding CFEs and still improves performance.

</details>


### [117] [DEEDEE: Fast and Scalable Out-of-Distribution Dynamics Detection](https://arxiv.org/abs/2510.21638)
*Tala Aljaafari,Varun Kanade,Philip Torr,Christian Schroeder de Witt*

Main category: cs.LG

TL;DR: DEEDEE是用于检测RL时间序列中分布变化的检测器，它使用简单的统计方法来检测异常，同时减少了计算资源的消耗并提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用中部署强化学习受分布变化影响的脆弱性限制，因此需要一种有效的分布外检测方法来保持模型的鲁棒性。DEEDEE旨在通过简单的统计方法提高检测准确性并降低计算成本。

Method: DEEDEE采用时间序列中的平均每集得分和到训练集概要的RBF核相似度，用于检测分布变化。这种方式轻量且有效。

Result: DEEDEE在标准的RL分布外数据集上表现优秀，减少了600倍的计算量，并且比基线方法的准确率提高了5%。这表明低阶统计量可以捕捉到不同类型的异常模式。

Conclusion: DEEDEE提出了一种在不需要复杂表示的情况下检测分布变化的有效方法，能够应用于复杂的RL环境中。

Abstract: Deploying reinforcement learning (RL) in safety-critical settings is
constrained by brittleness under distribution shift. We study
out-of-distribution (OOD) detection for RL time series and introduce DEEDEE, a
two-statistic detector that revisits representation-heavy pipelines with a
minimal alternative. DEEDEE uses only an episodewise mean and an RBF kernel
similarity to a training summary, capturing complementary global and local
deviations. Despite its simplicity, DEEDEE matches or surpasses contemporary
detectors across standard RL OOD suites, delivering a 600-fold reduction in
compute (FLOPs / wall-time) and an average 5% absolute accuracy gain over
strong baselines. Conceptually, our results indicate that diverse anomaly types
often imprint on RL trajectories through a small set of low-order statistics,
suggesting a compact foundation for OOD detection in complex environments.

</details>


### [118] [Disentangled Representation Learning via Modular Compositional Bias](https://arxiv.org/abs/2510.21402)
*Whie Jung,Dong Hoon Lee,Seunghoon Hong*

Main category: cs.LG

TL;DR: 提出了一个模块化的、与目标和架构分离的组成偏差，通过随机混排潜在变量并利用两个互补的目标函数来实现因子结构的解耦表示学习。实验表明该方法在属性和对象解耦方面表现出色，并且能在同一模型中实现全局样式和对象的联合解耦


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理新变异因素时不兼容，特别是在这些因素不符合先前假设时，需要重新设计架构或目标函数。因此，提出了一个可调整的组成偏差框架，以适应不同类型的因子，而无需修改目标函数或架构

Method: 通过随机混排潜在变量依据因子特定规则，使用两个互补的目标函数：一个先验损失确保每次混排都能解码为真实图像，另一个是组合一致性损失，确保每个复合图像与其相对应的复合潜在变量一致

Result: 实验结果表明，该方法在属性和对象解耦中表现出色，尤其在实现全局样式和对象的联合解耦上具有独特优势

Conclusion: 提出的方法提供了一种新的解决解耦表示学习问题的通用框架，简化了处理新变异因素的过程，提高了模型的鲁棒性和可扩展性

Abstract: Recent disentangled representation learning (DRL) methods heavily rely on
factor specific strategies-either learning objectives for attributes or model
architectures for objects-to embed inductive biases. Such divergent approaches
result in significant overhead when novel factors of variation do not align
with prior assumptions, such as statistical independence or spatial
exclusivity, or when multiple factors coexist, as practitioners must redesign
architectures or objectives. To address this, we propose a compositional bias,
a modular inductive bias decoupled from both objectives and architectures. Our
key insight is that different factors obey distinct recombination rules in the
data distribution: global attributes are mutually exclusive, e.g., a face has
one nose, while objects share a common support (any subset of objects can
co-exist). We therefore randomly remix latents according to factor-specific
rules, i.e., a mixing strategy, and force the encoder to discover whichever
factor structure the mixing strategy reflects through two complementary
objectives: (i) a prior loss that ensures every remix decodes into a realistic
image, and (ii) the compositional consistency loss introduced by Wiedemer et
al. (arXiv:2310.05327), which aligns each composite image with its
corresponding composite latent. Under this general framework, simply adjusting
the mixing strategy enables disentanglement of attributes, objects, and even
both, without modifying the objectives or architectures. Extensive experiments
demonstrate that our method shows competitive performance in both attribute and
object disentanglement, and uniquely achieves joint disentanglement of global
style and objects. Code is available at
https://github.com/whieya/Compositional-DRL.

</details>


### [119] [Unified token representations for sequential decision models](https://arxiv.org/abs/2510.21448)
*Zhuojing Tian,Yushu Chen*

Main category: cs.LG

TL;DR: 提出了一种统一标记表示(UTR)，将回报-去、状态和行动合并为一个标记，以减少序列长度和模型复杂性，实现更好的泛化和更高效的计算性能。


<details>
  <summary>Details</summary>
Motivation: 现有的一些决策变换器存在冗余标记化和二次注意力复杂性问题，限制了其在实时或资源受限环境下的可扩展性。现有方法效率不高，需要改进以提高模型的泛化能力和计算效率，同时保持或提高性能。因此，提出了统一标记表示(UTR)来解决这些问题。

Method: 提出了一种将回报-去、状态和动作合并为单个标记的机制，即UTR。同时还开发了两种变体—UDT和UDC，分别基于变压器和门控CNN骨干。这种方法通过减少序列长度和复杂性，显著降低了计算机资源需求，同时保持或提高了性能。

Result: 实验结果表明，UTR和UDT/UDC相比现有方法具有较低的计算复杂性，同时性能相当或更好。这表明UTR可以在不同的架构中广泛推广，可能为未来的大规模决策模型提供高效率的控制基础。

Conclusion: 研究发现，UTR通过合并多个组件为单个标记，不牺牲性能的情况下显著降低了模型的复杂性和计算成本，展示了有效的泛化能力，并且未来的大规模决策模型可能会受益于这种高效控制的结构。

Abstract: Transformers have demonstrated strong potential in offline reinforcement
learning (RL) by modeling trajectories as sequences of return-to-go, states,
and actions. However, existing approaches such as the Decision Transformer(DT)
and its variants suffer from redundant tokenization and quadratic attention
complexity, limiting their scalability in real-time or resource-constrained
settings. To address this, we propose a Unified Token Representation (UTR) that
merges return-to-go, state, and action into a single token, substantially
reducing sequence length and model complexity. Theoretical analysis shows that
UTR leads to a tighter Rademacher complexity bound, suggesting improved
generalization. We further develop two variants: UDT and UDC, built upon
transformer and gated CNN backbones, respectively. Both achieve comparable or
superior performance to state-of-the-art methods with markedly lower
computation. These findings demonstrate that UTR generalizes well across
architectures and may provide an efficient foundation for scalable control in
future large decision models.

</details>


### [120] [Towards Explainable Personalized Recommendations by Learning from Users' Photos](https://arxiv.org/abs/2510.21455)
*Jorge Díez,Pablo Pérez-Núñez,Oscar Luaces,Beatriz Remeseiro,Antonio Bahamonde*

Main category: cs.LG

TL;DR: 本文提出了一种通过预测用户为项目拍摄的照片来生成个性化解释的方法，以此增加推荐系统的可靠性和公司对用户偏好的理解。研究使用了TripAdvisor上六个不同城市的餐厅评论数据进行验证。


<details>
  <summary>Details</summary>
Motivation: 推荐系统的输出需要个性化解释，这能增加与用户的信任。通过预测用户选择的照片，可以揭示他们对产品的哪些方面特别重视。这种方法令推荐系统能够自我解释，同时也帮助企业了解客户偏好的视角。

Method: 本文构建了一个正式框架，用于估计给定用户和照片之间关系的概率，以此预测照片的选择。

Result: 研究数据分析表明，基于用户照片的推荐解释推论可以提高推荐系统的理解和接受度，同时也为公司提供了客户偏好的额外维度。

Conclusion: 通过结合个性化推荐和照片预测，不仅可以解释推荐系统的输出，还能帮助企业更深入地理解其产品在市场上的展示方式。

Abstract: Explaining the output of a complex system, such as a Recommender System (RS),
is becoming of utmost importance for both users and companies. In this paper we
explore the idea that personalized explanations can be learned as
recommendation themselves. There are plenty of online services where users can
upload some photos, in addition to rating items. We assume that users take
these photos to reinforce or justify their opinions about the items. For this
reason we try to predict what photo a user would take of an item, because that
image is the argument that can best convince her of the qualities of the item.
In this sense, an RS can explain its results and, therefore, increase its
reliability. Furthermore, once we have a model to predict attractive images for
users, we can estimate their distribution. Thus, the companies acquire a vivid
knowledge about the aspects that the clients highlight of their products. The
paper includes a formal framework that estimates the authorship probability for
a given pair (user, photo). To illustrate the proposal, we use data gathered
from TripAdvisor containing the reviews (with photos) of restaurants in six
cities of different sizes.

</details>


### [121] [Benchmarking Catastrophic Forgetting Mitigation Methods in Federated Time Series Forecasting](https://arxiv.org/abs/2510.21491)
*Khaled Hallak,Oudom Kem*

Main category: cs.LG

TL;DR: 本文提出了首个针对联邦持续时间序列预测中的灾难性遗忘问题的基准测试框架，并使用北京多站点空气质量数据集对若干遗忘减轻策略进行了系统性评测，为不断推进联邦时间序列预测系统的持续学习提供了重要工具和见解。


<details>
  <summary>Details</summary>
Motivation: 当前针对灾难性遗忘问题的研究主要集中在视觉领域的分类任务上，而物联网和边缘计算应用中常见的基于回归的预测问题较少被探索。本文旨在填补这一空白，提出了一个专为探究联邦学习中时间序列预测中的灾难性遗忘问题的基准测试框架。

Method: 利用北京多站点空气质量数据集中的12个分布式客户端，系统性地评估了包括Replay、Elastic Weight Consolidation、Learning Without Forgetting和Synaptic Intelligence在内的若干灾难性遗忘缓解策略。同时，提出了一套可复现的开源框架。

Result: 在评测中，本文引入了一种新的用于解决联邦学习中时间序列预测问题的灾难性遗忘问题的基准测试方法，全面评估了当前最优的方法，并为该领域的进一步研究提供了重要的工具和数据。

Conclusion: 本文通过提出一个全新的基准测试框架，对联邦学习中时间序列预测的灾难性遗忘问题进行了系统的探索，不仅验证了若干现有缓解策略的有效性，还为研究这一领域提供了可复现的开源框架。


Abstract: Catastrophic forgetting (CF) poses a persistent challenge in continual
learning (CL), especially within federated learning (FL) environments
characterized by non-i.i.d. time series data. While existing research has
largely focused on classification tasks in vision domains, the regression-based
forecasting setting prevalent in IoT and edge applications remains
underexplored. In this paper, we present the first benchmarking framework
tailored to investigate CF in federated continual time series forecasting.
Using the Beijing Multi-site Air Quality dataset across 12 decentralized
clients, we systematically evaluate several CF mitigation strategies, including
Replay, Elastic Weight Consolidation, Learning without Forgetting, and Synaptic
Intelligence. Key contributions include: (i) introducing a new benchmark for CF
in time series FL, (ii) conducting a comprehensive comparative analysis of
state-of-the-art methods, and (iii) releasing a reproducible open-source
framework. This work provides essential tools and insights for advancing
continual learning in federated time-series forecasting systems.

</details>


### [122] [Uniform Convergence Beyond Glivenko-Cantelli](https://arxiv.org/abs/2510.21506)
*Tanmay Devale,Pramith Devulapalli,Steve Hanneke*

Main category: cs.LG

TL;DR: 本文研究了在什么条件下，分布集合 {0,1
^[N } 允许一致的均值估计。通过引入 $UME-$ 估计可学习性（Uniform Mean Estimability），我们扩展了先前关于使用经验均值估计器的框架，并证明了可分性是足够条件。我们还用不同技术证明了在平均向量非可分时也有 $UME-$ 学习性。最后解决了 Cohen et al. (2025) 提出的猜想：可数联合 $UME-$ 学习集合依然是 $UME-$ 学习性的。


<details>
  <summary>Details</summary>
Motivation: 先前的工作（Vapnik 和Chervonenkis，1971）关注经验均值估计器下的均匀收敛问题。本文扩展此框架，引入了 $UME-$ 学习性（即使用任意估计器下的均匀均值估计性）。目标是开辟新的途径，来研究分布集合是否允许一致估计其均值的方法和条件，以推动该领域的发展，解决实际中的学习问题和理论挑战。

Method: 引入了 $UME-$ 学习性的概念，基于此，我们探讨了分布集合在特定条件下一致估计其均值的可能性。证明了在分布集平均向量可分时，实现 $UME-$ 学习性是可能的。此外，通过技术和证明上的创新，验证了当平均向量不可分时，$UME-$ 学习性仍然可以实现。我们解决了 Cohen et al.（2025）提出的猜想，表明可数联合 $UME-$ 学习集合依然是 $UME-$ 学习性的。这个过程涵盖了具体的数学分析和理论构建。

Result: 本文证明了当分布集合平均向量可分时，$UME-$ 学习性可实现；同时找到了一种平均向量不可分的分布集合，但这些集合在采用非传统方法时也可以达到 $UME-$ 学习性。此外，我们证实了可数联合 $UME-$ 学习集合同样是 $UME-$ 学习性。这一系列结果深化了我们对均值估计一致性的理解，并推动了该领域的理论进展。

Conclusion: 通过引入 $UME-$ 学习性这一概念我们扩展了之前的分析框架，解决了过去仅依赖经验均值的局限性。结果证明了 $UME-$ 学习性的实现不仅依赖于可分性，还取决于不同的估计技术。我们的发现对于理解一致均值估计在不同条件下的适用性非常关键，并且解决了涉及 $UME-$ 学习性的开放性猜想。

Abstract: We characterize conditions under which collections of distributions on
$\{0,1\}^\mathbb{N}$ admit uniform estimation of their mean. Prior work from
Vapnik and Chervonenkis (1971) has focused on uniform convergence using the
empirical mean estimator, leading to the principle known as $P-$
Glivenko-Cantelli. We extend this framework by moving beyond the empirical mean
estimator and introducing Uniform Mean Estimability, also called $UME-$
learnability, which captures when a collection permits uniform mean estimation
by any arbitrary estimator. We work on the space created by the mean vectors of
the collection of distributions. For each distribution, the mean vector records
the expected value in each coordinate. We show that separability of the mean
vectors is a sufficient condition for $UME-$ learnability. However, we show
that separability of the mean vectors is not necessary for $UME-$ learnability
by constructing a collection of distributions whose mean vectors are
non-separable yet $UME-$ learnable using techniques fundamentally different
from those used in our separability-based analysis. Finally, we establish that
countable unions of $UME-$ learnable collections are also $UME-$ learnable,
solving a conjecture posed in Cohen et al. (2025).

</details>


### [123] [Probe-based Fine-tuning for Reducing Toxicity](https://arxiv.org/abs/2510.21531)
*Jan Wehner,Mario Fritz*

Main category: cs.LG

TL;DR: 本文提出两种方法来对抗基于模型激活的探测器，同时保持探测器的准确性。研究发现，基于偏好的优化方法比基于分类器的方法更有利于保持探测器的检测能力，并且在条件允许的情况下重训探测器可以恢复高检测准确度，因此探测器集合的使用在这种情况下并不必要。


<details>
  <summary>Details</summary>
Motivation: 在训练模型时，探测器能够检测出模型的行为，这使得它们成为检测模型行为的有用工具。然而，当探测器作为训练目标时，它可能会失去可靠性。因此，本文的动机在于寻找一种方法来同时保留探测器的功能和准确性。

Method: 提出了两种方法：一种基于监督微调，另一种基于直接偏好优化。在这个测试框架上进行了一次探索，以减少毒性。评估了在对抗训练时探测器准确度下降的程度。尝试了三种方法来保留训练后的探测器准确性：对抗训练一组探测器、保留未用于训练的探测器、在训练后重新训练新的探测器。

Result: 发现在优化过程中，偏好学习的目标更有利于维护相关表示，比分类器更有利于保持探测器的检出能力。同时，研究发现保持探测器多样性并不是必须的，在条件允许的情况下通过重训可以恢复其检测准确度。

Conclusion: 研究表明，在某些情况下，训练模型对抗基于模型激活的探测器是可行的，但前提是能够在训练之后重新训练新的探测器。

Abstract: Probes trained on model activations can detect undesirable behaviors like
deception or biases that are difficult to identify from outputs alone. This
makes them useful detectors to identify misbehavior. Furthermore, they are also
valuable training signals, since they not only reward outputs, but also good
internal processes for arriving at that output. However, training against
interpretability tools raises a fundamental concern: when a monitor becomes a
training target, it may cease to be reliable (Goodhart's Law). We propose two
methods for training against probes based on Supervised Fine-tuning and Direct
Preference Optimization. We conduct an initial exploration of these methods in
a testbed for reducing toxicity and evaluate the amount by which probe accuracy
drops when training against them. To retain the accuracy of probe-detectors
after training, we attempt (1) to train against an ensemble of probes, (2)
retain held-out probes that aren't used for training, and (3) retrain new
probes after training.
  First, probe-based preference optimization unexpectedly preserves probe
detectability better than classifier-based methods, suggesting the preference
learning objective incentivizes maintaining rather than obfuscating relevant
representations. Second, probe diversity provides minimal practical benefit -
simply retraining probes after optimization recovers high detection accuracy.
Our findings suggest probe-based training can be viable for certain alignment
methods, though probe ensembles are largely unnecessary when retraining is
feasible.

</details>


### [124] [FrameShield: Adversarially Robust Video Anomaly Detection](https://arxiv.org/abs/2510.21532)
*Mojtaba Nafez,Mobina Poulaei,Nikan Vasei,Bardia Soltani Moakhar,Mohammad Sabokrou,MohammadHossein Rohban*

Main category: cs.LG

TL;DR: 本文提出了一种新的时空区域扭曲（SRD）方法，用于生成合成异常，以减少伪标签中的噪声，从而提高弱监督视频异常检测模型（WSVAD）在对抗攻击下的鲁棒性。相比现有方法，本文方法在多个基准上的AUROC性能平均提高71.0%。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视频异常检测模型容易受到对抗攻击的影响，且传统的对抗防御机制对于视频级别标签的弱监督不够有效。为了提高模型的鲁棒性，研究者们需要找到一种既能在帧级别标注，又能处理标签噪音的方法。

Method: 提出一种时空区域扭曲（SRD）方法，它通过给正常视频的局部区域施加剧烈增强，产生带有精确标注的合成异常样本。然后将这些样本整合到异常训练中，以减少伪标签中的噪声。这种方法解决了现有模型中由于伪标签而产生的问题，并且有效增强了模型对抗攻击的鲁棒性。

Result: 实验证明，该方法大幅提升了弱监督视频异常检测模型的鲁棒性，比现有的最佳方法平均高出71.0%的AUROC表现。

Conclusion: 该研究通过引入时空区域扭曲（SRD）方法，解决伪标签带来的问题，显著提升了弱监督视频异常检测模型在对抗攻击条件下的性能。

Abstract: Weakly Supervised Video Anomaly Detection (WSVAD) has achieved notable
advancements, yet existing models remain vulnerable to adversarial attacks,
limiting their reliability. Due to the inherent constraints of weak
supervision, where only video-level labels are provided despite the need for
frame-level predictions, traditional adversarial defense mechanisms, such as
adversarial training, are not effective since video-level adversarial
perturbations are typically weak and inadequate. To address this limitation,
pseudo-labels generated directly from the model can enable frame-level
adversarial training; however, these pseudo-labels are inherently noisy,
significantly degrading performance. We therefore introduce a novel
Pseudo-Anomaly Generation method called Spatiotemporal Region Distortion (SRD),
which creates synthetic anomalies by applying severe augmentations to localized
regions in normal videos while preserving temporal consistency. Integrating
these precisely annotated synthetic anomalies with the noisy pseudo-labels
substantially reduces label noise, enabling effective adversarial training.
Extensive experiments demonstrate that our method significantly enhances the
robustness of WSVAD models against adversarial attacks, outperforming
state-of-the-art methods by an average of 71.0\% in overall AUROC performance
across multiple benchmarks. The implementation and code are publicly available
at https://github.com/rohban-lab/FrameShield.

</details>


### [125] [Interpretable Multimodal Zero-Shot ECG Diagnosis via Structured Clinical Knowledge Alignment](https://arxiv.org/abs/2510.21551)
*Jialu Tang,Hung Manh Pham,Ignace De Lathauwer,Henk S. Schipper,Yuan Lu,Dong Ma,Aaqib Saeed*

Main category: cs.LG

TL;DR: ZETA是一个零样本多模态框架，旨在实现解释性强的心电图诊断，该框架能够模仿临床鉴别诊断过程。实验表明，ZETA具备竞争性的零样本分类性能，并且具有增强的可解释性，可以将预测锚定在特定的临床相关的阳性或阴性诊断特征上。


<details>
  <summary>Details</summary>
Motivation: 现的心电图自动解释系统在透明度和泛化能力上存在不足，ZETA框架旨在通过零样本学习和结构化临床知识的整合来提高AI诊断系统的透明性、泛化能力和可靠性，从而辅助临床决策。

Method: ZETA框架通过将心电信号与结构化的正负临床观察结果进行比较来进行诊断，并借助预训练的多模态模型将心电图和文本嵌入对齐，无需针对特定疾病进行微调。

Result: 实验结果表明，ZETA方法在零样本分类任务中具有竞争力，并且提供了定性和定量的证据，表明这种方法提高了可解释性，使预测能够锚定在特定的临床相关的正负诊断特征上。

Conclusion: ZETA方法缩小了心电图自动解释系统与临床工作流程之间的差距，实现了更具透明性、泛化能力和令人信赖的AI诊断系统。释放了整理后的观察数据集和代码以支持未来的研究。

Abstract: Electrocardiogram (ECG) interpretation is essential for cardiovascular
disease diagnosis, but current automated systems often struggle with
transparency and generalization to unseen conditions. To address this, we
introduce ZETA, a zero-shot multimodal framework designed for interpretable ECG
diagnosis aligned with clinical workflows. ZETA uniquely compares ECG signals
against structured positive and negative clinical observations, which are
curated through an LLM-assisted, expert-validated process, thereby mimicking
differential diagnosis. Our approach leverages a pre-trained multimodal model
to align ECG and text embeddings without disease-specific fine-tuning.
Empirical evaluations demonstrate ZETA's competitive zero-shot classification
performance and, importantly, provide qualitative and quantitative evidence of
enhanced interpretability, grounding predictions in specific, clinically
relevant positive and negative diagnostic features. ZETA underscores the
potential of aligning ECG analysis with structured clinical knowledge for
building more transparent, generalizable, and trustworthy AI diagnostic
systems. We will release the curated observation dataset and code to facilitate
future research.

</details>


### [126] [REVE: A Foundation Model for EEG -- Adapting to Any Setup with Large-Scale Pretraining on 25,000 Subjects](https://arxiv.org/abs/2510.21585)
*Yassine El Ouahidi,Jonathan Lys,Philipp Thölke,Nicolas Farrugia,Bastien Pasdeloup,Vincent Gripon,Karim Jerbi,Giulia Lioi*

Main category: cs.LG

TL;DR: REVE 是一个针对 EEG 信号设计的预训练模型，可以处理任意长度和电极排列的信号，使用了4D 位置编码方案。它在超过60,000小时的数据上进行预训练，并在多个下游任务中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有 EEG 基础模型在处理不同数据设置时普遍泛化能力不足，需要改进以适应各种 EEG 信号的异质性和变化性，从而提高性能和泛化能力。

Method: REVE 采用了一种新颖的 4D 位置编码方案，能够处理任意长度和电极排列的信号。通过掩码自动编码目标在超过60,000小时的数据集上进行预训练，涵盖92个数据集、25,000个受试者。

Result: 在包括运动意象分类、癫痫检测、睡眠分期、认知负荷估计和情绪识别在内的10个下游任务中，REVE 达到了最先进的性能。

Conclusion: 通过专为 EEG 信号设计的预训练模型 REVE，能够大幅提升 EEG 数据的处理能力与泛化性能，对于标准化 EEG 研究和临床神经科学的进步有重要意义。

Abstract: Foundation models have transformed AI by reducing reliance on task-specific
data through large-scale pretraining. While successful in language and vision,
their adoption in EEG has lagged due to the heterogeneity of public datasets,
which are collected under varying protocols, devices, and electrode
configurations. Existing EEG foundation models struggle to generalize across
these variations, often restricting pretraining to a single setup, resulting in
suboptimal performance, in particular under linear probing. We present REVE
(Representation for EEG with Versatile Embeddings), a pretrained model
explicitly designed to generalize across diverse EEG signals. REVE introduces a
novel 4D positional encoding scheme that enables it to process signals of
arbitrary length and electrode arrangement. Using a masked autoencoding
objective, we pretrain REVE on over 60,000 hours of EEG data from 92 datasets
spanning 25,000 subjects, representing the largest EEG pretraining effort to
date. REVE achieves state-of-the-art results on 10 downstream EEG tasks,
including motor imagery classification, seizure detection, sleep staging,
cognitive load estimation, and emotion recognition. With little to no
fine-tuning, it demonstrates strong generalization, and nuanced spatio-temporal
modeling. We release code, pretrained weights, and tutorials to support
standardized EEG research and accelerate progress in clinical neuroscience.

</details>


### [127] [Accelerating Data Generation for Nonlinear temporal PDEs via homologous perturbation in solution space](https://arxiv.org/abs/2510.21592)
*Lei Liu,Zhenxin Huang,Hong Wang,huanshuo dong,Haiyang Xin,Hongwei Zhao,Bin Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的数据生成算法HOmologous Perturbation in Solution Space (HOPSS)，用于生成训练非线性时变偏微分方程模型所需的较小时间步长的数据集，从而显著减少了计算开销且保证了模型训练的精度。该方法在Navier-Stokes方程上展示了高效性，生成10,000样本仅需传统方法的10%时间，但模型训练效果相当。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法生成训练所需的数据集需要进行大量时间步长迭代，这导致了高计算与时间开销，而基于机器学习的方法如神经算子需要大量的解函数对进行训练。为解决这一问题，本文提出了HOmologous Perturbation in Solution Space (HOPSS) 算法，以减少生成数据集的时间和计算资源消耗。

Method: 首先，通过可靠求解器，获得一系列基础解函数，再将其时间步长与训练数据对齐并通过下采样进行处理。之后，通过组合两个解函数（一个为主函数，另一个作为同源扰动项，以小标量缩放）加上随机噪声，生成具有相近精度的偏微分方程数据点。最后，利用这些数据点计算原方程的右侧变化，形成新的解函数对。

Result: 理论和实验验证表明HOPSS算法能够降低时间复杂度。在Navier-Stokes方程上，HOPSS能在传统方法时间的大约10%内生成10,000样本，同时保持模型训练性能不变。

Conclusion: 新提出的HOPSS算法通过更少的时间步长模拟生成训练所需的数据集，显著减少了计算资源消耗，实现高效的数据生成，同时达到了较高的精度，从而使得深度学习方法在非线性时变偏微分方程模型训练中的应用更为有效。

Abstract: Data-driven deep learning methods like neural operators have advanced in
solving nonlinear temporal partial differential equations (PDEs). However,
these methods require large quantities of solution pairs\u2014the solution
functions and right-hand sides (RHS) of the equations. These pairs are
typically generated via traditional numerical methods, which need thousands of
time steps iterations far more than the dozens required for training, creating
heavy computational and temporal overheads. To address these challenges, we
propose a novel data generation algorithm, called HOmologous Perturbation in
Solution Space (HOPSS), which directly generates training datasets with fewer
time steps rather than following the traditional approach of generating large
time steps datasets. This algorithm simultaneously accelerates dataset
generation and preserves the approximate precision required for model training.
Specifically, we first obtain a set of base solution functions from a reliable
solver, usually with thousands of time steps, and then align them in time steps
with training datasets by downsampling. Subsequently, we propose a "homologous
perturbation" approach: by combining two solution functions (one as the primary
function, the other as a homologous perturbation term scaled by a small scalar)
with random noise, we efficiently generate comparable-precision PDE data
points. Finally, using these data points, we compute the variation in the
original equation's RHS to form new solution pairs. Theoretical and
experimental results show HOPSS lowers time complexity. For example, on the
Navier-Stokes equation, it generates 10,000 samples in approximately 10% of
traditional methods' time, with comparable model training performance.

</details>


### [128] [Generalised Flow Maps for Few-Step Generative Modelling on Riemannian Manifolds](https://arxiv.org/abs/2510.21608)
*Oscar Davis,Michael S. Albergo,Nicholas M. Boffi,Michael M. Bronstein,Avishek Joey Bose*

Main category: cs.LG

TL;DR: 提出了一种新的几类生成模型Generalised Flow Maps (GFM)，并将这些模型应用于黎曼流形。通过三种基于自蒸馏的训练方法，该模型在多种几何数据集上实现了最佳的样本质量和对数似然值。


<details>
  <summary>Details</summary>
Motivation: 当前的几何生成模型在推断阶段仍然计算成本高昂，需要多步复杂的数值模拟。我们旨在提出一种新的几类生成模型来解决这个问题，使得生成模型在黎曼流形上也能高效运行，并且保持高样本质量。

Method: 我们提出了Generalised Flow Maps (GFM) 类型的新几类生成模型，并通过三种基于自蒸馏的训练方法实例化它们：Generalised Lagrangian Flow Maps，Generalised Eulerian Flow Maps 和 Generalised Progressive Flow Maps。这些方法可以统一现有欧几里得几类生成模型，并将它们提升到黎曼流形的设置下。

Result: 在一系列几何数据集上，包括地缘空间数据，RNA棘轮角，以及双曲流形数据集，GFMs实现了单步和多步评估的最佳样本质量和相媲美的对数似然性能。

Conclusion: 通过引入Generalised Flow Maps (GFM)，我们成功地将几类生成模型推广到复杂的黎曼流形。在多个几何数据集上进行了广泛测试，证明了GFMs的高效性和效果。

Abstract: Geometric data and purpose-built generative models on them have become
ubiquitous in high-impact deep learning application domains, ranging from
protein backbone generation and computational chemistry to geospatial data.
Current geometric generative models remain computationally expensive at
inference -- requiring many steps of complex numerical simulation -- as they
are derived from dynamical measure transport frameworks such as diffusion and
flow-matching on Riemannian manifolds. In this paper, we propose Generalised
Flow Maps (GFM), a new class of few-step generative models that generalises the
Flow Map framework in Euclidean spaces to arbitrary Riemannian manifolds. We
instantiate GFMs with three self-distillation-based training methods:
Generalised Lagrangian Flow Maps, Generalised Eulerian Flow Maps, and
Generalised Progressive Flow Maps. We theoretically show that GFMs, under
specific design decisions, unify and elevate existing Euclidean few-step
generative models, such as consistency models, shortcut models, and meanflows,
to the Riemannian setting. We benchmark GFMs against other geometric generative
models on a suite of geometric datasets, including geospatial data, RNA torsion
angles, and hyperbolic manifolds, and achieve state-of-the-art sample quality
for single- and few-step evaluations, and superior or competitive
log-likelihoods using the implicit probability flow.

</details>


### [129] [Optimal Graph Clustering without Edge Density Signals](https://arxiv.org/abs/2510.21669)
*Maximilien Dreveton,Elaine Siyu Liu,Matthias Grossglauser,Patrick Thiran*

Main category: cs.LG

TL;DR: 该论文在Popularity-Adjusted Block Model (PABM) 下建立了图聚类的理论限制，指出现有模型的不足。PABM引入了不同的流行度参数来描述内聚和外连的连接，证明了即使在传统边缘密度信号消失的情况下，也有可能在PABM下恢复聚类。此外，论文的数值实验表明，基于前k^2个特征向量的谱聚类算法优于传统的谱聚类算法。


<details>
  <summary>Details</summary>
Motivation: 因为现有的Stochastic Block Model (SBM) 和 Degree-Corrected Block Model (DCBM) 分别假设了均匀的顶点度数以及群集内统一的度修正，而PABM引入了描述同群集和异群集连接的不同流行度参数，文档的目标是为了探究PABM下聚类的最优错误率，展示比SBM 和 DCBM 更为深入的度异质性维度，并且改进了传统的谱聚类方法。

Method: 在PABM框架下，研究了聚类的最优错误率，并通过数值实验证明了前k^2个特征向量的谱聚类方法比传统方法更为高效。

Result: 在PABM下，即使传统的边缘密度信号消失，聚类的恢复仍然是可能的。此外，基于前k^2个特征向量的谱聚类算法展示了更好的性能。

Conclusion: 该研究提出了PABM模型下的聚类理论限制，不仅展示了模型对于传统方法的改进，同时也提出了对于传统谱聚类方法的改进措施。

Abstract: This paper establishes the theoretical limits of graph clustering under the
Popularity-Adjusted Block Model (PABM), addressing limitations of existing
models. In contrast to the Stochastic Block Model (SBM), which assumes uniform
vertex degrees, and to the Degree-Corrected Block Model (DCBM), which applies
uniform degree corrections across clusters, PABM introduces separate popularity
parameters for intra- and inter-cluster connections. Our main contribution is
the characterization of the optimal error rate for clustering under PABM, which
provides novel insights on clustering hardness: we demonstrate that unlike SBM
and DCBM, cluster recovery remains possible in PABM even when traditional
edge-density signals vanish, provided intra- and inter-cluster popularity
coefficients differ. This highlights a dimension of degree heterogeneity
captured by PABM but overlooked by DCBM: local differences in connectivity
patterns can enhance cluster separability independently of global edge
densities. Finally, because PABM exhibits a richer structure, its expected
adjacency matrix has rank between $k$ and $k^2$, where $k$ is the number of
clusters. As a result, spectral embeddings based on the top $k$ eigenvectors
may fail to capture important structural information. Our numerical experiments
on both synthetic and real datasets confirm that spectral clustering algorithms
incorporating $k^2$ eigenvectors outperform traditional spectral approaches.

</details>


### [130] [Equivariance by Contrast: Identifiable Equivariant Embeddings from Unlabeled Finite Group Actions](https://arxiv.org/abs/2510.21706)
*Tobias Schmidt,Steffen Schneider,Matthias Bethge*

Main category: cs.LG

TL;DR: 本文提出了通过对比学习来学习等变嵌入的方法EbC，不需要特定的群诱导偏置。在验证实验中，方法显示出了高保真度的等变性。论文还包括了非阿贝尔正交群和一般线性群的理论证明，但针对真实世界数据的广泛评估仍然是未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 动机是通过观测对（₿y，g·₿y）学习群作用对应的不变嵌入，而无需依赖群特定的归纳偏差，实现在单一编码器的通用等变学习，适用于非阿贝尔群和通过建模计算机视觉中的仿射等变性。

Method: 方法EbC，利用对比学习从观测对学习群作用对应的不变嵌入，联合学习一个潜在空间和群表示，使得群作用在潜在空间中对应于可逆线性映射

Result: 在验证实验中，方法显示出了高保真度的等变性，通过合成数据进一步验证了该方法对非阿贝尔正交群和一般线性群的有效性。初步的工作还包括了对于群动作观测的单一编码器等变学习的理论证明。但主要的广泛评估实验需要在未来的工作中进行。

Conclusion: 尽管在真实数据集上的广泛评估仍然是未来的研究方向，该方法已经成功示例了来自群动作观测的通用编码器的等变学习，包括非阿贝尔群和模仿计算机视觉中仿射等变模式的产品群。

Abstract: We propose Equivariance by Contrast (EbC) to learn equivariant embeddings
from observation pairs $(\mathbf{y}, g \cdot \mathbf{y})$, where $g$ is drawn
from a finite group acting on the data. Our method jointly learns a latent
space and a group representation in which group actions correspond to
invertible linear maps -- without relying on group-specific inductive biases.
We validate our approach on the infinite dSprites dataset with structured
transformations defined by the finite group $G:= (R_m \times \mathbb{Z}_n
\times \mathbb{Z}_n)$, combining discrete rotations and periodic translations.
The resulting embeddings exhibit high-fidelity equivariance, with group
operations faithfully reproduced in latent space. On synthetic data, we further
validate the approach on the non-abelian orthogonal group $O(n)$ and the
general linear group $GL(n)$. We also provide a theoretical proof for
identifiability. While broad evaluation across diverse group types on
real-world data remains future work, our results constitute the first
successful demonstration of general-purpose encoder-only equivariant learning
from group action observations alone, including non-trivial non-abelian groups
and a product group motivated by modeling affine equivariances in computer
vision.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [131] [Safety Monitor for Off-Road Planning with Uncertainty Bounded Bekker Costs](https://arxiv.org/abs/2510.21006)
*Akshay Naik,Ramavarapu S. Sreenivas,William R. Norris,Albert E. Patterson,Ahmet Soylemezoglu,Dustin Nottage*

Main category: eess.SY

TL;DR: 这篇论文提出了一种实时保证安全监控器，它可以与任何规划器合作使用带有有界不确定性的Bekker成本模型，确保在土壤强度不确定的情况下车辆的行驶是安全的。监控器会在风险过高时切换到一个经过验证的备用方案，以减缓速度、增加与软地面的安全距离或者停止在更坚固的地面。这种方法通过分析不确定性来计算上置信成本，并应用简单的干预规则。实验结果显示了干预率、违规概率和与名义计划的路径效率。


<details>
  <summary>Details</summary>
Motivation: 当土壤强度不确定时，可靠的越野自主性需要操作约束，以保持行为可预测和安全。这篇文章旨在通过实现一个实时的安全监控器来解决这个问题，使得不确定性情况下的车辆行驶可以被监控并保证安全。

Method: 这种方法使用了一个基于Bekker的成本模型，与任意规划器合作，从现场测试中识别出一个轻量级的压力沉陷模型来构建上置信通过成本。监控器检查每个计划的移动是否超过了最大沉陷和翻车裕度的限制；如果风险过高，它会切换到一个经过验证的备用方案来减少速度、增加与软地面的安全距离或停止在更坚固的地面。这种方法直接将安全性与车辆设计联系起来，并在运行时设置明确的速度、曲率和停止限制。此外，它也融入了解析不确定性的分析来计算上置信成本，并应用简单的干预规则。调优方法可以通过调整沉陷限制、翻车裕度和风险窗口来权衡效率与谨慎，同时确保监控器足够轻量，可以在嵌入式处理器上运行。

Result: 在从壤土到砂土的仿真测试环境中，包括干预率、违规概率和与名义计划的路径效率的实验结果。静力负载测试也提供了初步的实验证明。

Conclusion: 这种实时的安全监控方法通过合作的规划器，能够在不确定的土壤环境中确保车辆行驶的效率和安全。通过应用这一监控器，车辆可以在保证安全的同时继续其任务。

Abstract: Reliable off-road autonomy requires operational constraints so that behavior
stays predictable and safe when soil strength is uncertain. This paper presents
a runtime assurance safety monitor that collaborates with any planner and uses
a Bekker-based cost model with bounded uncertainty. The monitor builds an upper
confidence traversal cost from a lightweight pressure sinkage model identified
in field tests and checks each planned motion against two limits: maximum
sinkage and rollover margin. If the risk of crossing either limit is too high,
the monitor switches to a certified fallback that reduces vehicle speed,
increases standoff from soft ground, or stops on firmer soil. This separation
lets the planner focus on efficiency while the monitor keeps the vehicle within
clear safety limits on board. Wheel geometry, wheel load estimate, and a soil
raster serve as inputs, which tie safety directly to vehicle design and let the
monitor set clear limits on speed, curvature, and stopping at run time. The
method carries uncertainty analytically into the upper confidence cost and
applies simple intervention rules. Tuning of the sinkage limit, rollover
margin, and risk window trades efficiency for caution while keeping the monitor
light enough for embedded processors. Results from a simulation environment
spanning loam to sand include intervention rates, violation probability, and
path efficiency relative to the nominal plan, and a benchtop static loading
check provides initial empirical validation.

</details>


### [132] [The Role of Information Incompleteness in Defending Against Stealth Attacks](https://arxiv.org/abs/2510.21227)
*Ke Sun,Jingyi Yan,Zhenglin Li,Shaorong Xie*

Main category: eess.SY

TL;DR: 本文探讨了信息不完整性对数据注入攻击（DIAs）性能的影响，特别是在信息理论隐身攻击中，攻击者面临隐蔽性和破坏性之间的权衡。提出了一种最大化信息不完整性的策略来降低攻击的隐蔽性，并通过仿真实验验证了这一策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于数据注入攻击的有效性依赖于攻击者所掌握的系统信息的完整性，因此通过增强信息不完整性来降低攻击性能是重要的防御策略。具体来说，本文研究了信息不完整性如何影响攻击的隐蔽性和破坏性之间的平衡。

Method: 本文首先系统性地描述了信息不完整性对攻击隐蔽性和破坏性的影响，从而建立了两个不同操作模式的充分条件。针对超出这两个模式的情况，提出了最大化信息不完整性的策略来降低攻击的隐蔽性。通过缩减优化问题中的可行域，并引入启发式算法来寻找近似最优解，从而解决了相关的优化问题。最后，利用IEEE测试系统进行了数值仿真，以验证研究结果的有效性。

Result: 研究结果表明，通过最大化信息不完整性的策略可以有效地降低数据注入攻击的隐蔽性，而不会过度牺牲攻击的破坏性。针对特定场景，可以通过提出的算法找到最优的解决方案来实现对攻击隐蔽性的抑制。

Conclusion: 本文证明了信息不完整性可以通过影响攻击的隐蔽性和破坏性的平衡，从而有效降低数据注入攻击的性能。所提出的最大化信息不完整性的策略提供了一种新的防御途径，可用于保护复杂系统免受此类攻击。

Abstract: The effectiveness of Data Injections Attacks (DIAs) critically depends on the
completeness of the system information accessible to adversaries. This
relationship positions information incompleteness enhancement as a vital
defense strategy for degrading DIA performance. In this paper, we focus on the
information-theoretic stealth attacks, where the attacker encounters a
fundamental tradeoff between the attack stealthiness and destructiveness.
Specifically, we systematically characterize how incomplete admittance
information impacts the dual objectives. In particular, we establish sufficient
conditions for two distinct operational regimes: (i) stealthiness intensifies
while destructive potential diminishes and (ii) destructiveness increases while
stealth capability weakens. For scenarios beyond these regimes, we propose a
maximal incompleteness strategy to optimally degrade stealth capability. To
solve the associated optimization problem, the feasible region is reduced
without excluding the optimal solution, and a heuristic algorithm is then
introduced to effectively identify the near-optimal solutions within the
reduced region. Numerical simulations are conducted on IEEE test systems to
validate the findings.

</details>


### [133] [The PhasorArray Toolbox for Harmonic Analysis and Control Design](https://arxiv.org/abs/2510.21294)
*Maxime Grosso,Pierre Riedinger,Jamal Daafouz*

Main category: eess.SY

TL;DR: 一个名为Pha-sorArray的MATLAB工具箱被开发出来，以使谐波分析和控制方法变得实用且用户友好。该工具箱采用面向对象体系结构，支持周期矩阵的直观操作，包括加法、乘法、卷积和自动托普利兹构造。它还提供了谐波Sylvester、Lyapunov和Riccati方程求解器，并且可以无缝集成YALMIP，从而支持基于谐波框架的线性矩阵不等式(LMIs)的高级控制和分析技术。


<details>
  <summary>Details</summary>
Motivation: 为了使谐波分析和控制方法既实用又易于用户操作，开发了一个名为Pha-sorArray的MATLAB工具箱，该工具箱通过支持直观操作周期矩阵来实现这一目标，同时提供高级的谐波方程求解器和与YALMIP的集成支持。

Method: 工具箱采用了面向对象架构，允许通过重载运算符（加法、乘法、卷积、自动托普利兹构造）进行周期矩阵的直观处理。并且包含了用于谐波Sylvester、Lyapunov和Riccati方程的高级求解器，同时支持与YALMIP无缝集成。

Result: 通过该工具箱，谐波分析和控制方法变得更加实用和用户友好，它支持通过无缝集成YALMIP来执行基于LMIs的高级控制和分析任务，同时提供了先进的求解器用于谐波方程。这使得用户更容易实现复杂的控制策略和更深入的研究。

Conclusion: 开发了以实用性和用户友好性为目标的名为Pha-sorArray的MATLAB工具箱，它支持周期矩阵的直观操作，并具备高级方程求解器和与YALMIP的集成支持，从而促进了LMIs在谐波框架下的应用。

Abstract: We present a MATLAB package called the Pha-sorArray Toolbox that has been
developed to make harmonic analysis and control methods both practical and
user-friendly. The toolbox adopts an object-oriented architecture that enables
intuitive manipulation of periodic matrices through overloaded operators for
addition, multiplication, convolution, and automatic Toeplitz construction. Its
advanced features include harmonic Sylvester, Lyapunov and Riccati equations
solvers, and seamless integration with YALMIP, thereby facilitating advanced
control and analysis techniques based on Linear Matrix Inequalities (LMIs) in
the harmonic framework.

</details>


### [134] [Rate-cost tradeoffs in continuous-time control with a biomolecular application](https://arxiv.org/abs/2510.21612)
*Yorie Nakahira,Fangzhou Xiao,Victoria Kostina,John C. Doyle*

Main category: eess.SY

TL;DR: 本文研究了受控的广义Ornstein-Uhlenbeck过程的最小数据率需求，此过程中控制作用可以是乘法或加法，并且噪声方差依赖于控制动作。如果控制是通过加性白高斯信道进行，该下限将被达到。本文的系统模型近似于离散状态分子生灭过程的动力学，并直接应用于通过化学反应控制生物分子系统的问题上，其中乘法控制对应于降解速率，加法控制对应于生成速率，控制目标是减少被控分子物种对其期望浓度水平的波动。


<details>
  <summary>Details</summary>
Motivation: 探讨了当控制可以通过多种形式进行，且噪声方差受控时，广义Ornstein-Uhlenbeck过程的最小数据率需求。另一应用方向是探索如何通过化学反应来控制生物分子系统的稳定状态，为目标分子设定适当的生产和降解速率，以达到减少波动的目的。

Method: 建立模型，推导出了当控制通过加性白高斯信道进行时，实现所需控制成本的数据率的下限，并分析了系统稳定性的条件及其限制。同时考虑了该过程在应用上的含义，特别是分子动力学的情景

Result: 证明了如果通过加性白高斯信道来进行控制，可以实现最小数据率需求的条件。模型下限适用于分析生化过程中的噪声及其控制问题，揭示了如何通过设定特定的控制策略来减少化学反应中的波动

Conclusion: 通过研究广义Ornstein-Uhlenbeck过程的控制，提出了一种新的方法来确定必要的最小数据率，以控制分子浓度波动，支持了生化领域中化学反应控制的相关理论

Abstract: This paper focuses on rate-limited control of the generalized
Ornstein-Uhlenbeck process where the control action can be either
multiplicative or additive, and the noise variance can depend on the control
action. We derive a lower bound on the data rate necessary to achieve the
desired control cost. The lower bound is attained with equality if the control
is performed via an additive white Gaussian channel. The system model
approximates the dynamics of a discrete-state molecular birth-death process,
and the result has direct implications on the control of a biomolecular system
via chemical reactions, where the multiplicative control corresponds to the
degradation rate, the additive control corresponds to the production rate, and
the control objective is to decrease the fluctuations of the controlled
molecular species around their desired concentration levels.

</details>


### [135] [Data-driven Koopman MPC using Mixed Stochastic-Deterministic Tubes](https://arxiv.org/abs/2510.21308)
*Zhengang Zhong,Ehecatl Antonio del Rio-Chanona,Panagiotis Petsagkourakis*

Main category: eess.SY

TL;DR: 本文提出了一种基于Koopman算子和分布鲁棒优化(DRO)框架的数据驱动随机MPC设计方法，适用于具有加性干扰的离散时间非线性系统。该方法通过将动态系统提升到线性空间，实现了Koopman算子的有限维逼近，并使用混合随机-确定性管的方式处理建模误差和加性干扰，保证了在满足预定义约束条件的同时对原始非线性系统进行调控。数值仿真验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的MPC设计难以同时满足非线性系统约束并有效处理模型误差与加性干扰的问题，因此本文提出了一种新的设计方法解决这些问题，其目的是为了实现对存在干扰的非线性系统的有效调控。

Method: 通过使用Koopman算子和DRO框架，将动态系统提升到一个线性空间，并通过构建随机和确定性的管来进行约束和误差处理，同时提供了这两种管的有限样本误差界。

Result: 该方法能够有效调节存在干扰的非线性系统，并且能够满足给定的约束条件。通过数值仿真显示了方法的有效性。

Conclusion: 通过数据驱动随机MPC的设计方法，结合Koopman算子和DRO框架，本文提出了一种有效的处理非线性系统中模型误差和加性干扰的新途径。

Abstract: This paper presents a novel data-driven stochastic MPC design for
discrete-time nonlinear systems with additive disturbances by leveraging the
Koopman operator and a distributionally robust optimization (DRO) framework. By
lifting the dynamical system into a linear space, we achieve a
finite-dimensional approximation of the Koopman operator. We explicitly account
for the modeling approximation and additive disturbance error by a mixed
stochastic-deterministic tube for the lifted linear model. This ensures the
regulation of the original nonlinear system while complying with the
prespecified constraints. Stochastic and deterministic tubes are constructed
using a DRO and a hyper-cube hull, respectively. We provide finite sample error
bounds for both types of tubes. The effectiveness of the proposed approach is
demonstrated through numerical simulations.

</details>


### [136] [Predictive control barrier functions for piecewise affine systems with non-smooth constraints](https://arxiv.org/abs/2510.21321)
*Kanghui He,Anil Alan,Shengling Shi,Ton van den Boom,Bart De Schutter*

Main category: eess.SY

TL;DR: 本文提出了一种新的预测安全滤波器设计方法，通过引入集合值广义Clarke导数解决了复杂非光滑和非控制仿射系统的安全性问题，并提出了一种显式近似的预测安全滤波器方法，展示了通过数值例子的应用效果。


<details>
  <summary>Details</summary>
Motivation: 对于复杂的非线性系统和约束，获得具有大安全集的控制屏障函数是一个具有挑战性的任务。然而当前方法对于非光滑系统和控制非仿射系统来说是不够的，因为它们面临着定义不明确的关键元素和实时计算的问题。

Method: 在考虑了通常为控制非仿射的分段仿射系统，以及非线性状态和多面体输入约束的情况下，本文通过在预测安全滤波器设计中引进集合值广义Clarke导数，来解决安全问题。同时还提出了一种显式近似的预测安全滤波器方法以减轻计算负担。

Result: 证明了在整个扩展的Clarke导数中的控制屏障函数约束足以保证系统安全。通过数值例子演示了控制方法的结果。

Conclusion: 本文解决了复杂非线性系统的控制屏障函数的安全性问题，特别是在非光滑和控制非仿射系统中，展示了新的预测安全滤波器设计方法的有效性和实用性。

Abstract: Obtaining control barrier functions (CBFs) with large safe sets for complex
nonlinear systems and constraints is a challenging task. Predictive CBFs
address this issue by using an online finite-horizon optimal control problem
that implicitly defines a large safe set. The optimal control problem, also
known as the predictive safety filter (PSF), involves predicting the system's
flow under a given backup control policy. However, for non-smooth systems and
constraints, some key elements, such as CBF gradients and the sensitivity of
the flow, are not well-defined, making the current methods inadequate for
ensuring safety. Additionally, for control-non-affine systems, the PSF is
generally nonlinear and non-convex, posing challenges for real-time
computation. This paper considers piecewise affine systems, which are usually
control-non-affine, under nonlinear state and polyhedral input constraints. We
solve the safety issue by incorporating set-valued generalized Clarke
derivatives in the PSF design. We show that enforcing CBF constraints across
all elements of the generalized Clarke derivatives suffices to guarantee
safety. Moreover, to lighten the computational overhead, we propose an explicit
approximation of the PSF. The resulting control methods are demonstrated
through numerical examples.

</details>


### [137] [System-Theoretic Analysis of Dynamic Generalized Nash Equilibrium Problems -- Turnpikes and Dissipativity](https://arxiv.org/abs/2510.21556)
*Sophie Hall,Florian Dörfler,Timm Faulwasser*

Main category: eess.SY

TL;DR: 本文研究了广义纳什均衡（GNE）解在系统理论视角下的开环GNE轨迹性质。通过严格耗散性生成了Nash解的turnpike现象，并从反方向建立了关于turnpike现象和严格耗散性的关系。此外，在一定条件下，本文得出了稳态GNE是最优运行点的结论，并通过游戏价值函数给出了关于储值函数几何特性的地方性质。最后，设计了线性终端惩罚使得GNE开环轨迹收敛至并稳定在稳态GNE。该研究为今后的系统理论分析GNE提供了坚实基础，也类似与在最优控制方面已有的研究成果。


<details>
  <summary>Details</summary>
Motivation: 从系统理论的角度研究广义纳什均衡的开环轨迹性质及其反向转化，提供GNE问题的基础理论支持，为未来的研究打下基础

Method: 首先通过严格耗散性生成Nash解的turnpike现象，同时建立了turnpike现象和严格耗散性之间的反向关系；接着设计了线性终端惩罚，使GNE解的轨迹稳定于其最优操作点；使用游戏价值函数局部表征了储值函数的几何特征；最后建立了GNE的最优控制分析基础理论框架

Result: 建立了严格的关于广义纳什均衡的问题性质和其系统理论模型，通过线性终端惩罚和价值函数等工具，证明了GNE解的长期稳定性和最优性。并证实了这些结论可为今后的GNE问题提供理论上新的创新视角和研究方法

Conclusion: 本文通过严格数学证明和理论分析的方法，从系统理论角度深入解析了广义纳什均衡性质，并提出新的解决问题的方法论。之后的研究可以获取这些新结论，为推动广义纳什均衡在控制领域的应用提供了理论基础。

Abstract: Generalized Nash equilibria are used in multi-agent control applications to
model strategic interactions between agents that are coupled in the cost,
dynamics, and constraints. We study the properties of open-loop GNE
trajectories from a system-theoretic perspective. We show how strict
dissipativity generates the turnpike phenomenon in GNE solutions. Moreover, we
establish a converse turnpike result, i.e., the implication from turnpike to
strict dissipativity. We derive conditions under which the steady-state GNE is
the optimal operating point and, using a game value function, we give a local
characterization of the geometry of storage functions. Finally, we design
linear terminal penalties that ensure GNE open-loop trajectories converge to
and remain at the steady-state GNE. These connections provide the foundation
for future system-theoretic analysis of GNEs similar to those existing in
optimal control.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [138] [Cultural Alien Sampler: Open-ended art generation balancing originality and coherence](https://arxiv.org/abs/2510.20849)
*Alejandro H. Artiles,Hiromu Yakura,Levin Brinkmann,Mar Canet Sola,Hassan Abu Alhaija,Ignacio Serna,Nasim Rahaman,Bernhard Schölkopf,Iyad Rahwan*

Main category: cs.AI

TL;DR: 本文提出了一种新的概念选择方法Cultural Alien Sampler（CAS），用于生成既有内部一致性又能偏离传统文化的创新艺术想法。该方法通过两个GPT-2模型评估概念的组合连贯性和文化典型性，从而生成既具有创新性又保持一致性的艺术想法。实验结果显示，该方法在原创性和和谐性方面超过了随机选择和GPT-4o基线，并且生成了更多的多样性和探索更广阔的概念空间。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型在生成的艺术想法上要么重复熟悉的文化模式，要么牺牲连贯性追求新颖性。为了解决这个问题，本文开发了一种新方法来平衡艺术想法的原创性和内部一致性。

Method: 本文介绍了一种新的概念选择方法Cultural Alien Sampler (CAS)，使用了两个GPT-2模型：一个评估概念的组合连贯性，另一个评估这些概念的文化典型性。通过这种方法，算法可以生成高连贯性和低典型性的概念组合，从而产生创新而又具有一致性的艺术想法。

Result: 在人类评价实验中，这种新方法在原创性和和谐性方面超过了随机选择和GPT-4o基线，并且生成了更多多样性和更广泛的探索空间的艺术想法。量化研究表明，该方法产生的输出比其GPT-4o基线要更加多样化和探索更为广泛的概念空间。

Conclusion: 本文提出的方法能够有效地平衡艺术想法的创新性和内部一致性，展现了在创造性生成领域的巨大潜力。

Abstract: In open-ended domains like art, autonomous agents must generate ideas that
are both original and internally coherent, yet current Large Language Models
(LLMs) either default to familiar cultural patterns or sacrifice coherence when
pushed toward novelty. We address this by introducing the Cultural Alien
Sampler (CAS), a concept-selection method that explicitly separates
compositional fit from cultural typicality. CAS uses two GPT-2 models
fine-tuned on WikiArt concepts: a Concept Coherence Model that scores whether
concepts plausibly co-occur within artworks, and a Cultural Context Model that
estimates how typical those combinations are within individual artists' bodies
of work. CAS targets combinations that are high in coherence and low in
typicality, yielding ideas that maintain internal consistency while deviating
from learned conventions and embedded cultural context. In a human evaluation
(N = 100), our approach outperforms random selection and GPT-4o baselines and
achieves performance comparable to human art students in both perceived
originality and harmony. Additionally, a quantitative study shows that our
method produces more diverse outputs and explores a broader conceptual space
than its GPT-4o counterpart, demonstrating that artificial cultural alienness
can unlock creative potential in autonomous agents.

</details>


### [139] [Fuzzy numbers revisited: operations on extensional fuzzy numbers](https://arxiv.org/abs/2510.20861)
*Krzysztof Siminski*

Main category: cs.AI

TL;DR: 该论文提出了扩展型模糊数的概念，并定义了其上的操作和关系运算符，旨在解决传统模糊数操作中出现的计算复杂度高和泛化问题，同时保持模糊结果的准确性。该方法通过实际例子进行了展示，并在公共GitHub仓库中提供了C++实现代码。


<details>
  <summary>Details</summary>
Motivation: 传统模糊数在操作时存在计算复杂度高且操作结果可能不再是原类型的模糊集，以及模糊性会随着操作次数增加的问题，这限制了模糊数的应用范围。因此，论文尝试提出一种新型的模糊数——扩展型模糊数来解决这些问题。

Method: 论文定义了扩展型模糊数上的操作及其关系运算符，并通过具体的应用例子来展示这一方法的有效性。此外，论文还提供了C++实现代码，公众可以在GitHub上访问。

Result: 论文提出的方法能够保持操作结果的模糊特征不变，并且减少了计算复杂度，展示了这种新型模糊数的应用潜力。通过几个应用例子验证了其有效性。

Conclusion: 该论文通过引入扩展型模糊数的概念，提供了一种更为有效和灵活的方法来操作模糊数。这种方法适用于需要处理模棱两可数据的场景，特别是在计算复杂度要考虑的情况下。

Abstract: Fuzzy numbers are commonly represented with fuzzy sets. Their objective is to
better represent imprecise data. However, operations on fuzzy numbers are not
as straightforward as maths on crisp numbers. Commonly, the Zadeh's extension
rule is applied to elaborate a result. This can produce two problems: (1) high
computational complexity and (2) for some fuzzy sets and some operations the
results is not a fuzzy set with the same features (eg. multiplication of two
triangular fuzzy sets does not produce a triangular fuzzy set). One more
problem is the fuzzy spread -- fuzziness of the result increases with the
number of operations. These facts can severely limit the application field of
fuzzy numbers. In this paper we would like to revisite this problem with a
different kind of fuzzy numbers -- extensional fuzzy numbers. The paper defines
operations on extensional fuzzy numbers and relational operators (=, >, >=, <,
<=) for them. The proposed approach is illustrated with several applicational
examples. The C++ implementation is available from a public GitHub repository.

</details>


### [140] [Epistemic Deference to AI](https://arxiv.org/abs/2510.21043)
*Benjamin Lange*

Main category: cs.AI

TL;DR: 该论文讨论了在什么情况下我们应该选择相信AI的输出而不是人的专业判断。提出了AI预拚合主义观点，即AI输出应该取代而不是补充用户独立的知识考虑，但也指出了该观点的缺点，并提出了一种替代方案-总证据观点，即AI输出应该作为补充而不是完全替代用户独立的知识考虑。这种替代方案有三个主要优势：（i）最小化专业知识的丧失，（ii）为有意义的人类监督和控制提供一个知识依据，（iii）解释了为何在条件不满足时对AI的信任应被质疑。


<details>
  <summary>Details</summary>
Motivation: 论文提出了一些AI系统可以被看作人工知识权威（AEA），因为他们表现出可靠性和知识上的优越性。同时，也发现了一些AI预拚合主义的观点，即AEAs的输出应该替代而不是补充用户的独立知识考虑。

Method: 通过比较AI预拚合主义的观点和总证据观点来解决是否应该将AEAs的输出作为独立的知识考虑。

Result: 提出总证据观点作为替代方案，并讨论了这种观点的三个优势。

Conclusion: 虽然在实践上可能具有挑战性，但总证据观点提供了一个在满足严格可靠性条件的高风险环境中判断是否应该依赖AI的理论基础。

Abstract: When should we defer to AI outputs over human expert judgment? Drawing on
recent work in social epistemology, I motivate the idea that some AI systems
qualify as Artificial Epistemic Authorities (AEAs) due to their demonstrated
reliability and epistemic superiority. I then introduce AI Preemptionism, the
view that AEA outputs should replace rather than supplement a user's
independent epistemic reasons. I show that classic objections to preemptionism
- such as uncritical deference, epistemic entrenchment, and unhinging epistemic
bases - apply in amplified form to AEAs, given their opacity, self-reinforcing
authority, and lack of epistemic failure markers. Against this, I develop a
more promising alternative: a total evidence view of AI deference. According to
this view, AEA outputs should function as contributory reasons rather than
outright replacements for a user's independent epistemic considerations. This
approach has three key advantages: (i) it mitigates expertise atrophy by
keeping human users engaged, (ii) it provides an epistemic case for meaningful
human oversight and control, and (iii) it explains the justified mistrust of AI
when reliability conditions are unmet. While demanding in practice, this
account offers a principled way to determine when AI deference is justified,
particularly in high-stakes contexts requiring rigorous reliability.

</details>


### [141] [MedAlign: A Synergistic Framework of Multimodal Preference Optimization and Federated Meta-Cognitive Reasoning](https://arxiv.org/abs/2510.21093)
*Siyong Chen,Jinbo Wen,Jiawen Kang,Tenghui Huang,Xumin Huang,Yuanjia Su,Hudan Pan,Zishao Zhong,Dusit Niyato,Shengli Xie,Dong In Kim*

Main category: cs.AI

TL;DR: 开发了一个名为MedAlign的新框架，通过多模态偏好优化(mDPO)和检索感知专家混合(RA-MoE)架构来提高Large Vision-Language Models (LVLMs)在医疗领域的应用。该框架还使用了一个联邦治理机制，实现适应性推理和跨机构协作。实验结果表明MedAlign在医学图像问题回答方面有优异表现，F1分数提高了11.85%，并缩短了51.60%的推理长度。


<details>
  <summary>Details</summary>
Motivation: 在医疗智能服务中，LVLMs的应用受到三个方面的主要挑战：幻觉回答、固定深度推理效率低和跨机构协作困难。为了解决这些问题，开发了MedAlign框架来确保视觉正确的LVLMs在医疗图像问题回答（Med-VQA）中的应用。

Method: MedAlign框架采用一种新颖的多模态直接偏好优化（mDPO）目标，来明确将偏好学习与视觉上下文对齐。同时，提出了一种基于检索的混合专家（RA-MoE）架构，利用图像和文本相似性来路由查询到专门的专家。此外，还设计了一个联邦治理机制，其中选定的专家在本地进行基于mDPO的临床数据集微调的迭代链式推理，通过本地元认知不确定性估计器进行。

Result: 在三个代表性的Med-VQA数据集上，MedAlign框架的表现优于基准方法，提高了11.85%的F1分数，缩短了51.60%的推理长度。

Conclusion: MedAlign框架大幅度提升了LVLMs在医疗图像问题回答中的性能，为医疗智能服务提供了新的方向。

Abstract: Recently, large models have shown significant potential for smart healthcare.
However, the deployment of Large Vision-Language Models (LVLMs) for clinical
services is currently hindered by three critical challenges: a tendency to
hallucinate answers not grounded in visual evidence, the inefficiency of
fixed-depth reasoning, and the difficulty of multi-institutional collaboration.
To address these challenges, in this paper, we develop MedAlign, a novel
framework to ensure visually accurate LVLM responses for Medical Visual
Question Answering (Med-VQA). Specifically, we first propose a multimodal
Direct Preference Optimization (mDPO) objective to explicitly align preference
learning with visual context. We then design a Retrieval-Aware
Mixture-of-Experts (RA-MoE) architecture that utilizes image and text
similarity to route queries to a specialized and context-augmented LVLM (i.e.,
an expert), thereby mitigating hallucinations in LVLMs. To achieve adaptive
reasoning and facilitate multi-institutional collaboration, we propose a
federated governance mechanism, where the selected expert, fine-tuned on
clinical datasets based on mDPO, locally performs iterative Chain-of-Thought
(CoT) reasoning via the local meta-cognitive uncertainty estimator. Extensive
experiments on three representative Med-VQA datasets demonstrate that MedAlign
achieves state-of-the-art performance, outperforming strong retrieval-augmented
baselines by up to $11.85\%$ in F1-score, and simultaneously reducing the
average reasoning length by $51.60\%$ compared with fixed-depth CoT approaches.

</details>


### [142] [NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented Generation of LLM via Genetic Optimization of External Knowledge](https://arxiv.org/abs/2510.21144)
*Hanyu Zhu,Lance Fiondella,Jiawei Yuan,Kai Zeng,Long Jiao*

Main category: cs.AI

TL;DR: 提出了一种新的针对RAG（Retrieval-Augmented Generation）的攻击框架NeuroGenPoisoning，该框架通过生成对抗性外部知识来扰乱模型的内部神经元激活状态，同时有效解决了知识冲突问题，确保了语言模型的生成性与流畅性。实验结果表明，这种方法可以高效生成有效的被篡改知识，且能保持高准确率与流畅度。


<details>
  <summary>Details</summary>
Motivation: 现有针对RAG的攻击策略主要集中在操纵检索内容或提示结构上，忽视了模型内部表示动态和神经元层面的敏感性。因此，提出了一种基于大语言模型（Large Language Models, LLMs）的内部神经元归因和遗传优化的新攻击框架NeuroGenPoisoning，旨在生成对抗性的外部知识，以解决现有攻击策略的不足。

Method: 首先，该方法通过识别那些与上下文中中毒知识强烈相关的Poison-Responsive Neurons，然后利用遗传算法演化出能够最大程度激活这些神经元的对抗性段落。此外，该框架还通过观察归因信号来大量生成有效的被篡改知识，同时解决了知识冲突问题。

Result: 实验结果显示，该框架可显著提高Poison Overwrite Success Rate (POSR)，达到90%以上，且保持了语言模型输出的流畅性。实验证据表明，该方法可以有效解决知识冲突问题。

Conclusion: NeuroGenPoisoning提出了一种基于神经元归因和遗传优化的新攻击方法，不仅能够生成有效的被篡改知识，还解决了知识冲突的问题，保持了模型输出的流畅性。

Abstract: Retrieval-Augmented Generation (RAG) empowers Large Language Models (LLMs) to
dynamically integrate external knowledge during inference, improving their
factual accuracy and adaptability. However, adversaries can inject poisoned
external knowledge to override the model's internal memory. While existing
attacks iteratively manipulate retrieval content or prompt structure of RAG,
they largely ignore the model's internal representation dynamics and
neuron-level sensitivities. The underlying mechanism of RAG poisoning has not
been fully studied and the effect of knowledge conflict with strong parametric
knowledge in RAG is not considered. In this work, we propose NeuroGenPoisoning,
a novel attack framework that generates adversarial external knowledge in RAG
guided by LLM internal neuron attribution and genetic optimization. Our method
first identifies a set of Poison-Responsive Neurons whose activation strongly
correlates with contextual poisoning knowledge. We then employ a genetic
algorithm to evolve adversarial passages that maximally activate these neurons.
Crucially, our framework enables massive-scale generation of effective poisoned
RAG knowledge by identifying and reusing promising but initially unsuccessful
external knowledge variants via observed attribution signals. At the same time,
Poison-Responsive Neurons guided poisoning can effectively resolves knowledge
conflict. Experimental results across models and datasets demonstrate
consistently achieving high Population Overwrite Success Rate (POSR) of over
90% while preserving fluency. Empirical evidence shows that our method
effectively resolves knowledge conflict.

</details>


### [143] [How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and Reasoning through Evolutionary Domain Knowledge Adaptation](https://arxiv.org/abs/2510.21148)
*Yang Zhao,Pu Wang,Hao Frank Yang*

Main category: cs.AI

TL;DR: 提出了一种自动化框架EGO-Prompt，用于优化大语言模型（LLM）在特定领域的任务中的提示和推理过程。该框架通过迭代优化算法，提高了LLM的性能，并且提高了可解释性。在公共健康、交通和人类行为等任务上，EGO-Prompt的表现比现有最佳方法高出7.32%-12.61%。同时，小模型也能达到大模型的性能，但成本仅为后者的20%左右。


<details>
  <summary>Details</summary>
Motivation: 为了在现实世界的应用中设计出最优的提示和推理过程，以整合领域知识，提高推理效率，并提供给领域专家更好的知识整合提示，但是这在实际操作中是一项既必要又具有挑战性的任务。这个问题仍然没有被很好地解决，因此需要提出一种新的方法来解决这些挑战。

Method: EGO-Prompt 开始于一般提示和语义因果图形（SCG）描述，这些建立在初始的人类专家设定的基础上。然后，这个框架会被自动地优化来引导大语言模型进行推理。在专家定义的SCG可能是不完善的情况下，EGO-Prompt通过两次迭代强化Llama的流程，第一次，通过构建SCG产生几乎确定的推理引导；接下来，框架将调整Llama，使其能有效地利用这个引导与原始输入相结合。

Result: EGO-Prompt被测试在真实的公共卫生、交通以及人类行为等任务中，其结果比现有的最先进的方法提高了7.32%-12.61%的F1值。同时，小规模的模型也能够达到大规模模型的性能，但成本为后者的20%左右。最后，它的输出是一个更细致的、更具有特定领域的SCG，这提升了可解释性。

Conclusion: EGO-Prompt在多个领域展示了优于现有最佳方法的结果，以及付出较少计算资源实现大规模模型性能的能力，证明了其在设计优化大语言模型特定领域任务提示和推理过程中的有效性和新颖性。

Abstract: Designing optimal prompts and reasoning processes for large language models
(LLMs) on domain-specific tasks is both necessary and challenging in real-world
applications. Determining how to integrate domain knowledge, enhance reasoning
efficiency, and even provide domain experts with refined knowledge integration
hints are particularly crucial yet unresolved tasks. In this research, we
propose Evolutionary Graph Optimization for Prompting (EGO-Prompt), an
automated framework to designing better prompts, efficient reasoning processes
and providing enhanced causal-informed process. EGO-Prompt begins with a
general prompt and fault-tolerant initial Semantic Causal Graph (SCG)
descriptions, constructed by human experts, which is then automatically refined
and optimized to guide LLM reasoning. Recognizing that expert-defined SCGs may
be partial or imperfect and that their optimal integration varies across LLMs,
EGO-Prompt integrates a novel causal-guided textual gradient process in two
steps: first, generating nearly deterministic reasoning guidance from the SCG
for each instance, and second, adapting the LLM to effectively utilize the
guidance alongside the original input. The iterative optimization algorithm
further refines both the SCG and the reasoning mechanism using textual
gradients with ground-truth. We tested the framework on real-world public
health, transportation and human behavior tasks. EGO-Prompt achieves
7.32%-12.61% higher F1 than cutting-edge methods, and allows small models to
reach the performence of larger models at under 20% of the original cost. It
also outputs a refined, domain-specific SCG that improves interpretability.

</details>


### [144] [String Seed of Thought: Prompting LLMs for Distribution-Faithful and Diverse Generation](https://arxiv.org/abs/2510.21150)
*Kou Misaki,Takuya Akiba*

Main category: cs.AI

TL;DR: 本文提出了一个新的LLM提示方法String Seed of Thought (SSoT)，用于提高概率指令遵循(PIF)任务的表现，使得LLM在遇到需要非确定性行为的任务时，能够更好地生成多样化的响应。


<details>
  <summary>Details</summary>
Motivation: 虽然现有的大规模语言模型在解决需要单个确定性答案的任务上表现优异，但它们在解决概率指令遵循(PIF)任务时存在偏向，影响了一种生成多样化响应的能力，而这一能力对于模拟人类行为、内容多样化生成以及多人游戏应用等场景至关重要。因此，需要一个新方法来解决这个问题。

Method: 通过引入SSoT方法，该方法让LLM首先生成一个随机字符串以产生足够的熵，然后利用这个字符串导出最终答案，以维持多样性和满足特定约束。这种方法可以显著改善LLM在PIF任务上的表现，接近伪随机数生成器的性能。

Result: 实验结果表明，SSoT方法能够显著提高LLM在PIF任务上的性能，同时这种方法的好处也扩展到了对开放性任务而言可以增强响应多样性的场景。

Conclusion: 提出了一个名为String Seed of Thought (SSoT)的新方法，该方法通过创新的提示方式解决了现有的大规模语言模型在生成多样响应时存在不足的问题。

Abstract: We introduce String Seed of Thought (SSoT), a novel prompting method for LLMs
that improves Probabilistic Instruction Following (PIF). We define PIF as a
task requiring an LLM to select its answer from a predefined set of options,
each associated with a specific probability, such that the empirical
distribution of the generated answers aligns with the target distribution when
prompted multiple times. While LLMs excel at tasks with single, deterministic
answers, they often fail at PIF, exhibiting biases problematic for applications
requiring non-deterministic behaviors, such as human-behavior simulation,
content diversification, and multiplayer games. It also harms the diversity of
generated responses, a crucial factor in test-time scaling, by causing the
outputs to collapse into a limited set of answers. To address this, we propose
SSoT, a simple prompting method that instructs an LLM to first output a random
string to generate sufficient entropy. SSoT also instructs the LLM to extract
randomness by manipulating this string to derive a final answer, thereby
preserving diversity while adhering to specific constraints. We demonstrate
that SSoT significantly improves the PIF performance of LLMs, approaching the
ideal performance of a pseudo-random number generator. Furthermore, our
experiments on NoveltyBench show SSoT's benefits extend beyond closed-set tasks
to open-ended tasks by enhancing response diversity.

</details>


### [145] [Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot Vision-Language Models](https://arxiv.org/abs/2510.21175)
*Yujin Jo,Taesup Kim*

Main category: cs.AI

TL;DR: 介绍了NuSA-CL，一种无内存的持续学习框架，旨在为预训练的视觉语言模型（如CLIP）在真实环境中的任务持续学习提供解决方案。通过低秩适应和任务特定权重更新，在模型当前参数的近似零空间中进行约束，以最小化对先前知识的干扰，有效保持零样本迁移能力。实验表明该框架在持续学习基准上具有很高的竞争力，是一种实用且可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉语言模型虽然在零样本任务上有很强的表现，但是在具有分布变化和新任务的真实环境下，需要一种新的学习方法来避免灾难性遗忘，持续学习。现有的方法如使用回放缓冲区或昂贵的知识蒸馏，都会增加计算和内存的负担，因此提出了一种新的轻量级无内存的持续学习框架NuSA-CL来解决这个问题。

Method: NuSA-CL 采用低秩适应方法，并将任务特定的权重更新限制在模型当前参数的近似零空间，以避免对先前知识的干扰，同时保持零样本迁移的能力。这种方法避免了额外的内存和计算需求，适合于资源受限的持续学习环境。

Result: 实验表明，NuSA-CL 不仅有效保持了零样本迁移能力，还获得了和现有基准相当的持续学习性能，展示了该方法的实用性和扩展性。

Conclusion: 提出了NuSA-CL，一个轻量级且不需要额外内存的持续学习框架，能够有效帮助预训练的视觉语言模型在持续学习环境中保持性能，证明了其在持续学习基准上的优良表现及其实用性，具有广泛的潜在应用价值。

Abstract: Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated
remarkable zero-shot generalization, enabling deployment in a wide range of
real-world tasks without additional task-specific training. However, in real
deployment scenarios with evolving environments or emerging classes, these
models inevitably face distributional shifts and novel tasks. In such contexts,
static zero-shot capabilities are insufficient, and there is a growing need for
continual learning methods that allow models to adapt over time while avoiding
catastrophic forgetting. We introduce NuSA-CL (Null Space Adaptation for
Continual Learning), a lightweight memory-free continual learning framework
designed to address this challenge. NuSA-CL employs low-rank adaptation and
constrains task-specific weight updates to lie within an approximate null space
of the model's current parameters. This strategy minimizes interference with
previously acquired knowledge, effectively preserving the zero-shot
capabilities of the original model. Unlike methods relying on replay buffers or
costly distillation, NuSA-CL imposes minimal computational and memory overhead,
making it practical for deployment in resource-constrained, real-world
continual learning environments. Experiments show that our framework not only
effectively preserves zero-shot transfer capabilities but also achieves highly
competitive performance on continual learning benchmarks. These results
position NuSA-CL as a practical and scalable solution for continually evolving
zero-shot VLMs in real-world applications.

</details>


### [146] [OutboundEval: A Dual-Dimensional Benchmark for Expert-Level Intelligent Outbound Evaluation of Xbench's Professional-Aligned Series](https://arxiv.org/abs/2510.21244)
*Pengyu Xu,Shijia Li,Ao Sun,Feng Zhang,Yahan Li,Bo Wu,Zhanyu Ma,Jiguo Li,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Rui Wang,Yang Liu,Xiaobo Hu,Fan Yang,Jia Zheng,Guanghua Yao*

Main category: cs.AI

TL;DR: OutboundEval是一个用于评估大型语言模型在专家级智能外呼场景中的表现的全面基准。它解决了现有方法在数据集多样性、用户模拟和评估指标方面的不足，通过结构化框架、多样化用户模拟和动态评估方法来提升评估的准确性。实验表明，不同模型在任务完成和交互流畅性之间存在权衡，提出了一种面向专业的评估标准。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在评估大型语言模型时存在三大问题：数据集多样性和覆盖不足、用户模拟不真实、评估指标不准确。为此，本文提出OutboundEval，旨在构建一个全面、真实的评估环境，提升对模型的专业应用能力评估的准确性与可靠性。

Method: OutboundEval通过以下步骤实现：1、设计覆盖六个主要业务领域及其子场景的基准；2、开发一个基于大模型的用户模拟器，生成多样且富含个人特质的虚拟用户；3、引入一个适应任务变化的动态评估方法，结合自动化评估和人为干预，多维度评估大型语言模型的能力。

Result: 实验结果显示，不同大型语言模型在专家级任务完成和交互流畅性方面存在不同的权衡，这表明在构建可靠且似人的外呼AI系统时，有必要评估这些不同维度的能力和性能。

Conclusion: OutboundEval提供了一种面向专业的评估标准，为大型语言模型在专业应用中的性能评估树立了一个实用、可扩展且领域导向的标杆。

Abstract: We propose OutboundEval, a comprehensive benchmark for evaluating large
language models (LLMs) in expert-level intelligent outbound calling scenarios.
Unlike existing methods that suffer from three key limitations - insufficient
dataset diversity and category coverage, unrealistic user simulation, and
inaccurate evaluation metrics - OutboundEval addresses these issues through a
structured framework. First, we design a benchmark spanning six major business
domains and 30 representative sub-scenarios, each with scenario-specific
process decomposition, weighted scoring, and domain-adaptive metrics. Second,
we develop a large-model-driven User Simulator that generates diverse,
persona-rich virtual users with realistic behaviors, emotional variability, and
communication styles, providing a controlled yet authentic testing environment.
Third, we introduce a dynamic evaluation method that adapts to task variations,
integrating automated and human-in-the-loop assessment to measure task
execution accuracy, professional knowledge application, adaptability, and user
experience quality. Experiments on 12 state-of-the-art LLMs reveal distinct
trade-offs between expert-level task completion and interaction fluency,
offering practical insights for building reliable, human-like outbound AI
systems. OutboundEval establishes a practical, extensible, and domain-oriented
standard for benchmarking LLMs in professional applications.

</details>


### [147] [Out-of-Distribution Detection for Safety Assurance of AI and Autonomous Systems](https://arxiv.org/abs/2510.21254)
*Victoria J. Hodge,Colin Paterson,Ibrahim Habli*

Main category: cs.AI

TL;DR: 本文综述了针对自主系统的安全性保障的出界数据检测技术。重点探讨了导致出界数据的原因、自主系统安全性保障以及出界数据检测的挑战因素，同时也指出了在机器学习开发周期中可以使用的多种技术以及将其整合入系统周期时需要注意的事项。


<details>
  <summary>Details</summary>
Motivation: 由于机器人技术和机器学习的进步，AI增强的自主系统的操作能力和应用领域在过去几年中显著扩展。然而，为了负责任地采用这些系统，需要严格的验证方法来保证其安全性，尤其是在面对新颖和不确定的情况时。因此，这种综述旨在分析在过去的研究、开发和安全工程社区中受到越来越多关注的出界数据检测技术，尤其是在安全性关键领域。

Method: 首先定义了相关的概念，探讨了是什么导致了出界数据，然后研究了自主系统安全性保障以及出界数据检测面对的挑战因素。我们回顾了在整个机器学习开发生命周期中可以使用的一系列技术，并提出了在生命周期中可能使用这些技术来支持安全性保障论证的领域。我们讨论了系统和安全工程师在将出界数据检测整合入系统周期中必须注意的多个事项。

Result: 文中确认了一系列可以用于在整个机器学习开发周期中的技术，并建议了它们在生命周期中的使用位置以支持安全性保障论证。最后指出了整合出界数据检测到系统周期中的注意事项。

Conclusion: 最后总结了为了在各种领域和应用中的自主系统安全开发和操作而必需的挑战和未来工作。提出了整个开发生命周期中应在各种阶段使用出界数据检测方法的想法，同时回顾了在将出界数据检测整合入系统周期中时的注意事项。

Abstract: The operational capabilities and application domains of AI-enabled autonomous
systems have expanded significantly in recent years due to advances in robotics
and machine learning (ML). Demonstrating the safety of autonomous systems
rigorously is critical for their responsible adoption but it is challenging as
it requires robust methodologies that can handle novel and uncertain situations
throughout the system lifecycle, including detecting out-of-distribution (OoD)
data. Thus, OOD detection is receiving increased attention from the research,
development and safety engineering communities. This comprehensive review
analyses OOD detection techniques within the context of safety assurance for
autonomous systems, in particular in safety-critical domains. We begin by
defining the relevant concepts, investigating what causes OOD and exploring the
factors which make the safety assurance of autonomous systems and OOD detection
challenging. Our review identifies a range of techniques which can be used
throughout the ML development lifecycle and we suggest areas within the
lifecycle in which they may be used to support safety assurance arguments. We
discuss a number of caveats that system and safety engineers must be aware of
when integrating OOD detection into system lifecycles. We conclude by outlining
the challenges and future work necessary for the safe development and operation
of autonomous systems across a range of domains and applications.

</details>


### [148] [Investigating Scale Independent UCT Exploration Factor Strategies](https://arxiv.org/abs/2510.21275)
*Robin Schmöcker,Christoph Schnell,Alexander Dockhorn*

Main category: cs.AI

TL;DR: 本论文研究了UCT算法在面对不同奖励尺度的游戏时的表现，并提出了一种新的自适应选择UCT探索常数$λ$的方法。实验结果显示，新提出的方法优于现有方法，并且在一系列任务中表现更佳。这种新方法是选择$λ$作为所有状态动作对的Q值的经验标准差$2 σ$。


<details>
  <summary>Details</summary>
Motivation: 传统上应用于零和游戏中的UCT算法在面对奖励尺度不同的游戏时可能出现问题。研究团队旨在提升UCT算法对不同奖励尺度的适应性，提出了多种适应性选择探索常数$λ$的新策略。

Method: 团队评估了各种选择UCT探索常数$λ$的新策略，包括五种新的实验策略，其中一种成功的方法是将$λ$设置为所有状态动作对Q值的经验标准差乘以$2$。这些策略旨在减少对游戏奖励尺度的敏感性。

Result: 实验结果证明了新提出的选取$λ$为$2* σ$的方法表现出色，优于现有方法。这种新方法不仅在单一参数的设置下表现优于现有方法，在通过优化全部可用参数获得的峰值性能方面也超过了现有方法。

Conclusion: 针对不同奖励尺度的游戏，选择$λ$为所有状态动作对Q值的经验标准差的$2$倍的方法可以提高UCT算法的性能与适应性，为使用UCT算法解决具有不同奖励尺度问题提供了一种有效的方法。

Abstract: The Upper Confidence Bounds For Trees (UCT) algorithm is not agnostic to the
reward scale of the game it is applied to. For zero-sum games with the sparse
rewards of $\{-1,0,1\}$ at the end of the game, this is not a problem, but many
games often feature dense rewards with hand-picked reward scales, causing a
node's Q-value to span different magnitudes across different games. In this
paper, we evaluate various strategies for adaptively choosing the UCT
exploration constant $\lambda$, called $\lambda$-strategies, that are agnostic
to the game's reward scale. These $\lambda$-strategies include those proposed
in the literature as well as five new strategies. Given our experimental
results, we recommend using one of our newly suggested $\lambda$-strategies,
which is to choose $\lambda$ as $2 \cdot \sigma$ where $\sigma$ is the
empirical standard deviation of all state-action pairs' Q-values of the search
tree. This method outperforms existing $\lambda$-strategies across a wide range
of tasks both in terms of a single parameter value and the peak performances
obtained by optimizing all available parameters.

</details>


### [149] [When Models Outthink Their Safety: Mitigating Self-Jailbreak in Large Reasoning Models with Chain-of-Guardrails](https://arxiv.org/abs/2510.21285)
*Yingzhi Mao,Chunkang Zhang,Junxiang Wang,Xinyan Guan,Boxi Cao,Yaojie Lu,Hongyu Lin,Xianpei Han,Le Sun*

Main category: cs.AI

TL;DR: 大推理模型（LRMs）在复杂推理任务上表现出色，但存在生成有害内容和遭受攻击的风险。研究者提出了一种称为Chain-of-Guardrail（CoG）的训练框架，该框架能够重组或回溯不安全的推理步骤，使模型返回到安全轨迹，同时保留有效的推理链。实验结果表明，CoG在保持推理能力的同时显著提高模型的安全性，比以前的方法有明显优势。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型存在生成有害内容和遭受攻击的风险，而现有的缓解策略在缓解风险的同时抑制了模型的推理能力，无法解决安全性与推理能力之间的权衡问题。

Method: 通过分析不同大型推理模型的推理过程，发现了称为自我监禁的现象，并提出了Chain-of-Guardrail框架，该框架能够重组或回溯不安全的推理步骤，以确保模型的安全性。

Result: 实验结果表明，Chain-of-Guardrail框架能够显著提高大型推理模型的安全性，同时保持其推理能力，超过了之前的方法。

Conclusion: 研究表明，大型推理模型具有拒绝不安全请求的能力，但这种能力可能会受损，导致有害输出。通过引入Chain-of-Guardrail框架，可以有效缓解这一问题。

Abstract: Large Reasoning Models (LRMs) demonstrate remarkable capabilities on complex
reasoning tasks but remain vulnerable to severe safety risks, including harmful
content generation and jailbreak attacks. Existing mitigation strategies rely
on injecting heuristic safety signals during training, which often suppress
reasoning ability and fail to resolve the safety-reasoning trade-off. To
systematically investigate this issue, we analyze the reasoning trajectories of
diverse LRMs and uncover a phenomenon we term Self-Jailbreak, where models
override their own risk assessments and justify responding to unsafe prompts.
This finding reveals that LRMs inherently possess the ability to reject unsafe
queries, but this ability is compromised, resulting in harmful outputs.
Building on these insights, we propose the Chain-of-Guardrail (CoG), a training
framework that recomposes or backtracks unsafe reasoning steps, steering the
model back onto safe trajectories while preserving valid reasoning chains.
Extensive experiments across multiple reasoning and safety benchmarks
demonstrate that CoG substantially improves the safety of current LRMs while
preserving comparable reasoning ability, significantly outperforming prior
methods that suffer from severe safety-reasoning trade-offs.

</details>


### [150] [Understanding AI Trustworthiness: A Scoping Review of AIES & FAccT Articles](https://arxiv.org/abs/2510.21293)
*Siddharth Mehrotra,Jin Huang,Xuelong Fu,Roel Dobbe,Clara I. Sánchez,Maarten de Rijke*

Main category: cs.AI

TL;DR: 此研究认为当前AI伦理研究过多地关注技术层面的属性，如透明度、可问责性和鲁棒性，而忽略了社会和伦理方面的考量。研究者提出，理解和构建可信AI需要一个跨学科的方法，结合技术严谨性、社会、文化和机构因素，才能真正解决人工智能系统与社会之间的复杂互动，促进负责任的技术发展，造福所有相关方。 


<details>
  <summary>Details</summary>
Motivation: 当前AI伦理研究往往采用技术中心的方法，侧重于诸如可靠性、稳健性和公平性等技术属性，而忽视了理解AI可信度所必需的社会技术方面。因此，本研究旨在通过系统分析AIES和FAccT社区如何定义、度量和验证AI可信度，来确定主要差距和机会，进而提出一种结合技术严谨性和社会文化因素的多学科方法。

Method: 本研究对AIES和FAccT会议论文进行了系统回顾，分析了在其议程中如何定义、操作化和应用可信度，包括概念化方法、度量方法、确认和验证技术、应用领域和相关价值观。

Result: 虽然在定义技术属性方面取得了很大进展，但本研究发现，当前研究往往过于强调技术精度，而忽视了社会和伦理考虑。也不够探索AI系统的社会技术性质，导致了可信度的定义受有权定义它的人或群体所左右。

Conclusion: 为促进可信的AI，跨学科方法至关重要，即结合技术严谨性和社会、文化和制度因素，以真正解决AI系统与社会之间的复杂相互作用，推动负责任的技术发展，造福所有人。

Abstract: Background: Trustworthy AI serves as a foundational pillar for two major AI
ethics conferences: AIES and FAccT. However, current research often adopts
techno-centric approaches, focusing primarily on technical attributes such as
reliability, robustness, and fairness, while overlooking the sociotechnical
dimensions critical to understanding AI trustworthiness in real-world contexts.
  Objectives: This scoping review aims to examine how the AIES and FAccT
communities conceptualize, measure, and validate AI trustworthiness,
identifying major gaps and opportunities for advancing a holistic understanding
of trustworthy AI systems.
  Methods: We conduct a scoping review of AIES and FAccT conference proceedings
to date, systematically analyzing how trustworthiness is defined,
operationalized, and applied across different research domains. Our analysis
focuses on conceptualization approaches, measurement methods, verification and
validation techniques, application areas, and underlying values.
  Results: While significant progress has been made in defining technical
attributes such as transparency, accountability, and robustness, our findings
reveal critical gaps. Current research often predominantly emphasizes technical
precision at the expense of social and ethical considerations. The
sociotechnical nature of AI systems remains less explored and trustworthiness
emerges as a contested concept shaped by those with the power to define it.
  Conclusions: An interdisciplinary approach combining technical rigor with
social, cultural, and institutional considerations is essential for advancing
trustworthy AI. We propose actionable measures for the AI ethics community to
adopt holistic frameworks that genuinely address the complex interplay between
AI systems and society, ultimately promoting responsible technological
development that benefits all stakeholders.

</details>


### [151] [Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning](https://arxiv.org/abs/2510.21302)
*Sanghyun Ahn,Wonje Choi,Junyong Lee,Jinwoo Park,Honguk Woo*

Main category: cs.AI

TL;DR: 本文提出了一个神经符号实体任务规划框架，通过在代码生成过程中加入显式符号验证和交互验证步骤，提高了在复杂环境中生成代码的环境接地性，从而提高了任务成功率和执行率。实验表明，与Code-as-Policies基线相比，任务成功率提高了46.2%，任务相关行动的执行率超过了86.8%。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的代码生成方法存在环境特征缺失的问题，在动态或部分可观察场景中表现不佳。为解决这一问题，本文提出了一个基于神经符号的方法来改进代码生成的质量和环境适应性。

Method: 本文的方法采用了一个神经符号实体力任务规划框架，该框架在代码生成过程中加入了显式符号验证和交互验证的过程，能够在动态或者部分可观察的环境场景中自动生成代码，通过交互验证实现环境数据收集、优化生成代码。

Result: 实验结果表明，与基线方法相比，该框架成功提高了任务成功率和执行率，在复杂环境场景中表现更佳。具体来说，任务成功率提高了46.2%，任务相关行动的执行率超过了86.8%。

Conclusion: 本文提出的方法证明了通过引入神经符号验证和交互验证步骤，可以在动态或部分可观察环境下生成更具可靠性的任务规划代码，有助于提升实体智能系统的任务执行效率。

Abstract: Recent advances in large language models (LLMs) have enabled the automatic
generation of executable code for task planning and control in embodied agents
such as robots, demonstrating the potential of LLM-based embodied intelligence.
However, these LLM-based code-as-policies approaches often suffer from limited
environmental grounding, particularly in dynamic or partially observable
settings, leading to suboptimal task success rates due to incorrect or
incomplete code generation. In this work, we propose a neuro-symbolic embodied
task planning framework that incorporates explicit symbolic verification and
interactive validation processes during code generation. In the validation
phase, the framework generates exploratory code that actively interacts with
the environment to acquire missing observations while preserving task-relevant
states. This integrated process enhances the grounding of generated code,
resulting in improved task reliability and success rates in complex
environments. We evaluate our framework on RLBench and in real-world settings
across dynamic, partially observable scenarios. Experimental results
demonstrate that our framework improves task success rates by 46.2% over
Code-as-Policies baselines and attains over 86.8% executability of
task-relevant actions, thereby enhancing the reliability of task planning in
dynamic environments.

</details>


### [152] [CXRAgent: Director-Orchestrated Multi-Stage Reasoning for Chest X-Ray Interpretation](https://arxiv.org/abs/2510.21324)
*Jinhui Lou,Yan Yang,Zhou Yu,Zhenqi Fu,Weidong Han,Qingming Huang,Jun Yu*

Main category: cs.AI

TL;DR: 提出了一种新的CXR分析方法CXRAgent，它通过中央调度器协调工具调用、诊断计划和协作决策三个阶段的工作，提高了CXRX光片分析的适应性和可信度。实验表明，CXRAgent在各种CXR解释任务中表现优异，能够提供视觉证据并推广至不同复杂度的临床任务中。


<details>
  <summary>Details</summary>
Motivation: 现有的CXR分析模型缺乏适应性和可信度，特别是在处理新诊断任务和复杂推理场景时。为了提高模型的适应性、可信度和推理能力，提出CXRAgent方法。

Method: CXRAgent由工具调用、诊断规划和协作决策三个阶段组成。工具调用阶段通过证据驱动的验证器调用预定义的CXR分析工具；诊断规划阶段根据任务要求和中间发现制定诊断计划，并根据任务要求和中间发现组装专家团队；协作决策阶段将专家团队的见解与上下文记忆综合成基于证据的诊断结论。

Result: 实验显示CXRAgent在各种CXR解释任务中表现良好，能够提供丰富的视觉证据，并在不同的复杂氛围中表现出较好的推广能力，证明该方法的有效性和鲁棒性。

Conclusion: CXRAgent是一种强大的CXR分析方法，通过三个阶段的工作来提高模型的适应性和推理能力，为CXR分析提供了一个新方向。

Abstract: Chest X-ray (CXR) plays a pivotal role in clinical diagnosis, and a variety
of task-specific and foundation models have been developed for automatic CXR
interpretation. However, these models often struggle to adapt to new diagnostic
tasks and complex reasoning scenarios. Recently, LLM-based agent models have
emerged as a promising paradigm for CXR analysis, enhancing model's capability
through tool coordination, multi-step reasoning, and team collaboration, etc.
However, existing agents often rely on a single diagnostic pipeline and lack
mechanisms for assessing tools' reliability, limiting their adaptability and
credibility. To this end, we propose CXRAgent, a director-orchestrated,
multi-stage agent for CXR interpretation, where a central director coordinates
the following stages: (1) Tool Invocation: The agent strategically orchestrates
a set of CXR-analysis tools, with outputs normalized and verified by the
Evidence-driven Validator (EDV), which grounds diagnostic outputs with visual
evidence to support reliable downstream diagnosis; (2) Diagnostic Planning:
Guided by task requirements and intermediate findings, the agent formulates a
targeted diagnostic plan. It then assembles an expert team accordingly,
defining member roles and coordinating their interactions to enable adaptive
and collaborative reasoning; (3) Collaborative Decision-making: The agent
integrates insights from the expert team with accumulated contextual memories,
synthesizing them into an evidence-backed diagnostic conclusion. Experiments on
various CXR interpretation tasks show that CXRAgent delivers strong
performance, providing visual evidence and generalizes well to clinical tasks
of different complexity. Code and data are valuable at this
\href{https://github.com/laojiahuo2003/CXRAgent/}{link}.

</details>


### [153] [Advancing Symbolic Integration in Large Language Models: Beyond Conventional Neurosymbolic AI](https://arxiv.org/abs/2510.21425)
*Maneeha Rani,Bhupesh Kumar Mishra,Dhavalkumar Thakker*

Main category: cs.AI

TL;DR: 本文通过回顾现有的神经符号AI方法并提出一个新的符号集成到LLM的分类框架以及一个融合符号技术与LLM的路线图，来解决LLM透明度的问题。此框架涵盖了符号整合的不同阶段，耦合机制，架构范例，算法和应用级别视角等四个维度，并识别当前的基准，最前沿的进展和关键的差距，以促进未来的研究并提供如何实现增强LLM透明度的实用见解。


<details>
  <summary>Details</summary>
Motivation: 目前存在的是如何有效地将符号AI集成到LLM中以解决其透明度挑战的问题，现有的NeSy AI方法并不是专门为满足LLM的特定特征而设计的，因此需要一个系统性的理解以及实施方案来克服这一问题。

Method: 该论文首先回顾了已有的神经符号AI方法，然后提出了一种新的分类框架来描述如何将符号技术融入LLM，并通过组织现有文献介绍了一个路线图来指导未来的研发工作。这个路线图涵盖了四个维度：符号在LLM的各个阶段中的整合，整合的耦合机制，架构范式，还有算法及应用层面的角度。

Result: 论文识别出当前的基准，最先进的进展和关键的知识差距，并提供了一个融合符号和LLM的路线图以及未来研究的实施框架。

Conclusion: 通过识别最新的进展和知识性的差距，论文提供了关于如何将符号技术高效地融入LLM，使得LLM更透明地工作的实际见解。

Abstract: LLMs have demonstrated highly effective learning, human-like response
generation,and decision-making capabilities in high-risk sectors. However,
these models remain black boxes because they struggle to ensure transparency in
responses. The literature has explored numerous approaches to address
transparency challenges in LLMs, including Neurosymbolic AI (NeSy AI). NeSy AI
approaches were primarily developed for conventional neural networks and are
not well-suited to the unique features of LLMs. Consequently, there is a
limited systematic understanding of how symbolic AI can be effectively
integrated into LLMs. This paper aims to address this gap by first reviewing
established NeSy AI methods and then proposing a novel taxonomy of symbolic
integration in LLMs, along with a roadmap to merge symbolic techniques with
LLMs. The roadmap introduces a new categorisation framework across four
dimensions by organising existing literature within these categories. These
include symbolic integration across various stages of LLM, coupling mechanisms,
architectural paradigms, as well as algorithmic and application-level
perspectives. The paper thoroughly identifies current benchmarks, cutting-edge
advancements, and critical gaps within the field to propose a roadmap for
future research. By highlighting the latest developments and notable gaps in
the literature, it offers practical insights for implementing frameworks for
symbolic integration into LLMs to enhance transparency.

</details>


### [154] [AutoOpt: A Dataset and a Unified Framework for Automating Optimization Problem Solving](https://arxiv.org/abs/2510.21436)
*Ankur Sinha,Shobhit Arora,Dhaval Pujara*

Main category: cs.AI

TL;DR: AutoOpt-11k 是一个包含超过 11,000 个手写和打印数学优化模型的图像数据集。研究还提出了 AutoOpt 框架，一种基于机器学习的自动化优化问题求解方法。AutoOpt 框架包括图像到文本的转换、文本到文本的转换以及优化三个模块，使用深度学习模型和一个小规模微调的语言模型进行前两个步骤，第三个步骤采用分解法（BOBD）来解决优化问题。实验表明，AutoOpt 的 MER 模型在BLEU分数上优于 ChatGPT、Gemini 和 Nougat，而BOBD 方法在解决复杂问题上也表现出色。 


<details>
  <summary>Details</summary>
Motivation: 动机是创建一个可以自动解决数学优化问题的系统，减少人为干预的需求。这是通过收集大量的数学优化问题图像数据集以及开发自动化求解框架来实现的。

Method: 方法包括构建 AutoOpt-11k 数据集，开发 AutoOpt 框架，并使用深度学习和其他技术解决优化问题。AutoOpt 框架由三个模块组成：图像到文本（MER）、文本到优化建模语言的转换以及优化解决。前两个模块由深度学习和语言模型支持，最后一个模块则使用了一种称为 Bilevel Optimization Based Decomposition (BOBD) 的方法。

Result: 研究结果表明，AutoOpt 的 MER 模型在 BLEU 分数基准上优于 ChatGPT、Gemini 和 Nougat，而 BOBD 方法在解决复杂测试问题上则优于传统的内点法和遗传算法。

Conclusion: 本文展示了 AutoOpt-11k 数据集及其 AutoOpt 框架在解决数学优化问题方面的有效性。

Abstract: This study presents AutoOpt-11k, a unique image dataset of over 11,000
handwritten and printed mathematical optimization models corresponding to
single-objective, multi-objective, multi-level, and stochastic optimization
problems exhibiting various types of complexities such as non-linearity,
non-convexity, non-differentiability, discontinuity, and high-dimensionality.
The labels consist of the LaTeX representation for all the images and modeling
language representation for a subset of images. The dataset is created by 25
experts following ethical data creation guidelines and verified in two-phases
to avoid errors. Further, we develop AutoOpt framework, a machine learning
based automated approach for solving optimization problems, where the user just
needs to provide an image of the formulation and AutoOpt solves it efficiently
without any further human intervention. AutoOpt framework consists of three
Modules: (i) M1 (Image_to_Text)- a deep learning model performs the
Mathematical Expression Recognition (MER) task to generate the LaTeX code
corresponding to the optimization formulation in image; (ii) M2 (Text_to_Text)-
a small-scale fine-tuned LLM generates the PYOMO script (optimization modeling
language) from LaTeX code; (iii) M3 (Optimization)- a Bilevel Optimization
based Decomposition (BOBD) method solves the optimization formulation described
in the PYOMO script. We use AutoOpt-11k dataset for training and testing of
deep learning models employed in AutoOpt. The deep learning model for MER task
(M1) outperforms ChatGPT, Gemini and Nougat on BLEU score metric. BOBD method
(M3), which is a hybrid approach, yields better results on complex test
problems compared to common approaches, like interior-point algorithm and
genetic algorithm.

</details>


### [155] [EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law](https://arxiv.org/abs/2510.21524)
*Ilija Lichkovski,Alexander Müller,Mariam Ibrahim,Tiwai Mhundwa*

Main category: cs.AI

TL;DR: 介绍EU-Agent-Bench，一个评估大型语言模型（LLM）在欧盟法律规范下行为合规性的基准，用于防止用户输入可能导致非法行为的情况。该基准适用于数据保护、偏见/歧视、科学诚信等领域，通过对比模型调用功能与相关立法的合规性来评估LLM的行为。



<details>
  <summary>Details</summary>
Motivation: 动机是评估和防止大型语言模型在处理用户请求时可能出现的非法行为，特别是在欧盟法律框架下的合规性问题。


Method: 该文章提出了一种新的评估基准EU-Agent-Bench，通过将模型产生的行为与欧盟相关法律规范进行对比，以此来评估模型的行为合规性。


Result: 研究发现，通过提供相关法律条款作为系统提示的一部分，并明确要求模型遵循这些条款，可以提高模型的行为合规性。


Conclusion: 结论是EU-Agent-Bench为评估大型语言模型在特定法律框架下的行为合规性提供了有效的工具，并建议未来的工作可以扩展到不同的司法管辖区和多轮次、多语言的交互中。

Abstract: Large language models (LLMs) are increasingly deployed as agents in various
contexts by providing tools at their disposal. However, LLM agents can exhibit
unpredictable behaviors, including taking undesirable and/or unsafe actions. In
order to measure the latent propensity of LLM agents for taking illegal actions
under an EU legislative context, we introduce EU-Agent-Bench, a verifiable
human-curated benchmark that evaluates an agent's alignment with EU legal norms
in situations where benign user inputs could lead to unlawful actions. Our
benchmark spans scenarios across several categories, including data protection,
bias/discrimination, and scientific integrity, with each user request allowing
for both compliant and non-compliant execution of the requested actions.
Comparing the model's function calls against a rubric exhaustively supported by
citations of the relevant legislature, we evaluate the legal compliance of
frontier LLMs, and furthermore investigate the compliance effect of providing
the relevant legislative excerpts in the agent's system prompt along with
explicit instructions to comply. We release a public preview set for the
research community, while holding out a private test set to prevent data
contamination in evaluating upcoming models. We encourage future work extending
agentic safety benchmarks to different legal jurisdictions and to multi-turn
and multilingual interactions. We release our code on
\href{https://github.com/ilijalichkovski/eu-agent-bench}{this URL}.

</details>


### [156] [Learning Neural Control Barrier Functions from Expert Demonstrations using Inverse Constraint Learning](https://arxiv.org/abs/2510.21560)
*Yuxuan Yang,Hussein Sibai*

Main category: cs.AI

TL;DR: 本文提出了一种使用交互式分类学习(ICAL)的方法来训练神经CBF，该方法通过分类系统状态为安全或不安全，从专家示范中学习避免失败集合的控制屏障函数。这种方法在多个环境中被证明优于现有基线方法，并且性能与使用真实安全标签的数据训练的神经CBF相当。


<details>
  <summary>Details</summary>
Motivation: 在自主系统中，控制屏障函数(CBFs)用来设计最小化改变名义控制的安全滤波器，以保持系统的安全性。但是，失败状态集合通常是非直观的或难以形式化，因此提出了使用数据驱动的方法来学习神经CBF，以解决基于优化合成的计算复杂性问题。为此，本研究试图开发一种更直观的方法，使用专家演示来定义安全状态，而不是显式地指定失败集合。

Method: 使用交互式分类学习(ICAL)来训练约束函数，该函数分类系统状态为安全或不安全状态，然后使用训练的约束函数对新生成的模拟轨迹进行标注，以此来训练神经CBF。

Result: 该方法在四个不同的环境中进行了实验验证，结果表明其性能优于现有的基线方法，并且与使用真实安全标签的数据训练的神经CBF具有相似的性能。

Conclusion: 研究证明了通过从专家示范中学习安全状态而非显式定义失败状态集合，可以有效地训练神经CBF，这样既避免了复杂的计算负担，同时也保持了系统的安全性。

Abstract: Safety is a fundamental requirement for autonomous systems operating in
critical domains. Control barrier functions (CBFs) have been used to design
safety filters that minimally alter nominal controls for such systems to
maintain their safety. Learning neural CBFs has been proposed as a data-driven
alternative for their computationally expensive optimization-based synthesis.
However, it is often the case that the failure set of states that should be
avoided is non-obvious or hard to specify formally, e.g., tailgating in
autonomous driving, while a set of expert demonstrations that achieve the task
and avoid the failure set is easier to generate. We use ICL to train a
constraint function that classifies the states of the system under
consideration to safe, i.e., belong to a controlled forward invariant set that
is disjoint from the unspecified failure set, and unsafe ones, i.e., belong to
the complement of that set. We then use that function to label a new set of
simulated trajectories to train our neural CBF. We empirically evaluate our
approach in four different environments, demonstrating that it outperforms
existing baselines and achieves comparable performance to a neural CBF trained
with the same data but annotated with ground-truth safety labels.

</details>


### [157] [CMOMgen: Complex Multi-Ontology Alignment via Pattern-Guided In-Context Learning](https://arxiv.org/abs/2510.21656)
*Marta Contreiras Silva,Daniel Faria,Catia Pesquita*

Main category: cs.AI

TL;DR: 本文介绍了一种称为CMOMgen的复杂多本体匹配（CMOM）策略，该策略能够生成完整且语义正确的映射，无需对目标本体的数量或实体设置限制。CMOMgen在三个生物医学任务中表现优秀，F1得分至少为63%，并显示出能够构建语义正确映射的能力。


<details>
  <summary>Details</summary>
Motivation: 当前简单本体匹配方法存在局限，无法实现相关但彼此分离本体的全面语义整合。通过复杂多本体匹配可以建立更细致的等价关系，从而实现在本体层次上的全面整合。这一研究的目的是为了开发一种能够生成全面且语义正确的多本体映射策略。

Method: CMOMgen通过检索增强生成来选择合适的类并组成映射。它还通过筛选匹配参考映射来增强上下文学习。这一策略显著提高了类选择性能，并在三个生物医学任务中取得了优于基线及其他版本的结果。

Result: 实验评估指出，CMOMgen在所有任务中都表现出了比基线和其他版本更好的性能，尤其在两个任务中F1得分超过了63%，而在第三个任务中排名第二。手动评估未参考映射分数时，大约46%的映射都能获得满分，这进一步佐证了其可生成语义正确映射的能力。

Conclusion: CMOMgen作为一种复杂多本体匹配策略，展示了其在生成全面、语义合理的本体间映射方面的优越性，特别是在生物医学领域，能够大大提高相关任务的性能。

Abstract: Constructing comprehensive knowledge graphs requires the use of multiple
ontologies in order to fully contextualize data into a domain. Ontology
matching finds equivalences between concepts interconnecting ontologies and
creating a cohesive semantic layer. While the simple pairwise state of the art
is well established, simple equivalence mappings cannot provide full semantic
integration of related but disjoint ontologies. Complex multi-ontology matching
(CMOM) aligns one source entity to composite logical expressions of multiple
target entities, establishing more nuanced equivalences and provenance along
the ontological hierarchy.
  We present CMOMgen, the first end-to-end CMOM strategy that generates
complete and semantically sound mappings, without establishing any restrictions
on the number of target ontologies or entities. Retrieval-Augmented Generation
selects relevant classes to compose the mapping and filters matching reference
mappings to serve as examples, enhancing In-Context Learning. The strategy was
evaluated in three biomedical tasks with partial reference alignments. CMOMgen
outperforms baselines in class selection, demonstrating the impact of having a
dedicated strategy. Our strategy also achieves a minimum of 63% in F1-score,
outperforming all baselines and ablated versions in two out of three tasks and
placing second in the third. Furthermore, a manual evaluation of non-reference
mappings showed that 46% of the mappings achieve the maximum score, further
substantiating its ability to construct semantically sound mappings.

</details>


### [158] [A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection](https://arxiv.org/abs/2510.21679)
*Gaku Morio,Harri Rowlands,Dominik Stammbach,Christopher D. Manning,Peter Henderson*

Main category: cs.AI

TL;DR: 介绍了一个专家注释的视频广告数据集，用于评估视觉-语言模型（VLM）在理解和分类公共关系框架上的表现。该数据集包含了来自50多家公司和活动团体的视频广告，覆盖20个国家，并注释了13种框架类型。实验表明，GPT-4.1在检测环保信息方面表现良好（F1分数为79%），而最佳模型检测绿色创新框架的表现相对较低（F1分数为46%）。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解公共关系活动的目标和性质，特别是大型公司在公共关系中的不一致，本文希望研究基于视频的内容如何被公共关系团队视为传播特定框架的积极信息，以及分析公共关系的内容对于公共关系行业和多模态分析的研究具有重要的推动作用。

Method: 构建了一个专家注释的视频广告数据集，包括多模式视频数据，旨在评估视觉-语言模型(VLM)的能力，特别是它们在理解复杂文化和情境方面的限制。实验中也进行了基线测试，测试了这些模型在检测不同框架类型方面的表现。

Result: 发现当前的视觉-语言模型在识别特定框架类型（例如绿色创新）方面表现不佳，同时指出了识别隐性框架、处理不同长度的视频以及考虑隐性文化背景等方面的挑战。

Conclusion: 这项工作发布了一个新的数据集，提供了对于公共关系视频广告的详细注释，这对于评估和改进视觉-语言模型具有重要意义。同时，提出了一些需要进一步研究的问题，这也是未来工作的基础。

Abstract: Companies spend large amounts of money on public relations campaigns to
project a positive brand image. However, sometimes there is a mismatch between
what they say and what they do. Oil & gas companies, for example, are accused
of "greenwashing" with imagery of climate-friendly initiatives. Understanding
the framing, and changes in framing, at scale can help better understand the
goals and nature of public relations campaigns. To address this, we introduce a
benchmark dataset of expert-annotated video ads obtained from Facebook and
YouTube. The dataset provides annotations for 13 framing types for more than 50
companies or advocacy groups across 20 countries. Our dataset is especially
designed for the evaluation of vision-language models (VLMs), distinguishing it
from past text-only framing datasets. Baseline experiments show some promising
results, while leaving room for improvement for future work: GPT-4.1 can detect
environmental messages with 79% F1 score, while our best model only achieves
46% F1 score on identifying framing around green innovation. We also identify
challenges that VLMs must address, such as implicit framing, handling videos of
various lengths, or implicit cultural backgrounds. Our dataset contributes to
research in multimodal analysis of strategic communication in the energy
sector.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [159] [A Confidence-Constrained Cloud-Edge Collaborative Framework for Autism Spectrum Disorder Diagnosis](https://arxiv.org/abs/2510.21130)
*Qi Deng,Yinghao Zhang,Yalin Liu,Bishenghui Tao*

Main category: cs.NI

TL;DR: 提出了Confidence-Constrained Cloud-Edge Knowledge Distillation (C3EKD) 框架，结合边缘计算和云计算，提升自闭症谱系障碍(ASD)诊断系统的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统的纯云计算或者纯边缘计算在自闭症谱系障碍(ASD)诊断中存在隐私和延迟问题，或是准确率有限。因此提出了结合边缘和云的框架来优化这些问题。

Method: 该框架在边缘进行大部分推理，将低置信度样本上传至云端。云端生成温度缩放的软标签，并将其蒸馏回边缘模型，通过全局损失在参与学校之间聚合，从而提高边缘模型的泛化能力而不集中原始数据。

Result: 在两个公开的ASD面部图像数据集上，提出的框架达到了87.4％的准确率，展示了其在实际应用中的可扩展性。

Conclusion: C3EKD框架在保证隐私安全的同时提高了ASD诊断系统的准确度，可用于大规模的实际应用中。

Abstract: Autism Spectrum Disorder (ASD) diagnosis systems in school environments
increasingly relies on IoT-enabled cameras, yet pure cloud processing raises
privacy and latency concerns while pure edge inference suffers from limited
accuracy. We propose Confidence-Constrained Cloud-Edge Knowledge Distillation
(C3EKD), a hierarchical framework that performs most inference at the edge and
selectively uploads only low-confidence samples to the cloud. The cloud
produces temperature-scaled soft labels and distils them back to edge models
via a global loss aggregated across participating schools, improving
generalization without centralizing raw data. On two public ASD facial-image
datasets, the proposed framework achieves a superior accuracy of 87.4\%,
demonstrating its potential for scalable deployment in real-world applications.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [160] [Eye-Tracking as a Tool to Quantify the Effects of CAD Display on Radiologists' Interpretation of Chest Radiographs](https://arxiv.org/abs/2510.20864)
*Daisuke Matsumoto,Tomohiro Kikuchi,Yusuke Takagi,Soichiro Kojima,Ryoma Kobayashi,Daiju Ueda,Kohei Yamamoto,Sho Kawabe,Harushi Mori*

Main category: eess.IV

TL;DR: 这项研究使用眼动追踪技术，评估了带有边界框辅助的胸部X光片解读过程中，医生的视觉搜索行为变化。结果显示，边界框辅助延长了解读时间，增加了病变停留时间，但缩短了首次发现病变的时间，且增加了整个视野的覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是探索计算机辅助检测系统中，边界框这种辅助显示工具是否会影响医生在解读胸部X光片时的视觉搜索行为。目的是了解这种工具对工作流程和解读效率的影响，以及其潜在的应用价值和局限性。

Method: 研究人员从VinDR-CXR数据集中选取了180张放射片，包括120张含有孤立肺结节或肿块的，60张不含的。通过眼动追踪设备记录了三名放射科医生在使用和不使用边界框辅助时的眼动数据，并使用线性混合模型进行统计分析。主要分析对象是真正阳性的案例（n=96）。

Result: 研究结果表明，在使用边界框辅助时，医生的解读时间平均增加了4.9秒，病变停留时间增加了1.3秒，总注视路径长度增加了2,076像素，肺区覆盖率增加了10.5%。首次发现病变的时间则缩短了1.3秒。这些数据显示了辅助工具对医生视觉搜索行为的具体影响。

Conclusion: 该研究证明了使用眼动追踪技术分析视觉搜索行为变化的可行性，并强调了未来进行更大规模研究来确认这些结果，以及探讨不同模态和临床环境下影响的重要性。

Abstract: Rationale and Objectives: Computer-aided detection systems for chest
radiographs are widely used, and concurrent reader displays, such as
bounding-box (BB) highlights, may influence the reading process. This pilot
study used eye tracking to conduct a preliminary experiment to quantify which
aspects of visual search were affected. Materials and Methods: We sampled 180
chest radiographs from the VinDR-CXR dataset: 120 with solitary pulmonary
nodules or masses and 60 without. The BBs were configured to yield an overall
display sensitivity and specificity of 80%. Three radiologists (with 11, 5, and
1 years of experience, respectively) interpreted each case twice - once with
BBs visible and once without - after a washout of >= 2 weeks. Eye movements
were recorded using an EyeTech VT3 Mini. Metrics included interpretation time,
time to first fixation on the lesion, lesion dwell time, total gaze-path
length, and lung-field coverage ratio. Outcomes were modeled using a linear
mixed model, with reading condition as a fixed effect and case and reader as
random intercepts. The primary analysis was restricted to true positives
(n=96). Results: Concurrent BB display prolonged interpretation time by 4.9 s
(p<0.001) and increased lesion dwell time by 1.3 s (p<0.001). Total gaze-path
length increased by 2,076 pixels (p<0.001), and lung-field coverage ratio
increased by 10.5% (p<0.001). Time to first fixation on the lesion was reduced
by 1.3 s (p<0.001). Conclusion: Eye tracking captured measurable alterations in
search behavior associated with concurrent BB displays during chest radiograph
interpretation. These findings support the feasibility of this approach and
highlight the need for larger studies to confirm effects and explore
implications across modalities and clinical contexts.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [161] [Information Theoretic Learning for Diffusion Models with Warm Start](https://arxiv.org/abs/2510.20903)
*Yirong Shen,Lu Gan,Cong Ling*

Main category: cs.IT

TL;DR: 本文通过推导噪声驱动模型的更紧致的似然度边界，提升极大似然学习的准确性和效率，尤其是在处理图像数据时取得了SOTA的结果，并且该框架可以自然地扩展到离散数据上


<details>
  <summary>Details</summary>
Motivation: 当前基于扰动的方法在极大似然估计模型中占据重要地位，但在实际应用中存在收敛慢和理论理解不足的问题。本文旨在解决这一问题，提出一种新的方法来提升模型性能

Method: 通过拓展经典的KL散度与Fisher信息之间的关系至任意噪声扰动，提出了一种新的似然度边界，可以使用更灵活的随机噪声分布来更好地处理传感器噪声、量化效应等，同时在扩散过程中视为高斯信道来衡量数据与模型之间的信息失配度

Result: 实验表明，该方法在不同的数据集上取得了很好的效果，特别是在CIFAR-10和ImageNet数据集上通过极大似然估计实现了SOTA结果，并且在处理离散数据时也表现出色

Conclusion: 该方法提供了一种新的提升噪声驱动模型性能的方法，通过更精确的似然度边界来实现更好的学习效果，并且该框架可以自然扩展到其他类型的数据中

Abstract: Generative models that maximize model likelihood have gained traction in many
practical settings. Among them, perturbation based approaches underpin many
strong likelihood estimation models, yet they often face slow convergence and
limited theoretical understanding. In this paper, we derive a tighter
likelihood bound for noise driven models to improve both the accuracy and
efficiency of maximum likelihood learning. Our key insight extends the
classical KL divergence Fisher information relationship to arbitrary noise
perturbations, going beyond the Gaussian assumption and enabling structured
noise distributions. This formulation allows flexible use of randomized noise
distributions that naturally account for sensor artifacts, quantization
effects, and data distribution smoothing, while remaining compatible with
standard diffusion training. Treating the diffusion process as a Gaussian
channel, we further express the mismatched entropy between data and model,
showing that the proposed objective upper bounds the negative log-likelihood
(NLL). In experiments, our models achieve competitive NLL on CIFAR-10 and SOTA
results on ImageNet across multiple resolutions, all without data augmentation,
and the framework extends naturally to discrete data.

</details>


### [162] [Overlapped-repetition Shor codes achieving fourfold asymptotic rate](https://arxiv.org/abs/2510.21030)
*En-Jui Chang*

Main category: cs.IT

TL;DR: 通过重叠少量重复码来提高码率，特别是在最小距离情况下将标准Shor码从$[[9,1,3]]$优化为$[[7,1,3]]$


<details>
  <summary>Details</summary>
Motivation: 改善标准Shor码的码率，因为标准的Shor码虽然结构简单，但码率相对较低

Method: 通过重叠少量的重复码，来改善标准Shor码的结构和效率

Result: 在最小距离为3的情况下，将标准Shor码的配置从$[[9,1,3]]$优化为效率更高的$[[7,1,3]]$

Conclusion: 通过合理利用重复码的重叠，有效提高了量子纠错码的效率

Abstract: The standard Shor code employs two repetition codes as inner and outer codes,
yielding a simple structure but a relatively low code rate. By overlapping a
small number of repetition codes, we enhance the asymptotic code rate fourfold.
In the minimal-distance case $d = 3$, this construction reduces the overhead
from $[[9,1,3]]$ to the more efficient $[[7,1,3]]$ configuration.

</details>


### [163] [Complex DNA Synthesis Sequences](https://arxiv.org/abs/2510.21253)
*Boaz Moav,Ryan Gabrys,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 本文介绍了一种混合合成框架，该框架结合了酶促合成和光刻合成，通过对每个周期中平行合成的核苷酸进行限制，解决了现有方法的局限性。此外，文章拓展了信息速率的定义，分析了新模型下的删除球，并提供了最大化信息速率的表达式。同时，作者还设计了一个动态规划算法，用于计算最优复杂的合成序列。文章还定义了一个二维阵列模型，涵盖了以前的合成模型，并捕捉了大规模链阵列中的新结构限制。这些结果为受限DNA提供了一个新的理论框架，涵盖了先前的模型，为基础研究铺平了道路。


<details>
  <summary>Details</summary>
Motivation: DNA存储提供前所未有的密度和稳定性，但其扩展性受到并行链合成效率的限制。现有的合成方法要么允许单独链上的任意核苷酸添加（如酶促合成），要么强制规定很多链上的添加是一样的（如光刻合成）。文章旨在提供一种新的合成框架，以解决这些方法的局限性，并确立一个理论基础，指导未来的研究发展。

Method: 引入并分析了一种混合合成框架，该框架结合了酶促合成和光刻合成。扩展了信息速率定义，分析了新模型下的删除球，并为大型链阵列中的新结构限制定义了一个二维阵列模型。使用动态规划算法计算最优的复杂合成序列。

Result: 为DNA存储合成问题提供了一个新的理论框架，该框架综合了现有方法并覆盖了新的结构限制。提出了计算最优复杂合成序列的动态规划算法，并提供了最大化信息速率的理论表达式。

Conclusion: 该研究为DNA合成问题提供了深厚的理论支持，并为未来在DNA存储技术上的进步奠定了基础。

Abstract: DNA-based storage offers unprecedented density and durability, but its
scalability is fundamentally limited by the efficiency of parallel strand
synthesis. Existing methods either allow unconstrained nucleotide additions to
individual strands, such as enzymatic synthesis, or enforce identical additions
across many strands, such as photolithographic synthesis. We introduce and
analyze a hybrid synthesis framework that generalizes both approaches: in each
cycle, a nucleotide is selected from a restricted subset and incorporated in
parallel. This model gives rise to a new notion of a complex synthesis
sequence. Building on this framework, we extend the information rate definition
of Lenz et al. and analyze an analog of the deletion ball, defined and studied
in this setting, deriving tight expressions for the maximal information rate
and its asymptotic behavior. These results bridge the theoretical gap between
constrained models and the idealized setting in which every nucleotide is
always available. For the case of known strands, we design a dynamic
programming algorithm that computes an optimal complex synthesis sequence,
highlighting structural similarities to the shortest common supersequence
problem. We also define a distinct two-dimensional array model with synthesis
constraints over the rows, which extends previous synthesis models in the
literature and captures new structural limitations in large-scale strand
arrays. Additionally, we develop a dynamic programming algorithm for this
problem as well. Our results establish a new and comprehensive theoretical
framework for constrained DNA, subsuming prior models and setting the stage for
future advances in the field.

</details>


### [164] [Low-Complexity MIMO Channel Estimation with Latent Diffusion Models](https://arxiv.org/abs/2510.21386)
*Xiaotian Fan,Xingyu Zhou,Le Liang,Shi Jin*

Main category: cs.IT

TL;DR: 提出了一种基于潜扩散模型的信道估计算法（PSLD-CE），该算法在保持低计算复杂度和快速推理速度的同时，显著优于现有的信道估计方法。


<details>
  <summary>Details</summary>
Motivation: 现有信道估计方法可能在复杂度和性能之间难以平衡，而深度生成模型可以通过学习无线信道的复杂先验分布提供一种有吸引力的替代方案。因此，作者提出了一种基于潜扩散模型的信道估计算法，以期能同时提高性能并保持低计算复杂度。

Method: 采用了轻量级LDM架构作为生成性先验，捕捉复杂的信道分布，并改进了后验采样过程，引入了似然项的有效近似和变分自编码器潜空间的自一致性约束。

Result: 实验结果表明，PSLD-CE在广泛的标准上超越了现有的许多方法，同时保持了计算复杂度低和推理速度快的特点。

Conclusion: 该方法对于下一代无线系统来说是一个有前景和实用的解决方案。

Abstract: Deep generative models offer a powerful alternative to conventional channel
estimation by learning the complex prior distribution of wireless channels.
Capitalizing on this potential, this paper proposes a novel channel estimation
algorithm based on latent diffusion models (LDMs), termed posterior sampling
with latent diffusion for channel estimation (PSLD-CE). The core of our
approach is a lightweight LDM architecture specifically designed for channel
estimation, which serves as a powerful generative prior to capture the
intricate channel distribution. Furthermore, we enhance the diffusion posterior
sampling process by introducing an effective approximation for the likelihood
term and a tailored self-consistency constraint on the variational autoencoder
latent space. Extensive experimental results demonstrate that PSLD-CE
consistently outperforms a wide range of existing methods. Notably, these
significant performance gains are achieved while maintaining low computational
complexity and fast inference speed, establishing our method as a highly
promising and practical solution for next-generation wireless systems.

</details>


### [165] [Universal Maximum Likelihood (List) Decoding via Fast Vector-Matrix Multiplication](https://arxiv.org/abs/2510.21414)
*Hoang Ly,Emina Soljanin*

Main category: cs.IT

TL;DR: 本文提出了一种简单的框架，将任意块码的最大似然解码的最坏情况下的时间复杂度从$q^{k} n$降低到$q^{k}$，适用于线性和非线性块码以及ISI信道的ML列表解码。该方法依靠于构建特定矩阵并使用Mailman算法进行高效计算，但需要较高的空间复杂度来存储预先计算的码本矩阵。


<details>
  <summary>Details</summary>
Motivation: 寻找一种通用的解码方法，该方法不仅适用于线性和非线性块码，还能通过减少计算复杂度来提高解码效率，并能够高效地应用于一般的无记忆信道和ISI信道。

Method: 提出了一种框架，通过构建两个特定向量并计算它们的内积来表达每个序列在接收端条件概率，解码时只需计算一个向量矩阵乘法。使用Mailman算法进一步降低了计算复杂度。

Result: 将解码的最坏情况的时间复杂度从$q^{k} n$降低到仅$q^{k}$。这种改进适用于线性和非线性块码，并可以在ISI信道和ML列表解码中实现仅略微增加的复杂度。

Conclusion: 本论文为块码的ML解码提出了一个具有广泛适用性的方法，它能够有效地减少计算复杂度，适用于各种类型的码及信道，虽然这种方法在空间复杂度上有较高的要求。

Abstract: Maximum-likelihood (ML) decoding for arbitrary block codes remains
fundamentally hard, with worst-case time complexity-measured by the total
number of multiplications-being no better than straightforward exhaustive
search, which requires $q^{k} n$ operations for an $[n,k]_q$ code. This paper
introduces a simple, code-agnostic framework that reduces the worst-case
complexity by a factor of $n$, down to $q^{k}$ operations, a highly desirable
reduction in practice. The result holds for both linear and nonlinear block
codes over general memoryless channels and under both hard-decision and
soft-decision decoding. It naturally extends to intersymbol-interference (ISI)
channels and ML list decoding with only a negligible increase in complexity.
Our core insight is that, upon receipt of each sequence at the receiver, the
conditional probability of that sequence for each codeword in the codebook
(i.e., the \emph{likelihood}) can be expressed as the inner product of two
carefully constructed vectors -- the first depending on the received sequence,
and the second on that codeword itself. As a result, evaluating the likelihoods
for all codewords in the codebook reduces to a single vector-matrix
multiplication, and ML decoding (MLD) becomes the simple task of picking the
maximum entry in the resulting vector. The only non-trivial cost lies in the
vector-matrix product. However, our matrix construction allows the use of the
Mailman algorithm to reduce this cost. This time reduction is achieved at the
cost of high space complexity, requiring $\mathcal{O}(q^{k+1} n)$ space to
store the pre-computed codebook matrix.

</details>
