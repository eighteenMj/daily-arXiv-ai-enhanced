<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 58]
- [eess.IV](#eess.IV) [Total: 6]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.AI](#cs.AI) [Total: 15]
- [eess.SY](#eess.SY) [Total: 9]
- [cs.IT](#cs.IT) [Total: 4]
- [cs.LG](#cs.LG) [Total: 59]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench](https://arxiv.org/abs/2510.26865)
*Fenfen Lin,Yesheng Liu,Haiyu Xu,Chen Yue,Zheqi He,Mingxuan Zhao,Miguel Hu Chen,Jiakang Liu,JG Yao,Xi Yang*

Main category: cs.CV

TL;DR: 介绍了一个用于视觉测量读取的新基准MeasureBench，旨在评估视觉语言模型在测量读取任务上的能力，并发现这些模型在关键位置识别上存在问题，显示了在细粒度空间定位上的基本限制。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型在读取测量仪器方面存在挑战，尽管这些任务对于人类来说相对简单。作者希望创建一个基准来测试和提高模型在这一任务上的性能。

Method: 该研究提出了MeasureBench，一个包含合成图像和真实图像的新基准，这些图像来自不同类型的测量。作者还开发了一个可扩展的数据合成管线，用于生成各种具有可控视觉外观的测量仪表。

Result: 最先进的视觉语言模型在测量读取任务上表现不佳，尤其是在指针定位方面。在合成数据上取得了初步但乐观的成果，但在真实图像上的表现则不那么令人满意。

Conclusion: 当前的视觉语言模型在细粒度空间定位上的局限性明显，作者希望该基准能推动未来在视觉锚定的算术能力和精确的空间感知方面的工作。

Abstract: Reading measurement instruments is effortless for humans and requires
relatively little domain expertise, yet it remains surprisingly challenging for
current vision-language models (VLMs) as we find in preliminary evaluation. In
this work, we introduce MeasureBench, a benchmark on visual measurement reading
covering both real-world and synthesized images of various types of
measurements, along with an extensible pipeline for data synthesis. Our
pipeline procedurally generates a specified type of gauge with controllable
visual appearance, enabling scalable variation in key details such as pointers,
scales, fonts, lighting, and clutter. Evaluation on popular proprietary and
open-weight VLMs shows that even the strongest frontier VLMs struggle
measurement reading in general. A consistent failure mode is indicator
localization: models can read digits or labels but misidentify the key
positions of pointers or alignments, leading to big numeric errors despite
plausible textual reasoning. We have also conducted preliminary experiments
with reinforcement learning over synthetic data, and find encouraging results
on in-domain synthetic subset but less promising for real-world images. Our
analysis highlights a fundamental limitation of current VLMs in fine-grained
spatial grounding. We hope this resource can help future advances on visually
grounded numeracy and precise spatial perception of VLMs, bridging the gap
between recognizing numbers and measuring the world.

</details>


### [2] [PF-DAformer: Proximal Femur Segmentation via Domain Adaptive Transformer for Dual-Center QCT](https://arxiv.org/abs/2510.26903)
*Rochak Dhakal,Chen Zhao,Zixin Shi,Joyce H. Keyak,Tadashi S. Kaneko,Kuan-Jui Su,Hui Shen,Hong-Wen Deng,Weihua Zhou*

Main category: cs.CV

TL;DR: 本文开发了一种适用于多机构定量CT的领域适应变压器分割框架，以解决由于扫描仪、重建设置和患者人口统计学差异导致的数据域偏移问题。该框架基于3D TransUNet骨干网，结合对抗对齐和统计对齐策略，以实现跨机构的可重复性定量分析和结构有限元分析结果。


<details>
  <summary>Details</summary>
Motivation: 由于不同机构间的扫描仪、重建设置和患者人口统计学差异，导致定量CT在自部署自动化分割模型时面临困难。为了解决这一问题，我们需要开发一种能够跨越这些差异的模型，从而提高骨密度分割的稳定性和可靠性。这有助于多中心骨质疏松症研究和确保定量分析及结构有限元分析结果的跨地点可重复性。

Method: 作者提出了一种基于3D TransUNet的领域适应变压器分割框架，将对抗对齐（通过梯度反转层实现）和统计对齐（通过最大均值差异实现）两种策略结合在一起，以对抗两个数据集之间的分布差异，同时保持解剖细节的准确性。

Result: 实验结果显示，所提出的框架成功地减少了机构间的域偏移，提高了骨密度分割的稳定性和准确性，从而增强了跨机构定量分析和结构有限元分析结果的可重复性。

Conclusion: 针对跨机构定量CT应用中的域偏移问题，作者提出了一种新的领域适应分割框架，这为提高骨密度评估的准确性和可靠性提供了新的方法。同时，该方法也显示了在其他医学影像分析领域的潜在应用价值。

Abstract: Quantitative computed tomography (QCT) plays a crucial role in assessing bone
strength and fracture risk by enabling volumetric analysis of bone density
distribution in the proximal femur. However, deploying automated segmentation
models in practice remains difficult because deep networks trained on one
dataset often fail when applied to another. This failure stems from domain
shift, where scanners, reconstruction settings, and patient demographics vary
across institutions, leading to unstable predictions and unreliable
quantitative metrics. Overcoming this barrier is essential for multi-center
osteoporosis research and for ensuring that radiomics and structural finite
element analysis results remain reproducible across sites. In this work, we
developed a domain-adaptive transformer segmentation framework tailored for
multi-institutional QCT. Our model is trained and validated on one of the
largest hip fracture related research cohorts to date, comprising 1,024 QCT
images scans from Tulane University and 384 scans from Rochester, Minnesota for
proximal femur segmentation. To address domain shift, we integrate two
complementary strategies within a 3D TransUNet backbone: adversarial alignment
via Gradient Reversal Layer (GRL), which discourages the network from encoding
site-specific cues, and statistical alignment via Maximum Mean Discrepancy
(MMD), which explicitly reduces distributional mismatches between institutions.
This dual mechanism balances invariance and fine-grained alignment, enabling
scanner-agnostic feature learning while preserving anatomical detail.

</details>


### [3] [DC4GS: Directional Consistency-Driven Adaptive Density Control for 3D Gaussian Splatting](https://arxiv.org/abs/2510.26921)
*Moonsoo Jeong,Dongbeen Kim,Minseong Kim,Sungkil Lee*

Main category: cs.CV

TL;DR: 我们提出了一种基于方向一致性的自适应密度控制方法（DC4GS），用于3D高斯点阵。我们通过角度一致性的方式将方向一致性应用于当前的自适应密度控制方法中，改进了传统方法在处理局部复杂结构时的冗余性和精确度，减少了最高达30%的点阵数量，并提高了重建的保真度。


<details>
  <summary>Details</summary>
Motivation: 目标在于提高3D高斯点阵在处理局部复杂结构的能力，减少冗余的点阵数量，同时提高图像重建的质量和保真度。传统的自适应密度控制（ADC）方法依赖于位置梯度的大小来进行点阵的分裂，这在处理局部复杂结构时效果欠佳。因此，我们引入了基于角度一致性的方向一致性概念，以更有效地减少冗余和更好地捕捉局部复杂结构，改进了重建的保真度和效率。

Method: 我们提出的DC4GS方法通过方向一致性概念来定义最佳的分裂位置，使得子点阵与局部结构更好地对齐，从而减少了冗余的点阵数量并提高了重建保真度。这种方法改进了传统的自适应密度控制方法，通过角度一致性更好地处理局部复杂结构，避免冗余分裂，提高重建效率和保真度。

Result: 我们的方法在最高减少了30%的点阵数量的情况下提高了重建的保真度，证明了方向一致性在处理局部复杂度方面的有效性。通过与现有方法比较，DC4GS在减少点阵数量的同时仍保持与现有方法相当甚至更高的保真度。

Conclusion: 综上所述，结合方向一致性的自适应密度控制（DC4GS）方法在减少冗余点阵和提高重建质保真度方面表现优异，为3D高斯点阵提供了一种新的且有效的解决方案。

Abstract: We present a Directional Consistency (DC)-driven Adaptive Density Control
(ADC) for 3D Gaussian Splatting (DC4GS). Whereas the conventional ADC bases its
primitive splitting on the magnitudes of positional gradients, we further
incorporate the DC of the gradients into ADC, and realize it through the
angular coherence of the gradients. Our DC better captures local structural
complexities in ADC, avoiding redundant splitting. When splitting is required,
we again utilize the DC to define optimal split positions so that
sub-primitives best align with the local structures than the conventional
random placement. As a consequence, our DC4GS greatly reduces the number of
primitives (up to 30% in our experiments) than the existing ADC, and also
enhances reconstruction fidelity greatly.

</details>


### [4] [Scale-Aware Curriculum Learning for Ddata-Efficient Lung Nodule Detection with YOLOv11](https://arxiv.org/abs/2510.26923)
*Yi Luo,Yike Guo,Hamed Hooshangnejad,Kai Ding*

Main category: cs.CV

TL;DR: 提出了Scale Adaptive Curriculum Learning (SACL)策略，该策略通过动态调整基于可用数据规模的课程设计，提高了在数据稀疏场景下训练深度学习模型的能力。SACL在LUNA25数据集上的实验结果优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统静态课程学习策略在数据稀疏的情况下表现不佳，而新的动态课程学习策略可以解决这一问题，有助于提高早期肺部肿瘤检测系统的准确性和鲁棒性。

Method: SACL策略引入了三个关键机制：（1）自适应周期调度，（2）硬样本注入，（3）感知规模优化。该策略使用YOLOv11作为基础检测器，在LUNA25数据集上进行了评估。

Result: 实验结果表明，SACL策略在数据量分别是总数据10%，20%，50%时，与静态课程学习法相比在mAP50指标上分别提高了4.6%，3.5%和2.0%。这表明SACL对于数据稀疏条件下的模型训练效果显著提升。

Conclusion: SACL策略为医疗机构在有限标注资源条件下开发有效的肺部结节检测系统提供了一种实用的解决方案。

Abstract: Lung nodule detection in chest CT is crucial for early lung cancer diagnosis,
yet existing deep learning approaches face challenges when deployed in clinical
settings with limited annotated data. While curriculum learning has shown
promise in improving model training, traditional static curriculum strategies
fail in data-scarce scenarios. We propose Scale Adaptive Curriculum Learning
(SACL), a novel training strategy that dynamically adjusts curriculum design
based on available data scale. SACL introduces three key mechanisms:(1)
adaptive epoch scheduling, (2) hard sample injection, and (3) scale-aware
optimization. We evaluate SACL on the LUNA25 dataset using YOLOv11 as the base
detector. Experimental results demonstrate that while SACL achieves comparable
performance to static curriculum learning on the full dataset in mAP50, it
shows significant advantages under data-limited conditions with 4.6%, 3.5%, and
2.0% improvements over baseline at 10%, 20%, and 50% of training data
respectively. By enabling robust training across varying data scales without
architectural modifications, SACL provides a practical solution for healthcare
institutions to develop effective lung nodule detection systems despite limited
annotation resources.

</details>


### [5] [SYNAPSE-Net: A Unified Framework with Lesion-Aware Hierarchical Gating for Robust Segmentation of Heterogeneous Brain Lesions](https://arxiv.org/abs/2510.26961)
*Md. Mehedi Hassan,Shafqat Alam,Shahriar Ahmed Seam,Maruf Ahmed*

Main category: cs.CV

TL;DR: 提出了一种新的脑病变自动分割框架SYNAPSE-Net，结合了多流CNN编码器、Swin Transformer瓶颈、动态跨模态注意力融合机制和分层门控解码器。该框架在三个公开数据集上均达到了最先进的性能，证明了其在多类脑病理学中的广泛适用性和高可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习模型在脑病变分割中性能不稳定，难以泛化。为了提高模型的泛化能力和鲁棒性，促进其在临床中的应用，提出了一种新的脑病变自动分割框架SYNAPSE-Net。

Method: SYNAPSE-Net框架结合了多流CNN编码器、Swin Transformer瓶颈和动态跨模态注意力融合机制（CMAF），并使用了一个分层门控解码器。模型学习过程中结合了病灶特定的数据增强和难度感知采样方法以降低性能波动。

Result: 模型在MICCAI 2017 WMH Challenge数据集上达到了0.831的DSC值和3.03的HD95值；在ISLES 2022 Challenge数据集上实现了边界精度的最佳化，HD95值为9.69；在BraTS 2020 Challenge数据集上，肿瘤核心区域的DSC值达到了0.8651。在三个数据集上均表现出色。

Conclusion: SYNAPSE-Net框架在多类脑病理学图像分割任务上展示了卓越的性能，证明了其在临床应用中的广泛适用性和高可靠性，有助于推动脑病理学自动化分割技术的发展。

Abstract: Automated segmentation of heterogeneous brain lesions from multi-modal MRI
remains a critical challenge in clinical neuroimaging. Current deep learning
models are typically specialized `point solutions' that lack generalization and
high performance variance, limiting their clinical reliability. To address
these gaps, we propose the Unified Multi-Stream SYNAPSE-Net, an adaptive
framework designed for both generalization and robustness. The framework is
built on a novel hybrid architecture integrating multi-stream CNN encoders, a
Swin Transformer bottleneck for global context, a dynamic cross-modal attention
fusion (CMAF) mechanism, and a hierarchical gated decoder for high-fidelity
mask reconstruction. The architecture is trained with a variance reduction
strategy that combines pathology specific data augmentation and
difficulty-aware sampling method. The model was evaluated on three different
challenging public datasets: the MICCAI 2017 WMH Challenge, the ISLES 2022
Challenge, and the BraTS 2020 Challenge. Our framework attained a
state-of-the-art DSC value of 0.831 with the HD95 value of 3.03 in the WMH
dataset. For ISLES 2022, it achieved the best boundary accuracy with a
statistically significant difference (HD95 value of 9.69). For BraTS 2020, it
reached the highest DSC value for the tumor core region (0.8651). These
experimental findings suggest that our unified adaptive framework achieves
state-of-the-art performance across multiple brain pathologies, providing a
robust and clinically feasible solution for automated segmentation. The source
code and the pre-trained models are available at
https://github.com/mubid-01/SYNAPSE-Net-pre.

</details>


### [6] [Semantic Frame Aggregation-based Transformer for Live Video Comment Generation](https://arxiv.org/abs/2510.26978)
*Anam Fatima,Yi Yu,Janak Kapuriya,Julien Lalanne,Jainendra Shukla*

Main category: cs.CV

TL;DR: 研究提出了一种基于语义帧聚合的Transformer模型（SFAT），旨在提高视频直播评论生成的质量，通过强调视觉-文本信息相关的关键帧来减少无关信息的影响，提升了评论的上下文相关性。同时，构建了一个大规模的多模态英文视频评论数据集以供研究使用。


<details>
  <summary>Details</summary>
Motivation: 现有方法对视频中的关键帧筛选不足，导致生成的评论上下文不够相关。为了改善这一状况，研究提出了一种新的基于视频帧选择和加权的方法，用于生成更高质量的评论。此外，现有的数据集大多集中在中文内容且视频类别有限，无法满足研究需求，因此研究人员还建设了大规模的多模态英文视频评论数据集。

Method: 本研究采用了一种称为SFAT的模型，该模型利用了CLIP的视觉-文本多模态知识，同时为视频帧分配权重，其基于帧的语义与当前观众对话的相关性。该方法通过加权求和的方式，强调信息丰富的帧，而减少无关帧的影响。模型的解码器还利用了跨模态注意力机制，确保生成的评论反映了从视频和聊天中获取的上下文线索。构建的数据集包含11个视频类别，来自Twitch平台，共计438小时和320万个评论。

Result: 相比现有方法，SFAT模型能够更好地理解视频内容和观众对话的上下文关系，生成更具相关性的评论。实验结果表明，SFAT模型在评论生成任务中具有显著的效果。

Conclusion: 研究提出了SFAT模型，旨在生成高质量、相关性强的直播视频评论，通过加权关键帧选择减少无关信息的影响。同时，构建了一个大规模、多模态、英文视频评论数据集，为研究提供了有力的支持。

Abstract: Live commenting on video streams has surged in popularity on platforms like
Twitch, enhancing viewer engagement through dynamic interactions. However,
automatically generating contextually appropriate comments remains a
challenging and exciting task. Video streams can contain a vast amount of data
and extraneous content. Existing approaches tend to overlook an important
aspect of prioritizing video frames that are most relevant to ongoing viewer
interactions. This prioritization is crucial for producing contextually
appropriate comments. To address this gap, we introduce a novel Semantic Frame
Aggregation-based Transformer (SFAT) model for live video comment generation.
This method not only leverages CLIP's visual-text multimodal knowledge to
generate comments but also assigns weights to video frames based on their
semantic relevance to ongoing viewer conversation. It employs an efficient
weighted sum of frames technique to emphasize informative frames while focusing
less on irrelevant ones. Finally, our comment decoder with a cross-attention
mechanism that attends to each modality ensures that the generated comment
reflects contextual cues from both chats and video. Furthermore, to address the
limitations of existing datasets, which predominantly focus on Chinese-language
content with limited video categories, we have constructed a large scale,
diverse, multimodal English video comments dataset. Extracted from Twitch, this
dataset covers 11 video categories, totaling 438 hours and 3.2 million
comments. We demonstrate the effectiveness of our SFAT model by comparing it to
existing methods for generating comments from live video and ongoing dialogue
contexts.

</details>


### [7] [MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation](https://arxiv.org/abs/2510.26996)
*Arghavan Rezvani,Xiangyi Yan,Anthony T. Wu,Kun Han,Pooya Khosravi,Xiaohui Xie*

Main category: cs.CV

TL;DR: 提出了一种用于医学图像分割的Mixture of Visual Language Medical Experts（MoME）模型，该模型基于混合专家（MoE）范式，结合视觉语言模型的优势，利用多尺度视觉特征和文本嵌入提升医学图像分割的准确性。通过10个数据集的实验，验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高医学图像分割的准确性，本研究将混合专家（MoE）范式应用于医学视觉语言任务，利用视觉和文本信息的结合，实现更高效的医学图像分割。这种方法可以克服传统方法在处理医学图像复杂性上的局限性。

Method: 提出了一种新的医学图像分割方法MoME，该方法结合了视觉语言模型的优点，利用多尺度视觉特征和文本嵌入，通过动态专家选择提升了模型的性能。模型在多个数据集上进行了训练和测试，证明了该方法的有效性。

Result: 实验结果证明了MoME在多个数据集上的分割性能优于或等同于现有方法，特别是在复杂医学图像的分割上表现优异。

Conclusion: 通过结合视觉和语言信息，MoME为医学图像分割提供了一种新的有效方法，可以广泛应用于医学图像分析领域，推动该领域的研究和发展。

Abstract: In this study, we propose MoME, a Mixture of Visual Language Medical Experts,
for Medical Image Segmentation. MoME adapts the successful Mixture of Experts
(MoE) paradigm, widely used in Large Language Models (LLMs), for medical
vision-language tasks. The architecture enables dynamic expert selection by
effectively utilizing multi-scale visual features tailored to the intricacies
of medical imagery, enriched with textual embeddings. This work explores a
novel integration of vision-language models for this domain. Utilizing an
assembly of 10 datasets, encompassing 3,410 CT scans, MoME demonstrates strong
performance on a comprehensive medical imaging segmentation benchmark. Our
approach explores the integration of foundation models for medical imaging,
benefiting from the established efficacy of MoE in boosting model performance
by incorporating textual information. Demonstrating competitive precision
across multiple datasets, MoME explores a novel architecture for achieving
robust results in medical image analysis.

</details>


### [8] [VitalLens 2.0: High-Fidelity rPPG for Heart Rate Variability Estimation from Face Video](https://arxiv.org/abs/2510.27028)
*Philipp V. Rouast*

Main category: cs.CV

TL;DR: VitalLens 2.0 是一款用于从面部视频中估计生理信号的深度学习模型，其在远程光电容积描记术（rPPG）中准确性显著提高，能够稳健地估计心率（HR）、呼吸率（RR）及心率变异性（HRV）等指标。该模型通过新的模型架构和大量多样化训练数据的增加实现这一突破。在四个公开和私人数据集的综合测试集中，HR的平均绝对误差（MAE）为1.57 bpm，RR为1.08 bpm，HRV-SDNN为10.18 ms，HRV-RMSSD为16.45 ms，显著优于现有方法。该模型可通过VitalLens API获取。


<details>
  <summary>Details</summary>
Motivation: 为了提高远程光电容积描记术（rPPG）的准确性，研究旨在开发一种可以根据面部视频准确估计心率（HR）、呼吸率（RR）和心率变异性（HRV）等生理信号的深度学习模型，以实现在远程，非接触状态下对生理健康状态的有效监测。

Method: VitalLens 2.0 通过引入新的模型架构以及使用由1,413个独特个体组成的更大规模和更多样化的训练数据集来提高性能。其评估结果显示VitalLens 2.0 在心率和呼吸率估计方面的准确性和稳健性相较于目前最先进方法更加出色。

Result: 在包含422个独特个体的新综合测试集中，VitalLens 2.0 在心率估计方面的平均绝对误差（MAE）为1.57 bpm，呼吸率估计误差为1.08 bpm，对于心率变异性的估计误差分别为10.18 ms（SDNN）和16.45 ms（RMSSD）。这些结果达到或超过了现有方法的最佳性能水平。

Conclusion: VitalLens 2.0 通过提高rPPG的准确性和稳健性，真正突破了先前估算心率、呼吸率和心率变异性等生理信号的局限性。该模型现已通过VitalLens API开放给开发者使用，便于广泛应用。

Abstract: This report introduces VitalLens 2.0, a new deep learning model for
estimating physiological signals from face video. This new model demonstrates a
significant leap in accuracy for remote photoplethysmography (rPPG), enabling
the robust estimation of not only heart rate (HR) and respiratory rate (RR) but
also Heart Rate Variability (HRV) metrics. This advance is achieved through a
combination of a new model architecture and a substantial increase in the size
and diversity of our training data, now totaling 1,413 unique individuals. We
evaluate VitalLens 2.0 on a new, combined test set of 422 unique individuals
from four public and private datasets. When averaging results by individual,
VitalLens 2.0 achieves a Mean Absolute Error (MAE) of 1.57 bpm for HR, 1.08 bpm
for RR, 10.18 ms for HRV-SDNN, and 16.45 ms for HRV-RMSSD. These results
represent a new state-of-the-art, significantly outperforming previous methods.
This model is now available to developers via the VitalLens API at
https://rouast.com/api.

</details>


### [9] [AD-SAM: Fine-Tuning the Segment Anything Vision Foundation Model for Autonomous Driving Perception](https://arxiv.org/abs/2510.27047)
*Mario Camarena,Het Patel,Fatemeh Nazari,Evangelos Papalexakis,Mohamadhossein Noruzoliaee,Jia Chen*

Main category: cs.CV

TL;DR: 本文介绍了自动行驶场景分割模型(AD-SAM)，一个针对自动行驶中的语义分割任务而优化的视觉基础模型，AD-SAM通过引入双编码器和可变形解码器来更好地处理道路场景的复杂性和几何形状。实验表明，在Cityscapes和Berkeley DeepDrive 100K数据集上，AD-SAM的表现均优于其他模型，显示出强大的跨域泛化能力，且在数据效率和学习速度上也有优势。这些结果证明了对基础模型进行架构优化和优化策略的改进是实现可靠和可扩展的自动行驶感知的关键。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在提升自主驾驶中的语义分割精度，特别是针对复杂和多样化的道路场景。通过引入适当的架构改进和优化策略，将基础视觉模型转换为更适合自动驾驶应用的模型，满足精确感知的需求。

Method: AD-SAM基于SAM模型，并通过添加一个双编码器结构和可变形解码器来处理自驾车场景特有的复杂性。该模型的训练采用多损失函数综合，以平衡各类别，提高边界精度，并保持训练的稳定性。实验数据来自于Cityscapes和Berkeley DeepDrive 100K两个数据集，用于验证模型性能。

Result: 实验结果显示，AD-SAM在Cityscapes数据集上以68.1的平均交并比(mIoU)超过比较模型SAM、G-SAM和DeepLabV3，且在BDD100K上亦有类似的表现，显示出显著的数据有效性和跨领域泛化能力。值得注意的是，AD-SAM在其所解决的任务上展现出更快的学习速度，表现出比基准模型更高的学习效率。

Conclusion: 该研究展示了对基础模型进行有针对性的架构和优化调整，可以提高模型在自动行驶任务中的可靠性和可扩展性。结果证明了AD-SAM的有效性和潜力，对未来开发自驾车感知系统具有指导意义。

Abstract: This paper presents the Autonomous Driving Segment Anything Model (AD-SAM), a
fine-tuned vision foundation model for semantic segmentation in autonomous
driving (AD). AD-SAM extends the Segment Anything Model (SAM) with a
dual-encoder and deformable decoder tailored to spatial and geometric
complexity of road scenes. The dual-encoder produces multi-scale fused
representations by combining global semantic context from SAM's pretrained
Vision Transformer (ViT-H) with local spatial detail from a trainable
convolutional deep learning backbone (i.e., ResNet-50). A deformable fusion
module aligns heterogeneous features across scales and object geometries. The
decoder performs progressive multi-stage refinement using deformable attention.
Training is guided by a hybrid loss that integrates Focal, Dice,
Lovasz-Softmax, and Surface losses, improving semantic class balance, boundary
precision, and optimization stability. Experiments on the Cityscapes and
Berkeley DeepDrive 100K (BDD100K) benchmarks show that AD-SAM surpasses SAM,
Generalized SAM (G-SAM), and a deep learning baseline (DeepLabV3) in
segmentation accuracy. It achieves 68.1 mean Intersection over Union (mIoU) on
Cityscapes and 59.5 mIoU on BDD100K, outperforming SAM, G-SAM, and DeepLabV3 by
margins of up to +22.9 and +19.2 mIoU in structured and diverse road scenes,
respectively. AD-SAM demonstrates strong cross-domain generalization with a
0.87 retention score (vs. 0.76 for SAM), and faster, more stable learning
dynamics, converging within 30-40 epochs, enjoying double the learning speed of
benchmark models. It maintains 0.607 mIoU with only 1000 samples, suggesting
data efficiency critical for reducing annotation costs. These results confirm
that targeted architectural and optimization enhancements to foundation models
enable reliable and scalable AD perception.

</details>


### [10] [ZEBRA: Towards Zero-Shot Cross-Subject Generalization for Universal Brain Visual Decoding](https://arxiv.org/abs/2510.27128)
*Haonan Wang,Jingyu Lu,Hongrui Li,Xiaomeng Li*

Main category: cs.CV

TL;DR: 介绍了一种名为ZEBRA的零样本脑视觉解码框架，该框架通过分解fMRI表示的主体相关和语义相关成分，实现了无需主体特定调整即可通用化的能力，跨主体性能效果显著，可作为通用神经解码的重要一步，链接提供了代码和模型权重


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖于特定主体模型或需要特定主体微调，限制了其可扩展性和实际可应用性。为了克服这一挑战，引入了一个名为ZEBRA的零样本脑视觉解码框架，旨在消除对主体特定适应的需求，提高方法的通用性与可扩展性

Method: ZEBRA通过引入对抗性训练，对fMRI表示进行分解，显式地隔离了主体不变、语义特定的表示，从而实现了跨主体的通用化能力

Result: 实验结果显示，ZEBRA在多个度量标准上显著优于零样本基线，并且其性能可与完全微调的模型相媲美

Conclusion: ZEBRA展示了在零样本条件下解码脑活动的潜力，克服了现有方法依赖于特定主体数据的限制，是实现通用神经解码的可扩展且实践性的一步

Abstract: Recent advances in neural decoding have enabled the reconstruction of visual
experiences from brain activity, positioning fMRI-to-image reconstruction as a
promising bridge between neuroscience and computer vision. However, current
methods predominantly rely on subject-specific models or require
subject-specific fine-tuning, limiting their scalability and real-world
applicability. In this work, we introduce ZEBRA, the first zero-shot brain
visual decoding framework that eliminates the need for subject-specific
adaptation. ZEBRA is built on the key insight that fMRI representations can be
decomposed into subject-related and semantic-related components. By leveraging
adversarial training, our method explicitly disentangles these components to
isolate subject-invariant, semantic-specific representations. This
disentanglement allows ZEBRA to generalize to unseen subjects without any
additional fMRI data or retraining. Extensive experiments show that ZEBRA
significantly outperforms zero-shot baselines and achieves performance
comparable to fully finetuned models on several metrics. Our work represents a
scalable and practical step toward universal neural decoding. Code and model
weights are available at: https://github.com/xmed-lab/ZEBRA.

</details>


### [11] [WildfireX-SLAM: A Large-scale Low-altitude RGB-D Dataset for Wildfire SLAM and Beyond](https://arxiv.org/abs/2510.27133)
*Zhicong Sun,Jacqueline Lo,Jinxing Hu*

Main category: cs.CV

TL;DR: 我们构建了一个大型、综合、高质量的合成数据集WildfireX-SLAM，用于在野火和森林环境中进行SLAM。该数据集基于Unreal Engine 5开发，包含从大规模森林地图中采集的5.5k低空RGB-D航拍图像，总面积为16平方公里。并利用该数据集进行了彻底的基准测试，揭示了基于3D高斯点云的SLAM在森林中的独特挑战，并为未来的研究工作提出改进方向。项目网页：https://zhicongsun.github.io/wildfirexslam


<details>
  <summary>Details</summary>
Motivation: 当前，针对大规模森林场景的基于3D高斯点云的SLAM技术的发展受到了高质量数据集短缺的阻碍。我们希望通过构建一个大型且高质量的数据集来推动这一领域的发展，特别是对于野火紧急响应和森林管理等实际应用具有重要意义。同时，该数据集的建立有助于更好地理解森林环境中基于3DGS的SLAM所面临的挑战，并为后续研究提供参考与改进方向。这项工作试图弥补现有数据集在大型森林场景中的不足，因此具有很高的应用价值和科学意义。

Method: 我们利用Unreal Engine 5开发了一套采集程序，能够生成包括地面真实相机姿态以及各种模态数据在内的大量数据。此采集程序还提供了灵活的环境控制手段，包括光线、天气和野火类型与条件等，从而为不同的任务提供了支持，如森林测绘、野火紧急响应等。通过这种方式生成的数据集WildfireX-SLAM包含了从大规模森林地图中采集的5.5k低空RGB-D航拍图像，总面积为16平方公里。同时，我们使用此数据集开展了一个彻底的基准测试，以验证我们的方法和发现潜在的改进方向。

Result: 我们成功地构建了WildfireX-SLAM数据集，并在此数据集上进行了基准测试，揭示了基于3DGS的SLAM在森林中的独特挑战，并为未来研究提供了可能的改进方向。此外，我们还公开发布了数据集和相关代码，为更多的研究者提供了便利。通过基准测试，我们发现基于3DGS的SLAM在处理大规模森林场景时存在一些特定挑战，这些挑战为未来的研究提供了方向。数据集的公开也有助于推动整个领域的发展，使更多研究者能够参与到基于3DGS的SLAM研究中来。

Conclusion: 我们构建了一个大型、高质量的合成数据集，用于在野火和森林环境中进行SLAM研究。此数据集将为研究和应用带来很大的帮助，特别是在处理大规模森林场景时。我们希望我们的工作能够推动基于3DGS的SLAM技术的发展，使其更好地服务于实际应用，比如野火紧急响应和森林管理。

Abstract: 3D Gaussian splatting (3DGS) and its subsequent variants have led to
remarkable progress in simultaneous localization and mapping (SLAM). While most
recent 3DGS-based SLAM works focus on small-scale indoor scenes, developing
3DGS-based SLAM methods for large-scale forest scenes holds great potential for
many real-world applications, especially for wildfire emergency response and
forest management. However, this line of research is impeded by the absence of
a comprehensive and high-quality dataset, and collecting such a dataset over
real-world scenes is costly and technically infeasible. To this end, we have
built a large-scale, comprehensive, and high-quality synthetic dataset for SLAM
in wildfire and forest environments. Leveraging the Unreal Engine 5 Electric
Dreams Environment Sample Project, we developed a pipeline to easily collect
aerial and ground views, including ground-truth camera poses and a range of
additional data modalities from unmanned aerial vehicle. Our pipeline also
provides flexible controls on environmental factors such as light, weather, and
types and conditions of wildfire, supporting the need for various tasks
covering forest mapping, wildfire emergency response, and beyond. The resulting
pilot dataset, WildfireX-SLAM, contains 5.5k low-altitude RGB-D aerial images
from a large-scale forest map with a total size of 16 km2. On top of
WildfireX-SLAM, a thorough benchmark is also conducted, which not only reveals
the unique challenges of 3DGS-based SLAM in the forest but also highlights
potential improvements for future works. The dataset and code will be publicly
available. Project page: https://zhicongsun.github.io/wildfirexslam.

</details>


### [12] [E-MMDiT: Revisiting Multimodal Diffusion Transformer Design for Fast Image Synthesis under Limited Resources](https://arxiv.org/abs/2510.27135)
*Tong Shen,Jingai Yu,Dong Zhou,Dong Li,Emad Barsoum*

Main category: cs.CV

TL;DR: 提出了一种高效的多模态扩散模型E-MMDiT，该模型仅包含304M参数，可在低训练资源下快速合成图像。通过引入压缩视觉词化器、多路径压缩模块、Position Reinforcement和ASA等技术创新，E-MMDiT实现了高效的图像生成。实验表明，模型在较少量的数据和时间内达到较好的性能，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型需要大量的训练数据和计算资源，或面临复杂的结构和高延迟的问题。为解决这些问题，本文提出了一种高效的多模态扩散模型，以降低训练成本并提高生成效率。

Method: 提出一种仅含304M参数的高效多模态扩散模型E-MMDiT。采用了压缩视觉词化器、多路径压缩模块、Position Reinforcement和ASA等方法，以降低模型复杂度和计算量。此外，提出了AdaLN-affine模块，用于高效计算模态参数。E-MMDiT通过这些技术的组合在较少量的数据和时间内有效地生成了高质量图像。

Result: 在仅用25M公共数据和1.5天内，模型在8张AMD MI300X GPU上训练后，在GenEval上达到0.66的性能，进一步通过后期训练技术可以提升至0.72，展示出与现有模型相当甚至更好的性能。

Conclusion: E-MMDiT代表了一种有效且实用的基线，未来可用于促进生成AI模型的普及。模型的高效性和较低的训练成本使其成为未来研究的有力工具。

Abstract: Diffusion models have shown strong capabilities in generating high-quality
images from text prompts. However, these models often require large-scale
training data and significant computational resources to train, or suffer from
heavy structure with high latency. To this end, we propose Efficient Multimodal
Diffusion Transformer (E-MMDiT), an efficient and lightweight multimodal
diffusion model with only 304M parameters for fast image synthesis requiring
low training resources. We provide an easily reproducible baseline with
competitive results. Our model for 512px generation, trained with only 25M
public data in 1.5 days on a single node of 8 AMD MI300X GPUs, achieves 0.66 on
GenEval and easily reaches to 0.72 with some post-training techniques such as
GRPO. Our design philosophy centers on token reduction as the computational
cost scales significantly with the token count. We adopt a highly compressive
visual tokenizer to produce a more compact representation and propose a novel
multi-path compression module for further compression of tokens. To enhance our
design, we introduce Position Reinforcement, which strengthens positional
information to maintain spatial coherence, and Alternating Subregion Attention
(ASA), which performs attention within subregions to further reduce
computational cost. In addition, we propose AdaLN-affine, an efficient
lightweight module for computing modulation parameters in transformer blocks.
Our code is available at https://github.com/AMD-AGI/Nitro-E and we hope E-MMDiT
serves as a strong and practical baseline for future research and contributes
to democratization of generative AI models.

</details>


### [13] [Improving Cross-view Object Geo-localization: A Dual Attention Approach with Cross-view Interaction and Multi-Scale Spatial Features](https://arxiv.org/abs/2510.27139)
*Xingtao Ling Yingying Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种通过多轮交互学习和抑制边缘噪声的方法，改进了跨视图目标地理定位的性能。方法使用了Cross-view和Cross-attention Module(CVCAM)和Multi-head Spatial Attention Module(MHSAM)，并在一个新的“地面至无人机”地理定位数据集上进行了验证，实验表明其性能优于当前的最新技术。


<details>
  <summary>Details</summary>
Motivation: 现有的跨视图物体地理定位方法通过注意力机制捕获不同视图之间的空间依赖关系，但在视图间的信息转移和空间关系特征图的进一步细化方面存在不足，影响了模型的性能。为解决这一问题，本文提出了一种改进的方法。

Method: 提出了一种新的模块Cross-view and Cross-attention Module(CVCAM)，通过多个迭代交互学习查询对象的上下文信息；以及一种多头空间注意力模块Multi-head Spatial Attention Module(MHSAM)，该模块使用不同大小的卷积核提取多尺度的空间特征，增强了查询对象的特征表示。本文还创建了一个新的“地面到无人机”地理定位数据集G2D。

Result: 实验结果表明，本文提出的方法在CVOGL和G2D数据集上的定位准确率高于现有的最先进方法。

Conclusion: 通过跨视图和跨注意力模块及多头空间注意力模块，本文方法提升了跨视图目标地理定位的性能，并创建了一个新的“地面到无人机”数据集，对模型的性能进行了验证。

Abstract: Cross-view object geo-localization has recently gained attention due to
potential applications. Existing methods aim to capture spatial dependencies of
query objects between different views through attention mechanisms to obtain
spatial relationship feature maps, which are then used to predict object
locations. Although promising, these approaches fail to effectively transfer
information between views and do not further refine the spatial relationship
feature maps. This results in the model erroneously focusing on irrelevant edge
noise, thereby affecting localization performance. To address these
limitations, we introduce a Cross-view and Cross-attention Module (CVCAM),
which performs multiple iterations of interaction between the two views,
enabling continuous exchange and learning of contextual information about the
query object from both perspectives. This facilitates a deeper understanding of
cross-view relationships while suppressing the edge noise unrelated to the
query object. Furthermore, we integrate a Multi-head Spatial Attention Module
(MHSAM), which employs convolutional kernels of various sizes to extract
multi-scale spatial features from the feature maps containing implicit
correspondences, further enhancing the feature representation of the query
object. Additionally, given the scarcity of datasets for cross-view object
geo-localization, we created a new dataset called G2D for the "Ground-to-Drone"
localization task, enriching existing datasets and filling the gap in
"Ground-to-Drone" localization task. Extensive experiments on the CVOGL and G2D
datasets demonstrate that our proposed method achieves high localization
accuracy, surpassing the current state-of-the-art.

</details>


### [14] [HiGS: Hierarchical Generative Scene Framework for Multi-Step Associative Semantic Spatial Composition](https://arxiv.org/abs/2510.27148)
*Jiacheng Hong,Kunzhen Wu,Mingrui Yu,Yichao Gu,Shengze Xue,Shuangjiu Xiao,Deli Dong*

Main category: cs.CV

TL;DR: HiGS是一个分层生成框架，通过逐步的关联语义空间组合，用户可以迭代地扩展场景，同时模型自动完成边缘区域的设计。实验表明，与单一阶段方法相比，HiGS在布局合理性、风格一致性和用户偏好方面表现更优，提供了一种可控和可扩展的方式进行高效的3D场景构建。


<details>
  <summary>Details</summary>
Motivation: 现有大多数方法采用单一步骤生成场景，难以同时处理复杂性和最小用户输入的问题。受到人类认知过程在场景建模中从全局到局部，关注关键元素并通过语义关联完成场景的启发，提出了HiGS框架。该框架旨在解决高效3D场景构建中的控件制和扩展性问题。

Method: HiGS框架通过引入渐进式分层空间语义图（PHiSSG），实现了基于选择关键语义对象的迭代场景扩展，确保了空间和几何一致性。该图能够动态组织空间关系和语义依赖，维护图节点与生成物体的一对一映射，支持递归布局优化。

Result: 实验表明，与单一阶段方法相比，HiGS框架在布局合理性、风格一致性和用户偏好方面表现更优，证明了一种更有效的3D场景生成方法。

Conclusion: 通过基于分层生成和多步关联语义空间组合的HiGS框架，用户能够获得更高灵活性的场景控制以及更合理的布局，提出的方法对于高效3D场景构建有重要贡献。

Abstract: Three-dimensional scene generation holds significant potential in gaming,
film, and virtual reality. However, most existing methods adopt a single-step
generation process, making it difficult to balance scene complexity with
minimal user input. Inspired by the human cognitive process in scene modeling,
which progresses from global to local, focuses on key elements, and completes
the scene through semantic association, we propose HiGS, a hierarchical
generative framework for multi-step associative semantic spatial composition.
HiGS enables users to iteratively expand scenes by selecting key semantic
objects, offering fine-grained control over regions of interest while the model
completes peripheral areas automatically. To support structured and coherent
generation, we introduce the Progressive Hierarchical Spatial-Semantic Graph
(PHiSSG), which dynamically organizes spatial relationships and semantic
dependencies across the evolving scene structure. PHiSSG ensures spatial and
geometric consistency throughout the generation process by maintaining a
one-to-one mapping between graph nodes and generated objects and supporting
recursive layout optimization. Experiments demonstrate that HiGS outperforms
single-stage methods in layout plausibility, style consistency, and user
preference, offering a controllable and extensible paradigm for efficient 3D
scene construction.

</details>


### [15] [AFM-Net: Advanced Fusing Hierarchical CNN Visual Priors with Global Sequence Modeling for Remote Sensing Image Scene Classification](https://arxiv.org/abs/2510.27155)
*Yuanhao Tang,Xuechao Zou,Zhengpei Hu,Junliang Xing,Chengkun Zhang,Jianqiang Huang*

Main category: cs.CV

TL;DR: AFM-Net, a new model for remote sensing image scene classification, balances effectiveness and efficiency by integrating CNNs and Transformers with a Hierarchical Fusion Mechanism.


<details>
  <summary>Details</summary>
Motivation: 现有的CNN和Transformer分别在处理局部纹理和全球上下文方面表现出色，但是它们的有效融合依然是一个瓶颈。因此，作者提出AFM-Net，旨在解决这一问题，通过有效融合局部和全局信息来提高远程感测图像场景分类的效率和准确性。

Method: AFM-Net 包括两个分支：一个CNN分支用于提取分层视觉先验，一个Mamba分支用于高效全局序列建模。它的核心创新在于分层融合机制，可以逐步聚合两个路径的多尺度特征，产生高度区分性的表示。然后，这些融合的特征通过混合专家分类器模块进行适应性路由，以便将它们转发到最适合的专家进行细粒度场景识别。

Result: AFM-Net 在 AID, NWPU-RESISC45 和 UC Merced 数据集上分别获得93.72％，95.54％和96.92％的准确率，这些数据证明了该方法在准确性和效率之间的良好平衡以及优于现有最先进的方法的能力。

Conclusion: 通过有效结合CNN和Transformer的力量，并通过细致的多尺度特征融合，AFM-Net大幅度提升了远程感测图像场景分类的准确性，同时保持了计算效率。

Abstract: Remote sensing image scene classification remains a challenging task,
primarily due to the complex spatial structures and multi-scale characteristics
of ground objects. Existing approaches see CNNs excel at modeling local
textures, while Transformers excel at capturing global context. However,
efficiently integrating them remains a bottleneck due to the high computational
cost of Transformers. To tackle this, we propose AFM-Net, a novel Advanced
Hierarchical Fusing framework that achieves effective local and global
co-representation through two pathways: a CNN branch for extracting
hierarchical visual priors, and a Mamba branch for efficient global sequence
modeling. The core innovation of AFM-Net lies in its Hierarchical Fusion
Mechanism, which progressively aggregates multi-scale features from both
pathways, enabling dynamic cross-level feature interaction and contextual
reconstruction to produce highly discriminative representations. These fused
features are then adaptively routed through a Mixture-of-Experts classifier
module, which dispatches them to the most suitable experts for fine-grained
scene recognition. Experiments on AID, NWPU-RESISC45, and UC Merced show that
AFM-Net obtains 93.72, 95.54, and 96.92 percent accuracy, surpassing
state-of-the-art methods with balanced performance and efficiency. Code is
available at https://github.com/tangyuanhao-qhu/AFM-Net.

</details>


### [16] [How Close Are We? Limitations and Progress of AI Models in Banff Lesion Scoring](https://arxiv.org/abs/2510.27158)
*Yanfan Zhu,Juming Xiong,Ruining Deng,Yu Wang,Yaohong Wang,Shilin Zhao,Mengmeng Yin,Yuqing Liu,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: 该研究探讨了使用现有深度学习模型通过基于规则的框架来接近Banff病变评分的可能性。研究发现，尽管最终评分与专家注释匹配，但中间表示的不一致通常会削弱可解释性，突显了当前AI管道在复制计算专家级评分方面的局限性，并强调了模块化评估和计算Banff评分标准在指导未来模型开发中的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的Banff分类虽然是评估肾移植活检的全球标准，但由于其半定量性质、复杂标准和观察者间变异，给其计算复制带来了极大的挑战。

Method: 该研究通过模块化、基于规则的框架探索了使用现有深度学习模型接近Banff评分的可行性。每个Banff指标（如肾小球炎、小管周围毛细血管炎和动脉内膜炎）被分解成其结构和炎症成分，并且评估当前分割和检测工具是否可以支持这些指标的计算。模型输出通过与专家指南一致的启发式规则映射到Banff评分，并与专家注释进行对比。

Result: 该研究揭示了在结构遗漏、幻觉和检测模棱两可等问题中的部分成功和关键失败模式。即便最终评分与专家注释匹配，中间表示的不一致通常会削弱可解释性，反映了当前AI管道在复制计算专家级评分方面的局限性。

Conclusion: 研究结果强调了模块化评估和计算Banff评分标准在引导未来模型开发方面的重要性。

Abstract: The Banff Classification provides the global standard for evaluating renal
transplant biopsies, yet its semi-quantitative nature, complex criteria, and
inter-observer variability present significant challenges for computational
replication. In this study, we explore the feasibility of approximating Banff
lesion scores using existing deep learning models through a modular, rule-based
framework. We decompose each Banff indicator - such as glomerulitis (g),
peritubular capillaritis (ptc), and intimal arteritis (v) - into its
constituent structural and inflammatory components, and assess whether current
segmentation and detection tools can support their computation. Model outputs
are mapped to Banff scores using heuristic rules aligned with expert
guidelines, and evaluated against expert-annotated ground truths. Our findings
highlight both partial successes and critical failure modes, including
structural omission, hallucination, and detection ambiguity. Even when final
scores match expert annotations, inconsistencies in intermediate
representations often undermine interpretability. These results reveal the
limitations of current AI pipelines in replicating computational expert-level
grading, and emphasize the importance of modular evaluation and computational
Banff grading standard in guiding future model development for transplant
pathology.

</details>


### [17] [Generating Accurate and Detailed Captions for High-Resolution Images](https://arxiv.org/abs/2510.27164)
*Hankyeol Lee,Gawon Seo,Kyounggyu Lee,Dogun Kim,Kyungwoo Song,Jiyoung Jung*

Main category: cs.CV

TL;DR: 本文提出了一种结合视觉-语言模型、大语言模型和对象检测系统的新管道，用于增强高分辨率图像的图片描述的质量，减少幻觉并增加描述的细节。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型在对高分辨率图像进行准确和详细的描述时遇到困难，因为它们通常在低分辨率输入上进行预训练，导致图像细节丢失和重要对象被忽略。

Method: 该方法采用一种多阶段过程，首先通过视觉-语言模型生成初始描述，然后使用大语言模型识别图像中的关键对象，并通过对象检测系统验证这些预测。未在初始描述中提及的新检测到的对象会通过特定区域的描述来确保其被包含，从而增强了描述的细节，减少了幻觉。

Result: 实验显示，所提出的管道生成了更详细和可靠的图像描述，有效地减少了幻觉。我们通过成对比较和来自大型多模态模型的定量评分以及幻觉检测基准对增强的描述进行了评估。

Conclusion: 结合视觉-语言模型、大语言模型和对象检测系统的新管道，能够有效提升高分辨率图像描述的质量，减少幻觉并增加描述的细节。

Abstract: Vision-language models (VLMs) often struggle to generate accurate and
detailed captions for high-resolution images since they are typically
pre-trained on low-resolution inputs (e.g., 224x224 or 336x336 pixels).
Downscaling high-resolution images to these dimensions may result in the loss
of visual details and the omission of important objects. To address this
limitation, we propose a novel pipeline that integrates vision-language models,
large language models (LLMs), and object detection systems to enhance caption
quality. Our proposed pipeline refines captions through a novel, multi-stage
process. Given a high-resolution image, an initial caption is first generated
using a VLM, and key objects in the image are then identified by an LLM. The
LLM predicts additional objects likely to co-occur with the identified key
objects, and these predictions are verified by object detection systems. Newly
detected objects not mentioned in the initial caption undergo focused,
region-specific captioning to ensure they are incorporated. This process
enriches caption detail while reducing hallucinations by removing references to
undetected objects. We evaluate the enhanced captions using pairwise comparison
and quantitative scoring from large multimodal models, along with a benchmark
for hallucination detection. Experiments on a curated dataset of
high-resolution images demonstrate that our pipeline produces more detailed and
reliable image captions while effectively minimizing hallucinations.

</details>


### [18] [M^3Detection: Multi-Frame Multi-Level Feature Fusion for Multi-Modal 3D Object Detection with Camera and 4D Imaging Radar](https://arxiv.org/abs/2510.27166)
*Xiaozhi Li,Huijun Di,Jian Li,Feng Liu,Wei Liang*

Main category: cs.CV

TL;DR: 提出了M^3Detection框架，该框架用于融合多帧相机和4D成像雷达数据，以改善3D物体检测性能。M^3Detection利用中间特征和跟踪器生成参考轨迹，改进计算效率，并增加第二阶段的信息丰富度。实验表明，该框架达到了SOTA的3D检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的相机-雷达融合方法大多限于单帧输入，导致无法充分利用丰富的时空信息，M^3Detection旨在解决这一问题，通过多帧融合提供更全面的检测能力。

Method: M^3Detection框架采用了多级特征融合方法，包含全局级的跨对象特征聚合模块和局部级的跨网格特征聚合模块，分别提高了全局和局部特征的质量。此外，框架还包括轨迹级的多帧时空推理模块，增强了时间特征的表达能力。

Result: 实验表明，M^3Detection在VoD和TJ4DRadSet数据集上的3D检测性能达到了SOTA水平，验证了多帧检测的优越性以及相机-4D成像雷达融合的有效性。

Conclusion: M^3Detection提供了一种有效的多帧3D检测框架，通过融合相机和4D成像雷达的多模态数据，显著提高了检测性能。

Abstract: Recent advances in 4D imaging radar have enabled robust perception in adverse
weather, while camera sensors provide dense semantic information. Fusing the
these complementary modalities has great potential for cost-effective 3D
perception. However, most existing camera-radar fusion methods are limited to
single-frame inputs, capturing only a partial view of the scene. The incomplete
scene information, compounded by image degradation and 4D radar sparsity,
hinders overall detection performance. In contrast, multi-frame fusion offers
richer spatiotemporal information but faces two challenges: achieving robust
and effective object feature fusion across frames and modalities, and
mitigating the computational cost of redundant feature extraction.
Consequently, we propose M^3Detection, a unified multi-frame 3D object
detection framework that performs multi-level feature fusion on multi-modal
data from camera and 4D imaging radar. Our framework leverages intermediate
features from the baseline detector and employs the tracker to produce
reference trajectories, improving computational efficiency and providing richer
information for second-stage. In the second stage, we design a global-level
inter-object feature aggregation module guided by radar information to align
global features across candidate proposals and a local-level inter-grid feature
aggregation module that expands local features along the reference trajectories
to enhance fine-grained object representation. The aggregated features are then
processed by a trajectory-level multi-frame spatiotemporal reasoning module to
encode cross-frame interactions and enhance temporal representation. Extensive
experiments on the VoD and TJ4DRadSet datasets demonstrate that M^3Detection
achieves state-of-the-art 3D detection performance, validating its
effectiveness in multi-frame detection with camera-4D imaging radar fusion.

</details>


### [19] [DANCER: Dance ANimation via Condition Enhancement and Rendering with diffusion model](https://arxiv.org/abs/2510.27169)
*Yucheng Xing,Jinxing Yin,Xiaodong Liu*

Main category: cs.CV

TL;DR: 本文提出了一个基于最新型稳定视频扩散模型的单人舞蹈合成框架DANCER，通过引入外观增强模块和姿态渲染模块来提高视频生成的质量和连续性。实验结果显示该模型在真实世界数据集上的性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然扩散模型在生成静态图像方面表现出色，但生成高质量的视频尤其是涉及人的内容（如舞蹈）更具挑战性，因为人的动作具有很高的自由度。本文旨在通过优化框架来提高单人舞蹈生成的质量和连续性。

Method: 本文提出一种新的框架DANCER，包括外观增强模块（AEM）和姿态渲染模块（PRM）等，并收集了大量视频数据以生成新型数据集TikTok-3K，增强模型训练效果。

Result: 通过在真实世界数据集上的实验，证明了所提出模型的优越性，其性能优于当前最先进方法。

Conclusion: 本文提出的基于扩散模型的舞蹈视频合成框架DANCER，在提高单人舞蹈生成的质量和连续性方面取得了显著成果。

Abstract: Recently, diffusion models have shown their impressive ability in visual
generation tasks. Besides static images, more and more research attentions have
been drawn to the generation of realistic videos. The video generation not only
has a higher requirement for the quality, but also brings a challenge in
ensuring the video continuity. Among all the video generation tasks,
human-involved contents, such as human dancing, are even more difficult to
generate due to the high degrees of freedom associated with human motions. In
this paper, we propose a novel framework, named as DANCER (Dance ANimation via
Condition Enhancement and Rendering with Diffusion Model), for realistic
single-person dance synthesis based on the most recent stable video diffusion
model. As the video generation is generally guided by a reference image and a
video sequence, we introduce two important modules into our framework to fully
benefit from the two inputs. More specifically, we design an Appearance
Enhancement Module (AEM) to focus more on the details of the reference image
during the generation, and extend the motion guidance through a Pose Rendering
Module (PRM) to capture pose conditions from extra domains. To further improve
the generation capability of our model, we also collect a large amount of video
data from Internet, and generate a novel datasetTikTok-3K to enhance the model
training. The effectiveness of the proposed model has been evaluated through
extensive experiments on real-world datasets, where the performance of our
model is superior to that of the state-of-the-art methods. All the data and
codes will be released upon acceptance.

</details>


### [20] [H2-Cache: A Novel Hierarchical Dual-Stage Cache for High-Performance Acceleration of Generative Diffusion Models](https://arxiv.org/abs/2510.27171)
*Mingyu Sung,Il-Min Kim,Sangseok Yun,Jae-Mo Kang*

Main category: cs.CV

TL;DR: H2-Cache 是一种新的用于现代生成扩散模型架构的层次缓存机制，它通过将去噪过程分成结构定义阶段和细节微调阶段，并使用双阈值系统，在不牺牲图像质量的情况下显著加速了扩散模型的推理过程。实验结果表明，H2-Cache 达到了5.08倍的最大加速，同时保持了与基线模型几乎相同的图像质量，并且性能优于现有缓存方法。源代码可以在 https://github.com/Bluear7878/H2-cache-A-Hierarchical-Dual-Stage-Cache 获取。


<details>
  <summary>Details</summary>
Motivation: 现有的缓存技术在速度与质量之间存在难以调和的矛盾，往往导致质量下降和计算开销高。本文旨在解决这个难题，提出H2-Cache，以期在不牺牲图像质量的情况下显著提升扩散模型的推理速度，促进高保真扩散模型在实际应用中的部署。

Method: H2-Cache 通过将去噪过程分为结构定义阶段和细节微调阶段，使用双阈值系统分阶段缓存以加速推理。为了确保双阈值模式的有效性，引入了轻量级的池化特征总结（PFS）技术，用于快速且稳健的相似性估计。

Result: 实验结果证明，H2-cache 实现了高达5.08倍的加速效果，同时保持了与基线模型相同的图像质量，优于现有的缓存方法，解决了速度与质量之间的矛盾。

Conclusion: H2-Cache 是一种稳健且实用的解决方案，有效解决了速度与质量之间的难题，大大降低了高保真扩散模型在实际应用中的门槛。

Abstract: Diffusion models have emerged as state-of-the-art in image generation, but
their practical deployment is hindered by the significant computational cost of
their iterative denoising process. While existing caching techniques can
accelerate inference, they often create a challenging trade-off between speed
and fidelity, suffering from quality degradation and high computational
overhead. To address these limitations, we introduce H2-Cache, a novel
hierarchical caching mechanism designed for modern generative diffusion model
architectures. Our method is founded on the key insight that the denoising
process can be functionally separated into a structure-defining stage and a
detail-refining stage. H2-cache leverages this by employing a dual-threshold
system, using independent thresholds to selectively cache each stage. To ensure
the efficiency of our dual-check approach, we introduce pooled feature
summarization (PFS), a lightweight technique for robust and fast similarity
estimation. Extensive experiments on the Flux architecture demonstrate that
H2-cache achieves significant acceleration (up to 5.08x) while maintaining
image quality nearly identical to the baseline, quantitatively and
qualitatively outperforming existing caching methods. Our work presents a
robust and practical solution that effectively resolves the speed-quality
dilemma, significantly lowering the barrier for the real-world application of
high-fidelity diffusion models. Source code is available at
https://github.com/Bluear7878/H2-cache-A-Hierarchical-Dual-Stage-Cache.

</details>


### [21] [Dual-level Progressive Hardness-Aware Reweighting for Cross-View Geo-Localization](https://arxiv.org/abs/2510.27181)
*Guozheng Zheng,Jian Guan,Mingjie Xie,Xuanjia Zhao,Congyi Fan,Shiheng Zhang,Pengming Feng*

Main category: cs.CV

TL;DR: 本文提出了一种双级渐进困难感知重加权策略(DPHR)，用于解决无人机和卫星图像之间的跨视角地理定位问题。该策略通过样本级别和批级别双轨制方法，有效解决了现有静态加权方法在分布偏移和早期优化过程中产生的噪声梯度问题，并在两个基准数据集上取得了优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 面对无人机与卫星图像之间的地理定位难题，现有方法中的静态加权策略容易受到分布变化的影响，并可能过早地过分强调困难样本，从而导致了梯度噪音和不稳定收敛的问题。因此，需要一种新的策略来解决这些问题，即DPHR策略。

Method: 方法包含两部分：一是样本级别的基于比率的难度感知模块及相关流程；二是批量级别的渐进自适应损失加权机制，逐步稳定化并且提升困难样本的挖掘。通过动态调整权重来优化训练过程，减弱噪声梯度并提升结果质量。

Result: 实验结果表明，DPHR策略可以在多个基准数据集上获得比现有最佳方法更好的性能，展现了其有效的性能和稳健性。

Conclusion: 这种方法能够更高效地处理无人机和卫星图像间的跨视角地理定位问题，相较于传统的重加权方案，具有更好的稳定性和准确性。

Abstract: Cross-view geo-localization (CVGL) between drone and satellite imagery
remains challenging due to severe viewpoint gaps and the presence of hard
negatives, which are visually similar but geographically mismatched samples.
Existing mining or reweighting strategies often use static weighting, which is
sensitive to distribution shifts and prone to overemphasizing difficult samples
too early, leading to noisy gradients and unstable convergence. In this paper,
we present a Dual-level Progressive Hardness-aware Reweighting (DPHR) strategy.
At the sample level, a Ratio-based Difficulty-Aware (RDA) module evaluates
relative difficulty and assigns fine-grained weights to negatives. At the batch
level, a Progressive Adaptive Loss Weighting (PALW) mechanism exploits a
training-progress signal to attenuate noisy gradients during early optimization
and progressively enhance hard-negative mining as training matures. Experiments
on the University-1652 and SUES-200 benchmarks demonstrate the effectiveness
and robustness of the proposed DPHR, achieving consistent improvements over
state-of-the-art methods.

</details>


### [22] [Can MLLMs Read the Room? A Multimodal Benchmark for Verifying Truthfulness in Multi-Party Social Interactions](https://arxiv.org/abs/2510.27195)
*Caixin Kang,Yifei Huang,Liangyang Ouyang,Mingfang Zhang,Yoichi Sato*

Main category: cs.CV

TL;DR: 研究介绍了一个新的任务Multimodal Interactive Veracity Assessment (MIVA)和一个新数据集，用于评估AI系统在动态多党对话中的自动识别真相与谎言的能力，特别是当这些对话来源于社交游戏狼人杀时。结果表明即使是强大的模型如GPT-4o在这一任务上也表现不佳，凸显了构建更敏锐和值得信赖的AI系统的重要性。


<details>
  <summary>Details</summary>
Motivation: 在AI系统越来越多地融入人类生活中时，让它们具备识别真相与谎言的能力成为一个关键任务，这项任务在之前的自动检测多党动态对话中的难度大。为了推动这个方向的发展，研究提出了一个新的评估任务MIVA，并提出了一个有标签的新数据集来测试AI系统的能力。同时，为了便于比较，建立了基准测试，测试现有的LLMM们在该任务上的表现。这些结果表明，在社交线索和语言理解上，现有模型仍存在很大不足。更要问题的是，模型对于社交智能的理解和把握不足，导致它们在识别谎言和真话方面表现不够理想， 这凸显了未来开发更可感知和值得信赖的AI系统的重要性。

Method: 这个研究提出了一个用来评估多模态大型语言模型识别真相与谎言能力的新的任务MIVA和一个来源于社交游戏的数据集。数据集包含了同步的视频，文本，以及每个陈述的验证标签。用这个数据集建立了基准测试，用以评估当前最先进模型的表现。并且通过失败模式分析来评估模型在任务中的间题之处。

Result: 基准测试表明，尽管当下最强大的模型如GPT-4o在区分谎言和真实陈述方面也表现出明显的不足，而这些不足主要出在社交线索的把握及语言理解上。结果表明，这些大的语言模型虽然在语言理解上表现出强大能力，但在至关重要的识别谎言和真实陈述的任务上依然面临重大挑战。

Conclusion: 这个研究介绍了识别真相与谎言任务MIVA的解决方案，展示了现有最先进模型在测试上的不足，指出了社交定位和语言理解对任务的关键作用，突出了构建更全面和可信赖的AI系统的紧迫性。

Abstract: As AI systems become increasingly integrated into human lives, endowing them
with robust social intelligence has emerged as a critical frontier. A key
aspect of this intelligence is discerning truth from deception, a ubiquitous
element of human interaction that is conveyed through a complex interplay of
verbal language and non-verbal visual cues. However, automatic deception
detection in dynamic, multi-party conversations remains a significant
challenge. The recent rise of powerful Multimodal Large Language Models
(MLLMs), with their impressive abilities in visual and textual understanding,
makes them natural candidates for this task. Consequently, their capabilities
in this crucial domain are mostly unquantified. To address this gap, we
introduce a new task, Multimodal Interactive Veracity Assessment (MIVA), and
present a novel multimodal dataset derived from the social deduction game
Werewolf. This dataset provides synchronized video, text, with verifiable
ground-truth labels for every statement. We establish a comprehensive benchmark
evaluating state-of-the-art MLLMs, revealing a significant performance gap:
even powerful models like GPT-4o struggle to distinguish truth from falsehood
reliably. Our analysis of failure modes indicates that these models fail to
ground language in visual social cues effectively and may be overly
conservative in their alignment, highlighting the urgent need for novel
approaches to building more perceptive and trustworthy AI systems.

</details>


### [23] [Privacy-Aware Continual Self-Supervised Learning on Multi-Window Chest Computed Tomography for Domain-Shift Robustness](https://arxiv.org/abs/2510.27213)
*Ren Tasai,Guang Li,Ren Togo,Takahiro Ogawa,Kenji Hirata,Minghui Tang,Takaaki Yoshimura,Hiroyuki Sugimori,Noriko Nishioka,Yukie Shimizu,Kohsuke Kudo,Miki Haseyama*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的连续自我监督学习框架，可以同时从多窗口获取的胸部CT图像中学习多样化的特征，并确保数据隐私。该框架通过在未标记的图像上持续预训练，有效捕捉不同训练阶段先前学到的知识与新信息之间的关系，缓解由于领域偏移导致的灾难性遗忘，同时提高模型的稳定性和泛化能力，并通过结合Wasserstein距离基知识蒸馏和批知识集成技术来增强模型学习有意义且领域偏移鲁棒的表示的能力。


<details>
  <summary>Details</summary>
Motivation: 论文的主要动机是解决医疗图像诊断中由于大规模精确标注数据集的稀缺性和动态医疗环境中固有的领域偏移所带来的挑战，尤其是在胸部CT图像中由于窗口设置的不同导致的领域偏移问题。同时，以往连续自我监督学习框架通过重用过去数据来缓解领域偏移的方法通常是由于隐私限制而不可行的。因此，该论文提出了一个新的方法来解决这些问题。

Method: 该方法通过将隐式重现机制整合到连续自我监督学习中，有效捕捉先前学到的知识与新信息之间的关系，并通过结合Wasserstein距离基知识蒸馏和批知识集成技术来增强模型的学习能力。这种方法可以缓解由于领域偏移导致的灾难性遗忘，同时确保数据隐私。

Result: 实验结果证明了该方法的有效性，特别是在胸部CT图像不同窗口设置的情况下，该方法的表现优于其他方法。这表明该方法能够更好地保持模型的稳定性和泛化能力。

Conclusion: 论文提出的方法解决了在医疗图像诊断中由于数据标签稀少、领域差异以及隐私限制而面临的挑战，同时证明了该方法的有效性和优越性。

Abstract: We propose a novel continual self-supervised learning (CSSL) framework for
simultaneously learning diverse features from multi-window-obtained chest
computed tomography (CT) images and ensuring data privacy. Achieving a robust
and highly generalizable model in medical image diagnosis is challenging,
mainly because of issues, such as the scarcity of large-scale, accurately
annotated datasets and domain shifts inherent to dynamic healthcare
environments. Specifically, in chest CT, these domain shifts often arise from
differences in window settings, which are optimized for distinct clinical
purposes. Previous CSSL frameworks often mitigated domain shift by reusing past
data, a typically impractical approach owing to privacy constraints. Our
approach addresses these challenges by effectively capturing the relationship
between previously learned knowledge and new information across different
training stages through continual pretraining on unlabeled images.
Specifically, by incorporating a latent replay-based mechanism into CSSL, our
method mitigates catastrophic forgetting due to domain shifts during continual
pretraining while ensuring data privacy. Additionally, we introduce a feature
distillation technique that integrates Wasserstein distance-based knowledge
distillation (WKD) and batch-knowledge ensemble (BKE), enhancing the ability of
the model to learn meaningful, domain-shift-robust representations. Finally, we
validate our approach using chest CT images obtained across two different
window settings, demonstrating superior performance compared with other
approaches.

</details>


### [24] [Mask-to-Height: A YOLOv11-Based Architecture for Joint Building Instance Segmentation and Height Classification from Satellite Imagery](https://arxiv.org/abs/2510.27224)
*Mahmoud El Hussieni,Bahadır K. Güntürk,Hasan F. Ateş,Oğuz Hanoğlu*

Main category: cs.CV

TL;DR: 本文介绍了YOLOv11在卫星图像中联合提取建筑实例并进行离散高度分类的详细分析，使用DFC2023 Track 2数据集评估，结果显示YOLOv11在实例分割性能和分类准确性方面表现出色，优于前几代YOLO模型和多任务框架，适合实时大规模城市地图绘制任务。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于准确的建筑实例分割和高度分类对于城市规划、3D城市建模和基础设施监测至关重要，通过改进的YOLO系列模型YOLOv11来提高这些任务的性能和效率。

Method: 研究采用了YOLOv11模型，并使用DFC2023 Track 2数据集进行评估，测试了模型在实例分割和高度分类上的性能。YOLOv11在准确性和效率方面改进，特别是在处理遮挡和复杂建筑形状方面有了显著提升。

Result: 实验结果显示，YOLOv11在实例分割性能方面达到了60.4%的mAP@50和38.3%的mAP@50--95，同时保持了在五类预定义高度区间的分类准确性。YOLOv11在处理遮挡、复杂建筑形态和类别不平衡方面表现优于其它多任务框架，特别是在稀有高楼大厦的分类中表现优异。

Conclusion: 该研究证明了YOLOv11在实例分割和高度分类任务上的卓越性能，展示了其在实时大规模城市地图绘制中的应用潜力，有利于推动语义城市重建和远程感知及地理空间智能的发展。

Abstract: Accurate building instance segmentation and height classification are
critical for urban planning, 3D city modeling, and infrastructure monitoring.
This paper presents a detailed analysis of YOLOv11, the recent advancement in
the YOLO series of deep learning models, focusing on its application to joint
building extraction and discrete height classification from satellite imagery.
YOLOv11 builds on the strengths of earlier YOLO models by introducing a more
efficient architecture that better combines features at different scales,
improves object localization accuracy, and enhances performance in complex
urban scenes. Using the DFC2023 Track 2 dataset -- which includes over 125,000
annotated buildings across 12 cities -- we evaluate YOLOv11's performance using
metrics such as precision, recall, F1 score, and mean average precision (mAP).
Our findings demonstrate that YOLOv11 achieves strong instance segmentation
performance with 60.4\% mAP@50 and 38.3\% mAP@50--95 while maintaining robust
classification accuracy across five predefined height tiers. The model excels
in handling occlusions, complex building shapes, and class imbalance,
particularly for rare high-rise structures. Comparative analysis confirms that
YOLOv11 outperforms earlier multitask frameworks in both detection accuracy and
inference speed, making it well-suited for real-time, large-scale urban
mapping. This research highlights YOLOv11's potential to advance semantic urban
reconstruction through streamlined categorical height modeling, offering
actionable insights for future developments in remote sensing and geospatial
intelligence.

</details>


### [25] [MoRE: 3D Visual Geometry Reconstruction Meets Mixture-of-Experts](https://arxiv.org/abs/2510.27234)
*Jingnan Gao,Zhe Wang,Xianze Fang,Xingyu Ren,Zhuo Chen,Shengqi Liu,Yuhao Cheng,Jiangjing Lyu,Xiaokang Yang,Yichao Yan*

Main category: cs.CV

TL;DR: 我们提出了MoRE，一种基于Mixture-of-Experts架构的密集3D视觉基础模型，通过动态路由特性到特定任务专家，提高可扩展性和适应性，同时引入置信度基深度优化模块，提高几何估计的稳定性和精度，在多个基准测试中表现出色，无需额外计算即可支持下游应用。


<details>
  <summary>Details</summary>
Motivation: 由于几何监督的复杂性和3D数据的多样性，进一步扩大3D模型规模存在挑战。为了解决这个问题，提出了MoRE模型，以解决3D视觉几何重建任务中的扩展性和鲁棒性问题。

Method: 基于Mixture-of-Experts架构，通过路由任务特定特征，强化模型在几何数据上的表现。通过置信度基深度优化模块和定制损失函数优化模型表现，结合密集语义特征和全局对齐的3D骨干表示实现高保真表面法线预测。

Result: MoRE模型在多个几何任务上实现了优异的性能，并且无需额外计算就能支持下游应用。实验结果表明，MoRE模型在多个基准测试中取得了最先进的性能。

Conclusion: MoRE模型不仅克服了进一步扩大3D模型规模的挑战，还提高了模型在复杂几何数据上的鲁棒性和适应性，支持有效的下游应用。

Abstract: Recent advances in language and vision have demonstrated that scaling up
model capacity consistently improves performance across diverse tasks. In 3D
visual geometry reconstruction, large-scale training has likewise proven
effective for learning versatile representations. However, further scaling of
3D models is challenging due to the complexity of geometric supervision and the
diversity of 3D data. To overcome these limitations, we propose MoRE, a dense
3D visual foundation model based on a Mixture-of-Experts (MoE) architecture
that dynamically routes features to task-specific experts, allowing them to
specialize in complementary data aspects and enhance both scalability and
adaptability. Aiming to improve robustness under real-world conditions, MoRE
incorporates a confidence-based depth refinement module that stabilizes and
refines geometric estimation. In addition, it integrates dense semantic
features with globally aligned 3D backbone representations for high-fidelity
surface normal prediction. MoRE is further optimized with tailored loss
functions to ensure robust learning across diverse inputs and multiple
geometric tasks. Extensive experiments demonstrate that MoRE achieves
state-of-the-art performance across multiple benchmarks and supports effective
downstream applications without extra computation.

</details>


### [26] [RegionRAG: Region-level Retrieval-Augumented Generation for Visually-Rich Documents](https://arxiv.org/abs/2510.27261)
*Yinglu Li,Zhiying Lu,Zhihang Liu,Chuanbin Liu,Hongtao Xie*

Main category: cs.CV

TL;DR: 本文提出了一种新的框架RegionRAG，它将检索粒度从文档级别转移到区域级别，以减少冗余和不相关的上下文，提高模型性能。实验表明，RegionRAG在六个基准测试中表现出色，提高了检索和问答的准确性，并且使用较少的视觉标记。


<details>
  <summary>Details</summary>
Motivation: 当前方法将整个文档视为基本检索单元，导致引入大量无关视觉内容，从而分散模型注意力，降低性能。现有的方法没有有效解决这个问题，因此需要一种新的方法来改善性能。

Method: 提出了一种新的框架RegionRAG，将检索粒度从文档级别转移到区域级别。通过设计基于有标签和无标签数据的混合监督策略来精确定位相关区域，并在推理阶段设计一个动态流水线将关键区域组合成完整的语义区域。

Result: RegionRAG在检索精度上提高了10.02%（R@1），问答准确性提高了3.56%，同时仅使用了71.42%的视觉标记，表明了该方法的有效性。实验结果表明，RegionRAG在六个基准上都达到了最先进的性能水平。

Conclusion: RegionRAG通过从文档级别转移到区域级别检索，有效减少了冗余和不相关的内容，提高了检索和问答的准确性和效率。

Abstract: Multi-modal Retrieval-Augmented Generation (RAG) has become a critical method
for empowering LLMs by leveraging candidate visual documents. However, current
methods consider the entire document as the basic retrieval unit, introducing
substantial irrelevant visual content in two ways: 1) Relevant documents often
contain large regions unrelated to the query, diluting the focus on salient
information; 2) Retrieving multiple documents to increase recall further
introduces redundant and irrelevant documents. These redundant contexts
distract the model's attention and further degrade the performance. To address
this challenge, we propose \modelname, a novel framework that shifts the
retrieval paradigm from the document level to the region level. During
training, we design a hybrid supervision strategy from both labeled data and
unlabeled data to pinpoint relevant patches. During inference, we propose a
dynamic pipeline that intelligently groups salient patches into complete
semantic regions. By delegating the task of identifying relevant regions to the
retriever, \modelname enables the generator to focus solely on concise visual
content relevant to queries, improving both efficiency and accuracy.
Experiments on six benchmarks demonstrate that RegionRAG achieves
state-of-the-art performance. Improves retrieval accuracy by 10.02\% in R@1 on
average and increases question answering accuracy by 3.56\% while using only
71.42\% visual tokens compared to prior methods. The code will be available at
https://github.com/Aeryn666/RegionRAG.

</details>


### [27] [T3: Test-Time Model Merging in VLMs for Zero-Shot Medical Imaging Analysis](https://arxiv.org/abs/2510.27265)
*Raza Imam,Hu Wang,Dwarikanath Mahapatra,Mohammad Yaqub*

Main category: cs.CV

TL;DR: 我们提出了Test-Time Task自适应融合(T^3)框架，通过计算两个模型输出分布之间的Jensen-Shannon散度来决定每个样本的插值系数，从而提高了医学影像中的模型适应性和精度。我们还提出了一种批处理扩展T^3_B，进一步降低了计算成本。实验表明，T^3在各种医学影像任务中均取得了更好的性能，且效率足够高，适合临床应用。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言模型在面对医学影像时面临着广义的鲁棒性和特定模态特性的矛盾，而现有的模型合并技术由于静态插值问题，在临床任务中表现不佳。为了解决这些问题，本文提出了新的自适应融合框架T^3。

Method: 提出了Test-Time Task自适应融合(T^3)框架，该框架通过计算每个样本两个模型输出分布的Jensen-Shannon散度来动态决定插值系数，从而在两个模型表现一致时保持局部精度，在模型偏离时依赖广义模型的鲁棒性。为了克服基于样本的融合所带来的计算瓶颈，我们还提出了批处理扩展T^3_B，解决了这一问题。同时还提出了一种标准化的医学模型合并基准。

Result: T^3在多项医学影像任务中均取得了更好的性能，具体表现为在Top-1准确率和错误率降低方面超越了传统的基线模型。T^3的批处理扩展T^3_B在保持优异性能的同时，计算成本较低。

Conclusion: 我们提出了测试时间任务自适应融合(T^3)框架，克服了现有模型在医学影像任务中的局限性，且能够适配不同的临床任务需求，并通过T^3_B解决计算瓶颈，使得该方法具备实用价值。

Abstract: In medical imaging, vision-language models face a critical duality:
pretrained networks offer broad robustness but lack subtle, modality-specific
characteristics, while fine-tuned expert models achieve high in-distribution
accuracy yet falter under modality shift. Existing model-merging techniques,
designed for natural-image benchmarks, are simple and efficient but fail to
deliver consistent gains across diverse medical modalities; their static
interpolation limits reliability in varied clinical tasks. To address this, we
introduce Test-Time Task adaptive merging (T^3), a backpropagation-free
framework that computes per-sample interpolation coefficients via the
Jensen-Shannon divergence between the two models' output distributions. T^3
dynamically preserves local precision when models agree and defers to
generalist robustness under drift. To overcome the inference costs of
sample-wise merging, we further propose a batch-wise extension, T^3_B, that
computes a merging coefficient across a batch of samples, dramatically reducing
computational bottleneck. Recognizing the lack of a standardized
medical-merging benchmark, we present a rigorous cross-evaluation protocol
spanning in-domain, base-to-novel, and corruptions across four modalities.
Empirically, T^3 sets new state-of-the-art in Top-1 accuracy and error
reduction, outperforming strong baselines while maintaining efficiency, paving
the way for adaptive MVLM deployment in clinical settings. Our code is
available at https://github.com/Razaimam45/TCube.

</details>


### [28] [HyperClick: Advancing Reliable GUI Grounding via Uncertainty Calibration](https://arxiv.org/abs/2510.27266)
*Shaojie Zhang,Pei Fu,Ruoceng Zhang,Jiahui Yang,Anan Du,Xiuwen Xi,Shaokang Wang,Ying Huang,Bin Qin,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: 论文提出了HyperClick框架，该框架通过不确定性校准提升可靠GUI定位，并采用二元奖励机制结合基于截断高斯的空间置信度模型进行校准。实验表明，HyperClick能够在多个基准测试上取得最佳性能并提供良好的置信度校准，从而降低过度自信并支持更可靠的GUI自动化。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI定位模型过度自信且预测不可靠，特别是在动态GUI自动化任务中单个错误可能导致任务失败。因此，需要一种能够校准置信度并减少过度自信的方法来提升GUI自动化可靠性。

Method: 提出了一种新的框架HyperClick，通过引入不确定性校准，并采用二元奖励机制结合基于截断高斯的空间置信度模型，进行置信度校准，采用Brier分数进行校准。这种方法同时优化了定位准确性和置信度可靠性，促进了自我反思与批判。

Result: 在七个挑战性基准测试上，HyperClick达到了最先进的性能并提供良好的置信度校准，这表明该方法能够减少过度自信并支持更可靠的GUI自动化。

Conclusion: HyperClick框架通过置信度校准和自我反思，减少了过度自信，支持了更可靠的GUI自动化。

Abstract: Autonomous Graphical User Interface (GUI) agents rely on accurate GUI
grounding, which maps language instructions to on-screen coordinates, to
execute user commands. However, current models, whether trained via supervised
fine-tuning (SFT) or reinforcement fine-tuning (RFT), lack self-awareness of
their capability boundaries, leading to overconfidence and unreliable
predictions. We first systematically evaluate probabilistic and verbalized
confidence in general and GUI-specific models, revealing a misalignment between
confidence and actual accuracy, which is particularly critical in dynamic GUI
automation tasks, where single errors can cause task failure. To address this,
we propose HyperClick, a novel framework that enhances reliable GUI grounding
through uncertainty calibration. HyperClick introduces a dual reward mechanism,
combining a binary reward for correct actions with a truncated Gaussian-based
spatial confidence modeling, calibrated using the Brier score. This approach
jointly optimizes grounding accuracy and confidence reliability, fostering
introspective self-criticism. Extensive experiments on seven challenge
benchmarks show that HyperClick achieves state-of-the-art performance while
providing well-calibrated confidence. By enabling explicit confidence
calibration and introspective self-criticism, HyperClick reduces overconfidence
and supports more reliable GUI automation.

</details>


### [29] [FOCUS: Efficient Keyframe Selection for Long Video Understanding](https://arxiv.org/abs/2510.27280)
*Zirui Zhu,Hailun Xu,Yang Luo,Yong Liu,Kanchan Sarkar,Zhenheng Yang,Yang You*

Main category: cs.CV

TL;DR: 本文提出了一种名为FOCUS的训练自由、模型无关的关键帧选择模块，它可以在严格的令牌预算下选择查询相关帧，从而在长视频理解方面取得显著的准确性提升，并减少处理的视频帧数。


<details>
  <summary>Details</summary>
Motivation: 面向长视频，现有关键帧选择方法在推理成本上的预过滤步骤可能会错过最具有信息量的瞬间，因此提出一种新的方法来解决这一问题，即FOCUS，以在严格的令牌预算下选择查询相关的帧，提高准确性，减少处理的视频帧数，从而支持多模态大型语言模型在长视频处理中的理解和应用能力。

Method: FOCUS将关键帧选择问题建模为多臂老虎机中的纯探索组合问题。它将短期时序片段视为每个臂，利用经验均值和伯纳尔斯坦置信边界来识别具有信息量的区域同时保持未确定区域的探索。这种方式简化了关键帧的选择流程，实现了在简化查询的条件下也能够保证理论上的性能保障。模型提出了阶段式的把握-探索过程，首先通过定位有价值的时间段，然后选出时间段内的词汇得分最高的帧作为最终结果。

Result: 在两个长视频问答基准测试上，FOCUS在只处理小部分视频帧的情况下，显著提高了准确性。特别是在20分钟以上的视频测试上，FOCUS在LongVideoBench上的准确率提升了11.9%，显示了其在选择关键帧上的有效性和为多模态大型语言模型提供长视频理解能力的支持。

Conclusion: 通过训练自由、模型无关的关键帧选择方法，FOCUS在长视频理解和问答上展示了其优势，不仅减少了计算负荷而且提高了准确性，为使用多模态大型语言模型处理长视频提供了简单且有效的解决方案。

Abstract: Multimodal large language models (MLLMs) represent images and video frames as
visual tokens. Scaling from single images to hour-long videos, however,
inflates the token budget far beyond practical limits. Popular pipelines
therefore either uniformly subsample or apply keyframe selection with
retrieval-style scoring using smaller vision-language models. However, these
keyframe selection methods still rely on pre-filtering before selection to
reduce the inference cost and can miss the most informative moments.
  We propose FOCUS, Frame-Optimistic Confidence Upper-bound Selection, a
training-free, model-agnostic keyframe selection module that selects
query-relevant frames under a strict token budget. FOCUS formulates keyframe
selection as a combinatorial pure-exploration (CPE) problem in multi-armed
bandits: it treats short temporal clips as arms, and uses empirical means and
Bernstein confidence radius to identify informative regions while preserving
exploration of uncertain areas. The resulting two-stage
exploration-exploitation procedure reduces from a sequential policy with
theoretical guarantees, first identifying high-value temporal regions, then
selecting top-scoring frames within each region On two long-video
question-answering benchmarks, FOCUS delivers substantial accuracy improvements
while processing less than 2% of video frames. For videos longer than 20
minutes, it achieves an 11.9% gain in accuracy on LongVideoBench, demonstrating
its effectiveness as a keyframe selection method and providing a simple and
general solution for scalable long-video understanding with MLLMs.

</details>


### [30] [Rethinking Robust Adversarial Concept Erasure in Diffusion Models](https://arxiv.org/abs/2510.27285)
*Qinghong Yin,Yu Tian,Yue Zhang*

Main category: cs.CV

TL;DR: 提出了S-GRACE方法，通过语义引导来生成对抗样本，对扩散模型中的不需要的概念进行删除，提高了删除性能，同时保持了非目标概念，并减少了训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有方法在扩散模型中使用对抗训练进行概念抹除时，忽视了对抗样本生成过程中的概念语义，导致效果不佳，提出S-GRACE以此改进。

Method: S-GRACE通过在概念空间中引入语义引导来生成对抗样本，从而实现更有效的概念抹除训练。

Result: 实验显示S-GRACE在多种场景中提高了26%的删除性能，并减少90%的训练时间。

Conclusion: S-GRACE通过语义引导生成的对抗样本提高了扩散模型中概念抹除的效果，同时保持了模型的非目标概念特性。

Abstract: Concept erasure aims to selectively unlearning undesirable content in
diffusion models (DMs) to reduce the risk of sensitive content generation. As a
novel paradigm in concept erasure, most existing methods employ adversarial
training to identify and suppress target concepts, thus reducing the likelihood
of sensitive outputs. However, these methods often neglect the specificity of
adversarial training in DMs, resulting in only partial mitigation. In this
work, we investigate and quantify this specificity from the perspective of
concept space, i.e., can adversarial samples truly fit the target concept
space? We observe that existing methods neglect the role of conceptual
semantics when generating adversarial samples, resulting in ineffective fitting
of concept spaces. This oversight leads to the following issues: 1) when there
are few adversarial samples, they fail to comprehensively cover the object
concept; 2) conversely, they will disrupt other target concept spaces.
Motivated by the analysis of these findings, we introduce S-GRACE
(Semantics-Guided Robust Adversarial Concept Erasure), which grace leveraging
semantic guidance within the concept space to generate adversarial samples and
perform erasure training. Experiments conducted with seven state-of-the-art
methods and three adversarial prompt generation strategies across various DM
unlearning scenarios demonstrate that S-GRACE significantly improves erasure
performance 26%, better preserves non-target concepts, and reduces training
time by 90%. Our code is available at https://github.com/Qhong-522/S-GRACE.

</details>


### [31] [SAGS: Self-Adaptive Alias-Free Gaussian Splatting for Dynamic Surgical Endoscopic Reconstruction](https://arxiv.org/abs/2510.27318)
*Wenfeng Huang,Xiangyun Liao,Yinling Qian,Hao Liu,Yongming Yang,Wenjing Jia,Qiong Wang*

Main category: cs.CV

TL;DR: 提出了SAGS框架，通过引入注意力驱动的动态加权4D形变解码器和使用3D平滑滤波器以及2D Mip滤波器来改善动态组织的重建问题，提高了可视化质量和重建效率，实验结果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有技术中由于组织移动导致的别名效应和伪影，提高机器人辅助手术中动态组织重建的质量和效率。

Method: 提出了实时适应无别名高斯点阵框架（SAGS），采用注意力驱动的动态加权4D形变解码器，并利用3D平滑滤波器和2D Mip滤波器来减少变形组织重建中的伪影，从而更好地捕捉组织运动的细节。

Result: 实验结果表明，在PSNR、SSIM和LPIPS所有指标上，我们的方法优于现有的最先进技术，同时提供了更好的可视化质量。

Conclusion: SAGS框架通过改进现有的3DGS方法，减少了别名效应和伪影，提升了重建质量，并且保持了高效的渲染能力。

Abstract: Surgical reconstruction of dynamic tissues from endoscopic videos is a
crucial technology in robot-assisted surgery. The development of Neural
Radiance Fields (NeRFs) has greatly advanced deformable tissue reconstruction,
achieving high-quality results from video and image sequences. However,
reconstructing deformable endoscopic scenes remains challenging due to aliasing
and artifacts caused by tissue movement, which can significantly degrade
visualization quality. The introduction of 3D Gaussian Splatting (3DGS) has
improved reconstruction efficiency by enabling a faster rendering pipeline.
Nevertheless, existing 3DGS methods often prioritize rendering speed while
neglecting these critical issues. To address these challenges, we propose SAGS,
a self-adaptive alias-free Gaussian splatting framework. We introduce an
attention-driven, dynamically weighted 4D deformation decoder, leveraging 3D
smoothing filters and 2D Mip filters to mitigate artifacts in deformable tissue
reconstruction and better capture the fine details of tissue movement.
Experimental results on two public benchmarks, EndoNeRF and SCARED, demonstrate
that our method achieves superior performance in all metrics of PSNR, SSIM, and
LPIPS compared to the state of the art while also delivering better
visualization quality.

</details>


### [32] [Generative Semantic Coding for Ultra-Low Bitrate Visual Communication and Analysis](https://arxiv.org/abs/2510.27324)
*Weiming Chen,Yijia Wang,Zhihan Zhu,Zhihai He*

Main category: cs.CV

TL;DR: 此论文研究在极低带宽条件下，如何准确重建视觉场景。通过整合图像生成和深图像压缩，使用语义文本描述和编码潜在变量引导修正流模型，以期达到精度高且带宽消耗少的目标。实验结果表明，该方法可以在使用更少带宽的情况下，实现与现有方法相同的质量和视觉分析准确性。


<details>
  <summary>Details</summary>
Motivation: 论文旨在解决在极低带宽条件下，如何准确且有效地进行视觉通信、视觉分析和人类互动的问题，特别是在深空探索、战场情报和复杂环境中的机器人导航等场景中。现有的文本到图像生成模型可以实现视觉场景的语义级近似，但对于视觉通信和远程视觉分析来说，这种水平的近似是远远不够的。因此需要一种更好的解决方案来达到这一目标，并减少带宽消耗。

Method: 论文提出了一种将图像生成与深度图像压缩无缝整合的方法。通过使用语义文本描述和编码潜在变量引导修正流模型，从而实现对于视觉场景的精确生成。语义文本描述和编码潜在变量都将被编码并以极低的比特率发送到解码器端。这种方法结合了图像生成和深度图像压缩的优点，同时解决了现有文本到图像生成模型所带来的带宽问题。

Result: 实验结果显示，该方法能够在使用更少带宽的情况下，实现与现有方法相同的图像重建质量和视觉分析准确性。这表明该方法能够有效地减少带宽需求，同时保持高质量的视觉通信和视觉分析。

Conclusion: 论文提出了一种新的方法，用于在极低带宽条件下精确重建视觉场景。该方法通过将文本描述和深度学习的潜在变量结合，并将其应用于图像生成，从而使得图像的重建质量未受到影响的同时极大地降低了带宽需求。

Abstract: We consider the problem of ultra-low bit rate visual communication for remote
vision analysis, human interactions and control in challenging scenarios with
very low communication bandwidth, such as deep space exploration, battlefield
intelligence, and robot navigation in complex environments. In this paper, we
ask the following important question: can we accurately reconstruct the visual
scene using only a very small portion of the bit rate in existing coding
methods while not sacrificing the accuracy of vision analysis and performance
of human interactions? Existing text-to-image generation models offer a new
approach for ultra-low bitrate image description. However, they can only
achieve a semantic-level approximation of the visual scene, which is far
insufficient for the purpose of visual communication and remote vision analysis
and human interactions. To address this important issue, we propose to
seamlessly integrate image generation with deep image compression, using joint
text and coding latent to guide the rectified flow models for precise
generation of the visual scene. The semantic text description and coding latent
are both encoded and transmitted to the decoder at a very small bit rate.
Experimental results demonstrate that our method can achieve the same image
reconstruction quality and vision analysis accuracy as existing methods while
using much less bandwidth. The code will be released upon paper acceptance.

</details>


### [33] [MeisenMeister: A Simple Two Stage Pipeline for Breast Cancer Classification on MRI](https://arxiv.org/abs/2510.27326)
*Benjamin Hamm,Yannick Kirchhoff,Maximilian Rokuss,Klaus Maier-Hein*

Main category: cs.CV

TL;DR: 本文介绍了针对ODELIA乳腺MRI挑战赛的解决方案，重点开发了用于早期乳腺癌检测的稳健的分类方法。我们披露了我们的方法，从概念到实验过程，最终提交的设计依据。我们的实现已公开在GitHub上。


<details>
  <summary>Details</summary>
Motivation: 尽管存在通用的全身病灶分割方法以及多时间点分析方法，但乳腺癌检测依然具挑战性。缺乏高质量的分割标签是主要原因，因此需要开发稳健的分类方法支持早期乳腺癌检测。

Method: 方法从概念、基本假设和迭代开发过程进行详细说明。包括实验、评估和优化的步骤，以开发稳健有效的乳腺MRI筛查解决方案。

Result: 我们提交的成果具备高性能、鲁棒性和临床相关性，能够满足早期乳腺癌检测的需求。

Conclusion: 公开了我们的解决方案，强调了在大型筛查应用中开发稳健分类方法的重要性，以促进早期乳腺癌检测，提高患者生存率。

Abstract: The ODELIA Breast MRI Challenge 2025 addresses a critical issue in breast
cancer screening: improving early detection through more efficient and accurate
interpretation of breast MRI scans. Even though methods for general-purpose
whole-body lesion segmentation as well as multi-time-point analysis exist,
breast cancer detection remains highly challenging, largely due to the limited
availability of high-quality segmentation labels. Therefore, developing robust
classification-based approaches is crucial for the future of early breast
cancer detection, particularly in applications such as large-scale screening.
In this write-up, we provide a comprehensive overview of our approach to the
challenge. We begin by detailing the underlying concept and foundational
assumptions that guided our work. We then describe the iterative development
process, highlighting the key stages of experimentation, evaluation, and
refinement that shaped the evolution of our solution. Finally, we present the
reasoning and evidence that informed the design choices behind our final
submission, with a focus on performance, robustness, and clinical relevance. We
release our full implementation publicly at
https://github.com/MIC-DKFZ/MeisenMeister

</details>


### [34] [Understanding the Implicit User Intention via Reasoning with Large Language Model for Image Editing](https://arxiv.org/abs/2510.27335)
*Yijia Wang,Yiqing Shen,Weiming Chen,Zhihai He*

Main category: cs.CV

TL;DR: 提出了一种新方法CIELR，通过将复杂指令转换为简单明确的操作来简化复杂图像编辑，无需联合微调大语言模型和扩散模型，提高了编辑质量和效率。实验表明该方法在PSNR上优于SOTA方法9.955dB。同时，构建了CIEBench基准来评估基于推理的图像编辑方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑方法难以处理复杂的编辑指令，通常需要联合微调大语言模型和扩散模型，耗时耗资源。为了降低复杂度和成本，提高编辑效果，提出了CIELR方法。

Method: CIELR方法首先构造输入图像的结构化语义表示，然后采用迭代更新机制逐步细化表示，最后执行复杂灵活的图像编辑任务。具体包括构建基础模型，引入迭代更新机制，生成细粒度的视觉表示。

Result: 实验结果显示，CIELR方法在PSNR指标下优于SOTA方法9.955dB，表现出更优的保持一致区域的效果。此外，CIELR方法在新构建的CIEBench基准上也优于其他方法。

Conclusion: CIELR方法通过将复杂指令转换为简单操作，减少了联合微调的复杂度和成本，从而提高了图像编辑的效率和质量。同时，通过构建CIEBench基准，为后续研究提供了参考。

Abstract: Existing image editing methods can handle simple editing instructions very
well. To deal with complex editing instructions, they often need to jointly
fine-tune the large language models (LLMs) and diffusion models (DMs), which
involves very high computational complexity and training cost. To address this
issue, we propose a new method, called \textbf{C}omplex \textbf{I}mage
\textbf{E}diting via \textbf{L}LM \textbf{R}easoning (CIELR), which converts a
complex user instruction into a set of simple and explicit editing actions,
eliminating the need for jointly fine-tuning the large language models and
diffusion models. Specifically, we first construct a structured semantic
representation of the input image using foundation models. Then, we introduce
an iterative update mechanism that can progressively refine this
representation, obtaining a fine-grained visual representation of the image
scene. This allows us to perform complex and flexible image editing tasks.
Extensive experiments on the SmartEdit Reasoning Scenario Set show that our
method surpasses the previous state-of-the-art by 9.955 dB in PSNR, indicating
its superior preservation of regions that should remain consistent. Due to the
limited number of samples of public datasets of complex image editing with
reasoning, we construct a benchmark named CIEBench, containing 86 image
samples, together with a metric specifically for reasoning-based image editing.
CIELR also outperforms previous methods on this benchmark. The code and dataset
are available at
\href{https://github.com/Jia-shao/Reasoning-Editing}{https://github.com/Jia-shao/Reasoning-Editing}.

</details>


### [35] [RzenEmbed: Towards Comprehensive Multimodal Retrieval](https://arxiv.org/abs/2510.27350)
*Weijian Jian,Yajun Zhang,Dawei Liang,Chunyu Xie,Yixiao He,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: RzenEmbed 是一个新的统一框架，用于学习不同模态（如文本、图像、视频和视觉文档）的嵌入表示。它采用了一个两阶段的训练策略以及改进的 InfoNCE 损失函数，提高了模型的判别能力和指令跟随能力，并在 MMEB 基准测试中取得了最优成绩，特别是在视频和视觉文档检索任务上表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要针对自然图像，在其他重要的视觉模态（如视频和视觉文档）上支持有限。因此，提出 RzenEmbed 来填补这一空白，学习不同模态的嵌入表示。

Method: RzenEmbed 采用了一个两阶段的训练策略。第一阶段专注于基础的文本和多模态检索，第二阶段引入了改进的 InfoNCE 损失函数，通过权重机制优先考虑困难样本，并减小假阴性的影响和数据噪声。此外，还通过可学习的温度参数和模型汇总的方法来提升性能。

Result: RzenEmbed 在 MMEB 基准测试中取得了最优成绩，不仅整体得分最高，还在视频和视觉文档检索任务上超越了所有之前的工作。

Conclusion: RzenEmbed 成功地提高了多模态嵌入的学习能力，尤其是对视频和视觉文档的处理效果更为显著，从而设立了新的性能标准。

Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has
extended CLIP-based frameworks to produce powerful, universal embeddings for
retrieval tasks. However, existing methods primarily focus on natural images,
offering limited support for other crucial visual modalities such as videos and
visual documents. To bridge this gap, we introduce RzenEmbed, a unified
framework to learn embeddings across a diverse set of modalities, including
text, images, videos, and visual documents. We employ a novel two-stage
training strategy to learn discriminative representations. The first stage
focuses on foundational text and multimodal retrieval. In the second stage, we
introduce an improved InfoNCE loss, incorporating two key enhancements.
Firstly, a hardness-weighted mechanism guides the model to prioritize
challenging samples by assigning them higher weights within each batch.
Secondly, we implement an approach to mitigate the impact of false negatives
and alleviate data noise. This strategy not only enhances the model's
discriminative power but also improves its instruction-following capabilities.
We further boost performance with learnable temperature parameter and model
souping. RzenEmbed sets a new state-of-the-art on the MMEB benchmark. It not
only achieves the best overall score but also outperforms all prior work on the
challenging video and visual document retrieval tasks. Our models are available
in https://huggingface.co/qihoo360/RzenEmbed.

</details>


### [36] [FPS: Feedforward-based Parameter Selection For Efficient Fine-Tuning](https://arxiv.org/abs/2510.27359)
*Kenneth Yang,Wen-Li Wei,Jen-Chun Lin*

Main category: cs.CV

TL;DR: 提出了一种基于前馈的选择参数法 FPS，能在单次前向传递中选择最优参数子集，减少内存使用并加速参数选择，提高大规模预训练模型的微调效率。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调策略存在推理延迟、工程复杂度和峰值内存使用率高等问题，因此提出一种新方法以解决这些问题。

Method: 通过计算参数大小与相应输入激活的乘积来排名参数，以选出最优参数子集，此方法不依赖梯度且只需单次前向传递。

Result: FPS 方法在视觉任务上取得与现有最佳方法相当的性能，同时峰值内存使用减少了近 9 倍，参数选择速度提升了约 2 倍。

Conclusion: FPS 方法提供了一种内存高效且实用的大规模预训练模型微调解决方案。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) has emerged as a key strategy for
adapting large-scale pre-trained models to downstream tasks, but existing
approaches face notable limitations. Addition-based methods, such as Adapters
[1], introduce inference latency and engineering complexity, while
selection-based methods like Gradient-based Parameter Selection (GPS) [2]
require a full backward pass, which results in the same peak memory usage as
full fine-tuning. To address this dilemma, we propose Feedforward-based
Parameter Selection (FPS), a gradient-free method that identifies an optimal
parameter subset in a single forward pass. FPS ranks parameters by the product
of their magnitudes and corresponding input activations, leveraging both
pre-trained knowledge and downstream data. Evaluated on $24$ visual tasks from
FGVC and VTAB-1k, FPS achieves performance comparable to state-of-the-art
methods while reducing peak memory usage by nearly $9 \times$ and accelerating
parameter selection by about $2 \times$, offering a genuinely memory-efficient
and practical solution for fine-tuning large-scale pre-trained models.

</details>


### [37] [Fine-Tuning Open Video Generators for Cinematic Scene Synthesis: A Small-Data Pipeline with LoRA and Wan2.1 I2V](https://arxiv.org/abs/2510.27364)
*Meftun Akarsu,Kerem Catay,Sedat Bin Vedat,Enes Kutay Yarkan,Ilke Senturk,Arda Sar,Dafne Eksioglu*

Main category: cs.CV

TL;DR: 本文提出了一种从小数据集精细调整开源视频扩散变压器的实用流水线，用于合成电视和电影制作中的电影场景。该方法将视觉风格学习和运动生成解耦，在第二阶段中，通过模型的视频解码器将关键帧扩展成连贯的720p序列，提升了电影的真实感和时间稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了提高从少量视频数据合成电影场景的能力，减少训练时间和提高效果。

Method: 第一阶段使用LoRA模块在交叉注意力层中调整视觉表示；第二阶段生成关键帧并通过视频解码器扩展为连贯序列，同时采用轻量级并行化和序列分区策略加速推理。

Result: 实验结果表明，与基础模型相比，该方法在电影真实感和时间稳定性方面有了显著提高。

Conclusion: 该方法能够在短时间内获得高质量的电影场景合成效果，为其他领域应用提供了可重复性支持。

Abstract: We present a practical pipeline for fine-tuning open-source video diffusion
transformers to synthesize cinematic scenes for television and film production
from small datasets. The proposed two-stage process decouples visual style
learning from motion generation. In the first stage, Low-Rank Adaptation (LoRA)
modules are integrated into the cross-attention layers of the Wan2.1 I2V-14B
model to adapt its visual representations using a compact dataset of short
clips from Ay Yapim's historical television film El Turco. This enables
efficient domain transfer within hours on a single GPU. In the second stage,
the fine-tuned model produces stylistically consistent keyframes that preserve
costume, lighting, and color grading, which are then temporally expanded into
coherent 720p sequences through the model's video decoder. We further apply
lightweight parallelization and sequence partitioning strategies to accelerate
inference without quality degradation. Quantitative and qualitative evaluations
using FVD, CLIP-SIM, and LPIPS metrics, supported by a small expert user study,
demonstrate measurable improvements in cinematic fidelity and temporal
stability over the base model. The complete training and inference pipeline is
released to support reproducibility and adaptation across cinematic domains.

</details>


### [38] [Modality Alignment across Trees on Heterogeneous Hyperbolic Manifolds](https://arxiv.org/abs/2510.27391)
*Wu Wei,Xiaomeng Fan,Yuwei Wu,Zhi Gao,Pengxiang Li,Yunde Jia,Mehrtash Harandi*

Main category: cs.CV

TL;DR: 提出了一种跨树对齐的方法，通过构建并对齐图像和文本模态的树状层次特征，来解决现有模型在模态对齐上的不对称性和次优性问题。该方法在分类任务中表现出色，尤其是在少量数据和跨领域设置下。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理视觉和语言信息时存在模态不对称和次优对齐问题，因此本文提出了一种能构建图像和文本模态之间的树状层次特征对齐的方法，以解决这些问题。

Method: 方法包括了一个基于跨注意力机制的视觉特征提取框架，利用文本线索帮助提取带有细粒度语义的视觉特征；然后将两模态的特征树嵌入到具有不同曲率的双曲几何空间中，并通过最小化分布在异构流形上的KL距离来对齐不同流形上的数据，同时证明了最优中间流形的存在性和唯一性。

Result: 实验结果表明，该方法在不同图像数据集上的分类任务中，特别是在小样本和跨域设置下，优于许多强大的基线方法。具体来说，这证明了所提方法在处理异构数据集上的有效性和优越性。

Conclusion: 通过对图像和文本模态构建并对齐树状层次特征，解决了现有方法中的模态不对称和次优对齐问题，并实验证明了其在多个图像数据集上的优越性。

Abstract: Modality alignment is critical for vision-language models (VLMs) to
effectively integrate information across modalities. However, existing methods
extract hierarchical features from text while representing each image with a
single feature, leading to asymmetric and suboptimal alignment. To address
this, we propose Alignment across Trees, a method that constructs and aligns
tree-like hierarchical features for both image and text modalities.
Specifically, we introduce a semantic-aware visual feature extraction framework
that applies a cross-attention mechanism to visual class tokens from
intermediate Transformer layers, guided by textual cues to extract visual
features with coarse-to-fine semantics. We then embed the feature trees of the
two modalities into hyperbolic manifolds with distinct curvatures to
effectively model their hierarchical structures. To align across the
heterogeneous hyperbolic manifolds with different curvatures, we formulate a KL
distance measure between distributions on heterogeneous manifolds, and learn an
intermediate manifold for manifold alignment by minimizing the distance. We
prove the existence and uniqueness of the optimal intermediate manifold.
Experiments on taxonomic open-set classification tasks across multiple image
datasets demonstrate that our method consistently outperforms strong baselines
under few-shot and cross-domain settings.

</details>


### [39] [A Hybrid Deep Learning and Forensic Approach for Robust Deepfake Detection](https://arxiv.org/abs/2510.27392)
*Sales Aribe Jr*

Main category: cs.CV

TL;DR: 论文提出了一种结合了深度学习和取证分析的混合框架来检测deepfake，大幅提高了现有方法的性能和解释性。


<details>
  <summary>Details</summary>
Motivation: 现有deepfake检测方法存在局限性，要么依赖深度学习，缺乏泛化能力且容易受干扰，要么使用取证分析，但对新操纵技术的对抗性较弱。提出一种结合了深度学习和取证分析的混合框架以克服这些局限性。

Method: 融合了深度学习表示（从CNN和Vision Transformers中获取）和取证特征（如噪声残差、JPEG压缩痕迹和频域描述符）。

Result: 在FaceForensics++、Celeb-DF v2和DFDC数据集上，该模型优于单一方法基准线和其他现有混合方法，F1分数分别为0.96、0.82和0.77，并且在压缩、对抗干扰和未见过的操纵情况下仍保持稳定性能。

Conclusion: 该研究表明混合方法提供了一种平衡的解决方案，通过结合深度模型的适应性和取证线索的可解释性，能够开发出更加稳健和可信任的deepfake检测系统。

Abstract: The rapid evolution of generative adversarial networks (GANs) and diffusion
models has made synthetic media increasingly realistic, raising societal
concerns around misinformation, identity fraud, and digital trust. Existing
deepfake detection methods either rely on deep learning, which suffers from
poor generalization and vulnerability to distortions, or forensic analysis,
which is interpretable but limited against new manipulation techniques. This
study proposes a hybrid framework that fuses forensic features, including noise
residuals, JPEG compression traces, and frequency-domain descriptors, with deep
learning representations from convolutional neural networks (CNNs) and vision
transformers (ViTs). Evaluated on benchmark datasets (FaceForensics++, Celeb-DF
v2, DFDC), the proposed model consistently outperformed single-method baselines
and demonstrated superior performance compared to existing state-of-the-art
hybrid approaches, achieving F1-scores of 0.96, 0.82, and 0.77, respectively.
Robustness tests demonstrated stable performance under compression (F1 = 0.87
at QF = 50), adversarial perturbations (AUC = 0.84), and unseen manipulations
(F1 = 0.79). Importantly, explainability analysis showed that Grad-CAM and
forensic heatmaps overlapped with ground-truth manipulated regions in 82
percent of cases, enhancing transparency and user trust. These findings confirm
that hybrid approaches provide a balanced solution, combining the adaptability
of deep models with the interpretability of forensic cues, to develop resilient
and trustworthy deepfake detection systems.

</details>


### [40] [Mitigating Semantic Collapse in Partially Relevant Video Retrieval](https://arxiv.org/abs/2510.27432)
*WonJun Moon,MinSeok Jung,Gilhan Park,Tae-Young Kim,Cheol-Ho Cho,Woojin Jun,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法来解决部分相关视频检索中的语义塌陷问题，通过保持文本查询的语义关系和解耦不同时间尺度的视频表示来提高检索精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理部分相关视频检索时会将每个注释的文本-视频对都看作是正样本，并忽略视频内部和视频之间的丰富语义变化，导致检索性能受限。本文旨在解决这一问题，提高检索精度。

Method: 提出文本相关保持学习和跨分支视频对齐（CBVA）两种方法来解决语义塌陷问题。其中，文本相关保持学习保持了基础模型编码的文本查询的语义关系；跨分支视频对齐方法解耦不同时间尺度上的视频表示，进一步通过内部一致但相互区分的视频片段增强对齐。

Result: 实验结果表明，该框架可以有效防止语义塌陷，大幅提高检索准确性。

Conclusion: 本文提出了一种新颖的解决方案来改进部分相关视频检索中的语义塌陷问题，通过引入新的学习和对齐方法，显著提高了检索精度。

Abstract: Partially Relevant Video Retrieval (PRVR) seeks videos where only part of the
content matches a text query. Existing methods treat every annotated text-video
pair as a positive and all others as negatives, ignoring the rich semantic
variation both within a single video and across different videos. Consequently,
embeddings of both queries and their corresponding video-clip segments for
distinct events within the same video collapse together, while embeddings of
semantically similar queries and segments from different videos are driven
apart. This limits retrieval performance when videos contain multiple, diverse
events. This paper addresses the aforementioned problems, termed as semantic
collapse, in both the text and video embedding spaces. We first introduce Text
Correlation Preservation Learning, which preserves the semantic relationships
encoded by the foundation model across text queries. To address collapse in
video embeddings, we propose Cross-Branch Video Alignment (CBVA), a contrastive
alignment method that disentangles hierarchical video representations across
temporal scales. Subsequently, we introduce order-preserving token merging and
adaptive CBVA to enhance alignment by producing video segments that are
internally coherent yet mutually distinctive. Extensive experiments on PRVR
benchmarks demonstrate that our framework effectively prevents semantic
collapse and substantially improves retrieval accuracy.

</details>


### [41] [CoMViT: An Efficient Vision Backbone for Supervised Classification in Medical Imaging](https://arxiv.org/abs/2510.27442)
*Aon Safdar,Mohamed Saadeldin*

Main category: cs.CV

TL;DR: CoMViT 是一种紧凑且通用的视觉Transformer架构，专门用于资源受限的医学图像分析。它通过集成卷积编码器、对角线掩码、动态温度缩放和基于池化的序列聚合来提高性能和泛化能力。实验表明，CoMViT在保持轻量级设计的同时，在十二个MedMNIST数据集上取得了稳健的性能，相较于更深的CNN和ViT变体，CoMViT最多可减少5-20倍的参数，而不会牺牲准确性。此外，它能稳定地关注到临床相关的区域，展示出设计有效的Transformer模型在低资源医学成像应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision Transformers高昂的计算需求和在小数据集上的过拟合问题限制了其在实际临床场景中的应用。因此，开发出一种轻量、高效并且泛化能力强的模型成为了研究的焦点，特别是在资源受限的医学图像分析领域。CoMViT的动机就是针对这些问题，提供一个资源高效的医学图像分析解决方案。

Method: CoMViT整合了卷积编码器、对角线掩码、动态温度控制以及池化为基础的序列聚合等技术，优化了模型的设计，以提高其在资源受限条件下的性能和泛化能力。

Result: 实验结果显示，CoMViT在十二个MedMNIST数据集上取得了良好的性能，同时实现了模型参数量的大幅减少，可达5-20倍。此外，定性的Grad-CAM分析显示，CoMViT能够稳定地聚焦在医学图像中重要的诊断区域，展示了其在低资源医学图像分析上的潜力。

Conclusion: CoMViT通过采用一种系统性优化的架构设计，不仅提高了模型的性能和泛化能力，还大幅度减少了计算资源的需求。它在保持高效和准确的同时，也提高了模型的解释性，这对于实际应用中的医学图像分析尤其重要，尤其是资源受限的场景。

Abstract: Vision Transformers (ViTs) have demonstrated strong potential in medical
imaging; however, their high computational demands and tendency to overfit on
small datasets limit their applicability in real-world clinical scenarios. In
this paper, we present CoMViT, a compact and generalizable Vision Transformer
architecture optimized for resource-constrained medical image analysis. CoMViT
integrates a convolutional tokenizer, diagonal masking, dynamic temperature
scaling, and pooling-based sequence aggregation to improve performance and
generalization. Through systematic architectural optimization, CoMViT achieves
robust performance across twelve MedMNIST datasets while maintaining a
lightweight design with only ~4.5M parameters. It matches or outperforms deeper
CNN and ViT variants, offering up to 5-20x parameter reduction without
sacrificing accuracy. Qualitative Grad-CAM analyses show that CoMViT
consistently attends to clinically relevant regions despite its compact size.
These results highlight the potential of principled ViT redesign for developing
efficient and interpretable models in low-resource medical imaging settings.

</details>


### [42] [A Multi-tiered Human-in-the-loop Approach for Interactive School Mapping Using Earth Observation and Machine Learning](https://arxiv.org/abs/2510.27460)
*Casper Fibaek,Abi Riley,Kelsey Doerksen,Do-Hyung Kim,Rochelle Schneider*

Main category: cs.CV

TL;DR: 本论文提出一个多层级人机交互框架，用于对学校进行地图绘制，以提高教育设施记录的准确性和完整性，特别是在数据可能稀缺和更新不频繁的发展中地区。该框架通过机器学习分析人口密度、土地覆盖和现有基础设施，结合已知学校位置来识别潜在的空白和误标学校。后续层级使用中分辨率（Sentinel-2）和高分辨率卫星图像以及深度学习模型来生成详细的候选学校位置。最终还设计了一个交互式界面，使得操作员能够迭代地审查、验证和细化地图绘制结果。初步评估表明，多层级策略为教育基础设施地图绘制提供了可扩展且成本效益较高的解决方案，以支持规划和资源分配。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在提出一种改进教育设施记录准确性和完整性的方法，特别是在数据稀缺和更新不频繁的发展中地区。提出一个综合机器学习和深度学习的人机交互框架。

Method: 该论文采用多层级的方法，从机器学习分析人口密度、土地覆盖与现有基础设施开始。接着使用中分辨率卫星图像来评估学校存在的可能性，然后使用高分辨率图像和深度学习模型来绘制详细的地图。最后，设计一个交互式界面，允许操作人员审查、验证和细化结果。中分辨率卫星图像后来被移除，因为它没有带来显著的改进。

Result: 该框架通过结合机器学习和深度学习方法，对教育设施的地理位置进行了更加准确和详尽的定位。通过初步评估，该框架在准确性和成本效益之间取得了良好的平衡。与现有方法相比，这种方法表现出色，并且具有更广泛的适用性和可扩展性。

Conclusion: 多层级的人机交互框架为教育设施地图绘制提供了一种高效且成本效益高的解决方案，支持教育规划和资源分配。尽管中分辨率卫星图像被移除，但该框架仍有显著的改进，可以进一步推广和应用。

Abstract: This paper presents a multi-tiered human-in-the-loop framework for
interactive school mapping designed to improve the accuracy and completeness of
educational facility records, particularly in developing regions where such
data may be scarce and infrequently updated. The first tier involves a machine
learning based analysis of population density, land cover, and existing
infrastructure compared with known school locations. The first tier identifies
potential gaps and "mislabelled" schools. In subsequent tiers,
medium-resolution satellite imagery (Sentinel-2) is investigated to pinpoint
regions with a high likelihood of school presence, followed by the application
of very high-resolution (VHR) imagery and deep learning models to generate
detailed candidate locations for schools within these prioritised areas. The
medium-resolution approach was later removed due to insignificant improvements.
The medium and VHR resolution models build upon global pre-trained steps to
improve generalisation. A key component of the proposed approach is an
interactive interface to allow human operators to iteratively review, validate,
and refine the mapping results. Preliminary evaluations indicate that the
multi-tiered strategy provides a scalable and cost-effective solution for
educational infrastructure mapping to support planning and resource allocation.

</details>


### [43] [Referee: Reference-aware Audiovisual Deepfake Detection](https://arxiv.org/abs/2510.27475)
*Hyemin Boo,Eunsang Lee,Jiyoung Lee*

Main category: cs.CV

TL;DR: 提出了一种新的参考aware的音视频deepfake检测方法Referee，通过一个样本的提示来检测超出了时空残差的操纵，通过匹配和对齐参考和目标内容中的身份相关的查询到跨模态特征，实现了音视觉同步和身份一致性。实验表明，Referee在跨越数据集和跨语言的评价协议中取得了最先进的性能。强调了跨模态身份验证对未来deepfake检测的重要性。代码可在https://github.com/ewha-mmai/referee获取。


<details>
  <summary>Details</summary>
Motivation: 现有的音视频Deepfake检测方法在面对未见过的伪造物时效果有限，尤其是当伪造物产生严重的威胁时。现有的方法无法很好地泛化到新的伪造物。因此，提出了一种新的方法以解决这个问题，并提高检测未见过的伪造物的能力。

Method: 提出了一个参考aware的音视频Deepfake检测方法（Referee），通过只使用一份样本的提醒来检测超出时、空异常的操纵行为。通过匹配和调整参考和目标内容中的身份相关查询以获得跨模式特征，Referee共同解析有关音频-视频同步性和识别一致性的结果。

Result: 实验结果表明，Referee在跨越数据集和跨语言的评估协议上达到了最先进的性能，证明了跨模式身份验证对未来音视频伪造检测的重要性。

Conclusion: 这种方法通过跨模式身份验证强调了音视频同步性的重要性，有望在未来为音视频伪造检测提供新的解决方案。

Abstract: Since deepfakes generated by advanced generative models have rapidly posed
serious threats, existing audiovisual deepfake detection approaches struggle to
generalize to unseen forgeries. We propose a novel reference-aware audiovisual
deepfake detection method, called Referee. Speaker-specific cues from only
one-shot examples are leveraged to detect manipulations beyond spatiotemporal
artifacts. By matching and aligning identity-related queries from reference and
target content into cross-modal features, Referee jointly reasons about
audiovisual synchrony and identity consistency. Extensive experiments on
FakeAVCeleb, FaceForensics++, and KoDF demonstrate that Referee achieves
state-of-the-art performance on cross-dataset and cross-language evaluation
protocols. Experimental results highlight the importance of cross-modal
identity verification for future deepfake detection. The code is available at
https://github.com/ewha-mmai/referee.

</details>


### [44] [NAUTILUS: A Large Multimodal Model for Underwater Scene Understanding](https://arxiv.org/abs/2510.27481)
*Wei Xu,Cheng Wang,Dingkang Liang,Zongchuang Zhao,Xingyu Jiang,Peng Zhang,Xiang Bai*

Main category: cs.CV

TL;DR: 该论文提出了一个新的用于水下场景理解的大型多任务实例调优数据集NautData，并开发了一种可插拔视觉特征增强模块（VFE），以此来提高传统基线模型在水下场景理解任务上的性能。该增强模块能让模型更好地处理水下图像退化问题，从而提高了模型的鲁棒性。实验显示，VFE模块能在多个任务上显著提升模型性能，确保了NAUTILUS在水下场景理解方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 主要动机是推动水下场景理解的进步，这类任务极具挑战性，特别是在缺乏大规模多任务调优数据集及有效水下图像处理工具的情况下。此外，水下图像退化进一步加大了这一任务的难度，研究旨在通过引入物理先验和新方法来解决这些问题。

Method: 构建了一个包含1.45M图像文本对的大型多任务数据集NautData；提出了一种新的插拔式视觉特征增强模块（VFE），该模块通过引入水下成像模型中的物理先验来提高模型性能；将VFE模块集成到经典基线模型中构建了新模型NAUTILUS，并在所提出的NautData和公共水下数据集中进行广泛的实验测试。

Result: 实验结果表明，附加了VFE模块的基线模型在多数任务上的性能均有所提高，证明了新方法的有效性和优越性。NAUTILUS模型在水下场景理解方面表现出色。此外，实验结果也证明，提出的NautData数据集能够在不同的任务上提供有价值的训练和评估基准。

Conclusion: 综上，新的数据集NautData和VFE模块为推动水下场景理解的研究提供了一套有效的解决方案。该研究展示了将物理先验用于指导视觉特征增强的有效方法，并验证了此方法对改善水下图像处理的性能有重要作用。这为未来研究提供了宝贵资源和新方向。

Abstract: Underwater exploration offers critical insights into our planet and attracts
increasing attention for its broader applications in resource exploration,
national security, etc. We study the underwater scene understanding methods,
which aim to achieve automated underwater exploration. The underwater scene
understanding task demands multi-task perceptions from multiple granularities.
However, the absence of large-scale underwater multi-task instruction-tuning
datasets hinders the progress of this research. To bridge this gap, we
construct NautData, a dataset containing 1.45 M image-text pairs supporting
eight underwater scene understanding tasks. It enables the development and
thorough evaluation of the underwater scene understanding models. Underwater
image degradation is a widely recognized challenge that interferes with
underwater tasks. To improve the robustness of underwater scene understanding,
we introduce physical priors derived from underwater imaging models and propose
a plug-and-play vision feature enhancement (VFE) module, which explicitly
restores clear underwater information. We integrate this module into renowned
baselines LLaVA-1.5 and Qwen2.5-VL and build our underwater LMM, NAUTILUS.
Experiments conducted on the NautData and public underwater datasets
demonstrate the effectiveness of the VFE module, consistently improving the
performance of both baselines on the majority of supported tasks, thus ensuring
the superiority of NAUTILUS in the underwater scene understanding area. Data
and models are available at https://github.com/H-EmbodVis/NAUTILUS.

</details>


### [45] [ThinkMorph: Emergent Properties in Multimodal Interleaved Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.27492)
*Jiawei Gu,Yunzhuo Hao,Huichen Will Wang,Linjie Li,Michael Qizhe Shieh,Yejin Choi,Ranjay Krishna,Yu Cheng*

Main category: cs.CV

TL;DR: 论文提出了一个名为ThinkMorph的统一模型，该模型通过学习24K个高质量交织推理痕迹，能够生成连续的文本-图像推理步骤，从而在视觉中心基准上实现显著提升，并展现出多模态智能的新兴能力，如视觉操作能力、推理模式之间的自适应切换和更好的测试时间扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有研究尚不明确何种交织的思维链构成了有意义的多模态推理。论文提出视觉和语言应作为互补而非等同的模态，互相推进推理过程，从而提出了一个名为ThinkMorph的新模型以解决这一问题。

Method: 论文建立了一个被标记为ThinkMorph的新模型，该模型通过对包含24K个高质量交织推理痕迹的训练数据集进行微调，并且能够生成循序渐进的文本-图像推理步骤。这些步骤利用视觉内容的同时保持语言逻辑连贯。

Result: 通过对具体任务的应用，论文展示出ThinkMorph模型在视觉中心基准上的平均增速超过了以往的模型。此外，它还展现了许多未见过的外观操作技能，进行推理模式间的自适应切换，并且有更好的测试时间扩展性。这些功能构建了统一模型对于多模态推理的初步理解。

Conclusion: 研究表明，通过互相推进视觉和语言之间的统一推理过程，构建模型可以有效地实现多模态推理。这种新型的模型——ThinkMorph——在多种任务中都证明了其能力，并且展示了新的潜力，对于理解这一新兴领域的特征非常重要。

Abstract: Multimodal reasoning requires iterative coordination between language and
vision, yet it remains unclear what constitutes a meaningful interleaved chain
of thought. We posit that text and image thoughts should function as
complementary, rather than isomorphic, modalities that mutually advance
reasoning. Guided by this principle, we build ThinkMorph, a unified model
fine-tuned on 24K high-quality interleaved reasoning traces spanning tasks with
varying visual engagement. ThinkMorph learns to generate progressive text-image
reasoning steps that concretely manipulate visual content while maintaining
coherent verbal logic. It delivers large gains on vision-centric benchmarks
(averaging 34.7% over the base model) and generalizes to out-of-domain tasks,
matching or surpassing larger and proprietary VLMs. Beyond performance,
ThinkMorph exhibits emergent multimodal intelligence, including unseen visual
manipulation skills, adaptive switching between reasoning modes, and better
test-time scaling through diversified multimodal thoughts.These findings
suggest promising directions for characterizing the emergent capabilities of
unified models for multimodal reasoning.

</details>


### [46] [Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation](https://arxiv.org/abs/2510.27508)
*Elena Mulero Ayllón,Linlin Shen,Pierangelo Veltri,Fabrizia Gelardi,Arturo Chiti,Paolo Soda,Matteo Tortora*

Main category: cs.CV

TL;DR: 研究提出了vMambaX，一种轻量级多模态框架，通过上下文门控跨模态感知模块结合PET和CT扫描图像，增强了跨模态特征交互。在PCLT20K数据集上，该模型优于基线模型，同时保持较低的计算复杂度。这表明了自适应跨模态门控在多模态肿瘤分割中的有效性，并展示了vMambaX作为高级肺癌分析的有效且可扩展框架的潜力。


<details>
  <summary>Details</summary>
Motivation: 准确的肺肿瘤分割对于提高诊断和治疗计划至关重要，而有效地结合PET和CT的解剖和功能信息仍然是一个主要挑战。研究动机在于开发一种更有效的轻量级框架来处理这个问题。

Method: 基于Visual Mamba架构，vMambaX通过上下文门控跨模态感知模块来结合PET和CT影像，提高了跨模态特征交互的适应性，突出了具有信息性的区域同时抑制了噪声。

Result: 在PCLT20K数据集上的测试表明，vMambaX不仅超越了基线模型，而且保持较低的计算复杂度。这证明了自适应跨模态门控机制在多模态肿瘤分割中的优势。

Conclusion: 研究成功地引入了vMambaX，一个有效的且可扩展的框架，能够利用来自PET和CT影像的信息来进行更准确的肺肿瘤分割，展示了其在高级肺癌分析中的应用潜力。

Abstract: Accurate lung tumor segmentation is vital for improving diagnosis and
treatment planning, and effectively combining anatomical and functional
information from PET and CT remains a major challenge. In this study, we
propose vMambaX, a lightweight multimodal framework integrating PET and CT scan
images through a Context-Gated Cross-Modal Perception Module (CGM). Built on
the Visual Mamba architecture, vMambaX adaptively enhances inter-modality
feature interaction, emphasizing informative regions while suppressing noise.
Evaluated on the PCLT20K dataset, the model outperforms baseline models while
maintaining lower computational complexity. These results highlight the
effectiveness of adaptive cross-modal gating for multimodal tumor segmentation
and demonstrate the potential of vMambaX as an efficient and scalable framework
for advanced lung cancer analysis. The code is available at
https://github.com/arco-group/vMambaX.

</details>


### [47] [MapSAM2: Adapting SAM2 for Automatic Segmentation of Historical Map Images and Time Series](https://arxiv.org/abs/2510.27547)
*Xue Xia,Randall Balestriero,Tao Zhang,Yixin Zhou,Andrew Ding,Dev Saini,Lorenz Hurni*

Main category: cs.CV

TL;DR: MapSAM2 是一种自动分割历史地图图像和时间序列的统一框架，通过将地图视为视频来处理，并且能够减少标注成本，实现有效的时空关联学习和分割。


<details>
  <summary>Details</summary>
Motivation: 历史地图作为地理特征的时间文档，自动化分析充满挑战，特别是在构建链接时空数据集时。为了简化该过程并使任务更高效，我们提出了MapSAM2框架，旨在解决这些问题。

Method: MapSAM2 使用了视觉基础模型进行少样本微调，能够适应不同的分割任务。对于图像，其方法是将一组地块视为视频来处理，以利用上下文线索提升几何准确性。对于时间序列，生成假时间序列以减少标注成本。

Result: 实验结果显示，MapSAM2 在有限的监督下或使用伪视频时可以准确地分割和链接时间序列中的建筑物，并学习有效的时空关联。

Conclusion: MapSAM2 提供了自动分割历史地图图像和时间序列的方法，并将通过发布数据集和代码来支持未来的相关研究。

Abstract: Historical maps are unique and valuable archives that document geographic
features across different time periods. However, automated analysis of
historical map images remains a significant challenge due to their wide
stylistic variability and the scarcity of annotated training data. Constructing
linked spatio-temporal datasets from historical map time series is even more
time-consuming and labor-intensive, as it requires synthesizing information
from multiple maps. Such datasets are essential for applications such as dating
buildings, analyzing the development of road networks and settlements, studying
environmental changes etc. We present MapSAM2, a unified framework for
automatically segmenting both historical map images and time series. Built on a
visual foundation model, MapSAM2 adapts to diverse segmentation tasks with
few-shot fine-tuning. Our key innovation is to treat both historical map images
and time series as videos. For images, we process a set of tiles as a video,
enabling the memory attention mechanism to incorporate contextual cues from
similar tiles, leading to improved geometric accuracy, particularly for areal
features. For time series, we introduce the annotated Siegfried Building Time
Series Dataset and, to reduce annotation costs, propose generating pseudo time
series from single-year maps by simulating common temporal transformations.
Experimental results show that MapSAM2 learns temporal associations effectively
and can accurately segment and link buildings in time series under limited
supervision or using pseudo videos. We will release both our dataset and code
to support future research.

</details>


### [48] [Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum](https://arxiv.org/abs/2510.27571)
*Zhuoning Guo,Mingxin Li,Yanzhao Zhang,Dingkun Long,Pengjun Xie,Xiaowen Chu*

Main category: cs.CV

TL;DR: 该论文提出了一个满足多维度泛化需求的通用视频检索框架，包括建立了一个包含16个数据集的通用视频检索基准（UVRB），提出了一种生成大量高质量配对样本的合成工作流，以及设计了一种层级训练课程(Modality Pyramid)。实验结果表明，所提出的General Video Embedder（GVE）在UVRB上实现了当前最好的零样本泛化性能。这一框架为打破当前视频检索局限提供了新路径，有利于推动向真正意义上的通用视频检索迈进。


<details>
  <summary>Details</summary>
Motivation: 当前视频检索范式的结构与窄化的评估基准相悖，导致数据集受限，模型仅在其单一任务上训练。需要一个能够定义并要求多维度泛化能力的诊断性评估，以打破这种循环，推动视频检索技术的发展。因此，提出了一个新的框架，能够为通用视频检索提供支持和解决方案。

Method: 框架包括三个方面：1. 建立一个包含16个数据集的通用视频检索基准（UVRB），用于测度和诊断能力差距；2. 根据UVRB的诊断，介绍一种可扩展的合成工作流，生成155万对高质量的配对数据；3．提出一个层级训练程序

Result: 实验结果显示，所提出的GVE实现了在UVRB上的最佳零样本泛化性能。这项研究还揭示了流行的基准用来预测总体能力效果欠佳，部分相关的检索场景被忽视

Conclusion: 提出了一种新的框架来打破视频检索的有限领域，推动向真正意义上的通用视频检索发展

Abstract: The prevailing video retrieval paradigm is structurally misaligned, as narrow
benchmarks incentivize correspondingly limited data and single-task training.
Therefore, universal capability is suppressed due to the absence of a
diagnostic evaluation that defines and demands multi-dimensional
generalization. To break this cycle, we introduce a framework built on the
co-design of evaluation, data, and modeling. First, we establish the Universal
Video Retrieval Benchmark (UVRB), a suite of 16 datasets designed not only to
measure performance but also to diagnose critical capability gaps across tasks
and domains. Second, guided by UVRB's diagnostics, we introduce a scalable
synthesis workflow that generates 1.55 million high-quality pairs to populate
the semantic space required for universality. Finally, we devise the Modality
Pyramid, a curriculum that trains our General Video Embedder (GVE) by
explicitly leveraging the latent interconnections within our diverse data.
Extensive experiments show GVE achieves state-of-the-art zero-shot
generalization on UVRB. In particular, our analysis reveals that popular
benchmarks are poor predictors of general ability and that partially relevant
retrieval is a dominant but overlooked scenario. Overall, our co-designed
framework provides a practical path to escape the limited scope and advance
toward truly universal video retrieval.

</details>


### [49] [Who Made This? Fake Detection and Source Attribution with Diffusion Features](https://arxiv.org/abs/2510.27602)
*Simone Bonechi,Paolo Andreini,Barbara Toniella Corradini*

Main category: cs.CV

TL;DR: FRIDA利用预训练扩散模型的内部激活来进行深度伪造图像的检测和生成源的识别，取得了跨生成器性能的新状态。这种方法不需要微调，且模型紧凑、解释性强，为合成图像的取证提供了新的基础


<details>
  <summary>Details</summary>
Motivation: 现有的监督检测方法在面对新生成器时泛化能力差，需要大量的标记数据和频繁的重新训练。为了提高检测的泛化性和效率，同时保护版权和减少错误信息的传播，提出了FRIDA框架

Method: FRIDA通过提取预训练扩散模型的内部激活作为特征，并利用k近邻分类器进行分类，以完成深度伪造图像的检测和源生成器的识别任务。这种方法在无需微调的情况下取得了优秀的跨生成器性能

Result: 实验结果表明，基于扩散模型的内部激活可以准确地检测出深度伪造图像，并且能够准确识别出生成这些图像的源生成器，显示了扩散表示具有内在的生成器特定模式

Conclusion: FRIDA提供了一种简单、有效、解释性强的深度伪造检测和源生成器识别的方法，这对于解决当前合成图像带来的问题具有重要意义

Abstract: The rapid progress of generative diffusion models has enabled the creation of
synthetic images that are increasingly difficult to distinguish from real ones,
raising concerns about authenticity, copyright, and misinformation. Existing
supervised detectors often struggle to generalize across unseen generators,
requiring extensive labeled data and frequent retraining. We introduce FRIDA
(Fake-image Recognition and source Identification via Diffusion-features
Analysis), a lightweight framework that leverages internal activations from a
pre-trained diffusion model for deepfake detection and source generator
attribution. A k-nearest-neighbor classifier applied to diffusion features
achieves state-of-the-art cross-generator performance without fine-tuning,
while a compact neural model enables accurate source attribution. These results
show that diffusion representations inherently encode generator-specific
patterns, providing a simple and interpretable foundation for synthetic image
forensics.

</details>


### [50] [Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning](https://arxiv.org/abs/2510.27606)
*Yuhong Liu,Beichen Zhang,Yuhang Zang,Yuhang Cao,Long Xing,Xiaoyi Dong,Haodong Duan,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 本文介绍了一种新的自监督强化学习范式Spatial-SSRL，该范式通过从普通RGB或RGB-D图像中提取验证信号，来改进大型视觉语言模型的2D和3D空间理解能力。经过训练后，模型在多个空间理解基准上表现出更好性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型的空间理解能力较差，现有的监督微调和基于可验证奖励的强化学习方法依赖于昂贵的监督、特定工具或受限环境，限制了其可扩展性。本文旨在提出一种新的方法，以克服这些问题，提高大型视觉语言模型的空间理解能力。

Method: 提出了一种称为Spatial-SSRL的新自监督强化学习范式，该方法直接从普通RGB或RGB-D图像中提取可验证信号，设计了五种预训练任务来捕捉2D和3D空间结构：排列打乱的补丁重新排序、翻转补丁识别、裁剪补丁修复、区域深度排序和相对3D位置预测。这些任务的解决方案可以很容易地验证，且不需要人类或模型标注。

Result: 在七个空间理解基准测试中，训练后的模型与Qwen2.5-VL基线相比，在3B和7B参数规模上分别取得了4.63%和3.89%的平均准确率提升。这些结果表明，简单的内置监督能够使可验证奖励的强化学习达到规模化，并为大型视觉语言模型提供更强的空间智能。

Conclusion: Spatial-SSRL通过从普通RGB或RGB-D图像中提取验证信号，创造出新的自监督任务，提高了大型视觉语言模型的空间理解能力。这些任务简单且可验证，需要的监督最少，证明了在Spatial-SSRL中通过大规模自监督学习可以增强模型的空间智能。

Abstract: Spatial understanding remains a weakness of Large Vision-Language Models
(LVLMs). Existing supervised fine-tuning (SFT) and recent reinforcement
learning with verifiable rewards (RLVR) pipelines depend on costly supervision,
specialized tools, or constrained environments that limit scale. We introduce
Spatial-SSRL, a self-supervised RL paradigm that derives verifiable signals
directly from ordinary RGB or RGB-D images. Spatial-SSRL automatically
formulates five pretext tasks that capture 2D and 3D spatial structure:
shuffled patch reordering, flipped patch recognition, cropped patch inpainting,
regional depth ordering, and relative 3D position prediction. These tasks
provide ground-truth answers that are easy to verify and require no human or
LVLM annotation. Training on our tasks substantially improves spatial reasoning
while preserving general visual capabilities. On seven spatial understanding
benchmarks in both image and video settings, Spatial-SSRL delivers average
accuracy gains of 4.63% (3B) and 3.89% (7B) over the Qwen2.5-VL baselines. Our
results show that simple, intrinsic supervision enables RLVR at scale and
provides a practical route to stronger spatial intelligence in LVLMs.

</details>


### [51] [Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model](https://arxiv.org/abs/2510.27607)
*John Won,Kyungmin Lee,Huiwon Jang,Dongyoung Kim,Jinwoo Shin*

Main category: cs.CV

TL;DR: 提出了一种名为DUal-STream diffusion (DUST) 的框架，这是一个增强的视觉-语言-行动模型 (VLAs)，它通过处理模态冲突和增强VLAs处理各种任务的能力来改进机器人策略学习。实验中的模拟和实际任务证明了DUST的有效性，以及其在大规模预训练VLAs中的潜力


<details>
  <summary>Details</summary>
Motivation: 虽然给视觉-语言-行动模型 (VLA) 添加世界模型显示出在改进机器人策略学习方面的潜力，但同时预测下一个状态观测值和行动序列仍然具有挑战性，这是由于这两种模态之间的固有差异。为了处理这种模态冲突，我们设计了DUal-STream diffusion (DUST) 这一框架

Method: 我们提出了一种多模态扩散变换器架构，它可以明确地保持单独的模态流，同时仍然可以促进跨模态知识分享。此外，我们还引入了每种模态的独立噪声扰动和解耦流匹配损失。我们还提出了一种基于训练期间模态解耦的联合采样方法，支持测试时间扩展

Result: 在实验中，使用模拟基准测试（如RoboCasa和GR-1），DUST比基线方法提高6%，我们的测试时间扩展方法提供了额外的2-5%的提升。在实际任务中，使用Franka Research 3，DUST将成功率提高13%。DUST还可以通过在无行动视频上的预训练来进一步增强其能力

Conclusion: 该研究引入了DUST，一种通过处理模态冲突来改进机器人策略学习的增强的视觉-语言-行动模型 (VLA)。我们通过在模拟和真实世界的任务中取得的结果证实了DUST的有效性，并强调了它在大规模预训练VLAs中的潜力

Abstract: Recently, augmenting Vision-Language-Action models (VLAs) with world modeling
has shown promise in improving robotic policy learning. However, it remains
challenging to jointly predict next-state observations and action sequences
because of the inherent difference between the two modalities. To address this,
we propose DUal-STream diffusion (DUST), a world-model augmented VLA framework
that handles the modality conflict and enhances the performance of VLAs across
diverse tasks. Specifically, we propose a multimodal diffusion transformer
architecture that explicitly maintains separate modality streams while still
enabling cross-modal knowledge sharing. In addition, we introduce independent
noise perturbations for each modality and a decoupled flow-matching loss. This
design enables the model to learn the joint distribution in a bidirectional
manner while avoiding the need for a unified latent space. Based on the
decoupling of modalities during training, we also introduce a joint sampling
method that supports test-time scaling, where action and vision tokens evolve
asynchronously at different rates. Through experiments on simulated benchmarks
such as RoboCasa and GR-1, DUST achieves up to 6% gains over baseline methods,
while our test-time scaling approach provides an additional 2-5% boost. On
real-world tasks with the Franka Research 3, DUST improves success rates by
13%, confirming its effectiveness beyond simulation. Furthermore, pre-training
on action-free videos from BridgeV2 yields significant transfer gains on
RoboCasa, underscoring DUST's potential for large-scale VLA pretraining.

</details>


### [52] [Sketch-to-Layout: Sketch-Guided Multimodal Layout Generation](https://arxiv.org/abs/2510.27632)
*Riccardo Brioschi,Aleksandr Alekseev,Emanuele Nevali,Berkay Döner,Omar El Malki,Blagoj Mitrevski,Leandro Kieliger,Mark Collier,Andrii Maksai,Jesse Berent,Claudiu Musat,Efi Kokiopoulou*

Main category: cs.CV

TL;DR: 提出了一种新的图形布局生成方法，该方法利用用户提供的草图作为直观约束。通过训练基于Transformer的模型，该模型可以从草图和内容资产中生成高质量的布局。此外，还提出了一种合成生成训练数据的方法，以减少从人工标注者处收集数据的成本。实验结果表明，该方法优于现有的基于约束的方法，并且为未来的研究提供了公开的合成数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的图形布局生成方法虽然可以利用用户约束来指导布局生成，但是这些约束往往需要复杂的规格，降低了用户的使用体验。为此，研究引入了一种利用用户提供的草图作为直观约束的方法，以提高布局生成的可用性。

Method: 本文提出了一种利用草图和内容资产输入的多模态Transformer方法，用于生成高质量的布局。同时，提出了一种生成合成草图数据集的方法，以减少从人工标注者处获取训练数据的成本。

Result: 在标准的数据集上进行了实验，结果表明，该方法优于现有的基于约束的方法，并且提供了一种更直观的设计体验。实验结果证明了利用草图作为约束进行布局生成的有效性以及合成草图作为训练数据集的有效性。

Conclusion: 本文的工作通过引入草图作为约束，使得布局生成过程更加直观且易于使用。通过合成的数据集，有效地训练了模型，实现了高质量的布局生成效果。此外，通过公开数据集促进未来的可绘制布局研究。

Abstract: Graphic layout generation is a growing research area focusing on generating
aesthetically pleasing layouts ranging from poster designs to documents. While
recent research has explored ways to incorporate user constraints to guide the
layout generation, these constraints often require complex specifications which
reduce usability. We introduce an innovative approach exploiting user-provided
sketches as intuitive constraints and we demonstrate empirically the
effectiveness of this new guidance method, establishing the sketch-to-layout
problem as a promising research direction, which is currently under-explored.
To tackle the sketch-to-layout problem, we propose a multimodal
transformer-based solution using the sketch and the content assets as inputs to
produce high quality layouts. Since collecting sketch training data from human
annotators to train our model is very costly, we introduce a novel and
efficient method to synthetically generate training sketches at scale. We train
and evaluate our model on three publicly available datasets: PubLayNet,
DocLayNet and SlidesVQA, demonstrating that it outperforms state-of-the-art
constraint-based methods, while offering a more intuitive design experience. In
order to facilitate future sketch-to-layout research, we release O(200k)
synthetically-generated sketches for the public datasets above. The datasets
are available at https://github.com/google-deepmind/sketch_to_layout.

</details>


### [53] [VessShape: Few-shot 2D blood vessel segmentation by leveraging shape priors from synthetic images](https://arxiv.org/abs/2510.27646)
*Cesar H. Comin,Wesley N. Galvão*

Main category: cs.CV

TL;DR: 本文提出了VessShape方法，用于生成包含血管形状偏好的大规模合成数据集，以提高血管分割模型的数据效率和泛化能力。实验表明，在少量样本的情况下，模型可以实现很好的分割性能，并且在未见过的域上也能有效分割血管。这表明使用形状偏好可以克服数据稀缺问题并改善模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于标注数据稀少和模型在不同成像模式下的泛化能力不足，需要一种方法以提高血管分割模型的数据效率和泛化能力。特别地，提出了利用血管形状的先验信息来改善模型的性能。

Method: 提出了VessShape方法，用于生成包含血管形状偏好的大规模合成数据集，通过该数据集对模型进行预训练，从而使其学习形状而非纹理。

Result: 实验表明，在少量样本的情况下，模型可以实现很好的分割性能，并且在未见过的域上也能有效分割血管。这表明使用形状偏好可以克服数据稀缺问题并改善模型的泛化能力。

Conclusion: 通过形状偏好的预训练可以有效提高血管分割模型的性能和泛化能力，是一种有效的策略。

Abstract: Semantic segmentation of blood vessels is an important task in medical image
analysis, but its progress is often hindered by the scarcity of large annotated
datasets and the poor generalization of models across different imaging
modalities. A key aspect is the tendency of Convolutional Neural Networks
(CNNs) to learn texture-based features, which limits their performance when
applied to new domains with different visual characteristics. We hypothesize
that leveraging geometric priors of vessel shapes, such as their tubular and
branching nature, can lead to more robust and data-efficient models. To
investigate this, we introduce VessShape, a methodology for generating
large-scale 2D synthetic datasets designed to instill a shape bias in
segmentation models. VessShape images contain procedurally generated tubular
geometries combined with a wide variety of foreground and background textures,
encouraging models to learn shape cues rather than textures. We demonstrate
that a model pre-trained on VessShape images achieves strong few-shot
segmentation performance on two real-world datasets from different domains,
requiring only four to ten samples for fine-tuning. Furthermore, the model
exhibits notable zero-shot capabilities, effectively segmenting vessels in
unseen domains without any target-specific training. Our results indicate that
pre-training with a strong shape bias can be an effective strategy to overcome
data scarcity and improve model generalization in blood vessel segmentation.

</details>


### [54] [Gaussian Combined Distance: A Generic Metric for Object Detection](https://arxiv.org/abs/2510.27649)
*Ziqian Guan,Xieyi Fu,Pengjun Huang,Hengyuan Zhang,Hubin Du,Yongtao Liu,Yinglin Wang,Qang Ma*

Main category: cs.CV

TL;DR: 本文提出了一种新的相似度度量方法GCD，解决了现有的IoU和Wasserstein Distance在检测小目标时的问题，提高了模型的定位性能和泛化能力。GCD在AI-TOD-v2、MS-COCO-2017和Visdrone-2019数据集上均表现优异，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在检测小目标时存在不足，IoU对小目标位置偏差敏感，Wasserstein Distance缺乏尺度不变性，导致模型泛化能力弱，训练慢精度低。因此提出GCD。

Method: 提出了Gaussain Combined Distance方法，结合尺度不变性和联合优化，解决小目标检测问题。

Result: 实验表明，GCD作为回归损失函数和标签分配度量，在AI-TOD-v2和通用数据集上表现最优。

Conclusion: GCD是一个有效的尺度不变相似度度量方法，适合于各类小目标检测任务。

Abstract: In object detection, a well-defined similarity metric can significantly
enhance model performance. Currently, the IoU-based similarity metric is the
most commonly preferred choice for detectors. However, detectors using IoU as a
similarity metric often perform poorly when detecting small objects because of
their sensitivity to minor positional deviations. To address this issue, recent
studies have proposed the Wasserstein Distance as an alternative to IoU for
measuring the similarity of Gaussian-distributed bounding boxes. However, we
have observed that the Wasserstein Distance lacks scale invariance, which
negatively impacts the model's generalization capability. Additionally, when
used as a loss function, its independent optimization of the center attributes
leads to slow model convergence and unsatisfactory detection precision. To
address these challenges, we introduce the Gaussian Combined Distance (GCD).
Through analytical examination of GCD and its gradient, we demonstrate that GCD
not only possesses scale invariance but also facilitates joint optimization,
which enhances model localization performance. Extensive experiments on the
AI-TOD-v2 dataset for tiny object detection show that GCD, as a bounding box
regression loss function and label assignment metric, achieves state-of-the-art
performance across various detectors. We further validated the generalizability
of GCD on the MS-COCO-2017 and Visdrone-2019 datasets, where it outperforms the
Wasserstein Distance across diverse scales of datasets. Code is available at
https://github.com/MArKkwanGuan/mmdet-GCD.

</details>


### [55] [Deep learning denoising unlocks quantitative insights in operando materials microscopy](https://arxiv.org/abs/2510.27667)
*Samuel Degnan-Morgenstern,Alexander E. Cohen,Rajeev Gopal,Megan Gober,George J. Nelson,Peng Bai,Martin Z. Bazant*

Main category: cs.CV

TL;DR: 该论文提出了一种基于深度学习降噪的泛在框架，用于提高各类显微技术的工作流程质量。这种方法可以减少实验中噪声引起的极化和不确定性，提高图像定量分析的准确性。该方法在锂离子电池材料显微分析中取得了显著效果，大大减少了噪声引起的可变性，提高了图像定量分析的质量和精度。


<details>
  <summary>Details</summary>
Motivation: 测量噪声限制了有效解析度，并且影响了定量分析，该论文试图通过整合深度学习降噪来提高各类显微技术的工作流程质量，以实现更好的定量成像效果。

Method: 提出了一种基于深度学习降噪的方法，这种方法可以用于各类显微技术中，包括透射X射线显微镜（STXM），光学显微镜和中子辐照中，去噪的过程可以保持物理的真实性，减少学习模型中的偏置，并且减少了实验中的噪声引起的可变性。结果显示，降噪后图像中锂离子电池材料的化学和结构异质性更加明显，同时自动粒子分割和相位分类的准确性也得到了提高。

Result: 该论文提出的降噪技术显著提高了图像的质量，特别是在锂离子电池材料的显微分析中，表现出明显的效果，提高了图像的质量和精度。同时，这种方法还能够减少噪声引起了可变性，并且适用于各种显微技术中。

Conclusion: 该研究展示了一种基于深度学习的降噪技术，这项技术可以大大提高图像分析的质量，并且可以应用于各种显微技术中，提高了定量成像的效果，这为以前受噪声限制的技术提供了可能，并扩展了其应用范围。

Abstract: Operando microscopy provides direct insight into the dynamic chemical and
physical processes that govern functional materials, yet measurement noise
limits the effective resolution and undermines quantitative analysis. Here, we
present a general framework for integrating unsupervised deep learning-based
denoising into quantitative microscopy workflows across modalities and length
scales. Using simulated data, we demonstrate that deep denoising preserves
physical fidelity, introduces minimal bias, and reduces uncertainty in model
learning with partial differential equation (PDE)-constrained optimization.
Applied to experiments, denoising reveals nanoscale chemical and structural
heterogeneity in scanning transmission X-ray microscopy (STXM) of lithium iron
phosphate (LFP), enables automated particle segmentation and phase
classification in optical microscopy of graphite electrodes, and reduces
noise-induced variability by nearly 80% in neutron radiography to resolve
heterogeneous lithium transport. Collectively, these results establish deep
denoising as a powerful, modality-agnostic enhancement that advances
quantitative operando imaging and extends the reach of previously noise-limited
techniques.

</details>


### [56] [Vision Transformer for Robust Occluded Person Reidentification in Complex Surveillance Scenes](https://arxiv.org/abs/2510.27677)
*Bo Li,Duyuan Zheng,Xinyang Liu,Qingwen Li,Hong Li,Hongyan Cui,Ge Gao,Chen Liu*

Main category: cs.CV

TL;DR: 提出了一种名为Sh-ViT的轻量级和鲁棒的模型，用于遮挡下的人重识别任务。该模型在监视条件下的表现优于CNN和ViT基线模型，并且在Market1501数据集上超越了当前的最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理遮挡、视角扭曲和图像质量差等问题时存在挑战，性能依赖于复杂的模块，或者只在清晰的正面图像上表现良好。为此，本文提出了Sh-ViT，一个轻量且鲁棒的模型，以应对遮挡情况下的人员重识别任务，提高模型在实际应用场景中的表现能力。同时，本文还建立了一个新的数据集MyTT以支持真实世界的评估。

Method: Sh-ViT基于ViT-Base构建，引入了三个组成部分：1）在最终的Transformer层中的Shuffle模块，用于破坏空间相关性并增强对遮挡和模糊的鲁棒性；2）针对场景适应的增强方法（几何变换、擦除、模糊和颜色调整等），以模拟监视条件；3）DeiT基的知识蒸馏，以在有限的标签情况下提高学习效果。

Result: 实验表明，Sh-ViT在MyTT数据集上达到了83.2％的Rank-1和80.1％的mAP，优于CNN和ViT基线模型，并在Market1501数据集上达到了94.6％的Rank-1和87.5％的mAP，超过了现有的SOTA方法。Sh-ViT无需外部模块即可提高对遮挡和模糊的鲁棒性。

Conclusion: Sh-ViT提供了一种无需额外硬件支持就可以应用于实际监控场景的人重识别解决方案。

Abstract: Person re-identification (ReID) in surveillance is challenged by occlusion,
viewpoint distortion, and poor image quality. Most existing methods rely on
complex modules or perform well only on clear frontal images. We propose Sh-ViT
(Shuffling Vision Transformer), a lightweight and robust model for occluded
person ReID. Built on ViT-Base, Sh-ViT introduces three components: First, a
Shuffle module in the final Transformer layer to break spatial correlations and
enhance robustness to occlusion and blur; Second, scenario-adapted augmentation
(geometric transforms, erasing, blur, and color adjustment) to simulate
surveillance conditions; Third, DeiT-based knowledge distillation to improve
learning with limited labels.To support real-world evaluation, we construct the
MyTT dataset, containing over 10,000 pedestrians and 30,000+ images from base
station inspections, with frequent equipment occlusion and camera variations.
Experiments show that Sh-ViT achieves 83.2% Rank-1 and 80.1% mAP on MyTT,
outperforming CNN and ViT baselines, and 94.6% Rank-1 and 87.5% mAP on
Market1501, surpassing state-of-the-art methods.In summary, Sh-ViT improves
robustness to occlusion and blur without external modules, offering a practical
solution for surveillance-based personnel monitoring.

</details>


### [57] [PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting](https://arxiv.org/abs/2510.27680)
*Danyal Maqbool,Changhee Lee,Zachary Huemann,Samuel D. Church,Matthew E. Larson,Scott B. Perlman,Tomas A. Romero,Joshua D. Warner,Meghan Lubner,Xin Tie,Jameson Merkow,Junjie Hu,Steve Y. Cho,Tyler J. Bradshaw*

Main category: cs.CV

TL;DR: 本文提出了PETAR-4B，这是一个结合了PET、CT和病变轮廓的3D掩码感知视觉-语言模型，用于生成基于空间的报告。该模型在3D医学视觉语言理解方面取得了显著进展，提高了PET/CT报告生成的质量。


<details>
  <summary>Details</summary>
Motivation: 尽管在视觉-语言模型（VLMs）在多模态推理方面取得了进展，但大多数医学应用仍然局限于2D成像。本文旨在将VLMs扩展到3D PET/CT领域，以处理大型体积数据、小而分散的病变和冗长的放射学报告。

Method: 本文构建了一个大规模数据集，包含超过11,000个病变级别的描述和从超过5,000个PET/CT检查中提取的3D分割。基于此数据集，引入了PETAR-4B模型，该模型整合了PET、CT和病变轮廓以生成空间定位的报告。

Result: 自动化和人工评估显示，PETAR-4B显著提升了PET/CT报告生成的质量，实现了3D医学视觉语言理解的进步。

Conclusion: PETAR-4B模型能够在3D医学图像中实现高水平的视觉语言理解，生成临床相关的、局部化的发现，并提高了PET/CT报告的质量。

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive
multimodal reasoning, yet most medical applications remain limited to 2D
imaging. In this work, we extend VLMs to 3D positron emission tomography and
computed tomography (PET/CT), a domain characterized by large volumetric data,
small and dispersed lesions, and lengthy radiology reports. We introduce a
large-scale dataset comprising over 11,000 lesion-level descriptions paired
with 3D segmentations from more than 5,000 PET/CT exams, extracted via a hybrid
rule-based and large language model (LLM) pipeline. Building upon this dataset,
we propose PETAR-4B, a 3D mask-aware vision-language model that integrates PET,
CT, and lesion contours for spatially grounded report generation. PETAR bridges
global contextual reasoning with fine-grained lesion awareness, producing
clinically coherent and localized findings. Comprehensive automated and human
evaluations demonstrate that PETAR substantially improves PET/CT report
generation quality, advancing 3D medical vision-language understanding.

</details>


### [58] [Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals](https://arxiv.org/abs/2510.27684)
*Xiangyu Fan,Zesong Qiu,Zhuguanyu Wu,Fanzhou Wang,Zhiqian Lin,Tianxiang Ren,Dahua Lin,Ruihao Gong,Lei Yang*

Main category: cs.CV

TL;DR: Phased DMD 是一种分布匹配蒸馏框架，通过分阶段蒸馏和专家混合(MoE)技术，解决了多步骤蒸馏过程中生成多样性下降的问题，同时保持了生成能力。它在图像和视频生成模型上都表现出了优越性的实验结果，并将发布代码和模型。


<details>
  <summary>Details</summary>
Motivation: 对于复杂的生成任务，如文本到视频生成，受限的模型容量会导致一步蒸馏模型在性能上达不到要求。直接扩展DMD到多步骤蒸馏存在记忆使用、计算深度增加等问题，导致不稳定和效率降低。同时，先前工作的随机梯度截断方法虽然可行，但会大幅降低多步骤模型生成的多样性，使其与一步模型相似。作者提出Phased DMD以解决这些问题。

Method: Phased DMD 通过将分布匹配和分数匹配的思想应用于子区间的方法，逐步提高噪声比率（SNR）范围，确保每个子区间内的训练目标准确性。这一方案使用分阶段蒸馏与专家混合(MoE)技术，以减少学习难度，增强模型容量。详细实验设计包括数学推导和验证模型的有效性。

Result: 在领先的图像和视频生成模型上的应用中，Phased DMD证明了它可以更好地保留生成多样性，并保持关键的生成能力，相较于DMD，Phased DMD在图像和视频生成任务上的性能更为优越。实验结果表明，Phased DMD不仅性能优越，同时也计划发布相关的代码和模型以供进一步研究和使用。

Conclusion: 通过分阶段蒸馏和专家混合(MoE)技术，Phased DMD成功解决了多步骤蒸馏过程中遇到的挑战，并在保持生成能力的同时，确保生成多样性。这为未来的设计蒸馏算法提供了新的视角和方向。

Abstract: Distribution Matching Distillation (DMD) distills score-based generative
models into efficient one-step generators, without requiring a one-to-one
correspondence with the sampling trajectories of their teachers. However,
limited model capacity causes one-step distilled models underperform on complex
generative tasks, e.g., synthesizing intricate object motions in text-to-video
generation. Directly extending DMD to multi-step distillation increases memory
usage and computational depth, leading to instability and reduced efficiency.
While prior works propose stochastic gradient truncation as a potential
solution, we observe that it substantially reduces the generation diversity of
multi-step distilled models, bringing it down to the level of their one-step
counterparts. To address these limitations, we propose Phased DMD, a multi-step
distillation framework that bridges the idea of phase-wise distillation with
Mixture-of-Experts (MoE), reducing learning difficulty while enhancing model
capacity. Phased DMD is built upon two key ideas: progressive distribution
matching and score matching within subintervals. First, our model divides the
SNR range into subintervals, progressively refining the model to higher SNR
levels, to better capture complex distributions. Next, to ensure the training
objective within each subinterval is accurate, we have conducted rigorous
mathematical derivations. We validate Phased DMD by distilling state-of-the-art
image and video generation models, including Qwen-Image (20B parameters) and
Wan2.2 (28B parameters). Experimental results demonstrate that Phased DMD
preserves output diversity better than DMD while retaining key generative
capabilities. We will release our code and models.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [59] [UP2D: Uncertainty-aware Progressive Pseudo-label Denoising for Source-Free Domain Adaptive Medical Image Segmentation](https://arxiv.org/abs/2510.26826)
*Quang-Khai Bui-Tran,Thanh-Huy Nguyen,Manh D. Ho,Thinh B. Lam,Vi Vu,Hoang-Thien Nguyen,Phat Huynh,Ulas Bagci*

Main category: eess.IV

TL;DR: 提出了一种新的不确定性感知逐步伪标签去噪框架（UP2D）用于无源域自适应（SFDA），提高了伪标签的质量并减少了确认偏差，实验表明UP2D在标准和开放域设置下均达到了最先进的性能水平，优于之前的UDA和SFDA方法


<details>
  <summary>Details</summary>
Motivation: 目的是在数据共享限制阻碍访问源图像时，解决医学图像分割模型在域偏移下的性能下降问题，并减少伪标签噪声和类别不平衡

Method: UP2D框架结合了三个关键组件：高效的原型过滤模块，不确定性引导的EMA策略和基于分位数的熵最小化方案。这些组件协同工作，逐步提高伪标签质量并减少确认偏差

Result: 在三个具有挑战性的视网膜基金标上进行了大量实验，结果表明UP2D在标准和开放域设置下均实现了最先进的性能，超越了之前的UDA和SFDA方法，并且在边界精度方面保持了优越性

Conclusion: 通过引入UP2D框架，解决了在数据共享限制下医学图像分割模型的性能下降问题，证明该方法在各个领域都表现出色，是目前的研究热点

Abstract: Medical image segmentation models face severe performance drops under domain
shifts, especially when data sharing constraints prevent access to source
images. We present a novel Uncertainty-aware Progressive Pseudo-label Denoising
(UP2D) framework for source-free domain adaptation (SFDA), designed to mitigate
noisy pseudo-labels and class imbalance during adaptation. UP2D integrates
three key components: (i) a Refined Prototype Filtering module that suppresses
uninformative regions and constructs reliable class prototypes to denoise
pseudo-labels, (ii) an Uncertainty-Guided EMA (UG-EMA) strategy that
selectively updates the teacher model based on spatially weighted boundary
uncertainty, and (iii) a quantile-based entropy minimization scheme that
focuses learning on ambiguous regions while avoiding overconfidence on easy
pixels. This single-stage student-teacher framework progressively improves
pseudo-label quality and reduces confirmation bias. Extensive experiments on
three challenging retinal fundus benchmarks demonstrate that UP2D achieves
state-of-the-art performance across both standard and open-domain settings,
outperforming prior UDA and SFDA approaches while maintaining superior boundary
precision.

</details>


### [60] [Diffusion-Driven Generation of Minimally Preprocessed Brain MRI](https://arxiv.org/abs/2510.26834)
*Samuel W. Remedios,Aaron Carass,Jerry L. Prince,Blake E. Dewey*

Main category: eess.IV

TL;DR: 该研究介绍了并比较了三种用于生成3D T1加权MRI人脑图像的去噪扩散概率模型（DDPMs），这些模型使用80,675张图像进行了训练，并通过了分割和FID评估，尽管统计测试结果为负，但DDPMs能生成高质量的3D T1加权脑图像，权重和代码在GitHub上提供。


<details>
  <summary>Details</summary>
Motivation: 研究的目的是介绍和比较三种生成3D T1加权MRI人脑图像的去噪扩散概率模型。这些模型使用了大量经过专家人工检查和初步处理的高质量3D MRI脑图像数据集进行训练，该研究旨在展示不受头骨剥离或注册影响的3D非隐式扩散模型的方法和能力。

Method: 三个DDPM模型通过大约1 mm等效分辨率的3D T1加权MRI脑图像数据集进行训练，这些图像是未注册和未修正的，以确保自然的方向变化和非均匀性。模型能力通过分割、FID评估和定性检验进行评估。

Result: 所有的DDPM模型都生成了连贯的脑体积。速度和流动预测模型的FID比预测样本模型低。然而，所有模型与真实图像相比，FID值较高。生成的脑区域体积分布与真实数据有统计学差异，但速度和流动预测模型在丘脑和壳核中的差异较小。

Conclusion: 该研究展示了并公开了第一个无需头骨剥离或注册的3D去噪扩散模型。尽管统计测试结果为负，但模型表现出生成高质量的3D T1加权脑图像的能力。

Abstract: The purpose of this study is to present and compare three denoising diffusion
probabilistic models (DDPMs) that generate 3D $T_1$-weighted MRI human brain
images. Three DDPMs were trained using 80,675 image volumes from 42,406
subjects spanning 38 publicly available brain MRI datasets. These images had
approximately 1 mm isotropic resolution and were manually inspected by three
human experts to exclude those with poor quality, field-of-view issues, and
excessive pathology. The images were minimally preprocessed to preserve the
visual variability of the data. Furthermore, to enable the DDPMs to produce
images with natural orientation variations and inhomogeneity, the images were
neither registered to a common coordinate system nor bias field corrected.
Evaluations included segmentation, Frechet Inception Distance (FID), and
qualitative inspection. Regarding results, all three DDPMs generated coherent
MR brain volumes. The velocity and flow prediction models achieved lower FIDs
than the sample prediction model. However, all three models had higher FIDs
compared to real images across multiple cohorts. In a permutation experiment,
the generated brain regional volume distributions differed statistically from
real data. However, the velocity and flow prediction models had fewer
statistically different volume distributions in the thalamus and putamen. In
conclusion this work presents and releases the first 3D non-latent diffusion
model for brain data without skullstripping or registration. Despite the
negative results in statistical testing, the presented DDPMs are capable of
generating high-resolution 3D $T_1$-weighted brain images. All model weights
and corresponding inference code are publicly available at
https://github.com/piksl-research/medforj .

</details>


### [61] [A fragile zero-watermarking method based on dual quaternion matrix decomposition](https://arxiv.org/abs/2510.27307)
*Mingcui Zhang,Zhigang Jia*

Main category: eess.IV

TL;DR: 提出了一种基于双四元数矩阵分解的脆弱零水印模型，用于保护医学影像的版权并检测内容篡改。


<details>
  <summary>Details</summary>
Motivation: 医学影像在辅助诊断、远程会诊和学术研究中具有重要作用，但在传输和共享过程中存在版权和内容篡改的风险，因此需要有效的版权保护和篡改检测方法。零水印技术因其不修改原始载体的特点成为一种理想的方法。

Method: 基于双四元数矩阵分解，利用双四元数的标准部分和双部分之间的操作关系，将原载体影像与水印影像相关联，生成零水印信息。

Result: 实现了医学影像的版权保护和内容篡改检测。

Conclusion: 所提出的脆弱零水印模型能够有效保护医学影像的版权，并能检测到内容篡改。

Abstract: Medical images play a crucial role in assisting diagnosis, remote
consultation, and academic research. However, during the transmission and
sharing process, they face serious risks of copyright ownership and content
tampering. Therefore, protecting medical images is of great importance. As an
effective means of image copyright protection, zero-watermarking technology
focuses on constructing watermarks without modifying the original carrier by
extracting its stable features, which provides an ideal approach for protecting
medical images. This paper aims to propose a fragile zero-watermarking model
based on dual quaternion matrix decomposition, which utilizes the operational
relationship between the standard part and the dual part of dual quaternions to
correlate the original carrier image with the watermark image, and generates
zero-watermarking information based on the characteristics of dual quaternion
matrix decomposition, ultimately achieving copyright protection and content
tampering detection for medical images.

</details>


### [62] [Combined fluorescence and photoacoustic imaging of tozuleristide in muscle tissue in vitro -- toward optically-guided solid tumor surgery: feasibility studies](https://arxiv.org/abs/2510.27595)
*Ruibo Shang,Matthew Thompson,Matthew D. Carson,Eric J. Seibel,Matthew O'Donnell,Ivan Pelivanov*

Main category: eess.IV

TL;DR: 这篇论文提出了一种结合近红外荧光成像（NIRF）和快速扫描光声超声成像（PAUS）的方法，以改善肿瘤切除手术中对深层肿瘤的检测能力。在体外实验中，使用PAUS成像技术检测到在肌肉组织深处注入的20 uM浓度的显像剂，显示了该方法在深度上具有更大的检测能力。并验证了激光剂量补偿和强背景抑制技术可以提高光声成像的精确度和检测限，以及减少图像伪影。这种方法对于固体肿瘤的检测和切缘切除手术可能具有重要的应用价值。


<details>
  <summary>Details</summary>
Motivation: 近红外荧光成像技术在深层肿瘤检测中的局限性，限制了其在肿瘤切除手术中的应用。因此，本文提出采用快速扫描光声超声成像技术来弥补该技术在深层内的检测不足。

Method: 研究通过向牛肌肉组织中直接注射20 uM浓度的tozuleristide显像剂，并使用PAUS技术来进行光源补偿和背景抑制，以增强光声成像的效果。此外，通过直接注射的方式来验证该方法的光谱PAUS成像能力。

Result: 实验结果显示PAUS技术可以在～34mm的深度检测到20 uM浓度的tozuleristide，超越了单独使用NIRF的方法。并且证实了光源剂量补偿和强背景抑制技术可以有效地提高光声成像的精确度和检测限。

Conclusion: 将NIRF与PAUS相结合的方法在固体肿瘤的检测和手术切缘的精确切除上具有潜在的应用价值。

Abstract: Near-infrared fluorescence (NIRF) can deliver high-contrast, video-rate,
non-contact imaging of tumor-targeted contrast agents with the potential to
guide surgeries excising solid tumors. However, it has been met with skepticism
for wide-margin excision due to sensitivity and resolution limitations at
depths larger than ~5 mm in tissue. To address this limitation, fast-sweep
photoacoustic-ultrasound (PAUS) imaging is proposed to complement NIRF. In an
exploratory in vitro feasibility study using dark-red bovine muscle tissue, we
observed that PAUS scanning can identify tozuleristide, a clinical stage
investigational imaging agent, at a concentration of 20 uM from the background
at depths of up to ~34 mm, highly extending the capabilities of NIRF alone. The
capability of spectroscopic PAUS imaging was tested by direct injection of 20
uM tozuleristide into bovine muscle tissue at a depth of ~ 8 mm. It is shown
that laser-fluence compensation and strong clutter suppression enabled by the
unique capabilities of the fast-sweep approach greatly improve spectroscopic
accuracy and the PA detection limit, and strongly reduce image artifacts. Thus,
the combined NIRF-PAUS approach can be promising for comprehensive pre- (with
PA) and intra- (with NIRF) operative solid tumor detection and wide-margin
excision in optically guided solid tumor surgery.

</details>


### [63] [Navigated hepatic tumor resection using intraoperative ultrasound imaging](https://arxiv.org/abs/2510.27596)
*Karin Olthof,Theo Ruers,Tiziano Natali,Lisanne Venix,Jasper Smit,Anne den Hartor,Niels Kok,Matteo Fusaglia,Koert Kuhlmann*

Main category: eess.IV

TL;DR: 这项概念验证研究评估了一种基于超声波的导航系统在开放性肝手术中的可行性和准确性。研究表明，仅基于术中超声波的导航方法是可行且准确的，为更简单、更准确的图像引导系统铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 验证超声波引导手术的可行性和准确性，这种导航系统不依赖于术前成像，而是利用术中获得的超声波数据生成3D模型。主要目标是为开放性肝手术提供一种新的、准确的、不依赖于术前图像的导航方法。

Method: 在25名进行肝脏转移瘤切除的患者中进行了一项初步研究，前五个病例用于优化工作流程。术中，使用电磁传感器跟踪器官运动，随后获取超声体积。血管自动分割，肿瘤半自动分割，采用区域生长（n=15）或深度学习算法（n=5）。生成的3D模型与跟踪的外科手术器械一起可视化。通过将导航软件中的夹子到肿瘤的距离与术后CT上切除标本的相同距离进行比较来评估准确性。

Result: 所有20名患者均成功建立了导航，并在16名可评估患者中分析了78次夹子到肿瘤的距离，导航的中位准确度为3.2毫米 [IQR：2.8-4.8毫米]。R0切除在15/16患者中实现，一名患者进行了R1血管切除。

Conclusion: 基于单纯术中获得的超声波数据的导航对于肝手术是可行且准确的。这为更简单、更准确的图像引导系统开辟了道路。

Abstract: Purpose: This proof-of-concept study evaluates feasibility and accuracy of an
ultrasound-based navigation system for open liver surgery. Unlike most
conventional systems that rely on registration to preoperative imaging, the
proposed system provides navigation-guided resection using 3D models generated
from intraoperative ultrasound.
  Methods: A pilot study was conducted in 25 patients undergoing resection of
liver metastases. The first five cases served to optimize the workflow.
Intraoperatively, an electromagnetic sensor compensated for organ motion, after
which an ultrasound volume was acquired. Vasculature was segmented
automatically and tumors semi-automatically using region-growing (n=15) or a
deep learning algorithm (n=5). The resulting 3D model was visualized alongside
tracked surgical instruments. Accuracy was assessed by comparing the distance
between surgical clips and tumors in the navigation software with the same
distance on a postoperative CT of the resected specimen.
  Results: Navigation was successfully established in all 20 patients. However,
four cases were excluded from accuracy assessment due to intraoperative sensor
detachment (n=3) or incorrect data recording (n=1). The complete navigation
workflow was operational within 5-10 minutes. In 16 evaluable patients, 78
clip-to-tumor distances were analyzed. The median navigation accuracy was 3.2
mm [IQR: 2.8-4.8 mm], and an R0 resection was achieved in 15/16 (93.8%)
patients and one patient had an R1 vascular resection.
  Conclusion: Navigation based solely on intra-operative ultrasound is feasible
and accurate for liver surgery. This registration-free approach paves the way
for simpler and more accurate image guidance systems.

</details>


### [64] [Bayesian model selection and misspecification testing in imaging inverse problems only from noisy and partial measurements](https://arxiv.org/abs/2510.27663)
*Tom Sprunck,Marcelo Pereyra,Tobias Liaudat*

Main category: eess.IV

TL;DR: 本文提出了一种基于贝叶斯交叉验证和数据裂变（一种随机测量分割技术）的新方法，用于无监督的贝叶斯成像模型选择和模型误指定检测。该方法适用于任何贝叶斯成像采样器。实验结果表明，在使用不同的评分规则和模型误指定类型的情况下，该方法具有非常高的选择和检测准确率，且计算成本较低。


<details>
  <summary>Details</summary>
Motivation: 在现代成像技术中，贝叶斯统计模型常被用来解决复杂的图像重建和恢复问题。当真实数据不可用时，如何客观评估这些模型成为一大挑战。现有的一些无监督模型评估方法通常计算成本高且与现代成像先验不符。因此，需要开发出一种新的、低计算成本且适合现代成像的无监督模型选择和误指定检测方法。

Method: 本文提出的方法结合了贝叶斯交叉验证和数据裂变（一种随机的测量分割技术），适用于任何贝叶斯成像采样器，包括扩散和即插即用采样器。通过不同的评分规则和模型误指定类型进行实验验证，证明了该方法的有效性。

Result: 实验结果显示，使用本文提出的方法可以在低计算成本下实现高度准确的模型选择和误指定检测。该方法适用于各种贝叶斯成像模型。

Conclusion: 本文提出了一种新的无监督贝叶斯成像模型选择和误指定检测方法，证明了其在低计算成本下具备高准确率，并且适用于多种计算成像任务。

Abstract: Modern imaging techniques heavily rely on Bayesian statistical models to
address difficult image reconstruction and restoration tasks. This paper
addresses the objective evaluation of such models in settings where ground
truth is unavailable, with a focus on model selection and misspecification
diagnosis. Existing unsupervised model evaluation methods are often unsuitable
for computational imaging due to their high computational cost and
incompatibility with modern image priors defined implicitly via machine
learning models. We herein propose a general methodology for unsupervised model
selection and misspecification detection in Bayesian imaging sciences, based on
a novel combination of Bayesian cross-validation and data fission, a randomized
measurement splitting technique. The approach is compatible with any Bayesian
imaging sampler, including diffusion and plug-and-play samplers. We demonstrate
the methodology through experiments involving various scoring rules and types
of model misspecification, where we achieve excellent selection and detection
accuracy with a low computational cost.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [65] [Analytical Model of NR-V2X Mode 2 with Re-Evaluation Mechanism](https://arxiv.org/abs/2510.27108)
*Shuo Zhu,Siyu Lin*

Main category: cs.NI

TL;DR: 本文基于3GPP高级V2X服务推荐的流量模式，建立了NR-V2X模式2的分析模型，使用离散时间马尔可夫链构建了消息生成器。研究显示，重新评估机制提高了NR-V2X传输的可靠性，但仍需进一步降低延迟。


<details>
  <summary>Details</summary>
Motivation: 目前对NR-V2X重新评估机制的研究较少，且大部分研究仅在固定流量下分析，因此为了更准确地分析和比较该机制，本文建立了包含变化流量的分析模型。

Method: 本文使用了离散时间马尔可夫链（DTMC）构建了消息生成器来模拟推荐的3GPP高级V2X服务流量模式，并基于该模型分析了NR-V2X重新评估机制的表现。

Result: 研究显示，重新评估机制提高了传输可靠性，但为了进一步降低传输延迟，该机制还可进行局部改进。

Conclusion: 通过使用包含变化流量的分析模型，本文验证了NR-V2X重新评估机制对提高传输可靠性的作用，并为未来改进该机制以减少传输延迟提出了建议。

Abstract: Massive message transmissions, unpredictable aperiodic messages, and
high-speed moving vehicles contribute to the complex wireless environment,
resulting in inefficient resource collisions in Vehicle to Everything (V2X). In
order to achieve better medium access control (MAC) layer performance, 3GPP
introduced several new features in NR-V2X. One of the most important is the
re-evaluation mechanism. It allows the vehicle to continuously sense resources
before message transmission to avoid resource collisions. So far, only a few
articles have studied the re-evaluation mechanism of NR-V2X, and they mainly
focus on network simulator that do not consider variable traffic, which makes
analysis and comparison difficult. In this paper, an analytical model of NR-V2X
Mode 2 is established, and a message generator is constructed by using discrete
time Markov chain (DTMC) to simulate the traffic pattern recommended by 3GPP
advanced V2X services. Our study shows that the re-evaluation mechanism
improves the reliability of NR-V2X transmission, but there are still local
improvements needed to reduce latency.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [66] [Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations](https://arxiv.org/abs/2510.26905)
*Pedro Antonio Alarcón Granadeno,Arturo Miguel Bernal Russell,Sofia Nelson,Demetrius Hernandez,Maureen Petterson,Michael Murphy,Walter J. Scheirer,Jane Cleland-Huang*

Main category: cs.AI

TL;DR: 本文介绍了认知包络的概念，旨在通过限制AI生成的决策来解决大型语言模型和视觉-语言模型在自主决策中引入的新类型错误问题，并提出了一种补充元认知和传统安全包络的方法。


<details>
  <summary>Details</summary>
Motivation: 随着对自动化的更高要求，Foundational Models（如大型语言模型和视觉-语言模型）被广泛采用以提高自主决策的能力。然而，这些模型也引入了新的错误类型，如错觉、过度概括和上下文不对齐，这可能会导致不正确的和有缺陷的决策。为了防止这些问题，需要一种新的方法来约束AI生成的决策。这个方法就是认知包络。

Method: 本文的方法主要是引入了'认知包络'的概念。'认知包络'是设计来建立推理边界，以限制AI生成的决策，并补充元认知和传统的安全包络。

Result: 本文提出了一个新的概念——认知包络，它可以帮助定义、验证和保证AI决策的安全性，实现AI更合理、更安全的应用。这项工作也将为进一步的系统化流程提供理论基础和实用指导。

Conclusion: 在未来的工作中，将以认知包络为基础，进一步定义、验证并保证认知包络的有效性，最终使其成为安全决策支持的一部分，以提高基于AI的决策的准确性和安全性。

Abstract: Cyber-physical systems increasingly rely on Foundational Models such as Large
Language Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy
through enhanced perception, inference, and planning. However, these models
also introduce new types of errors, such as hallucinations,
overgeneralizations, and context misalignments, resulting in incorrect and
flawed decisions. To address this, we introduce the concept of Cognition
Envelopes, designed to establish reasoning boundaries that constrain
AI-generated decisions while complementing the use of meta-cognition and
traditional safety envelopes. As with safety envelopes, Cognition Envelopes
require practical guidelines and systematic processes for their definition,
validation, and assurance.

</details>


### [67] [SUSTAINABLE Platform: Seamless Smart Farming Integration Towards Agronomy Automation](https://arxiv.org/abs/2510.26989)
*Agorakis Bompotas,Konstantinos Koutras,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Dimitra Gariza,Athanasios P. Kalogeras,Christos Alexakos*

Main category: cs.AI

TL;DR: SUSTAINABLE是一个旨在通过整合物联网(IoT)、人工智能(AI)、卫星成像和基于角色的任务编排来实现高效、可追溯和可持续农业的智能农业平台。该研究介绍了智能农业的现状，比较了现有的解决方案，并介绍了SUSTAINABLE的关键功能，尤其是卫星指数整合、实时环境数据和针对地中海葡萄园的基于角色的任务管理。


<details>
  <summary>Details</summary>
Motivation: 全球农业部门正经历着由食品需求增加、气候变异性以及对可持续农业实践的需求所驱动的转型。传统农业面临着挑战，需要引入更智能、更可持续的技术进行升级。然而，现有的智能农业解决方案在整合性和高效性方面存有不足。因此，开发一个能够整合各个技术元素，能适应多样环境及满足精细化管理需求的智能农业平台变得尤为重要。SUSTAINABLE平台应运而生，旨在填补这一空白，特别是在葡萄种植领域的应用。

Method: 提出了一个名为SUSTAINABLE的智能农业平台，该平台集成了IoT、AI、卫星成像以及基于角色的任务编排技术。通过这三个核心技术，SUSTAINABLE实现了一套综合性解决方案，包括但不限于：卫星指数的整合，提供了更详细的作物健康监测；实时环境数据捕获，确保了精准的现场干预；基于角色的任务管理，使得不同参与者的任务分配更加高效和准确；尤其是，该平台进行了特定于地中海葡萄园的定制，增强了其在实际场景中的适应性。

Result: 通过对现有智能农业解决方案的比较分析，SUSTAINABLE平台展示了其在技术整合、环境适应性以及精细化管理方面的优势。初步试验结果表明，该平台能够在减少环境影响的同时提高农业产出质量，对于推动全球农业向更加智能、可持续的方向发展具有重要的示范意义。

Conclusion: 智能农业是应对未来农业挑战的关键，特别是考虑到全球人口增长、资源有限以及气候变化等因素。SUSTAINABLE平台利用前沿技术提供了一种解决农业可持续性问题的新路径，特别是针对特定作物类型（如葡萄）的应用，展现出显著的潜力。此外，本研究还强调了跨学科合作的重要性，指出了智能农业科技在推广和应用过程中可能面临的挑战和机遇。

Abstract: The global agricultural sector is undergoing a transformative shift, driven
by increasing food demands, climate variability and the need for sustainable
practices. SUSTAINABLE is a smart farming platform designed to integrate IoT,
AI, satellite imaging, and role-based task orchestration to enable efficient,
traceable, and sustainable agriculture with a pilot usecase in viticulture.
This paper explores current smart agriculture solutions, presents a comparative
evaluation, and introduces SUSTAINABLE's key features, including satellite
index integration, real-time environmental data, and role-aware task management
tailored to Mediterranean vineyards.

</details>


### [68] [Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models](https://arxiv.org/abs/2510.27009)
*Jared Junkin,Samuel Nathanson*

Main category: cs.AI

TL;DR: 本文研究了在具有空间或关系结构的数据上使用因果屏蔽是否可行，并通过国际象棋这一同时支持空间和序列表示的领域进行了验证。结果表明，在空间数据上使用因果屏蔽训练语言模型在某些领域甚至更优于序列化方法。


<details>
  <summary>Details</summary>
Motivation: 传统上语言模型的设计基于因果屏蔽。然而，在具有空间或关系结构的领域中，因果屏蔽被认为不合适且引入了信息损失。该研究旨在探讨因果屏蔽在非序列数据上适用性的问题，并选择国际象棋作为研究对象，因为它同时支持空间的数据形式（如棋盘状态）和序列化数据形式（如下一步行动序列）

Method: 文章在国际象棋领域中，使用空间棋盘状态和序列化动作数据，分别训练使用双向和因果屏蔽机制的模型。然后进行对比实验来提出因果屏蔽在空间数据上的训练是否可行且效果如何。旨在探索因果屏蔽方法对于单模态LLM（语言模型）在空间数据上的适用性，并验证因果屏蔽是否可能优于序列化进行训练的方式。

Result: 实验结果表明，即使在空间棋盘状态上应用因果屏蔽方法，所训练出的模型也能更强地体现出下棋的强度或能力，这表明因果屏蔽在空间数据上的训练是可行的，可能甚至是优于序列化数据进行模型训练的

Conclusion: 这次研究不仅揭示了因果屏蔽在空间数据上的训练具有可行性，同时也表明在某些情况下，这种方法可能是优于序列化数据的方法。尽管研究主要集中在国际象棋领域，但研究方法可能适用于更广泛的数据库和应用场景。

Abstract: Language models are traditionally designed around causal masking. In domains
with spatial or relational structure, causal masking is often viewed as
inappropriate, and sequential linearizations are instead used. Yet the question
of whether it is viable to accept the information loss introduced by causal
masking on nonsequential data has received little direct study, in part because
few domains offer both spatial and sequential representations of the same
dataset. In this work, we investigate this issue in the domain of chess, which
naturally supports both representations. We train language models with
bidirectional and causal self-attention mechanisms on both spatial
(board-based) and sequential (move-based) data. Our results show that models
trained on spatial board states - \textit{even with causal masking} -
consistently achieve stronger playing strength than models trained on
sequential data. While our experiments are conducted on chess, our results are
methodological and may have broader implications: applying causal masking to
spatial data is a viable procedure for training unimodal LLMs on spatial data,
and in some domains is even preferable to sequentialization.

</details>


### [69] [e1: Learning Adaptive Control of Reasoning Effort](https://arxiv.org/abs/2510.27042)
*Michael Kleinman,Matthew Trager,Alessandro Achille,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: 我们提出了一种自适应强化学习方法——自适应努力控制，它允许用户根据任务难度动态调整推理成本与准确性之间的权衡。这种方法消除了数据集和阶段特定调整的需求，并且在减少推理链长度的同时保持或提高了性能。


<details>
  <summary>Details</summary>
Motivation: 当前的方法要求用户指定确切的令牌数量，这对于用户而言难度较大，因为这需要他们预先知道问题的难度，这限制了用户对于消耗成本和获得结果之间平衡的控制。因此，我们提出了一种新的方法来解决这个问题，以更好地利用时间，成本和质量之间的权衡关系。 

Method: 我们提出了自适应努力控制，这是一种自我适应的强化学习方法，允许用户根据当前平均推理步骤长度来动态调整推理预算，用户可以在推理时通过一个连续的努力参数来动态调整成本准确性的权衡。 

Result: 我们的方法无需进行特定的数据集或阶段特定调校，同时比标准方法产生更好的成本-准确性权衡曲线，研究表明这种方法能够将思考链长度减少约3倍，同时保持或提高与用于强化学习训练的基础模型相比的性能。 

Conclusion: 通过引入自适应的努力控制方法，我们在减少推理资源使用量的同时也提高了模型效率和用户体验。

Abstract: Increasing the thinking budget of AI models can significantly improve
accuracy, but not all questions warrant the same amount of reasoning. Users may
prefer to allocate different amounts of reasoning effort depending on how they
value output quality versus latency and cost. To leverage this tradeoff
effectively, users need fine-grained control over the amount of thinking used
for a particular query, but few approaches enable such control. Existing
methods require users to specify the absolute number of desired tokens, but
this requires knowing the difficulty of the problem beforehand to appropriately
set the token budget for a query. To address these issues, we propose Adaptive
Effort Control, a self-adaptive reinforcement learning method that trains
models to use a user-specified fraction of tokens relative to the current
average chain-of-thought length for each query. This approach eliminates
dataset- and phase-specific tuning while producing better cost-accuracy
tradeoff curves compared to standard methods. Users can dynamically adjust the
cost-accuracy trade-off through a continuous effort parameter specified at
inference time. We observe that the model automatically learns to allocate
resources proportionally to the task difficulty and, across model scales
ranging from 1.5B to 32B parameters, our approach enables approximately 3x
reduction in chain-of-thought length while maintaining or improving performance
relative to the base model used for RL training.

</details>


### [70] [Glia: A Human-Inspired AI for Automated Systems Design and Optimization](https://arxiv.org/abs/2510.27176)
*Pouya Hamadanian,Pantea Karimi,Arash Nasr-Esfahany,Kimia Noorbakhsh,Joseph Chandler,Ali ParandehGheibi,Mohammad Alizadeh,Hari Balakrishnan*

Main category: cs.AI

TL;DR: Glia, an AI architecture for designing computer systems, can autonomously generate new algorithms that perform at human-expert levels and provide novel insights.


<details>
  <summary>Details</summary>
Motivation: The goal is to determine if an AI can design mechanisms for computer systems as effectively and creatively as human experts.

Method: Glia utilizes large language models in a multi-agent workflow designed to reason, experiment, and analyze. It generates interpretable designs and exposes its reasoning process.

Result: When applied to a distributed GPU cluster, Glia produced algorithms for request routing, scheduling, and auto-scaling that matched human expert performance and offered unique insights.

Conclusion: The study suggests that combining reasoning LLMs with structured experimentation allows AI to create creative and understandable designs for complex systems.

Abstract: Can an AI autonomously design mechanisms for computer systems on par with the
creativity and reasoning of human experts? We present Glia, an AI architecture
for networked systems design that uses large language models (LLMs) in a
human-inspired, multi-agent workflow. Each agent specializes in reasoning,
experimentation, and analysis, collaborating through an evaluation framework
that grounds abstract reasoning in empirical feedback. Unlike prior
ML-for-systems methods that optimize black-box policies, Glia generates
interpretable designs and exposes its reasoning process. When applied to a
distributed GPU cluster for LLM inference, it produces new algorithms for
request routing, scheduling, and auto-scaling that perform at human-expert
levels in significantly less time, while yielding novel insights into workload
behavior. Our results suggest that by combining reasoning LLMs with structured
experimentation, an AI can produce creative and understandable designs for
complex systems problems.

</details>


### [71] [Fints: Efficient Inference-Time Personalization for LLMs with Fine-Grained Instance-Tailored Steering](https://arxiv.org/abs/2510.27206)
*Kounianhua Du,Jianxing Liu,Kangning Zhang,Wenxiang Jiao,Yuan Lu,Jiarui Jin,Weiwen Liu,Yong Yu,Weinan Zhang*

Main category: cs.AI

TL;DR: 提出了一种基于样本级别的干扰向量动态生成，并将其注入模型前向传播的个性化适应框架，该框架具有高灵活性和数据效率，在快速变化的分布和高数据稀疏场景中有良好表现。该方法易于与其他个性化技术兼容，实验结果表明其在多场景下具有优秀的个性化性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对现有个性化方法在处理动态用户模式和高数据稀疏情况下的低适应性和数据效率问题，提出了一种新的个性化适应框架，实现在快速变化的环境下高效精准的个性化适应。

Method: 设计了一个细粒度的导引组件，通过捕捉注意力和MLP层激活信号中的细微信号，同时引入一个输入感知聚合模块来合成这些信号，从而生成上下文相关的个性化增强信息。此方法具有高灵活性和数据效率，可与现有个性化方法兼容，作为一个插件组件工作。

Result: 实验结果展示了该方法在快速变换分布和高数据稀疏环境中的高效个性化性能，同时也证明了其在多种交互模式和上下文长度下的鲁棒性。代码在GitHub上开源。

Conclusion: 本研究创新性地提出了一种能够处理动态用户模式和高数据稀疏的问题的个性化适应方法，通过动态生成样本级别的干扰向量，注入模型前向传播，实现了高效的个性化适应，并且与现有方法兼容。

Abstract: The rapid evolution of large language models (LLMs) has intensified the
demand for effective personalization techniques that can adapt model behavior
to individual user preferences. Despite the non-parametric methods utilizing
the in-context learning ability of LLMs, recent parametric adaptation methods,
including personalized parameter-efficient fine-tuning and reward modeling
emerge. However, these methods face limitations in handling dynamic user
patterns and high data sparsity scenarios, due to low adaptability and data
efficiency. To address these challenges, we propose a fine-grained and
instance-tailored steering framework that dynamically generates sample-level
interference vectors from user data and injects them into the model's forward
pass for personalized adaptation. Our approach introduces two key technical
innovations: a fine-grained steering component that captures nuanced signals by
hooking activations from attention and MLP layers, and an input-aware
aggregation module that synthesizes these signals into contextually relevant
enhancements. The method demonstrates high flexibility and data efficiency,
excelling in fast-changing distribution and high data sparsity scenarios. In
addition, the proposed method is orthogonal to existing methods and operates as
a plug-in component compatible with different personalization techniques.
Extensive experiments across diverse scenarios--including short-to-long text
generation, and web function calling--validate the effectiveness and
compatibility of our approach. Results show that our method significantly
enhances personalization performance in fast-shifting environments while
maintaining robustness across varying interaction modes and context lengths.
Implementation is available at https://github.com/KounianhuaDu/Fints.

</details>


### [72] [Reinforcement Learning for Long-Horizon Unordered Tasks: From Boolean to Coupled Reward Machines](https://arxiv.org/abs/2510.27329)
*Kristina Levina,Nikolaos Pappas,Athanasios Karapantelakis,Aneta Vulgarakis Feljan,Jendrik Seipp*

Main category: cs.AI

TL;DR: 本文提出三种扩展的奖励机器来应对长时间线且子任务无序的强化学习问题。方法是Q学习结合扩展的奖励机器（CoRM）。结果表明，CoRM比现有最优算法在长时段和无序子任务的问题上表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励机器在处理长时间线并且子任务无序问题上有局限，导致学习效率低下。因此本文希望通过扩展奖励机器来改善这一限制。

Method: 提出了三种扩展的奖励机器以及一个新的组合学习算法：CoRM。

Result: 新算法CoRM在长时间线和无序子任务的问题上优于现有最优算法。

Conclusion: 研究展示了如何通过扩展奖励机器和组合算法应对长时间线且子任务无序的问题，这对复杂环境中学习任务有重要影响。

Abstract: Reward machines (RMs) inform reinforcement learning agents about the reward
structure of the environment. This is particularly advantageous for complex
non-Markovian tasks because agents with access to RMs can learn more
efficiently from fewer samples. However, learning with RMs is ill-suited for
long-horizon problems in which a set of subtasks can be executed in any order.
In such cases, the amount of information to learn increases exponentially with
the number of unordered subtasks. In this work, we address this limitation by
introducing three generalisations of RMs: (1) Numeric RMs allow users to
express complex tasks in a compact form. (2) In Agenda RMs, states are
associated with an agenda that tracks the remaining subtasks to complete. (3)
Coupled RMs have coupled states associated with each subtask in the agenda.
Furthermore, we introduce a new compositional learning algorithm that leverages
coupled RMs: Q-learning with coupled RMs (CoRM). Our experiments show that CoRM
scales better than state-of-the-art RM algorithms for long-horizon problems
with unordered subtasks.

</details>


### [73] [Discriminative Rule Learning for Outcome-Guided Process Model Discovery](https://arxiv.org/abs/2510.27343)
*Ali Norouzifar,Wil van der Aalst*

Main category: cs.AI

TL;DR: 本文提出了一个基于控制流特征的学习可解释区别规则的方法，将具有相似可取性的轨迹分组，并在每个组内单独进行流程发现。这种方法可以在真实生活事件日志上有效隔离和可视化关键流程模式，提高流程合规性和性能分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的单一过程模型发现方法无法完全捕捉关键的行为差异，可能导致对流程结果至关重要的结构差异被忽视。通过对控制流特征进行学习，可以更好地识别和区分可取的和不可取的过程执行，进而优化流程改进。

Method: 通过学习控制流特征的可解释区别规则，将具有相似可取性的轨迹分组，并在每个组内采用独立的流程发现算法，生成更加聚焦和可解释的过程模型。

Result: 这种方法有效区分了可取的和不可取的过程执行，揭示了两者的行为驱动因素，并在多个真实生活事件日志上验证了其有效性，展示了关键流程模式的隔离和可视化效果。

Conclusion: 本文提出的基于控制流特征学习可解释区别规则的方法能够在流程改进中提供更加聚焦和可解释的过程模型，提高对流程合规性和性能分析的理解和改进效益。

Abstract: Event logs extracted from information systems offer a rich foundation for
understanding and improving business processes. In many real-world
applications, it is possible to distinguish between desirable and undesirable
process executions, where desirable traces reflect efficient or compliant
behavior, and undesirable ones may involve inefficiencies, rule violations,
delays, or resource waste. This distinction presents an opportunity to guide
process discovery in a more outcome-aware manner. Discovering a single process
model without considering outcomes can yield representations poorly suited for
conformance checking and performance analysis, as they fail to capture critical
behavioral differences. Moreover, prioritizing one behavior over the other may
obscure structural distinctions vital for understanding process outcomes. By
learning interpretable discriminative rules over control-flow features, we
group traces with similar desirability profiles and apply process discovery
separately within each group. This results in focused and interpretable models
that reveal the drivers of both desirable and undesirable executions. The
approach is implemented as a publicly available tool and it is evaluated on
multiple real-life event logs, demonstrating its effectiveness in isolating and
visualizing critical process patterns.

</details>


### [74] [An In-depth Study of LLM Contributions to the Bin Packing Problem](https://arxiv.org/abs/2510.27353)
*Julien Herrmann,Guillaume Pallez*

Main category: cs.AI

TL;DR: 该研究重新评估了大型语言模型（LLM）在数学发现中的贡献，通过详细分析由LLM生成的启发式算法，发现这些算法虽然可读，但对于领域专家来说仍然不透明。提出了针对特定箱装载问题的新算法类别，这些新算法更具解释性、效率和泛化能力。研究强调了对LLM生成输出进行严格验证和情境化的必要性，以评估其科学价值。


<details>
  <summary>Details</summary>
Motivation: 重新评估大型语言模型（LLM）在解决数学问题（例如箱装载问题）中的潜力，特别是关于这些模型生成的启发式算法对领域专家的透明度和贡献度。

Method: 详细分析了LLM生成的启发式算法的行为和可理解性（intererptability），并基于此提出了针对性的新算法。

Result: 新算法在效率、可解释性、泛化能力和实用性方面都优于原始LLM生成的启发式算法，表明原始问题实例相对简单。

Conclusion: 研究强调了对大型语言模型生成的输出进行严格验证和情境化的重要性，挑战了大型语言模型在数学发现中的贡献这一广泛观点。

Abstract: Recent studies have suggested that Large Language Models (LLMs) could provide
interesting ideas contributing to mathematical discovery. This claim was
motivated by reports that LLM-based genetic algorithms produced heuristics
offering new insights into the online bin packing problem under uniform and
Weibull distributions. In this work, we reassess this claim through a detailed
analysis of the heuristics produced by LLMs, examining both their behavior and
interpretability. Despite being human-readable, these heuristics remain largely
opaque even to domain experts. Building on this analysis, we propose a new
class of algorithms tailored to these specific bin packing instances. The
derived algorithms are significantly simpler, more efficient, more
interpretable, and more generalizable, suggesting that the considered instances
are themselves relatively simple. We then discuss the limitations of the claim
regarding LLMs' contribution to this problem, which appears to rest on the
mistaken assumption that the instances had previously been studied. Our
findings instead emphasize the need for rigorous validation and
contextualization when assessing the scientific value of LLM-generated outputs.

</details>


### [75] [Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints](https://arxiv.org/abs/2510.27383)
*Yueyang Wang,Mehmet Dogar,Gustav Markkula*

Main category: cs.AI

TL;DR: 研究开发了一种结合视觉和运动约束的多智能体强化学习框架，用于模拟行人与驾驶员之间的互动，此模型在行为真实度上表现最佳，并且在数据有限的情况下优于行为克隆模型。


<details>
  <summary>Details</summary>
Motivation: 当前模型依赖规则、博弈论或黑箱机器学习，缺乏灵活性，忽视人的感知和运动约束。因此，旨在开发一种新的多智能体强化学习框架来更好地模拟行人与司机的互动。

Method: 通过将视觉和运动约束整合到多智能体强化学习框架中，利用真实的行人过街数据来测试不同的模型变体，以评估行为真实度。

Result: 实验结果表明，同时包含视觉和运动约束的模型表现最佳。具有运动约束的模型引导智能体产生平滑运动，更接近人类速度调整。视觉约束引入了感知不确定性和视野限制，使得智能体行为更加谨慎和变化。

Conclusion: 在数据有限的情况下，该模型优于行为克隆模型，表明这种方法可以在没有大量训练数据的情况下有效工作。研究还首次通过公共群体分布来建模人类约束中控制参数的个体差异，展示了多智能体强化学习结合人类约束在模拟真实道路用户互动中的潜力。

Abstract: Modelling pedestrian-driver interactions is critical for understanding human
road user behaviour and developing safe autonomous vehicle systems. Existing
approaches often rely on rule-based logic, game-theoretic models, or
'black-box' machine learning methods. However, these models typically lack
flexibility or overlook the underlying mechanisms, such as sensory and motor
constraints, which shape how pedestrians and drivers perceive and act in
interactive scenarios. In this study, we propose a multi-agent reinforcement
learning (RL) framework that integrates both visual and motor constraints of
pedestrian and driver agents. Using a real-world dataset from an unsignalised
pedestrian crossing, we evaluate four model variants, one without constraints,
two with either motor or visual constraints, and one with both, across
behavioural metrics of interaction realism. Results show that the combined
model with both visual and motor constraints performs best. Motor constraints
lead to smoother movements that resemble human speed adjustments during
crossing interactions. The addition of visual constraints introduces perceptual
uncertainty and field-of-view limitations, leading the agents to exhibit more
cautious and variable behaviour, such as less abrupt deceleration. In this
data-limited setting, our model outperforms a supervised behavioural cloning
model, demonstrating that our approach can be effective without large training
datasets. Finally, our framework accounts for individual differences by
modelling parameters controlling the human constraints as population-level
distributions, a perspective that has not been explored in previous work on
pedestrian-vehicle interaction modelling. Overall, our work demonstrates that
multi-agent RL with human constraints is a promising modelling approach for
simulating realistic road user interactions.

</details>


### [76] [DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains](https://arxiv.org/abs/2510.27419)
*Tian Liang,Wenxiang Jiao,Zhiwei He,Jiahao Xu,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: 提出了一种新的框架DeepCompress，该框架通过自适应长度奖励机制，同时提高LRMs的准确性和效率，特别是在处理难题时鼓励更深入的思考链条，从而在不牺牲准确性的情况下提高效率。实验表明，DeepCompress在数学基准测试中优于基线方法，同时提高了准确性和token效率。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的方法（如SFT或RL）在提高LRMs效率的同时牺牲了准确性。DeepCompress旨在解决这一问题，通过调整逻辑推理路径的长度，来同时提高准确性和效率。

Method: DeepCompress采用了一种自适应长度奖励机制，实时将问题分类为“简单”或“困难”问题，对于简单的问题鼓励更短的推理路径，对于困难的问题鼓励更长的、更具探索性的思考链条。这使模型能够根据问题的难度动态调整其思考链条的长度，从而提高准确性和效率。

Result: 实验在数学基准测试上展示了该方法的有效性：DeepCompress在不降低准确性的前提下，提高了token效率，优越于现有的基线方法。

Conclusion: DeepCompress有效地解决了当前方法在提高效率时准确性下降的问题，通过动态调整思考链条的长度，确保模型在面对各种问题时都能展现最佳性能。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive capabilities but
suffer from cognitive inefficiencies like ``overthinking'' simple problems and
``underthinking'' complex ones. While existing methods that use supervised
fine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can
improve efficiency, they often do so at the cost of accuracy. This paper
introduces \textbf{DeepCompress}, a novel framework that simultaneously
enhances both the accuracy and efficiency of LRMs. We challenge the prevailing
approach of consistently favoring shorter reasoning paths, showing that longer
responses can contain a broader range of correct solutions for difficult
problems. DeepCompress employs an adaptive length reward mechanism that
dynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on
the model's evolving capability. It encourages shorter, more efficient
reasoning for ``Simple'' problems while promoting longer, more exploratory
thought chains for ``Hard'' problems. This dual-reward strategy enables the
model to autonomously adjust its Chain-of-Thought (CoT) length, compressing
reasoning for well-mastered problems and extending it for those it finds
challenging. Experimental results on challenging mathematical benchmarks show
that DeepCompress consistently outperforms baseline methods, achieving superior
accuracy while significantly improving token efficiency.

</details>


### [77] [GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language](https://arxiv.org/abs/2510.27448)
*Yuhao Zhang,Dingxin Hu,Tinghao Yu,Hao Liu,Yiting Liu*

Main category: cs.AI

TL;DR: 提出了GeoFM，一种用于合成几何数据的新方法，能够生成高保真度且正确的几何问题，实验显示此方法在解决几何问题上超越了现有模型和GPT-4o模型。


<details>
  <summary>Details</summary>
Motivation: 当前生成合成几何数据的方法容易产生缺乏多样性或带有噪音的数据，且合成的几何图与真实几何图差异大。为了解决这些问题，提出了GeoFM这种方法。

Method: GeoFM采用形式语言在度量空间中探索条件组合，利用符号引擎来确保生成的几何问题正确无误。

Result: 实验结果显示：采用新方法生成的数据在解决几何问题方面显著优于现有的模型，超出GPT-4o模型在MathVista上的几何问题解决任务18.7%，在GeoQA上的几何问题解决任务16.5%，并超过了一个领先的开源模型在MathVista上的表现5.7%，在GeoQA上的表现2.7%。

Conclusion: 通过此方法生成的几何数据显著优于当前的生成方式，极大地提高了模型解决几何问题的能力。

Abstract: Multi-modal Large Language Models (MLLMs) have gained significant attention
in both academia and industry for their capabilities in handling multi-modal
tasks. However, these models face challenges in mathematical geometric
reasoning due to the scarcity of high-quality geometric data. To address this
issue, synthetic geometric data has become an essential strategy. Current
methods for generating synthetic geometric data involve rephrasing or expanding
existing problems and utilizing predefined rules and templates to create
geometric images and problems. However, these approaches often produce data
that lacks diversity or is prone to noise. Additionally, the geometric images
synthesized by existing methods tend to exhibit limited variation and deviate
significantly from authentic geometric diagrams. To overcome these limitations,
we propose GeoFM, a novel method for synthesizing geometric data. GeoFM uses
formal languages to explore combinations of conditions within metric space,
generating high-fidelity geometric problems that differ from the originals
while ensuring correctness through a symbolic engine. Experimental results show
that our synthetic data significantly outperforms existing methods. The model
trained with our data surpass the proprietary GPT-4o model by 18.7\% on
geometry problem-solving tasks in MathVista and by 16.5\% on GeoQA.
Additionally, it exceeds the performance of a leading open-source model by
5.7\% on MathVista and by 2.7\% on GeoQA.

</details>


### [78] [Mechanics of Learned Reasoning 1: TempoBench, A Benchmark for Interpretable Deconstruction of Reasoning System Performance](https://arxiv.org/abs/2510.27544)
*Nikolaus Holzer,William Fishell,Baishakhi Ray,Mark Santolucito*

Main category: cs.AI

TL;DR: TempoBench是一个新的诊断基准，用于系统性地分析LLM（大语言模型）的推理性能，填补了现有方法在性能和实用性上的不足。通过两项基准测试（时间轨迹评估TTE和时间因果评估TCE），它能够评估LLM理解执行复杂推理流程和进行多步骤因果推理的能力。研究发现，模型在TCE-normal中的得分是65.6%，但在TCE-hard中的得分为7.5%，这表明现有技术在复杂系统中的表现不佳。相关代码已开源在GitHub上。


<details>
  <summary>Details</summary>
Motivation: 为了改进LLM的推理能力，现有的方法存在不足。基于此，设计了一个新的诊断基准TempoBench，以填补现有方法在性能和实用性上的缺口，确保其不仅能够验证推理结果，还能捕捉真实世界的决策链问题。

Method: TempoBench通过两项关键测试来评估模型的推理能力：时间轨迹评估TTE和时间因果评估TCE。前者测试模型理解并模拟给定多步骤推理系统执行的能力，后者则测试模型进行多步骤因果推理的能力以及从复杂系统中提炼因果关系的能力。

Result: 在TCE-normal任务中，模型得分达到了65.6%，表明它们理解并能合理执行该任务，但在TCE-hard任务中，得分仅为7.5%，这反映了模型在解决复杂系统问题上表现不佳。这些发现有助于揭示现有技术的薄弱环节。

Conclusion: TempoBench为研究LLM的推理能力提供了一个重要的工具，特别是在处理复杂系统和因果关系时。尽管模型在常规任务上表现出色，但在处理复杂任务时则面临挑战，这为未来研究指明了方向。

Abstract: Large Language Models (LLMs) are increasingly excelling and outpacing human
performance on many tasks. However, to improve LLM reasoning, researchers
either rely on ad-hoc generated datasets or formal mathematical proof systems
such as the Lean proof assistant. Whilst ad-hoc generated methods can capture
the decision chains of real-world reasoning processes, they may encode some
inadvertent bias in the space of reasoning they cover; they also cannot be
formally verified. On the other hand, systems like Lean can guarantee
verifiability, but are not well-suited to capture the nature of agentic
decision chain-based tasks. This creates a gap both in performance for
functions such as business agents or code assistants, and in the usefulness of
LLM reasoning benchmarks, whereby these fall short in reasoning structure or
real-world alignment. We introduce TempoBench, the first formally grounded and
verifiable diagnostic benchmark that parametrizes difficulty to systematically
analyze how LLMs perform reasoning. TempoBench uses two evaluation benchmarks
to break down reasoning ability. First, temporal trace evaluation (TTE) tests
the ability of an LLM to understand and simulate the execution of a given
multi-step reasoning system. Subsequently, temporal causal evaluation (TCE)
tests an LLM's ability to perform multi-step causal reasoning and to distill
cause-and-effect relations from complex systems. We find that models score
65.6% on TCE-normal, and 7.5% on TCE-hard. This shows that state-of-the-art
LLMs clearly understand the TCE task but perform poorly as system complexity
increases. Our code is available at our
\href{https://github.com/nik-hz/tempobench}{GitHub repository}.

</details>


### [79] [Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning](https://arxiv.org/abs/2510.27623)
*Qiusi Zhan,Hyeonjeong Ha,Rui Yang,Sirui Xu,Hanyang Chen,Liang-Yan Gui,Yu-Xiong Wang,Huan Zhang,Heng Ji,Daniel Kang*

Main category: cs.AI

TL;DR: BEAT 是一种用于在多模态大语言模型（MLLM）基础的具身智能体中注入视觉后门的框架。它通过构造多样化的训练集和引入对比触发学习（CTL），提高了后门激活的准确性和鲁棒性，攻击成功率可达到80%。同时保持了良好的正常任务性能，并能良好地泛化到分布外的触发器位置。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉引导的具身智能体存在一种新的安全风险，即视觉后门攻击，这种攻击在环境中特定对象作为触发器出现时，会持久性地执行攻击者指定的多步骤策略。BEAT旨在通过泛化能力强的训练集和对比触发学习方法来应对这一挑战，提高注入后门的成功率和鲁棒性，同时保持智能体在正常任务上的优秀表现。这种方法直接回应了MLLMs应用于实际场景前需解决的安全问题。

Method: BEAT采用了一种两阶段训练方案，首先应用监督微调（SFT）来熟悉基本任务，然后引入对比触发学习（CTL）来进一步精确化触发器的识别能力。CTL通过对比包含触发器和不含触发器的输入，强化决策边界，确保准确地激活后门。此外，BEAT通过构造包含多种场景和任务的训练集来应对触发器多样性的挑战，提高后门激活的泛化能力。

Result: 实验结果表明，BEAT可以实现高达80%的攻击成功率，并且保持强大的正常表现。特别是，与简单的SFT相比，CTL可以将后门激活的准确性提高最多39%。此外，BEAT能够成功攻击分布外的触发器位置，显示出其强大的泛化能力。这些结果表明了在MLLMs实际部署前需要解决的严重安全漏洞。

Conclusion: 针对MLLMs基础的具身智能体，BEAT提供了一种有效的方法来实现视觉后门攻击，同时保持了它的正常任务性能。该研究揭示了一个重要的未被充分探索的安全风险，并强调了开发稳健防御的必要性，以保障MLLMs在现实世界中的安全应用。

Abstract: Multimodal large language models (MLLMs) have advanced embodied agents by
enabling direct perception, reasoning, and planning task-oriented actions from
visual inputs. However, such vision driven embodied agents open a new attack
surface: visual backdoor attacks, where the agent behaves normally until a
visual trigger appears in the scene, then persistently executes an
attacker-specified multi-step policy. We introduce BEAT, the first framework to
inject such visual backdoors into MLLM-based embodied agents using objects in
the environments as triggers. Unlike textual triggers, object triggers exhibit
wide variation across viewpoints and lighting, making them difficult to implant
reliably. BEAT addresses this challenge by (1) constructing a training set that
spans diverse scenes, tasks, and trigger placements to expose agents to trigger
variability, and (2) introducing a two-stage training scheme that first applies
supervised fine-tuning (SFT) and then our novel Contrastive Trigger Learning
(CTL). CTL formulates trigger discrimination as preference learning between
trigger-present and trigger-free inputs, explicitly sharpening the decision
boundaries to ensure precise backdoor activation. Across various embodied agent
benchmarks and MLLMs, BEAT achieves attack success rates up to 80%, while
maintaining strong benign task performance, and generalizes reliably to
out-of-distribution trigger placements. Notably, compared to naive SFT, CTL
boosts backdoor activation accuracy up to 39% under limited backdoor data.
These findings expose a critical yet unexplored security risk in MLLM-based
embodied agents, underscoring the need for robust defenses before real-world
deployment.

</details>


### [80] [Validity Is What You Need](https://arxiv.org/abs/2510.27628)
*Sebastian Benthall,Andrew Clark*

Main category: cs.AI

TL;DR: 本文提出了Agentic AI的新定义，强调其作为软件交付机制的重要性，其中LLMs是可能实现有效性的技术选项之一。Agentic AI的成功依赖于最终用户和主要利益相关者的验证。


<details>
  <summary>Details</summary>
Motivation: 针对目前对Agentic AI的定义模糊不清的问题，该论文提出了一种新的现实主义定义，旨在更准确地描述Agentic AI及其在复杂企业环境中的应用价值，并探讨其成功的关键因素。

Method: 论文对Agentic AI的定义、实现方式、验证方法进行了探讨，尤其是强调了LLMs在实现Agentic AI中的潜力。

Result: 提出了Agentic AI的新定义，并指出其成功的关键在于有效的验证机制，而不是依赖于复杂的LLMs或者其他前沿技术。

Conclusion: 有效的验证机制对于Agentic AI的成功至关重要，而LLMs可能是实现这种机制的可行选项。

Abstract: While AI agents have long been discussed and studied in computer science,
today's Agentic AI systems are something new. We consider other definitions of
Agentic AI and propose a new realist definition. Agentic AI is a software
delivery mechanism, comparable to software as a service (SaaS), which puts an
application to work autonomously in a complex enterprise setting. Recent
advances in large language models (LLMs) as foundation models have driven
excitement in Agentic AI. We note, however, that Agentic AI systems are
primarily applications, not foundations, and so their success depends on
validation by end users and principal stakeholders. The tools and techniques
needed by the principal users to validate their applications are quite
different from the tools and techniques used to evaluate foundation models.
Ironically, with good validation measures in place, in many cases the
foundation models can be replaced with much simpler, faster, and more
interpretable models that handle core logic. When it comes to Agentic AI,
validity is what you need. LLMs are one option that might achieve it.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [81] [Cooperative Integrated Estimation-Guidance for Simultaneous Interception of Moving Targets](https://arxiv.org/abs/2510.26948)
*Lohitvel Gopikannan,Shashi Ranjan Kumar,Abhinav Sinha*

Main category: eess.SY

TL;DR: 提出了一个合作集成估计-制导框架，用于使用一组自主无人车辆同时拦截非机动目标。基于部分车辆装备有专用传感器来测量目标状态的假设，该框架实现了估计和制导设计的统一，并且使用了一种新的导航引导方法以及预定时间观测器和控制器来提高系统性能。


<details>
  <summary>Details</summary>
Motivation: 传统的估计方法或制导设计方法通常独立执行，而本文提出了一个将它们统一在一个合作架构中的框架，以提高目标拦截任务的效率和准确性，特别是当只有部分车辆装备有传感器时。此外，利用预定时间观测器和控制器来解决观测异质性和时间收敛的问题。

Method: 该方法使用了真实比例导航引导，通过精确到达时间公式适用于广泛的移动目标。此外，采用了预定时间观测器和控制器，使得实际目标状态的收敛性和预计到达时间的共识性能够在预定的时间内完成。

Result: 仿真结果显示，提出的框架在各种交战场景下都表现出色，证明了该方法的有效性。

Conclusion: 该研究提出了一种新的合作集成估计-制导框架，该框架通过统一估计和制导设计，并且配备了高效的时间预定观测器和控制器，显著提高了无人车辆任务的性能。

Abstract: This paper proposes a cooperative integrated estimation-guidance framework
for simultaneous interception of a non-maneuvering target using a team of
unmanned autonomous vehicles, assuming only a subset of vehicles are equipped
with dedicated sensors to measure the target's states. Unlike earlier
approaches that focus solely on either estimation or guidance design, the
proposed framework unifies both within a cooperative architecture. To
circumvent the limitation posed by heterogeneity in target observability,
sensorless vehicles estimate the target's state by leveraging information
exchanged with neighboring agents over a directed communication topology
through a prescribed-time observer. The proposed approach employs true
proportional navigation guidance (TPNG), which uses an exact time-to-go
formulation and is applicable across a wide spectrum of target motions.
Furthermore, prescribed-time observer and controller are employed to achieve
convergence to true target's state and consensus in time-to-go within set
predefined times, respectively. Simulations demonstrate the effectiveness of
the proposed framework under various engagement scenarios.

</details>


### [82] [Ferrohydrodynamic Microfluidics for Bioparticle Separation and Single-Cell Phenotyping: Principles, Applications, and Emerging Directions](https://arxiv.org/abs/2510.26950)
*Yuhao Zhang,Yong Teng,Kenan Song,Xianqiao Wang,Xianyan Chen,Yuhua Liu,Yiping Zhao,He Li,Leidong Mao,Yang Liu*

Main category: eess.SY

TL;DR: 基于铁磁流体的微流控平台在生物颗粒的分离和表型分析中显示出巨大的潜力。本文综述了最近在多尺度生物颗粒分离等方面的发展和应用，包括细胞和亚微米级的细胞外囊泡，并探讨了在生物相容性、系统通量和纳米颗粒去除方面的关键挑战以及未来的研究方向，如机器学习、3D打印和多路检测技术。这些见解为磁流体在精确诊断和细胞工程中的应用开拓了一条道路。


<details>
  <summary>Details</summary>
Motivation: 生物颗粒的分离和表型分析对于生物医学、诊断和细胞工程领域具有重要意义，基于铁磁流体的微流控平台因其非标记操作和多功能性变得越来越重要。这项研究旨在总结和探索这些平台的潜力，并讨论在实际应用中遇到的挑战和未来的机会。

Method: 本文通过回顾相关文献和研究，重点讨论了铁磁流体力学的基本原理，包括磁流体力学操作中的主导磁浮力，以及如何利用这些原理进行高分辨率的生物颗粒分离、亚细胞颗粒富集和基于物理性状的表型筛选。此外，还讨论了铁磁流体力学微流控技术的关键挑战和未来的研究方向。

Result: 文章总结了铁磁流体力学微流控平台的发展及其在生物颗粒分离、富集和表型筛选中的应用。强调了如何通过应用物理原理实现高分辨率分离和表型筛选，并讨论了改善系统通量和生物相容性的方法。通过展望机器学习、3D打印和多路检测技术，论文还提出了未来该领域发展的潜在方向。

Conclusion: 这些基于铁磁流体的微流控技术对于推进精准医学、诊断学和细胞工程技术具有重要意义。未来的技术进步可能会解决当前在系统通量和纳米颗粒去除方面的挑战，并可能通过新兴的技术如机器学习、3D打印和多路检测进一步增强这些平台的能力。

Abstract: Ferrohydrodynamic microfluidics relies on magnetic field gradients to
manipulate diamagnetic particles in ferrofluid-filled microenvironments. It has
emerged as a promising tool for label-free manipulation of bioparticles,
including their separation and phenotyping. This perspective reviews recent
progress in the development and applications of ferrofluid-based microfluidic
platforms for multiscale bioparticle separation, ranging from micron-scale
cells to submicron extracellular vesicles. We highlight the fundamental
physical principles for ferrohydrodynamic manipulation, including the dominant
magnetic buoyancy force resulting from the interaction of ferrofluids and
particles. We then describe how these principles enable high-resolution
size-based bioparticle separation, subcellular bioparticle enrichment, and
phenotypic screening based on physical traits. We also discuss key challenges
in ferrohydrodynamic microfluidics from the aspects of ferrofluid
biocompatibility, system throughput, and nanoparticle depletion. Finally, we
outline future research directions involving machine learning, 3D printing, and
multiplexed detection. These insights chart a path for advancing
ferrofluid-based technologies in precision biomedicine, diagnostics, and
cellular engineering.

</details>


### [83] [Quantifying Grid-Forming Behavior: Bridging Device-level Dynamics and System-Level Strength](https://arxiv.org/abs/2510.26953)
*Kehao Zhuang,Huanhai Xin,Verena Häberle,Xiuqiang He,Linbin Huang,Florian Dörfler*

Main category: eess.SY

TL;DR: 本文提出了一个量化grid-forming(GFM)变换器行为的新度量标准——形成指数（FI），并在系统层面提出了新的量化系统强度的测量方法，从而建立了从设备到系统层面的统一基准。


<details>
  <summary>Details</summary>
Motivation: 当前对于grid-forming技术的具体量化方法和定义尚不明确，以及GFM对系统稳定性的影响没有准确量化，导致设备层面和系统层面间存在差距。

Method: 文中从设备层面提出了一个新型度量标准——形成指数（FI），并在系统层面提出了新的量化系统强度的测量方法。同时，该方法能够连接设备层面与系统层面，证明GFM变换器可以增强系统强度。

Result: 文章提出的新方法能够提供一种统一的基准，用于GFM变换器的设计、最佳位置选择及系统稳定性评估。

Conclusion: 我们的方法为GFM变流器的作用和影响提供了一个全新的视角，并提供了一个统一的基准，以更好地理解和优化GFM变换器及其在电力系统中的作用。

Abstract: Grid-forming (GFM) technology is widely regarded as a promising solution for
future power systems dominated by power electronics. However, a precise method
for quantifying GFM converter behavior and a universally accepted GFM
definition remain elusive. Moreover, the impact of GFM on system stability is
not precisely quantified, creating a significant disconnect between device and
system levels. To address these gaps from a small-signal perspective, at the
device level, we introduce a novel metric, the Forming Index (FI) to quantify a
converter's response to grid voltage fluctuations. Rather than enumerating
various control architectures, the FI provides a metric for the converter's GFM
ability by quantifying its sensitivity to grid variations. At the system level,
we propose a new quantitative measure of system strength that captures the
multi-bus voltage stiffness, which quantifies the voltage and phase angle
responses of multiple buses to current or power disturbances. We further extend
this concept to grid strength and bus strength to identify weak areas within
the system. Finally, we bridge the device and system levels by formally proving
that GFM converters enhance system strength. Our proposed framework provides a
unified benchmark for GFM converter design, optimal placement, and system
stability assessment.

</details>


### [84] [Adaptive Control for a Physics-Informed Model of a Thermal Energy Distribution System: Qualitative Analysis](https://arxiv.org/abs/2510.26959)
*Paul Seurin,Auradha Annaswamy,Linyu Lin*

Main category: eess.SY

TL;DR: 本文提出了一种适应控制(AC)的线性系统形式化方法，用于集成能源系统(IIES)中糖醇换热器(GHX)的控制，该方法能够减少误差，并且计算开销和控制基础设施的增加很小，但是控制消耗较大，因此需要进一步研究其对物理系统的影响。


<details>
  <summary>Details</summary>
Motivation: 在集成能源系统中，由于物理机制不完全了解而引入的不确定性阻碍了系统的可靠应用。需要一种统一的方法来处理这种不确定性，以确保系统的正常运行。适应控制可能提供了一种实时处理不确定性的方法。

Method: 该方法基于先前的研究，通过量化糖醇换热器系统动态的不确定性，引入了名义模型中的四个术语的50%的误差。然后，采用线性二次调节器作为名义控制，并应用适应控制来优化控制效果。

Result: 实验发现，在线性二次调节器作为名义控制时，使用适应控制可以将相对误差和积分误差降低30%到75%，并且计算开销和控制基础设施的增加最小。但是，控制消耗显著增加。

Conclusion: 适应控制在处理集成能源系统的不确定性方面显示出潜力。然而，控制消耗是一个需要解决的重要问题。未来的研究将致力于改进线性形式的适应控制，以应对部分可观测和非线性动态的情况。

Abstract: Integrated energy systems (IES) are complex heterogeneous architectures that
typically encompass power sources, hydrogen electrolyzers, energy storage, and
heat exchangers. This integration is achieved through operating control
strategy optimization. However, the lack of physical understanding as to how
these systems evolve over time introduces uncertainties that hinder reliable
application thereof. Techniques that can accommodate such uncertainties are
fundamental for ensuring proper operation of these systems. Unfortunately, no
unifying methodology exists for accommodating uncertainties in this regard.
That being said, adaptive control (AC) is a discipline that may allow for
accommodating such uncertainties in real-time. In the present work, we derive
an AC formulation for linear systems in which all states are observable and
apply it to the control of a glycol heat exchanger (GHX) in an IES. Based on
prior research in which we quantified the uncertainties of the GHXs system
dynamics, we introduced an error of 50% on four terms of the nominal model. In
the case where a linear quadratic regulator is used as the nominal control for
the reference system, we found that employing AC can reduce the mean absolute
error and integral time absolute error by a factor of 30%-75%. This reduction
is achieved with minimal computing overhead and control infrastructure, thus
underscoring the strength of AC. However, the control effort induced is
significant, therefore warranting further study in order to estimate its impact
on a physical system. To address further challenges, including partially
observable and non-linear dynamics, enhancements of the linear formulation are
currently being developed.

</details>


### [85] [Dispatchable Current Source Virtual Oscillator Control Achieving Global Stability](https://arxiv.org/abs/2510.26977)
*Kehao Zhuang,Linbin Huang,Huanhai Xin,Xiuqiang He,Verena Häberle,Florian Dörfler*

Main category: eess.SY

TL;DR: 介绍了一种新型的可调度电流源虚拟振荡器控制（dCVOC）方案，用于电网跟随（GFL）转换器，该方案在两种方式上与可调度虚拟振荡器控制（dVOC）具有对偶性：a）电流频率通过无功功率控制生成，类似于锁相环；b）电流幅度参考通过有功功率控制生成。我们正式证明了所提出的控制在合理的电网和转换器参数条件下始终提供稳态平衡并确保全局稳定性，即使考虑低电压穿越（LVRT）和电流饱和约束情况也不例外。所提出的方法避免了低电压瞬态和弱电网不稳定，这与传统GFL控制不同。所提出控制的有效性通过高保真的电磁暂态仿真得到验证。


<details>
  <summary>Details</summary>
Motivation: 目的是通过提出一种新的调度电流源虚拟振荡器控制来处理传统GFL控制中的低电压瞬变和弱电网不稳定问题，该方法提供稳态平衡保证全局稳定性，并在LVRT和电流饱和约束条件下仍然有效。

Method: 提出了一种新型的可调度电流源虚拟振荡器控制（dCVOC）对于GFL转换器，它使用无功功率和有功功率控制方式来生成电流频率和幅度参考。其设计保证了在合理条件下始终存在稳态状态并确保全局稳定性。通过高保真的电磁暂态仿真验证了所提出方法的效果和优势。

Result: 提出的控制方案在避免低电压瞬变、弱电网不稳定的情况下，保持了稳态并提供了全局稳定性。通过高保真的电磁暂态仿真验证了该方案的有效性和其相对于传统GFL控制的优势。

Conclusion: 所提出的dCVOC方案是解决GFL转换器中低电压瞬变和弱电网不稳定问题的一个有效方法。它在合理条件下保证了稳态并提供了全局稳定性，避免了这些问题并优于传统GFL控制。

Abstract: This work introduces a novel dispatchable current source virtual oscillator
control (dCVOC) scheme for grid-following (GFL) converters, which exhibits
duality with dispatchable virtual oscillator control (dVOC) in two ways: a) the
current frequency is generated through reactive power control, similar to a PLL
; b) the current magnitude reference is generated through active power control.
We formally prove that our proposed control always admits a steady-state
equilibrium and ensures global stability under reasonable conditions on grid
and converter parameters, even when considering LVRT and current saturation
constraints. Our approach avoids low-voltage transients and weak grid
instability, which is not the case for conventional GFL control. The
effectiveness of our proposed control is verified through high-fidelity
electromagnetic transient simulations.

</details>


### [86] [Simplifying Preference Elicitation in Local Energy Markets: Combinatorial Clock Exchange](https://arxiv.org/abs/2510.27306)
*Shobhit Singhal,Lesia Mitridati*

Main category: eess.SY

TL;DR: 本文介绍了一种新的市场平台，允许用户通过简洁的方式表达他们对多种电力产品和电网支持产品的复杂偏好，提高用户参与复杂市场结构的能力。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源资源（DERs）的增加，未来电力系统需要一个新市场平台来让能源生成和消费综合起来的个体（prosumer）能够进行多种电力产品的交易，但是这些个体往往存在复杂的偏好和有限的知识资源，难以参与到复杂的市场结构中来。为了应对这一挑战，提出了新的市场平台方案。

Method: 通过融合组合式时钟拍卖和机器学习技术，本文提出了一种多产品的市场机制，仅仅需要个体报告自己愿意购买的产品组合及相关价格即可，机器学习辅助价格发现能够加速市场收敛。同时，线性定价规则增加了市场的透明度和易理解性。

Result: 数值仿真表明，在大约15个拍卖时间段后，这种新市场机制可以达到出清价格。

Conclusion: 本文提出了一种新的市场机制解决了prosumers参与现有市场时面临的挑战，能够在不增加认知负担的情况下实现复杂的市场交易。

Abstract: As distributed energy resources (DERs) proliferate, future power system will
need new market platforms enabling prosumers to trade various electricity and
grid-support products. However, prosumers often exhibit complex, product
interdependent preferences and face limited cognitive and computational
resources, hindering engagement with complex market structures and bid formats.
We address this challenge by introducing a multi-product market that allows
prosumers to express complex preferences through an intuitive format, by fusing
combinatorial clock exchange and machine learning (ML) techniques. The
iterative mechanism only requires prosumers to report their preferred package
of products at posted prices, eliminating the need for forecasting product
prices or adhering to complex bid formats, while the ML-aided price discovery
speeds up convergence. The linear pricing rule further enhances transparency
and interpretability. Finally, numerical simulations demonstrate convergence to
clearing prices in approximately 15 clock iterations.

</details>


### [87] [A Switching Strategy for Event-Trigger Control of Spacecraft Rendezvous](https://arxiv.org/abs/2510.27414)
*Tommaso Del Carro,Gerson Portilla,Alexandre Seuret,Rafael Vazquez*

Main category: eess.SY

TL;DR: 本文提出了一种基于Hill-Clohessy-Wiltshire方程的航天器对接状态反馈控制律设计，采用脉冲控制策略调节发动机操作。通过自控理论（特别是Lyapunov稳定性分析和线性矩阵不等式框架）推导了非线性控制律，并通过数值案例研究展示了该方法的有效性，与传统预测性控制方案进行了比较，展示了其优势和权衡。


<details>
  <summary>Details</summary>
Motivation: 目的是设计一种基于Hill-Clohessy-Wiltshire方程的状态反馈控制律，以实现航天器对接，并通过引入脉冲控制策略来降低总动作用次数，同时保证系统的稳定性。这种方法可以在复杂的空间环境中有效地管理发动机操作。

Method: 利用自动控制理论中的Lyapunov稳定性分析和线性矩阵不等式框架提出了一个非线性的控制方法，并通过状态依赖的切换框架确定控制输入和触发状态条件。该方法可以将控制律应用到航天器对接问题，并通过理论和数值分析验证其性能。

Result: 所提方法在数值案例研究中展示了良好的性能。与标准模型预测控制方案相比，该方法不仅稳定，而且显著减少了总的动作用次数。此外，也讨论了该方法的优点和权衡。

Conclusion: 本文提出了一种新颖的控制方法，适用于航天器的对接任务，通过采用脉冲控制策略，可以有效地减少总的动作用次数，同时保证系统的稳定性和对接过程的安全性。

Abstract: This paper presents the design of a state-feedback control law for spacecraft
rendezvous, formulated using the Hill-Clohessy-Wiltshire equations. The
proposed method introduces an impulsive control strategy to regulate thruster
operations. Specifically, a state-dependent switching framework is developed to
determine both the control input magnitudes and the precise state conditions
that trigger thruster activation. The nonlinear control law is derived using
principles from automatic control theory, particularly Lyapunov stability
analysis and the Linear Matrix Inequality framework. The resulting closed-loop
system is proven to be stable, while simultaneously minimizing the total number
of actuation events. The effectiveness of the proposed method is demonstrated
through a numerical case study, which includes a comparative analysis with a
standard Model Predictive Control scheme, highlighting the advantages and
trade-offs of the developed control structure.

</details>


### [88] [Context-Aware Stochastic Modeling of Consumer Energy Resource Aggregators in Electricity Markets](https://arxiv.org/abs/2510.27478)
*Chatum Sankalpa,Ghulam Mohy-ud-din,Erik Weyer,Maria Vrakopoulou*

Main category: eess.SY

TL;DR: 本文提出了三种处理消费者能源资源(CERs)不确定性影响的两阶段随机优化方法：风险中立、鲁棒和机会约束，适用于澳大利亚国家电力市场中的能源和调频服务市场。这些方法利用了电池存储的灵活性，并针对大场景集合采用了松弛方法。这三种方法在不同的操作和市场设置下进行了评估，以提供对聚合商在选择最具适当的随机优化方法时的指导。


<details>
  <summary>Details</summary>
Motivation: 由于消费者能源资源(CERs)，如屋顶太阳能和电池储能(BES)，由于其固有的不确定性给聚合商带来了挑战，优化方法的选择不当会导致不可行的问题或收入损失。因此，需要开发有效的随机优化方法来解决这一问题。

Method: 本文提出了三种两阶段随机优化方法：风险中立、鲁棒和机会约束方法。这些问题被形成两阶段随机混合整数线性规划问题，并针对大的场景集合采用了松弛方法。同时，采用基于场景的方法和仿射恢复策略来获得可处理的重新制定。

Result: 这三种方法在不同的操作和市场设置下进行了评估，表现出在管理不确定性、提升盈利能力方面的能力，并为聚合商提供选择最适当随机优化方法的指导。

Conclusion: 针对澳大利亚国家电力市场的能源和调节服务市场，提出了三种有效的两阶段随机优化方法，利用了电池存储的灵活性，并通过在不同的操作和市场设置的安全性和性能评估，提供了对聚合商在选择随机优化方法时的指导。

Abstract: Aggregators of consumer energy resources (CERs) like rooftop solar and
battery energy storage (BES) face challenges due to their inherent
uncertainties. A sensible approach is to use stochastic optimization to handle
such uncertainties, which can lead to infeasible problems or loss in revenues
if not chosen appropriately. This paper presents three efficient two-stage
stochastic optimization methods: risk-neutral, robust, and chance-constrained,
to address the impact of CER uncertainties for aggregators who participate in
energy and regulation services markets in the Australian National Electricity
Market. Furthermore, these methods utilize the flexibility of BES, considering
precise state-of-charge dynamics and complementarity constraints, aiming for
scalable performance while managing uncertainty. The problems are formed as
two-stage stochastic mixed-integer linear programs, with relaxations adopted
for large scenario sets. The solution approach employs scenario-based
methodologies and affine recourse policies to obtain tractable reformulations.
These methods are evaluated across use cases reflecting diverse operational and
market settings, uncertainty characteristics, and decision-making preferences,
demonstrating their ability to mitigate uncertainty, enhance profitability, and
provide context-aware guidance for aggregators in choosing the most appropriate
stochastic optimization method.

</details>


### [89] [Technical Report for Dissipativity Learning in Reproducing Kernel Hilbert Space](https://arxiv.org/abs/2510.27669)
*Xiuzhen Ye,Wentao Tang*

Main category: eess.SY

TL;DR: 本文提出了一种在再生核希尔伯特空间中学习非参数耗散性的框架，该框架能通过数据驱动的方式不需要显式动态模型就能验证未知非线性系统的稳定性性能。与之前的参数方法相比，新方法使用希尔伯特-施密特算子来表示存储函数和供给率，能够隐式地捕捉非线性。该方法通过提出基于核的支持向量机来解决优化问题，并获得有限维凸规划问题的解。最后，新方法在数值结果中显示了能够直接从输入输出数据中识别非线性耗散性行为的有效性，为模型无关控制分析和合成提供了一种强大的可解释框架。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是通过数据驱动的方式提供一种不依赖于显式动态模型的方法来验证未知非线性系统的稳定性性能。这是因为在许多情况下，建立这样的模型是困难的或是不可能的。此方法提供了一种新的途径，利用非参数框架来学习以一种不受固定矩阵限制的方式描述系统的非线性特征。同时，通过使用希尔伯特-施密特算子将这些描述变为在再生核希尔伯特空间中可处理的形态，从而可以在不牺牲凸性的前提下隐式地捕捉非线性。目标是使学习过程更加灵活，同时保持理论分析和实际应用间的一致性。

Method: 此方法在再生核希尔伯特空间(RKHS)中提出了一个用于学习耗散性的非参数框架。不同于以前的方法，该方法用希尔伯特-施密特算子来表示存储函数和供给率，被称为核函数特征。接下来，一个核支持向量机的一类问题被建立解决这个优化问题。通过表达性定理，该问题被化缩减为有限维的凸规划问题，解决了通过核Gram矩阵描述的矩阵表示。通过统计学习理论，保证了结果中的普遍性倾向，包括对耗散率和L2增益的置信边界。此外，该方法展示了直接从输入输出数据中识别非线性耗散性行为的能力。最终，该过程被给予了大量的数值确认，表明其在模型无关控制分析和合成中的有效性。

Result: 实验结果表明，该方法通过从输入输出数据中直接识别非线性耗散性行为，展示了其在模型无关控制分析和合成中的有效性。同时，该方法维护了凸性和统计学习理论提供的广义保证，包括对系统耗散率和L2增益的置信上限。这也是首次在一个非参数的、数据驱动的框架中实现这种特性。该方法提供了一种新的途径，作为当前分析和设计工具的有效补充。

Conclusion: 本文提出了一种新的方法，该方法用于在再生核希尔伯特空间中学习一般耗散性的非参数框架。该方法能够在不依赖于明确的动态模型的情况下进行稳定性性能的验证，这是模型未知情况下的关键优势。它通过将耗散性的功能在希尔伯特-施密特算子上进行优化解决。此外，该方法通过核支持向量机和统计学习理论，提供了一种灵活且可解释的框架，使得能够直接从输入输出数据中识别非线性耗散性行为。这种方法能够有力地应用于模型无关控制分析和合成中，并对未来系统的稳定性和性能提供确保证据。

Abstract: This work presents a nonparametric framework for dissipativity learning in
reproducing kernel Hilbert spaces, which enables data-driven certification of
stability and performance properties for unknown nonlinear systems without
requiring an explicit dynamic model. Dissipativity is a fundamental system
property that generalizes Lyapunov stability, passivity, and finite L2 gain
conditions through an energy balance inequality between a storage function and
a supply rate. Unlike prior parametric formulations that approximate these
functions using quadratic forms with fixed matrices, the proposed method
represents them as Hilbert Schmidt operators acting on canonical kernel
features, thereby capturing nonlinearities implicitly while preserving
convexity and analytic tractability. The resulting operator optimization
problem is formulated in the form of a one-class support vector machine and
reduced, via the representer theorem, to a finite dimensional convex program
expressed through kernel Gram matrices. Furthermore, statistical learning
theory is applied to establish generalization guarantees, including confidence
bounds on the dissipation rate and the L2 gain. Numerical results demonstrate
that the proposed RKHS based dissipativity learning method effectively
identifies nonlinear dissipative behavior directly from input output data,
providing a powerful and interpretable framework for model free control
analysis and synthesis.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [90] [Multi-hop Parallel Image Semantic Communication for Distortion Accumulation Mitigation](https://arxiv.org/abs/2510.26844)
*Bingyan Xie,Jihong Park,Yongpeng Wu,Wenjun Zhang,Tony Quek*

Main category: cs.IT

TL;DR: 提出了多跳并行图像语义通信框架（MHPSC），通过在每个跳数上引入残差补偿链路来解决多跳无线图像传输中的失真积累问题，并设计了一种粗到细的残差压缩方案来最小化传输带宽开销。实验结果表明，MHPSC在传输带宽只略有增加的情况下，优于现有的语义通信和传统的分离编码方案。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信方案主要关注单跳场景，忽略了多跳无线图像传输中的挑战。语义通信本质上具有损耗性，会导致多跳中的累积失真，从而显著降低性能。为了应对这一问题，本文提出了一种新的框架。

Method: 提出了多跳并行图像语义通信（MHPSC）框架，引入了并行残差补偿链路以减轻累积失真问题。设计了一种粗到细的残差压缩方案，以最小化传输带宽开销。采用了基于深度学习的残差压缩算法，并通过自适应算术编码进一步压缩。利用残差分布估计模块预测先验分布，使算术编码能够实现精细的压缩性能。

Result: 实验结果显示，MHPSC在只略有增加传输带宽的情况下，优于现址的语义通信和传统的分离编码方案。这种方法确保了鲁棒的多跳图像传输。

Conclusion: 提出的MHPSC框架提出了一种新的方法来解决多跳无线图像传输中的失真积累问题。

Abstract: Existing semantic communication schemes primarily focus on single-hop
scenarios, overlooking the challenges of multi-hop wireless image transmission.
As semantic communication is inherently lossy, distortion accumulates over
multiple hops, leading to significant performance degradation. To address this,
we propose the multi-hop parallel image semantic communication (MHPSC)
framework, which introduces a parallel residual compensation link at each hop
against distortion accumulation. To minimize the associated transmission
bandwidth overhead, a coarse-to-fine residual compression scheme is designed. A
deep learning-based residual compressor first condenses the residuals, followed
by the adaptive arithmetic coding (AAC) for further compression. A residual
distribution estimation module predicts the prior distribution for the AAC to
achieve fine compression performances. This approach ensures robust multi-hop
image transmission with only a minor increase in transmission bandwidth.
Experimental results confirm that MHPSC outperforms both existing semantic
communication and traditional separated coding schemes.

</details>


### [91] [Inferring the Chemotaxis Distortion Function from Cellular Decision Strategies](https://arxiv.org/abs/2510.26988)
*Fardad Vakilipoor,Johannes Konrad,Maximilian Schäfer*

Main category: cs.IT

TL;DR: 该论文应用基于速率失真理论的信息理论框架，研究了细胞在不确定性环境下如何处理环境信号并做出决策。通过逆Blahut-Arimoto算法，成功估计了细胞凋亡场景中的失真函数，并揭示了细胞在状态依赖性决策中的准则。此框架不仅适用于趋化性，还适用于需要在不确定性下高效信息处理的生物和工程系统中。


<details>
  <summary>Details</summary>
Motivation: 为了研究细胞如何在不确定性环境信号中做出准确决策，基于速率失真理论的信息理论框架被应用。通过最小化信息量与满足失真限制的方式来平衡感知准确性与资源成本。此框架可以为各种生物系统提供理论基础。

Method: 论文提出了一种逆Blahut-Arimoto算法，用来计算失真函数。该算法不仅可以准确地估计细胞凋亡过程中的理论失真函数，同时通过构建局部兴奋全局抑制模型来模拟趋化性反应，进一步从细胞视角计算了失真函数。

Result: 论文通过应用逆Blahut-Arimoto算法，成功地估计了细胞凋亡情景中的失真函数，并揭示了细胞通过感知不同的环境信号从而做出状态依赖性的决策过程。此算法对于揭示细胞响应不确定性环境的信息处理方式十分重要。

Conclusion: 该研究利用基于速率失真理论的信息理论框架，揭示了细胞在处理不确定性环境信号时的状态依赖性决策过程。此框架不仅对于趋化性研究具有重要的理论价值，对所有需在不确定性环境下做出高效信息处理的生物和工程系统也有潜在价值。

Abstract: Cellular intelligence enables cells to process environmental signals and make
context-dependent decisions, as exemplified by chemotaxis, where cells navigate
chemical gradients despite noisy signaling pathways. To investigate how cells
deal with uncertainty, we apply an information-theoretic framework based on
rate distortion theory (RDT). The Blahut-Arimoto algorithm (BAA) computes
optimal decision strategies that minimize mutual information while satisfying
distortion constraints, balancing sensing accuracy with distortion constraint
equivalent to resource cost. We propose the inverse Blahut-Arimoto algorithm
(IBAA) to compute the distortion function, which quantifies the system's
decision-making criteria for realizing a decision strategy to map input signals
to outputs. This general framework extends beyond chemotaxis to biological and
engineered systems requiring efficient information processing under
uncertainty. We validate the proposed IBAA by accurately estimating theoretical
distortion functions in a cellular apoptosis scenario. Additionally, using the
local excitation global inhibition (LEGI) model to simulate chemotactic
responses, we compute the distortion functions from the cell's perspective. Our
finding reveals a state-dependent decision criteria by the cell.

</details>


### [92] [Dual-Scale Antenna Deployment for Pinching Antenna Systems](https://arxiv.org/abs/2510.27185)
*Xu Gan,Zhaolin Wang,Yuanwei Liu*

Main category: cs.IT

TL;DR: 提出了一种用于pinching天线系统（PASS）的双尺度部署（DSD）框架。该框架包括粗略阶段的大范围波导级天线转移和精炼阶段的高精度小范围天线调整，并提出了四种部署协议。随后，根据实用的功耗模型，推导了理论的能量效率公式，并通过联合优化传输预编码，天线辐射功率和天线部署来最大化能量效率。通过仿真实验验证了理论结果的准确性和所提算法的收敛性，并展示了PASS相对于传统无蜂窝架构和MIMO系统在能量效率方面的优势以及适当地指定DSD分辨率和部署协议的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了提高复杂无线通信场景中的能量效率，需要对天线系统的部署和使用进行优化。研究提出了一种新的天线部署框架，并推导出能量效率的相关公式和算法，用以提升PASS的能量效率。原文动机旨在通过优化天线部署和使用，提高无线通信的能量效率，尤其是在传统架构和MIMO系统的限制下。此外，还探讨了DSD分辨率和部署协议的选定对于能量效率最大化的关键性。

Method: 提出了一种包含两个阶段的DSD框架：首先，在粗略阶段，天线在大范围内波导级别上转移。随后，在细密阶段，精确的天线位置调整在更大的近乎瞬时尺度上演化。文中提供了四个PASS的天线部署协议。基于实际的功耗模型推导出能量效率的理论公式。通过联合优化预编码、天线辐射功率和天线配置，实现能量效率的最大化。针对提出的非凸、高度耦合优化问题，提出了一种低复杂度的惩罚交替优化方法。该算法通过迭代优化逐步逼近最优解，并通过仿真证明了理论有效性和算法收敛性。

Result: 仿真实验验证了理论推导的能量效率公式和提出的算法的有效性和收敛性。在对比实验中，PASS比传统无蜂窝架构具有约70%更高的能量效率，比MIMO系统几乎提高了一倍。研究还证明了适当地指定DSD分辨率和部署协议对PASS实现最大能量效率的重要性。

Conclusion: 本文创新性地提出了DSD框架以及相关的PASS优化协议和算法，显著提高了无线通信的能量效率特别是相对于传统无蜂窝和MIMO架构。同时也揭示了正确指定DSD分辨率和部署协议对能量效率提升的重要性。

Abstract: A dual-scale deployment (DSD) framework for pinching antenna systems (PASS)
is proposed. 1) In the first coarse stage, the pinching antenna (PA) is
transferred over a large-scale range at the waveguide level. 2) The refinement
stage performs small-scale relocation of the PA with high precision. Four PA
deployment protocols are provided in the proposed DSD framework. Then, a
practical power consumption model is proposed, based on which the theoretical
energy efficiency formulas for PASS are derived. The transmit precoding, PA
radiation power, and PA deployment are jointly optimized to maximize the energy
efficiency under the provided PA deployment protocols. To solve this
non-convex, highly coupled problem, a low-complexity penalty-based alternating
optimization algorithm is proposed. Simulation results validate the accuracy of
theoretical results and the convergence of the proposed algorithm. It is
demonstrated that: 1) PASS delivers about 70% higher energy efficiency than the
conventional cell-free architecture and nearly twofold improvement relative to
MIMO systems; 2) it is essential to specify the DSD resolution and deployment
protocol to achieve the maximum energy efficiency for PASS.

</details>


### [93] [Weight Enumerators From Equivalence Relations and MacWilliams Identities](https://arxiv.org/abs/2510.27358)
*S. T. Dougherty,C. Fernández-Córdoba*

Main category: cs.IT

TL;DR: 本文研究了有限域、有限阿贝尔群和有限Frobenius环上的编码问题，并探讨了完全重量枚举器、汉明重量枚举器和一些特定等价关系下的重量枚举器的MacWilliams关系成立的条件。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和应用有限域、有限阿贝尔群和有限Frobenius环上的编码问题，研究了重量枚举器的MacWilliams关系在不同等价关系下的性质。

Method: 定义了编码关于等价关系的重量枚举器，并研究了其在特定等价关系下的MacWilliams关系。

Result: 给出了几个特定的等价关系下，重量枚举器的MacWilliams关系成立的条件。

Conclusion: 该研究丰富了编码理论在有限域、有限阿贝尔群和有限Frobenius环上的理解，为进一步的应用提供了理论基础。

Abstract: In this paper, we consider codes over finite fields, finite abelian groups,
and finite Frobenius rings. For such codes, the complete weight enumerator and
the Hamming weight enumerator serve as powerful tools. These two types of
weight enumerators satisfy the MacWilliams relations. We define the weight
enumerator of a code with respect to an equivalence relation and determine in
which cases the MacWilliams relations hold for this weight enumerator. We also
study some weight enumerators for specific equivalence relations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [94] [Layer of Truth: Probing Belief Shifts under Continual Pre-Training Poisoning](https://arxiv.org/abs/2510.26829)
*Svetlana Churina,Niranjan Chebrolu,Kokil Jaidka*

Main category: cs.LG

TL;DR: 研究者引入了一种名为Layer of Truth的新框架，旨在探索大型语言模型在持续训练过程中相信编造信息的能力。实验发现，即使少量的编造数据也能导致模型在某些事实上的表征漂移。这揭示了持续更新的大型语言模型的一个未被重视的弱点——它们有能力类比人类的方式内化错误信息，这强调了在模型更新过程中保持事实完整性的需求。


<details>
  <summary>Details</summary>
Motivation: 研究者受到人类认知中'虚假真理效应'的启发，探索大型语言模型在持续训练过程中是否也会因重复接触错误信息而吸收这些信息，产生信仰偏差。

Method: 研究者引入了Layer of Truth框架，通过注入受控数量的中毒数据，并分析不同模型规模、检查点、问题类型下的中间表示，来量化事实信念何时以及如何发生变化。

Result: 研究发现，即使是少量的中毒数据也能导致模型在某些广泛接受的事实上的持久性表征漂移，且这种易感性在各个层次和模型规模间存在差异。

Conclusion: 研究结果揭示了持续更新的大型语言模型的一个未被重视的弱点，即类似于人类的方式，模型有能力内化错误信息，这强调了在模型更新过程中需要加强对其事实完整性的监控。

Abstract: Large language models (LLMs) continually evolve through pre-training on
ever-expanding web data, but this adaptive process also exposes them to subtle
forms of misinformation. While prior work has explored data poisoning during
static pre-training, the effects of such manipulations under continual
pre-training remain largely unexplored. Drawing inspiration from the illusory
truth effect in human cognition - where repeated exposure to falsehoods
increases belief in their accuracy - we ask whether LLMs exhibit a similar
vulnerability. We investigate whether repeated exposure to false but
confidently stated facts can shift a model's internal representation away from
the truth.
  We introduce Layer of Truth, a framework and dataset for probing belief
dynamics in continually trained LLMs. By injecting controlled amounts of
poisoned data and probing intermediate representations across checkpoints,
model scales, and question types, we quantify when and how factual beliefs
shift. Our findings reveal that even minimal exposure can induce persistent
representational drift in well-established facts, with susceptibility varying
across layers and model sizes. These results highlight an overlooked
vulnerability of continually updated LLMs: their capacity to internalize
misinformation analogously to humans, underscoring the need for robust
monitoring of factual integrity during model updates.

</details>


### [95] [SmoothGuard: Defending Multimodal Large Language Models with Noise Perturbation and Clustering Aggregation](https://arxiv.org/abs/2510.26830)
*Guangzhi Su,Shuchang Huang,Yutong Ke,Zhuohang Liu,Long Qian,Kaizhu Huang*

Main category: cs.LG

TL;DR: 本研究提出了SmoothGuard，一种增强多模态大语言模型(MLLMs)对抗攻击鲁棒性的轻量级、模型无关的防御框架。通过随机噪声注入和基于嵌入的聚类预测聚合，SmoothGuard在保持模型性能的同时提高了对抗攻击的抵抗力。实验表明，在POPE，LLaVA-Bench和MM-SafetyBench上，SmoothGuard在对抗攻击下保持了较高的模型稳定性和实用性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在处理文本和视觉输入任务时表现优异，但它们对对抗性操作非常敏感，这限制了它们在实际应用中的安全性和可靠性。SmoothGuard旨在提高MLLMs的安全性和鲁棒性，同时保持其实用性和性能。

Method: SmoothGuard通过高斯噪声注入到连续模式（例如，图像和音频）中，生成多个候选输出，并使用基于嵌入的聚类滤除对抗性影响的预测。最终选择来自多数簇的答案，确保在恶意干扰下保持稳定的响应。

Result: 实验表明，SmoothGuard能够显著提高MLLMs在对抗攻击下的鲁棒性，同时保持竞争力的实用性和性能。噪声范围0.1-0.2被确定为在保护鲁棒性的同时保持性能的平衡点。

Conclusion: 该研究成功地将SmoothGuard作为一种增强MLLMs对抗攻击鲁棒性的有效且轻量级的防御方法验证，提升了模型在实际部署中的安全性和可靠性。

Abstract: Multimodal large language models (MLLMs) have achieved impressive performance
across diverse tasks by jointly reasoning over textual and visual inputs.
Despite their success, these models remain highly vulnerable to adversarial
manipulations, raising concerns about their safety and reliability in
deployment. In this work, we first generalize an approach for generating
adversarial images within the HuggingFace ecosystem and then introduce
SmoothGuard, a lightweight and model-agnostic defense framework that enhances
the robustness of MLLMs through randomized noise injection and clustering-based
prediction aggregation. Our method perturbs continuous modalities (e.g., images
and audio) with Gaussian noise, generates multiple candidate outputs, and
applies embedding-based clustering to filter out adversarially influenced
predictions. The final answer is selected from the majority cluster, ensuring
stable responses even under malicious perturbations. Extensive experiments on
POPE, LLaVA-Bench (In-the-Wild), and MM-SafetyBench demonstrate that
SmoothGuard improves resilience to adversarial attacks while maintaining
competitive utility. Ablation studies further identify an optimal noise range
(0.1-0.2) that balances robustness and utility.

</details>


### [96] [Accurate Target Privacy Preserving Federated Learning Balancing Fairness and Utility](https://arxiv.org/abs/2510.26841)
*Kangkang Sun,Jun Wu,Minyi Guo,Jianhua Li,Jianwei Huang*

Main category: cs.LG

TL;DR: 提出了名为FedPF的联邦学习算法，该算法同时考虑了隐私保护和公平性。理论分析揭示了隐私保护与消除人口统计学偏差之间存在意外的反比关系。实验表明，在维护较准确的同时，可以减少多达42.9%的歧视现象，但是要在隐私保护与公平性之间找到平衡是不可避免的，并且它们不能单独优化。代码已经开源。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，参与者需要同时确保不同人口群体之间的公平性并保护敏感数据的隐私，而这是有挑战性的。因此，提出了一种新的差异化隐私公平联邦学习算法FedPF。

Method: 通过将多目标优化转换为零和博弈形式，以确保隐私和公平之间的竞争存在。在此模式下，更严格的隐私保护会限制检测和纠正人口统计学偏差的能力，从而产生内在的隐私和公平间的矛盾。该博弈展示了非单调关系，这挑战了传统的公平性-使用率之间的权衡观念。FedPF利用此理论进行模型训练，同时考虑隐私保护和公平性问题。

Result: 在三个数据集上，证明了适度的公平性约束最初能够改善模型推广，但过度严格反而会导致性能下降。尽管存在隐私与公平性之间的固有紧张，但该方法可以在减少高达42.9%歧视的情况下，保持较准确。实验结果挑战了传统的公平性-使用率间的平衡观念，同时展示了在隐私与公平性之间做出妥协的重要性。

Conclusion: 通过揭示差别隐私保护和公平性之间的复杂关系，FedPF指出了解决联邦学习中隐私与公平性之间紧张关系的方法是必需的，而不仅仅是独立地优化一个目标。

Abstract: Federated Learning (FL) enables collaborative model training without data
sharing, yet participants face a fundamental challenge, e.g., simultaneously
ensuring fairness across demographic groups while protecting sensitive client
data. We introduce a differentially private fair FL algorithm (\textit{FedPF})
that transforms this multi-objective optimization into a zero-sum game where
fairness and privacy constraints compete against model utility. Our theoretical
analysis reveals a surprising inverse relationship, i.e., stricter privacy
protection fundamentally limits the system's ability to detect and correct
demographic biases, creating an inherent tension between privacy and fairness.
Counterintuitively, we prove that moderate fairness constraints initially
improve model generalization before causing performance degradation, where a
non-monotonic relationship that challenges conventional wisdom about
fairness-utility tradeoffs. Experimental validation demonstrates up to 42.9 %
discrimination reduction across three datasets while maintaining competitive
accuracy, but more importantly, reveals that the privacy-fairness tension is
unavoidable, i.e., achieving both objectives simultaneously requires carefully
balanced compromises rather than optimization of either in isolation. The
source code for our proposed algorithm is publicly accessible at
https://github.com/szpsunkk/FedPF.

</details>


### [97] [CAS-Spec: Cascade Adaptive Self-Speculative Decoding for On-the-Fly Lossless Inference Acceleration of LLMs](https://arxiv.org/abs/2510.26843)
*Zhiyuan Ning,Jiawei Shao,Ruge Xu,Xinfei Guo,Jun Zhang,Chi Zhang,Xuelong Li*

Main category: cs.LG

TL;DR: 提出了一种名为 Cascade Adaptive Self-Speculative Decoding (CAS-Spec) 的新方法，该方法通过利用动态可切换的推理加速策略（如层稀疏化和激活量化）来构建推测性草稿模型，并引入了适应性地路由多级草稿模型的Dynamic Tree Cascade (DyTC) 算法。这种方法在各种LLMs和数据集上实现了1.1倍到2.3倍的加速，相较于现有的推测性方法具有州-of-the-art的加速效果。DyTC算法相较于基于cascade和基于树的基线算法分别提高了47%和48%的平均加速率。此方法可以被大多数现有LLMs容易地集成，并具有进一步加速的可能性。


<details>
  <summary>Details</summary>
Motivation: 当前的推测性解码方法在速度提升上遇到瓶颈，尤其是在训练多个模型时成本高，从而限制了实用性。为了实现更好的加速效果，提出了一种新的方法CAS-Spec及其适应性路由算法DyTC，以克服传统方法的不足。

Method: Cas-Spec方法通过利用DSIA策略（包括层稀疏化和激活量化）构建推测性草稿模型，并利用DyTC算法根据接受率和延迟预测自适应路由多级草稿模型来动态分配草稿长度。这种组合可以提高解码速度和灵活性，同时减少计算资源的消耗。

Result: 实验结果表明，Cas-Spec方法相比于现有推测性解码方法取得了优于现有州-of-the-art的加速效果，通过使用DyTC算法，平均加速比现有cascade和树基线算法分别提高了47%和48%。这证明了 CAS-Spec 方法的有效性。

Conclusion: 该研究提出的方法通过引入DSIA策略和DyTC算法，成功实现了高效加速，这表明该方法在提高大语言模型的预测速度方面具有潜在的应用价值和前景。

Abstract: Speculative decoding has become a widely adopted as an effective technique
for lossless inference acceleration when deploying large language models
(LLMs). While on-the-fly self-speculative methods offer seamless integration
and broad utility, they often fall short of the speed gains achieved by methods
relying on specialized training. Cascading a hierarchy of draft models promises
further acceleration and flexibility, but the high cost of training multiple
models has limited its practical application. In this paper, we propose a novel
Cascade Adaptive Self-Speculative Decoding (CAS-Spec) method which constructs
speculative draft models by leveraging dynamically switchable inference
acceleration (DSIA) strategies, including layer sparsity and activation
quantization. Furthermore, traditional vertical and horizontal cascade
algorithms are inefficient when applied to self-speculative decoding methods.
We introduce a Dynamic Tree Cascade (DyTC) algorithm that adaptively routes the
multi-level draft models and assigns the draft lengths, based on the heuristics
of acceptance rates and latency prediction. Our CAS-Spec method achieves
state-of-the-art acceleration compared to existing on-the-fly speculative
decoding methods, with an average speedup from $1.1\times$ to $2.3\times$ over
autoregressive decoding across various LLMs and datasets. DyTC improves the
average speedup by $47$\% and $48$\% over cascade-based baseline and tree-based
baseline algorithms, respectively. CAS-Spec can be easily integrated into most
existing LLMs and holds promising potential for further acceleration as
self-speculative decoding techniques continue to evolve.

</details>


### [98] [Integrating Ontologies with Large Language Models for Enhanced Control Systems in Chemical Engineering](https://arxiv.org/abs/2510.26898)
*Crystal Su,Kuai Yu,Jingrui Zhang,Mingyuan Shao,Daniel Bauer*

Main category: cs.LG

TL;DR: 本文提出了一种结合结构化领域知识和生成性推理的化学工程领域的大语言模型框架。该框架通过一系列数据获取、语义预处理、信息提取和本体映射步骤，将模型训练和推理与COPE本体相连接，通过模板化的问答对指导微调。一个控制导向的解码阶段和引文关卡通过限制输出仅为本体链接的术语，来约束输出以确保语法和事实基础。评估指标量化了语言质量和本体准确性。反馈和未来扩展将增强系统的可解释性和可靠性。该方法结合了符号结构和神经生成，提供了一种透明、可审计的方法，将大语言模型应用于工艺控制、安全分析等关键工程场景中。


<details>
  <summary>Details</summary>
Motivation: 动机是为了结合结构化领域知识和生成性推理，提高在化学工程领域使用大语言模型的效果和可靠性，同时保证输出的质量和准确性。

Method: 方法包括通过一系列的数据获取、语义预处理、信息提取和本体映射步骤，将大语言模型的训练和推理与本体相连接；通过模板化的问答对引导模型进行微调；利用控制导向的解码阶段和引文关卡确保输出的语法和事实准确性；通过评估指标量化模型的语言质量和本体准确性；最后通过反馈和未来扩展增强系统的可解释性和可靠性。

Result: 该方法不仅提供了高质量、高准确性、高可靠性的问题回答，还增强了系统的可解释性和透明度，可应用于工艺控制、安全分析等关键工程场景中。

Conclusion: 该研究展示了如何将符号结构和神经生成相结合，为大语言模型在化学工程领域的应用提供了透明、可审计的方法。

Abstract: This work presents an ontology-integrated large language model (LLM)
framework for chemical engineering that unites structured domain knowledge with
generative reasoning. The proposed pipeline aligns model training and inference
with the COPE ontology through a sequence of data acquisition, semantic
preprocessing, information extraction, and ontology mapping steps, producing
templated question-answer pairs that guide fine-tuning. A control-focused
decoding stage and citation gate enforce syntactic and factual grounding by
constraining outputs to ontology-linked terms, while evaluation metrics
quantify both linguistic quality and ontological accuracy. Feedback and future
extensions, including semantic retrieval and iterative validation, further
enhance the system's interpretability and reliability. This integration of
symbolic structure and neural generation provides a transparent, auditable
approach for applying LLMs to process control, safety analysis, and other
critical engineering contexts.

</details>


### [99] [Discovering EV Charging Site Archetypes Through Few Shot Forecasting: The First U.S.-Wide Study](https://arxiv.org/abs/2510.26910)
*Kshitij Nikhal,Luke Ackerknecht,Benjamin S. Riggan,Phil Stahlfeld*

Main category: cs.LG

TL;DR: 本文提出了一种结合聚类和少样本预测的框架，利用新型大规模充电需求数据集来识别站点特征，展示了基于特征的专家模型在预测未知站点需求上的优越性，并提供了可以降低运营成本、优化能源和定价策略，支持电网韧性的见解。


<details>
  <summary>Details</summary>
Motivation: 为了促进交通运输的去碳化，需要准确理解电动汽车充电行为以确保成本效益和电网的弹性基础设施。现有工作受到小规模数据集、简单的时间依赖性模型和对运营历史有限的站点弱泛化能力的限制。

Method: 本文提出了一种新型的结合聚类和少样本预测的框架，使用大规模充电需求数据集来识别特征站点，并基于此建立特定特征的专家模型。

Result: 结果显示，基于特征的专家模型在预测未知站点需求上优于全局基线模型，产生了可以降低运营商成本、优化能源与定价策略、支持电网韧性的见解。

Conclusion: 通过将预测性能作为基础设施分割的基础，能够为促进实现气候目标的电网弹性提供可操作的见解。

Abstract: The decarbonization of transportation relies on the widespread adoption of
electric vehicles (EVs), which requires an accurate understanding of charging
behavior to ensure cost-effective, grid-resilient infrastructure. Existing work
is constrained by small-scale datasets, simple proximity-based modeling of
temporal dependencies, and weak generalization to sites with limited
operational history. To overcome these limitations, this work proposes a
framework that integrates clustering with few-shot forecasting to uncover site
archetypes using a novel large-scale dataset of charging demand. The results
demonstrate that archetype-specific expert models outperform global baselines
in forecasting demand at unseen sites. By establishing forecast performance as
a basis for infrastructure segmentation, we generate actionable insights that
enable operators to lower costs, optimize energy and pricing strategies, and
support grid resilience critical to climate goals.

</details>


### [100] [MM-OPERA: Benchmarking Open-ended Association Reasoning for Large Vision-Language Models](https://arxiv.org/abs/2510.26937)
*Zimeng Huang,Jinxin Ke,Xiaoxuan Fan,Yufeng Yang,Yang Liu,Liu Zhonghan,Zedi Wang,Junteng Dai,Haoyi Jiang,Yuyu Zhou,Keze Wang,Ziliang Chen*

Main category: cs.LG

TL;DR: 本文提出了MM-OPERA，一个系统化的基准测试，用于评估视觉语言大型模型（LVLM）的开放性关联推理能力，填补了现有基准测试的不足，同时提供了一种评估开放性输出的策略，并通过大量实验证明了LVLM在关联推理上的局限性，为开发更像人一样通用的AI铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 当前的基准测试主要针对封闭任务，未能捕捉到开放性关联推理的重要性，缺乏对LVLM在这一关键认知领域能力的全面评估。

Method: 本文提出了MM-OPERA基准测试系统，包括远程项目关联（RIA）和在上下文中的关联（ICA）两个开放性任务，同时提出了一种专门针对开放性输出评估的方法。

Result: 通过一系列实验，证明了当前最先进LVLM在开放性关联推理上的局限性，并展示了MM-OPERA基准的有效性。

Conclusion: 本文通过提出MM-OPERA基准，提供了一个新的方向来改进LVLM的开放性关联推理能力，为开发更像人一样智能的AI系统开辟了途径。

Abstract: Large Vision-Language Models (LVLMs) have exhibited remarkable progress.
However, deficiencies remain compared to human intelligence, such as
hallucination and shallow pattern matching. In this work, we aim to evaluate a
fundamental yet underexplored intelligence: association, a cornerstone of human
cognition for creative thinking and knowledge integration. Current benchmarks,
often limited to closed-ended tasks, fail to capture the complexity of
open-ended association reasoning vital for real-world applications. To address
this, we present MM-OPERA, a systematic benchmark with 11,497 instances across
two open-ended tasks: Remote-Item Association (RIA) and In-Context Association
(ICA), aligning association intelligence evaluation with human psychometric
principles. It challenges LVLMs to resemble the spirit of divergent thinking
and convergent associative reasoning through free-form responses and explicit
reasoning paths. We deploy tailored LLM-as-a-Judge strategies to evaluate
open-ended outputs, applying process-reward-informed judgment to dissect
reasoning with precision. Extensive empirical studies on state-of-the-art
LVLMs, including sensitivity analysis of task instances, validity analysis of
LLM-as-a-Judge strategies, and diversity analysis across abilities, domains,
languages, cultures, etc., provide a comprehensive and nuanced understanding of
the limitations of current LVLMs in associative reasoning, paving the way for
more human-like and general-purpose AI. The dataset and code are available at
https://github.com/MM-OPERA-Bench/MM-OPERA.

</details>


### [101] [Towards a Measure of Algorithm Similarity](https://arxiv.org/abs/2510.27063)
*Shairoz Sohail,Taher Ali*

Main category: cs.LG

TL;DR: 本文介绍了一种新的框架EMOC，用于评估和区分算法实现之间的相似性，并展示了其在检测近似克隆和量化大语言模型生成程序多样性方面的应用。同时，发布了一个PACD数据集以支持实验的可重复性。


<details>
  <summary>Details</summary>
Motivation: 对于给定的两个算法，如何确定它们在本质上是否有差异？在实际应用中，这是一个至关重要的问题，特别是对于程序克隆检测和程序合成等领域。然而，这个问题的一般情况在理论计算上是无法解决的，实际操作中也面临着多重相似性的概念混淆。因此，亟需一种实用且一致的相似性度量标准。

Method: 本文回顾了现有的等价和相似性概念，并提出了EMOC框架，通过评估、内存和操作复杂性来将算法实现嵌入到适用于下游任务的特征空间中。此外，构建了一个名为PACD的数据集，包含三个问题的经过验证的Python实现，以支持实验的可重复性。

Result: 研究结果表明，EMOC特征能够有效支持算法类型的聚类和分类，近似克隆的检测以及对大语言模型生成程序多样性的量化。这些发现为算法相似性的进一步研究提供了新的方法论和数据基础。

Conclusion: 提出了一种新的框架EMOC，以支持算法相似度的度量，并通过实证研究证明了其有效性。这为解决实际中的复杂问题，如程序克隆检测和多样化生成提供了强有力的工具。同时，发布数据集和使用的工具以推进这一领域的研究。

Abstract: Given two algorithms for the same problem, can we determine whether they are
meaningfully different? In full generality, the question is uncomputable, and
empirically it is muddied by competing notions of similarity. Yet, in many
applications (such as clone detection or program synthesis) a pragmatic and
consistent similarity metric is necessary. We review existing equivalence and
similarity notions and introduce EMOC: An
Evaluation-Memory-Operations-Complexity framework that embeds algorithm
implementations into a feature space suitable for downstream tasks. We compile
PACD, a curated dataset of verified Python implementations across three
problems, and show that EMOC features support clustering and classification of
algorithm types, detection of near-duplicates, and quantification of diversity
in LLM-generated programs. Code, data, and utilities for computing EMOC
embeddings are released to facilitate reproducibility and future work on
algorithm similarity.

</details>


### [102] [Mind the Gaps: Auditing and Reducing Group Inequity in Large-Scale Mobility Prediction](https://arxiv.org/abs/2510.26940)
*Ashwin Kumar,Hanyu Zhang,David A. Schweidel,William Yeoh*

Main category: cs.LG

TL;DR: 该论文揭示了在位置预测模型中基于用户人口统计学的隐形差异，并提出了一种名为Fairness-Guided Incremental Sampling (FGIS)的群体感知采样策略，用以修正这种差异，同时保持整体准确度。该方法在低资源环境下尤其有效，能够减少总体差异高达40%。


<details>
  <summary>Details</summary>
Motivation: 揭示人口统计学在大规模位置预测数据集中的隐形差异，并开发出一种新的采样策略，以减少这种差异，提高公平性。

Method: 引入了Size-Aware K-Means (SAKM) 分区方法，根据人口统计数据划分用户群体，以及Fairness-Guided Incremental Sampling (FGIS) 抽样策略，该策略确保公平性的同时，也保持了原有的准确性。

Result: 该方法在实验中大规模减少了种族和族裔群体之间的预测性能差异，最多可减少40%的差距，同时保持整体准确性几乎不受影响。测试表明，该方法在低资源环境下尤其有效。

Conclusion: 研究结果揭示了位置预测系统中存在的结构性不平等，并展示了如何通过细粒度的干预措施提高预测公平性，而无需增加太多复杂性，特别适用于数据量较少的应用场景。

Abstract: Next location prediction underpins a growing number of mobility, retail, and
public-health applications, yet its societal impacts remain largely unexplored.
In this paper, we audit state-of-the-art mobility prediction models trained on
a large-scale dataset, highlighting hidden disparities based on user
demographics. Drawing from aggregate census data, we compute the difference in
predictive performance on racial and ethnic user groups and show a systematic
disparity resulting from the underlying dataset, resulting in large differences
in accuracy based on location and user groups. To address this, we propose
Fairness-Guided Incremental Sampling (FGIS), a group-aware sampling strategy
designed for incremental data collection settings. Because individual-level
demographic labels are unavailable, we introduce Size-Aware K-Means (SAKM), a
clustering method that partitions users in latent mobility space while
enforcing census-derived group proportions. This yields proxy racial labels for
the four largest groups in the state: Asian, Black, Hispanic, and White. Built
on these labels, our sampling algorithm prioritizes users based on expected
performance gains and current group representation. This method incrementally
constructs training datasets that reduce demographic performance gaps while
preserving overall accuracy. Our method reduces total disparity between groups
by up to 40\% with minimal accuracy trade-offs, as evaluated on a state-of-art
MetaPath2Vec model and a transformer-encoder model. Improvements are most
significant in early sampling stages, highlighting the potential for
fairness-aware strategies to deliver meaningful gains even in low-resource
settings. Our findings expose structural inequities in mobility prediction
pipelines and demonstrate how lightweight, data-centric interventions can
improve fairness with little added complexity, especially for low-data
applications.

</details>


### [103] [Can machines think efficiently?](https://arxiv.org/abs/2510.26954)
*Adam Winchell*

Main category: cs.LG

TL;DR: 传统图灵测试已不再适用于区分人工与自然智能，本研究提出了一种新的测试方法，即在评价智能时加入能量消耗作为限制条件，使智能测试的评价标准更加注重效率与资源消耗的实际考虑。


<details>
  <summary>Details</summary>
Motivation: 随着先进人工智能系统已经可以顺利通过传统图灵测试，这引发了一系列伦理和环境问题，提示我们需要更新测试标准，以更好地区分和评估人工与自然智能。

Method: 本研究在传统图灵测试基础上提出了一个新的测试框架，即引入能量消耗变量，作为判断智能程度的新标准。

Result: 通过在测试中加入能量消耗的因素，使测试结果不再只是抽象的思维模拟，而是更具有实际意义的资源效率评价。同时，该方法为社会提供了衡量使用人工智能的时间节约与资源消耗之间的权衡工具。

Conclusion: 总结来说，本研究提出的新测试方法强调了智能评价中的资源效率问题，并提供了更加实用和可量化的评价方式。

Abstract: The Turing Test is no longer adequate for distinguishing human and machine
intelligence. With advanced artificial intelligence systems already passing the
original Turing Test and contributing to serious ethical and environmental
concerns, we urgently need to update the test. This work expands upon the
original imitation game by accounting for an additional factor: the energy
spent answering the questions. By adding the constraint of energy, the new test
forces us to evaluate intelligence through the lens of efficiency, connecting
the abstract problem of thinking to the concrete reality of finite resources.
Further, this proposed new test ensures the evaluation of intelligence has a
measurable, practical finish line that the original test lacks. This additional
constraint compels society to weigh the time savings of using artificial
intelligence against its total resource cost.

</details>


### [104] [Predicting Household Water Consumption Using Satellite and Street View Images in Two Indian Cities](https://arxiv.org/abs/2510.26957)
*Qiao Wang,Joseph George*

Main category: cs.LG

TL;DR: 文章探索了使用公开卫星图和街景图像来预测印度Hubballi-Dharwad地区的家庭用水量，该方法接近传统调查法的准确度，并为城市分析提供了可靠的用水量估算替代方案


<details>
  <summary>Details</summary>
Motivation: 城市化快地区的家庭用水量监测受限于时间和成本，研究旨在探索公开的卫星和街景图像作为替代方法

Method: 通过四种方法（调查特征，CNN嵌入，街景视觉分割和辅助数据）来预测家庭用水量

Result: 街景视觉分割并辅以遥感协变量在用水量预测中获得了0.55的准确度，接近于调查基准模型的0.59准确度

Conclusion: 公共图像和少量地理空间数据可以作为可靠的替代方案来估算家庭用水量

Abstract: Monitoring household water use in rapidly urbanizing regions is hampered by
costly, time-intensive enumeration methods and surveys. We investigate whether
publicly available imagery-satellite tiles, Google Street View (GSV)
segmentation-and simple geospatial covariates (nightlight intensity, population
density) can be utilized to predict household water consumption in
Hubballi-Dharwad, India. We compare four approaches: survey features
(benchmark), CNN embeddings (satellite, GSV, combined), and GSV semantic maps
with auxiliary data. Under an ordinal classification framework, GSV
segmentation plus remote-sensing covariates achieves 0.55 accuracy for water
use, approaching survey-based models (0.59 accuracy). Error analysis shows high
precision at extremes of the household water consumption distribution, but
confusion among middle classes is due to overlapping visual proxies. We also
compare and contrast our estimates for household water consumption to that of
household subjective income. Our findings demonstrate that open-access imagery,
coupled with minimal geospatial data, offers a promising alternative to
obtaining reliable household water consumption estimates using surveys in urban
analytics.

</details>


### [105] [Fine-Grained Iterative Adversarial Attacks with Limited Computation Budget](https://arxiv.org/abs/2510.26981)
*Zhichao Hou,Weizhi Gao,Xiaorui Liu*

Main category: cs.LG

TL;DR: 本文提出了一个精细控制机制，以在有限的计算预算下提高迭代对抗攻击的有效性，通过选择性地重新计算层次激活，从而在同等成本下优于现有的基线方法，并在整合到对抗训练中时，仅使用原始预算的30%，就能达到相似的效果


<details>
  <summary>Details</summary>
Motivation: 在有限的计算资源约束下，如何在固定的计算预算内最大化迭代对抗攻击的强度

Method: 提出了一种精细控制机制，包括迭代级和层次级的选择性重新计算层次激活

Result: 实验表明，该方法在同等成本下超越现有的标准方法，当集成到对抗训练中时，仅使用30%的预算就能取得相似结果

Conclusion: 所提出的方法能够有效提升在有限资源下的对抗攻击效率

Abstract: This work tackles a critical challenge in AI safety research under limited
compute: given a fixed computation budget, how can one maximize the strength of
iterative adversarial attacks? Coarsely reducing the number of attack
iterations lowers cost but substantially weakens effectiveness. To fulfill the
attainable attack efficacy within a constrained budget, we propose a
fine-grained control mechanism that selectively recomputes layer activations
across both iteration-wise and layer-wise levels. Extensive experiments show
that our method consistently outperforms existing baselines at equal cost.
Moreover, when integrated into adversarial training, it attains comparable
performance with only 30% of the original budget.

</details>


### [106] [HADSF: Aspect Aware Semantic Control for Explainable Recommendation](https://arxiv.org/abs/2510.26994)
*Zheng Nie,Peijie Sun*

Main category: cs.LG

TL;DR: 本文提出了一种双阶段语义框架，可以改善基于评论系统的推荐系统的数据提取过程，提高模型效果，并减少大语言模型的错误输出。实验结果表明，该方法在预测准确度上优于现有方法，并展示了更优的小模型性能。相关的代码和数据文件也已公开。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型在信息提取方面虽有进步，但还存在挖掘自由格式评论时无范围控制、缺乏下游效果链接的主题模型幻觉的度量以及不同规模模型的代价-质量权衡仍未被充分研究等问题。提出的方法旨在解决这些问题。

Method: 该方法包含两个阶段：第一个阶段采用自适应选择方法生成紧缩、面向语料库的主题词汇表；第二阶段在主题词汇表的指导下，执行结构化的主题-观点三元组抽取。同时，该方法通过引入主题漂移率和观点忠实率来评估生成表示的保真度，发现在语言模型幻觉的严重程度与预测评分误差之间存在非单调的关系。

Result: 实验结果表明，在引入标准评分预测器后，该方法可以实现预测误差的持续减少，还可以使较小的模型在代表性部署场景中实现具有竞争力的性能。对大约3,000,000条长尾评论进行了测试。

Conclusion: 通过引入紧凑且精确的表示规范，Hyper-Adaptive Dual-Stage Semantic Framework (HADSF) 降低了大型语言模型（LLM）在数据提取过程中的形式漂移率，提高了LLM在下游推荐系统中的预测准确度。这些发现可以促进更有效的LLM增强型可解释推荐技术的研究。

Abstract: Recent advances in large language models (LLMs) promise more effective
information extraction for review-based recommender systems, yet current
methods still (i) mine free-form reviews without scope control, producing
redundant and noisy representations, (ii) lack principled metrics that link LLM
hallucination to downstream effectiveness, and (iii) leave the cost-quality
trade-off across model scales largely unexplored. We address these gaps with
the Hyper-Adaptive Dual-Stage Semantic Framework (HADSF), a two-stage approach
that first induces a compact, corpus-level aspect vocabulary via adaptive
selection and then performs vocabulary-guided, explicitly constrained
extraction of structured aspect-opinion triples. To assess the fidelity of the
resulting representations, we introduce Aspect Drift Rate (ADR) and Opinion
Fidelity Rate (OFR) and empirically uncover a nonmonotonic relationship between
hallucination severity and rating prediction error. Experiments on
approximately 3 million reviews across LLMs spanning 1.5B-70B parameters show
that, when integrated into standard rating predictors, HADSF yields consistent
reductions in prediction error and enables smaller models to achieve
competitive performance in representative deployment scenarios. We release
code, data pipelines, and metric implementations to support reproducible
research on hallucination-aware, LLM-enhanced explainable recommendation. Code
is available at https://github.com/niez233/HADSF

</details>


### [107] [Gradient Descent as Loss Landscape Navigation: a Normative Framework for Deriving Learning Rules](https://arxiv.org/abs/2510.26997)
*John J. Vastola,Samuel J. Gershman,Kanaka Rajan*

Main category: cs.LG

TL;DR: 本文提出了一种理论框架，将学习规则视为在(部分可观察)损失景观中导航的策略，并将最优规则识别为相关最优控制问题的解决方案。该框架下，许多已知规则自然出现，比如动量从长期规划出现，自然梯度考虑参数空间几何，自适应优化器如Adam从在线贝叶斯推断损失景观形状出现，以及重量重置的持续学习策略作为对任务不确定性的最优响应出现。该框架统一这些现象在单一目标下，澄清了学习的计算结构，并为设计自适应算法提供了原则基础。


<details>
  <summary>Details</summary>
Motivation: 为什么要研究一些学习规则比其他规则表现更好，以及在哪种假设下给定规则可以被认为是最佳的？本文旨在为此提供一种理论基础，研究学习规则的最优性。

Method: 本文提出了一种框架，该框架将学习规则视为策略，在(部分可观察)损失景观中导航，并将最优规则作为相关最优控制问题的解决方案。该框架探讨了不同假设下的多种规则，包括梯度下降、动量、自然梯度等等。此外，还将重量重置的持续学习策略作为对任务不确定性的最优响应进行研究，并探讨了在单一目标下统一这些现象的作用。

Result: 在本文的理论框架下，多种已知的学习规则如梯度下降、动量、自然梯度等自然出现，证明了框架的有效性。同时，框架也为理解自适应优化器如Adam提供了新的视角，并明确了持续学习策略如重量重置作为一种对任务不确定性的最优响应的角色。

Conclusion: 我们通过统一这些现象在单一目标下，提出了一个理论框架来澄清学习的计算结构，并为设计自适应算法提供了原则基础。

Abstract: Learning rules -- prescriptions for updating model parameters to improve
performance -- are typically assumed rather than derived. Why do some learning
rules work better than others, and under what assumptions can a given rule be
considered optimal? We propose a theoretical framework that casts learning
rules as policies for navigating (partially observable) loss landscapes, and
identifies optimal rules as solutions to an associated optimal control problem.
A range of well-known rules emerge naturally within this framework under
different assumptions: gradient descent from short-horizon optimization,
momentum from longer-horizon planning, natural gradients from accounting for
parameter space geometry, non-gradient rules from partial controllability, and
adaptive optimizers like Adam from online Bayesian inference of loss landscape
shape. We further show that continual learning strategies like weight resetting
can be understood as optimal responses to task uncertainty. By unifying these
phenomena under a single objective, our framework clarifies the computational
structure of learning and offers a principled foundation for designing adaptive
algorithms.

</details>


### [108] [A Framework for Fair Evaluation of Variance-Aware Bandit Algorithms](https://arxiv.org/abs/2510.27001)
*Elise Wolf*

Main category: cs.LG

TL;DR: 本文提出了一个用于系统性评估多臂赌博机算法的框架，分析了在高不确定性环境下，方差感知算法相比传统算法的优势所在。同时，该框架实现了多个性能指标以及用户交互功能，增强了评估的可重复性和透明度。


<details>
  <summary>Details</summary>
Motivation: 目前，多臂赌博机（MAB）算法的评估和比较由于缺乏标准化条件而变得困难，这在评估如UCB等经典方法的方差感知扩展时尤为突出。因此，研究如何可靠地观察不同MAB算法之间的性能差异，并找出方差感知算法在何种条件下优于经典算法显得尤为重要。

Method: 提出了一套可重复的评估方案，系统性地比较了8种经典与方差感知的MAB算法。该评估框架以代码库的形式记录下来，并实现了多个性能衡量指标，旨在提供一套透明且可重复的评估标准。此外，这个框架还包含了一个交互式评价接口，帮助用户进行一直且透明的分析。

Result: 研究表明，在不确定性较高的场景中，方差感知的MAB算法比传统算法更能提供优势。而在较为分离的场景或经过深度调参的过程中，经典算法通常表现出色或表现相当。

Conclusion: 主要贡献包括构建了一种评估多臂赌博机算法的系统性框架，并探讨了方差感知算法在何种条件下超越其经典版本的具体情况。

Abstract: Multi-armed bandit (MAB) problems serve as a fundamental building block for
more complex reinforcement learning algorithms. However, evaluating and
comparing MAB algorithms remains challenging due to the lack of standardized
conditions and replicability. This is particularly problematic for
variance-aware extensions of classical methods like UCB, whose performance can
heavily depend on the underlying environment. In this study, we address how
performance differences between bandit algorithms can be reliably observed, and
under what conditions variance-aware algorithms outperform classical ones. We
present a reproducible evaluation designed to systematically compare eight
classical and variance-aware MAB algorithms. The evaluation framework,
implemented in our Bandit Playground codebase, features clearly defined
experimental setups, multiple performance metrics (reward, regret, reward
distribution, value-at-risk, and action optimality), and an interactive
evaluation interface that supports consistent and transparent analysis. We show
that variance-aware algorithms can offer advantages in settings with high
uncertainty where the difficulty arises from subtle differences between arm
rewards. In contrast, classical algorithms often perform equally well or better
in more separable scenarios or if fine-tuned extensively. Our contributions are
twofold: (1) a framework for systematic evaluation of MAB algorithms, and (2)
insights into the conditions under which variance-aware approaches outperform
their classical counterparts.

</details>


### [109] [Jasmine: A Simple, Performant and Scalable JAX-based World Modeling Codebase](https://arxiv.org/abs/2510.27002)
*Mihir Mahajan,Alfred Nguyen,Franz Srambical,Stefan Bauer*

Main category: cs.LG

TL;DR: 文章介绍了Jasmine，一个基于JAX的用于世界建模的高性能代码库，可以在最少的代码更改的情况下从单个主机扩展到数百个加速器。Jasmine在CoinRun案例研究中的重现实验相较于之前的开源实现快了一个数量级，这得益于在数据加载、训练和检查点方面的性能优化。Jasmine保证了完全重复的训练，并且支持多样化的分区配置。通过将Jasmine与大规模数据集结合使用，文章建立了跨模型系列和架构消融的严格基准测试流水线的基础设施。


<details>
  <summary>Details</summary>
Motivation: 当前尽管世界模型在克服诸如机器人领域的数据稀缺方面被广泛关注，但用于世界建模的开放训练基础设施仍然不成熟。因此，本文作者希望提供一种稳定且高效的代码库来支持世界模型的训练和研究，Jasmine应运而生。它的目标是以更高的性能和更好的可扩展性促进相关研究的发展。

Method: Jasmine是一个基于JAX的高性能世界模型代码库，该代码库在数据加载、训练和检查点保存过程中进行了系统性的性能优化，实现了一个量级的速度提升，并提供完全可重复训练和架构优化的灵活性。此外，代码库还设计了大规模数据集的管理和基准测试的基础设施。

Result: 该工作提出的世界模型代码库Jasmine扩展性强，性能优越，远超出现了现有开源实现；支持数据加载，训练和保存的优化保证了高效运行。此外，Jasmine通过支持多样化的大规模数据集来支持严格的基准测试流程设计。

Conclusion: Jasmine提供了一个高性能的世界模型代码库，解决了世界模型开放训练基础设施缺失的问题。它的实现和技术具有重要的研究价值。

Abstract: While world models are increasingly positioned as a pathway to overcoming
data scarcity in domains such as robotics, open training infrastructure for
world modeling remains nascent. We introduce Jasmine, a performant JAX-based
world modeling codebase that scales from single hosts to hundreds of
accelerators with minimal code changes. Jasmine achieves an order-of-magnitude
faster reproduction of the CoinRun case study compared to prior open
implementations, enabled by performance optimizations across data loading,
training and checkpointing. The codebase guarantees fully reproducible training
and supports diverse sharding configurations. By pairing Jasmine with curated
large-scale datasets, we establish infrastructure for rigorous benchmarking
pipelines across model families and architectural ablations.

</details>


### [110] [Enhancing Sentiment Classification with Machine Learning and Combinatorial Fusion](https://arxiv.org/abs/2510.27014)
*Sean Patten,Pin-Yu Chen,Christina Schweikert,D. Frank Hsu*

Main category: cs.LG

TL;DR: 本文提出了一种新的情感分类方法，使用组合融合分析（CFA）将多个机器学习模型集成在一起，在IMDB情感分析数据集上达到了97.072%的最新准确率。CFA利用认知多样性概念，通过秩分特征函数量化模型之间的差异，并战略性地结合它们的预测。此方法在资源使用上与扩大单个模型规模的传统方法相比更加高效。实验结果表明，CFA能够通过有效计算和利用模型多样性超过传统的集成方法。本文的方法结合了RoBERTa架构的Transformer模型和传统的机器学习模型，包括随机森林、SVM和XGBoost。


<details>
  <summary>Details</summary>
Motivation: 传统的集成方法通常通过增加单个模型的规模来提高性能，这在计算资源上效率较低。本文希望通过利用认知多样性，能够更有效地结合多个模型的预测，从而提高情感分类的准确率。

Method: 本文提出了一种基于组合融合分析（CFA）的情感分类方法，该方法通过利用秩分特征函数量化模型间的差异，然后战略性地融合这些预测。具体实现上，将RoBERTa模型与随机森林、SVM和XGBoost等传统机器学习模型结合。

Result: 实验表明，基于CFA的方法在IMDB情感分析数据集中实现了97.072%的准确性，表现优于传统的集成方法。此外，CFA方法因有效利用模型多样性而高效利用了计算资源。

Conclusion: 该方法利用认知多样性概念，创造了更高效利用多个机器学习模型的预测方法，不仅提高了情感分类的准确性，而且在计算资源使用上也显示出优越性。

Abstract: This paper presents a novel approach to sentiment classification using the
application of Combinatorial Fusion Analysis (CFA) to integrate an ensemble of
diverse machine learning models, achieving state-of-the-art accuracy on the
IMDB sentiment analysis dataset of 97.072\%. CFA leverages the concept of
cognitive diversity, which utilizes rank-score characteristic functions to
quantify the dissimilarity between models and strategically combine their
predictions. This is in contrast to the common process of scaling the size of
individual models, and thus is comparatively efficient in computing resource
use. Experimental results also indicate that CFA outperforms traditional
ensemble methods by effectively computing and employing model diversity. The
approach in this paper implements the combination of a transformer-based model
of the RoBERTa architecture with traditional machine learning models, including
Random Forest, SVM, and XGBoost.

</details>


### [111] [Quantitative Bounds for Length Generalization in Transformers](https://arxiv.org/abs/2510.27015)
*Zachary Izzo,Eshaan Nichani,Jason D. Lee*

Main category: cs.LG

TL;DR: 本文提供了一个关于变压器在较短序列上训练后，在较长未见过的输入上保持性能的能力的定量界限。研究了无限范式误差控制和平均误差控制等不同场景下的长度推广问题，并证明了当较短序列的行为可以模拟训练时较长序列的行为时，就会发生长度推广。这些界限为训练数据长度提供了定性估计，并通过实验验证了这些见解。从而加深了我们对变压器外推机制的理论理解，并正式化了较为复杂的任务需要更丰富的训练数据的直觉。


<details>
  <summary>Details</summary>
Motivation: 前人的研究已经指出，当训练序列长度超过一定阈值后，变压器能够实现长度推广。但这些问题的细节和定量界限还尚未明确。本文旨在探讨这些细节，提供一个关于变压器在较短序列上训练后，能够在较长未见过的输入上保持性能的能力的定量界限，并验证这些理论上的定性估计。

Method: 在无限范式误差控制和平均误差控制等不同场景下进行分析。定量估计当较短序列的行为可以模拟训练时较长序列的行为时，模型如何实现长度推广，并通过实验来验证这些理论推测。

Result: 研究确定了长度推广成功的场景，提供了关于训练数据长度的具体要求。这为理解变压器在复杂任务上的训练数据要求提供了一个理论基础。实验验证了理论上的定性估计，证明了理论上的上限是正确的。

Conclusion: 这些结果加深了我们对长度推广机制的理解，并为比较复杂的任务所需训练数据的规模提供了一个理论上的理解。研究表明，较宽泛的任务需要丰富的训练数据来推广到较长输入序列上。

Abstract: We study the problem of length generalization (LG) in transformers: the
ability of a model trained on shorter sequences to maintain performance when
evaluated on much longer, previously unseen inputs. Prior work by Huang et al.
(2025) established that transformers eventually achieve length generalization
once the training sequence length exceeds some finite threshold, but left open
the question of how large it must be. In this work, we provide the first
quantitative bounds on the required training length for length generalization
to occur. Motivated by previous empirical and theoretical work, we analyze LG
in several distinct problem settings: $\ell_\infty$ error control vs. average
error control over an input distribution, infinite-precision softmax attention
vs. finite-precision attention (which reduces to an argmax) in the transformer,
and one- vs. two-layer transformers. In all scenarios, we prove that LG occurs
when the internal behavior of the transformer on longer sequences can be
"simulated" by its behavior on shorter sequences seen during training. Our
bounds give qualitative estimates for the length of training data required for
a transformer to generalize, and we verify these insights empirically. These
results sharpen our theoretical understanding of the mechanisms underlying
extrapolation in transformers, and formalize the intuition that richer training
data is required for generalization on more complex tasks.

</details>


### [112] [Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning](https://arxiv.org/abs/2510.27044)
*Md Tanvirul Alam,Nidhi Rastogi*

Main category: cs.LG

TL;DR: 研究者通过RLVR对两个组合问题进行了研究，发现RLVR能改进评估指标，但常常通过强化启发式方法而不是学习新的推理策略。这突显了RLVR泛化的局限性，强调了分解真推理与捷径利用的基准的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在增强LLMs的数学推理能力方面的效果尚不明确，研究者希望通过研究探讨其在促进真正推理方面的潜力和局限性。

Method: 该研究使用精心挑选的数据集，以增强型活动调度和最长递增子序列两个组合问题为测试对象，应用多个奖励设计进行实验。

Result: 结果发现，RLVR虽然改善了评估指标，但往往通过强化表面的启发式方法，而不是学习新的推理策略来实现。

Conclusion: 这些发现强调了进一步研究的必要性，以创造可以区分真推理与捷径利用的基准，从而准确衡量进展。

Abstract: Mathematical reasoning is a central challenge for large language models
(LLMs), requiring not only correct answers but also faithful reasoning
processes. Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as
a promising approach for enhancing such capabilities; however, its ability to
foster genuine reasoning remains unclear. We investigate RLVR on two
combinatorial problems with fully verifiable solutions: \emph{Activity
Scheduling} and the \emph{Longest Increasing Subsequence}, using carefully
curated datasets with unique optima. Across multiple reward designs, we find
that RLVR improves evaluation metrics but often by reinforcing superficial
heuristics rather than acquiring new reasoning strategies. These findings
highlight the limits of RLVR generalization, emphasizing the importance of
benchmarks that disentangle genuine mathematical reasoning from shortcut
exploitation and provide faithful measures of progress. Code available at
https://github.com/xashru/rlvr-seq-generalization.

</details>


### [113] [Consistency Training Helps Stop Sycophancy and Jailbreaks](https://arxiv.org/abs/2510.27062)
*Alex Irpan,Alexander Matt Turner,Mark Kurzeja,David K. Elson,Rohin Shah*

Main category: cs.LG

TL;DR: 研究提出了两种一致性训练方法（BCT和ACT）来提高模型对无关提示的抗干扰性，尤其是减少模型的奉承行为和‘越狱’行为。相比BCT，ACT在减少奉承行为方面表现良好，而BCT在减少‘越狱’行为方面更有效。这两种方法避免了使用过时的训练数据导致的问题，并简化了训练流程。研究认为一些对齐问题应该从一致性问题的角度来看待而不是寻找最优响应。


<details>
  <summary>Details</summary>
Motivation: LLM的客观性和拒绝训练可能会由于提示的简单变化而受到破坏，因此提出了一种自监督的一致性训练方法来解决这个问题，使模型在不同的提示增强下保持一致的行为，减少模型输出对于无关提示的敏感性。

Method: 文章提出了两种方法：包括外部输出一致性的偏倚增强一致性训练（BCT）以及内部激活一致性的激活一致性训练（ACT）。它们帮助模型保持行为一致性，提高对无关提示的抗干扰能力。具体方法为训练模型在面对经过不同数据增强的提示时保持相同的响应。BCT通过模型的输出来自我学习，ACT则是通过调整模型内部激活来实现，以达到减少措施的影响。

Result: 该研究表明，BCT和ACT都能有效减少模型的奉承行为和‘越狱’行为，不过BCT对于减少‘越狱’行为的效果更加显著。此外，由于这两种方法利用模型自动生成的数据进行训练，因此可以避免由于训练数据过时而导致的问题，如模型能力退化等，并简化了训练流程。

Conclusion: 通过一致性的训练方式，可以有效地提高模型对提示变化的鲁棒性。文章强调了一些对齐问题应该被看作是一致性问题而不是寻找最优响应，并且BCT在简化训练流程和提高模型一致性上有更大的潜力。

Abstract: An LLM's factuality and refusal training can be compromised by simple changes
to a prompt. Models often adopt user beliefs (sycophancy) or satisfy
inappropriate requests which are wrapped within special text (jailbreaking). We
explore \emph{consistency training}, a self-supervised paradigm that teaches a
model to be invariant to certain irrelevant cues in the prompt. Instead of
teaching the model what exact response to give on a particular prompt, we aim
to teach the model to behave identically across prompt data augmentations (like
adding leading questions or jailbreak text). We try enforcing this invariance
in two ways: over the model's external outputs (\emph{Bias-augmented
Consistency Training} (BCT) from Chua et al. [2025]) and over its internal
activations (\emph{Activation Consistency Training} (ACT), a method we
introduce). Both methods reduce Gemini 2.5 Flash's susceptibility to irrelevant
cues. Because consistency training uses responses from the model itself as
training data, it avoids issues that arise from stale training data, such as
degrading model capabilities or enforcing outdated response guidelines. While
BCT and ACT reduce sycophancy equally well, BCT does better at jailbreak
reduction. We think that BCT can simplify training pipelines by removing
reliance on static datasets. We argue that some alignment problems are better
viewed not in terms of optimal responses, but rather as consistency issues.

</details>


### [114] [MLPerf Automotive](https://arxiv.org/abs/2510.27065)
*Radoyeh Shojaei,Predrag Djurdjevic,Mostafa El-Khamy,James Goel,Kasper Mecklenburg,John Owens,Pınar Muyan-Özçelik,Tom St. John,Jinho Suh,Arjun Suresh*

Main category: cs.LG

TL;DR: MLPerf Automotive 是首个用于评估汽车系统中机器学习系统的标准化公共基准。它专门考虑了汽车工作负载的独特约束，并提供了一致和可重复的性能比较方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基准套件无法用于汽车系统，因为汽车工作负载有安全和实时处理的独特约束。需要标准化的性能评估方法来满足这些需求。

Method: 该基准测试框架提供了延迟和准确性指标，以及评估协议，使得可以在不同的硬件平台和软件实现之间进行一致且可重复的性能比较。第一轮基准测试包括2D物体检测，2D语义分割和3D物体检测任务。Benchmark 的详细设计方法被描述，包括任务选择，参考模型和提交规则。同时提供了首次基准测试提交的详细信息以及在获取数据集和开发基准实现过程中遇到的挑战。

Result: 基准测试的第一轮结果说明了该基准测试的效用，并展示了首次提交的配置在各个任务上的表现。这种方式有助于识别和比较在实际汽车系统中实现的最佳性能选项。

Conclusion: 已经发布了MLPerf Automotive的首次基准测试。此公告为评估和比较用于汽车系统的机器学习系统性能提供了标准化的框架。

Abstract: We present MLPerf Automotive, the first standardized public benchmark for
evaluating Machine Learning systems that are deployed for AI acceleration in
automotive systems. Developed through a collaborative partnership between
MLCommons and the Autonomous Vehicle Computing Consortium, this benchmark
addresses the need for standardized performance evaluation methodologies in
automotive machine learning systems. Existing benchmark suites cannot be
utilized for these systems since automotive workloads have unique constraints
including safety and real-time processing that distinguish them from the
domains that previously introduced benchmarks target. Our benchmarking
framework provides latency and accuracy metrics along with evaluation protocols
that enable consistent and reproducible performance comparisons across
different hardware platforms and software implementations. The first iteration
of the benchmark consists of automotive perception tasks in 2D object
detection, 2D semantic segmentation, and 3D object detection. We describe the
methodology behind the benchmark design including the task selection, reference
models, and submission rules. We also discuss the first round of benchmark
submissions and the challenges involved in acquiring the datasets and the
engineering efforts to develop the reference implementations. Our benchmark
code is available at https://github.com/mlcommons/mlperf_automotive.

</details>


### [115] [Towards Understanding Self-play for LLM Reasoning](https://arxiv.org/abs/2510.27072)
*Justin Yang Chae,Md Tanvirul Alam,Nidhi Rastogi*

Main category: cs.LG

TL;DR: 通过绝对零点理由者分析了自我游戏的训练动态，并与其他后训练策略进行比较，揭示了自我游戏的内在限制和改进LLM数学推理的未来方向


<details>
  <summary>Details</summary>
Motivation: 由于自我游戏如何改善LLM推理的具体机制尚不清楚，因此通过绝对零点理由者分析其训练动态，探讨它与其他策略之间的异同

Method: 比较了RLVR和监督微调(SFT)，并分析了参数更新稀疏性、令牌分布熵和替代提议者奖励函数

Result: 发现了自我游戏与其他后训练策略相比的独特动态，并指出了其改进方向

Conclusion: 自我游戏作为一种改善LLM推理能力的方法，虽然有效，但也存在局限性，未来可以通过优化奖励函数来提升其效果

Abstract: Recent advances in large language model (LLM) reasoning, led by reinforcement
learning with verifiable rewards (RLVR), have inspired self-play post-training,
where models improve by generating and solving their own problems. While
self-play has shown strong in-domain and out-of-domain gains, the mechanisms
behind these improvements remain poorly understood. In this work, we analyze
the training dynamics of self-play through the lens of the Absolute Zero
Reasoner, comparing it against RLVR and supervised fine-tuning (SFT). Our study
examines parameter update sparsity, entropy dynamics of token distributions,
and alternative proposer reward functions. We further connect these dynamics to
reasoning performance using pass@k evaluations. Together, our findings clarify
how self-play differs from other post-training strategies, highlight its
inherent limitations, and point toward future directions for improving LLM math
reasoning through self-play.

</details>


### [116] [Functional embeddings enable Aggregation of multi-area SEEG recordings over subjects and sessions](https://arxiv.org/abs/2510.27090)
*Sina Javadzadeh,Rahil Soroushmojdehi,S. Alireza Seyyed Mousavi,Mehrnaz Asadi,Sumiko Abe,Terence D. Sanger*

Main category: cs.LG

TL;DR: 本文提出了一种可扩展的表示学习框架，旨在将不同受试者的颅内记录数据进行聚合。该框架通过Siamese编码器学习每个电极的功能身份，并使用Transformer模型建模不同区域之间的关系。在大规模多受试者的数据集中进行了验证，证明了该方法的有效性，为大规模跨受试者聚合和预训练提供了可能途径。


<details>
  <summary>Details</summary>
Motivation: 跨受试者聚合颅内记录的数据面临电极数量、位置和覆盖范围不一致的挑战。现有的空间标准化方法，如MNI坐标，无法有效捕捉真正的功能相似性，尤其是在定位不精确的情况下。这促使作者寻找新的方法来解决这一问题，即开发一种能够学习电极功能特性的表示学习框架。

Method: 本文提出的方法包括两部分：一是使用Siamese编码器（带有对比目标）从多区域局部场电位中学习每个电极的无受试者特定的功能身份，二是将这些嵌入进行分词以用于Transformer，该Transformer模型能够使用可变数量的通道来建模不同区域之间的关系。

Result: 实验结果表明，学习到的功能空间支持精准的受试者内的区分，并形成了清晰、区域一致的簇。该方法还能够在新的通道上实现零样本转移，Transformer模型在没有任何特定受试者的头部或监督的情况下，能够捕捉跨区域的依赖关系并实现掩码通道的重建。

Conclusion: 此框架的结果表明了向大范围跨受试者聚合和预训练颅内神经数据发展的可能路径，尤其是在任务结构严格且传感器布置不一致的情况下。

Abstract: Aggregating intracranial recordings across subjects is challenging since
electrode count, placement, and covered regions vary widely. Spatial
normalization methods like MNI coordinates offer a shared anatomical reference,
but often fail to capture true functional similarity, particularly when
localization is imprecise; even at matched anatomical coordinates, the targeted
brain region and underlying neural dynamics can differ substantially between
individuals. We propose a scalable representation-learning framework that (i)
learns a subject-agnostic functional identity for each electrode from
multi-region local field potentials using a Siamese encoder with contrastive
objectives, inducing an embedding geometry that is locality-sensitive to
region-specific neural signatures, and (ii) tokenizes these embeddings for a
transformer that models inter-regional relationships with a variable number of
channels. We evaluate this framework on a 20-subject dataset spanning basal
ganglia-thalamic regions collected during flexible rest/movement recording
sessions with heterogeneous electrode layouts. The learned functional space
supports accurate within-subject discrimination and forms clear,
region-consistent clusters; it transfers zero-shot to unseen channels. The
transformer, operating on functional tokens without subject-specific heads or
supervision, captures cross-region dependencies and enables reconstruction of
masked channels, providing a subject-agnostic backbone for downstream decoding.
Together, these results indicate a path toward large-scale, cross-subject
aggregation and pretraining for intracranial neural data where strict task
structure and uniform sensor placement are unavailable.

</details>


### [117] [QiNN-QJ: A Quantum-inspired Neural Network with Quantum Jump for Multimodal Sentiment Analysis](https://arxiv.org/abs/2510.27091)
*Yiwei Chen,Kehuan Yan,Yu Pan,Daoyi Dong*

Main category: cs.LG

TL;DR: 提出了一种名为QiNN-QJ（Quantum-inspired Neural Network with Quantum Jump）的量子启发式多模态融合模型，该模型通过模拟量子跳跃算子来生成可控制的跨模态纠缠，并在基准数据集上取得了优于现有最佳模型的结果。此外，该模型还增强了后验证的可解释性。这项工作为纠缠多模态融合建立了原理框架，并为量子启发式方法在跨模态复杂相关性建模中的应用铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 现有的量子启发式融合模型依赖单位元或类似的量子变换生成纠缠，但这种方法在训练稳定性和泛化能力方面存在不足。QiNN-QJ旨在通过引入量子跳跃算子实现更加可控和稳定的跨模态纠缠生成，解决这些问题。

Method: 该方法首先将每个模态编码为量子纯态，然后通过一个可微分模块模拟量子跳跃算子来将分离积状态转换为纠缠表示。通过联合学习哈密尔顿算子和林德布拉德算子，QiNN-QJ生成了具有耗散动力学的可控跨模态纠缠。最后，纠缠状态被映射到可训练的测量向量以生成预测结果。

Result: 在CMU-MOSI，CMU-MOSEI和CH-SIMS等基准数据集上，QiNN-QJ在性能上优于现有最佳模型。此外，与传统测量机制相比，QiNN-QJ通过冯·诺依曼纠缠熵增强了后验可解释性。

Conclusion: 这项工作提供了一种新的方法来处理多模态数据之间的复杂关系，通过引入量子跳跃算子，它解决了现有方法在训练稳定性和泛化能力方面的挑战，并展示了优于现有模型的性能和增强的解释能力。

Abstract: Quantum theory provides non-classical principles, such as superposition and
entanglement, that inspires promising paradigms in machine learning. However,
most existing quantum-inspired fusion models rely solely on unitary or
unitary-like transformations to generate quantum entanglement. While
theoretically expressive, such approaches often suffer from training
instability and limited generalizability. In this work, we propose a
Quantum-inspired Neural Network with Quantum Jump (QiNN-QJ) for multimodal
entanglement modelling. Each modality is firstly encoded as a quantum pure
state, after which a differentiable module simulating the QJ operator
transforms the separable product state into the entangled representation. By
jointly learning Hamiltonian and Lindblad operators, QiNN-QJ generates
controllable cross-modal entanglement among modalities with dissipative
dynamics, where structured stochasticity and steady-state attractor properties
serve to stabilize training and constrain entanglement shaping. The resulting
entangled states are projected onto trainable measurement vectors to produce
predictions. In addition to achieving superior performance over the
state-of-the-art models on benchmark datasets, including CMU-MOSI, CMU-MOSEI,
and CH-SIMS, QiNN-QJ facilitates enhanced post-hoc interpretability through
von-Neumann entanglement entropy. This work establishes a principled framework
for entangled multimodal fusion and paves the way for quantum-inspired
approaches in modelling complex cross-modal correlations.

</details>


### [118] [Hierarchical Bayesian Model for Gene Deconvolution and Functional Analysis in Human Endometrium Across the Menstrual Cycle](https://arxiv.org/abs/2510.27097)
*Crystal Su,Kuai Yu,Mingyuan Shao,Daniel Bauer*

Main category: cs.LG

TL;DR: 该研究提出了一种基于概率性层次贝叶斯模型的方法，通过解卷积批量RNA-seq数据，实现了异质样本中细胞类型特异性表达谱的重建。这种方法利用了高分辨率的单细胞参考数据。应用该模型研究了人类子宫内膜组织在整个月经周期中的组织变化，揭示了上皮细胞、间质细胞和免疫细胞的动态转变，以及与内膜功能相关的细胞类型特异性差异表达。此外，研究还验证了该模型的稳健性，并探讨了其潜在的临床意义和未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统的批量组织RNA测序数据平均了不同细胞类型的基因表达谱，掩盖了细胞类型特异性动力学。为了克服这一问题，该研究开发了一种新方法，利用层次贝叶斯模型来解卷积批量RNA-seq数据，从而细化细胞类型表达谱的分析，提供更详细的细胞类型动态变化信息，特别是在受激素驱动的细胞组成变化明显的组织中，如子宫内膜在月经周期中的变化。

Method: 采用了一种基于概率性层次贝叶斯模型的方法来解卷积批量RNA-seq数据，以获得细胞类型特异性的表达谱。该方法利用了高分辨率的单细胞参考数据，并且通过详细的模型结构、先验知识及推理策略，在模拟实验和与其他现有方法的对比中展示了其性能。此外，还进行了鲁棒性测试，展示了贝叶斯方法在参考数据不匹配和噪声条件下的稳定表现。

Result: 该研究揭示了子宫内膜组织中上皮细胞、间质细胞和免疫细胞在月经周期各阶段的动态转变，并且还识别了和子宫内膜功能相关的细胞类型特异性差异基因表达现象。例如，发现间质细胞在分泌期表现出脱细胞化标记物的差异表达。此外，该方法还在模拟实验和实际应用中表现出良好的性能和稳健性。

Conclusion: 通过使用不同细胞类型特异性的基因表达谱和含量比例来重建解卷积数据，该方法能够在大规模的多细胞群体中提供详细的细胞类型动力学观察。这为理解激素驱动的组织变化以及潜在的临床应用提供了基础，指出了未来集成空间转录组学的可能性。

Abstract: Bulk tissue RNA sequencing of heterogeneous samples provides averaged gene
expression profiles, obscuring cell type-specific dynamics. To address this, we
present a probabilistic hierarchical Bayesian model that deconvolves bulk
RNA-seq data into constituent cell-type expression profiles and proportions,
leveraging a high-resolution single-cell reference. We apply our model to human
endometrial tissue across the menstrual cycle, a context characterized by
dramatic hormone-driven cellular composition changes. Our extended framework
provides a principled inference of cell type proportions and cell-specific gene
expression changes across cycle phases. We demonstrate the model's structure,
priors, and inference strategy in detail, and we validate its performance with
simulations and comparisons to existing methods. The results reveal dynamic
shifts in epithelial, stromal, and immune cell fractions between menstrual
phases, and identify cell-type-specific differential gene expression associated
with endometrial function (e.g., decidualization markers in stromal cells
during the secretory phase). We further conduct robustness tests and show that
our Bayesian approach is resilient to reference mismatches and noise. Finally,
we discuss the biological significance of our findings, potential clinical
implications for fertility and endometrial disorders, and future directions,
including integration of spatial transcriptomics.

</details>


### [119] [Group-Sensitive Offline Contextual Bandits](https://arxiv.org/abs/2510.27123)
*Yihong Guo,Junjie Luo,Guodong Gao,Ritu Agarwal,Anqi Liu*

Main category: cs.LG

TL;DR: 本文提出了一种在离线上下文老虎机中减少群体间收益差异的框架，通过引入群体收益差异约束到基于策略梯度的优化方法中，并提供了一种双重鲁棒估计器来提高训练期间收益差异的估计。实验证明该方法能够在降低收益差异的同时保持竞争的整体性能。


<details>
  <summary>Details</summary>
Motivation: 在离线策略优化中，最大化整体预期收益可能会无意中加剧群体间的收益差距，导致某些群体比其他群体更多地受益，特别是在资源有限的情况下，这种不公平的现象更加明显。因此，本文旨在研究离线上下文老虎机中的群体敏感公平性约束，以减少群体间的收益差异。

Method: 提出了一种带约束的离线策略优化框架，通过将群体收益差异约束引入基于策略梯度的优化过程中，并使用双重鲁棒估计器来改进训练期间群体收益差异的估计。同时提供了一种聚收敛保证策略优化。

Result: 在合成数据和真实世界数据集上的实证结果表明，该方法能够在降低收益差异的同时保持竞争的整体性能。

Conclusion: 所提出的带群体收益差异约束的离线策略优化框架是一种有效减少离线上下文老虎机中群体间收益差异的方法，同时也保持了竞争的整体性能。

Abstract: Offline contextual bandits allow one to learn policies from
historical/offline data without requiring online interaction. However, offline
policy optimization that maximizes overall expected rewards can unintentionally
amplify the reward disparities across groups. As a result, some groups might
benefit more than others from the learned policy, raising concerns about
fairness, especially when the resources are limited. In this paper, we study a
group-sensitive fairness constraint in offline contextual bandits, reducing
group-wise reward disparities that may arise during policy learning. We tackle
the following common-parity requirements: the reward disparity is constrained
within some user-defined threshold or the reward disparity should be minimized
during policy optimization. We propose a constrained offline policy
optimization framework by introducing group-wise reward disparity constraints
into an off-policy gradient-based optimization procedure. To improve the
estimation of the group-wise reward disparity during training, we employ a
doubly robust estimator and further provide a convergence guarantee for policy
optimization. Empirical results in synthetic and real-world datasets
demonstrate that our method effectively reduces reward disparities while
maintaining competitive overall performance.

</details>


### [120] [AI Agents in Drug Discovery](https://arxiv.org/abs/2510.27130)
*Srijit Seal,Dinh Long Huynh,Moudather Chelbi,Sara Khosravi,Ankur Kumar,Mattson Thieme,Isaac Wilks,Mark Davies,Jessica Mustali,Yannick Sun,Nick Edwards,Daniil Boiko,Andrei Tyrin,Douglas W. Selinger,Ayaan Parikh,Rahul Vijayan,Shoman Kasbekar,Dylan Reid,Andreas Bender,Ola Spjuth*

Main category: cs.LG

TL;DR: 本文概述了基于大型语言模型（LLMs）的智能AI系统在药物发现中的应用，包括文献汇总、毒性预测、自动化协议生成、小分子合成、药物重新定位和端到端决策等。早期部署已在速度、可重复性和可扩展性方面显示出显著优势，并解决了以往耗时长的问题。但也提出了与数据异构性、系统可靠性、隐私和基准测试相关的一些挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的药物发现流程耗时长且流程复杂，需要整合多样的生物医学数据来执行任务并通过实验迭代假设。因此，研究采用了具有感知、计算、行动和记忆工具的大型语言模型（LLMs），建立可以自主学习和自我优化的智能AI系统。这将提高药物发现的效率、可重复性和可扩展性，为未来科技支持科学和转化探索提供了方向。 

Method: 该工作涵盖了概念性和技术性两方面，介绍了从ReAct和Reflection到Supervisor和Swarm系统的агентическиеAI架构，并就这些系统在药物发现各个阶段的应用提出了见解和案例，包括文献综述、毒性预测、自动化协议生成、小分子合成、药物再定位以及端到端决策。文中还讨论了实施过程中遇到的挑战，比如数据异构性、系统可靠性、隐私和基准测试的数据支持。 

Result: 初步实施显示，智能AI系统在速度、可重复性和可扩展性方面实现了显著提升，能够将原本耗时长的工作流程压缩到数小时内，并且保持科学可追踪性。这代表了第一个全面工作的介绍，向工业界展示了部署在操作药物发现中的智能系统的实际实施和量化的成果影响。 

Conclusion: 尽管早期的部署已经取得了进展，但智能的AI系统在药物发现中的实施仍面临挑战，包括数据异构性、系统可靠性、隐私和基准测试等方面。未来的研究需要进一步解决这些挑战，以最大化技术对科学的支持和转化的影响。

Abstract: Artificial intelligence (AI) agents are emerging as transformative tools in
drug discovery, with the ability to autonomously reason, act, and learn through
complicated research workflows. Building on large language models (LLMs)
coupled with perception, computation, action, and memory tools, these agentic
AI systems could integrate diverse biomedical data, execute tasks, carry out
experiments via robotic platforms, and iteratively refine hypotheses in closed
loops. We provide a conceptual and technical overview of agentic AI
architectures, ranging from ReAct and Reflection to Supervisor and Swarm
systems, and illustrate their applications across key stages of drug discovery,
including literature synthesis, toxicity prediction, automated protocol
generation, small-molecule synthesis, drug repurposing, and end-to-end
decision-making. To our knowledge, this represents the first comprehensive work
to present real-world implementations and quantifiable impacts of agentic AI
systems deployed in operational drug discovery settings. Early implementations
demonstrate substantial gains in speed, reproducibility, and scalability,
compressing workflows that once took months into hours while maintaining
scientific traceability. We discuss the current challenges related to data
heterogeneity, system reliability, privacy, and benchmarking, and outline
future directions towards technology in support of science and translation.

</details>


### [121] [Exploring the Utilities of the Rationales from Large Language Models to Enhance Automated Essay Scoring](https://arxiv.org/abs/2510.27131)
*Hong Jiao,Hanna Choi,Haowei Hua*

Main category: cs.LG

TL;DR: 该研究探索了GPT-4.1和GPT-5生成的理由在使用Prompt 6作文的2012年Kaggle ASAP数据中自动评分的效用。结果显示，基于作文的评分通常优于基于理由的评分，具有更高的QWK。然而，在存在班级不平衡问题的0分的情况下，基于理由的评分具有更高的准确度。作文评分模型的集成增加了特定分数级别和所有分数级别的评分准确性。作文评分模型与理由评分模型的集成效果相同。将作文评分和两个理由模型集成后，获得了最高的评分准确性，QWK为0.870，优于文献中报告的0.848。


<details>
  <summary>Details</summary>
Motivation: 研究探索了GPT模型生成的理由在作文自动评分中的效用，旨在为解决班级不平衡问题提供解决方案，提高评分准确性。

Method: 研究使用了2012年Kaggle ASAP数据集中的Prompt 6作文。比较了基于作文的评分和基于理由的评分，使用了QWK和F1分数来评估。引入了集成模型，将作文评分模型与理由评分模型相结合，以此提高评分准确性。

Result: 总体而言，基于作文的评分优于基于理由的评分，但在处理0分时，基于理由的评分表现更好。集成作文评分和理由评分能够显著提高所有评分级别的准确性，特别是作文评分和两个理由模型的集成的最佳组合。

Conclusion: 提出了使用GPT模型生成的理由通过集成模型进行积分的新方法，这提高了在处理班级不平衡问题时的评分准确性，该贡献可以用于改进自动评分系统。

Abstract: This study explored the utilities of rationales generated by GPT-4.1 and
GPT-5 in automated scoring using Prompt 6 essays from the 2012 Kaggle ASAP
data. Essay-based scoring was compared with rationale-based scoring. The study
found in general essay-based scoring performed better than rationale-based
scoring with higher Quadratic Weighted Kappa (QWK). However, rationale-based
scoring led to higher scoring accuracy in terms of F1 scores for score 0 which
had less representation due to class imbalance issues. The ensemble modeling of
essay-based scoring models increased the scoring accuracy at both specific
score levels and across all score levels. The ensemble modeling of essay-based
scoring and each of the rationale-based scoring performed about the same.
Further ensemble of essay-based scoring and both rationale-based scoring
yielded the best scoring accuracy with QWK of 0.870 compared with 0.848
reported in literature.

</details>


### [122] [FairAD: Computationally Efficient Fair Graph Clustering via Algebraic Distance](https://arxiv.org/abs/2510.27136)
*Minh Phu Vuong,Young-Ju Lee,Iván Ojeda-Ruiz,Chul-Ho Lee*

Main category: cs.LG

TL;DR: 本研究提出的FairAD算法能够在保证公平性的前提下高效地进行图聚类，并且在实验中显示出较现有最佳算法快40倍的速度优势。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决在大型图数据中应用公平性约束的图聚类算法时面临的计算挑战，特别是在图聚类中实现基于保护群体比例一致性的公平性目标时的技术难题。

Method: FairAD算法首先基于代数距离的概念创建一个新的亲和度矩阵，并在此基础上实施图简化过程以找到代表性的节点，接着通过求解一个带有约束的最小化问题来获取具有公平性的聚类结果。

Result: 实验结果表明，FairAD在公平聚类方面优于或等同于当前最先进的公平图聚类算法，并且在速度上有显著优势（可快40倍）.

Conclusion: FairAD提供了一种有效地结合公平性和效率的图聚类解决方案，为处理大型图数据集中的公平性问题提供了新途径。

Abstract: Due to the growing concern about unsavory behaviors of machine learning
models toward certain demographic groups, the notion of 'fairness' has recently
drawn much attention from the community, thereby motivating the study of
fairness in graph clustering. Fair graph clustering aims to partition the set
of nodes in a graph into $k$ disjoint clusters such that the proportion of each
protected group within each cluster is consistent with the proportion of that
group in the entire dataset. It is, however, computationally challenging to
incorporate fairness constraints into existing graph clustering algorithms,
particularly for large graphs. To address this problem, we propose FairAD, a
computationally efficient fair graph clustering method. It first constructs a
new affinity matrix based on the notion of algebraic distance such that
fairness constraints are imposed. A graph coarsening process is then performed
on this affinity matrix to find representative nodes that correspond to $k$
clusters. Finally, a constrained minimization problem is solved to obtain the
solution of fair clustering. Experiment results on the modified stochastic
block model and six public datasets show that FairAD can achieve fair
clustering while being up to 40 times faster compared to state-of-the-art fair
graph clustering algorithms.

</details>


### [123] [Exploring Landscapes for Better Minima along Valleys](https://arxiv.org/abs/2510.27153)
*Tong Zhao,Jiacheng Li,Yuanchang Zhou,Guangming Tan,Weile Jia*

Main category: cs.LG

TL;DR: 提出了一个新的优化器适配器'E'，用于改进现有的基于梯度的优化器，以寻找更低且更泛化的局部最小值，尤其适用于难度较大的大规模批量训练任务中，提高了测试准确率。这项工作可能为优化算法的设计开辟了一个新的研究方向。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的优化器在达到局部最低点时停止搜索参数空间。然而，由于损失地形具有复杂的几何特性，这并不能保证找到最低或最佳泛化的点。为了应对这一挑战，提出了一种新的适配器'E'，以探索损失山谷并进一步寻找潜在更好的局部最小值。

Method: 通过添加适配器'E'到现有的基于梯度的优化器中，引导优化器在达到局部最小值后沿着损失山谷继续探索，从而发现更低、更平滑的局部最小值。同时提供了优化者在凸和非凸场景下的收敛性证明。最新测试表明，该适应器可以提高Lamb优化器在大规模批量训练任务中的测试准确率。此方法还适用于其他各种类型的批量训练任务。

Result: 测试结果表明，改进后的优化器ALTO（Adapted Lamb）平均提高了现有的最优批量训练优化器2.5%的测试准确性。这些实验展示出新的优化器适配器'E'的有效性并证明其在大规模批量训练任务中的泛化能力。

Conclusion: 这项工作提出了一个新的优化器适配器'E'，并在大规模批量训练任务中取得了显著的性能改进。它为设计优化算法提供了新的视角和研究方向，从而能够更好地推广到实际的应用场景。

Abstract: Finding lower and better-generalizing minima is crucial for deep learning.
However, most existing optimizers stop searching the parameter space once they
reach a local minimum. Given the complex geometric properties of the loss
landscape, it is difficult to guarantee that such a point is the lowest or
provides the best generalization. To address this, we propose an adaptor "E"
for gradient-based optimizers. The adapted optimizer tends to continue
exploring along landscape valleys (areas with low and nearly identical losses)
in order to search for potentially better local minima even after reaching a
local minimum. This approach increases the likelihood of finding a lower and
flatter local minimum, which is often associated with better generalization. We
also provide a proof of convergence for the adapted optimizers in both convex
and non-convex scenarios for completeness. Finally, we demonstrate their
effectiveness in an important but notoriously difficult training scenario,
large-batch training, where Lamb is the benchmark optimizer. Our testing
results show that the adapted Lamb, ALTO, increases the test accuracy
(generalization) of the current state-of-the-art optimizer by an average of
2.5% across a variety of large-batch training tasks. This work potentially
opens a new research direction in the design of optimization algorithms.

</details>


### [124] [Adaptive Defense against Harmful Fine-Tuning for Large Language Models via Bayesian Data Scheduler](https://arxiv.org/abs/2510.27172)
*Zixuan Hu,Li Shen,Zhenyi Wang,Yongxian Wei,Dacheng Tao*

Main category: cs.LG

TL;DR: 提出了一种无需攻击模拟的自适应调优阶段防御策略Bayesian Data Scheduler (BDS)，通过贝叶斯推理学习数据点的安全属性，约束调优过程以减轻有害数据的影响，实现实时自适应防御并有效转移至新数据，展示了该方法在多样化攻击和防御设置中的优越性。


<details>
  <summary>Details</summary>
Motivation: 当前防御策略存在根本性问题：无法超越有限的威胁模型扩展攻击模拟，难以适应多变的攻击场景。因此，提出了一种不依赖预先攻击模拟的方法来应对有害微调问题。

Method: 将有害微调防御定义为一个贝叶斯推断问题，通过学习数据点的安全属性，使用后验概率指导微调过程中的数据加权，以此来缓解有害微调的影响。

Result: 实验显示BDS在各种攻击和防御场景下均表现出色，证明了该方法的有效性和先进性。

Conclusion: 通过利用贝叶斯推断的特点，BDS能够适应具体数据集的具体威胁，从而实现自适应防御，并通过神经调度器实现了新数据的快速转移，提高了效率。

Abstract: Harmful fine-tuning poses critical safety risks to fine-tuning-as-a-service
for large language models. Existing defense strategies preemptively build
robustness via attack simulation but suffer from fundamental limitations: (i)
the infeasibility of extending attack simulations beyond bounded threat models
due to the inherent difficulty of anticipating unknown attacks, and (ii)
limited adaptability to varying attack settings, as simulation fails to capture
their variability and complexity. To address these challenges, we propose
Bayesian Data Scheduler (BDS), an adaptive tuning-stage defense strategy with
no need for attack simulation. BDS formulates harmful fine-tuning defense as a
Bayesian inference problem, learning the posterior distribution of each data
point's safety attribute, conditioned on the fine-tuning and alignment
datasets. The fine-tuning process is then constrained by weighting data with
their safety attributes sampled from the posterior, thus mitigating the
influence of harmful data. By leveraging the post hoc nature of Bayesian
inference, the posterior is conditioned on the fine-tuning dataset, enabling
BDS to tailor its defense to the specific dataset, thereby achieving adaptive
defense. Furthermore, we introduce a neural scheduler based on amortized
Bayesian learning, enabling efficient transfer to new data without retraining.
Comprehensive results across diverse attack and defense settings demonstrate
the state-of-the-art performance of our approach. Code is available at
https://github.com/Egg-Hu/Bayesian-Data-Scheduler.

</details>


### [125] [A Polynomial-time Algorithm for Online Sparse Linear Regression with Improved Regret Bound under Weaker Conditions](https://arxiv.org/abs/2510.27177)
*Junfan Li,Shizhong Liao,Zenglin Xu,Liqiang Nie*

Main category: cs.LG

TL;DR: 本文研究了在线稀疏线性回归(OSLR)问题，提出了一种新的多项式时间算法，改进了以前的遗憾界，在兼容性条件下获得了更好的性能。算法结合了Dantzig Selector，并引入了几种新颖的技术，例如自适应参数调整方案，批处理在线牛顿步以及精心设计的初始化策略。此外，算法还扩展到了可以观察额外特征的OSLR问题中，进一步优化了遗憾界。


<details>
  <summary>Details</summary>
Motivation: 在线稀疏线性回归(OSLR)问题中，算法只能使用给定实例的k个属性进行预测，并且已证明此问题是NP难问题。先前的工作在给定的数据矩阵满足特征线性独立性，兼容性条件或受限等距属性的情况下提出了多项式时间算法。为此，本文旨在开发一种新的多项式时间算法，通过降低lm1m-范数误差的收敛率来改进先前的遗憾界。

Method: 我们引入了一种新的多项式时间算法，结合了Dantzig Selector，同时利用了自适应参数调整方案，批处理在线牛顿步骤以及谨慎的初始化。具体的，算法使用了依赖于算法的采样方案来估计协方差矩阵，并对协方差非独立随机变量进行了细致的分析，开发了一种新的归纳方法来分析lm1m-范数误差，并且将遗憾进行分解来进一步优化算法性能。

Result: 我们的算法在兼容性条件下显著改进了Ito等人(2017)的工作，缩短了lm1m-范数误差的收敛率。此外，算法还扩展到了可以观察额外特征的OSLR问题中，进一步优化了遗憾界。

Conclusion: 本文提出了一种新的多项式时间算法，改进了在线稀疏线性回归中的遗憾界，同时优化了算法的性能，这在实际应用中具有重要意义。

Abstract: In this paper, we study the problem of online sparse linear regression (OSLR)
where the algorithms are restricted to accessing only $k$ out of $d$ attributes
per instance for prediction, which was proved to be NP-hard. Previous work gave
polynomial-time algorithms assuming the data matrix satisfies the linear
independence of features, the compatibility condition, or the restricted
isometry property. We introduce a new polynomial-time algorithm, which
significantly improves previous regret bounds (Ito et al., 2017) under the
compatibility condition that is weaker than the other two assumptions. The
improvements benefit from a tighter convergence rate of the $\ell_1$-norm error
of our estimators. Our algorithm leverages the well-studied Dantzig Selector,
but importantly with several novel techniques, including an algorithm-dependent
sampling scheme for estimating the covariance matrix, an adaptive parameter
tuning scheme, and a batching online Newton step with careful initializations.
We also give novel and non-trivial analyses, including an induction method for
analyzing the $\ell_1$-norm error, careful analyses on the covariance of
non-independent random variables, and a decomposition on the regret. We further
extend our algorithm to OSLR with additional observations where the algorithms
can observe additional $k_0$ attributes after each prediction, and improve
previous regret bounds (Kale et al., 2017; Ito et al., 2017).

</details>


### [126] [SERFLOW: A Cross-Service Cost Optimization Framework for SLO-Aware Dynamic ML Inference](https://arxiv.org/abs/2510.27182)
*Zongshun Zhang,Ibrahim Matta*

Main category: cs.LG

TL;DR: SERFLOW是一种通过在VM和无服务器函数之间动态分配机器学习模型分区来平衡处理和传输延迟并最小化成本的方法，它能够适应不同的请求分布。通过这种实时的负载平衡，SERFLOW将成本降低了超过23%。


<details>
  <summary>Details</summary>
Motivation: 传统的云资源分配策略在处理VM冷启动、长尾服务时间等因素时存在不足，SERFLOW被设计来解决这些问题，提高资源利用效率并降低云服务成本。

Method: SERFLOW通过将每个机器学习查询建模为沿着无环阶段序列的遍历，每一次阶段是稀疏模型参数的连续块，直到内部或最终分类器，实现了针对不同查询分布的需求。通过结合阶段特定的资源分配和基于请求吞吐量的VM和无服务器函数之间的负载平衡，SERFLOW实现了高效的成本管理。

Result: 实验结果显示，相较于传统的单一配置策略，SERFLOW能够显著降低成本，超过23%。同时，SERFLOW还有效地适应了动态工作负载，证明了其在处理多样化请求上的效率和灵活性。

Conclusion: SERFLOW通过有效的资源分配和负载均衡机制，展现了对动态适应性推理应用的支持，展示了处理机器学习模型复杂的资源需求的能力，而不会牺牲成本效益。

Abstract: Dynamic offloading of Machine Learning (ML) model partitions across different
resource orchestration services, such as Function-as-a-Service (FaaS) and
Infrastructure-as-a-Service (IaaS), can balance processing and transmission
delays while minimizing costs of adaptive inference applications. However,
prior work often overlooks real-world factors, such as Virtual Machine (VM)
cold starts, requests under long-tail service time distributions, etc. To
tackle these limitations, we model each ML query (request) as traversing an
acyclic sequence of stages, wherein each stage constitutes a contiguous block
of sparse model parameters ending in an internal or final classifier where
requests may exit. Since input-dependent exit rates vary, no single resource
configuration suits all query distributions. IaaS-based VMs become
underutilized when many requests exit early, yet rapidly scaling to handle
request bursts reaching deep layers is impractical. SERFLOW addresses this
challenge by leveraging FaaS-based serverless functions (containers) and using
stage-specific resource provisioning that accounts for the fraction of requests
exiting at each stage. By integrating this provisioning with adaptive load
balancing across VMs and serverless functions based on request ingestion,
SERFLOW reduces cloud costs by over $23\%$ while efficiently adapting to
dynamic workloads.

</details>


### [127] [Feature-Function Curvature Analysis: A Geometric Framework for Explaining Differentiable Models](https://arxiv.org/abs/2510.27207)
*Hamed Najafi,Dongsheng Luo,Jason Liu*

Main category: cs.LG

TL;DR: FFCA是一种新的解释性AI框架，它通过分析模型学习功能的几何特性来提供更全面和动态的特征角色描述。FFCA生成每个特征的4维签名，并提供直接的实证证据表明模型层级学习的过程。此外，该框架还提供了识别模型容量不足和预测过拟合开始的新诊断方法。


<details>
  <summary>Details</summary>
Motivation: 主流归因方法无法完全描述模型的最终状态，它们将特征的作用简化为单一分数，无法处理非线性和交互作用。为了解决这个问题，引入了FFCA框架，以便提供对学习过程的更全面和动态的解释。

Method: FFCA框架通过分析模型学习功能的几何特性，对每个特征产生一个4维的签名，其中包括影响、波动性、非线性和交互作用。同时，它还扩展到动态原型分析，跟踪训练过程中的特征签名演变。

Result: 实验表明FFCA及其静止和动态组件能够提供整个学习过程的细腻、可信的分析，而不只是简单的量化。此外，该框架能够识别模型容量不足，并预测过拟合的开始。

Conclusion: FFCA为模型解释提供了必要的几何上下文，使得解释过程从简单的量化转变为对整个学习过程的细致可信分析。

Abstract: Explainable AI (XAI) is critical for building trust in complex machine
learning models, yet mainstream attribution methods often provide an
incomplete, static picture of a model's final state. By collapsing a feature's
role into a single score, they are confounded by non-linearity and
interactions. To address this, we introduce Feature-Function Curvature Analysis
(FFCA), a novel framework that analyzes the geometry of a model's learned
function. FFCA produces a 4-dimensional signature for each feature, quantifying
its: (1) Impact, (2) Volatility, (3) Non-linearity, and (4) Interaction.
Crucially, we extend this framework into Dynamic Archetype Analysis, which
tracks the evolution of these signatures throughout the training process. This
temporal view moves beyond explaining what a model learned to revealing how it
learns. We provide the first direct, empirical evidence of hierarchical
learning, showing that models consistently learn simple linear effects before
complex interactions. Furthermore, this dynamic analysis provides novel,
practical diagnostics for identifying insufficient model capacity and
predicting the onset of overfitting. Our comprehensive experiments demonstrate
that FFCA, through its static and dynamic components, provides the essential
geometric context that transforms model explanation from simple quantification
to a nuanced, trustworthy analysis of the entire learning process.

</details>


### [128] [Soft Task-Aware Routing of Experts for Equivariant Representation Learning](https://arxiv.org/abs/2510.27222)
*Jaebyeong Jeon,Hyeonseo Jang,Jy-yong Sohn,Kibok Lee*

Main category: cs.LG

TL;DR: 介绍了一种名为Soft Task-Aware Routing (STAR)的投影头路由策略，旨在减少不变表示学习与等变表示学习中的冗余特征学习，提升模型容量利用效率。STAR还将投影头视为专家，使其专注于捕捉共享或任务特定的信息。实验结果表明，使用STAR的模型在多种迁移学习任务上实现了性能的一致性提升。


<details>
  <summary>Details</summary>
Motivation: 近期研究显示，同时学习不变表示和等变表示通常有利于下游任务。然而，目前的设计通过使用单独的投影头来实现这一点，这可能会导致冗余特征学习，并限制了模型容量的有效利用。因此，本文旨在提出一种新的投影头路由策略来解决这些问题，以提升模型性能。

Method: 提出了名为Soft Task-Aware Routing (STAR)的新方法，其核心是将投影头视作专家，并通过引入共享或任务特定信息的专业化过程来减少冗余特征学习。具体设计包括设计特定的共享桥接层，使得专家可以更好地专注其特定任务，同时降低用于无关任务的信息冗余度。我们进一步观察到，通过降低不变和等变嵌入间的典范关联度可以有效减少信息冗余，达到提升模型效率的效果。

Result: 实验结果表明，相较于现有方法，STAR设计能够使得模型在多种迁移学习任务上取得一致性的性能提升。STAR方法能够更有效利用模型容量，更好地适应各种任务需求。此外，通过比较不变和等变嵌入之间的典范关联度，我们进一步验证了STAR方法减少了冗余特征学习。这些发现验证了STAR方法的有效性。

Conclusion: 通过将不变和等变表示结合的方式，同时减少冗余特征学习，STAR提供了一个新的解决架构，这对于高效表示学习具有重要意义。我们的研究为进一步研究提供了潜在的新路径，特别是在复杂任务和模型应用中，可以进一步提升模型效果。

Abstract: Equivariant representation learning aims to capture variations induced by
input transformations in the representation space, whereas invariant
representation learning encodes semantic information by disregarding such
transformations. Recent studies have shown that jointly learning both types of
representations is often beneficial for downstream tasks, typically by
employing separate projection heads. However, this design overlooks information
shared between invariant and equivariant learning, which leads to redundant
feature learning and inefficient use of model capacity. To address this, we
introduce Soft Task-Aware Routing (STAR), a routing strategy for projection
heads that models them as experts. STAR induces the experts to specialize in
capturing either shared or task-specific information, thereby reducing
redundant feature learning. We validate this effect by observing lower
canonical correlations between invariant and equivariant embeddings.
Experimental results show consistent improvements across diverse transfer
learning tasks. The code is available at https://github.com/YonseiML/star.

</details>


### [129] [Not All Instances Are Equally Valuable: Towards Influence-Weighted Dataset Distillation](https://arxiv.org/abs/2510.27253)
*Qiyan Deng,Changqian Zheng,Lianpeng Qiao,Yuping Wang,Chengliang Chai,Lei Cao*

Main category: cs.LG

TL;DR: 提出一种基于影响函数的数据集精简框架IWD，该框架可以基于数据实例对精简目标的影响，给它们分配自适应权重。实验结果表明，IWD可以改善精简后的数据集质量，并提高模型性能，具有高达7.8％的准确率提升。 


<details>
  <summary>Details</summary>
Motivation: 现有数据集精简方法假设所有真实实例对精简过程的贡献是均等的，但在实际中，数据集中包含有益的、冗余的甚至有害的实例。直接对全数据集进行精简而不考虑数据质量可能降低模型性能。因此，本文提出IWD来改善数据集精简效率，提高模型性能。 

Method: IWD使用影响函数来估计数据实例对精简目标的影响，并根据这种影响为每个实例分配自适应权重。IWD可以与各种数据集精简框架无缝整合。 

Result: 实验结果表明，使用IWD可以得到质量更高、更好的将被精简数据集以及更高的模型性能。准确率最高提升了7.8％。 

Conclusion: IWD提供了一个有效的方法来改善数据集精简过程中的数据质量，从而提升了模型的性能。

Abstract: Dataset distillation condenses large datasets into synthetic subsets,
achieving performance comparable to training on the full dataset while
substantially reducing storage and computation costs. Most existing dataset
distillation methods assume that all real instances contribute equally to the
process. In practice, real-world datasets contain both informative and
redundant or even harmful instances, and directly distilling the full dataset
without considering data quality can degrade model performance. In this work,
we present Influence-Weighted Distillation IWD, a principled framework that
leverages influence functions to explicitly account for data quality in the
distillation process. IWD assigns adaptive weights to each instance based on
its estimated impact on the distillation objective, prioritizing beneficial
data while downweighting less useful or harmful ones. Owing to its modular
design, IWD can be seamlessly integrated into diverse dataset distillation
frameworks. Our empirical results suggest that integrating IWD tends to improve
the quality of distilled datasets and enhance model performance, with accuracy
gains of up to 7.8%.

</details>


### [130] [ECVL-ROUTER: Scenario-Aware Routing for Vision-Language Models](https://arxiv.org/abs/2510.27256)
*Xin Tang,Youfang Han,Fangfei Gou,Wei Zhao,Xin Meng,Yang Yu,Jinguo Zhang,Yuanchun Shi,Yuntao Wang,Tengxiang Zhang*

Main category: cs.LG

TL;DR: 在多模式任务场景下，提出了一种基于场景感知的路由框架（ECVL-ROUTER），根据用户需求动态选择合适模型，从而最大化整体效用。实验结果显示，该方法将超过80%的查询路由到小型模型，而解决问题的概率只降低了不到10%。


<details>
  <summary>Details</summary>
Motivation: 在多模式任务中，用户要求多样化，可以根据响应速度、输出质量和能耗来分类。单纯依赖大型模型所需的高延迟和能量消耗过高，小型模型则能在边缘设备上以低延迟和低能耗处理简单任务。因此，开发一种能够充分利用大型和小型模型优点的方法是必要的。

Method: 提出了一种新的基于场景的路由框架（ECVL-ROUTER），设计了一种新的路由策略和评估标准，根据用户的需求动态地选择合适大小的模型来处理每个请求。此外，创建了一个专门用于培训路由的多模式响应质量数据集。

Result: 实验结果显示，超过80%的查询可以成功地路由到小型模型，而解决问题的概率仅仅减少了不到10%。这种方法有效地利用了大型和小型模型的优点，并且能够在各种场景下提供更好的用户体验。

Conclusion: 该研究通过提出ECVL-ROUTER框架，证明了基于场景感知的路由方法在处理复杂多模式任务时的有效性。

Abstract: Vision-Language Models (VLMs) excel in diverse multimodal tasks. However,
user requirements vary across scenarios, which can be categorized into fast
response, high-quality output, and low energy consumption. Relying solely on
large models deployed in the cloud for all queries often leads to high latency
and energy cost, while small models deployed on edge devices are capable of
handling simpler tasks with low latency and energy cost. To fully leverage the
strengths of both large and small models, we propose ECVL-ROUTER, the first
scenario-aware routing framework for VLMs. Our approach introduces a new
routing strategy and evaluation metrics that dynamically select the appropriate
model for each query based on user requirements, maximizing overall utility. We
also construct a multimodal response-quality dataset tailored for router
training and validate the approach through extensive experiments. Results show
that our approach successfully routes over 80\% of queries to the small model
while incurring less than 10\% drop in problem solving probability.

</details>


### [131] [ODP-Bench: Benchmarking Out-of-Distribution Performance Prediction](https://arxiv.org/abs/2510.27263)
*Han Yu,Kehan Li,Dongbai Li,Yue He,Xingxuan Zhang,Peng Cui*

Main category: cs.LG

TL;DR: 提出了Out-of-Distribution Performance Prediction Benchmark (ODP-Bench), 一个综合基准，包括常用OOD数据集和现有实用性能预测算法，为各种算法提供便利和公平的比较，同时通过提供预训练模型保证比较的一致性和避免重复训练的负担，并进行深入的实验分析以更好地理解其能力边界


<details>
  <summary>Details</summary>
Motivation: 当前关于Out-of-Distribution (OOD) 性能预测的研究存在评估协议不一致的问题，多数工作仅涵盖有限数量的真实世界OOD数据集和分布变化类型。为了改进这一现状，引入ODP-Bench，以提供一个综合基准进行公平比较

Method: ODP-Bench 包括了常用的OOD数据集和现有的实用性能预测算法，并提供了预训练模型作为测试基准，同时进行了深入的实验分析以理解其能力边界

Result: 通过引入ODP-Bench，为各个算法提供了公平的比较环境，也避免了重复训练的负担，并揭示出这些算法的能力边界

Conclusion: 本研究通过提出ODP-Bench，为OOD性能预测算法的评估提供了一个全面而公平的框架，有利于未来的研究和开发

Abstract: Recently, there has been gradually more attention paid to Out-of-Distribution
(OOD) performance prediction, whose goal is to predict the performance of
trained models on unlabeled OOD test datasets, so that we could better leverage
and deploy off-the-shelf trained models in risk-sensitive scenarios. Although
progress has been made in this area, evaluation protocols in previous
literature are inconsistent, and most works cover only a limited number of
real-world OOD datasets and types of distribution shifts. To provide convenient
and fair comparisons for various algorithms, we propose Out-of-Distribution
Performance Prediction Benchmark (ODP-Bench), a comprehensive benchmark that
includes most commonly used OOD datasets and existing practical performance
prediction algorithms. We provide our trained models as a testbench for future
researchers, thus guaranteeing the consistency of comparison and avoiding the
burden of repeating the model training process. Furthermore, we also conduct
in-depth experimental analyses to better understand their capability boundary.

</details>


### [132] [Can LLMs Help You at Work? A Sandbox for Evaluating LLM Agents in Enterprise Environments](https://arxiv.org/abs/2510.27287)
*Harsh Vishwakarma,Ankush Agarwal,Ojas Patil,Chaitanya Devaguptapu,Mahesh Chandran*

Main category: cs.LG

TL;DR: 本文介绍了一个名为EnterpriseBench的企业基准测试，该测试模拟了企业的各种场景，旨在评估大型语言模型在企业环境中的表现。实验结果显示，即使是最先进的模型，任务完成率也只有41.8%。这表明在面向企业的AI系统方面还有很大的改进空间。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于，虽然大型语言模型在许多任务上表现良好，但在复杂多变的企业环境下，仍有很多挑战，比如数据分布复杂，访问控制机制等。因此，开发一个能够更真实地反映企业实际环境的基准测试是非常必要的。 

Method: 开发了一个名为EnterpriseBench的企业环境基准，其中包含了500个来自不同业务领域的任务。此外，还提出了一种新的数据生成流水线，该流水线可以基于组织元数据生成企业级任务，使得模型能够面对更加复杂的任务场景。 

Result: 实验结果显示，即使是目前最先进的大语言模型，在这个企业特定的基准上也只能完成大约41.8%的任务。这一结果揭示出当前模型在处理企业环境中的任务时存在明显不足。 

Conclusion: 研究表明，企业环境中的AI模型开发具有独特挑战。EnterpriseBench不仅为评估大型语言模型在企业中的表现提供了一个工具，还为未来的发展方向指出了道路。

Abstract: Enterprise systems are crucial for enhancing productivity and decision-making
among employees and customers. Integrating LLM based systems into enterprise
systems enables intelligent automation, personalized experiences, and efficient
information retrieval, driving operational efficiency and strategic growth.
However, developing and evaluating such systems is challenging due to the
inherent complexity of enterprise environments, where data is fragmented across
multiple sources and governed by sophisticated access controls. We present
EnterpriseBench, a comprehensive benchmark that simulates enterprise settings,
featuring 500 diverse tasks across software engineering, HR, finance, and
administrative domains. Our benchmark uniquely captures key enterprise
characteristics including data source fragmentation, access control
hierarchies, and cross-functional workflows. Additionally, we provide a novel
data generation pipeline that creates internally consistent enterprise tasks
from organizational metadata. Experiments with state-of-the-art LLM agents
demonstrate that even the most capable models achieve only 41.8% task
completion, highlighting significant opportunities for improvement in
enterprise-focused AI systems.

</details>


### [133] [Temporal Cardiovascular Dynamics for Improved PPG-Based Heart Rate Estimation](https://arxiv.org/abs/2510.27297)
*Berken Utku Demirel,Christian Holz*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法，通过互信息研究心率的非线性混沌行为，并改进了实际生活条件下心率估计的深度学习解决方案。该方法在真实场景的数据集上验证了其性能，相较于传统方法和现有机器学习技术，在估计心率方面有显著的提升，可提高40%的准确度。


<details>
  <summary>Details</summary>
Motivation: 心率的振荡行为复杂且非线性，这给日常生活中的心血管健康监测带来了挑战。为了更好地理解和处理这种非线性时序复杂性，本文提出了一种新的方法来改善实际条件下的心率估计。

Method: 通过利用互信息研究心率的非线性混沌行为，提出一种新型的方法来改进心率估计的深度学习解决方案。该方法在四个真实场景数据集上进行了验证，并通过广泛的消融实验与现有算法进行了比较。

Result: 实验结果表明，与传统方法和现有机器学习技术相比，提出的方法在估计心率方面有显著的提升。最高可达40%的改进，同时减少了对多传感器模式的依赖并消除了后处理步骤的需求。

Conclusion: 本文提出的方法显著提高了心率的估计精度，显示了在处理心率非线性复杂性方面的有效性和实用性。

Abstract: The oscillations of the human heart rate are inherently complex and
non-linear -- they are best described by mathematical chaos, and they present a
challenge when applied to the practical domain of cardiovascular health
monitoring in everyday life. In this work, we study the non-linear chaotic
behavior of heart rate through mutual information and introduce a novel
approach for enhancing heart rate estimation in real-life conditions. Our
proposed approach not only explains and handles the non-linear temporal
complexity from a mathematical perspective but also improves the deep learning
solutions when combined with them. We validate our proposed method on four
established datasets from real-life scenarios and compare its performance with
existing algorithms thoroughly with extensive ablation experiments. Our results
demonstrate a substantial improvement, up to 40\%, of the proposed approach in
estimating heart rate compared to traditional methods and existing
machine-learning techniques while reducing the reliance on multiple sensing
modalities and eliminating the need for post-processing steps.

</details>


### [134] [Un-Attributability: Computing Novelty From Retrieval & Semantic Similarity](https://arxiv.org/abs/2510.27313)
*Philipp Davydov,Ameya Prabhu,Matthias Bethge,Elisa Nguyen,Seong Joon Oh*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法来衡量语言模型输出的新颖性，即通过判断模型输出是否可以归因于预训练语料库中的任何部分来定义。这种方法通过一个两阶段检索管道实现，首先使用轻量级的GIST嵌入索引预训练语料库，然后使用ColBERTv2重新排序候选输出。研究发现模型输出的新颖性依赖于数据范围、领域特征以及调优类型，这种方法使得在大规模预训练数据上进行新颖性评估成为可能。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过语言模型预训练语料库来理解模型行为。以往的方法通常通过清除一部分训练数据来测试模型输出是否受到影响，而本文则从反向出发，探索哪些模型输出无法归因于任何预训练的语料库部分，以此作为衡量模型新颖性的标准。这种方法不仅提高了新颖性评估的效率，也能够更好地适用于大规模预训练数据集。

Method: 本文提出了基于un-attributability的概念来定义语言模型新颖性。通过构建一个两阶段的检索流程，首先是基于轻量级GIST嵌入对预训练语料库进行索引，其次是用ColBERTv2来重排序候选输出。该方法将模型输出与预训练数据的相似度进行比较，以此来判断新颖性。此外，还提供了大量的语料库索引和数据以支持该分析方法的广泛复制和扩展。

Result: 研究发现语言模型会在更长时间范围内借鉴预训练数据；某些领域倾向于促进或抑制新颖性；指示调优不仅改变了表达风格，而且增加了新颖性。这种方法使得在大规模的预训练数据上对模型新颖性进行有效和高效的评估成为可能。

Conclusion: 将新颖性评估重新定义为un-attributability不仅提高了效率，也使得对大规模预训练数据进行新颖性评估成为可能。进一步的研究支持其在更大范围内的应用并将提供更多的工具和资源来支持复制和扩展此分析方法的研究。

Abstract: Understanding how language-model outputs relate to the pretraining corpus is
central to studying model behavior. Most training data attribution (TDA)
methods ask which training examples causally influence a given output, often
using leave-one-out tests. We invert the question: which outputs cannot be
attributed to any pretraining example? We introduce un-attributability as an
operational measure of semantic novelty: an output is novel if the pretraining
corpus contains no semantically similar context. We approximate this with a
simple two-stage retrieval pipeline: index the corpus with lightweight GIST
embeddings, retrieve the top-n candidates, then rerank with ColBERTv2. If the
nearest corpus item is less attributable than a human-generated text reference,
we consider the output of the model as novel. We evaluate on SmolLM and SmolLM2
and report three findings: (1) models draw on pretraining data across much
longer spans than previously reported; (2) some domains systematically promote
or suppress novelty; and (3) instruction tuning not only alters style but also
increases novelty. Reframing novelty assessment around un-attributability
enables efficient analysis at pretraining scale. We release ~20 TB of corpus
chunks and index artifacts to support replication and large-scale extension of
our analysis at https://huggingface.co/datasets/stai-tuebingen/faiss-smollm

</details>


### [135] [MedM2T: A MultiModal Framework for Time-Aware Modeling with Electronic Health Record and Electrocardiogram Data](https://arxiv.org/abs/2510.27321)
*Yu-Chen Kuo,Yi-Ju Tseng*

Main category: cs.LG

TL;DR: MedM2T 是一种时间感知的多模态框架，用于处理医疗数据中的多重模态性和异质性时间结构。它在MIMIC-IV和MIMIC-IV-ECG数据集上超过了最先进的多模态学习框架和现有的时间序列模型。


<details>
  <summary>Details</summary>
Motivation: 医疗数据中的内在多重模态性和异质性时间结构带来了显著的建模挑战。

Method: MedM2T 集成了三项关键技术：稀疏时间序列编码器、层次时间感知融合以及双向注意机制。此外，MedM2T 使用模态特异性预训练编码器来消除模态之间的颗粒度差距，并将生成的特征在共享编码器内对齐。

Result: 在心脏疾病预测、住院死亡率预测和重症监护病房住院天数回归任务上，MedM2T 达到了0.947 AUROC 和 0.706 AUPRC的心脏疾病预测；0.901 AUROC 和 0.558 AUPRC的死亡率预测；以及 2.31 MAE 的住院天数回归。

Conclusion: 实验结果证明了 MedM2T 的稳健性和广泛适用性，使其成为临床预测中一种有前景的工具。

Abstract: The inherent multimodality and heterogeneous temporal structures of medical
data pose significant challenges for modeling. We propose MedM2T, a time-aware
multimodal framework designed to address these complexities. MedM2T integrates:
(i) Sparse Time Series Encoder to flexibly handle irregular and sparse time
series, (ii) Hierarchical Time-Aware Fusion to capture both micro- and
macro-temporal patterns from multiple dense time series, such as ECGs, and
(iii) Bi-Modal Attention to extract cross-modal interactions, which can be
extended to any number of modalities. To mitigate granularity gaps between
modalities, MedM2T uses modality-specific pre-trained encoders and aligns
resulting features within a shared encoder. We evaluated MedM2T on MIMIC-IV and
MIMIC-IV-ECG datasets for three tasks that encompass chronic and acute disease
dynamics: 90-day cardiovascular disease (CVD) prediction, in-hospital mortality
prediction, and ICU length-of-stay (LOS) regression. MedM2T outperformed
state-of-the-art multimodal learning frameworks and existing time series
models, achieving an AUROC of 0.947 and an AUPRC of 0.706 for CVD prediction;
an AUROC of 0.901 and an AUPRC of 0.558 for mortality prediction; and Mean
Absolute Error (MAE) of 2.31 for LOS regression. These results highlight the
robustness and broad applicability of MedM2T, positioning it as a promising
tool in clinical prediction. We provide the implementation of MedM2T at
https://github.com/DHLab-TSENG/MedM2T.

</details>


### [136] [Reasoning Models Sometimes Output Illegible Chains of Thought](https://arxiv.org/abs/2510.27338)
*Arun Jose*

Main category: cs.LG

TL;DR: 研究表明，通过结果导向的强化学习训练的语言模型，其链式推理过程（CoT）对于人类和AI监控来说往往是不可理解的。尽管模型可以生成准确的答案，但它们的推理过程通常是不透明的，尤其是在较难的问题上。这表明，除非明确优化可读性，否则结果导向的RL会自然地产生推理过程越来越晦涩难懂的模型，可能破坏监控方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于监控强化学习训练的语言模型的意图和潜在恶意行为需要模型的链式推理过程（CoT）清晰且忠实。然而，实际的模型在实现这一点上遇到了挑战，进而探讨解决方法。

Method: 研究对比了14种推理模型，在不同类型问题上的推理解读性，观察是否模型在生成答案正确的同时，还保持了推理过程的清晰。此外，还考虑了通过强制模型使用可读部分对模型性能的影响。

Result: 研究发现，尽管模型生成的答案是可读的，它们利用不可读的推理来得出正确答案，且这种推理的可读性随着问题难度的增加而降低。当强制使用可读部分时，模型的准确率下降了53%。同时并无证据表明推理的可读性与性能正相关。研究观察到可能促进这一现象的原因，如通过掩盖信息的细微行为（steganography）、训练数据中的细节偏差（training artifacts）以及遗留掉的特殊词汇（vestigial tokens）的存在。

Conclusion: 研究结论是，如果没有明确的可读性优化，通过结果导向的RL训练产生的模型将具有越来越不透明的推理过程，这可能破坏了原来监控方法的有效性。

Abstract: Language models trained via outcome-based reinforcement learning (RL) to
reason using chain-of-thought (CoT) have shown remarkable performance.
Monitoring such a model's CoT may allow us to understand its intentions and
detect potential malicious behavior. However, to be effective, this requires
that CoTs are legible and faithful. We study CoT legibility across 14 reasoning
models, finding that RL often causes reasoning to become illegible to both
humans and AI monitors, with reasoning models (except Claude) generating
illegible CoTs while returning to perfectly readable final answers. We show
that models use illegible reasoning to reach correct answers (accuracy dropping
by 53\% when forced to use only legible portions), yet find no correlation
between legibility and performance when resampling - suggesting the
relationship is more nuanced. We also find that legibility degrades on harder
questions. We discuss potential hypotheses for these results, including
steganography, training artifacts, and vestigial tokens. These results suggest
that without explicit optimization for legibility, outcome-based RL naturally
produces models with increasingly opaque reasoning processes, potentially
undermining monitoring approaches.

</details>


### [137] [Measuring Chain-of-Thought Monitorability Through Faithfulness and Verbosity](https://arxiv.org/abs/2510.27378)
*Austin Meek,Eitan Sprejer,Iván Arcuschin,Austin J. Brockmeier,Steven Basart*

Main category: cs.LG

TL;DR: 论文提出了一个衡量模型生成的chain-of-thought (CoT) 的透明度和详细程度的新方法，通过引入'verbose'的概念，即CoT是否列出了解决任务所需的所有因素。并开发了一个综合的可监控性得分，用于评估模型的外部工作记忆功能。实验表明，一些模型即使在表现忠实的情况下也可能难以监控，因为它们可能会遗漏关键因素。此方法公开了其评估代码和库，以支持后续者的工作。


<details>
  <summary>Details</summary>
Motivation: 论文动机在于提高对大型语言模型内部推理过程的理解和监控,尤其是在模型回答与提示输入相关的推理任务时的表现。通过引入'verbose'的概念，该论文希望通过更全面的方法去衡量模型chain-of-thought (CoT) 的透明性和详细程度，而不是仅仅关注模型在接收到特定提示后是否改变其答案。这有助于更好地理解和改进模型的可信任度与安全性。

Method: 论文提出了一种结合诚实性(faithfulness) 和详细性(verbosity) 的综合可监控性分数，用来评估模型的外部工作记忆功能。并基于BBH, GPQA, 和 MMLU 进行了实验评估，使用了Inspect库来支持可重复研究的代码发布。这项研究有助于检测模型在提供关键推理步骤时的透明度。

Result: 研究表明，即使模型在某些方面表现合乎诚实（faithfulness）标准，它们在回答问题时也可能会忽略关键因素。这表明仅仅观察模型是否在收到提示的情况下改变答案，无法全面评估模型推理过程的质量。此外，模型的可监控性在不同的模型架构中表现存在显著差异。

Conclusion: 论文强调了使用更精细和量化的指标来评估模型内部工作的必要性。通过引入综合的可监控性得分，该研究为理解和改进大型语言模型的外部工作记忆带来了可能。

Abstract: Chain-of-thought (CoT) outputs let us read a model's step-by-step reasoning.
Since any long, serial reasoning process must pass through this textual trace,
the quality of the CoT is a direct window into what the model is thinking. This
visibility could help us spot unsafe or misaligned behavior (monitorability),
but only if the CoT is transparent about its internal reasoning (faithfulness).
Fully measuring faithfulness is difficult, so researchers often focus on
examining the CoT in cases where the model changes its answer after adding a
cue to the input. This proxy finds some instances of unfaithfulness but loses
information when the model maintains its answer, and does not investigate
aspects of reasoning not tied to the cue. We extend these results to a more
holistic sense of monitorability by introducing verbosity: whether the CoT
lists every factor needed to solve the task. We combine faithfulness and
verbosity into a single monitorability score that shows how well the CoT serves
as the model's external `working memory', a property that many safety schemes
based on CoT monitoring depend on. We evaluate instruction-tuned and reasoning
models on BBH, GPQA, and MMLU. Our results show that models can appear faithful
yet remain hard to monitor when they leave out key factors, and that
monitorability differs sharply across model families. We release our evaluation
code using the Inspect library to support reproducible future work.

</details>


### [138] [FedMuon: Accelerating Federated Learning with Matrix Orthogonalization](https://arxiv.org/abs/2510.27403)
*Junkang Liu,Fanhua Shang,Junchao Zhou,Hongying Liu,Yuanyuan Liu,Jin Liu*

Main category: cs.LG

TL;DR: Muon 优化器在局部更新中引入了矩阵正交化来解决 Federated Learning 中的通信瓶颈问题。然而在非 I.I.D. 设置下，FedMuon 通过汇聚动量和局部全局对齐来减少客户端漂移，从而提高了收敛速度并减少了通信轮次。实验证明 FedMuon 相对于其他基线方法在减少通信轮次和提高测试准确性方面有显著效果。


<details>
  <summary>Details</summary>
Motivation: 解决 Fedrated Learning 中的通信瓶颈问题, 特别是在非 I.I.D. 设置下减少客户端漂移的挑战

Method: 引入 Muon 优化器来解决矩阵结构参数的优化问题，并在 Fedrated Learning 框架下提出 FedMuon, 通过汇聚动量和局部全局对齐来解决非 I.I.D. 设置下的客户端漂移问题

Result: FedMuon 能加速收敛速度并减少通信轮次，相对于其他基线方法（如 Local SGD 和 Local AdamW），在语言和视觉模型上均表现出显著改进

Conclusion: FedMuon 提供了一种新的方法来解决 Federated Learning 中的挑战，特别在非 I.I.D. 设置下，通过引入新的优化技术，实现了更好的性能和更快的收敛速度

Abstract: The core bottleneck of Federated Learning (FL) lies in the communication
rounds. That is, how to achieve more effective local updates is crucial for
reducing communication rounds. Existing FL methods still primarily use
element-wise local optimizers (Adam/SGD), neglecting the geometric structure of
the weight matrices. This often leads to the amplification of pathological
directions in the weights during local updates, leading deterioration in the
condition number and slow convergence. Therefore, we introduce the Muon
optimizer in local, which has matrix orthogonalization to optimize
matrix-structured parameters. Experimental results show that, in IID setting,
Local Muon significantly accelerates the convergence of FL and reduces
communication rounds compared to Local SGD and Local AdamW. However, in non-IID
setting, independent matrix orthogonalization based on the local distributions
of each client induces strong client drift. Applying Muon in non-IID FL poses
significant challenges: (1) client preconditioner leading to client drift; (2)
moment reinitialization. To address these challenges, we propose a novel
Federated Muon optimizer (FedMuon), which incorporates two key techniques: (1)
momentum aggregation, where clients use the aggregated momentum for local
initialization; (2) local-global alignment, where the local gradients are
aligned with the global update direction to significantly reduce client drift.
Theoretically, we prove that \texttt{FedMuon} achieves a linear speedup
convergence rate without the heterogeneity assumption, where $S$ is the number
of participating clients per round, $K$ is the number of local iterations, and
$R$ is the total number of communication rounds. Empirically, we validate the
effectiveness of FedMuon on language and vision models. Compared to several
baselines, FedMuon significantly reduces communication rounds and improves test
accuracy.

</details>


### [139] [Atlas-Alignment: Making Interpretability Transferable Across Language Models](https://arxiv.org/abs/2510.27413)
*Bruno Puri,Jim Berend,Sebastian Lapuschkin,Wojciech Samek*

Main category: cs.LG

TL;DR: 介绍了一种名为Atlas-Alignment的框架，用于在语言模型之间转移可解释性，通过将未知的潜在空间对齐到一个标记的、人类可解释的概念图集上来实现。该框架使得在原来不透明的模型中进行语义特征搜索和检索、以及沿着人类可解释的概念进行生成操作成为可能，并且这种对齐不需要额外的标记概念数据，从而大幅降低了解释AI的成本。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型可解释性研究存在实现成本高、难以规模化的挑战，且通常需要对每个新模型单独训练稀疏自动编码器、标注SAE组件及其验证，这样的过程非常耗时且繁琐。因此，本研究致力于开发一种简便高效的方法来转移语言模型的可解释性，以提高模型的透明度和控制性。

Method: 提出了变量Atlas-Alignment框架，通过利用尽可能多的共享输入以及轻量级的表示对齐技术，将未知的潜在空间与一个标记的、人类可理解的概念图集对齐，实现解释性的跨模型转移。这种方法仅需要共享输入和轻量级表示对齐技术，大大减少了解释AI所需的人力和资源。

Result: 实验证明，相较于传统的解释机制，变量Atlas-Alignment不仅能够实现更好的语义特征搜索和生成导向，还能够以较低的边际成本使多个新模型变得透明且可控制，无需为了每个单独的新模型重复投资用于训练稀疏自动编码器和手动标注的概念数据。此外，在定量和定性的评估中，研究团队展示了简单的表示对齐技术能够提供强大的语义检索功能和有导向的生成能力。

Conclusion: 通过使用Atlas-Alignment对多语言模型进行对齐，能够有效地降低解释AI的成本，并且仅通过一次高昂的投入构建高质量的概念图集就能够在许多新模型中实现透明和控制性，使得研发可解释的人工智能成为了一项更加可行和高效的任务。

Abstract: Interpretability is crucial for building safe, reliable, and controllable
language models, yet existing interpretability pipelines remain costly and
difficult to scale. Interpreting a new model typically requires costly training
of model-specific sparse autoencoders, manual or semi-automated labeling of SAE
components, and their subsequent validation. We introduce Atlas-Alignment, a
framework for transferring interpretability across language models by aligning
unknown latent spaces to a Concept Atlas - a labeled, human-interpretable
latent space - using only shared inputs and lightweight representational
alignment techniques. Once aligned, this enables two key capabilities in
previously opaque models: (1) semantic feature search and retrieval, and (2)
steering generation along human-interpretable atlas concepts. Through
quantitative and qualitative evaluations, we show that simple representational
alignment methods enable robust semantic retrieval and steerable generation
without the need for labeled concept data. Atlas-Alignment thus amortizes the
cost of explainable AI and mechanistic interpretability: by investing in one
high-quality Concept Atlas, we can make many new models transparent and
controllable at minimal marginal cost.

</details>


### [140] [MVeLMA: Multimodal Vegetation Loss Modeling Architecture for Predicting Post-fire Vegetation Loss](https://arxiv.org/abs/2510.27443)
*Meenu Ravi,Shailik Sarkar,Yanshen Sun,Vaishnavi Singh,Chang-Tien Lu*

Main category: cs.LG

TL;DR: 提出了一个新的机器学习管道MVeLMA来预测火灾后的植被损失，该管道可以提高预测精度，并且有助于制定生态政策和发展野生动物恢复管理。


<details>
  <summary>Details</summary>
Motivation: 目前对于理解火灾后植被损失的因素、它们的模态及相互作用尚不完全了解，并且在预测模型的可解释性上存在局限，导致模型在实际应用中实用性较差。因此，提出了一个新的机器学习管道MVeLMA来更准确地预测火灾后的植被损失。

Method: MVeLMA使用了一个多模态特征集成流水线和堆叠集成架构，以捕捉不同模态并利用概率建模方法进行不确定性的量化。通过综合实验，证明了该模型在预测火灾后植被损失方面优于现有的其他模型。

Result: 实验结果表明，该模型在预测火灾后植被损失方面优于其他常用的模型。通过生成植被损失置信图，该模型可以帮助识别高风险地区，并进行针对性恢复。

Conclusion: 这项工作的结果将有助于未来灾难响应规划、生态政策的制定以及野生动物恢复管理。

Abstract: Understanding post-wildfire vegetation loss is critical for developing
effective ecological recovery strategies and is often challenging due to the
extended time and effort required to capture the evolving ecosystem features.
Recent works in this area have not fully explored all the contributing factors,
their modalities, and interactions with each other. Furthermore, most research
in this domain is limited by a lack of interpretability in predictive modeling,
making it less useful in real-world settings. In this work, we propose a novel
end-to-end ML pipeline called MVeLMA (\textbf{M}ultimodal \textbf{Ve}getation
\textbf{L}oss \textbf{M}odeling \textbf{A}rchitecture) to predict county-wise
vegetation loss from fire events. MVeLMA uses a multimodal feature integration
pipeline and a stacked ensemble-based architecture to capture different
modalities while also incorporating uncertainty estimation through
probabilistic modeling. Through comprehensive experiments, we show that our
model outperforms several state-of-the-art (SOTA) and baseline models in
predicting post-wildfire vegetation loss. Furthermore, we generate vegetation
loss confidence maps to identify high-risk counties, thereby helping targeted
recovery efforts. The findings of this work have the potential to inform future
disaster relief planning, ecological policy development, and wildlife recovery
management.

</details>


### [141] [Simplex-to-Euclidean Bijections for Categorical Flow Matching](https://arxiv.org/abs/2510.27480)
*Bernardo Williams,Victor M. Yeom-Song,Marcelo Hartmann,Arto Klami*

Main category: cs.LG

TL;DR: 提出了一种在单纯形上学习和采样概率分布的方法，通过光滑双射将开单纯形映射到欧氏空间，利用Aitchison几何学定义映射，支持通过狄利克雷插值对分类数据建模，使得在仿射空间中通过双射进行密度建模的同时，仍能准确恢复原始离散分布。与之前使用黎曼几何或自定义噪声过程的单纯形方法相比，该方法在欧氏空间中操作，同时尊重Aitchison几何，并在合成数据集和真实数据集上实现了竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 为了在单纯形上学习和采样概率分布，同时支持离散数据的建模，提出了一种新方法。

Method: 通过将开单纯形映射到欧氏空间，利用Aitchison几何学定义映射，并通过狄利克雷插值对分类数据进行建模，实现了在欧氏空间中的密度建模与离散分布的准确恢复。

Result: 提出的方法在欧氏空间中操作，同时尊重Aitchison几何，并在合成数据集和真实数据集上实现了竞争性性能。与之前的方法相比，该方法具有显著优点。

Conclusion: 该方法在单纯形上学习和采样概率分布的同时，支持离散数据的建模，并在欧氏空间中实现了有效的密度建模与竞争性性能。

Abstract: We propose a method for learning and sampling from probability distributions
supported on the simplex. Our approach maps the open simplex to Euclidean space
via smooth bijections, leveraging the Aitchison geometry to define the
mappings, and supports modeling categorical data by a Dirichlet interpolation
that dequantizes discrete observations into continuous ones. This enables
density modeling in Euclidean space through the bijection while still allowing
exact recovery of the original discrete distribution. Compared to previous
methods that operate on the simplex using Riemannian geometry or custom noise
processes, our approach works in Euclidean space while respecting the Aitchison
geometry, and achieves competitive performance on both synthetic and real-world
data sets.

</details>


### [142] [Thought Branches: Interpreting LLM Reasoning Requires Resampling](https://arxiv.org/abs/2510.27484)
*Uzay Macar,Paul C. Bogdan,Senthooran Rajamanoharan,Neel Nanda*

Main category: cs.LG

TL;DR: 通过重新采样研究模型决策，发现用单一条理进行推理研究不足以理解因果影响和底层计算。重新采样在多种情况下可实现可靠因果分析，清晰地揭示出模型推理的过程，并提供原理性的一条理干预方法。


<details>
  <summary>Details</summary>
Motivation: 大多数工作只研究单一的链式思考，但这些模型实际上定义了多种可能的链式思考。通过重新采样调查模型决策，可以更全面地理解这些模型的因果影响和计算机制。研究单一样本难以完全了解模型的因果影响。通过研究分布可以更深入地理解模型的推理过程。

Method: 通过重新采样方法研究模型决策的因果影响，包括核对模型声明的原因是否导致行动、评估人工编辑是否足以引导推理、考察删除推理步骤的影响和研究不忠实的链式思考情况。引入了一种新的评估模型稳健性的指标，称为恢复力指标。提出了一种适应因果中介分析的方法，以找到实际因果影响的方式。

Result: 在不同的案例研究中，重新采样显示了每个原因如何影响模型的决策，发现人工编辑对决策的影响较小且不稳定。另外，重要的规划陈述抵抗删除，但它们的影响在删除后仍然很大。即使预测提供了一些暗示，这些暗示也对最终输出有累积影响。重新采样增强了模型因果分析的可靠性，并提供了明确的模型推理叙述。

Conclusion: 通过重新采样研究分布，研究人员能够对模型的决策过程进行更详细的了解，不仅可以发现模型表面的因果结构，也能发现模型内部更为潜在的因果关系。这种方法提供了更清晰的模型推理解释，并提供了科学的干预方法。

Abstract: Most work interpreting reasoning models studies only a single
chain-of-thought (CoT), yet these models define distributions over many
possible CoTs. We argue that studying a single sample is inadequate for
understanding causal influence and the underlying computation. Though fully
specifying this distribution is intractable, it can be understood by sampling.
We present case studies using resampling to investigate model decisions. First,
when a model states a reason for its action, does that reason actually cause
the action? In "agentic misalignment" scenarios, we resample specific sentences
to measure their downstream effects. Self-preservation sentences have small
causal impact, suggesting they do not meaningfully drive blackmail. Second, are
artificial edits to CoT sufficient for steering reasoning? These are common in
literature, yet take the model off-policy. Resampling and selecting a
completion with the desired property is a principled on-policy alternative. We
find off-policy interventions yield small and unstable effects compared to
resampling in decision-making tasks. Third, how do we understand the effect of
removing a reasoning step when the model may repeat it post-edit? We introduce
a resilience metric that repeatedly resamples to prevent similar content from
reappearing downstream. Critical planning statements resist removal but have
large effects when eliminated. Fourth, since CoT is sometimes "unfaithful", can
our methods teach us anything in these settings? Adapting causal mediation
analysis, we find that hints that have a causal effect on the output without
being explicitly mentioned exert a subtle and cumulative influence on the CoT
that persists even if the hint is removed. Overall, studying distributions via
resampling enables reliable causal analysis, clearer narratives of model
reasoning, and principled CoT interventions.

</details>


### [143] [FedAdamW: A Communication-Efficient Optimizer with Convergence and Generalization Guarantees for Federated Large Models](https://arxiv.org/abs/2510.27486)
*Junkang Liu,Fanhua Shang,Kewen Zhu,Hongying Liu,Yuanyuan Liu,Jin Liu*

Main category: cs.LG

TL;DR: 提出了一个新的FedAdamW算法，旨在解决AdamW在联邦学习环境中遇到的数据异质性问题以及本地过拟合和收敛速度慢的问题。该算法通过本地修正机制和解耦权重衰减来缓解本地过拟合，并且在理论上证明了其收敛速度的线性加速。实验结果表明，FedAdamW相比其他基线算法在通信轮次和测试精度上都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 直接在联邦学习环境下应用AdamW遇到数据异质性问题，导致第二动量估计$oldsymbol{v}$的高方差；本地AdamW过拟合引起客户端漂移；每次通信轮次重新初始化动量估计（$oldsymbol{v}$，$oldsymbol{m}$）也可能导致收敛速度减慢。

Method: 提出FedAdamW算法，通过本地修正机制和解耦权重衰减减缓本地过拟合，同时有效聚合第二动量估计的均值以减少方差并重新初始化动量估计。理论分析上证明了FedAdamW收敛速度的线性加速性，实践经验验证了其效果。

Result: FedAdamW通过减少通信轮次和提高测试精度相对于几种基线算法显示出更好的效果。算法的代码可通过提供的链接获取。

Conclusion: 提出了FedAdamW算法，通过本地修正机制和解耦权重衰减以及其他创新性策略有效解决联邦学习中的挑战，提高了训练大规模模型的效率。

Abstract: AdamW has become one of the most effective optimizers for training
large-scale models. We have also observed its effectiveness in the context of
federated learning (FL). However, directly applying AdamW in federated learning
settings poses significant challenges: (1) due to data heterogeneity, AdamW
often yields high variance in the second-moment estimate $\boldsymbol{v}$; (2)
the local overfitting of AdamW may cause client drift; and (3) Reinitializing
moment estimates ($\boldsymbol{v}$, $\boldsymbol{m}$) at each round slows down
convergence. To address these challenges, we propose the first
\underline{Fed}erated \underline{AdamW} algorithm, called \texttt{FedAdamW},
for training and fine-tuning various large models. \texttt{FedAdamW} aligns
local updates with the global update using both a \textbf{local correction
mechanism} and decoupled weight decay to mitigate local overfitting.
\texttt{FedAdamW} efficiently aggregates the \texttt{mean} of the second-moment
estimates to reduce their variance and reinitialize them. Theoretically, we
prove that \texttt{FedAdamW} achieves a linear speedup convergence rate of
$\mathcal{O}(\sqrt{(L \Delta \sigma_l^2)/(S K R \epsilon^2)}+(L \Delta)/R)$
without \textbf{heterogeneity assumption}, where $S$ is the number of
participating clients per round, $K$ is the number of local iterations, and $R$
is the total number of communication rounds. We also employ PAC-Bayesian
generalization analysis to explain the effectiveness of decoupled weight decay
in local training. Empirically, we validate the effectiveness of
\texttt{FedAdamW} on language and vision Transformer models. Compared to
several baselines, \texttt{FedAdamW} significantly reduces communication rounds
and improves test accuracy. The code is available in
https://github.com/junkangLiu0/FedAdamW.

</details>


### [144] [DP-FedPGN: Finding Global Flat Minima for Differentially Private Federated Learning via Penalizing Gradient Norm](https://arxiv.org/abs/2510.27504)
*Junkang Liu,Yuxuan Tian,Fanhua Shang,Yuanyuan Liu,Hongying Liu,Junchao Zhou,Daorui Ding*

Main category: cs.LG

TL;DR: 提出了一个新的客户端级差分隐私联邦学习算法DP-FedPGN，通过引入全局梯度范数惩罚来寻找全局平坦最小值，从而减少DP保护导致的模型泛化能力下降。该方法还能降低本地更新范数，减少剪辑梯度带来的误差。DP-FedPGN在理论上分析了其如何缓解由于DP导致的性能下降，且通过Rényi DP提供了严格的隐私保证，并对局部更新进行了敏感性分析。实验结果表明，DP-FedPGN在多种任务上优于现有最佳算法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决当前客户端级差分隐私联邦学习方法导致的模型泛化能力下降问题，找到全局平坦最小值，同时减少误差，提供严格的隐私保证，并对数据异质性无影响，实现快速收敛。

Method: 通过引入全局梯度范数惩罚到局部损失中，寻找全局平坦最小值，同时减少局部更新范数，减少剪辑梯度带来的误差，使用Rényi DP提供严格的隐私保证，进行敏感性分析。

Result: 通过ResNet和Transformer模型上的实验，DP-FedPGN在六种视觉和自然语言处理任务上都有显著改进，优于现有最佳算法。

Conclusion: 提出的新算法DP-FedPGN能够有效缓解由于DP导致的性能下降，实现全局平坦最小值，提供严格的隐私保证，并实现了快速收敛。

Abstract: To prevent inference attacks in Federated Learning (FL) and reduce the
leakage of sensitive information, Client-level Differentially Private Federated
Learning (CL-DPFL) is widely used. However, current CL-DPFL methods usually
result in sharper loss landscapes, which leads to a decrease in model
generalization after differential privacy protection. By using Sharpness Aware
Minimization (SAM), the current popular federated learning methods are to find
a local flat minimum value to alleviate this problem. However, the local
flatness may not reflect the global flatness in CL-DPFL. Therefore, to address
this issue and seek global flat minima of models, we propose a new CL-DPFL
algorithm, DP-FedPGN, in which we introduce a global gradient norm penalty to
the local loss to find the global flat minimum. Moreover, by using our global
gradient norm penalty, we not only find a flatter global minimum but also
reduce the locally updated norm, which means that we further reduce the error
of gradient clipping. From a theoretical perspective, we analyze how DP-FedPGN
mitigates the performance degradation caused by DP. Meanwhile, the proposed
DP-FedPGN algorithm eliminates the impact of data heterogeneity and achieves
fast convergence. We also use R\'enyi DP to provide strict privacy guarantees
and provide sensitivity analysis for local updates. Finally, we conduct
effectiveness tests on both ResNet and Transformer models, and achieve
significant improvements in six visual and natural language processing tasks
compared to existing state-of-the-art algorithms. The code is available at
https://github.com/junkangLiu0/DP-FedPGN

</details>


### [145] [Leveraging Generic Time Series Foundation Models for EEG Classification](https://arxiv.org/abs/2510.27522)
*Théo Gnassounou,Yessin Moakher,Shifeng Xie,Vasilii Feofanov,Ievgen Redko*

Main category: cs.LG

TL;DR: 本文研究了最近提出的时间序列分类基础模型在EEG任务（如运动想象分类和睡眠阶段预测）上的适用性。实验结果显示，无论是基于多领域真实世界数据还是纯合成数据进行预训练，该模型均表现出色，优于常用的卷积基线模型EEGNet和最新的EEG专用基础模型CBraMod。这说明通用时间序列基础模型即使在非神经源数据或合成信号上预训练，也能有效转移到EEG信号分析。这项发现表明，跨领域预训练模型可以用于分析脑信号，这可能使EEG受益于时间序列文献的进步。


<details>
  <summary>Details</summary>
Motivation: 论文旨在探究通用时间序列分类基础模型在生物医学信号领域尤其是EEG信号上的适用性及表现。这将有助于推动EEG信号处理和分析的技术进步。

Method: 研究测试了两种预训练策略：预训练基于多领域的真实世界时间序列数据和预训练基于纯合成数据。然后将模型应用于不同的EEG任务（例如运动想象分类和睡眠阶段预测）。

Result: 实验结果显示，两种预训练方案均能有效应用于EEG任务，优于卷积基线模型EEGNet和EEG专用基础模型CBraMod。这说明通用时间序列基础模型即使是在非神经源数据上预训练也能有效泛化到EEG分析中。

Conclusion: 该发现表明，跨领域预训练模型在处理EEG信号中的前景，并且EEG很可能将从时间序列领域的研究进展中获益。

Abstract: Foundation models for time series are emerging as powerful general-purpose
backbones, yet their potential for domain-specific biomedical signals such as
electroencephalography (EEG) remains rather unexplored. In this work, we
investigate the applicability a recently proposed time series classification
foundation model, to a different EEG tasks such as motor imagery classification
and sleep stage prediction. We test two pretraining regimes: (a) pretraining on
heterogeneous real-world time series from multiple domains, and (b) pretraining
on purely synthetic data. We find that both variants yield strong performance,
consistently outperforming EEGNet, a widely used convolutional baseline, and
CBraMod, the most recent EEG-specific foundation model. These results suggest
that generalist time series foundation models, even when pretrained on data of
non-neural origin or on synthetic signals, can transfer effectively to EEG. Our
findings highlight the promise of leveraging cross-domain pretrained models for
brain signal analysis, suggesting that EEG may benefit from advances in the
broader time series literature.

</details>


### [146] [Active transfer learning for structural health monitoring](https://arxiv.org/abs/2510.27525)
*J. Poole,N. Dervilis,K. Worden,P. Gardner,V. Giglioni,R. S. Mills,A. J. Hughes*

Main category: cs.LG

TL;DR: 提出了一种基于贝叶斯框架的领域适应方法，用于结构健康监测系统，该方法能利用少量标签数据改进无监督领域适应映射，并结合主动采样策略来进一步减少标签数据的需求


<details>
  <summary>Details</summary>
Motivation: 解决结构健康监测系统中标签数据获取困难的问题，通过转移学习和主动学习方法，在标签数据稀缺的情况下提高分类模型的学习效率

Method: 提出了一个结合无监督领域适应和少量标签数据改进的贝叶斯框架，同时结合了主动采样策略来选择最具有信息量的样本进行标签更新

Result: 实验结果表明，在实验桥梁数据集上，该方法可以提高数据效率；在标签数据稀缺的情况下，转移学习和主动学习的结合能够提高分类模型的学习效率

Conclusion: 说明了在结构健康监测领域，结合转移学习和主动学习方法，可以在维持相同性能的情况下减少对标签数据的需求，从而减少检测频率和操作成本

Abstract: Data for training structural health monitoring (SHM) systems are often
expensive and/or impractical to obtain, particularly for labelled data.
Population-based SHM (PBSHM) aims to address this limitation by leveraging data
from multiple structures. However, data from different structures will follow
distinct distributions, potentially leading to large generalisation errors for
models learnt via conventional machine learning methods. To address this issue,
transfer learning -- in the form of domain adaptation (DA) -- can be used to
align the data distributions. Most previous approaches have only considered
\emph{unsupervised} DA, where no labelled target data are available; they do
not consider how to incorporate these technologies in an online framework --
updating as labels are obtained throughout the monitoring campaign. This paper
proposes a Bayesian framework for DA in PBSHM, that can improve unsupervised DA
mappings using a limited quantity of labelled target data. In addition, this
model is integrated into an active sampling strategy to guide inspections to
select the most informative observations to label -- leading to further
reductions in the required labelled data to learn a target classifier. The
effectiveness of this methodology is evaluated on a population of experimental
bridges. Specifically, this population includes data corresponding to several
damage states, as well as, a comprehensive set of environmental conditions. It
is found that combining transfer learning and active learning can improve data
efficiency when learning classification models in label-scarce scenarios. This
result has implications for data-informed operation and maintenance of
structures, suggesting a reduction in inspections over the operational lifetime
of a structure -- and therefore a reduction in operational costs -- can be
achieved.

</details>


### [147] [TetraJet-v2: Accurate NVFP4 Training for Large Language Models with Oscillation Suppression and Outlier Control](https://arxiv.org/abs/2510.27527)
*Yuxiang Chen,Xiaoming Xu,Pengle Zhang,Michael Beyer,Martin Rapp,Jun Zhu,Jianfei Chen*

Main category: cs.LG

TL;DR: TetraJet-v2 是一种端到端的4位全精度训练方法，使用NVFP4格式在所有线性层中用于激活、权重和梯度，解决了低精度训练中的权重振荡和异常值问题，性能优于先前的FP4训练方法，缩小了与全精度训练的性能差距。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的训练成本高昂，驱动了低精度全量化训练的研究。尽管4位格式如NVFP4在效率上有了显著提升，但在如此低的精度下实现接近无损训练仍具挑战性。TetraJet-v2旨在实现高效的4位全精度训练，降低成本并保持性能。

Method: 提出了TetraJet-v2，采用双块量化方法解决NVFP4线性层的偏置问题，并提出OsciReset方法抑制权重振荡，以及OutControl方法保留异常值精度，从而在4位全精度训练中实现更好的性能。

Result: TetraJet-v2能够在预训练语言模型上超越之前的4位训练方法，模型大小可达3.7亿参数，数据量可达2000亿个令牌，性能差距平均缩小51.3%。

Conclusion: TetraJet-v2证明了在4位精度下训练大型语言模型的可行性，并提出了若干改进方法，为低精度全量化训练开辟了新的可能。

Abstract: Large Language Models (LLMs) training is prohibitively expensive, driving
interest in low-precision fully-quantized training (FQT). While novel 4-bit
formats like NVFP4 offer substantial efficiency gains, achieving near-lossless
training at such low precision remains challenging. We introduce TetraJet-v2,
an end-to-end 4-bit FQT method that leverages NVFP4 for activations, weights,
and gradients in all linear layers. We identify two critical issues hindering
low-precision LLM training: weight oscillation and outliers. To address these,
we propose: 1) an unbiased double-block quantization method for NVFP4 linear
layers, 2) OsciReset, an algorithm to suppress weight oscillation, and 3)
OutControl, an algorithm to retain outlier accuracy. TetraJet-v2 consistently
outperforms prior FP4 training methods on pre-training LLMs across varying
model sizes up to 370M and data sizes up to 200B tokens, reducing the
performance gap to full-precision training by an average of 51.3%.

</details>


### [148] [AstuteRAG-FQA: Task-Aware Retrieval-Augmented Generation Framework for Proprietary Data Challenges in Financial Question Answering](https://arxiv.org/abs/2510.27537)
*Mohammad Zahangir Alam,Khandoker Ashik Uz Zaman,Mahdi H. Miraz*

Main category: cs.LG

TL;DR: AstuteRAG-FQA是一个专为金融问答(FQA)设计的自适应RAG框架，通过采用混合检索策略，结合开源和专有金融数据，并维持严格的隐私和合规性，解决了RAG应用于金融领域的挑战。该框架具备实时动态提示框架，能够根据查询复杂性调整提示，同时提出一种四层任务分类，涵盖显式事实、隐含事实、可解释原因及涉及隐含因果推理的隐含原因。框架还集成了多层安全机制，包括差分隐私、数据匿名化及基于角色的访问控制，以保护敏感的金融信息。此外，AstuteRAG-FQA通过自动合规验证系统实现了实时合规监控。该系统会验证响应是否符合行业标准和法律义务。我们评估了上下文嵌入、小模型增强和定向微调三种数据整合技术的有效性和可行性。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机在于解决将RAG应用于金融领域如受限数据访问、检索精度有限、监管约束及敏感数据解释等问题。引入AstuteRAG-FQA框架，以增强金融问答的效率和准确性，同时保证数据安全和合规性，从而推动金融领域信息检索技术的发展。

Method: AstuteRAG-FQA采用了混合检索策略，利用开源和专有金融数据，设计了针对不同查询复杂性动态调整提示的框架，并提出了一套四层的任务分类系统。此外，框架还采用多层安全机制，包括差分隐私、数据匿名化及基于角色的访问控制，以确保敏感金融信息的安全。再者，通过自动化法律法规验证系统以实时监控并确保响应的合规性。在数据整合方面，则通过了三种方法的评估，以分析它们在不同金融环境中的应用效果和可行性。

Result: 实验结果表明，AstuteRAG-FQA通过引入动态提示框架和多层安全机制，有效改善了金融问答系统的精度和安全性，同时，针对不同任务的设计也提升了系统对复杂查询的处理能力。在数据整合方法上，评估验证了上下文嵌入、小模型增强和定向微调的实用性和有效性。

Conclusion: AstuteRAG-FQA框架为解决金融领域的问答问题提供了一个有效的方案，展示了其在提高检索精度、保证数据安全及监管合规性等方面的潜力。

Abstract: Retrieval-Augmented Generation (RAG) shows significant promise in
knowledge-intensive tasks by improving domain specificity, enhancing temporal
relevance, and reducing hallucinations. However, applying RAG to finance
encounters critical challenges: restricted access to proprietary datasets,
limited retrieval accuracy, regulatory constraints, and sensitive data
interpretation. We introduce AstuteRAG-FQA, an adaptive RAG framework tailored
for Financial Question Answering (FQA), leveraging task-aware prompt
engineering to address these challenges. The framework uses a hybrid retrieval
strategy integrating both open-source and proprietary financial data while
maintaining strict security protocols and regulatory compliance. A dynamic
prompt framework adapts in real time to query complexity, improving precision
and contextual relevance. To systematically address diverse financial queries,
we propose a four-tier task classification: explicit factual, implicit factual,
interpretable rationale, and hidden rationale involving implicit causal
reasoning. For each category, we identify key challenges, datasets, and
optimization techniques within the retrieval and generation process. The
framework incorporates multi-layered security mechanisms including differential
privacy, data anonymization, and role-based access controls to protect
sensitive financial information. Additionally, AstuteRAG-FQA implements
real-time compliance monitoring through automated regulatory validation systems
that verify responses against industry standards and legal obligations. We
evaluate three data integration techniques - contextual embedding, small model
augmentation, and targeted fine-tuning - analyzing their efficiency and
feasibility across varied financial environments.

</details>


### [149] [ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling](https://arxiv.org/abs/2510.27610)
*Zhuohan Wang,Ziwei Zhu,Ziniu Li,Congliang Chen,Yizhou Han,Yufeng Lin,Zhihang Lin,Angyang Gu,Xinglin Hu,Ruoyu Sun,Tian Ding*

Main category: cs.LG

TL;DR: 提出了ORGEval，一种基于图论的评估框架，用于评估LLM在制定线性与混合整数线性规划方面的能力。该框架将优化模型作为图进行表示，通过图同构测试来检测等价性。实验结果显示，该方法成功检测了模型等价性，在随机参数配置下结果完全一致，且在运行时间上显著优于基于解算器的方法，尤其是在难题上。利用ORGEval，构建了Bench4Opt数据集，对最先进的LLM进行优化建模基准测试，DeepSeek-V3和Claude-Opus-4在直接提示下表现出最高精度，优于其他推理模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在自动化工业应用的优化问题形成过程中面临性能评估难题，现有基于解算器的方法往往存在不一致、不可行性和高计算成本的问题，因此需要一种新的评估框架ORGEval来解决这些问题。

Method: 通过将优化模型表示为图，将等价检测问题转化为图同构测试问题，并证明当测试图为对称可分解时，WL测试能够正确识别同构。ORGEval结合定制版的WL测试和对称可分解检测算法，以结构等价性而非实例级配置为焦点进行评估。

Result: 实验表明，ORGEval方法能成功检测模型等价性，且在随机参数配置下取得一致结果，特别是在运行时间上，显著优于基于解算器的方法，尤其是在难题上。此外，还构建了Bench4Opt数据集，对最先进的LLM进行了优化建模基准测试，结果显示DeepSeek-V3和Claude-Opus-4直接提示下的精度最高。

Conclusion: ORGEval框架通过图的表示和同构检测，提供了一种评估LLM优化模型能力的新方法。该方法在准确性和效率上都优于现有基于解算器的方法，且构建的数据集揭示了最新的DeepSeek-V3和Claude-Opus-4在优化模型精度上的优势。

Abstract: Formulating optimization problems for industrial applications demands
significant manual effort and domain expertise. While Large Language Models
(LLMs) show promise in automating this process, evaluating their performance
remains difficult due to the absence of robust metrics. Existing solver-based
approaches often face inconsistency, infeasibility issues, and high
computational costs. To address these issues, we propose ORGEval, a
graph-theoretic evaluation framework for assessing LLMs' capabilities in
formulating linear and mixed-integer linear programs. ORGEval represents
optimization models as graphs, reducing equivalence detection to graph
isomorphism testing. We identify and prove a sufficient condition, when the
tested graphs are symmetric decomposable (SD), under which the
Weisfeiler-Lehman (WL) test is guaranteed to correctly detect isomorphism.
Building on this, ORGEval integrates a tailored variant of the WL-test with an
SD detection algorithm to evaluate model equivalence. By focusing on structural
equivalence rather than instance-level configurations, ORGEval is robust to
numerical variations. Experimental results show that our method can
successfully detect model equivalence and produce 100\% consistent results
across random parameter configurations, while significantly outperforming
solver-based methods in runtime, especially on difficult problems. Leveraging
ORGEval, we construct the Bench4Opt dataset and benchmark state-of-the-art LLMs
on optimization modeling. Our results reveal that although optimization
modeling remains challenging for all LLMs, DeepSeek-V3 and Claude-Opus-4
achieve the highest accuracies under direct prompting, outperforming even
leading reasoning models.

</details>


### [150] [Panprediction: Optimal Predictions for Any Downstream Task and Loss](https://arxiv.org/abs/2510.27638)
*Sivaraman Balakrishnan,Nika Haghtalab,Daniel Hsu,Brian Lee,Eric Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种新的监督学习框架—泛预测（panprediction），该框架将模型训练视为从数据中抽取信息以使模型适用于多种损失和任务，其统计复杂度通过理论分析得到了展示。文中设计的算法在确定性和随机化下分别需要大约$	ilde{O}(1/ho^3)$和$	ilde{O}(1/ho^2)$的样本数。


<details>
  <summary>Details</summary>
Motivation: 传统的监督学习是训练模型来最小化固定分布上的固定损失函数，但新的范式认为模型应该能从数据中提取足够信息来执行许多下游任务的各种损失。这一转变促使研究人员提出新的框架以应对实际中可能遇到的多种损失函数和任务需求的问题，即泛预测（panprediction）。

Method: 本文首先从理论上定义了泛预测的概念及其数学框架，并展示了其如何泛化于全预测（omniprediction）和多组学习之上。接着，设计并实现了确定性和随机化的泛预测学习算法，最后通过理论证明和实验验证了算法的有效性。

Result: 文章设计的算法在确定性和随机性假设下，学习泛预测器所需的样本数是$	ilde{O}(1/ho^3)$和$	ilde{O}(1/ho^2)$。这一发现表明，只要满足温和假设，同时最小化无限多数目损失和任务比单独最小化单个损失和任务同样容易。同时，该研究还改进了已知的最佳全预测确定性样本复杂度保证，提升了效率。

Conclusion: 本文提出的泛预测框架具备解决多种损失和任务的潜力，其方法有效且具有统计效率，对理解和解决实际中的复杂监督学习问题提供了新的视角。

Abstract: Supervised learning is classically formulated as training a model to minimize
a fixed loss function over a fixed distribution, or task. However, an emerging
paradigm instead views model training as extracting enough information from
data so that the model can be used to minimize many losses on many downstream
tasks. We formalize a mathematical framework for this paradigm, which we call
panprediction, and study its statistical complexity. Formally, panprediction
generalizes omniprediction and sits upstream from multi-group learning, which
respectively focus on predictions that generalize to many downstream losses or
many downstream tasks, but not both. Concretely, we design algorithms that
learn deterministic and randomized panpredictors with
$\tilde{O}(1/\varepsilon^3)$ and $\tilde{O}(1/\varepsilon^2)$ samples,
respectively. Our results demonstrate that under mild assumptions,
simultaneously minimizing infinitely many losses on infinitely many tasks can
be as statistically easy as minimizing one loss on one task. Along the way, we
improve the best known sample complexity guarantee of deterministic
omniprediction by a factor of $1/\varepsilon$, and match all other known sample
complexity guarantees of omniprediction and multi-group learning. Our key
technical ingredient is a nearly lossless reduction from panprediction to a
statistically efficient notion of calibration, called step calibration.

</details>


### [151] [Imbalanced Classification through the Lens of Spurious Correlations](https://arxiv.org/abs/2510.27650)
*Jakob Hackstein,Sidney Bender*

Main category: cs.LG

TL;DR: 本文提出了一种基于可解释人工智能的方法，通过识别和消除在不平衡数据集下出现的Clever Hans效应，来解决机器学习中的类别不平衡问题，该方法在三个数据集上达到了竞争性的分类性能，且展示了解释性的AI如何识别不平衡数据中出现的Clever Hans效应的途径，这是现有方法所忽略的领域。


<details>
  <summary>Details</summary>
Motivation: 传统的数据或损失重加权方法在类别不平衡问题上存在不足，本文创新地将类别不平衡视为一种通过underspecification(参数欠定)现象放大Clever Hans效应的数据条件，并通过可解释AI的方法来解决这一问题。

Method: 本文提出了一种基于可解释AI的反事实解释方法，通过识别并消除在类别不平衡条件下出现的Clever Hans效应来进行分类改进。

Result: 该方法在三个数据集上获得了竞争性的分类结果，并且展示了解释性AI如何检测不平衡数据集中的Clever Hans效应，这与现有方法有所不同。

Conclusion: 本文提出的方法提供了一种新的视角来理解和解决类别不平衡问题，通过利用解释性AI技术来克服Clever Hans效应，并在不同数据集上验证了该方法的有效性。

Abstract: Class imbalance poses a fundamental challenge in machine learning, frequently
leading to unreliable classification performance. While prior methods focus on
data- or loss-reweighting schemes, we view imbalance as a data condition that
amplifies Clever Hans (CH) effects by underspecification of minority classes.
In a counterfactual explanations-based approach, we propose to leverage
Explainable AI to jointly identify and eliminate CH effects emerging under
imbalance. Our method achieves competitive classification performance on three
datasets and demonstrates how CH effects emerge under imbalance, a perspective
largely overlooked by existing approaches.

</details>


### [152] [Challenges in Credit Assignment for Multi-Agent Reinforcement Learning in Open Agent Systems](https://arxiv.org/abs/2510.27659)
*Alireza Saleh Abadi,Leen-Kiat Soh*

Main category: cs.LG

TL;DR: 本文探讨了多智能体强化学习中开放系统对信用分配问题的影响，剖析了传统信用分配方法在开放环境中的不足，并通过实验证明开放性会导致信用误分配，表现为损失函数不稳定和性能下降。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体强化学习中动态系统的研究日益深入，理解开放系统中的动力学变得至关重要。本文聚焦开放性与信用分配问题之间的相互作用，旨在解决传统信用分配方法在开放环境中的局限性，确保更准确的效果评估。

Method: 首先，本文进行概念性分析，介绍新开放类别并详述如智能体流动或任务取消如何打破传统CAP方法的静态环境假设。接着，使用代表性的时序和结构算法进行实证研究，在开放环境中验证开放性假设并测试信用分配方法的效果。

Result: 研究结果表明，开放性直接导致信用误分配，表现为不稳定的损失函数和显著的性能下降。这些问题证明了传统信用分配方法的不足以及必要性改进的方向。

Conclusion: 开放性对信用分配问题构成了挑战，传统的信用分配方法假设静态环境和固定团队组成，难以适用于动态变化的开放系统。实验表明，在开放环境中，现有方法无法有效分配信用，未来的工作应致力于开发更适合开放环境的方法来解决这个问题。

Abstract: In the rapidly evolving field of multi-agent reinforcement learning (MARL),
understanding the dynamics of open systems is crucial. Openness in MARL refers
to the dynam-ic nature of agent populations, tasks, and agent types with-in a
system. Specifically, there are three types of openness as reported in (Eck et
al. 2023) [2]: agent openness, where agents can enter or leave the system at
any time; task openness, where new tasks emerge, and existing ones evolve or
disappear; and type openness, where the capabil-ities and behaviors of agents
change over time. This report provides a conceptual and empirical review,
focusing on the interplay between openness and the credit assignment problem
(CAP). CAP involves determining the contribution of individual agents to the
overall system performance, a task that becomes increasingly complex in open
environ-ments. Traditional credit assignment (CA) methods often assume static
agent populations, fixed and pre-defined tasks, and stationary types, making
them inadequate for open systems. We first conduct a conceptual analysis,
in-troducing new sub-categories of openness to detail how events like agent
turnover or task cancellation break the assumptions of environmental
stationarity and fixed team composition that underpin existing CAP methods. We
then present an empirical study using representative temporal and structural
algorithms in an open environment. The results demonstrate that openness
directly causes credit misattribution, evidenced by unstable loss functions and
significant performance degradation.

</details>
