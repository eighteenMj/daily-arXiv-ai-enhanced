<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 52]
- [cs.IT](#cs.IT) [Total: 6]
- [cs.AI](#cs.AI) [Total: 25]
- [eess.SY](#eess.SY) [Total: 18]
- [eess.IV](#eess.IV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 55]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices](https://arxiv.org/abs/2511.03765)
*Hyunseok Kwak,Kyeongwon Lee,Jae-Jin Lee,Woojoo Lee*

Main category: cs.CV

TL;DR: LoRA-Edge 是一种参数高效的细调方法，通过结合低秩适应 (LoRA) 和张量分解 (TT-SVD)，使得在有限内存和能量预算下，能够在设备上调整 CNN 模型以适应领域变化，保持高精度同时大幅度减少参数量和训练时间。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备中，如人类活动识别 (HAR) 应用中，需要在严格的内存、计算和能量预算内对预训练的 CNN 进行微调，以对抗领域偏移。然而，全量细调在此条件下不可行。因此，需要开发一种参数高效的细调方法来满足设备的预算要求，同时保持模型性能。LoRA-Edge 的动机就是在这些限制条件下，设计一种参数高效的细调方法，以实现结构化的、对设备友好的 CNN 调整。

Method: LoRA-Edge 结合了张量分解（TT-SVD）和参数高效的低秩适应（LoRA），具体步骤包括：(i) 应用张量-张量奇异值分解（TT-SVD）预训练的卷积层；(ii) 只选择性地更新输出测核心且该核心初始化为零，使其辅助路径保持不活动；(iii) 将更新融合回稠密核中，同时保持推理成本不变，这样设计就保存了卷积结构，减少了至少一个数量级的可训练参数。通过这种方法，LoRA-Edge 实现了与全量细调相似的准确度，同时更新的参数只占全量细调的一部分，从而提供了更快的收敛速度和更低的能源消耗。

Result: 在多个 HAR 数据集和 CNN 模型上，LoRA-Edge 能够实现与全量微调相近的准确度同时更新的参数只占全量微调的1.49%，显著优于其他参数高效的方法。这表明 LoRA-Edge 方法在设备上进行参数高效的 CNN 微调是可行的。此外，在 Jetson Orin Nano 设备上，TT-SVD初始化和选择性核心训练使模型可以达到最高1.4-3.8倍的收敛速度。

Conclusion: LoRA-Edge 提供了一种结构化的、参数高效的设备上 CNN 微调方法，适用于边缘计算平台，通过结合 LoRA 和 TT-SVD，强制模型在严格的资源限制下保持高效的同时提供优异的性能。这种方法确立了在边缘设备中进行高效和高精度模型微调的可行路径。

Abstract: On-device fine-tuning of CNNs is essential to withstand domain shift in edge
applications such as Human Activity Recognition (HAR), yet full fine-tuning is
infeasible under strict memory, compute, and energy budgets. We present
LoRA-Edge, a parameter-efficient fine-tuning (PEFT) method that builds on
Low-Rank Adaptation (LoRA) with tensor-train assistance. LoRA-Edge (i) applies
Tensor-Train Singular Value Decomposition (TT-SVD) to pre-trained convolutional
layers, (ii) selectively updates only the output-side core with
zero-initialization to keep the auxiliary path inactive at the start, and (iii)
fuses the update back into dense kernels, leaving inference cost unchanged.
This design preserves convolutional structure and reduces the number of
trainable parameters by up to two orders of magnitude compared to full
fine-tuning. Across diverse HAR datasets and CNN backbones, LoRA-Edge achieves
accuracy within 4.7% of full fine-tuning while updating at most 1.49% of
parameters, consistently outperforming prior parameter-efficient baselines
under similar budgets. On a Jetson Orin Nano, TT-SVD initialization and
selective-core training yield 1.4-3.8x faster convergence to target F1.
LoRA-Edge thus makes structure-aligned, parameter-efficient on-device CNN
adaptation practical for edge platforms.

</details>


### [2] [SILVI: Simple Interface for Labeling Video Interactions](https://arxiv.org/abs/2511.03819)
*Ozan Kanbertay,Richard Vogg,Elif Karakoc,Peter M. Kappeler,Claudia Fichtel,Alexander S. Ecker*

Main category: cs.CV

TL;DR: SILVI是一个开源标签软件，结合了行为标注和个体定位的功能，用于分析动物行为的视频数据，该软件支持生成结构化的输出，适用于训练和验证计算机视觉模型，也适用于其他需要提取动态场景图的人类互动视频标注任务


<details>
  <summary>Details</summary>
Motivation: 现有开源标注工具要么支持行为标签但不支持个体定位，要么支持定位但不支持捕捉互动。SILVI旨在填补这一空白

Method: SILVI将行为生态学与计算机视觉相结合，直接在视频数据中进行行为和互动标注

Result: SILVI生成结构化的输出，适用于训练和验证计算机视觉模型，同时支持动态场景图的生成

Conclusion: SILVI在美国动物行为研究中发挥了作用，但也可能在其他视频中人类互动的标注任务中有用，例如需要提取动态场景图的视频。软件和文档可以在上述链接中获取

Abstract: Computer vision methods are increasingly used for the automated analysis of
large volumes of video data collected through camera traps, drones, or direct
observations of animals in the wild. While recent advances have focused
primarily on detecting individual actions, much less work has addressed the
detection and annotation of interactions -- a crucial aspect for understanding
social and individualized animal behavior. Existing open-source annotation
tools support either behavioral labeling without localization of individuals,
or localization without the capacity to capture interactions. To bridge this
gap, we present SILVI, an open-source labeling software that integrates both
functionalities. SILVI enables researchers to annotate behaviors and
interactions directly within video data, generating structured outputs suitable
for training and validating computer vision models. By linking behavioral
ecology with computer vision, SILVI facilitates the development of automated
approaches for fine-grained behavioral analyses. Although developed primarily
in the context of animal behavior, SILVI could be useful more broadly to
annotate human interactions in other videos that require extracting dynamic
scene graphs. The software, along with documentation and download instructions,
is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.

</details>


### [3] [Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets](https://arxiv.org/abs/2511.03855)
*Duong Mai,Lawrence Hall*

Main category: cs.CV

TL;DR: 本研究探讨了在训练过程中使用基本的噪声注入技术（高斯、Speckle、泊松和Salt and Pepper）来提高COVID-19检测模型在不同数据分布下的鲁棒性。实验结果表明，该技术显著减少了在分布内和分布外评估之间的性能差距，使模型更加稳健。源代码可在此处获得：https://github.com/Duongmai127/Noisy-ood


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在处理不同来源的数据时泛化能力较差，特别是COVID-19的检测模型在面对训练集中未覆盖的新临床源数据时表现不佳。模型通常利用特定来源的特异结构而非有效的生物标记来最大化在训练集内的性能，导致分布偏移的问题。为了提高模型的鲁棒性，本研究尝试使用噪声注入技术解决此问题

Method: 本研究在训练过程中引入高斯噪声、Speckle噪声、泊松噪声和Salt and Pepper噪声，以提高模型对于分布变化的鲁棒性

Result: 实验结果表明，这一方法可以显著降低分布内和分布外评估之间的性能差距，从0.10-0.20缩小至0.01-0.06。这个结果是在10次随机种子下，针对关键指标如AUC、F1、精确度、召回率和特异性的均值计算得到的

Conclusion: 研究证明了使用噪声注入技术可以有效提高深度学习模型在不同分布数据下的稳健性，可以应用于各种目标检测场景。

Abstract: Deep learned (DL) models for image recognition have been shown to fail to
generalize to data from different devices, populations, etc. COVID-19 detection
from Chest X-rays (CXRs), in particular, has been shown to fail to generalize
to out-of-distribution (OOD) data from new clinical sources not covered in the
training set. This occurs because models learn to exploit shortcuts -
source-specific artifacts that do not translate to new distributions - rather
than reasonable biomarkers to maximize performance on in-distribution (ID)
data. Rendering the models more robust to distribution shifts, our study
investigates the use of fundamental noise injection techniques (Gaussian,
Speckle, Poisson, and Salt and Pepper) during training. Our empirical results
demonstrate that this technique can significantly reduce the performance gap
between ID and OOD evaluation from 0.10-0.20 to 0.01-0.06, based on results
averaged over ten random seeds across key metrics such as AUC, F1, accuracy,
recall and specificity. Our source code is publicly available at
https://github.com/Duongmai127/Noisy-ood

</details>


### [4] [Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures](https://arxiv.org/abs/2511.03882)
*Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath*

Main category: cs.CV

TL;DR: 基于模仿学习的机器人控制策略在视频机器人中重新受到关注。然而，这些策略是否适用于X光引导的程序（如脊柱内固定）仍不清楚。研究团队开发了一个模拟平台，通过自动化模拟X光引导下的脊柱程序，探讨了模仿学习政策在双平面引导下的针头插入程序中的机遇与挑战。模仿学习政策在68.5%的案例中首次尝试就成功，并且能够在不同脊椎水平保持安全的路径。尽管这些初步结果很有希望，但研究指出精度的限制，特别在进入点的准确性上。未来需要解决校正循环控制频率的问题，此类模型可能为未来轻量级且无需CT的机器人辅助脊柱导航提供基础。


<details>
  <summary>Details</summary>
Motivation: 利用模仿学习策略来探索其在X光指导的微创手术程序，如脊柱内固定中的应用潜力与挑战，特别是针对多视角X光的解释难题。

Method: 研究团队开发了用于X光引导的脊柱程序的真实感模拟平台，制作了针头插入过程中的正确轨迹和对应的双平面X光序列的数据库，以此来训练计划和开环控制的模仿学习策略。这些策略仅基于视觉信息逐步校准针头的位置。并且，通过实际的双平面X光实验表明，尽管完全在模拟环境下训练，模型仍能产生可能的轨迹。

Result: 模仿学习策略在68.5%的案例中初步尝试即取得成功，可以在不同脊椎水平维持安全的途径，对于复杂解剖结构仍然稳健，包括骨折等情形。然而，在进入点的准确性方面仍然有所限制。模型对于真实双平面X光下的操作表现出强大的适应性，尽管之前完全在模拟环境中训练。

Conclusion: 初步结果表明基于模仿学习的机器人控制器在X光引导程序中具有潜力，虽然进入点的准确性仍旧是个挑战，进一步改进需要解决反馈机制和更强的先验知识等问题，这种模型可以在未来轻量级、不需要CT的机器人辅助脊柱导航中搭桥铺路。

Abstract: Imitation learning-based robot control policies are enjoying renewed interest
in video-based robotics. However, it remains unclear whether this approach
applies to X-ray-guided procedures, such as spine instrumentation. This is
because interpretation of multi-view X-rays is complex. We examine
opportunities and challenges for imitation policy learning in bi-plane-guided
cannula insertion. We develop an in silico sandbox for scalable, automated
simulation of X-ray-guided spine procedures with a high degree of realism. We
curate a dataset of correct trajectories and corresponding bi-planar X-ray
sequences that emulate the stepwise alignment of providers. We then train
imitation learning policies for planning and open-loop control that iteratively
align a cannula solely based on visual information. This precisely controlled
setup offers insights into limitations and capabilities of this method. Our
policy succeeded on the first attempt in 68.5% of cases, maintaining safe
intra-pedicular trajectories across diverse vertebral levels. The policy
generalized to complex anatomy, including fractures, and remained robust to
varied initializations. Rollouts on real bi-planar X-rays further suggest that
the model can produce plausible trajectories, despite training exclusively in
simulation. While these preliminary results are promising, we also identify
limitations, especially in entry point precision. Full closed-look control will
require additional considerations around how to provide sufficiently frequent
feedback. With more robust priors and domain knowledge, such models may provide
a foundation for future efforts toward lightweight and CT-free robotic
intra-operative spinal navigation.

</details>


### [5] [Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model](https://arxiv.org/abs/2511.03888)
*Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui*

Main category: cs.CV

TL;DR: 本文提出了一种基于优化的YOLOv12框架的实时物体检测系统，用于在沙漠环境中进行垃圾检测，该系统结合了自我对抗训练和特定的数据增强策略，能够实现低延迟和小型化的模型部署，并在DroneTrashNet数据集上显示出更高的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的废物收集方法在沙漠等偏远或极端环境中效率低下且危险。现有的自动废物检测系统研究主要集中在城市环境中，并且很大程度上忽略了有机废物和危险废物。本文旨在开发一种适应沙漠环境的高效实时废物检测系统。

Method: 通过使用一个优化的YOLOv12框架结合自我对抗训练（SAT）和特定的数据增强策略，提出了一个新的实时物体检测系统，同时在DroneTrashNet数据集上测试其性能和效果。

Result: 模型在低延迟、小型化框架下有效提高了精度、召回率和平均精度（mAP），并显示出与当前最优的轻量级YOLO变体相当的性能。

Conclusion: 研究通过综合数据和模型优化，成功实现了在沙漠环境下的实时、高效的垃圾检测系统。该研究展示了在资源受限条件下优化废物检测系统的可行性和有效性。

Abstract: The global waste crisis is escalating, with solid waste generation expected
to increase by 70% by 2050. Traditional waste collection methods, particularly
in remote or harsh environments like deserts, are labor-intensive, inefficient,
and often hazardous. Recent advances in computer vision and deep learning have
opened the door to automated waste detection systems, yet most research focuses
on urban environments and recyclable materials, overlooking organic and
hazardous waste and underexplored terrains such as deserts. In this work, we
propose an enhanced real-time object detection framework based on a pruned,
lightweight version of YOLOv12 integrated with Self-Adversarial Training (SAT)
and specialized data augmentation strategies. Using the DroneTrashNet dataset,
we demonstrate significant improvements in precision, recall, and mean average
precision (mAP), while achieving low latency and compact model size suitable
for deployment on resource-constrained aerial drones. Benchmarking our model
against state-of-the-art lightweight YOLO variants further highlights its
optimal balance of accuracy and efficiency. Our results validate the
effectiveness of combining data-centric and model-centric enhancements for
robust, real-time waste detection in desert environments.

</details>


### [6] [Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition](https://arxiv.org/abs/2511.03891)
*Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat*

Main category: cs.CV

TL;DR: 该论文提出了基于图像合成的Class-Based Image Composition方法，以增加训练输入的类别内变化，提高训练样本的信息密度，并提高模型区分细微疾病模式的能力。使用这种方法，作者在OCTDL数据集的一个完美平衡版本Co-OCTDL上通过VGG16模型进行实验，显著提高了诊断准确率，达到了接近完美的99.6%的准确率，F1分数为0.995，AUC为0.9996，并且降低了虚警率。


<details>
  <summary>Details</summary>
Motivation: 研究基于深度学习的模型在小样本或不平衡数据集上的虚假预测问题。提出了一种通过合成图像来增加训练输入的类别内变化，提高模型区分能力的方法。

Method: 通过将同一类别的多个图像融合为多图像布局的组合图像，构成一个平衡的数据集Co-OCTDL。实验中使用VGG16模型进行实验，确保模型架构和超参数在实验组和控制组间保持一致。

Result: 此方法达到了接近完美的准确率（99.6%），F1分数为0.995，AUC为0.9996，并且相较于原始数据集，虚警率显著降低。

Conclusion: Class-Based Image Composition方法可以有效提高深度学习模型区分细微疾病模式的能力，对于受到类别不平衡或样本数量影响的弱数据集，也能生成高质量的预测结果。

Abstract: Small, imbalanced datasets and poor input image quality can lead to high
false predictions rates with deep learning models. This paper introduces
Class-Based Image Composition, an approach that allows us to reformulate
training inputs through a fusion of multiple images of the same class into
combined visual composites, named Composite Input Images (CoImg). That enhances
the intra-class variance and improves the valuable information density per
training sample and increases the ability of the model to distinguish between
subtle disease patterns. Our method was evaluated on the Optical Coherence
Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et
al., 2024), which contains 2,064 high-resolution optical coherence tomography
(OCT) scans of the human retina, representing seven distinct diseases with a
significant class imbalance. We constructed a perfectly class-balanced version
of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout
composite image. To assess the effectiveness of this new representation, we
conducted a comparative analysis between the original dataset and its variant
using a VGG16 model. A fair comparison was ensured by utilizing the identical
model architecture and hyperparameters for all experiments. The proposed
approach markedly improved diagnostic results.The enhanced Dataset achieved
near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared
to a baseline model trained on raw dataset. The false prediction rate was also
significantly lower, this demonstrates that the method can producehigh-quality
predictions even for weak datasets affected by class imbalance or small sample
size.

</details>


### [7] [Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data](https://arxiv.org/abs/2511.04304)
*Robin Spanier,Thorsten Hoeser,Claudia Kuenzer*

Main category: cs.CV

TL;DR: 通过使用合成数据和真实Sentinel-1卫星图像训练YOLOv10对象检测模型，该研究证明了合成训练数据可以提高模型在检测海上平台方面的表现。测试在三个方面展开，总共有3,529个海上平台被检测到，且模型的F1分数达到了0.85，使用合成数据后提升到了0.90。说明了平衡的数据集和生成合成数据对解决遥感中的常见挑战的有效性，表明深度学习在实现全球海上基础设施监测中具有潜在的应用价值。


<details>
  <summary>Details</summary>
Motivation: 在海上基础设施（如风力发电场，石油和天然气平台，人工岛和水产养殖设施）的扩张背景下，该研究致力于通过使用平衡的数据集和生成合成数据来提高海上平台检测的模型性能，解决样本稀疏的问题。

Method: 该研究通过结合使用合成数据和真实Sentinel-1卫星图像在四个区域（里海，南中国海，几内亚湾和巴西海岸）进行训练，测试了基于深度学习的YOLOv10对象检测模型。模型的性能通过应用到三个未见过的区域（墨西哥湾，北海，波斯湾）来评估。

Result: 研究通过不同的区域验证了模型在检测海上平台上的有效性和其地理迁移性。在没有使用合成数据的情况下，模型的F1分数达到了0.85；使用合成数据后，该分数上升至0.90。总共检测到了3,529个海上平台，主要在墨西哥湾和波斯湾区域。

Conclusion: 研究强调了平衡数据集的必要性，展示了深度学习的潜在应用价值，特别是在通过使用合成数据生成增强模型性能方面，对于解决遥感中的常见挑战具有重要意义。

Abstract: The recent and ongoing expansion of marine infrastructure, including offshore
wind farms, oil and gas platforms, artificial islands, and aquaculture
facilities, highlights the need for effective monitoring systems. The
development of robust models for offshore infrastructure detection relies on
comprehensive, balanced datasets, but falls short when samples are scarce,
particularly for underrepresented object classes, shapes, and sizes. By
training deep learning-based YOLOv10 object detection models with a combination
of synthetic and real Sentinel-1 satellite imagery acquired in the fourth
quarter of 2023 from four regions (Caspian Sea, South China Sea, Gulf of
Guinea, and Coast of Brazil), this study investigates the use of synthetic
training data to enhance model performance. We evaluated this approach by
applying the model to detect offshore platforms in three unseen regions (Gulf
of Mexico, North Sea, Persian Gulf) and thereby assess geographic
transferability. This region-holdout evaluation demonstrated that the model
generalises beyond the training areas. In total, 3,529 offshore platforms were
detected, including 411 in the North Sea, 1,519 in the Gulf of Mexico, and
1,593 in the Persian Gulf. The model achieved an F1 score of 0.85, which
improved to 0.90 upon incorporating synthetic data. We analysed how synthetic
data enhances the representation of unbalanced classes and overall model
performance, taking a first step toward globally transferable detection of
offshore infrastructure. This study underscores the importance of balanced
datasets and highlights synthetic data generation as an effective strategy to
address common challenges in remote sensing, demonstrating the potential of
deep learning for scalable, global offshore infrastructure monitoring.

</details>


### [8] [Adaptive Temporal Refinement: Continuous Depth Allocation and Distance Regression for Efficient Action Localization](https://arxiv.org/abs/2511.03943)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CV

TL;DR: 提出了边界距离回归(BDR)和自适应时间细化(ATR)两项贡献，BDR通过回归而非分类进行精确边界检测，ATR则通过选择计算深度来适应性分配计算资源。这些方法在不同架构上显著提高了精确度和效率，减少了计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理动作边界定位时存在统一计算的问题，忽略了不同边界间的难度差异。需要一种方法能够更精确地检测动作边界且效率更高，计算成本更低。

Method: 提出了边界距离回归(BDR)；提出了自适应时间细化(ATR)，一个允许前端到后端可微分优化的方法；使用知识蒸馏减轻训练成本。

Result: BDR在不同的架构上提供了一致的1.8到3.1%的mAP@0.7改进，而在THUMOS14数据集上，ATR相较于统一处理而言，在减少大约18%计算的情况下，仍提供了2.9%的mAP@0.7改善。短动作上的改进更是达到了4.2%。这些改进通过严格的统计检验在四个基准上得到了验证。

Conclusion: 通过引入BDR和ATR，有效地提高了边界定位的精度，同时降低了计算成本。知识蒸馏技术的使用进一步减轻了训练成本。

Abstract: Temporal action localization requires precise boundary detection; however,
current methods apply uniform computation despite significant variations in
difficulty across boundaries. We present two complementary contributions.
First, Boundary Distance Regression (BDR) provides information-theoretically
optimal localization through signed-distance regression rather than
classification, achieving 43\% sharper boundary peaks. BDR retrofits to
existing methods with approximately 50 lines of code, yielding consistent 1.8
to 3.1\% mAP@0.7 improvements across diverse architectures. Second, Adaptive
Temporal Refinement (ATR) allocates computation via continuous depth selection
$\tau \in [0,1]$, enabling end-to-end differentiable optimization without
reinforcement learning. On THUMOS14, ATR achieves 56.5\% mAP@0.7 at 162G FLOPs,
compared to 53.6\% at 198G for uniform processing, providing a 2.9\%
improvement with 18\% less compute. Gains scale with boundary heterogeneity,
showing 4.2\% improvement on short actions. Training cost is mitigated via
knowledge distillation, with lightweight students retaining 99\% performance at
baseline cost. Results are validated across four benchmarks with rigorous
statistical testing.

</details>


### [9] [Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization](https://arxiv.org/abs/2511.03950)
*Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang*

Main category: cs.CV

TL;DR: 提出一种同时优化网格几何和顶点颜色的新框架，用于高质量的3D重建，并可用于下游编辑任务如重新照明和形状变形


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将几何准确性和视觉真实感渲染分开处理，这对于下游编辑任务是有挑战性的。此框架通过统一处理几何和外观优化来应对这个问题

Method: 采用Gaussian引导的可微渲染进行网格几何和顶点颜色的同时优化，利用输入图像的照相一致性以及法线和深度图的几何规则化

Result: 实现高质量的3D重建，可用于下游编辑任务如重新照明和形状变形

Conclusion: 提出的框架可以有效解决现有方法中的不足，提供高质量的3D重建，同时支持下游编辑任务

Abstract: Reconstructing real-world objects from multi-view images is essential for
applications in 3D editing, AR/VR, and digital content creation. Existing
methods typically prioritize either geometric accuracy (Multi-View Stereo) or
photorealistic rendering (Novel View Synthesis), often decoupling geometry and
appearance optimization, which hinders downstream editing tasks. This paper
advocates an unified treatment on geometry and appearance optimization for
seamless Gaussian-mesh joint optimization. More specifically, we propose a
novel framework that simultaneously optimizes mesh geometry (vertex positions
and faces) and vertex colors via Gaussian-guided mesh differentiable rendering,
leveraging photometric consistency from input images and geometric
regularization from normal and depth maps. The obtained high-quality 3D
reconstruction can be further exploit in down-stream editing tasks, such as
relighting and shape deformation. The code will be publicly available upon
acceptance.

</details>


### [10] [A Linear Fractional Transformation Model and Calibration Method for Light Field Camera](https://arxiv.org/abs/2511.03962)
*Zhong Chen,Changfeng Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于线性分数变换（LFT）参数的解耦方法来进行光场相机的内部参数校准，该方法包括基于最小二乘法的解析解和非线性优化。实验结果验证了该方法的有效性，并且基于该模型，光场原始图像的模拟速度加快，这对于数据驱动的深度学习方法至关重要。


<details>
  <summary>Details</summary>
Motivation: 光场相机的3D重建需要准确校准内部参数，这是一个关键但具有挑战性的任务。本文旨在提出一种新的方法来解决这一问题。

Method: 本文提出了一种基于线性分数变换（LFT）参数的方法来解耦主镜头和微透镜阵列（MLA），并采用最小二乘法的解析解和非线性优化进行参数校准。同时，本文还介绍了从原始图像中检测特征的方法。

Result: 实验结果表明，所提出的方法在物理和模拟数据上都验证了其有效性，基于该模型，光场原始图像的模拟速度加快。

Conclusion: 基于线性分数变换（LFT）参数的解耦方法不仅能够有效地校准光场相机的内部参数，而且提高了光场原始图像的模拟速度，为数据驱动的深度学习方法提供了支持。

Abstract: Accurate calibration of internal parameters is a crucial yet challenging
prerequisite for 3D reconstruction using light field cameras. In this paper, we
propose a linear fractional transformation(LFT) parameter $\alpha$ to decoupled
the main lens and micro lens array (MLA). The proposed method includes an
analytical solution based on least squares, followed by nonlinear refinement.
The method for detecting features from the raw images is also introduced.
Experimental results on both physical and simulated data have verified the
performance of proposed method. Based on proposed model, the simulation of raw
light field images becomes faster, which is crucial for data-driven deep
learning methods. The corresponding code can be obtained from the author's
website.

</details>


### [11] [Room Envelopes: A Synthetic Dataset for Indoor Layout Reconstruction from Images](https://arxiv.org/abs/2511.03970)
*Sam Bahrami,Dylan Campbell*

Main category: cs.CV

TL;DR: 论文提出了一个称为Room Envelopes的合成数据集，用于改善对场景结构元素（如墙体、地面和天花板）的重建。该数据集通过提供场景可见表面和去除内部设施后的表面的点地图，支持直接监督前馈单目几何估计器的训练，从而促进对这些结构元素的准确预测。


<details>
  <summary>Details</summary>
Motivation: 当前的3D场景重建方法在处理可见表面时表现良好，但对于重建被遮挡的场景结构元素（例如墙壁、地板和天花板）却较少探索。论文认为，由于这些结构元素通常是平面、重复且简单的，因此应该更容易预测，并且可以采用成本较低的方法。因此，创建了Room Envelopes数据集，以推动针对这些问题的进一步研究。

Method: 论文提出了一个合成数据集Room Envelopes，其中包含RGB图像和对应的两个点图：一个是可见表面的点图，另一个是去除内部设施后的表面的点图。该数据集为前馈单目几何估计器的直接监督提供支持。

Result: 合成数据集Room Envelopes的使用为场景的结构元素提供了有效的重建方法，使得前馈单目几何估计器能够预测场景的第一个可见表面和第一个布局表面。这有助于理解场景的范围，以及场景中物体的形状和位置。

Conclusion: 通过提供可以直接监督前馈单目几何估计器的合成数据集，本文为准确预测和重建场景的结构元素开辟了新的途径，并有助于改进场景的整体理解和重建。

Abstract: Modern scene reconstruction methods are able to accurately recover 3D
surfaces that are visible in one or more images. However, this leads to
incomplete reconstructions, missing all occluded surfaces. While much progress
has been made on reconstructing entire objects given partial observations using
generative models, the structural elements of a scene, like the walls, floors
and ceilings, have received less attention. We argue that these scene elements
should be relatively easy to predict, since they are typically planar,
repetitive and simple, and so less costly approaches may be suitable. In this
work, we present a synthetic dataset -- Room Envelopes -- that facilitates
progress on this task by providing a set of RGB images and two associated
pointmaps for each image: one capturing the visible surface and one capturing
the first surface once fittings and fixtures are removed, that is, the
structural layout. As we show, this enables direct supervision for feed-forward
monocular geometry estimators that predict both the first visible surface and
the first layout surface. This confers an understanding of the scene's extent,
as well as the shape and location of its objects.

</details>


### [12] [Simple 3D Pose Features Support Human and Machine Social Scene Understanding](https://arxiv.org/abs/2511.03988)
*Wenshuo Qin,Leyla Isik*

Main category: cs.CV

TL;DR: 该研究发现人类依靠3D视觉空间姿势信息来判断社交互动，这一信息在大多数AI视觉模型中缺失。通过将先进的姿态和深度估计算法结合，该研究发现3D关节位置比大多数当前AI视觉模型更能预测人类社交互动判断。结果显示，简化的人体姿势特征可以显著提升现成AI视觉模型的表现，表明人类的社交场景理解依赖于显式3D姿势表示和结构化的视觉空间原语。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索人类如何通过视觉输入理解社交互动，并挑战了先进AI模型在此方面的不足，提出假设人类依赖于3D视觉空间姿势信息来判断社交互动，而大多数AI模型缺乏这一信息。

Method: 研究使用最先进的姿态和深度估计算法，提取视频片段中人物的3D关节位置，并与当前AI视觉模型的预测能力进行比较。通过提取面部的位置和方向等最简3D社交姿势特征，比较它们与完整3D关节位置的预测强度，并将其与现成的AI模型结合，以提升模型的表现。

Result: 研究结果表明，3D关节位置比大多数当前AI视觉模型预测人类社交互动判断的能力更强，提取简化的人体姿势特征能够显著提升现成AI模型的表现，且3D社交姿势特征的表示程度可以预测AI模型匹配人类社交判断的能力。

Conclusion: 研究结果提供了人类社交场景理解依赖于显式3D姿势表征及简单结构化视觉空间原语的强证据，为未来研究的模型设计提供参考。

Abstract: Humans can quickly and effortlessly extract a variety of information about
others' social interactions from visual input, ranging from visuospatial cues
like whether two people are facing each other to higher-level information. Yet,
the computations supporting these abilities remain poorly understood, and
social interaction recognition continues to challenge even the most advanced AI
vision systems. Here, we hypothesized that humans rely on 3D visuospatial pose
information to make social interaction judgments, which is absent in most AI
vision models. To test this, we combined state-of-the-art pose and depth
estimation algorithms to extract 3D joint positions of people in short video
clips depicting everyday human actions and compared their ability to predict
human social interaction judgments with current AI vision models. Strikingly,
3D joint positions outperformed most current AI vision models, revealing that
key social information is available in explicit body position but not in the
learned features of most vision models, including even the layer-wise
embeddings of the pose models used to extract joint positions. To uncover the
critical pose features humans use to make social judgments, we derived a
compact set of 3D social pose features describing only the 3D position and
direction of faces in the videos. We found that these minimal descriptors
matched the predictive strength of the full set of 3D joints and significantly
improved the performance of off-the-shelf AI vision models when combined with
their embeddings. Moreover, the degree to which 3D social pose features were
represented in each off-the-shelf AI vision model predicted the model's ability
to match human social judgments. Together, our findings provide strong evidence
that human social scene understanding relies on explicit representations of 3D
pose and can be supported by simple, structured visuospatial primitives.

</details>


### [13] [CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation](https://arxiv.org/abs/2511.03992)
*Yuwen Tao,Kanglei Zhou,Xin Tan,Yuan Xie*

Main category: cs.CV

TL;DR: CaRF提出了一种新的方法，直接在3D高斯空间中操作，实现了多视角一致性，克服了现有方法在处理跨视角一致性时的不足。通过引入GFCE和ITPVS，提升了场景理解的可靠性和视角一致性，具有潜在的应用价值。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理跨视角一致性方面存在不足，依赖于2D渲染的伪监督和视角特定的特征学习，使得模型容易过拟合特定视角并忽视其他视角的信息。CaRF提出一种新的框架来解决这一问题，它能直接在3D高斯空间中操作，实现多视角一致性和跨视角的信息共享。同时，它也能够提升场景理解的可靠性和处理跨视角变化的能力，为应用在AR/VR交互、自主感知等领域能力的提升打下基础。

Method: CaRF通过引入Gaussian Field Camera Encoding (GFCE)，将相机几何信息整合到高斯文本交互中，以具体模型视角依赖的变化并提升几何推理能力。此外，提出In Training Paired View Supervision (ITPVS) 用于在训练期间对校准视角下的每个高斯特征进行对齐，从而有效减轻单视角过拟合并揭示视角间差异以供优化。

Result: 在三个基准数据集上进行的实验表明，CaRF在mIoU上相对于最先进的方法平均提高了16.8%，4.3%和2.0%，证实了该方法的有效性。这表明CaRF可以更可靠和一致地理解3D场景，对于推广跨视角一致性至关重要。

Conclusion: CaRF不仅在性能上超越了当前最先进的方法，而且还提出一种能够实现多视角一致性和增强可靠性理解3D场景的方法。同时，它具有潜在的应用价值，能够更好地服务于AR/VR交互、自主感知等领域。

Abstract: Referring 3D Gaussian Splatting Segmentation (R3DGS) aims to interpret
free-form language expressions and localize the corresponding 3D regions in
Gaussian fields. While recent advances have introduced cross-modal alignment
between language and 3D geometry, existing pipelines still struggle with
cross-view consistency due to their reliance on 2D rendered pseudo supervision
and view specific feature learning. In this work, we present Camera Aware
Referring Field (CaRF), a fully differentiable framework that operates directly
in the 3D Gaussian space and achieves multi view consistency. Specifically,
CaRF introduces Gaussian Field Camera Encoding (GFCE), which incorporates
camera geometry into Gaussian text interactions to explicitly model view
dependent variations and enhance geometric reasoning. Building on this, In
Training Paired View Supervision (ITPVS) is proposed to align per Gaussian
logits across calibrated views during training, effectively mitigating single
view overfitting and exposing inter view discrepancies for optimization.
Extensive experiments on three representative benchmarks demonstrate that CaRF
achieves average improvements of 16.8%, 4.3%, and 2.0% in mIoU over state of
the art methods on the Ref LERF, LERF OVS, and 3D OVS datasets, respectively.
Moreover, this work promotes more reliable and view consistent 3D scene
understanding, with potential benefits for embodied AI, AR/VR interaction, and
autonomous perception.

</details>


### [14] [PhysCorr: Dual-Reward DPO for Physics-Constrained Text-to-Video Generation with Automated Preference Selection](https://arxiv.org/abs/2511.03997)
*Peiyao Wang,Weining Wang,Qi Li*

Main category: cs.CV

TL;DR: PhysCorr是一个统一的框架，用于在视频生成中建模、评估和优化物理一致性，提出了PhysicsRM和PhyDPO来提高物理真实性，同时保持视觉保真度和语义对齐，适用于多种视频生成模型的无缝集成和优化。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成技术存在物理一致性的缺陷，造成了内容无法充分模拟现实世界，这对应用于具身AI、机器人及模拟密集型领域构成了挑战。为了弥补这一不足，提出了一个能够评估和优化物理一致性的框架。

Method: 引入了第一个同时量化物件内部稳定性与物件间交互的双维度奖励模型PhysicsRM，并开发了一种新的直接偏好优化管道PhyDPO，该管道利用对比反馈和物理感知权重来引导生成过程，以便得到物理上一致的结果。此方法是模型无关的，并且可扩展，可以无缝结合多种视频扩散和变换模型。

Result: 在多个基准上的实验表明，本文的方法在保持视觉保真度和语义一致性的同时，显著提高了物理真实性。这为可信且物理基础的视频生成做出了重要贡献。

Conclusion: 本文提出了一种用于提高视频生成物理一致性的方法，该方法不仅提高了物理真实性还保持了视觉质量和语义一致性，并且能够跨多种视频生成模型集成与优化。

Abstract: Recent advances in text-to-video generation have achieved impressive
perceptual quality, yet generated content often violates fundamental principles
of physical plausibility - manifesting as implausible object dynamics,
incoherent interactions, and unrealistic motion patterns. Such failures hinder
the deployment of video generation models in embodied AI, robotics, and
simulation-intensive domains. To bridge this gap, we propose PhysCorr, a
unified framework for modeling, evaluating, and optimizing physical consistency
in video generation. Specifically, we introduce PhysicsRM, the first
dual-dimensional reward model that quantifies both intra-object stability and
inter-object interactions. On this foundation, we develop PhyDPO, a novel
direct preference optimization pipeline that leverages contrastive feedback and
physics-aware reweighting to guide generation toward physically coherent
outputs. Our approach is model-agnostic and scalable, enabling seamless
integration into a wide range of video diffusion and transformer-based
backbones. Extensive experiments across multiple benchmarks demonstrate that
PhysCorr achieves significant improvements in physical realism while preserving
visual fidelity and semantic alignment. This work takes a critical step toward
physically grounded and trustworthy video generation.

</details>


### [15] [Near-Lossless 3D Voxel Representation Free from Iso-surface](https://arxiv.org/abs/2511.04029)
*Yihao Luo,Xianglong He,Chuanyu Pan,Yiwen Chen,Jiaqi Wu,Yangguang Li,Wanli Ouyang,Yuanming Hu,Guang Yang,ChoonHwai Yap*

Main category: cs.CV

TL;DR: 提出了一种名为Faithful Contouring的稀疏体素表示方法，可以支持2048+分辨率的任意网格表示，并且在不牺牲几何保真度的情况下进行精细度和内部结构的保持。同时，还设计了一种适用于Faithful Contouring的双模态自编码器，可以实现可扩展且精细度保持的形状重建。实验结果表明，该方法在精度和效率方面均优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的基于等值面的3D网格体素表示方法依赖于水密化或渲染优化，这会不可避免地降低几何保真度。为了提高几何保真度，本文提出了一种稀疏体素化表示方法，它支持高分辨率的任意网格表示，并能够在保持精细度和内部结构的前提下进行操作，同时保持几何保真度。

Method: 提出Faithful Contouring稀疏体素表示方法，它不需要将网格转换为场函数，也不需要在重构时提取等值面，可以支持2048+分辨率的任意网格表示，并且能够保持高保真度。同时，设计了一种适用于Faithful Contouring的双模态自编码器，可以实现可扩展且精细度保持的形状重建。

Result: 实验结果显示，与现有技术相比，Faithful Contouring在距离误差上低至$10^{-5}$，在Chamfer Distance上减少了35%，F-score提高了93%，证明了它作为3D学习任务表示方法的优越性。

Conclusion: Faithful Contouring是一种新颖的高保真度的稀疏体素化表示方法，能够在不牺牲几何保真度的情况下支持高分辨率任意网格的精细度和内部结构保持，通过实验验证其优越性。

Abstract: Accurate and efficient voxelized representations of 3D meshes are the
foundation of 3D reconstruction and generation. However, existing
representations based on iso-surface heavily rely on water-tightening or
rendering optimization, which inevitably compromise geometric fidelity. We
propose Faithful Contouring, a sparse voxelized representation that supports
2048+ resolutions for arbitrary meshes, requiring neither converting meshes to
field functions nor extracting the isosurface during remeshing. It achieves
near-lossless fidelity by preserving sharpness and internal structures, even
for challenging cases with complex geometry and topology. The proposed method
also shows flexibility for texturing, manipulation, and editing. Beyond
representation, we design a dual-mode autoencoder for Faithful Contouring,
enabling scalable and detail-preserving shape reconstruction. Extensive
experiments show that Faithful Contouring surpasses existing methods in
accuracy and efficiency for both representation and reconstruction. For direct
representation, it achieves distance errors at the $10^{-5}$ level; for mesh
reconstruction, it yields a 93\% reduction in Chamfer Distance and a 35\%
improvement in F-score over strong baselines, confirming superior fidelity as a
representation for 3D learning tasks.

</details>


### [16] [A Hybrid Deep Learning Model for Robust Biometric Authentication from Low-Frame-Rate PPG Signals](https://arxiv.org/abs/2511.04037)
*Arfina Rahman,Mahesh Banavar*

Main category: cs.CV

TL;DR: 本文提出了一种基于PPG信号的低成本生物认证框架，特别是在低帧率的手指视频中提取PPG信号。使用连续小波变换(CWT)将PPG信号转换为时频斯托姆格拉姆，然后利用CVT-ConvMixer-LSTM混合深度学习模型生成时空特征。实验结果表明，该系统可以达到98%的认证精度，对噪声和个体间差异有较强的鲁棒性，适合移动和嵌入式生物识别安全应用。


<details>
  <summary>Details</summary>
Motivation: 无创、低成本、捕捉瞬时心血管动力，适用于实时监控和生物识别系统，特别是面对运动伪影、光照变化和个体间差异时的强鲁棒性认证。

Method: 利用连续小波变换(CWT)将一维PPG信号转化为二维时空谱图。开发了一种混合深度学习模型CVT-ConvMixer-LSTM，结合了空间和时间特征。采用CFIHSR数据集进行实验评估。

Result: 实验结果表明新型生物认证系统在46个受试者中的准确率为98%，体现出对噪声和个体间差异的强鲁棒性。

Conclusion: 该系统具备通用性和良好的实时性，适用于实时监控和生物识别应用，认证准确度高，强鲁棒性。由于其成本低，可以通过佩戴式设备进行大规模部署。

Abstract: Photoplethysmography (PPG) signals, which measure changes in blood volume in
the skin using light, have recently gained attention in biometric
authentication because of their non-invasive acquisition, inherent liveness
detection, and suitability for low-cost wearable devices. However, PPG signal
quality is challenged by motion artifacts, illumination changes, and
inter-subject physiological variability, making robust feature extraction and
classification crucial. This study proposes a lightweight and cost-effective
biometric authentication framework based on PPG signals extracted from
low-frame-rate fingertip videos. The CFIHSR dataset, comprising PPG recordings
from 46 subjects at a sampling rate of 14 Hz, is employed for evaluation. The
raw PPG signals undergo a standard preprocessing pipeline involving baseline
drift removal, motion artifact suppression using Principal Component Analysis
(PCA), bandpass filtering, Fourier-based resampling, and amplitude
normalization. To generate robust representations, each one-dimensional PPG
segment is converted into a two-dimensional time-frequency scalogram via the
Continuous Wavelet Transform (CWT), effectively capturing transient
cardiovascular dynamics. We developed a hybrid deep learning model, termed
CVT-ConvMixer-LSTM, by combining spatial features from the Convolutional Vision
Transformer (CVT) and ConvMixer branches with temporal features from a Long
Short-Term Memory network (LSTM). The experimental results on 46 subjects
demonstrate an authentication accuracy of 98%, validating the robustness of the
model to noise and variability between subjects. Due to its efficiency,
scalability, and inherent liveness detection capability, the proposed system is
well-suited for real-world mobile and embedded biometric security applications.

</details>


### [17] [Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment](https://arxiv.org/abs/2511.04078)
*Zehui Feng,Chenqi Zhang,Mingru Wang,Minuo Wei,Shiwei Cheng,Cuntai Guan,Ting Han*

Main category: cs.CV

TL;DR: 本文提出了Bratrix，一种跨模态的视觉-大脑对齐框架，能更好地解耦视觉刺激并在一个共享的潜在空间中形成对齐的视觉-语言和大脑-语言嵌入，通过语言锚定语义矩阵增强跨模态相关性和采用两阶段的训练策略，提高检索、重建和描述任务的性能，特别是在EEG检索任务上超过了14.3%的性能


<details>
  <summary>Details</summary>
Motivation: 当前的方法直接将神经活动与视觉嵌入对齐，但视觉单一表示往往难以捕捉潜在的语义维度，限制了解释性和深度鲁棒性。为了解决这些问题，Bratrix被设计为首个端到端的框架，通过语言锚定来实现视觉-大脑的对齐，并能处理噪声神经信号以模拟人类感知可靠性

Method: Bratrix采用了一种新的不确定性感知模块，在对齐阶段应用不确定性感知的加权，使用可学习的语言锚定语义矩阵增强跨模态相关性，并采用单模态预训练加多模态微调的两阶段训练策略

Result: 在EEG、MEG和fMRI基准测试中，Bratrix显示出了比当前最佳方法更好的检索、重建和描述性能。特别是在200路EEG检索任务中，Bratrix的性能比最佳方法提升了14.3%以上

Conclusion: Bratrix改善了视觉-大脑对齐的质量，提供了更好的跨模态语义理解和更具鲁棒性的语言锚定模态对齐

Abstract: Unveiling visual semantics from neural signals such as EEG, MEG, and fMRI
remains a fundamental challenge due to subject variability and the entangled
nature of visual features. Existing approaches primarily align neural activity
directly with visual embeddings, but visual-only representations often fail to
capture latent semantic dimensions, limiting interpretability and deep
robustness. To address these limitations, we propose Bratrix, the first
end-to-end framework to achieve multimodal Language-Anchored Vision-Brain
alignment. Bratrix decouples visual stimuli into hierarchical visual and
linguistic semantic components, and projects both visual and brain
representations into a shared latent space, enabling the formation of aligned
visual-language and brain-language embeddings. To emulate human-like perceptual
reliability and handle noisy neural signals, Bratrix incorporates a novel
uncertainty perception module that applies uncertainty-aware weighting during
alignment. By leveraging learnable language-anchored semantic matrices to
enhance cross-modal correlations and employing a two-stage training strategy of
single-modality pretraining followed by multimodal fine-tuning, Bratrix-M
improves alignment precision. Extensive experiments on EEG, MEG, and fMRI
benchmarks demonstrate that Bratrix improves retrieval, reconstruction, and
captioning performance compared to state-of-the-art methods, specifically
surpassing 14.3% in 200-way EEG retrieval task. Code and model are available.

</details>


### [18] [Adversarial and Score-Based CT Denoising: CycleGAN vs Noise2Score](https://arxiv.org/abs/2511.04083)
*Abu Hanif Muhammad Syarubany*

Main category: cs.CV

TL;DR: 研究了无配对和自监督条件下的CT图像去噪，通过评估两种强大的、数据效率高的框架：基于CycleGAN的残差翻译器和基于Noise2Score的得分匹配去噪器，发现CycleGAN在图像质量上较强，而Noise2Score在没有干净图像对的情况下表现良好。


<details>
  <summary>Details</summary>
Motivation: 研究无配对和自监督条件下CT图像去噪的有效方法，通过两种强大的框架进行比较，探索不同的去噪方法在实际应用中的优劣。

Method: 评估了两种模型：基于CycleGAN的残差翻译器和Noise2Score得分匹配去噪器，采用了统一的评估协议，并进行了配置扫描来确定最优设置。最后选择了在图像质量上表现较好的CycleGAN模型。

Result: CycleGAN模型在测试中表现出了比Noise2Score更强的图像质量，PSNR从34.66 dB提升到38.913 dB，SSIM从0.9234提升到0.971。Noise2Score虽然在绝对PSNR/SSIM得分上稍低，但在处理极高噪声输入时表现更好。

Conclusion: CycleGAN在图像质量上表现最好，而Noise2Score提供了一种无需成对数据的稳健且性能竞争力强的去噪方法。这两种方法在不同的去噪任务中各有优势，可根据具体需求选择最合适的去噪方式。

Abstract: We study CT image denoising in the unpaired and self-supervised regimes by
evaluating two strong, training-data-efficient paradigms: a CycleGAN-based
residual translator and a Noise2Score (N2S) score-matching denoiser. Under a
common evaluation protocol, a configuration sweep identifies a simple standard
U-Net backbone within CycleGAN (lambda_cycle = 30, lambda_iden = 2, ngf = ndf =
64) as the most reliable setting; we then train it to convergence with a longer
schedule. The selected CycleGAN improves the noisy input from 34.66 dB / 0.9234
SSIM to 38.913 dB / 0.971 SSIM and attains an estimated score of 1.9441 and an
unseen-set (Kaggle leaderboard) score of 1.9343. Noise2Score, while slightly
behind in absolute PSNR / SSIM, achieves large gains over very noisy inputs,
highlighting its utility when clean pairs are unavailable. Overall, CycleGAN
offers the strongest final image quality, whereas Noise2Score provides a robust
pair-free alternative with competitive performance. Source code is available at
https://github.com/hanifsyarubany/CT-Scan-Image-Denoising-using-CycleGAN-and-Noise2Score.

</details>


### [19] [When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation](https://arxiv.org/abs/2511.04084)
*Nishchal Sapkota,Haoyan Shi,Yejia Zhang,Xianshi Ma,Bofang Zheng,Danny Z. Chen*

Main category: cs.CV

TL;DR: 该研究提出了UKAST，一种融合了Kolmogorov-Arnold Networks (KANs)的U-Net架构，这种架构在Swin Transformer编码器中引入了基于有理函数的KANs，提高了模型的表达能力和数据效率，同时减少了FLOPs（浮点运算次数）和参数量。UKAST在几个多样的2D和3D医学影像分割基准测试中达到了最先进的性能，特别是在数据稀缺的场景中表现更加突出。这一成果展现了KAN增强的Transformer在推进高效医学影像分割方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的CNN和Transformer在医学影像分割中存在局限性，如长程依赖建模不足和数据效率低下等。为解决这些问题，该研究提出了一种新的混合架构以提高医学影像分割的表现和数据效率。

Method: 该研究基于Swin Transformer Encoder，引入rational-base functions 和 Group Rational KANs (GR-KANs)，构建一种新颖的U-Net like架构UKAST，增强了局部特征提取和全球依赖建模，同时提高了模型效率。

Result: UKAST在四个不同的2D和3D医学影像分割基准测试中表现出了超越现有CNN和Transformer模型的表现，尤其在数据稀缺的场景中展现了其优越的性能和高效的数据利用。

Conclusion: 通过引入KAN到Transformer结构中，构建了新的UKAST架构，大幅改善了医学影像分割的任务精度，并在数据使用上更加高效，这表明了KAN增强的Transformer架构的潜力和优势。

Abstract: Medical image segmentation is critical for accurate diagnostics and treatment
planning, but remains challenging due to complex anatomical structures and
limited annotated training data. CNN-based segmentation methods excel at local
feature extraction, but struggle with modeling long-range dependencies.
Transformers, on the other hand, capture global context more effectively, but
are inherently data-hungry and computationally expensive. In this work, we
introduce UKAST, a U-Net like architecture that integrates rational-function
based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders. By
leveraging rational base functions and Group Rational KANs (GR-KANs) from the
Kolmogorov-Arnold Transformer (KAT), our architecture addresses the
inefficiencies of vanilla spline-based KANs, yielding a more expressive and
data-efficient framework with reduced FLOPs and only a very small increase in
parameter count compared to SwinUNETR. UKAST achieves state-of-the-art
performance on four diverse 2D and 3D medical image segmentation benchmarks,
consistently surpassing both CNN- and Transformer-based baselines. Notably, it
attains superior accuracy in data-scarce settings, alleviating the data-hungry
limitations of standard Vision Transformers. These results show the potential
of KAN-enhanced Transformers to advance data-efficient medical image
segmentation. Code is available at: https://github.com/nsapkota417/UKAST

</details>


### [20] [SpatialLock: Precise Spatial Control in Text-to-Image Synthesis](https://arxiv.org/abs/2511.04112)
*Biao Liu,Yuanzhi Liang*

Main category: cs.CV

TL;DR: SpatialLock 是一种新的 T2I 框架，它利用感知信号和定位信息来控制图像生成中的对象空间位置，提高了生成图像的质量和精确度。


<details>
  <summary>Details</summary>
Motivation: 当前 T2I 合成在对象定位的精确控制方面存在不足，主要是因为现有方法未能充分利用位置信息。

Method:  SpatialLock 包含 PoI 和 PoG 两个组件。PoI 通过注意力层直接整合空间信息，促进模型学习定位信息。PoG 使用感知监督进一步优化对象定位。这两个组件共同作用，使得生成的图像对象位置更精确、视觉质量更高。

Result: 实验表明，SpatialLock 达到了新的状态-of-the-art，跨多个数据集的 IOU 评分超过 0.9。

Conclusion: SpatialLock 通过利用感知信号和定位信息，提高了 T2I 合成中对象定位的精确度，同时提升了生成图像的视觉质量。

Abstract: Text-to-Image (T2I) synthesis has made significant advancements in recent
years, driving applications such as generating datasets automatically. However,
precise control over object localization in generated images remains a
challenge. Existing methods fail to fully utilize positional information,
leading to an inadequate understanding of object spatial layouts. To address
this issue, we propose SpatialLock, a novel framework that leverages perception
signals and grounding information to jointly control the generation of spatial
locations. SpatialLock incorporates two components: Position-Engaged Injection
(PoI) and Position-Guided Learning (PoG). PoI directly integrates spatial
information through an attention layer, encouraging the model to learn the
grounding information effectively. PoG employs perception-based supervision to
further refine object localization. Together, these components enable the model
to generate objects with precise spatial arrangements and improve the visual
quality of the generated images. Experiments show that SpatialLock sets a new
state-of-the-art for precise object positioning, achieving IOU scores above 0.9
across multiple datasets.

</details>


### [21] [Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with Multirate Integration](https://arxiv.org/abs/2511.04117)
*Yunghee Lee,Byeonghyun Pak,Junwha Hong,Hoseong Kim*

Main category: cs.CV

TL;DR: 本文提出了Tortoise and Hare Guidance (THG)策略，无需训练即可加速扩散采样同时保持高保真生成。THG通过在粗粒度时间步网格上仅对额外指导进行积分，显著减少计算量，保持了生成的保真度。THG比现有技术在相同计算预算下表现更好，证明了多重速率格式对扩散求解器的潜力，为实现无需模型重新训练的实时高质量图像合成铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 在现有方法中，额外指导分支容易受到数值误差的影响，而该分支的冗余度使传统求解器无法利用。为了改善这一点，作者引入了Tortoise and Hare Guidance (THG)策略，加速扩散采样过程，同时保持高保真度。THG的核心动机是为了提高生成图像的质量和速度，减少计算量，同时确保生成的保真度不受影响。

Method: THG策略通过将噪声估计与“乌龟”方程在原始时间步网格上进行积分，而将额外指导与“兔子”方程仅在粗粒度时间步网格上进行积分，减少计算量。此外，引入了时间步适应性采样器和指导尺度调度器，以适应不同的计算需求和稳定性要求。

Result: THG策略可以减少高达30%的功能评估数量（NFE），并且在图像保真度上几乎没有损失（$\Delta$ImageReward $\leq$ 0.032）。在相同的计算预算下，与现有的训练免加速器相比，THG策略表现更优，证明了多速率求解器对扩散过程应用的价值和潜力。

Conclusion: 本文提出了一种新颖的方法，通过利用多重速率系统改进了基于扩散的生成模型的采样过程，显著加速了模型生成图像的速度，同时保持了图像的高保真度，为实现动态生成和实时高质量图像合成提供了一种有效的方法。

Abstract: In this paper, we propose Tortoise and Hare Guidance (THG), a training-free
strategy that accelerates diffusion sampling while maintaining high-fidelity
generation. We demonstrate that the noise estimate and the additional guidance
term exhibit markedly different sensitivity to numerical error by reformulating
the classifier-free guidance (CFG) ODE as a multirate system of ODEs. Our
error-bound analysis shows that the additional guidance branch is more robust
to approximation, revealing substantial redundancy that conventional solvers
fail to exploit. Building on this insight, THG significantly reduces the
computation of the additional guidance: the noise estimate is integrated with
the tortoise equation on the original, fine-grained timestep grid, while the
additional guidance is integrated with the hare equation only on a coarse grid.
We also introduce (i) an error-bound-aware timestep sampler that adaptively
selects step sizes and (ii) a guidance-scale scheduler that stabilizes large
extrapolation spans. THG reduces the number of function evaluations (NFE) by up
to 30% with virtually no loss in generation fidelity ($\Delta$ImageReward
$\leq$ 0.032) and outperforms state-of-the-art CFG-based training-free
accelerators under identical computation budgets. Our findings highlight the
potential of multirate formulations for diffusion solvers, paving the way for
real-time high-quality image synthesis without any model retraining. The source
code is available at https://github.com/yhlee-add/THG.

</details>


### [22] [Text to Sketch Generation with Multi-Styles](https://arxiv.org/abs/2511.04123)
*Tengjie Li,Shikui Tu,Lei Xu*

Main category: cs.CV

TL;DR: 我们提出了一个基于扩散模型的无需训练的框架，该框架通过文本提示和参考风格草图实现明确的风格指导，从而提高了草图生成的精确性和灵活性。我们的方法在草图生成方面实现了高质量的内容合风格正确对齐，显著减少了参考草图的内容泄漏，并提高了风格控制的灵活性。我们还将框架扩展以支持可控的多风格生成。实验结果表明，该方法在草图生成任务方面表现出色，具有高合成质量，尤其是在参考草图和目标草图之间结构相似性较低的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有的草图生成方法主要集中在通用合成，缺乏对草图风格的精确控制。目前的风格转换方法存在参考草图内容泄漏的问题。为此，我们提出了一种新的训练自由的框架，旨在解决这些问题并提高生成的草图质量。

Method: 新框架基于扩散模型，并采用线性平滑和参考草图特征作为辅助信息来实现风格和内容的指导，通过AdaIN模块实现多风格参考草图特征的协同，并减少从参考草图到目标草图的内容泄漏。我们通过这种方法增强了合成质量，尤其是在结构不同之处。

Result: 我们的方法显著减少了参考草图的内容泄漏，提高了合成质量，并增强了对风格的精确控制。实验结果表明，在结构更不相似的情况下，我们的方法仍能生成高质量的草图。

Conclusion: 我们引入了一种无需训练的草图创作框架，它利用文本提示和参考草图实现了明确的风格指导。实验结果再次证明了其效果，我们的方法实现了准确的风格对齐和改进的风格控制灵活性，并可以生成高质量的草图。

Abstract: Recent advances in vision-language models have facilitated progress in sketch
generation. However, existing specialized methods primarily focus on generic
synthesis and lack mechanisms for precise control over sketch styles. In this
work, we propose a training-free framework based on diffusion models that
enables explicit style guidance via textual prompts and referenced style
sketches. Unlike previous style transfer methods that overwrite key and value
matrices in self-attention, we incorporate the reference features as auxiliary
information with linear smoothing and leverage a style-content guidance
mechanism. This design effectively reduces content leakage from reference
sketches and enhances synthesis quality, especially in cases with low
structural similarity between reference and target sketches. Furthermore, we
extend our framework to support controllable multi-style generation by
integrating features from multiple reference sketches, coordinated via a joint
AdaIN module. Extensive experiments demonstrate that our approach achieves
high-quality sketch generation with accurate style alignment and improved
flexibility in style control. The official implementation of M3S is available
at https://github.com/CMACH508/M3S.

</details>


### [23] [Automated Tennis Player and Ball Tracking with Court Keypoints Detection (Hawk Eye System)](https://arxiv.org/abs/2511.04126)
*Venkata Manikanta Desu,Syed Fawaz Ali*

Main category: cs.CV

TL;DR: 本文提出了一种自动网球比赛分析的完整流程，通过集成多个深度学习模型实现实时球员和网球检测与跟踪，并识别场地关键点提供空间参考。该系统提供了详细的分析，包括球员运动模式、球速、击球准确性及反应时间等。实验显示该系统在不同的场地条件和比赛情景中表现出色。模型输出注释视频以及详细性能指标，为教练、广播员和球员提供对比赛动态的行动性洞察。


<details>
  <summary>Details</summary>
Motivation: 动机是为了解决网球比赛分析中手动记录的低效性和不可操作性问题，通过设计自动化的深度学习框架来提高分析的准确性和实时性，从而为教练和球员提供有价值的洞察。

Method: 方法包括使用YOLOv8进行球员检测、自定义训练的YOLOv5模型进行网球追踪以及基于ResNet50的架构进行场地关键点检测。整个系统能实时提供详细的运动分析，包含球员运动模式、球速、击球准确性及反应时间等。

Result: 实验结果表明该系统在多种场地条件和比赛情景中表现稳健。模型能够输出注释视频和详细性能指标，具有实用性。

Conclusion: 结论是该系统为网球比赛提供了全面且实时的数据分析，增强了教练和球员对比赛的理解，有助于提高训练和比赛的战术调整。

Abstract: This study presents a complete pipeline for automated tennis match analysis.
Our framework integrates multiple deep learning models to detect and track
players and the tennis ball in real time, while also identifying court
keypoints for spatial reference. Using YOLOv8 for player detection, a
custom-trained YOLOv5 model for ball tracking, and a ResNet50-based
architecture for court keypoint detection, our system provides detailed
analytics including player movement patterns, ball speed, shot accuracy, and
player reaction times. The experimental results demonstrate robust performance
in varying court conditions and match scenarios. The model outputs an annotated
video along with detailed performance metrics, enabling coaches, broadcasters,
and players to gain actionable insights into the dynamics of the game.

</details>


### [24] [Seeing Straight: Document Orientation Detection for Efficient OCR](https://arxiv.org/abs/2511.04161)
*Suranjan Goswami,Abhinav Ravi,Raja Kolla,Ali Faraz,Shaharukh Khan,Akash,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: 本文介绍了一种新的基准测试（OCR-Rotation-Bench，ORB）来评估光学字符识别对图像旋转的鲁棒性，并提出了一种基于Phi-3.5-Vision模型的快速、稳健且轻量级的旋转分类管道，该管道在两种数据集上的准确率分别为96%和92%，显著提高了光学字符识别的性能。


<details>
  <summary>Details</summary>
Motivation: 光学字符识别的准确性依赖于文档的正确方向，实际场景中的用户错误（如相机姿态不正确）会导致文档图像的旋转，影响OCR性能，因此需要一种有效的旋转校正方法以提高下游OCR任务的性能。

Method: 通过构建OCR-Rotation-Bench（ORB）基准测试，包括两个数据集（ORB-En和ORB-Indic），以及使用Phi-3.5-Vision模型的旋转分类管道，该管道应用动态图像裁剪技术，专门针对4类旋转任务进行微调。

Result: 提出的旋转分类管道在ORB-En和ORB-Indic数据集上实现了96%和92%的准确率，显示出对OCR性能的显著提升，包括商业闭源模型和开源模型的性能提升分别高达14%和4倍。

Conclusion: 实验结果表明，旋转分类管道不仅提高了旋转分类的准确性，还显著增强了OCR任务的性能。

Abstract: Despite significant advances in document understanding, determining the
correct orientation of scanned or photographed documents remains a critical
pre-processing step in the real world settings. Accurate rotation correction is
essential for enhancing the performance of downstream tasks such as Optical
Character Recognition (OCR) where misalignment commonly arises due to user
errors, particularly incorrect base orientations of the camera during capture.
In this study, we first introduce OCR-Rotation-Bench (ORB), a new benchmark for
evaluating OCR robustness to image rotations, comprising (i) ORB-En, built from
rotation-transformed structured and free-form English OCR datasets, and (ii)
ORB-Indic, a novel multilingual set spanning 11 Indic mid to low-resource
languages. We also present a fast, robust and lightweight rotation
classification pipeline built on the vision encoder of Phi-3.5-Vision model
with dynamic image cropping, fine-tuned specifically for 4-class rotation task
in a standalone fashion. Our method achieves near-perfect 96% and 92% accuracy
on identifying the rotations respectively on both the datasets. Beyond
classification, we demonstrate the critical role of our module in boosting OCR
performance: closed-source (up to 14%) and open-weights models (up to 4x) in
the simulated real-world setting.

</details>


### [25] [Systematic Evaluation of Preprocessing Techniques for Accurate Image Registration in Digital Pathology](https://arxiv.org/abs/2511.04171)
*Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz*

Main category: cs.CV

TL;DR: 本研究调查了不同颜色转换技术如何影响HE染色图像和非线性多模式图像之间的图像配准。使用20个组织样本对的数据集进行实验，结果显示，CycleGAN颜色转换方法在图像配准中表现最佳，使得不同模式图像之间的对齐更准确，从而支持数字病理学中的更可靠分析。


<details>
  <summary>Details</summary>
Motivation: 数字病理学中，图像配准是直接比较和整合来自不同染色或成像模式的信息的关键步骤。本研究旨在研究不同颜色转换技术如何影响HE染色图像和非线性多模式图像之间的配准效果。

Method: 使用包含20个组织样本对的数据集进行研究，每对样本经过包括颜色变换（CycleGAN，Macenko，Reinhard，Vahadane）、倒置、对比度调整、强度归一化和去噪等预处理步骤。利用VALIS注册方法，该方法首先执行刚性注册，然后分两步在低分辨率和高分辨率图像上进行非刚性注册。通过相对目标注册误差(rTRE)、中位数中位数相对目标注册误差(MMrTRE)和平均中位数相对目标注册误差(AMrTRE)进行性能评估。此外，还进行了基于点的评估，使用了十个手动选择的关键点。

Result: 研究结果显示，无论是在利用原始还是倒置的多模式图像进行配对的情景下，CycleGAN颜色转换方法获得了最低的配准误差。

Conclusion: 这些发现表明，配准前进行颜色转换可以提高不同模式图像之间的对齐准确性，进而支持数字病理学中的更可靠分析。

Abstract: Image registration refers to the process of spatially aligning two or more
images by mapping them into a common coordinate system, so that corresponding
anatomical or tissue structures are matched across images. In digital
pathology, registration enables direct comparison and integration of
information from different stains or imaging modalities, sup-porting
applications such as biomarker analysis and tissue reconstruction. Accurate
registration of images from different modalities is an essential step in
digital pathology. In this study, we investigated how various color
transformation techniques affect image registration between hematoxylin and
eosin (H&E) stained images and non-linear multimodal images. We used a dataset
of 20 tissue sample pairs, with each pair undergoing several preprocessing
steps, including different color transformation (CycleGAN, Macenko, Reinhard,
Vahadane), inversion, contrast adjustment, intensity normalization, and
denoising. All images were registered using the VALIS registration method,
which first applies rigid registration and then performs non-rigid registration
in two steps on both low and high-resolution images. Registration performance
was evaluated using the relative Target Registration Error (rTRE). We reported
the median of median rTRE values (MMrTRE) and the average of median rTRE values
(AMrTRE) for each method. In addition, we performed a custom point-based
evaluation using ten manually selected key points. Registration was done
separately for two scenarios, using either the original or inverted multimodal
images. In both scenarios, CycleGAN color transformation achieved the lowest
registration errors, while the other methods showed higher errors. These
findings show that applying color transformation before registration improves
alignment between images from different modalities and supports more reliable
analysis in digital pathology.

</details>


### [26] [AStF: Motion Style Transfer via Adaptive Statistics Fusor](https://arxiv.org/abs/2511.04192)
*Hanmo Chen,Chenghao Xu,Jiexi Yan,Cheng Deng*

Main category: cs.CV

TL;DR: 提出了一种新的自适应统计融合器（AStF）来改进人体运动风格转换，以捕捉运动数据的复杂动态模式和时空连贯性。该方法通过引入偏度和峰度两个参数，改进了传统的基于均值和方差的风格转移方法，并结合运动一致性正则化（MCR）来提高运动风格转换的效果。实验表明，该方法在运动风格转移方面比现有技术更有效。


<details>
  <summary>Details</summary>
Motivation: 现有方法基于均值和方差进行运动风格转换，但由于图像与运动的固有差异，仅靠这些参数无法充分捕捉运动数据中的复杂动态模式与时空连贯性。因此，引入偏度和峰度两个统计参数，以期能更好地模仿和转换运动风格。

Method: 提出了自适应统计融合器（AStF），该模型由风格解耦模块（SDM）和高阶多统计注意（HOS-Attn）组成，并配合运动一致性正则化（MCR）训练。通过引入偏度和峰度，该模型能够更全面地捕捉运动数据的时空统计特征。

Result: 实验结果显示，AStF在运动风格转移方面优于当前最佳技术，证明其在捕捉复杂动态模式和时空连贯性方面具有显著优势。

Conclusion: 该研究提出了一种更全面的方法来捕捉并转换运动数据中的动态风格，展示了在运动风格转移方面的显著改进。

Abstract: Human motion style transfer allows characters to appear less rigidity and
more realism with specific style. Traditional arbitrary image style transfer
typically process mean and variance which is proved effective. Meanwhile,
similar methods have been adapted for motion style transfer. However, due to
the fundamental differences between images and motion, relying on mean and
variance is insufficient to fully capture the complex dynamic patterns and
spatiotemporal coherence properties of motion data. Building upon this, our key
insight is to bring two more coefficient, skewness and kurtosis, into the
analysis of motion style. Specifically, we propose a novel Adaptive Statistics
Fusor (AStF) which consists of Style Disentanglement Module (SDM) and
High-Order Multi-Statistics Attention (HOS-Attn). We trained our AStF in
conjunction with a Motion Consistency Regularization (MCR) discriminator.
Experimental results show that, by providing a more comprehensive model of the
spatiotemporal statistical patterns inherent in dynamic styles, our proposed
AStF shows proficiency superiority in motion style transfers over
state-of-the-arts. Our code and model are available at
https://github.com/CHMimilanlan/AStF.

</details>


### [27] [MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection](https://arxiv.org/abs/2511.04255)
*Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li*

Main category: cs.CV

TL;DR: 本文重新审视了人体中心基础模（基础数据模型）在医学影像中解剖标志检测的应用，并提出了一个新的模型 MedSapiens，该模型在多个数据集上获得新的最佳状态（SOTA）。与现有的先进模型相比，MedSapiens 在平均成功检测率（SDR）上分别取得了最多 5.26% 和 21.81% 的提升，并在少量数据的设定下取得了 2.69% 的改进。


<details>
  <summary>Details</summary>
Motivation: 在医学影像中，解剖标志检测通常依赖特定领域模型，在大型预训练视觉模型的出现后，人体中心基础模型的潜在应用尚未得到充分挖掘。本文提出通过将一个专门为姿势估计设计的人体中心基础模型 Sapiens 适应到医学影像领域，来尝试引入这一点

Method: 文章提出新的模型 MedSapiens，并通过多数据集预训练，充分验证了人体中心基础模型在解剖标志检测的潜力。该研究还在少量标注数据的情况下评估了 MedSapiens 的适应性，同时也公开了代码和技术细节，方便复现和其它研究者的使用

Result: 与现有最佳模型相比，该模型在 SDR（平均成功检测率）上提升了最多 5.26%。在有限数据的任务设置下，SDR 上也取得了 2.69% 的提升。另外，与专业模型的对比中，也取得了最多 21.81% 的提升。这表明 MedSapiens 在各种任务中都有较好的适应性和性能表现

Conclusion: 人体中心基础模型在解剖标志检测中的潜力在本文中得到了证实，提出的 MedSapiens 不仅实现了性能的提升，在有限的标注数据下也表现出色。该研究为未来的研究提供了一个新的视角，并展示了人体中心基础模型在医学图像领域的广泛潜力。该研究相关的代码和技术细节已经公开，供其他研究者复现和进一步探索。

Abstract: This paper does not introduce a novel architecture; instead, it revisits a
fundamental yet overlooked baseline: adapting human-centric foundation models
for anatomical landmark detection in medical imaging. While landmark detection
has traditionally relied on domain-specific models, the emergence of
large-scale pre-trained vision models presents new opportunities. In this
study, we investigate the adaptation of Sapiens, a human-centric foundation
model designed for pose estimation, to medical imaging through multi-dataset
pretraining, establishing a new state of the art across multiple datasets. Our
proposed model, MedSapiens, demonstrates that human-centric foundation models,
inherently optimized for spatial pose localization, provide strong priors for
anatomical landmark detection, yet this potential has remained largely
untapped. We benchmark MedSapiens against existing state-of-the-art models,
achieving up to 5.26% improvement over generalist models and up to 21.81%
improvement over specialist models in the average success detection rate (SDR).
To further assess MedSapiens adaptability to novel downstream tasks with few
annotations, we evaluate its performance in limited-data settings, achieving
2.69% improvement over the few-shot state of the art in SDR. Code and model
weights are available at https://github.com/xmed-lab/MedSapiens .

</details>


### [28] [Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human Face Imagery](https://arxiv.org/abs/2511.04260)
*Claudio Giusti,Luca Guarnera,Sebastiano Battiato*

Main category: cs.CV

TL;DR: 提出了一种名为Proto-LeakNet的模型，能够通过对扩散模型的潜在域进行操作，揭示生成特定的线索，进而实现对合成图像和深度伪造的识别功能。该模型在封闭数据集上训练，在开放集评估中表现出色，表明了建模潜在空间中的信号泄漏偏差可以实现可靠且可解释的AI图像和深度伪造取证分析。


<details>
  <summary>Details</summary>
Motivation: 当前合成图像和深度伪造模型越来越复杂，这使得计算机视觉系统对图像来源和真实性验证变得极具挑战。研究认为，生成模型会无意在输出中留下所谓的信号泄漏，特别是在潜在表示中。这些信号泄漏为识别生成的图像提供了可能，因此开发了一种对信号泄漏有所了解的归因框架Proto-LeakNet。

Method: 模型通过再模拟部分前向扩散以暴露特定生成者的线索，采用时间注意力编码器聚合多步潜在特征，而特征加权原型头构造了嵌入空间，并实现了透明归因。通过仅对封闭数据进行训练，模型实现了对已知和未知生成器的强分离性，能够识别深度伪造图像和合成图像。

Result: 在封闭数据集上，Proto-LeakNet模型达到了Macro AUC 98.13%的性能，展现出了在开放集评价中的强大性能，并且在后期处理中表现出抗干扰性，超越了当前最先进的方法。

Conclusion: 通过对潜在空间中的信号泄漏偏差进行建模，能够实现可靠且可解释的AI图像和深度伪造取证分析。

Abstract: The growing sophistication of synthetic image and deepfake generation models
has turned source attribution and authenticity verification into a critical
challenge for modern computer vision systems. Recent studies suggest that
diffusion pipelines unintentionally imprint persistent statistical traces,
known as signal leaks, within their outputs, particularly in latent
representations. Building on this observation, we propose Proto-LeakNet, a
signal-leak-aware and interpretable attribution framework that integrates
closed-set classification with a density-based open-set evaluation on the
learned embeddings, enabling analysis of unseen generators without retraining.
Operating in the latent domain of diffusion models, our method re-simulates
partial forward diffusion to expose residual generator-specific cues. A
temporal attention encoder aggregates multi-step latent features, while a
feature-weighted prototype head structures the embedding space and enables
transparent attribution. Trained solely on closed data and achieving a Macro
AUC of 98.13%, Proto-LeakNet learns a latent geometry that remains robust under
post-processing, surpassing state-of-the-art methods, and achieves strong
separability between known and unseen generators. These results demonstrate
that modeling signal-leak bias in latent space enables reliable and
interpretable AI-image and deepfake forensics. The code for the whole work will
be available upon submission.

</details>


### [29] [DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification](https://arxiv.org/abs/2511.04281)
*Yujie Yang,Shuang Li,Jun Ye,Neng Dong,Fan Li,Huafeng Li*

Main category: cs.CV

TL;DR: 提出了一种基于DINOv2的DinoGRL框架，利用其丰富的视觉先验学习步态特征，以补充外观线索，从而增强跨模态视频匹配的时空一致性。



<details>
  <summary>Details</summary>
Motivation: 现有的方法主要依赖于模态不变的视觉特征，却忽略了步态特征，而步态特征不仅模态不变，而且富含时间动态性，这对跨模态视频匹配的时空一致性建模至关重要。


Method: 提出了DinoGRL框架，其中包括Semantic-Aware Silhouette and Gait Learning (SASGL)模型和Progressive Bidirectional Multi-Granularity Enhancement (PBMGE)模块。


Result: 实验结果表明，所提出的方法在HITSZ-VCM和BUPT数据集上显著优于现有的最新方法。


Conclusion: 相比现有的方法，本文的方法通过引入步态特征，更好地建模了时空一致性，从而提高了跨模态视频匹配的性能。


Abstract: Video-based Visible-Infrared person re-identification (VVI-ReID) aims to
retrieve the same pedestrian across visible and infrared modalities from video
sequences. Existing methods tend to exploit modality-invariant visual features
but largely overlook gait features, which are not only modality-invariant but
also rich in temporal dynamics, thus limiting their ability to model the
spatiotemporal consistency essential for cross-modal video matching. To address
these challenges, we propose a DINOv2-Driven Gait Representation Learning
(DinoGRL) framework that leverages the rich visual priors of DINOv2 to learn
gait features complementary to appearance cues, facilitating robust
sequence-level representations for cross-modal retrieval. Specifically, we
introduce a Semantic-Aware Silhouette and Gait Learning (SASGL) model, which
generates and enhances silhouette representations with general-purpose semantic
priors from DINOv2 and jointly optimizes them with the ReID objective to
achieve semantically enriched and task-adaptive gait feature learning.
Furthermore, we develop a Progressive Bidirectional Multi-Granularity
Enhancement (PBMGE) module, which progressively refines feature representations
by enabling bidirectional interactions between gait and appearance streams
across multiple spatial granularities, fully leveraging their complementarity
to enhance global representations with rich local details and produce highly
discriminative features. Extensive experiments on HITSZ-VCM and BUPT datasets
demonstrate the superiority of our approach, significantly outperforming
existing state-of-the-art methods.

</details>


### [30] [FastGS: Training 3D Gaussian Splatting in 100 Seconds](https://arxiv.org/abs/2511.04283)
*Shiwei Ren,Tianci Wen,Yongchun Fang,Biao Lu*

Main category: cs.CV

TL;DR: FastGS是一种新的加速框架，通过基于多视角一致性的策略来优化Gaussian的数量，有效解决了训练时间和渲染质量之间的折中问题。在多个数据集上均表现出了比现有方法更快的训练速度和与现有方法相当的渲染质量。同时，FastGS在多个任务上均展示了良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前最常用的三维高斯溅射加速方法在训练过程中无法有效控制Gaussian的数量，导致过高的计算开销。为了克服这个问题，作者提出了一种新的加速框架FastGS。

Method: FastGS设计了一种基于多视角一致性的稠密化和剪枝策略，从而有效地控制Gaussian的数量。这种方法不需要预算机制，能更高效地解决训练时间和渲染质量之间的折中问题。

Result: 在Mip-NeRF 360、Tanks & Temples 和 Deep Blending数据集上，FastGS相比现有的最先进方法实现了显著的速度提升，对于Mip-NeRF 360数据集，FastGS比DashGaussian的加速率达到3.32倍，对于Deep Blending数据集则达到15.45倍。同时，FastGS在动态场景重建、表面重建、稀疏视图重建、大规模重建和同时定位与建图等任务上均展现出2-7倍的训练加速效果。

Conclusion: FastGS作为一种简单且通用的加速框架，能够有效提升3D Gaussian splatting方法的训练速度，并保持较高的渲染质量。

Abstract: The dominant 3D Gaussian splatting (3DGS) acceleration methods fail to
properly regulate the number of Gaussians during training, causing redundant
computational time overhead. In this paper, we propose FastGS, a novel, simple,
and general acceleration framework that fully considers the importance of each
Gaussian based on multi-view consistency, efficiently solving the trade-off
between training time and rendering quality. We innovatively design a
densification and pruning strategy based on multi-view consistency, dispensing
with the budgeting mechanism. Extensive experiments on Mip-NeRF 360, Tanks &
Temples, and Deep Blending datasets demonstrate that our method significantly
outperforms the state-of-the-art methods in training speed, achieving a
3.32$\times$ training acceleration and comparable rendering quality compared
with DashGaussian on the Mip-NeRF 360 dataset and a 15.45$\times$ acceleration
compared with vanilla 3DGS on the Deep Blending dataset. We demonstrate that
FastGS exhibits strong generality, delivering 2-7$\times$ training acceleration
across various tasks, including dynamic scene reconstruction, surface
reconstruction, sparse-view reconstruction, large-scale reconstruction, and
simultaneous localization and mapping. The project page is available at
https://fastgs.github.io/

</details>


### [31] [Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment](https://arxiv.org/abs/2511.04288)
*Leire Benito-Del-Valle,Artzai Picón,Daniel Mugica,Manuel Ramos,Eva Portillo,Javier Romero,Carlos Javier Jimenez,Ramón Navarra-Mestre*

Main category: cs.CV

TL;DR: 本文提出了一种针对除草剂试验适应的视觉基础模型，通过自监督学习方法在大规模农业数据集上训练，显著提高了植物物种识别和除草剂损伤分类的准确性，特别是在未知条件下和不同模态数据上表现更加优越，同时还能提高分割准确度，在低标注数据条件下仍可实现较高的分数并节省标注工作量，提供了一种可扩展和自动化的解决方案


<details>
  <summary>Details</summary>
Motivation: 传统的视觉基础模型在农业领域表现较为有限，本文旨在通过特定领域预训练改进模型性能，以提高除草剂试验中植物物种识别和除草剂损伤分类的准确性

Method: 通过自监督学习方法在大规模高质量农业数据集上训练模型，提高其在除草剂试验中图像的表示能力，并在特定领域进行预训练以适应复杂多变的农业环境

Result: 领域特定模型显著提高了植物物种识别（F1分数从0.91提高到0.94）和损伤分类的准确率（从0.26提高到0.33），在未知条件下表现更优（物种识别从0.56提高到0.66；损伤分类从0.17提高到0.27），在无人机图像等不同模态下的表现仍然稳定（物种分类从0.49提高到0.60）。此外，还提高了分割精确度，具有较高的标记效率

Conclusion: 展示了领域特定基础模型在除草剂试验中的泛化能力，证明了其潜力能够显著减少手动标注工作量，提供了一种可扩展和自动化解决方案来分析除草剂试验

Abstract: Herbicide field trials require accurate identification of plant species and
assessment of herbicide-induced damage across diverse environments. While
general-purpose vision foundation models have shown promising results in
complex visual domains, their performance can be limited in agriculture, where
fine-grained distinctions between species and damage types are critical.
  In this work, we adapt a general-purpose vision foundation model to herbicide
trial characterization. Trained using a self-supervised learning approach on a
large, curated agricultural dataset, the model learns rich and transferable
representations optimized for herbicide trials images.
  Our domain-specific model significantly outperforms the best general-purpose
foundation model in both species identification (F1 score improvement from 0.91
to 0.94) and damage classification (from 0.26 to 0.33). Under unseen conditions
(new locations and other time), it achieves even greater gains (species
identification from 0.56 to 0.66; damage classification from 0.17 to 0.27). In
domain-shift scenarios, such as drone imagery, it maintains strong performance
(species classification from 0.49 to 0.60).
  Additionally, we show that domain-specific pretraining enhances segmentation
accuracy, particularly in low-annotation regimes. An annotation-efficiency
analysis reveals that, under unseen conditions, the domain-specific model
achieves 5.4% higher F1 score than the general-purpose model, while using 80%
fewer labeled samples.
  These results demonstrate the generalization capabilities of domain-specific
foundation models and their potential to significantly reduce manual annotation
efforts, offering a scalable and automated solution for herbicide trial
analysis.

</details>


### [32] [RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive Text-to-Video Generation](https://arxiv.org/abs/2511.04317)
*Xiangjun Zhang,Litong Gong,Yinglin Zheng,Yansong Liu,Wentao Jiang,Mingyi Xu,Biao Wang,Tiezheng Ge,Ming Zeng*

Main category: cs.CV

TL;DR: RISE-T2V 是一种新型的文本到视频扩散模型，能够在生成视频时实时修正文本提示，提高视频质量和用户意图匹配度。它将文本重述和语义特征提取合并为一步，提高了模型的通用性和适用性。实验表明，RISE-T2V 显著提高了文本到视频任务的质量和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到视频扩散模型依赖预训练的文本编码器进行语义对齐，但在使用简短提示时无法保持视频质量，因为文本编码器无法在线修正提示，以更好地匹配用户意图，限制了模型的可扩展性和可用性。为了解决这些问题，引入了RISE-T2V。

Method: RISE-T2V 包括一个称为重述适配器的模块，可以使扩散模型在生成视频时使用文本隐藏状态来预测下一个单词。通过重述适配器，视频生成模型可以自动将简单的文本提示转化为更丰富的表示，更好地匹配用户意图。此外，还利用预训练语言模型的强大功能，来实现更多样化的文本到视频任务。

Result: 实验表明，RISE-T2V 能够显著提高文本到视频任务的质量和用户满意程度。该框架适用于各种预训练语言模型和视频扩散模型架构，显示出了广泛的应用前景。

Conclusion: RISE-T2V 是一种创新的方法，能够提高文本到视频扩散模型的性能和适用性。这种方法通过将文本重述和语义理解合二为一，从而提高了生成视频的质量和与用户意图的匹配度。

Abstract: Most text-to-video(T2V) diffusion models depend on pre-trained text encoders
for semantic alignment, yet they often fail to maintain video quality when
provided with concise prompts rather than well-designed ones. The primary issue
lies in their limited textual semantics understanding. Moreover, these text
encoders cannot rephrase prompts online to better align with user intentions,
which limits both the scalability and usability of the models, To address these
challenges, we introduce RISE-T2V, which uniquely integrates the processes of
prompt rephrasing and semantic feature extraction into a single and seamless
step instead of two separate steps. RISE-T2V is universal and can be applied to
various pre-trained LLMs and video diffusion models(VDMs), significantly
enhancing their capabilities for T2V tasks. We propose an innovative module
called the Rephrasing Adapter, enabling diffusion models to utilize text hidden
states during the next token prediction of the LLM as a condition for video
generation. By employing a Rephrasing Adapter, the video generation model can
implicitly rephrase basic prompts into more comprehensive representations that
better match the user's intent. Furthermore, we leverage the powerful
capabilities of LLMs to enable video generation models to accomplish a broader
range of T2V tasks. Extensive experiments demonstrate that RISE-T2V is a
versatile framework applicable to different video diffusion model
architectures, significantly enhancing the ability of T2V models to generate
high-quality videos that align with user intent. Visual results are available
on the webpage at https://rise-t2v.github.io.

</details>


### [33] [Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion for 3D Object Detection](https://arxiv.org/abs/2511.04347)
*Sanjay Kumar,Tim Brophy,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising*

Main category: cs.CV

TL;DR: 本文研究了传感器遮挡对基于BEVFusion架构的3D物体检测准确度的影响，发现在雾、霾等条件下，摄像头遮挡会导致检测精度大幅下降，而激光雷达在严重遮挡时性能剧烈下降。研究表明，在现实世界中，需要开发出针对部分传感器故障或因恶劣环境因素导致的性能下降的鲁棒性评估方法和传感器融合技术，以维持检测准确性。


<details>
  <summary>Details</summary>
Motivation: 探索传感器遮挡对基于Bird's Eye View (BEV) 表示的多传感器融合架构3D物体检测精度的影响，以寻求提高在复杂现实环境中感知的鲁棒性。

Method: 通过在nuScenes数据集上评估BEVFusion架构，在摄像头和激光雷达输出中分别引入遮挡，并使用平均精度均值（mAP）和nuScenes 检测分数（NDS）来度量检测性能。

Result: 研究发现在中等遮挡下，基于摄像头的检测mAP从35.6%降至20.9%，而激光雷达在严重遮挡下的mAP减少到34.1%；在融合状态下，遮挡摄像头导致mAP下降4.1%，遮挡激光雷达则导致了26.8%的下降。

Conclusion: 结果说明未来需要研究针对遮挡的问题和改善传感器融合技术，维持部分传感器故障或环境因素导致的性能下降情况下的检测准确性。

Abstract: Accurate 3D object detection is essential for automated vehicles to navigate
safely in complex real-world environments. Bird's Eye View (BEV)
representations, which project multi-sensor data into a top-down spatial
format, have emerged as a powerful approach for robust perception. Although
BEV-based fusion architectures have demonstrated strong performance through
multimodal integration, the effects of sensor occlusions, caused by
environmental conditions such as fog, haze, or physical obstructions, on 3D
detection accuracy remain underexplored. In this work, we investigate the
impact of occlusions on both camera and Light Detection and Ranging (LiDAR)
outputs using the BEVFusion architecture, evaluated on the nuScenes dataset.
Detection performance is measured using mean Average Precision (mAP) and the
nuScenes Detection Score (NDS). Our results show that moderate camera
occlusions lead to a 41.3% drop in mAP (from 35.6% to 20.9%) when detection is
based only on the camera. On the other hand, LiDAR sharply drops in performance
only under heavy occlusion, with mAP falling by 47.3% (from 64.7% to 34.1%),
with a severe impact on long-range detection. In fused settings, the effect
depends on which sensor is occluded: occluding the camera leads to a minor 4.1%
drop (from 68.5% to 65.7%), while occluding LiDAR results in a larger 26.8%
drop (to 50.1%), revealing the model's stronger reliance on LiDAR for the task
of 3D object detection. Our results highlight the need for future research into
occlusion-aware evaluation methods and improved sensor fusion techniques that
can maintain detection accuracy in the presence of partial sensor failure or
degradation due to adverse environmental conditions.

</details>


### [34] [A MATLAB tutorial on deep feature extraction combined with chemometrics for analytical applications](https://arxiv.org/abs/2511.04349)
*Puneet Mishra,Martijntje Vollebregt,Yizhou Ma,Maria Font-i-Furnols*

Main category: cs.CV

TL;DR: 此教程旨在通过提供分步骤指南来应用深度学习方法从成像数据中提取空间信息并将其与其他数据源（如光谱信息）集成，解决了在分析化学中使用深度学习的难题。重点是使用现有的开源模型来提取成像数据中的深度特征，而非训练深度学习模型。包含MATLAB代码教程演示，展示处理来自常见于分析化学中的各种成像模态的成像数据。


<details>
  <summary>Details</summary>
Motivation: 在分析化学中，虽然可以使用各种成像技术获取材料的空间信息，但高效地提取和利用这些信息进行探索性或预测性分析仍然是一个挑战，尤其是在使用传统化学生物信息学方法时。随着深度学习和人工智能的最新进展，图像处理能力大大增强，使得提取传统图像处理技术难以捕捉的多尺度深层特征成为可能。然而，由于缺乏结构化、分步骤的实施指导，这些先进的方法在分析化学领域的应用受限。为了填补这一空白，设计了本教程来引领用户从成像数据中提取空间信息。

Method: 通过利用深度学习和人工智能的进步，本教程提供了一种解决方案，它使用现有的开源深度学习模型来提取成像数据中的多尺度深层特征。更重要的是，此教程引入MATLAB代码教程演示，学员可以将其应用于他们自己的数据集。

Result: 本教程为用户提供了一个逐步的指南，展示了如何使用现有的开源模型来提取成像数据中的多尺度深层特征，并将其与其他数据源结合。这极大地促进了分析化学领域应用深度学习的发展，使得该技术更易为研究人员所用。

Conclusion: 总之，该教程通过提供MATLAB代码和算法，使得使用深度学习的图像处理技术在分析化学中得以普及，并简化了多尺度特征信息的提取过程。这使得化学研究者能更好地利用成像数据进行复杂的数据分析和解释，也增加了化学数据分析的深度和洞察力。

Abstract: Background In analytical chemistry, spatial information about materials is
commonly captured through imaging techniques, such as traditional color cameras
or with advanced hyperspectral cameras and microscopes. However, efficiently
extracting and analyzing this spatial information for exploratory and
predictive purposes remains a challenge, especially when using traditional
chemometric methods. Recent advances in deep learning and artificial
intelligence have significantly enhanced image processing capabilities,
enabling the extraction of multiscale deep features that are otherwise
challenging to capture with conventional image processing techniques. Despite
the wide availability of open-source deep learning models, adoption in
analytical chemistry remains limited because of the absence of structured,
step-by-step guidance for implementing these models.
  Results This tutorial aims to bridge this gap by providing a step-by-step
guide for applying deep learning approaches to extract spatial information from
imaging data and integrating it with other data sources, such as spectral
information. Importantly, the focus of this work is not on training deep
learning models for image processing but on using existing open source models
to extract deep features from imaging data.
  Significance The tutorial provides MATLAB code tutorial demonstrations,
showcasing the processing of imaging data from various imaging modalities
commonly encountered in analytical chemistry. Readers must run the tutorial
steps on their own datasets using the codes presented in this tutorial.

</details>


### [35] [Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal VQA](https://arxiv.org/abs/2511.04384)
*Itbaan Safwan,Muhammad Annas Shaikh,Muhammad Haaris,Ramail Khan,Muhammad Atif Tahir*

Main category: cs.CV

TL;DR: 本文提出了一个针对MediaEval Medico 2025挑战的多任务框架，利用LoRA调优的Florence-2模型实现了同时进行视觉问答、解释生成和视觉接地。通过三个精心设计的数据集的集成，该系统能够在视觉定位和解释准确度上显著优于单一任务基础模型，证明了多任务学习在医学视觉问答应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高医学领域的视觉问答任务的性能，特别是在准确性与解释性之间取得平衡，作者提出了一个多任务框架，并应用LoRA技术调整了一个预训练模型Florence-2。具体来说，通过联合训练视觉问答、解释生成和视觉接地，使得模型能够更好地理解和处理医学图像中的信息。此外，基于三个数据集的不同特性，多任务框架得以进一步提高模型的学习能力和部署效果。

Method: 该框架采用了LoRA（Low-rank Adaptation）技术对预训练的Florence-2模型进行微调，通过整合三类数据集：1）Kvasir-VQA-x1用于问答学习；2）一个合成的丰富的解释数据集，提供结构化的医学推理；3）文本区域对，将视觉特征与分割掩码联系起来。采用多任务联合训练的方式，使得模型能够在单一框架下完成视觉问答、解释生成和视觉接地任务。

Result: 实验结果表明，该方法在答案准确率和视觉定位上都显著优于传统的单一任务基础模型。这验证了多任务学习框架的有效性，尤其是在医学视觉问答任务中。此外，该方法还可以生成准确且可解释的回答，这对于医疗领域中的应用来说是非常有价值的。

Conclusion: 提出了一种基于LoRA技术的多任务框架，用于改进医学视觉问答任务。通过联合训练，该框架显著提高了模型的准确性和解释能力，并且比单一任务模型表现更优。这种方法提供了一个有价值的工具，可以帮助医生和其他专业人员更有效地分析和理解复杂的医学图像信息。

Abstract: We present a multi-task framework for the MediaEval Medico 2025 challenge,
leveraging a LoRA-tuned Florence-2 model for simultaneous visual question
answering (VQA), explanation generation, and visual grounding. The proposed
system integrates three curated datasets: (1) Kvasir-VQA-x1 for question-answer
learning, (2) a synthetically enriched explanation dataset offering structured
medical reasoning, and (3) text-to-region pairs linking visual features with
segmentation masks. This multi-task setup enables the model to jointly learn
visual grounding, reasoning, and interpretation, producing responses that are
both accurate and interpretable. Extensive evaluation demonstrates that our
approach substantially improves over single-task baselines in both answer
accuracy and visual localization, highlighting the effectiveness of grounded
multi-task learning for medical VQA applications.

</details>


### [36] [BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary Refinement for Embedded Systems](https://arxiv.org/abs/2511.04388)
*Chang Liu,Juan Li,Sheng Zhang,Chang Liu,Jie Li,Xu Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为BoRe-Depth的新单目深度估计模型，参数量仅为8.7M，改进了嵌入式系统上的深度估计性能和边界清晰度，特别是在NVIDIA Jetson Orin上实现了50.7帧/秒的运行效率，并在多个具有挑战性的数据集上显著优于现有轻量级模型。论文进行了详细的消融研究，并开放了代码。


<details>
  <summary>Details</summary>
Motivation: 基于单目深度估计在无人驾驶系统中的关键作用，探讨了如何在嵌入式系统上提高深度估计性能和边界清晰度的问题，并提出了改进方案。

Method: 提出了BoRe-Depth模型，引入了增强特征自适应融合模块（EFAF）以自适应融合深度特征，提升了边界细节的表达；同时还集成了语义知识到编码器中，进一步增强了对象识别和边界感知能力。模型在NVIDIA Jetson Orin上以50.7FPS高效运行，展示了良好的性能。

Result: 该模型在嵌入式系统上实现了高精度的深度估计，边界质量显著提升，特别是在多个具有挑战性的数据集上，优于现有轻量级模型。经过详细的消融研究，进一步验证了模型的有效性。

Conclusion: 通过引入创新的EFAF模块及语义集成编码器的设计，BoRe-Depth成功地提高了单目深度估计在嵌入式系统上的性能和边界清晰度，展示了良好的应用前景。

Abstract: Depth estimation is one of the key technologies for realizing 3D perception
in unmanned systems. Monocular depth estimation has been widely researched
because of its low?cost advantage, but the existing methods face the challenges
of poor depth estimation performance and blurred object boundaries on embedded
systems. In this paper, we propose a novel monocular depth estimation model,
BoRe-Depth, which contains only 8.7M parameters. It can accurately estimate
depth maps on embedded systems and significantly improves boundary quality.
Firstly, we design an Enhanced Feature Adaptive Fusion Module (EFAF) which
adaptively fuses depth features to enhance boundary detail representation.
Secondly, we integrate semantic knowledge into the encoder to improve the
object recognition and boundary perception capabilities. Finally, BoRe-Depth is
deployed on NVIDIA Jetson Orin, and runs efficiently at 50.7 FPS. We
demonstrate that the proposed model significantly outperforms previous
lightweight models on multiple challenging datasets, and we provide detailed
ablation studies for the proposed methods. The code is available at
https://github.com/liangxiansheng093/BoRe-Depth.

</details>


### [37] [HideAndSeg: an AI-based tool with automated prompting for octopus segmentation in natural habitats](https://arxiv.org/abs/2511.04426)
*Alan de Aguiar,Michaella Pereira Andrade,Charles Morphy D. Santos,João Paulo Gois*

Main category: cs.CV

TL;DR: HideAndSeg是一款基于AI的工具，用于分割八爪鱼视频，解决了野外研究中的多个挑战。该工具通过整合SAM2和自定义训练的YOLOv11对象检测器，在最小的人工监督下实现自动化分割。此外，还提出了两个无监督指标来评估分割质量。实验表明，HideAndSeg在自然环境下的表现优于传统方法，减少了分割噪声，同时能有效处理完全遮挡的情况。


<details>
  <summary>Details</summary>
Motivation: 该论文主要受到野外研究中八爪鱼行为研究的挑战驱动，特别是由于八爪鱼的变色、变形和遮挡，以及水下照明和浑浊带来的复杂性，导致难以建立大规模标注的数据集。HideAndSeg的目的是提供一种实用的工具，减少对人工分析的需求，提高野外行为研究的效率。

Method: HideAndSeg使用用户提供的点坐标生成初始分割掩码，并以此训练YOLO模型。随后，通过向SAM2提供边界框提示，实现了完整自动化分割流程，减少了进一步的人工干预。研究过程中还创新性地引入了两个无监督指标，用来在没有基准数据的情况下评估分割质量。

Result: 实验结果表明，HideAndSeg相较于手动提示方法，降低了噪声并进一步提高了分割质量。尤其在自然环境中的完全遮挡场景下，HideAndSeg展示了比手动提示模型更好的重新识别和分割性能。

Conclusion: 该研究提供了一个自动化、高质量的八爪鱼视频分割解决方案，显著减少了野外研究中的工作量，并为更高效研究八爪鱼的行为特征提供了有力工具。

Abstract: Analyzing octopuses in their natural habitats is challenging due to their
camouflage capability, rapid changes in skin texture and color, non-rigid body
deformations, and frequent occlusions, all of which are compounded by variable
underwater lighting and turbidity. Addressing the lack of large-scale annotated
datasets, this paper introduces HideAndSeg, a novel, minimally supervised
AI-based tool for segmenting videos of octopuses. It establishes a quantitative
baseline for this task. HideAndSeg integrates SAM2 with a custom-trained
YOLOv11 object detector. First, the user provides point coordinates to generate
the initial segmentation masks with SAM2. These masks serve as training data
for the YOLO model. After that, our approach fully automates the pipeline by
providing a bounding box prompt to SAM2, eliminating the need for further
manual intervention. We introduce two unsupervised metrics - temporal
consistency $DICE_t$ and new component count $NC_t$ - to quantitatively
evaluate segmentation quality and guide mask refinement in the absence of
ground-truth data, i.e., real-world information that serves to train, validate,
and test AI models. Results show that HideAndSeg achieves satisfactory
performance, reducing segmentation noise compared to the manually prompted
approach. Our method can re-identify and segment the octopus even after periods
of complete occlusion in natural environments, a scenario in which the manually
prompted model fails. By reducing the need for manual analysis in real-world
scenarios, this work provides a practical tool that paves the way for more
efficient behavioral studies of wild cephalopods.

</details>


### [38] [Solving Convex Partition Visual Jigsaw Puzzles](https://arxiv.org/abs/2511.04450)
*Yaniv Ohayon,Ofir Itzhak Shahar,Ohad Ben-Shahar*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法来解决凸多边形拼图问题，并介绍了一种贪婪求解器以及公布了首个此类问题的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的自动解拼图的文献主要关注于解决方形拼图，这限制了其实际应用范围。本文旨在扩展计算解决的拼图类型，专注于一种被称为凸分割的多边形拼图。解决这种类型拼图不仅有实际应用价值，还能推广到更多种类的拼图解决方法。

Method: 本文提出了一个新颖的解题方法，利用了几何和图像的兼容性。设计并实现了一种贪婪求解器。

Result: 测试表明所提出的方法和贪婪求解器提供了很有希望的解题效果。同时，本文还有助于建立评估拼图求解方法的基准数据集。

Conclusion: 评价了贪婪求解器在解决凸分割拼图上的性能，并证实了该方法的有效性。另外，通过首次发布的基准数据集，可促进更多创新性的解决方法的发展。

Abstract: Jigsaw puzzle solving requires the rearrangement of unordered pieces into
their original pose in order to reconstruct a coherent whole, often an image,
and is known to be an intractable problem. While the possible impact of
automatic puzzle solvers can be disruptive in various application domains, most
of the literature has focused on developing solvers for square jigsaw puzzles,
severely limiting their practical use. In this work, we significantly expand
the types of puzzles handled computationally, focusing on what is known as
Convex Partitions, a major subset of polygonal puzzles whose pieces are convex.
We utilize both geometrical and pictorial compatibilities, introduce a greedy
solver, and report several performance measures next to the first benchmark
dataset of such puzzles.

</details>


### [39] [V-Thinker: Interactive Thinking with Images](https://arxiv.org/abs/2511.04460)
*Runqi Qiao,Qiuna Tan,Minghan Yang,Guanting Dong,Peiqing Yang,Shiqiang Lang,Enhui Wan,Xiaowan Wang,Yida Xu,Lan Yang,Chong Sun,Chen Li,Honggang Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种名为V-Thinker的工具，它通过强化学习使大型多模态模型能够交互式地进行视觉中心推理，从而克服了图像互动推理中的工具空间和工作流程设计的局限。V-Thinker 包括数据进化飞轮和视觉渐进训练课程两个关键组件，实验结果表明其在通用和交互推理场景中优于基于 LMM 的基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有进展受限于有限的视觉工具空间和特定任务的工作流程设计，为此，提出V-Thinker来促进大型多模态模型实现交互式、视觉中心性思考。

Method: V-Thinker利用了end-to-end强化学习，包括一个数据进化飞轮和一个视觉渐进而来的训练计划。

Result: 实验结果表明，相较于现有的基线方法，V-Thinker在通用和交互式推理任务中表现更优。

Conclusion: 该研究提供了一个支撑图像互动推理应用的新方法，为多模态模型在复杂的视觉任务中的性能提升提供了新的见解。

Abstract: Empowering Large Multimodal Models (LMMs) to deeply integrate image
interaction with long-horizon reasoning capabilities remains a long-standing
challenge in this field. Recent advances in vision-centric reasoning explore a
promising "Thinking with Images" paradigm for LMMs, marking a shift from
image-assisted reasoning to image-interactive thinking. While this milestone
enables models to focus on fine-grained image regions, progress remains
constrained by limited visual tool spaces and task-specific workflow designs.
To bridge this gap, we present V-Thinker, a general-purpose multimodal
reasoning assistant that enables interactive, vision-centric thinking through
end-to-end reinforcement learning. V-Thinker comprises two key components: (1)
a Data Evolution Flywheel that automatically synthesizes, evolves, and verifies
interactive reasoning datasets across three dimensions-diversity, quality, and
difficulty; and (2) a Visual Progressive Training Curriculum that first aligns
perception via point-level supervision, then integrates interactive reasoning
through a two-stage reinforcement learning framework. Furthermore, we introduce
VTBench, an expert-verified benchmark targeting vision-centric interactive
reasoning tasks. Extensive experiments demonstrate that V-Thinker consistently
outperforms strong LMM-based baselines in both general and interactive
reasoning scenarios, providing valuable insights for advancing
image-interactive reasoning applications.

</details>


### [40] [Landslide Hazard Mapping with Geospatial Foundation Models: Geographical Generalizability, Data Scarcity, and Band Adaptability](https://arxiv.org/abs/2511.04474)
*Wenwen Li,Sizhe Wang,Hyunho Lee,Chenyan Lu,Sujit Roy,Rahul Ramachandran,Chia-Yu Hsu*

Main category: cs.CV

TL;DR: 介绍了基于地理空间基础模型（GeoFMs）的三轴分析框架（传感器、标签、领域），通过实验展示了在精确和及时的滑坡测绘中的优越性。该模型在谱变、标签稀缺性和跨不同数据集和地理环境的泛化能力方面表现出色，但还存在计算成本高和训练数据不足的问题。研究结果支持了GeoFMs在滑坡风险降低和环境监测中的潜力应用。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习模型在不同的传感器、地区或在有限的训练数据条件下表现不佳。目的是提高滑坡测绘的准确性和及时性，通过构建一个三轴分析框架来解决这些问题。

Method: 使用Prithvi-EO-2.0等地理空间基础模型进行滑坡测绘，利用全球预训练、自我监督和可适应的微调方法。并通过与任务特定的CNN（U-Net，U-Net++），视觉变压器（Segformer，SwinV2-B）及其他地理空间基础模型（TerraMind，SatMAE）的实验对比，验证了该方法的有效性。

Result: 实验结果表明，该模型在谱变下保持准确性和跨多样数据集及地理环境下的泛化能力上，优于其他模型。并且在标签稀缺情况下仍能维持高精度。但计算成本高和可重用的AI训练数据不足仍是挑战。

Conclusion: 研究表明，地理空间基础模型不仅在滑坡测绘中展示了实际价值，还为滑坡风险减少提供了稳健且可扩展的方法，同时对滑坡研究的数据准备提出挑战。

Abstract: Landslides cause severe damage to lives, infrastructure, and the environment,
making accurate and timely mapping essential for disaster preparedness and
response. However, conventional deep learning models often struggle when
applied across different sensors, regions, or under conditions of limited
training data. To address these challenges, we present a three-axis analytical
framework of sensor, label, and domain for adapting geospatial foundation
models (GeoFMs), focusing on Prithvi-EO-2.0 for landslide mapping. Through a
series of experiments, we show that it consistently outperforms task-specific
CNNs (U-Net, U-Net++), vision transformers (Segformer, SwinV2-B), and other
GeoFMs (TerraMind, SatMAE). The model, built on global pretraining,
self-supervision, and adaptable fine-tuning, proved resilient to spectral
variation, maintained accuracy under label scarcity, and generalized more
reliably across diverse datasets and geographic settings. Alongside these
strengths, we also highlight remaining challenges such as computational cost
and the limited availability of reusable AI-ready training data for landslide
research. Overall, our study positions GeoFMs as a step toward more robust and
scalable approaches for landslide risk reduction and environmental monitoring.

</details>


### [41] [THEval. Evaluation Framework for Talking Head Video Generation](https://arxiv.org/abs/2511.04520)
*Nabyl Quignon,Baptiste Chopin,Yaohui Wang,Antitza Dantcheva*

Main category: cs.CV

TL;DR: 提出了一种新的评估体系，包含8个与视频质量、自然度和同步性相关的指标，来评估头部视频生成的算法。通过大量实验发现，虽然大多数算法在嘴唇同步方面表现出色，但在生成表情和无瑕疵细节方面仍有不足。计划公开发布代码、数据集和排行榜，以反映这一领域的发展。


<details>
  <summary>Details</summary>
Motivation: 现有的评估标准难以全面评估头部视频生成算法的多种方面，因此需要更为全面和高效的评估框架来衡量这些算法的表现。新的评估体系应当能够准确反映人类对于生成视频的偏好，并识别算法的长处与短处。

Method: 开发了一个新的评估框架，集合了8个具体的技术评估指标，包括但不限于质量、自然度、同步性等多个维度，并且着重考虑了评估的效度和与人类偏好的匹配度。为了测试该框架的有效性，作者在85,000个视频上进行了多次实验，这些视频由当前最先进的17种算法生成。测试集为一种新的真实数据集，以尽量减少训练数据偏见的影响。

Result: 研究发现，虽然大多数算法在嘴唇同步方面表现优异，但在生成视频的表情及无瑕疵细节方面仍面临挑战。

Conclusion: 新提出的评估框架是评估头部视频生成算法的一个重要工具，有助于识别先进算法的优点和不足，并促进算法的改进。该框架计划开放，以供研究社区进行讨论和改进。

Abstract: Video generation has achieved remarkable progress, with generated videos
increasingly resembling real ones. However, the rapid advance in generation has
outpaced the development of adequate evaluation metrics. Currently, the
assessment of talking head generation primarily relies on limited metrics,
evaluating general video quality, lip synchronization, and on conducting user
studies. Motivated by this, we propose a new evaluation framework comprising 8
metrics related to three dimensions (i) quality, (ii) naturalness, and (iii)
synchronization. In selecting the metrics, we place emphasis on efficiency, as
well as alignment with human preferences. Based on this considerations, we
streamline to analyze fine-grained dynamics of head, mouth, and eyebrows, as
well as face quality. Our extensive experiments on 85,000 videos generated by
17 state-of-the-art models suggest that while many algorithms excel in lip
synchronization, they face challenges with generating expressiveness and
artifact-free details. These videos were generated based on a novel real
dataset, that we have curated, in order to mitigate bias of training data. Our
proposed benchmark framework is aimed at evaluating the improvement of
generative methods. Original code, dataset and leaderboards will be publicly
released and regularly updated with new methods, in order to reflect progress
in the field.

</details>


### [42] [Learning from Single Timestamps: Complexity Estimation in Laparoscopic Cholecystectomy](https://arxiv.org/abs/2511.04525)
*Dimitrios Anastasiou,Santiago Barbarisi,Lucy Culshaw,Jayna Patel,Evangelos B. Mazomenos,Imanol Luengo,Danail Stoyanov*

Main category: cs.CV

TL;DR: 本文介绍了一种名为STC-Net的新框架，用于通过Parkland Grading Scale（PGS）进行腹腔镜胆囊切除术（LC）的复杂度估计。STC-Net针对全视频操作，通过硬位置和软定位目标的结合以及背景感知的分级监督，实现了时间上的定位和分级。在评估上，它在外围基线上的准确性和F1得分方面分别提高了10%和8%。这表明弱监督对于手术复杂度评估的有效性，为术后分析和手术培训提供了有前景的方法。


<details>
  <summary>Details</summary>
Motivation: 准确评估腹腔镜胆囊切除术（LC）期间手术的复杂性非常重要，特别是在严重的炎症情况下。Parkland Grading Scale（PGS）已经证明是一个有效的炎症严重程度分类框架，但是还没有将其在手术视频中自动化。因此，本研究开发了一个名为STC-Net的新模型，用于在完整视频中进行基于PGS的手术复杂度估计。

Method: 该研究开发了一种新的框架STC-Net，它通过时间定位和评分模块联合操作，直接作用于全视频而不是静态图像或手动裁剪的片段。特别的是，其结合了硬位置和软定位目标以及背景感知的评分监督，推出了一种新颖的损失格式化。

Result: 测试阶段，基于一个包含了1,859个LC视频的私人数据集，STC-Net在准确性和F1得分上优于外围基线模型，在这两种指标上分别提高了约10%和8%，这证明了弱监督的有效性。

Conclusion: STC-Net提供了一种从完整LC视频进行自动化PGS基于的手术复杂度评估的有效和可扩展的方法，这预示着它在未来术后分析和手术塔训中有巨大的应用潜力。

Abstract: Purpose: Accurate assessment of surgical complexity is essential in
Laparoscopic Cholecystectomy (LC), where severe inflammation is associated with
longer operative times and increased risk of postoperative complications. The
Parkland Grading Scale (PGS) provides a clinically validated framework for
stratifying inflammation severity; however, its automation in surgical videos
remains largely unexplored, particularly in realistic scenarios where complete
videos must be analyzed without prior manual curation. Methods: In this work,
we introduce STC-Net, a novel framework for SingleTimestamp-based Complexity
estimation in LC via the PGS, designed to operate under weak temporal
supervision. Unlike prior methods limited to static images or manually trimmed
clips, STC-Net operates directly on full videos. It jointly performs temporal
localization and grading through a localization, window proposal, and grading
module. We introduce a novel loss formulation combining hard and soft
localization objectives and background-aware grading supervision. Results:
Evaluated on a private dataset of 1,859 LC videos, STC-Net achieves an accuracy
of 62.11% and an F1-score of 61.42%, outperforming non-localized baselines by
over 10% in both metrics and highlighting the effectiveness of weak supervision
for surgical complexity assessment. Conclusion: STC-Net demonstrates a scalable
and effective approach for automated PGS-based surgical complexity estimation
from full LC videos, making it promising for post-operative analysis and
surgical training.

</details>


### [43] [UniSplat: Unified Spatio-Temporal Fusion via 3D Latent Scaffolds for Dynamic Driving Scene Reconstruction](https://arxiv.org/abs/2511.04595)
*Chen Shi,Shaoshuai Shi,Xiaoyang Lyu,Chunyang Liu,Kehua Sheng,Bo Zhang,Li Jiang*

Main category: cs.CV

TL;DR: UniSplat是一个用于自动驾驶的前馈3D重建框架，通过统一的时空融合学习稳健的动态场景重建。它构建了一个3D潜在框架，能够捕捉场景的几何和语义信息，并通过有效的融合机制实现连续一致的时空对齐和详细的重建。实验表明，UniSplat在新视图合成中表现优异，甚至在原摄像机覆盖范围之外的视点也能提供稳健且高质量的渲染效果。


<details>
  <summary>Details</summary>
Motivation: 当前的3D重建方法在稀疏、非重叠的相机视角和复杂场景动力学方面存在困难。本研究旨在通过统一的潜在时空融合来解决这些问题，实现稳健的动态场景重建。

Method: UniSplat通过构建一个三维潜在框架，结合预训练的模型捕捉场景的几何和语义上下文，通过直接在3D框架内的高效融合机制来整合空间视图和时间帧的信息。它采用双分支解码器来生成动态感知的高斯分布，并保持静止高斯分布的持久内存，以实现场景的持续完成。

Result: 实验显示，UniSplat在新视图合成中达到了最先进的性能，并且可以在超出原摄像机覆盖范围的视点提供稳健和高质量的渲染效果。

Conclusion: UniSplat是一个成功的解决方案，它通过统一的潜在模型和高效的融合机制提供稳健的动态场景重建，同时支持新视图合成和超出摄像机覆盖范围的高质量渲染。

Abstract: Feed-forward 3D reconstruction for autonomous driving has advanced rapidly,
yet existing methods struggle with the joint challenges of sparse,
non-overlapping camera views and complex scene dynamics. We present UniSplat, a
general feed-forward framework that learns robust dynamic scene reconstruction
through unified latent spatio-temporal fusion. UniSplat constructs a 3D latent
scaffold, a structured representation that captures geometric and semantic
scene context by leveraging pretrained foundation models. To effectively
integrate information across spatial views and temporal frames, we introduce an
efficient fusion mechanism that operates directly within the 3D scaffold,
enabling consistent spatio-temporal alignment. To ensure complete and detailed
reconstructions, we design a dual-branch decoder that generates dynamic-aware
Gaussians from the fused scaffold by combining point-anchored refinement with
voxel-based generation, and maintain a persistent memory of static Gaussians to
enable streaming scene completion beyond current camera coverage. Extensive
experiments on real-world datasets demonstrate that UniSplat achieves
state-of-the-art performance in novel view synthesis, while providing robust
and high-quality renderings even for viewpoints outside the original camera
coverage.

</details>


### [44] [PixCLIP: Achieving Fine-grained Visual Language Understanding via Any-granularity Pixel-Text Alignment Learning](https://arxiv.org/abs/2511.04601)
*Yicheng Xiao,Yu Chen,Haoxuan Ma,Jiale Hong,Caorui Li,Lingxiang Wu,Haiyun Guo,Jinqiao Wang*

Main category: cs.CV

TL;DR: PixCLIP框架通过结合视觉提示输入和处理长文本描述的能力来增强视觉和文本内容处理的粒度。实验表明，PixCLIP在像素级别的交互处理长文本方面表现出色，达到了最先进的性能水平。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要通过增加视觉信息处理的粒度来提高CLIP的细粒度图像文本对齐能力。像素级视觉提示可以指导模型关注图像内部的特定局部区域，然而CLIP的文本编码器受制于固有的标记长度限制，无法处理长文本序列中嵌入的细粒度文本信息。为了协同利用增强视觉和文本内容处理粒度的优势，提出了PixCLIP框架。

Method: 构建了一个自动化注释管道，可以生成图像的像素级别的本地化，长格式文本描述。利用此管道建立了一个包括近150万个样本的高质量数据集LongGRIT，然后用LMM替换CLIP的原始文本编码器，并提出了一种三支路的像素文本对齐学习框架，支持图像区域和相应文本描述在任意粒度上的细粒度对齐。

Result: 实验表明，PixCLIP在处理像素级别的交互以及长文本方面表现出色，达到了最先进的性能水平。

Conclusion: 本文提出了一个名为PixCLIP的框架，该框架通过结合视觉提示输入和处理长文本描述的能力来增强视觉和文本内容处理的粒度。通过构建自动化注释管道和使用LMM替换CLIP的文本编码器，PixCLIP可以实现细粒度的图像文本对齐。

Abstract: While the Contrastive Language-Image Pretraining(CLIP) model has achieved
remarkable success in a variety of downstream vison language understanding
tasks, enhancing its capability for fine-grained image-text alignment remains
an active research focus. To this end, most existing works adopt the strategy
of explicitly increasing the granularity of visual information processing,
e.g., incorporating visual prompts to guide the model focus on specific local
regions within the image. Meanwhile, researches on Multimodal Large Language
Models(MLLMs) have demonstrated that training with long and detailed textual
descriptions can effectively improve the model's fine-grained vision-language
alignment. However, the inherent token length limitation of CLIP's text encoder
fundamentally limits CLIP to process more granular textual information embedded
in long text sequences. To synergistically leverage the advantages of enhancing
both visual and textual content processing granularity, we propose PixCLIP, a
novel framework designed to concurrently accommodate visual prompt inputs and
process lengthy textual descriptions. Specifically, we first establish an
automated annotation pipeline capable of generating pixel-level localized,
long-form textual descriptions for images. Utilizing this pipeline, we
construct LongGRIT, a high-quality dataset comprising nearly 1.5 million
samples. Secondly, we replace CLIP's original text encoder with the LLM and
propose a three-branch pixel-text alignment learning framework, facilitating
fine-grained alignment between image regions and corresponding textual
descriptions at arbitrary granularity. Experiments demonstrate that PixCLIP
showcases breakthroughs in pixel-level interaction and handling long-form
texts, achieving state-of-the-art performance.

</details>


### [45] [Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality](https://arxiv.org/abs/2511.04615)
*Tushar Kataria,Shikha Dubey,Mary Bronner,Jolanta Jedrzkiewicz,Ben J. Brintz,Shireen Y. Elhabian,Beatrice S. Knudsen*

Main category: cs.CV

TL;DR: 该论文提出了一种基于像素级别的方法来评估虚拟组织化学（IHC）染色图像的质量，通过这种方法，可以更准确地评估各种虚拟IHC模型的表现。结果表明，传统的图像保真度指标与实际的染色准确性之间关系较差，说明新的质量评估方法的必要性。配对模型在染色准确性上表现更好，而整体幻灯片图像则揭示出更严重的性能下降问题，说明评估尺度的重要性。该研究为虚拟IHC模型提供了可重复的质量评估方法，加速其在病理学中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有的基于纹理和分布的图像质量评估方法无法衡量虚拟IHC染色的准确性，论文旨在开发一种能够直接量化准确性的自动化评估框架，并基于这种方法评估多个虚拟IHC模型的质量。

Method: 论文使用颜色解卷积方法生成实际IHC和虚拟IHC图像的像素级别标签，进而计算这些标签的一致性指标（如Dice系数、IoU、豪斯多夫距离）来度量染色准确性。由于这种方法不依赖手动标注，可以在多个模型间使用相同的标准进行比较。

Result: 研究中发现，传统的图像保真度指标（如FID、PSNR和SSIM）与实际染色准确性及病理学家的评估结果之间相关性较低。配对模型的染色准确性普遍高于非配对模型，同时在整体幻灯片级别上的评估更能揭示性能下降的问题。

Conclusion: 该研究贡献了一个可重复的评估框架，用于衡量虚拟IHC模型的质量。新的像素级别准确性度量方法和整体幻灯片级别的评估对于确保虚拟IHC模型在临床实践中的可靠性和准确性至关重要。

Abstract: Deep learning models can generate virtual immunohistochemistry (IHC) stains
from hematoxylin and eosin (H&E) images, offering a scalable and low-cost
alternative to laboratory IHC. However, reliable evaluation of image quality
remains a challenge as current texture- and distribution-based metrics quantify
image fidelity rather than the accuracy of IHC staining. Here, we introduce an
automated and accuracy grounded framework to determine image quality across
sixteen paired or unpaired image translation models. Using color deconvolution,
we generate masks of pixels stained brown (i.e., IHC-positive) as predicted by
each virtual IHC model. We use the segmented masks of real and virtual IHC to
compute stain accuracy metrics (Dice, IoU, Hausdorff distance) that directly
quantify correct pixel - level labeling without needing expert manual
annotations. Our results demonstrate that conventional image fidelity metrics,
including Frechet Inception Distance (FID), peak signal-to-noise ratio (PSNR),
and structural similarity (SSIM), correlate poorly with stain accuracy and
pathologist assessment. Paired models such as PyramidPix2Pix and AdaptiveNCE
achieve the highest stain accuracy, whereas unpaired diffusion- and GAN-based
models are less reliable in providing accurate IHC positive pixel labels.
Moreover, whole-slide images (WSI) reveal performance declines that are
invisible in patch-based evaluations, emphasizing the need for WSI-level
benchmarks. Together, this framework defines a reproducible approach for
assessing the quality of virtual IHC models, a critical step to accelerate
translation towards routine use by pathologists.

</details>


### [46] [NovisVQ: A Streaming Convolutional Neural Network for No-Reference Opinion-Unaware Frame Quality Assessment](https://arxiv.org/abs/2511.04628)
*Kylie Cancilla,Alexander Moore,Amar Saini,Carmen Carrano*

Main category: cs.CV

TL;DR: 本文提出了一种基于流处理的视频质量评估模型，该模型不需要参考视频且无需人工意见标签的参与，通过合成的DAVIS数据集降级训练，能够从降级视频中直接预测全参考指标，证明了时间建模在视频质量评估中的价值和时间感知的无意见方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频质量评估方法存在局限性，全参考方法需要清洁的参考视频，而大部分无参考方法依赖于昂贵的人工标注标签，并且许多无参考方法忽略时间上下文信息。因此，开发一种无需参考视频、无需人工意见标签，并能捕捉时间上下文信息的模型是必要的。

Method: 本文设计了一种基于流处理、时间感知、无意见的视频质量评估模型，该模型通过对DAVIS数据集的降级合成进行训练，能够直接预测全参考指标，无需参考视频，在infer过程中实现零偏见评估。

Result: 实验结果表明，该模型在不同的降级情况下能够泛化，并且与广泛使用的带有意见标签的全参考基准BRISQUE相比，我们的模型与全参考指标的关联性更高，证明了时间建模对视频质量评估的重要性及时间感知无意见方法的有效性。

Conclusion: 本文提出了一个基于流处理的视频质量评估框架，通过去除对干净参考视频和人工意见标签的依赖，模型不仅提高了性能，也提高了视频质量评估的可扩展性。

Abstract: Video quality assessment (VQA) is vital for computer vision tasks, but
existing approaches face major limitations: full-reference (FR) metrics require
clean reference videos, and most no-reference (NR) models depend on training on
costly human opinion labels. Moreover, most opinion-unaware NR methods are
image-based, ignoring temporal context critical for video object detection. In
this work, we present a scalable, streaming-based VQA model that is both
no-reference and opinion-unaware. Our model leverages synthetic degradations of
the DAVIS dataset, training a temporal-aware convolutional architecture to
predict FR metrics (LPIPS , PSNR, SSIM) directly from degraded video, without
references at inference. We show that our streaming approach outperforms our
own image-based baseline by generalizing across diverse degradations,
underscoring the value of temporal modeling for scalable VQA in real-world
vision systems. Additionally, we demonstrate that our model achieves higher
correlation with full-reference metrics compared to BRISQUE, a widely-used
opinion-aware image quality assessment baseline, validating the effectiveness
of our temporal, opinion-unaware approach.

</details>


### [47] [Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts](https://arxiv.org/abs/2511.04655)
*Ellis Brown,Jihan Yang,Shusheng Yang,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: 本文提出了一种诊断和去偏的方法来评估模态大语言模型（MLLMs）在多模态基准测试中的表现，发现模型可以通过利用语言偏见和表面模式而不需要强视觉理解力就通过许多基准测试。通过使用“训练在测试集上”的方法来直接诊断测试集，可以识别和缓解这些非视觉偏见。该方法可以有效降低基准测试中非视觉问题的可解性，提高模型的视觉性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态基准测试可能过于容易被基于语言偏见和表面模式的模型利用，而不是要求模型具备强视觉理解力。因此，迫切需要一种方法来评估和去除这些非视觉偏见，以便更有效地测试MLLMs的视觉理解能力。

Method: 该研究提出了一个两步法，包括测试集压力测试（TsT）和迭代偏见修剪（IBP）。TsT通过在测试集上微调语言模型，以揭示模型利用的语言偏见并将每个样本分配一个偏见分数。IBP通过去除高偏见样本来去偏。该框架在四个基准测试上运行，以验证其效果。

Result: 使用该框架处理四个基准测试，发现了普遍存在的非视觉偏见。在案例研究中，处理过的VSI-Bench（VSI-Bench-Debiased）展示了降低的非视觉问题可解性，以及与原基准相比更广泛的视觉盲性能差距。证明了该方法的有效性。

Conclusion: 此论文引入了一套诊断和去偏方法，以提升多模态基准测试的有效性，帮助准确评估MLLM的视觉理解能力。该方法的使用有助于改进未来多模态基准的设计，以真正测试模态大语言模型的视觉理解力。

Abstract: Robust benchmarks are crucial for evaluating Multimodal Large Language Models
(MLLMs). Yet we find that models can ace many multimodal benchmarks without
strong visual understanding, instead exploiting biases, linguistic priors, and
superficial patterns. This is especially problematic for vision-centric
benchmarks that are meant to require visual inputs. We adopt a diagnostic
principle for benchmark design: if a benchmark can be gamed, it will be.
Designers should therefore try to ``game'' their own benchmarks first, using
diagnostic and debiasing procedures to systematically identify and mitigate
non-visual biases. Effective diagnosis requires directly ``training on the test
set'' -- probing the released test set for its intrinsic, exploitable patterns.
  We operationalize this standard with two components. First, we diagnose
benchmark susceptibility using a ``Test-set Stress-Test'' (TsT) methodology.
Our primary diagnostic tool involves fine-tuning a powerful Large Language
Model via $k$-fold cross-validation on exclusively the non-visual, textual
inputs of the test set to reveal shortcut performance and assign each sample a
bias score $s(x)$. We complement this with a lightweight Random Forest-based
diagnostic operating on hand-crafted features for fast, interpretable auditing.
Second, we debias benchmarks by filtering high-bias samples using an
``Iterative Bias Pruning'' (IBP) procedure. Applying this framework to four
benchmarks -- VSI-Bench, CV-Bench, MMMU, and VideoMME -- we uncover pervasive
non-visual biases. As a case study, we apply our full framework to create
VSI-Bench-Debiased, demonstrating reduced non-visual solvability and a wider
vision-blind performance gap than the original.

</details>


### [48] [SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding](https://arxiv.org/abs/2511.04668)
*Ellis Brown,Arijit Ray,Ranjay Krishna,Ross Girshick,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: 本文提出了一种新的数据生成框架SIMS-V，利用3D仿真器的特有信息来生成包含丰富空间信息的视频训练数据，用于多模态语言模型。研究发现，使用三种类型的问题（度量测量、视角依赖推理和时间追踪）可以有效地开发可迁移的空间智能，使得训练更加高效，模型在真实世界空间推理基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前多模态语言模型在空间推理方面的表现不足，同时获取包含精确空间注释的多样视频数据面临瓶颈，本文旨在解决这一问题，提出了新的数据生成框架SIMS-V。

Method: 通过使用3D仿真器的特权信息来生成空间丰富的视频训练数据，并通过系统消融实验来识别哪些模拟数据属性能驱动有效的跨域迁移学习。

Result: 证明了使用少数类型的问题可以有效地开发可迁移的空间智能，并实现了高效的训练，模型在真实世界空间推理基准测试中表现出色。

Conclusion: 实验结果表明，该方法具有强大的泛化能力，不仅保持了对通用视频理解的性能，还在嵌入式和真实世界空间任务上表现出显著提高。

Abstract: Despite impressive high-level video comprehension, multimodal language models
struggle with spatial reasoning across time and space. While current spatial
training approaches rely on real-world video data, obtaining diverse footage
with precise spatial annotations remains a bottleneck. To alleviate this
bottleneck, we present SIMS-V -- a systematic data-generation framework that
leverages the privileged information of 3D simulators to create spatially-rich
video training data for multimodal language models. Using this framework, we
investigate which properties of simulated data drive effective real-world
transfer through systematic ablations of question types, mixes, and scales. We
identify a minimal set of three question categories (metric measurement,
perspective-dependent reasoning, and temporal tracking) that prove most
effective for developing transferable spatial intelligence, outperforming
comprehensive coverage despite using fewer question types. These insights
enable highly efficient training: our 7B-parameter video LLM fine-tuned on just
25K simulated examples outperforms the larger 72B baseline and achieves
competitive performance with proprietary models on rigorous real-world spatial
reasoning benchmarks. Our approach demonstrates robust generalization,
maintaining performance on general video understanding while showing
substantial improvements on embodied and real-world spatial tasks.

</details>


### [49] [Cambrian-S: Towards Spatial Supersensing in Video](https://arxiv.org/abs/2511.04670)
*Shusheng Yang,Jihan Yang,Pinzhi Huang,Ellis Brown,Zihao Yang,Yue Yu,Shengbang Tong,Zihan Zheng,Yifan Xu,Muhan Wang,Daohan Lu,Rob Fergus,Yann LeCun,Li Fei-Fei,Saining Xie*

Main category: cs.CV

TL;DR: 论文提出了一个更广泛的认识方式——超感知，来发展真正的跨模式智能，并提出了评估和推动超感知发展的新基准和训练方法。这些方法在某些任务上表现出色，但仍然存在局限，作者提出预测性感知作为未来研究的方向。


<details>
  <summary>Details</summary>
Motivation: 现有系统在处理跨模式信息时主要采用反应式的，任务驱动的方法，缺乏对长时序背景的理解，论文希望推动研究者们的思考，从传统的方法中脱离出来，转向一种更广阔的思考模式——超感知，该模式更能模拟人类的感知过程。

Method: 作者提出了一个新的评估基准VSI-SUPER来评估超感知的进步，此基准由两部分组成：VSR和VSC。通过对大量数据的训练，作者试图检测其方法的有效性。另外，作者提出了一种新的方法——预测性感知，以预测下一环节的潜在帧作为线索，来驱动记忆和事件分割，从而更好地组织和筛选信息。

Result: 在VSI-SUPER评估上，所提出的方法取得了与现有基线相比显著的提升，特别是在需要较多预测的任务中。这表明，具有预测性感知能力的模型在处理时空信息时具有明显的优势。但是，结果显示单纯的数据规模还不足以支持超感知，还需要更进一步的研究和改进。

Conclusion: 虽然发现了规模上的提升并不足够实现超感知这一结果，论文仍然展示了一种新的方向——预测性感知，该方向可以为未来真正具有智能性的机器提供可能的框架。

Abstract: We argue that progress in true multimodal intelligence calls for a shift from
reactive, task-driven systems and brute-force long context towards a broader
paradigm of supersensing. We frame spatial supersensing as four stages beyond
linguistic-only understanding: semantic perception (naming what is seen),
streaming event cognition (maintaining memory across continuous experiences),
implicit 3D spatial cognition (inferring the world behind pixels), and
predictive world modeling (creating internal models that filter and organize
information). Current benchmarks largely test only the early stages, offering
narrow coverage of spatial cognition and rarely challenging models in ways that
require true world modeling. To drive progress in spatial supersensing, we
present VSI-SUPER, a two-part benchmark: VSR (long-horizon visual spatial
recall) and VSC (continual visual spatial counting). These tasks require
arbitrarily long video inputs yet are resistant to brute-force context
expansion. We then test data scaling limits by curating VSI-590K and training
Cambrian-S, achieving +30% absolute improvement on VSI-Bench without
sacrificing general capabilities. Yet performance on VSI-SUPER remains limited,
indicating that scale alone is insufficient for spatial supersensing. We
propose predictive sensing as a path forward, presenting a proof-of-concept in
which a self-supervised next-latent-frame predictor leverages surprise
(prediction error) to drive memory and event segmentation. On VSI-SUPER, this
approach substantially outperforms leading proprietary baselines, showing that
spatial supersensing requires models that not only see but also anticipate,
select, and organize experience.

</details>


### [50] [InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation](https://arxiv.org/abs/2511.04675)
*Jinlai Liu,Jian Han,Bin Yan,Hui Wu,Fengda Zhu,Xing Wang,Yi Jiang,Bingyue Peng,Zehuan Yuan*

Main category: cs.CV

TL;DR: InfinityStar是一个用于高分辨率图像和动态视频合成的统一时空自回归框架。它在单个架构中捕捉空间和时间依赖性，支持多种生成任务，并且在VBench上得分较高，生成视频速度快且质量高。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决传统自回归模型在处理图像和视频生成中空间和时间依赖性分离的问题，提出一个统一的架构来同时捕捉这些依赖性，从而提高生成质量与速度。

Method: InfinityStar采用纯离散的方法，将时空自回归框架应用于图像和视频生成，支持多种任务如文本到图像、文本到视频、图像到视频及长时交互视频生成。

Result: 实验结果显示，InfinityStar在VBench评分83.74，超过所有自回归模型，甚至超越某些扩散模型，如HunyuanVideo。此外，它生成10秒720p视频的速度大约是领先扩散方法的10倍。

Conclusion: InfinityStar是首个能生成工业级720p视频的纯离散自回归视频生成器。这些成就将会促进高效、高质量视频生成的研究。

Abstract: We introduce InfinityStar, a unified spacetime autoregressive framework for
high-resolution image and dynamic video synthesis. Building on the recent
success of autoregressive modeling in both vision and language, our purely
discrete approach jointly captures spatial and temporal dependencies within a
single architecture. This unified design naturally supports a variety of
generation tasks such as text-to-image, text-to-video, image-to-video, and long
interactive video synthesis via straightforward temporal autoregression.
Extensive experiments demonstrate that InfinityStar scores 83.74 on VBench,
outperforming all autoregressive models by large margins, even surpassing some
diffusion competitors like HunyuanVideo. Without extra optimizations, our model
generates a 5s, 720p video approximately 10x faster than leading
diffusion-based methods. To our knowledge, InfinityStar is the first discrete
autoregressive video generator capable of producing industrial level 720p
videos. We release all code and models to foster further research in efficient,
high-quality video generation.

</details>


### [51] [Tracking and Understanding Object Transformations](https://arxiv.org/abs/2511.04678)
*Yihong Sun,Xinyu Yang,Jennifer J. Sun,Bharath Hariharan*

Main category: cs.CV

TL;DR: 提出了Track Any State任务，即在对象状态变化过程中对其进行跟踪，并检测和描述状态变化。为此引进了TubeletGraph系统，这是一种零样本系统，能够恢复变换后的缺失对象并在时间上生成状态图。TubeletGraph具有最先进的变换跟踪性能，并且在复杂对象变换的理解方面表现出卓越的能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在对象经历状态变化（如切割或孵化）时，往往会丢失目标对象的跟踪，因为对象的外观会发生显著变化。这种情况下，对目标对象进行跟踪就显得异常困难，但也是实现更深入理解现实世界对象和动态的关键。为此，我们的目标是开发一种跟踪系统，它不仅能够跟踪对象，还能检测并描述其状态变化，进而更好地理解状态变化的过程及其背后的原因。

Method: 我们的方法名为TubeletGraph，这是一种零样本系统，它首次识别出可能是被遗漏的轨迹，并通过语义和位置先验确定是否应该把这些轨迹整合到跟踪中。其次，它更进一步推理关于新补全的轨迹，生成每个观察到的状态变化的图。这样，我们就可以得到一个对象状态随时间演化的模型。

Result: 我们的方法TubeletGraph在跟踪变换方面达到了最先进的水平，同时显示了更深层次的对象变换理解能力以及在时间定位和语义推理方面的前景，特别是在处理复杂对象变换时。

Conclusion: 我们提出的TubeletGraph系统能够有效地跟踪对象状态变化，并生成描述对象状态如何随时间变化的图。这也为未来开发更复杂的对象跟踪和理解系统打下了基础。

Abstract: Real-world objects frequently undergo state transformations. From an apple
being cut into pieces to a butterfly emerging from its cocoon, tracking through
these changes is important for understanding real-world objects and dynamics.
However, existing methods often lose track of the target object after
transformation, due to significant changes in object appearance. To address
this limitation, we introduce the task of Track Any State: tracking objects
through transformations while detecting and describing state changes,
accompanied by a new benchmark dataset, VOST-TAS. To tackle this problem, we
present TubeletGraph, a zero-shot system that recovers missing objects after
transformation and maps out how object states are evolving over time.
TubeletGraph first identifies potentially overlooked tracks, and determines
whether they should be integrated based on semantic and proximity priors. Then,
it reasons about the added tracks and generates a state graph describing each
observed transformation. TubeletGraph achieves state-of-the-art tracking
performance under transformations, while demonstrating deeper understanding of
object transformations and promising capabilities in temporal grounding and
semantic reasoning for complex object transformations. Code, additional
results, and the benchmark dataset are available at
https://tubelet-graph.github.io.

</details>


### [52] [Carousel: A High-Resolution Dataset for Multi-Target Automatic Image Cropping](https://arxiv.org/abs/2511.04680)
*Rafe Loya,Andrew Hamara,Benjamin Estell,Benjamin Kilpatrick,Andrew C. Freeman*

Main category: cs.CV

TL;DR: 本文提出了通过图像分区算法作为预处理步骤，对几种单次裁剪模型进行评估，以生成多个具有美学吸引力的裁剪图像，特别是在现代社会媒体应用中这一问题更加凸显。相关数据集包含277张图片及其人工标签，可在https://github.com/RafeLoya/carousel访问。


<details>
  <summary>Details</summary>
Motivation: 在现代社会媒体应用中，单一的图像裁剪方法往往无法满足多样化的需求，本文希望通过生成多个具有美学吸引力的裁剪图像，来提高用户在不同场景下的体验。

Method: 本文引入了一个包含277张图片及其人工标签的数据集，并通过图像分区算法作为预处理步骤，评估了几个现有的单次裁剪模型。

Result: 研究发现，通过引入图像分区算法作为预处理步骤，能够显著提高现有单次裁剪模型在生成多样化的美学裁剪图像时的效果。

Conclusion: 本文证明了在现代社会媒体应用中，通过改进的裁剪技术可以生成更多具有美学吸引力的裁剪图像，从而提升用户体验。

Abstract: Automatic image cropping is a method for maximizing the human-perceived
quality of cropped regions in photographs. Although several works have proposed
techniques for producing singular crops, little work has addressed the problem
of producing multiple, distinct crops with aesthetic appeal. In this paper, we
motivate the problem with a discussion on modern social media applications,
introduce a dataset of 277 relevant images and human labels, and evaluate the
efficacy of several single-crop models with an image partitioning algorithm as
a pre-processing step. The dataset is available at
https://github.com/RafeLoya/carousel.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [53] [Environment Division Multiple Access (EDMA): A Feasibility Study via Pinching Antennas](https://arxiv.org/abs/2511.03820)
*Zhiguo Ding,Robert Schober,H. V. Poor*

Main category: cs.IT

TL;DR: 该论文提出了一种基于无线传播环境动态特性的新型多址接入技术——环境划分多址接入（EDMA），利用夹具天线在不增加复杂信号处理的情况下改善信号强度并抑制多址接入干扰。通过理论分析和算法开发，证明了EDMA在支持多用户通信方面的潜力，并通过模拟验证了其性能优于传统多址接入方法。


<details>
  <summary>Details</summary>
Motivation: 无线传播环境具有动态特性，可以被利用来改进多用户通信中的信号强度问题。传统的多址接入技术需要复杂的信号处理技术来解决这些问题，而这种新型技术希望能够利用无线环境本身的特点来解决问题，减少对复杂信号处理的需求。特别是，提出了夹具天线辅助EDMA技术，通过智能地重新配置多用户的传播环境来改善接收器处的信号强度并抑制多址接入干扰。

Method: 通过放置夹具天线在特定位置，故意阻挡干扰链路，利用夹具天线调整视距（LoS）链路的能力来创造有利的传播环境。此外，还研究了夹具天线位置优化问题。针对上行和下行传输分别开发了两个低复杂度的算法。

Result: 理论分析表明，与传统多址接入相比，所提出的EDMA具有显著的潜力来支持多用户通信。模拟结果显示所提出的方法优于基准方法，通过低复杂度算法实现了与穷尽搜索对比后的性能优势。

Conclusion: 通过利用无线传播环境动态特性的夹具天线辅助EDMA技术可以改进信号强度并减少多址接入干扰，从而支持多用户通信。在理论分析和模拟验证的基础上，证明了这种新方法在改善多用户通信方面的巨大潜力。

Abstract: This paper exploits the dynamic features of wireless propagation environments
as the basis for a new multiple access technique, termed environment division
multiple access (EDMA). In particular, with the proposed
pinching-antenna-assisted EDMA, the multi-user propagation environment is
intelligently reconfigured to improve signal strength at intended receivers and
simultaneously suppress multiple-access interference, without requiring complex
signal processing, e.g., precoding, beamforming, or multi-user detection. The
key to creating a favorable propagation environment is to utilize the
capability of pinching antennas to reconfigure line-of-sight (LoS) links, e.g.,
pinching antennas are placed at specific locations, such that interference
links are blocked on purpose. Based on a straightforward choice of
pinching-antenna locations, the ergodic sum-rate gain of EDMA over conventional
multiple access and the probability that EDMA achieves a larger instantaneous
sum rate than the considered benchmarking scheme are derived in closed form.
The obtained analytical results demonstrate the significant potential of EDMA
for supporting multi-user communications. Furthermore, pinching antenna
location optimization is also investigated, since the locations of pinching
antennas are critical for reconfiguring LoS links and large-scale path losses.
Two low-complexity algorithms are developed for uplink and downlink
transmission, respectively, and simulation results are provided to show their
optimality in comparison to exhaustive searches.

</details>


### [54] [Which Similarity-Sensitive Entropy?](https://arxiv.org/abs/2511.03849)
*Phuc Nguyen,Josiah Couch,Rahul Bansal,Alexandra Morgan,Chris Tam,Miao Li,Rima Arnaout,Ramy Arnaout*

Main category: cs.IT

TL;DR: 本文通过概念、分析和实验的方法比较了Leinster-Cobbold-Reeve (LCR)和Vendi Score (VS)，发现在大多数情况下LCR更有利于捕捉系统之间的相似性信息，而VS只在特定情况下或者系统具有量子性质时更优。


<details>
  <summary>Details</summary>
Motivation: 动机在于比较两种不同的相似性敏感熵测量方法（LCR和Vendi Score），确定哪种方法在不同情况下可能更适合使用。

Method: 研究人员使用了53个机器学习数据集，通过数学推导和实验验证了两种方法在不同参数取值下的特性。他们引入了“半距离”的概念来探讨相似性尺度的影响，并且进行了严格的数学证明来比较两者的关系。

Result: 实验结果显示LCR和VS在一些情况下可以产生截然不同的结果，并且二者可以捕捉关于系统的互补信息。但是在某些特定条件下，VS为LCR提供了一个上界。

Conclusion: 结论指出，在捕捉系统之间丰富的相似性信息时，LCR方法更常被推荐使用；然而，在某些特定条件下，比如系统具有量子性质或者元素可以被解释为更多基本元素的线性组合时，VS方法可能更具优势。

Abstract: A canonical step in quantifying a system is to measure its entropy. Shannon
entropy and other traditional entropy measures capture only the information
encoded in the frequencies of a system's elements. Recently, Leinster, Cobbold,
and Reeve (LCR) introduced a method that also captures the rich information
encoded in the similarities and differences among elements, yielding
similarity-sensitive entropy. More recently, the Vendi score (VS) was
introduced as an alternative, raising the question of how LCR and VS compare,
and which is preferable. Here we address these questions conceptually,
analytically, and experimentally, using 53 machine-learning datasets. We show
that LCR and VS can differ by orders of magnitude and can capture complementary
information about a system, except in limiting cases. We demonstrate that both
LCR and VS depend on how similarities are scaled and introduce the concept of
``half distance'' to parameterize this dependence. We prove that VS provides an
upper bound on LCR for several values of the R\'enyi-Hill order parameter and
conjecture that this bound holds for all values. We conclude that VS is
preferable only when interpreting elements as linear combinations of a more
fundamental set of ``ur-elements'' or when the system or dataset possesses a
quantum-mechanical character. In the broader circumstance where one seeks
simply to capture the rich information encoded by similarity, LCR is favored;
nevertheless, for certain half-distances the two methods can complement each
other.

</details>


### [55] [Efficient and rate-optimal list-decoding in the presence of minimal feedback: Weldon and Slepian-Wolf in sheep's clothing](https://arxiv.org/abs/2511.04088)
*Pranav Joshi,Daniel McMorrow,Yihan Zhang,Amitalok J. Budkuley,Sidharth Jaggi*

Main category: cs.IT

TL;DR: 在存在敌手以固定比率任意篡改信道情况下的信息传输问题，该论文提出了一种有效的反馈系统，使得传输率接近最优信息理论值，且接收者能够确定发送者消息的可能集合较小。对于任意基$q\geq 2$，在接收者可向发送者提供少量反馈的情况下，该系统实现了距离最优信息理论传输率$\varepsilon$以内的效果，具有较低的传输和存储复杂度，同时保证了极低的错误率。


<details>
  <summary>Details</summary>
Motivation: 在存在敌手的情况下，如何实现接近最优的信息传输并且保证接收者能够准确识别出发送者的少量潜在消息集是值得研究的问题。现有的方案只对较大的$q$有效，对于所有$q\geq 2$的通用方案尚待开发。问题的核心是在保证传输效率和信息准确性的基础上引入最低限度的反馈机制，以解决低传输率和存储复杂度优化的问题。该论文的动机就是为任意$q$提供一种能在敌手以固定比率篡改信道的情况下实现高效传输的方法。

Method: 改进了现有的编码/解码过程，确定了一种反馈机制（反馈率为$\mathcal{O}(1/\log n)$），能大大减少编码和解码的计算复杂度，并且在一定程度上减少存储空间的需求。并引入一个小的误差参数$\varepsilon$，使得传输率接近最优信息理论值$1-H_q(\varrho)-\varepsilon$，其中$q$-ary熵函数$H_q(\varrho)$是衡量传输效率的一个标准。此外，还提出了列表大小及存储复杂度的具体值，以详细说明其传输效率和复杂度。

Result: 论文介绍的一种反馈机制在实现传递率接近最优值的同时，还保证了较低的传输和存储复杂度，这里的误差可以控制得相对较小，使传输的容错性增强。具体来说，传输率与最优值之差仅为$\varepsilon$，而误码率降低到$\mathcal{O}(n^{-\eta})$，反馈容量也极大优化了。除此之外，传输/存储复杂度也得到了相应的优化，使得该方案在实际操作上具有足够的可执行性。

Conclusion: 这项工作提供了一种创新的编码/解码方案，该方案通过引入反馈机制在敌手以固定比率篡改信道的情况下实现了接近最优的信息传输率。这种方案对于任意的基$q$都能够实现，是一种通用且易于实现的方法。尽管包含一些复杂的理论计算，但对于实际通信的应用具有极大的参考价值。

Abstract: Given a channel with length-$n$ inputs and outputs over the alphabet
$\{0,1,\ldots,q-1\}$, and of which a fraction $\varrho \in (0,1-1/q)$ of
symbols can be arbitrarily corrupted by an adversary, a fundamental problem is
that of communicating at rates close to the information-theoretically optimal
values, while ensuring the receiver can infer that the transmitter's message is
from a ``small" set. While the existence of such codes is known, and
constructions with computationally tractable encoding/decoding procedures are
known for large $q$, we provide the first schemes that attain this performance
for any $q \geq 2$, as long as low-rate feedback (asymptotically negligible
relative to the number of transmissions) from the receiver to the transmitter
is available. For any sufficiently small $\varepsilon > 0$ and $\varrho \in
(1-1/q-\Theta(\sqrt{\varepsilon})$ our minimal feedback scheme has the
following parameters: Rate $1-H_q(\varrho) - \varepsilon$ (i.e.,
$\varepsilon$-close to information-theoretically optimal -- here $H_q(\varrho)$
is the $q$-ary entropy function), list-size
$\exp(\mathcal{O}(\varepsilon^{-3/2}\log^2(1/\varepsilon))$, computational
complexity of encoding/decoding
$n^{\mathcal{O}(\varepsilon^{-1}\log(1/\varepsilon))}$, storage complexity
$\mathcal{O}(n^{\eta+1}\log n)$ for a code design parameter $\eta>1$ that
trades off storage complexity with the probability of error. The error
probability is $\mathcal{O}(n^{-\eta})$, and the (vanishing) feedback rate is
$\mathcal{O}(1/ \log n)$.

</details>


### [56] [List Decoding of Folded Reed-Solomon Codes Over Galois Ring](https://arxiv.org/abs/2511.04135)
*Chen Yuan,Ruiqi Zhu*

Main category: cs.IT

TL;DR: 本文扩展了Guruswami和Sudan的列表解码程序以适应Galois环上的Reed-Solomon码，证明了这些代码可以列表解码到半径$1-	ext{sqrt}(r)$。进一步研究了折叠的Reed-Solomon码的列表解码，表明可以达到Singleton界。同时通过将最近的工作应用于Galois环，将列表大小提高到$O(rac{1}{	ext{eps}^2})$。这项工作推进了零知识证明系统的发展。


<details>
  <summary>Details</summary>
Motivation: 当前的研究重点在于Galois环上的代码的研究，特别是列表解码能力的提高，这对零知识证明系统的发展十分重要。现有RS代码在Galois环上的解码能力尚不清晰，限制了环基算术电路的零知识证明系统的发展。因此，本研究是为了扩展Galois环上的RS码的列表解码能力，并推进相关内容的研究。

Method: 扩展了Guruswami和Sudan的列表解码方案到Galois环上的RS码，然后研究折叠的RS码的列表解码。

Result: 证明了Galois环上RS码可以被列表解码到半径$1-	ext{sqrt}(r)$，而且折叠的RS码的解码半径可达Singleton限。给出的列表大小为$O(rac{1}{	ext{eps}^2})$，这个改进是基于最近的工作在Galois环上的扩展。

Conclusion: 本文扩展了Galois环上RS码的列表解码过程，并提高了折叠RS码的解码性能。成果推进了零知识证明系统的发展。

Abstract: List decoding of codes can be seen as the generalization of unique decoding
of codes While list decoding over finite fields has been extensively studied,
extending these results to more general algebraic structures such as Galois
rings remains an important challenge. Due to recent progress in zero knowledge
systems, there is a growing demand to investigate the proximity gap of codes
over Galois rings in Yizhou Yao and coauthors(2025), Alexander Golovne and
coauthors(2023), Yuanju Wei and coauthors(2025). The proximity gap is closely
related to the decoding capability of codes. It was shown in Eli Ben-Sasson and
coauthors(2020) that the proximity gap for RS codes over finite field can be
improved to $1-\sqrt{r}$ if one consider list decoding instead of unique
decoding. However, we know very little about RS codes over Galois ring which
might hinder the development of zero knowledge proof system for ring-based
arithmetic circuit. In this work, we first extend the list decoding procedure
of Guruswami and Sudan to Reed-Solomon codes over Galois rings, which shows
that RS codes with rate $r$ can be list decoded up to radius $1-\sqrt{r}$.
Then, we investigate the list decoding of folded Reed-Solomon codes over Galois
rings. We show that the list decoding radius of folded Reed-Solomon codes can
reach the Singlton bound as its counterpart over finite field. Finally, we
improve the list size of our folded Reed-Solomon code to
$O(\frac{1}{\varepsilon^2})$ by extending recent work in Shashank
Srivastava(2025) to Galois Rings.

</details>


### [57] [Affine Frequency Division Multiplexing: From Communication to Sensing](https://arxiv.org/abs/2511.04471)
*Ali Bemani,Nassar Ksairi,Marios Kountouris*

Main category: cs.IT

TL;DR: AFDM波形被研究用于集成感知和通信(ISAC)系统，以解决两个主要挑战：一是通过低复杂度的自干扰消除(SIC)方案和模拟消啁啾降低采样率来支持较高的带宽需求，二是利用离散仿射傅立叶变换(DAFT)资源分配灵活性来减少多雷达环境中的干扰。在单站感知中，AFDM-ISAC接收器可以应对直接发射机-接收机泄漏的问题；在异站感知中，AFDM支持亚奈奎斯特采样，而无需硬件修改，并且保持延迟分辨率。


<details>
  <summary>Details</summary>
Motivation: 本文提出了一种新的AFDM波形优化策略，旨在解决ISAC系统中的复杂度、能量消耗和多雷达环境中的干扰问题，满足高带宽和高分辨率的需求。

Method: 通过理论分析和实验验证了AFDM波形在单站和异站感知中的应用，包括低复杂度自干扰消除(SIC)算法和亚奈奎斯特采样技术。此外，还讨论了基于DAFT资源分配灵活性减少多雷达环境中的干扰策略。

Result: 提出的AFDM-ISAC接收机制在处理直接发射机-接收机泄漏时表现出色，并且即使在硬件未修改的情况下，AFDM也能实现亚奈奎斯特采样。利用DAFT资源分配灵活性，可以有效减少多雷达环境中的干扰。

Conclusion: 研究表明，AFDM波形在ISAC系统中有广泛的应用前景，特别是在降低接收端复杂度和降低功耗方面，同时也能有效解决多雷达环境中的干扰问题。

Abstract: Affine Frequency Division Multiplexing (AFDM) has been proposed as an
effective waveform for achieving the full diversity of doubly-dispersive
(delay-Doppler) channels. While this property is closely related to range and
velocity estimation in sensing, this article focuses on other AFDM features
that are particularly relevant for addressing two challenges in integrated
sensing and communication (ISAC) systems: (1) maintaining receiver complexity
and energy consumption at acceptable levels while supporting the large
bandwidths required for high delay/range resolution, and (2) mitigating
interference in multiradar environments. In monostatic sensing, where direct
transmitter-receiver leakage is a major impairment, we show that AFDM-based
ISAC receivers can address the first challenge through their compatibility with
low-complexity self-interference cancellation (SIC) schemes and reduced
sampling rates via analog dechirping. In bistatic sensing, where such analog
solutions may not be feasible, we demonstrate that AFDM supports sub-Nyquist
sampling without requiring hardware modifications while preserving delay
resolution. Finally, we show that the second challenge can be addressed by
leveraging the resource-assignment flexibility of the discrete affine Fourier
transform (DAFT) underlying the AFDM waveform.

</details>


### [58] [Age of Job Completion Minimization with Stable Queues](https://arxiv.org/abs/2511.04630)
*Stavros Mitrolaris,Subhankar Banerjee,Sennur Ulukus*

Main category: cs.IT

TL;DR: 本文研究了一个时间槽的作业分配系统，其中涉及一个中心服务器、多个用户和一个随马尔可夫链变化的机器。为了最大化单位时间内完成的作业数量，引入了作业完成的‘年龄’作为新指标，并提出了两种策略来最小化该‘年龄’及采样成本。同时研究了在何种条件下作业队列保持稳定。


<details>
  <summary>Details</summary>
Motivation: 为了优化作业分配系统的效率，特别是在实现高工率方面，引入了作业完成的‘年龄’这一新指标，希望可以最小化系统中的作业排队等待时间及减少采样成本。

Method: 提出并分析了两种策略，用于最小化作业完成的‘年龄’和降低采样成本；并通过数值仿真来评估这两种策略的性能。同时推导出作业队列稳定的充分条件。

Result: 通过数值分析，这两种策略成功地降低了作业完成的‘年龄’和采样成本，且得出了队列稳定性的证明。

Conclusion: 本文通过引入作业完成的‘年龄’作为新的优化指标，并采用两种策略，在减轻用户等待时间的同时降低采样成本，有效提升了作业分配系统效率。此外，还揭示了作业队列稳定性的条件。

Abstract: We consider a time-slotted job-assignment system with a central server, N
users and a machine which changes its state according to a Markov chain (hence
called a Markov machine). The users submit their jobs to the central server
according to a stochastic job arrival process. For each user, the server has a
dedicated job queue. Upon receiving a job from a user, the server stores that
job in the corresponding queue. When the machine is not working on a job
assigned by the server, the machine can be either in internally busy or in free
state, and the dynamics of these states follow a binary symmetric Markov chain.
Upon sampling the state information of the machine, if the server identifies
that the machine is in the free state, it schedules a user and submits a job to
the machine from the job queue of the scheduled user. To maximize the number of
jobs completed per unit time, we introduce a new metric, referred to as the age
of job completion. To minimize the age of job completion and the sampling cost,
we propose two policies and numerically evaluate their performance. For both of
these policies, we find sufficient conditions under which the job queues will
remain stable.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [59] [How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis](https://arxiv.org/abs/2511.03825)
*Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder*

Main category: cs.AI

TL;DR: 该研究评估了自然语言处理（NLP）分词模型及其参数选择在汇编代码语料库中的内在属性，如词汇量大小，并探索适配汇编代码特性的预处理选项和预分词规则。通过使用诸如Llama 3.2、BERT和BART等最先进的预训练模型，研究结果表明分词器的选择显著影响下游任务性能，为汇编代码优化提供了宝贵见解。


<details>
  <summary>Details</summary>
Motivation: 尽管汇编代码的分词化对词汇量大小、语义覆盖率和下游任务性能有重大影响，但在该领域的研究仍然不足。研究目的在于填补这一空白，评估NLP分词模型在处理汇编代码时的内在属性及参数选择的影响。

Method: 系统分析了各种分词模型在对汇编指令进行编码和捕捉语义细微差别的效率。通过内因评价比较了分词器的分词效率、词汇压缩和对汇编代码的表示保真度。

Result: 研究表明，分词器的选择显著影响下游任务性能。初步研究结果表明，内因评价部分但不完全可以预测外因评价的结果。这些结果揭示了内在分词器属性和它们在实际汇编代码任务中的实用性之间的复杂权衡。

Conclusion: 该研究为汇编代码优化提供了宝贵的见解，有助于自然语言模型（NLM）驱动的二进制分析工作流程的健壮性和可扩展性。

Abstract: Tokenization is fundamental in assembly code analysis, impacting intrinsic
characteristics like vocabulary size, semantic coverage, and extrinsic
performance in downstream tasks. Despite its significance, tokenization in the
context of assembly code remains an underexplored area. This study aims to
address this gap by evaluating the intrinsic properties of Natural Language
Processing (NLP) tokenization models and parameter choices, such as vocabulary
size. We explore preprocessing customization options and pre-tokenization rules
tailored to the unique characteristics of assembly code. Additionally, we
assess their impact on downstream tasks like function signature prediction -- a
critical problem in binary code analysis.
  To this end, we conduct a thorough study on various tokenization models,
systematically analyzing their efficiency in encoding assembly instructions and
capturing semantic nuances. Through intrinsic evaluations, we compare
tokenizers based on tokenization efficiency, vocabulary compression, and
representational fidelity for assembly code. Using state-of-the-art pre-trained
models such as the decoder-only Large Language Model (LLM) Llama 3.2, the
encoder-only transformer BERT, and the encoder-decoder model BART, we evaluate
the effectiveness of these tokenizers across multiple performance metrics.
Preliminary findings indicate that tokenizer choice significantly influences
downstream performance, with intrinsic metrics providing partial but incomplete
predictability of extrinsic evaluation outcomes. These results reveal complex
trade-offs between intrinsic tokenizer properties and their utility in
practical assembly code tasks. Ultimately, this study provides valuable
insights into optimizing tokenization models for low-level code analysis,
contributing to the robustness and scalability of Natural Language Model
(NLM)-based binary analysis workflows.

</details>


### [60] [To See or To Read: User Behavior Reasoning in Multimodal LLMs](https://arxiv.org/abs/2511.03845)
*Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: 文章介绍了一种称为\texttt{BehaviorLens}的系统性框架，用于评估多模态大型语言模型在用户行为推理中的表现。研究发现，当用图像而非文本表示用户行为数据时，可以显著提升模型对未来购买预测的准确性，提高幅度达到87.5%，并且无额外计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前用于分析用户行为的多模态大型语言模型是如何在文本和图像表示之间进行选择的问题尚不清楚，这可能导致模型性能下降。因此，本文旨在通过引入\texttt{BehaviorLens}框架来解决这一问题，其目标是探索不同表示方式对模型表现的影响。

Method: 使用包含三种表示形式的真实购买序列数据集对六个大型语言模型进行测试和比较，三种表示形式包括文本段落、散点图和流程图。在每种表示方式下，评估模型在进行未来购买预测任务的表现。

Result: 在实验中，采用图像表示的方式，MLLM的预测准确率相较于文本表示提高了87.5%。而且，这种提高不需要额外的计算开销。这表明图像对于解析用户行为优于文本段落。

Conclusion: 研究得出结论，对于类似购买行为解析等任务，图像表示将比单纯文本表示具有更高的解释性以及预测准确性。这项研究的意义在于创建了评估用户行为数据表示方式对于预测效果影响的一种新框架。

Abstract: Multimodal Large Language Models (MLLMs) are reshaping how modern agentic
systems reason over sequential user-behavior data. However, whether textual or
image representations of user behavior data are more effective for maximizing
MLLM performance remains underexplored. We present \texttt{BehaviorLens}, a
systematic benchmarking framework for assessing modality trade-offs in
user-behavior reasoning across six MLLMs by representing transaction data as
(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a
real-world purchase-sequence dataset, we find that when data is represented as
images, MLLMs next-purchase prediction accuracy is improved by 87.5% compared
with an equivalent textual representation without any additional computational
cost.

</details>


### [61] [Extracting Causal Relations in Deep Knowledge Tracing](https://arxiv.org/abs/2511.03948)
*Kevin Hong,Kia Karbasi,Gregory Pottie*

Main category: cs.AI

TL;DR: 本文挑战了Deep Knowledge Tracing (DKT)模型卓越表现源于其双向建模能力的传统观点，提出其强项在于其隐含地对先修关系进行了因果结构建模。通过将练习关系图转化为Directed Acyclic Graphs (DAGs)并对因果子集进行训练，证实了该观点。同时，提出了一种基于DKT学习到的表示来提取练习关系DAG的新方法，并提供了实验证据支持这一发现。


<details>
  <summary>Details</summary>
Motivation: 挑战并验证Deep Knowledge Tracing (DKT)模型优异表现是否源于其对先修知识因果结构建模的能力，而不是简单的双向关系建模。同时，提出一种新方法从DKT学习的表示中提取练习关系DAG的因果结构。目的在于更好地解释和应用DKT模型。

Method: 1. 将练习关系图转化为Directed Acyclic Graphs (DAGs)；2. 对因果子集进行DKT模型的训练；3. 提出一种基于DKT学习表示的DAG提取方法，并通过实验验证该方法的正确性。

Result: 证明了DKT模型的优越性主要由于其能够隐含地建模因果关系，而非简单的双向关系。提出的方法也得到了实验证明的有效性。

Conclusion: 本文的研究结果表明,DKT模型的成功在于其对知识成分之间因果依赖关系的有效建模，这一发现丰富并深化了对DKT及其应用的理解。

Abstract: A longstanding goal in computational educational research is to develop
explainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which
leverages a Recurrent Neural Network (RNN) to predict student knowledge and
performance on exercises, has been proposed as a major advancement over
traditional KT methods. Several studies suggest that its performance gains stem
from its ability to model bidirectional relationships between different
knowledge components (KCs) within a course, enabling the inference of a
student's understanding of one KC from their performance on others. In this
paper, we challenge this prevailing explanation and demonstrate that DKT's
strength lies in its implicit ability to model prerequisite relationships as a
causal structure, rather than bidirectional relationships. By pruning exercise
relation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal
subsets of the Assistments dataset, we show that DKT's predictive capabilities
align strongly with these causal structures. Furthermore, we propose an
alternative method for extracting exercise relation DAGs using DKT's learned
representations and provide empirical evidence supporting our claim. Our
findings suggest that DKT's effectiveness is largely driven by its capacity to
approximate causal dependencies between KCs rather than simple relational
mappings.

</details>


### [62] [LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing](https://arxiv.org/abs/2511.03980)
*Bram Bulté,Ayla Rigouts Terryn*

Main category: cs.AI

TL;DR: 研究探讨了大型语言模型(LLM)在不同文化背景下的表现。经过多项实验，发现LLM在不同语言和文化背景下会生成不同的反应，但同时也显示出对少数特定国家文化（如荷兰、德国、美国和日本）的偏好。尽管通过文化视角的引导可以改善对人类价值观的匹配度，但这种效果并未显著提升。实验结果揭示了LLM在文化多样性的反映上的尴尬处境：它们足够敏感以应对外部提示的变化，但又过于依赖特定的文化默认设置，无法充分代表文化的多样性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨和分析大型语言模型在不同文化背景下的表现，验证语言提示和文化视角如何影响模型对不同国家文化价值观的匹配度，最终揭示大型语言模型在反映文化多样性方面的局限性。

Method: 研究通过向10款大型语言模型发出包含63项霍夫斯迪价值观调查模块和世界价值观调查项目的跨文化翻译提示，探讨语言提示和文化视角对模型响应的影响。提示被设计成带有和不带有不同显式文化视角的形式，并转换成11种不同的语言。

Result: 实验结果表明，提示语言和文化视角确实可以引起大型语言模型输出的变化，但模型普遍表现出对特定国家文化偏好的默认设置。模型在多语言环境下能较好地反映人类的一些基本价值观，但这对于代表全面的文化多样性来说是不够的。同时发现，通过文化视角引导的效果比通过语言提示的更加显著，而且两者结合起来也没有显现出优于只采用文化视角的效果。

Conclusion: 研究揭示了大型语言模型在文化多样性反映上的一个尴尬处境：虽然它们在特定提示下能够产生变化，但深层次的文化偏好看似难以改变，这提示我们需要对模型的训练数据和优化目标进行更加深入的研究，以更充分地包容全世界的文化多样性。

Abstract: Large Language Models (LLMs) are rapidly being adopted by users across the
globe, who interact with them in a diverse range of languages. At the same
time, there are well-documented imbalances in the training data and
optimisation objectives of this technology, raising doubts as to whether LLMs
can represent the cultural diversity of their broad user base. In this study,
we look at LLMs and cultural values and examine how prompt language and
cultural framing influence model responses and their alignment with human
values in different countries. We probe 10 LLMs with 63 items from the Hofstede
Values Survey Module and World Values Survey, translated into 11 languages, and
formulated as prompts with and without different explicit cultural
perspectives. Our study confirms that both prompt language and cultural
perspective produce variation in LLM outputs, but with an important caveat:
While targeted prompting can, to a certain extent, steer LLM responses in the
direction of the predominant values of the corresponding countries, it does not
overcome the models' systematic bias toward the values associated with a
restricted set of countries in our dataset: the Netherlands, Germany, the US,
and Japan. All tested models, regardless of their origin, exhibit remarkably
similar patterns: They produce fairly neutral responses on most topics, with
selective progressive stances on issues such as social tolerance. Alignment
with cultural values of human respondents is improved more with an explicit
cultural perspective than with a targeted prompt language. Unexpectedly,
combining both approaches is no more effective than cultural framing with an
English prompt. These findings reveal that LLMs occupy an uncomfortable middle
ground: They are responsive enough to changes in prompts to produce variation,
but too firmly anchored to specific cultural defaults to adequately represent
cultural diversity.

</details>


### [63] [Detecting Silent Failures in Multi-Agentic AI Trajectories](https://arxiv.org/abs/2511.04032)
*Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi*

Main category: cs.AI

TL;DR: 本文提出了一种在多智能体AI系统中检测异常的任务，并创建了两个基准数据集来评估不同的异常检测方法，其中包括监督学习和半监督学习方法，展示了其在检测多智能体AI系统中的性能（准确率可达98%和96%）


<details>
  <summary>Details</summary>
Motivation: 大型语言模型驱动的多智能体AI系统容易出现难以察觉的异常情况，如漂移、循环和输出细节缺失。现有方法难以有效检测这些问题

Method: 提出了异常检测的任务，并开发了一个数据集收集管道，该管道能够捕获用户行为、智能体非确定性和语言模型的变化。在此基础上，创建了两个数据集，并使用监督学习（XGBoost）和半监督学习（SVDD）方法来评估异常检测效果

Result: 研究表明，监督学习和半监督学习方法的性能相当，准确率分别可达到98%和96%。这为未来的研究提供了宝贵的资源和方向

Conclusion: 本研究通过提供数据集、基准和对未来研究的洞察，为多智能体AI系统中的异常检测提供了首个系统性的研究

Abstract: Multi-Agentic AI systems, powered by large language models (LLMs), are
inherently non-deterministic and prone to silent failures such as drift,
cycles, and missing details in outputs, which are difficult to detect. We
introduce the task of anomaly detection in agentic trajectories to identify
these failures and present a dataset curation pipeline that captures user
behavior, agent non-determinism, and LLM variation. Using this pipeline, we
curate and label two benchmark datasets comprising \textbf{4,275 and 894}
trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection
methods on these datasets, we show that supervised (XGBoost) and
semi-supervised (SVDD) approaches perform comparably, achieving accuracies up
to 98% and 96%, respectively. This work provides the first systematic study of
anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,
and insights to guide future research.

</details>


### [64] [Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models](https://arxiv.org/abs/2511.04053)
*Hirohane Takagi,Gouki Minegishi,Shota Kizawa,Issey Sukeda,Hitomi Yanaka*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）内部在处理数值属性时存在系统性放大现实世界数值相关性的特点，并且无关的数值背景会导致其数值表示发生一致性的偏移，具体影响会因模型大小而有所不同。这项研究揭示了LLMs决策过程中的一个脆弱性，并为解决多属性纠缠下的公平表示控制奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管行为研究已经证明了大型语言模型（LLMs）在数值推理方面存在错误，但这些错误背后的表示机制尚不清楚。研究者希望通过研究LLMs如何整合单个实体的多个数值属性以及这些表示如何受到无关数值上下文影响，来探讨数值属性在共享潜在子空间中的存在情况。

Method: 研究者结合了线性探测与部分相关分析，并通过不同大小的模型进行了基于提示的脆弱性测试，以解答两个研究问题。

Result: 研究结果显示，LLMs确实编码了现实世界的数值相关性，但有系统地放大这些相关性；而且，无关的上下文信息会引起数值表示的一致性偏移，这种偏移对最终输出的影响会因模型大小的不同而有所差异。

Conclusion: 这些发现揭示了LLMs中的一个决策脆弱性，并为多属性纠缠的情况下实现更公平的表示控制提供了研究基础。

Abstract: Although behavioral studies have documented numerical reasoning errors in
large language models (LLMs), the underlying representational mechanisms remain
unclear. We hypothesize that numerical attributes occupy shared latent
subspaces and investigate two questions:(1) How do LLMs internally integrate
multiple numerical attributes of a single entity? (2)How does irrelevant
numerical context perturb these representations and their downstream outputs?
To address these questions, we combine linear probing with partial correlation
analysis and prompt-based vulnerability tests across models of varying sizes.
Our results show that LLMs encode real-world numerical correlations but tend to
systematically amplify them. Moreover, irrelevant context induces consistent
shifts in magnitude representations, with downstream effects that vary by model
size. These findings reveal a vulnerability in LLM decision-making and lay the
groundwork for fairer, representation-aware control under multi-attribute
entanglement.

</details>


### [65] [KGFR: A Foundation Retriever for Generalized Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04093)
*Yuanning Cui,Zequn Sun,Wei Hu,Zhangjie Fu*

Main category: cs.AI

TL;DR: 本文提出了LLM-KGFR框架，结合了大型语言模型和知识图谱基础检索器，解决了大型语言模型在处理知识密集型问题时的局限性。该框架采用不对称渐进传播策略，实现了对大图的有效处理，并保持了推理的可控性和泛化能力。实验表明，在保持规模性和泛化性的前提下，LLM-KGFR框架可以取得较好的效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理知识密集型问题时受限于上下文和参数知识的限制，现有依赖于精细调整的LLM或GNN检索器的方法也受限于数据集特定的调整或大规模未见图的可扩展性，因此提出改进方案。

Method: 提出了一种基于大型语言模型和结构化检索器KGFR的LLM-KGFR框架，KGFR通过使用大型语言模型生成的关系描述进行编码，并根据问题角色初始化实体，从而在未知知识图中实现零样本泛化。并通过不规则渐进传播策略，有选择地限制高度节点，保留信息路径，以处理大型图，同时通过节点、边和路径级接口实现可控制的循环推理。

Result: 实验表明，LLM-KGFR框架不仅可以实现较强的性能，同时还能保持可扩展性和泛化性，有效解决了原问题。

Conclusion: LLM-KGFR框架提供了一个有效的知识增强推理解决方案，展示了大型语言模型与结构化检索器融合的潜力。

Abstract: Large language models (LLMs) excel at reasoning but struggle with
knowledge-intensive questions due to limited context and parametric knowledge.
However, existing methods that rely on finetuned LLMs or GNN retrievers are
limited by dataset-specific tuning and scalability on large or unseen graphs.
We propose the LLM-KGFR collaborative framework, where an LLM works with a
structured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR
encodes relations using LLM-generated descriptions and initializes entities
based on their roles in the question, enabling zero-shot generalization to
unseen KGs. To handle large graphs efficiently, it employs Asymmetric
Progressive Propagation (APP)- a stepwise expansion that selectively limits
high-degree nodes while retaining informative paths. Through node-, edge-, and
path-level interfaces, the LLM iteratively requests candidate answers,
supporting facts, and reasoning paths, forming a controllable reasoning loop.
Experiments demonstrate that LLM-KGFR achieves strong performance while
maintaining scalability and generalization, providing a practical solution for
KG-augmented reasoning.

</details>


### [66] [Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms](https://arxiv.org/abs/2511.04133)
*Miguel E. Andres,Vadim Fedorov,Rida Sadek,Enric Spagnolo-Arrizabalaga,Nadescha Trudel*

Main category: cs.AI

TL;DR: 提出了首个评估语音AI测试质量的人机结合基准框架，结合心理测量技术和严格统计验证，为任何测试方法提供可重现的指标。通过三个商业平台的综合实证评估，确认了该框架的有效性。Evalion平台表现最佳，在评价质量上达到0.92，模拟质量上达到0.61。该框架有助于实现大规模语音AI部署所需的测试功能的实验验证。 


<details>
  <summary>Details</summary>
Motivation: 当前语音AI测试没有系统的方法来确保测试的可靠性，这导致了无法评估测试方法是否有效的问题。为此，提出了评估语音AI测试质量的人机结合基准框架，以解决测试平台生成真实对话和准确评估反应的基本挑战。 

Method: 采用心理测量技术（成对比较产生Elo等级、自举置信区间和置换测试）和严格统计验证，创建了一个综合性的评估框架，适用于任何测试方法。通过三个领先的商业平台（聚焦于语音AI测试）的实证评估来验证其有效性。一共使用了21,600个人的判断，45个模拟，并对60个对话进行了实证验证。 

Result: 实验结果显示，采用提出的框架，不同平台之间存在显著的性能差异。最高表现的平台Evalion在评价质量上达到0.92，模拟质量上达到0.61。而其他平台分别仅有0.73和0.43。 

Conclusion: 这一框架为研究人员和组织提供了一种实验验证测试平台的方法，为大规模语音AI部署提供了不可或缺的测量基础。进一步相关的资料被提供以利于实现可再现性和采用。

Abstract: Voice AI agents are rapidly transitioning to production deployments, yet
systematic methods for ensuring testing reliability remain underdeveloped.
Organizations cannot objectively assess whether their testing approaches
(internal tools or external platforms) actually work, creating a critical
measurement gap as voice AI scales to billions of daily interactions.
  We present the first systematic framework for evaluating voice AI testing
quality through human-centered benchmarking. Our methodology addresses the
fundamental dual challenge of testing platforms: generating realistic test
conversations (simulation quality) and accurately evaluating agent responses
(evaluation quality). The framework combines established psychometric
techniques (pairwise comparisons yielding Elo ratings, bootstrap confidence
intervals, and permutation tests) with rigorous statistical validation to
provide reproducible metrics applicable to any testing approach.
  To validate the framework and demonstrate its utility, we conducted
comprehensive empirical evaluation of three leading commercial platforms
focused on Voice AI Testing using 21,600 human judgments across 45 simulations
and ground truth validation on 60 conversations. Results reveal statistically
significant performance differences with the proposed framework, with the
top-performing platform, Evalion, achieving 0.92 evaluation quality measured as
f1-score versus 0.73 for others, and 0.61 simulation quality using a league
based scoring system (including ties) vs 0.43 for other platforms.
  This framework enables researchers and organizations to empirically validate
the testing capabilities of any platform, providing essential measurement
foundations for confident voice AI deployment at scale. Supporting materials
are made available to facilitate reproducibility and adoption.

</details>


### [67] [When Empowerment Disempowers](https://arxiv.org/abs/2511.04177)
*Claire Yang,Maya Cakmak,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: 本文提出了一种新的多个人工智能辅助情境下的算法，揭示了在单独的AI设定中看起来对齐的目标在多AI情境中可能会出现偏差。引入了一个开源工具来测试这种现象，即助一个AI可能降低另一个AI的环境影响力和奖励，命名为disempowerment，并提出了通过联合优化来缓解这一问题的方法但会以用户奖励为代价。


<details>
  <summary>Details</summary>
Motivation: 激励在多个人类环境中工作的AI模型以辅助方式行动，改进单一用户环境的控制权优化方法，同时减少在多用户环境中的负面影响，即disempowerment现象的出现。这促使了开发者研究群体环境中的AI对齐问题及其挑战。

Method: 引入了一个开源工具——Disempower-Grid，它是一个多个人工智能辅助的网格世界测试套件，用以研究和测试disempowerment现象，并通过实验证明了助一个用户的AI可能会降低另一个用户的环境影响和奖励。此外，他们还研究了如何通过联合优化来避免这种现象，尽管这样会减少用户奖励。

Result: 发现了一个在多个人工智能协助环境中的现象——disempowerment，在优化一个用户的环境控制权时，可能减少了另一个用户的环境影响和奖励，而联合优化虽可缓解此问题，但会减少用户奖励。

Conclusion: 研究表明，单独用户设定下的目标对齐在多用户设定中可能会失准。解决这个问题需要在AI设计中更深入地思考多用户环境中的对齐挑战。

Abstract: Empowerment, a measure of an agent's ability to control its environment, has
been proposed as a universal goal-agnostic objective for motivating assistive
behavior in AI agents. While multi-human settings like homes and hospitals are
promising for AI assistance, prior work on empowerment-based assistance assumes
that the agent assists one human in isolation. We introduce an open source
multi-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we
empirically show that assistive RL agents optimizing for one human's
empowerment can significantly reduce another human's environmental influence
and rewards - a phenomenon we formalize as disempowerment. We characterize when
disempowerment occurs in these environments and show that joint empowerment
mitigates disempowerment at the cost of the user's reward. Our work reveals a
broader challenge for the AI alignment community: goal-agnostic objectives that
seem aligned in single-agent settings can become misaligned in multi-agent
contexts.

</details>


### [68] [Opus: A Quantitative Framework for Workflow Evaluation](https://arxiv.org/abs/2511.04220)
*Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston*

Main category: cs.AI

TL;DR: 文章介绍了Opus Workflow Evaluation Framework，这是一个概率规范化的公式，用于量化工作流的质量和效率，并结合了成功概率、资源使用和输出收益等因素，支持自动化评估、排名和优化工作流，可用于强化学习循环中指导工作流发现和精炼过程


<details>
  <summary>Details</summary>
Motivation: 该研究提出了一个量化工作流质量和效率的新方法，以支持自动化系统的评估、排名和优化

Method: 提出Opus Workflow Evaluation Framework，结合Opus Workflow Reward和Penalties，用于工作流评估、排名和优化

Result: 本文提出了一种新的框架，能够将工作流的成功概率、资源使用和输出收益等因素整合到一个概率期望模型中，并定义了捕捉工作流结构、语义和信号相关性质的规范性处罚

Conclusion: 该研究提供了一种统一的优化公式，可以识别和排名在奖励-处罚权衡下最佳的工作流

Abstract: This paper introduces the Opus Workflow Evaluation Framework, a
probabilistic-normative formulation for quantifying Workflow quality and
efficiency. It integrates notions of correctness, reliability, and cost into a
coherent mathematical model that enables direct comparison, scoring, and
optimization of Workflows. The framework combines the Opus Workflow Reward, a
probabilistic function estimating expected performance through success
likelihood, resource usage, and output gain, with the Opus Workflow Normative
Penalties, a set of measurable functions capturing structural and informational
quality across Cohesion, Coupling, Observability, and Information Hygiene. It
supports automated Workflow assessment, ranking, and optimization within modern
automation systems such as Opus and can be integrated into Reinforcement
Learning loops to guide Workflow discovery and refinement. In this paper, we
introduce the Opus Workflow Reward model that formalizes Workflow success as a
probabilistic expectation over costs and outcomes. We define measurable Opus
Workflow Normative Penalties capturing structural, semantic, and signal-related
properties of Workflows. Finally, we propose a unified optimization formulation
for identifying and ranking optimal Workflows under joint Reward-Penalty
trade-offs.

</details>


### [69] [Shared Spatial Memory Through Predictive Coding](https://arxiv.org/abs/2511.04235)
*Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang*

Main category: cs.AI

TL;DR: 本文介绍了一种多智能体预测编码框架，该框架将协调视为智能体之间相互不确定性最小化的问题。在该框架下，智能体通过内部空间编码自发地学习到合作伙伴的位置，并通过分层强化学习策略减少联合不确定性。实验表明，该方法在带宽受限的情况下表现出色，能够有效实现多智能体之间的空间记忆共享和重建，建立了复杂社交表示从统一预测驱动中产生的理论基础和生物学可能性论证。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，由于部分可观测性和有限带宽常导致协调失败，因此需要一种能够在带宽受限条件下有效实现多智能体空间记忆共享和重建的方法。

Method: 提出了一种多智能体预测编码框架，通过信息瓶颈目标函数使智能体学习何时、向谁、传达什么信息。以栅格细胞似的内在空间编码为基础进行自我定位，并在此基础上形成带宽高效的通信机制。该框架还引入了与海马体社交地方细胞相对应的特化神经群体，进而通过层次化强化学习策略主动探索减少联合不确定性。

Result: 在Memory-Maze基准测试中，该方法表现出对带宽约束的强大适应性，在带宽从128位/步缩小到4位/步的情况下成功率温和下降（从73.5%降至64.4%），而全广播基线则崩塌（从67.6%降至28.6%）。

Conclusion: 我们确立了一种复杂社交表示如何从统一预测驱动中产生的理论基础和生物可行性，这促进了社会集体智能的发展。

Abstract: Sharing and reconstructing a consistent spatial memory is a critical
challenge in multi-agent systems, where partial observability and limited
bandwidth often lead to catastrophic failures in coordination. We introduce a
multi-agent predictive coding framework that formulate coordination as the
minimization of mutual uncertainty among agents. Instantiated as an information
bottleneck objective, it prompts agents to learn not only who and what to
communicate but also when. At the foundation of this framework lies a
grid-cell-like metric as internal spatial coding for self-localization,
emerging spontaneously from self-supervised motion prediction. Building upon
this internal spatial code, agents gradually develop a bandwidth-efficient
communication mechanism and specialized neural populations that encode
partners' locations: an artificial analogue of hippocampal social place cells
(SPCs). These social representations are further enacted by a hierarchical
reinforcement learning policy that actively explores to reduce joint
uncertainty. On the Memory-Maze benchmark, our approach shows exceptional
resilience to bandwidth constraints: success degrades gracefully from 73.5% to
64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast
baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically
principled and biologically plausible basis for how complex social
representations emerge from a unified predictive drive, leading to social
collective intelligence.

</details>


### [70] [RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization](https://arxiv.org/abs/2511.04285)
*Zeng Zhiyuan,Jiashuo Liu,Zhangyue Yin,Ge Zhang,Wenhao Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: 本文提出了一种名为RLoop的框架，用于解决强化学习中由于策略过度专业化和灾难性遗忘而导致的过拟合问题。RLoop通过迭代策略初始化，将标准训练过程转化为探索和开发的良性循环，提高了模型的泛化能力和准确率。


<details>
  <summary>Details</summary>
Motivation: 研究发现，在强化学习中，由于策略过度专业化和对多样化解决方案的灾难性遗忘，模型容易出现训练过拟合的问题。标准优化过程忽略了不同步骤之间的策略多样性。为了解决这些问题，提出了RLoop框架。

Method: RLoop框架包括两个主要步骤：首先，使用强化学习探索解决方案空间，然后使用拒绝采样微调(RFT)技术从成功轨迹中创建专家数据集，并用于改进初始策略。该过程通过迭代重新初始化实现策略多样性的持续利用，进一步提高性能。

Result: 实验表明，与传统的强化学习相比，RLoop框架能够有效改善模型的泛化能力，平均准确率提高9%，pass@32指标提高超过15%。

Conclusion: RLoop通过迭代策略初始化，成功地转化了瞬时策略变异为稳健的性能提升，有效地缓解了模型遗忘问题，提高了模型的泛化能力。

Abstract: While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for
training large reasoning models, its training dynamics harbor a critical
challenge: RL overfitting, where models gain training rewards but lose
generalization. Our analysis reveals this is driven by policy
over-specialization and catastrophic forgetting of diverse solutions generated
during training. Standard optimization discards this valuable inter-step policy
diversity. To address this, we introduce RLoop, a self-improving framework
built on iterative policy initialization. RLoop transforms the standard
training process into a virtuous cycle: it first uses RL to explore the
solution space from a given policy, then filters the successful trajectories to
create an expert dataset. This dataset is used via Rejection-sampling
Fine-Tuning (RFT) to refine the initial policy, creating a superior starting
point for the next iteration. This loop of exploration and exploitation via
iterative re-initialization effectively converts transient policy variations
into robust performance gains. Our experiments show RLoop mitigates forgetting
and substantially improves generalization, boosting average accuracy by 9% and
pass@32 by over 15% compared to vanilla RL.

</details>


### [71] [Probing the Probes: Methods and Metrics for Concept Alignment](https://arxiv.org/abs/2511.04312)
*Jacob Lysnæs-Larsen,Marte Eggen,Inga Strümke*

Main category: cs.AI

TL;DR: 论文指出，传统的CAV依赖线性分类器的准确性来衡量概念对齐性是一个不可靠的方法。为此，作者提出了一种基于空间线性归因的概念定位方法，并引入了多类量化指标来评估概念对齐性，进一步证明模型架构和目标概念的性质对改善概念对齐也非常重要。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是解决当前使用线性分类器准确性来衡量概念激活向量（CAV）对齐性这一方法的局限性。这种传统方法往往捕获到了虚假的相关性，而非真正反映目标概念。因此，需要提出新的、更准确的方法来度量这种对齐性。

Method: 提出了一种新的基于空间线性归因的概念定位方法，用于检测和减轻概念错配。同时，还提出了一系列评估方法，即用三个类别的度量标准来量化概念对齐：硬准确性、分割得分、归一化鲁棒性。

Result: 实验结果显示，具有翻译不变性和空间对齐的探针概念对齐显著增加。这说明了使用新的量化指标来评估概念对齐方法的重要性。

Conclusion: 论文得出结论，传统的只依赖线性探针准确性来衡量概念对齐的方法是不可靠的。更好的方法应该是基于新的度量标准来对模型架构和目标概念的特性进行定制化探针构建。

Abstract: In explainable AI, Concept Activation Vectors (CAVs) are typically obtained
by training linear classifier probes to detect human-understandable concepts as
directions in the activation space of deep neural networks. It is widely
assumed that a high probe accuracy indicates a CAV faithfully representing its
target concept. However, we show that the probe's classification accuracy alone
is an unreliable measure of concept alignment, i.e., the degree to which a CAV
captures the intended concept. In fact, we argue that probes are more likely to
capture spurious correlations than they are to represent only the intended
concept. As part of our analysis, we demonstrate that deliberately misaligned
probes constructed to exploit spurious correlations, achieve an accuracy close
to that of standard probes. To address this severe problem, we introduce a
novel concept localization method based on spatial linear attribution, and
provide a comprehensive comparison of it to existing feature visualization
techniques for detecting and mitigating concept misalignment. We further
propose three classes of metrics for quantitatively assessing concept
alignment: hard accuracy, segmentation scores, and augmentation robustness. Our
analysis shows that probes with translation invariance and spatial alignment
consistently increase concept alignment. These findings highlight the need for
alignment-based evaluation metrics rather than probe accuracy, and the
importance of tailoring probes to both the model architecture and the nature of
the target concept.

</details>


### [72] [AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research](https://arxiv.org/abs/2511.04316)
*Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann*

Main category: cs.AI

TL;DR: AdversariaLLM 是一个针对大规模语言模型（LLM）进行安全性和稳健性研究的工具箱，旨在解决当前研究领域中存在的可重复性差和难于比较的问题。它实现了12种对抗性攻击算法，整合了7个基准数据集，并提供了对Hugging Face上各种开源LLM的访问。该工具箱还具有计算资源跟踪、确定性结果和分布评估等高级特性，以促进研究的透明度、可比较性和可重复性。


<details>
  <summary>Details</summary>
Motivation: 由于大规模语言模型研究的安全性和稳健性领域的快速扩张，出现了许多不一致的实现方式、数据集和评估方法，这导致了研究的可重复性和可比性困难，阻碍了研究的进步。

Method: 开发AdversariaLLM，一个专门用于大规模语言模型的抗越狱（jailbreak）稳健性研究的工具箱，包含十二种不同的对抗性攻击算法，使用了七个不同的基准数据集，并且可以通过Hugging Face平台访问多种开源的大规模语言模型。同时，该工具箱还具备追踪计算资源、确保结果的可重复性和进行分布评估等特性。

Result: 通过AdversariaLLM，建立了一个坚实的基础来支持大规模语言模型安全性的透明、可比较和可重复的研究。采用统一的方法可以使得不同的研究实验之间更容易进行有效的比较，并且确保研究结果的可靠性和可重复性。

Conclusion: AdversariaLLM 工具箱的开发和使用，将极大改善大规模语言模型研究中的可重复性和可比性问题，推动该领域的发展走向透明、可靠和高效。

Abstract: The rapid expansion of research on Large Language Model (LLM) safety and
robustness has produced a fragmented and oftentimes buggy ecosystem of
implementations, datasets, and evaluation methods. This fragmentation makes
reproducibility and comparability across studies challenging, hindering
meaningful progress. To address these issues, we introduce AdversariaLLM, a
toolbox for conducting LLM jailbreak robustness research. Its design centers on
reproducibility, correctness, and extensibility. The framework implements
twelve adversarial attack algorithms, integrates seven benchmark datasets
spanning harmfulness, over-refusal, and utility evaluation, and provides access
to a wide range of open-weight LLMs via Hugging Face. The implementation
includes advanced features for comparability and reproducibility such as
compute-resource tracking, deterministic results, and distributional evaluation
techniques. \name also integrates judging through the companion package
JudgeZoo, which can also be used independently. Together, these components aim
to establish a robust foundation for transparent, comparable, and reproducible
research in LLM safety.

</details>


### [73] [RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation](https://arxiv.org/abs/2511.04328)
*Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang*

Main category: cs.AI

TL;DR: 本文提出一个框架，用于模拟和评估临床咨询中大型语言模型（LLMs）的用药安全性。该框架包含一个专门的用药安全数据库RxRisk DB和一个基准RxSafeBench。评估表明，当前的LLMs在用药安全方面仍存在挑战，尤其是在面对隐含风险时。本研究提供了改进LLMs可靠性的建议，对AI驱动的临床决策支持系统的安全性做出了贡献。


<details>
  <summary>Details</summary>
Motivation: 由于缺少真实世界的数据集，以及评估LLMs在真人咨询设置中关于用药安全性的评估不足，文章希望填补这些空白，以确保医疗系统的安全性和可靠性。

Method: 文章生成了包含药品风险的会话对话，并用两阶段筛选策略构建了高质量的RxSafeBench 数据库，其中包含2,443个咨询场景。随后，使用结构化的选择题，测试了模型在模拟患者场景下推荐安全药品的能力。

Result: 实验结果显示，现有的LLMs在处理隐含风险上有明显的困难。通过这些发现，文章强调了改进药物安全性的必要性。

Conclusion: 这项研究揭示了确保LLM中介药安全性的关键挑战，并提供了改善可靠性的建议。同时，为评估LLMs的用药安全性提供了首个全面的基准，促进了更安全且值得信赖的AI临床决策支持系统的发展。

Abstract: Numerous medical systems powered by Large Language Models (LLMs) have
achieved remarkable progress in diverse healthcare tasks. However, research on
their medication safety remains limited due to the lack of real world datasets,
constrained by privacy and accessibility issues. Moreover, evaluation of LLMs
in realistic clinical consultation settings, particularly regarding medication
safety, is still underexplored. To address these gaps, we propose a framework
that simulates and evaluates clinical consultations to systematically assess
the medication safety capabilities of LLMs. Within this framework, we generate
inquiry diagnosis dialogues with embedded medication risks and construct a
dedicated medication safety database, RxRisk DB, containing 6,725
contraindications, 28,781 drug interactions, and 14,906 indication-drug pairs.
A two-stage filtering strategy ensures clinical realism and professional
quality, resulting in the benchmark RxSafeBench with 2,443 high-quality
consultation scenarios. We evaluate leading open-source and proprietary LLMs
using structured multiple choice questions that test their ability to recommend
safe medications under simulated patient contexts. Results show that current
LLMs struggle to integrate contraindication and interaction knowledge,
especially when risks are implied rather than explicit. Our findings highlight
key challenges in ensuring medication safety in LLM-based systems and provide
insights into improving reliability through better prompting and task-specific
tuning. RxSafeBench offers the first comprehensive benchmark for evaluating
medication safety in LLMs, advancing safer and more trustworthy AI-driven
clinical decision support.

</details>


### [74] [Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning](https://arxiv.org/abs/2511.04341)
*Nick Oh,Fernand Gobet*

Main category: cs.AI

TL;DR: 本文提出了Monitor-Generate-Verify (MGV)框架，通过引入元认知监控，来解决现有生成-验证架构中存在的早期固定假设问题，提高模型在推理过程中的灵活性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有测试时间推理架构忽视了监控过程，导致模型过早地固定在低效的推理路径上，影响了生成和验证的效果。因此，作者引入元认知监控来改进这一问题。

Method: 将Flavell和Nelson & Narens的元认知理论转化为计算规格，提出Monitor-Generate-Verify (MGV)框架，通过监控在生成前的元认知体验，并在验证反馈中调整未来的监控。

Result: 尽管没有实证验证，该工作为理解和解决推理系统失败提供了一个原则性词汇，并提出了针对未来测试时间推理设计的具体架构改进方案。

Conclusion: 本文通过引入Monitor-Generate-Verify (MGV)框架，首次系统地将基础元认知理论转化为计算规格，为优化现有测试时间推理架构提供了理论指导。

Abstract: Test-time reasoning architectures such as those following the Generate-Verify
paradigm -- where a model iteratively refines or verifies its own generated
outputs -- prioritise generation and verification but exclude the monitoring
processes that determine when and how reasoning should begin. This omission may
contribute to the prefix dominance trap, in which models commit early to
suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy
loss. We address this architectural gap by formalising Flavell's and Nelson and
Narens' metacognitive theories into computational specifications, proposing the
Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify
paradigm by adding explicit monitoring that captures metacognitive experiences
(from difficulty assessments to confidence judgements) before generation begins
and refines future monitoring through verification feedback. Though we present
no empirical validation, this work provides the first systematic computational
translation of foundational metacognitive theories, offering a principled
vocabulary for understanding reasoning system failures and suggesting specific
architectural interventions for future test-time reasoning designs.

</details>


### [75] [Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach](https://arxiv.org/abs/2511.04393)
*Chanwoo Park,Ziyang Chen,Asuman Ozdaglar,Kaiqing Zhang*

Main category: cs.AI

TL;DR: 提出了迭代反悔最小化微调（Iterative RMFT）方法，以提高大型语言模型（LLMs）在决策制定（DM）中的表现。该方法通过引导模型生成低反悔决策轨迹来动态提升模型的决策能力，比之前依赖固定算法或手动模板的方法更灵活且自然。实验证明，该方法可以提升不同类型LLMs在不同任务上的表现，并为增强LLMs的决策能力提供通用框架。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然被应用于决策场景中，但是其原始设计并未针对决策过程，因此在许多决策问题上表现不佳。为了改善这一情况，研究者提出了一种新的微调方法，旨在提高模型在决策方面的表现。

Method: 迭代反悔最小化微调（Iterative RMFT）：这种方法通过反复提炼低反悔决策路径并将其反馈给基础模型来进行放样后处理。在每一轮中，模型会运行多个决策路径，选择几个反悔较低的路径并据此进行微调。这种方法依赖于模型自我生成的决策理由，避免了传统方法中的输出工程难题，提供了更为灵活且自然的训练信号。

Result: 实验表明，该方法显著提升了不同类型语言模型在多种任务上的决策表现，体现了其在不同背景和上下文中的泛化能力。理论分析还显示，该方法可以使简化的单层变压器模型成为一个无遗憾的学习者。

Conclusion: 提出的方法建立了一种优化大型语言模型在决策方面的表现的原则性和通用性的放样后处理框架，展示了其对于改进模型决策性能的潜力和广泛适用性。

Abstract: Large language models (LLMs) are increasingly deployed as "agents" for
decision-making (DM) in interactive and dynamic environments. Yet, since they
were not originally designed for DM, recent studies show that LLMs can struggle
even in basic online DM problems, failing to achieve low regret or an effective
exploration-exploitation tradeoff. To address this, we introduce Iterative
Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure
that repeatedly distills low-regret decision trajectories back into the base
model. At each iteration, the model rolls out multiple decision trajectories,
selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior
methods that (a) distill action sequences from known DM algorithms or (b) rely
on manually crafted chain-of-thought templates, our approach leverages the
regret metric to elicit the model's own DM ability and reasoning rationales.
This reliance on model-generated reasoning avoids rigid output engineering and
provides more flexible, natural-language training signals. Empirical results
show that Iterative RMFT improves LLMs' DM performance across diverse models -
from Transformers with numerical input/output, to open-weight LLMs, and
advanced closed-weight models like GPT-4o mini. Its flexibility in output and
reasoning formats enables generalization across tasks with varying horizons,
action spaces, reward processes, and natural-language contexts. Finally, we
provide theoretical insight showing that a single-layer Transformer under this
paradigm can act as a no-regret learner in a simplified setting. Overall,
Iterative RMFT offers a principled and general post-training framework for
enhancing LLMs' decision-making capabilities.

</details>


### [76] [The Peril of Preference: Why GRPO fails on Ordinal Rewards](https://arxiv.org/abs/2511.04439)
*Anisha Garg,Ganesh Venkatesh*

Main category: cs.AI

TL;DR: 提出了Correctness Relative Policy Optimization（CoRPO），改善了GRPO在使用标度奖励时的不足，提高了LLMs的培训效果和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 发现了Group-relative Policy Optimization (GRPO) 在使用非二进制反馈时存在缺陷，导致模型错误行为正强化的问题。为了提高基于强化学习的大语言模型的训练质量，提出了CoRPO方法，以解决这些问题。

Method: CoRPO 采用自适应基线，设置最低质量阈值，并在此基础上进入相对偏好模式，促进模型寻找最优解。此外，通过实验验证此方法在代码验证任务上表现出更稳定的收敛和更好的泛化能力。

Result: CoRPO 方法解决了GRPO在使用标度奖励时的问题，验证实践中表现出了更好的收敛性和泛化能力。

Conclusion: 此项工作标志着关键进展，使得LLMs能够通过强化学习学习真正的新能力，逐步从二进制奖励提升至多维度反馈。

Abstract: Group-relative Policy Optimization's (GRPO) simplicity makes it highly
desirable for adapting LLMs to become experts at specific tasks. But this
simplicity also makes it ill-specified as we seek to enhance RL training with
richer, non-binary feedback. When using ordinal rewards to give partial credit,
GRPO's simplicity starts to hurt, as its group-average baseline often assigns a
positive advantage to failed trajectories and reinforces incorrect behavior.
  We introduce Correctness Relative Policy Optimization (CoRPO), a new
formulation that solves this flaw. CoRPO uses an adaptive baseline that
enforces a minimum quality threshold, ensuring failed solutions are never
positively reinforced. Once the policy consistently meets this threshold, the
baseline automatically transitions to a relative preference mode, pushing the
model to find optimal solutions rather than just "acceptable" ones. We
empirically validate CoRPO on a code verification task, where it demonstrates
more stable convergence and better out-of-domain generalization.
  This work represents a critical step in our broader research program to
enable LLMs to learn genuinely new capabilities through reinforcement learning.
We achieve this by enabling LLMs to learn from rich, multi-dimensional feedback
- progressing from binary to ordinal rewards in this work, and onward to
denser, per-step supervision.

</details>


### [77] [Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context](https://arxiv.org/abs/2511.04464)
*Carnot Braun,Rafael O. Jarczewski,Gabriel U. Talasso,Leandro A. Villas,Allan M. de Souza*

Main category: cs.AI

TL;DR: PAVe引入了一种新的车辆路径规划方法，结合了大型语言模型(LLM)与经典的路径查找算法，以提供个性化、适应性强、可扩展的解决方案，提高了城市交通优化的效果。


<details>
  <summary>Details</summary>
Motivation: 传统车辆路径系统在优化单一指标时表现优越，但在多指标优化以及结合人类驾驶者的上下文信息时存在不足。本文旨在通过结合大型语言模型和经典路径算法，增强系统的上下文理解和适应能力。

Method: 提出了一种新的辅助系统PAVe，该系统结合了大型语言模型和多目标(时间、CO2)的Dijkstra算法，通过预处理的地理缓存来评估路径候选集合，以满足用户的任务、偏好和避免规则。

Result: 在现实城市的实验场景中，PAVe在初次路由选择中达到了超过88%的准确性。这表明，结合大型语言模型与经典算法是创建个性化、适应性强的城市交通优化的有效途径。

Conclusion: 结合大型语言模型的语义推理层与经典路由算法，可以在城市交通优化中实现个性化、适应性强、可扩展的解决方案。

Abstract: Traditional vehicle routing systems efficiently optimize singular metrics
like time or distance, and when considering multiple metrics, they need more
processes to optimize . However, they lack the capability to interpret and
integrate the complex, semantic, and dynamic contexts of human drivers, such as
multi-step tasks, situational constraints, or urgent needs. This paper
introduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a
hybrid agentic assistant designed to augment classical pathfinding algorithms
with contextual reasoning. Our approach employs a Large Language Model (LLM)
agent that operates on a candidate set of routes generated by a multi-objective
(time, CO2) Dijkstra algorithm. The agent evaluates these options against
user-provided tasks, preferences, and avoidance rules by leveraging a
pre-processed geospatial cache of urban Points of Interest (POIs). In a
benchmark of realistic urban scenarios, PAVe successfully used complex user
intent into appropriate route modifications, achieving over 88% accuracy in its
initial route selections with a local model. We conclude that combining
classical routing algorithms with an LLM-based semantic reasoning layer is a
robust and effective approach for creating personalized, adaptive, and scalable
solutions for urban mobility optimization.

</details>


### [78] [Large language models replicate and predict human cooperation across experiments in game theory](https://arxiv.org/abs/2511.04500)
*Andrea Cera Palatsi,Samuel Martin-Gutierrez,Ana S. Cardenal,Max Pellert*

Main category: cs.AI

TL;DR: 研究开发了一种用于检验大型语言模型(LLM)决策方式是否与人类相似的框架，通过游戏理论实验的数字孪生进行评估。研究发现LLM在某些情况下能够复制人类的行为模式，尤其是在合作行为方面。特别是Llama模型在模仿人类非理性选择方面表现良好，而Qwen模型则倾向于遵守纳什均衡预测。这些发现表明，适当校准的LLM可以在复制人类行为模式方面提供传统社会科学研究的补充方法，并能够探索新的实验空间。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于理解大型语言模型（LLMs）决策方式与实际人类决策的匹配程度，探讨其在健康、教育和法律等领域的应用潜力以及作为社会模拟工具的有效性。尤其是当LLMs与人类行为不一致时，可能产生负面后果。因此，研究试图填补这一空白，通过开发新的验证框架来评估LLMs的能力。

Method: 研究的方法是通过开发数字孪生技术，创建一个游戏理论实验并用特定的模型（包括Llama, Mistral 和 Qwen）进行实验，通过上述模型来测试他们在实人行为模拟中的表现。实验包括了复制和拓展游戏理论的现有实验，同时生成和注册了对新游戏形态的可验证假设。

Result: 结果表明，LLM可以高度复制人类合作模式，并在特定条件下（如Llama模型），甚至可以捕捉到人类偏离理性选择的行为特性。Qwen模型则更倾向于符合纳什均衡的预测。这些模型能够在不使用基于角色的提示的情况下实现总体行为的复制，简化了模拟流程。此外，实验还能探索原本实验设计外的新研究领域。

Conclusion: 总的来说，该研究证明了大型语言模型在适当的校准下可以提供复制总体人类行为模式的能力，这对传统社会科学研究是一种补充，同时也开启了研究人类社会决策行为的新实验空间。

Abstract: Large language models (LLMs) are increasingly used both to make decisions in
domains such as health, education and law, and to simulate human behavior. Yet
how closely LLMs mirror actual human decision-making remains poorly understood.
This gap is critical: misalignment could produce harmful outcomes in practical
applications, while failure to replicate human behavior renders LLMs
ineffective for social simulations. Here, we address this gap by developing a
digital twin of game-theoretic experiments and introducing a systematic
prompting and probing framework for machine-behavioral evaluation. Testing
three open-source models (Llama, Mistral and Qwen), we find that Llama
reproduces human cooperation patterns with high fidelity, capturing human
deviations from rational choice theory, while Qwen aligns closely with Nash
equilibrium predictions. Notably, we achieved population-level behavioral
replication without persona-based prompting, simplifying the simulation
process. Extending beyond the original human-tested games, we generate and
preregister testable hypotheses for novel game configurations outside the
original parameter grid. Our findings demonstrate that appropriately calibrated
LLMs can replicate aggregate human behavioral patterns and enable systematic
exploration of unexplored experimental spaces, offering a complementary
approach to traditional research in the social and behavioral sciences that
generates new empirical predictions about human social decision-making.

</details>


### [79] [Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach](https://arxiv.org/abs/2511.04556)
*Zihang Ding,Kun Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种基于数据驱动的稀疏传感框架(DSS)，结合EPA-SWMM模型，在预算和技术资源有限的情况下，优化传感器部署并重建暴雨系统的峰值径流量，从而实现对城市排水系统的有效监测和流量预测。通过明尼苏达州德卢斯市伍德兰大道流域的案例研究，验证了框架的有效性，仅用三个最优位置的传感器即可实现高精度流量重建，且模型对于测量不确定性和传感器故障表现出良好的鲁棒性。此外，该框架可以整合于预测模型中，实现缺水和监控资源有限时的洪水预警和实时控制功能。


<details>
  <summary>Details</summary>
Motivation: 城市地表水泛滥由于暴雨超出了排水系统的承载能力而频繁发生，这种状况变得越来越普遍。然而，由于时间、预算及技术限制，要实现高时间、空间分辨率的城市洪水预测和监测是有难度的。本研究旨在通过开发一种数据驱动的稀疏传感框架来解决这个问题，以优化传感器部署和重建暴雨流域的峰值径流状态，通过有限的资源实现有效的监测和预报。

Method: 本研究提出了一种结合EPA-SWMM的数据驱动稀疏传感框架。利用SWMM模型生成训练数据集，以生成峰值流速轮廓，并利用该数据来优化传感器位置。该框架运用了奇异值分解进行降维和QR分解进行传感器分配，依据模拟训练数据集确定最优的监测节点。这一方法在明尼苏达州德卢斯的某个流域进行了案例研究。研究中部署3个传感器及其分布结果，通过比较DSS-重建的峰值流速轮廓和SWMM获取的数据的差异，验证了该方法的有效性。同时研究了该方法对于测量不确定性和传感器故障的鲁棒性。

Result: 研究结果表明，通过仅在77个节点中的3个最优位置部署传感器，峰值流速回收能达到较高的精确度，Nash-Sutcliffe效率指数值为0.92-0.95（25到75百分位），显示了可靠且高效的流速回收。进一步显示了模型在不同地点对于测量不确定性和传感器故障都有良好的鲁棒性，并且随着部署传感器数量的增加鲁棒性改进。

Conclusion: 该研究实现了一种结合EPA-SWMM的数据驱动稀疏传感框架，可以用来实现对城市排水系统的有效监测和流量预测，有较好的效果和鲁棒性。该框架在计算效率和物理可解释性之间取得了平衡，从而能够利用最少数量的传感器实现高精度流量重建。此外，该框架能够与预测模型集成，以实现洪水警报和实时控制，特别是在传感器配置有限或运行预算紧张的情况下。

Abstract: Urban surface water flooding, triggered by intense rainfall overwhelming
drainage systems, is increasingly frequent and widespread. While flood
prediction and monitoring in high spatial-temporal resolution are desired,
practical constraints in time, budget, and technology hinder its full
implementation. How to monitor urban drainage networks and predict flow
conditions under constrained resource is a major challenge. This study presents
a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to
optimize sensor placement and reconstruct peak flowrates in a stormwater
system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case
study. We utilized a SWMM model to generate a training dataset of peak flowrate
profiles across the stormwater network. Furthermore, we applied DSS -
leveraging singular value decomposition for dimensionality reduction and QR
factorization for sensor allocation - to identify the optimal monitoring nodes
based on the simulated training dataset. We then validated the
representativeness of these identified monitoring nodes by comparing the
DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three
optimally placed sensors among 77 nodes achieved satisfactory reconstruction
performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to
75th percentiles). In addition, the model showed good robustness to uncertainty
in measurements. Its robustness to sensor failures is location-dependent and
improves with the number of sensors deployed. The framework balances
computational efficiency and physical interpretability, enabling high-accuracy
flow reconstruction with minimal sensors. This DSS framework can be further
integrated with predictive models to realize flood early warning and real-time
control under limited sensing and monitoring resource.

</details>


### [80] [Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis](https://arxiv.org/abs/2511.04584)
*Daniel Gomm,Cornelius Wolff,Madelon Hulsebos*

Main category: cs.AI

TL;DR: 本文提出了一种将查询歧义视为查询双方责任共享的一部分来处理的框架，而不是将其视为缺点。该框架用于评估表格问答和分析，揭示了现有数据集中查询类型的不恰当混杂，强调了合作解决问题的重要性，并为自然语言接口设计提供了新视角和未来研究的方向。


<details>
  <summary>Details</summary>
Motivation: 处理自然语言接口中的查询歧义问题，将其从系统缺陷重新定位为合作交互的一种特征，以此优化表格数据处理能力。

Method: 开发了一种区分合作查询（可以解决的查询）和非合作查询（无法解决的查询）的框架，并通过15个流行数据集的应用，评估了该方法的有效性。

Result: 揭示了不同数据集中查询类型的混杂，展示了该框架在评估和设计自然语言接口系统方面的效能，并指示了未来的研究方向。

Conclusion: 新的框架有助于更好地理解和处理表格数据的自然语言查询，通过认识到歧义处理中的合作特性，可以设计出更加智能和有效的自然语言接口系统。

Abstract: Natural language interfaces to tabular data must handle ambiguities inherent
to queries. Instead of treating ambiguity as a deficiency, we reframe it as a
feature of cooperative interaction, where the responsibility of query
specification is shared among the user and the system. We develop a principled
framework distinguishing cooperative queries, i.e., queries that yield a
resolvable interpretation, from uncooperative queries that cannot be resolved.
Applying the framework to evaluations for tabular question answering and
analysis, we analyze the queries in 15 popular datasets, and observe an
uncontrolled mixing of query types neither adequate for evaluating a system's
execution accuracy nor for evaluating interpretation capabilities. Our
framework and analysis of queries shifts the perspective from fixing ambiguity
to embracing cooperation in resolving queries. This reflection enables more
informed design and evaluation for natural language interfaces for tabular
data, for which we outline implications and directions for future research.

</details>


### [81] [Question the Questions: Auditing Representation in Online Deliberative Processes](https://arxiv.org/abs/2511.04588)
*Soham De,Lodewijk Gelauff,Ashish Goel,Smitha Milli,Ariel Procaccia,Alice Siu*

Main category: cs.AI

TL;DR: 本文介绍了一种衡量代表性水平的审计框架，基于社会选择概念中的正当代表论。它提出了第一个适用于一般效用设置的审计JR的算法。通过将其应用到历史审议中，研究了专家小组实际讨论的问题、ILP选出的问题以及由大型语言模型生成的问题之间的代表性差异。最后，该方法被集成到一个在线审议平台上，使从业者能够审计和改进未来审议的代表性。


<details>
  <summary>Details</summary>
Motivation: 在审议过程中，参与者有机会直接与专家交流，但受到时间限制，只能选择少数问题进行讨论。本文的动机是如何选择能最好代表所有参加者利益的一套问题。为此，引入了基于社会选择理论中的正当代表论的审阅框架来衡量问题的代表性水平。

Method: 本文提出了第一个适用于一般效用设置的审计JR的算法，其中最高效的算法的运行时间为$O(mnlogn)$。方法包括审计和比较由不同方式选择的问题集的代表性水平。

Result: 研究结果表明，不同的方式选取的问题集在代表性上有显著差异，并且展示了大型语言模型在支持审议过程中的潜力与局限性。

Conclusion: 通过将审计方法集成到一个线上审议平台，使得审议过程中的代表性能够得到更好的监控和改进。

Abstract: A central feature of many deliberative processes, such as citizens'
assemblies and deliberative polls, is the opportunity for participants to
engage directly with experts. While participants are typically invited to
propose questions for expert panels, only a limited number can be selected due
to time constraints. This raises the challenge of how to choose a small set of
questions that best represent the interests of all participants. We introduce
an auditing framework for measuring the level of representation provided by a
slate of questions, based on the social choice concept known as justified
representation (JR). We present the first algorithms for auditing JR in the
general utility setting, with our most efficient algorithm achieving a runtime
of $O(mn\log n)$, where $n$ is the number of participants and $m$ is the number
of proposed questions. We apply our auditing methods to historical
deliberations, comparing the representativeness of (a) the actual questions
posed to the expert panel (chosen by a moderator), (b) participants' questions
chosen via integer linear programming, (c) summary questions generated by large
language models (LLMs). Our results highlight both the promise and current
limitations of LLMs in supporting deliberative processes. By integrating our
methods into an online deliberation platform that has been used for over
hundreds of deliberations across more than 50 countries, we make it easy for
practitioners to audit and improve representation in future deliberations.

</details>


### [82] [DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration](https://arxiv.org/abs/2511.04646)
*Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong*

Main category: cs.AI

TL;DR: DR. WELL 是一个用于合作多智能体规划的去中心化神经符号框架，通过两个阶段的协议进行合作：智能体首先提出候选角色，然后在一致性和环境约束下承诺联合分配。在承诺之后，每个智能体独立生成并执行与其角色相关的符号计划，从而避免了脆弱的步级对齐。实验表明，通过动态世界模型，DR. WELL 在执行合作任务时提高了任务完成率和效率，同时适应了不同任务的需要。


<details>
  <summary>Details</summary>
Motivation: 克服多智能体规划中的协调问题，提高任务完成率和执行效率。通过提高抽象级别并提供一套最小的动作指令，使得智能体的行动可以进行同步和集体推进，同时又避免了具体轨迹层面的问题。

Method: 提出了一种叫做DR. WELL的框架，这个框架包含两个阶段:提议和选择阶段，智能体提出可行的角色并达成协同分配；执行阶段，智能体根据分配的角色生成并执行本人的计划。引入了动态世界模型，可以更新当前状态，从而改善了行动的结果。

Result: 通过实验证明，DR. WELL 框架能够改善合作任务的完成率和效率，并且还可以通过自我改进来适应不同的协作策略。这个框架有效地避免了多层次协议中对齐问题，每个智能体则可以在高层面进行相互通信和行动。

Conclusion: DR. WELL 通过提高抽象级别，重新定义了智能体之间合作的层次和方式，证明了合理使用符号计划进行合作的重要性，同时表明了去中心化和自我适应对解决多智能体规划问题的有效性。

Abstract: Cooperative multi-agent planning requires agents to make joint decisions with
partial information and limited communication. Coordination at the trajectory
level often fails, as small deviations in timing or movement cascade into
conflicts. Symbolic planning mitigates this challenge by raising the level of
abstraction and providing a minimal vocabulary of actions that enable
synchronization and collective progress. We present DR. WELL, a decentralized
neurosymbolic framework for cooperative multi-agent planning. Cooperation
unfolds through a two-phase negotiation protocol: agents first propose
candidate roles with reasoning and then commit to a joint allocation under
consensus and environment constraints. After commitment, each agent
independently generates and executes a symbolic plan for its role without
revealing detailed trajectories. Plans are grounded in execution outcomes via a
shared world model that encodes the current state and is updated as agents act.
By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids
brittle step-level alignment and enables higher-level operations that are
reusable, synchronizable, and interpretable. Experiments on cooperative
block-push tasks show that agents adapt across episodes, with the dynamic world
model capturing reusable patterns and improving task completion rates and
efficiency. Experiments on cooperative block-push tasks show that our dynamic
world model improves task completion and efficiency through negotiation and
self-refinement, trading a time overhead for evolving, more efficient
collaboration strategies.

</details>


### [83] [VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks](https://arxiv.org/abs/2511.04662)
*Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala*

Main category: cs.AI

TL;DR: 文章介绍了一种名为VeriCoT的技术，该技术可以提取并验证LLM在思考链过程中产生的逻辑论证，以此来提高推理的准确性和可信度，并在实验中展示了其效果。


<details>
  <summary>Details</summary>
Motivation: LLM在进行多步推理时虽然能通过思考链得到正确答案，但背后的推理过程可能存在缺陷，影响了在高风险场景中的信任，因此需要一种技术来验证这些推理过程的准确性。

Method: VeriCoT技术将每个思考链推理步骤转化为一阶逻辑，并识别出基础论证的前提，同时利用自动求解器验证逻辑正确性，实现了LLM推理过程的验证与改进。此方法还可以用于推理时刻的自我反思、基于VeriCoT提炼数据集的监督微调及使用验证基础成对奖励的偏好微调以进一步提升推理的有效性和准确性。

Result: 实验结果表明，VeriCoT可以有效识别出推理缺陷，并能作为最终答案准确性的强预测指标。此外，使用VeriCoT的验证信号进行一系列操作可以进一步提高推理的合理性和准确性。

Conclusion: VeriCoT提供了一种新的方法来增强大型语言模型的推理能力，特别是它提供了对推理过程的自动验证，这对于提高模型在产生答案时的可信度非常重要。

Abstract: LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but
they cannot reliably verify their own logic. Even when they reach correct
answers, the underlying reasoning may be flawed, undermining trust in
high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a
neuro-symbolic method that extracts and verifies formal logical arguments from
CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order
logic and identifies premises that ground the argument in source context,
commonsense knowledge, or prior reasoning steps. The symbolic representation
enables automated solvers to verify logical validity while the NL premises
allow humans and systems to identify ungrounded or fallacious reasoning steps.
Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT
effectively identifies flawed reasoning, and serves as a strong predictor of
final answer correctness. We also leverage VeriCoT's verification signal for
(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on
VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct
preference optimization (DPO) using verification-based pairwise rewards,
further improving reasoning validity and accuracy.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [84] [On excitation of control-affine systems and its use for data-driven Koopman approximants](https://arxiv.org/abs/2511.03734)
*Philipp Schmitz,Lea Bold,Friedrich M. Philipp,Mario Rosenfelder,Peter Eberhard,Henrik Ebel,Karl Worthmann*

Main category: eess.SY

TL;DR: 本文提出了一种针对控制仿射映射的数据拟合框架，以提高相关系统识别问题的稳健性，并提供了更可靠的双线性EDMD方案。该框架通过基于子空间角度选择输入信号，确保了极小奇异值的阈值，同时给出了最大化极小奇异值的最优性条件的必要和充分条件，并通过非完整机器人的双线性EDMD示例，展示了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 复杂动态系统在建模、分析和控制方面，Koopman算子及其数据驱动逼近方法EDMD引起了广泛的关注。然而，将这些方法应用于控制仿射系统（导致双线性近似模型）会面临苛刻的数据需求，使其应用变得复杂。因此，改进现有方法的稳健性和可靠性是本文的动力。

Method: 本文提出了一种新的框架，通过数据拟合控制仿射映射，提高了双线性EDMD方法的稳健性和可靠性。具体而言，提出了基于子空间角度的选择准则，保证了输入信号的选择能够满足极小奇异值的阈值要求，同时通过数学推导给出了最大化极小奇异值的一个或多个最优性条件。

Result: 通过理论分析和实际案例（非完整机器人的运动控制），本文展示了所提出的方法能够通过合理选择输入信号提高双线性EDMD方法的稳定性和有效性，并增强了系统识别的可靠性。

Conclusion: 本文通过数据拟合框架改进了双线性EDMD方法，增加了该方法在控制仿射系统中的适用性和可靠性，特别是在非完整机器人的控制中得到了验证。

Abstract: The Koopman operator and extended dynamic mode decomposition (EDMD) as a
data-driven technique for its approximation have attracted considerable
attention as a key tool for modeling, analysis, and control of complex
dynamical systems. However, extensions towards control-affine systems resulting
in bilinear surrogate models are prone to demanding data requirements rendering
their applicability intricate. In this paper, we propose a framework for
data-fitting of control-affine mappings to increase the robustness margin in
the associated system identification problem and, thus, to provide more
reliable bilinear EDMD schemes. In particular, guidelines for input selection
based on subspace angles are deduced such that a desired threshold with respect
to the minimal singular value is ensured. Moreover, we derive necessary and
sufficient conditions of optimality for maximizing the minimal singular value.
Further, we demonstrate the usefulness of the proposed approach using bilinear
EDMD with control for non-holonomic robots.

</details>


### [85] [Hybrid ILM-NILM Smart Plug System](https://arxiv.org/abs/2511.03737)
*Dániel István Németh,Kálmán Tornai*

Main category: eess.SY

TL;DR: 本文提出了一种混合负载分类解决方案，通过扩展智能插头解决方案以支持多个负载，从而在降低成本的同时，降低系统的控制粒度。该方法还考虑了家庭中常见的使用延长线连接不同负载的情况。


<details>
  <summary>Details</summary>
Motivation: 传统上，电气负载分类分为侵入式和非侵入式两种方法，各有优缺点。侵入式方法虽然能够实现对单个设备的控制，但安装成本较高；而非侵入式方法安装成本低，但无法实现对设备的控制。因此，本文试图提出一种结合两者的解决方案，以在降低成本和控制粒度之间取得平衡。此外，还考虑了家庭常见的使用延长线连接不同负载的情况。

Method: 本文提出了一种新的混合负载分类解决方案，通过将多个负载连接到单个智能插头上来降低成本，同时避免了传统智能插头方式的高昂安装成本。该方案还处理了使用延长线连接各种负载的情况。具体方法包括硬件设计、负载分类算法等。

Result: 本文的混合负载分类解决方案能够显著降低系统的安装成本，并且在一定程度上保留了对负载的控制能力。此外，该方案还适应了家庭中常用延长线连接不同负载的情况。

Conclusion: 本文提出的混合解决方案为降低成本和保留负载控制提供了一种新的途径，特别是在处理家庭中常见的延长线连接不同负载的情况方面，具有潜在的应用价值。

Abstract: Electrical load classification is generally divided into intrusive and
non-intrusive approaches, both having their limitations and advantages. With
the non-intrusive approach, controlling appliances is not possible, but the
installation cost of a single measurement device is cheap. In comparison,
intrusive, smart plug-based solutions offer individual appliance control, but
the installation cost is much higher. There have been very few approaches
aiming to combine these methods. In this paper we show that extending a smart
plug-based solution to multiple loads per plug can reduce control granularity
in favor of lowering the system's installation costs. Connecting various loads
to a Smart Plug through an extension cord is seldom considered in the
literature, even though it is common in households. This scenario is also
handled by the hybrid load classification solution presented in this paper.

</details>


### [86] [Electric Vehicle Charging Load Modeling: A Survey, Trends, Challenges and Opportunities](https://arxiv.org/abs/2511.03741)
*Xiachong Lin,Arian Prabowo,Imran Razzak,Hao Xue,Matthew Amos,Sam Behrens,Flora D. Salim*

Main category: eess.SY

TL;DR: 本论文回顾了过去五年中电动汽车充电负荷模型的发展，将现有建模方法分为统计、模拟和数据驱动三种，分析了每种方法的优势和不足，并探讨了现有模型在信息融合方面的挑战，为未来研究提供了指导方向和实证研究路径。


<details>
  <summary>Details</summary>
Motivation: 现有的文献综述缺乏对信息融合建模方法的系统性分析，这使得准确预测电动汽车充电行为的难度加大，因此需要对电动汽车充电负荷模型进行系统回顾和分析。

Method: 本文回顾了过去五年中电动汽车充电负荷模型的发展，将现有建模方法分为统计、模拟和数据驱动三种，分析了每种方法的优势和不足，并讨论了现有模型在信息融合方面的三个层次操作。

Result: 分析了当前电动汽车充电负荷模型存在的挑战及未来研究的可能性，为模型设计提供了参考。

Conclusion: 指出电动汽车充电负荷预测以及信息融合建模在处理不确定性时面临的挑战，对未来研究提供指导和实证路径建议。

Abstract: The evolution of electric vehicles (EVs) is reshaping the automotive
industry, advocating for more sustainable transportation practices. Accurately
predicting EV charging behavior is essential for effective infrastructure
planning and optimization. However, the charging load of EVs is significantly
influenced by uncertainties and randomness, posing challenges for accurate
estimation. Furthermore, existing literature reviews lack a systematic analysis
of modeling approaches focused on information fusion. This paper
comprehensively reviews EV charging load models from the past five years. We
categorize state-of-the-art modeling methods into statistical, simulated, and
data-driven approaches, examining the advantages and drawbacks of each.
Additionally, we analyze the three bottom-up level operations of information
fusion in existing models. We conclude by discussing the challenges and
opportunities in the field, offering guidance for future research endeavors to
advance our understanding and explore practical research directions.

</details>


### [87] [A Model-Based Approach to Automated Digital Twin Generation in Manufacturing](https://arxiv.org/abs/2511.03742)
*Angelos Alexopoulos,Agorakis Bompotas,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Athanasios P. Kalogeras,Christos Alexakos*

Main category: eess.SY

TL;DR: 本文提出了一种利用AutomationML工厂计划自动生成和部署数字孪生的平台，并通过GAI驱动的仿真场景生成器和自动物理生产线重组，实现了制造过程的高效和适应性的闭环管理


<details>
  <summary>Details</summary>
Motivation: 现代制造业需要高度的灵活性和重构能力来适应动态的生产需求，模型化工程（MBE）支持生产线的快速设计，但最终重构还需要仿真和验证，数字孪生（DTs）通过实现实时监控、仿真和重组来简化这一过程

Method: 提出了一种新的平台，该平台使用基于AutomationML的工厂计划来自动进行数字孪生的生成和部署，并通过GAI驱动的仿真场景生成器和自动物理生产线重组来完成闭环管理

Result: 该平台通过自动化的数字孪生生成和部署、GAI驱动的仿真场景生成、以及自动物理生产线重组，提高了制造过程的效率和适应性

Conclusion: 研究结论表明，通过将基于AutomationML的工厂计划和GAI技术集成在一个完整的闭环自动化平台中，可以显著提高生产系统的灵活性和效率

Abstract: Modern manufacturing demands high flexibility and reconfigurability to adapt
to dynamic production needs. Model-based Engineering (MBE) supports rapid
production line design, but final reconfiguration requires simulations and
validation. Digital Twins (DTs) streamline this process by enabling real-time
monitoring, simulation, and reconfiguration. This paper presents a novel
platform that automates DT generation and deployment using AutomationML-based
factory plans. The platform closes the loop with a GAI-powered simulation
scenario generator and automatic physical line reconfiguration, enhancing
efficiency and adaptability in manufacturing.

</details>


### [88] [Predictive Compensation in Finite-Horizon LQ Games under Gauss-Markov Deviations](https://arxiv.org/abs/2511.03744)
*Navid Mojahed,Mahdis Rabbani,Shima Nazari*

Main category: eess.SY

TL;DR: 本文提出了一种预测补偿框架，用于存在Gauss-Markov偏离的有限时间离散线性二次动态博弈。一个玩家经历相关随机偏离，另一个玩家使用预测策略进行补偿。推导了均值和协方差的闭合形式递归，并分析了期望成本的敏感性以评估性能改进。


<details>
  <summary>Details</summary>
Motivation: 研究存在Gauss-Markov偏差时，离散线性二次动态博弈的预测补偿策略，以改善博弈参与者的性能表现。

Method: 通过建立一个预测补偿框架，考虑一个玩家的相关随机性，并推导出均值和协方差的闭合形式递归。

Result: 推导出均值和协方差的闭合形式递归，并通过期望成本的敏感性分析显示了性能改进。

Conclusion: 预测补偿框架能够有效改善存在Gauss-Markov偏差时动态博弈的性能。

Abstract: This paper presents a predictive compensation framework for finite-horizon
discrete-time linear quadratic dynamic games in the presence of Gauss-Markov
deviations from feedback Nash strategies. One player experiences correlated
stochastic deviations, modeled via a first-order autoregressive process, while
the other compensates using a predictive strategy that anticipates the effect
of future correlation. Closed-form recursions for mean and covariance
propagation are derived, and the resulting performance improvement is analyzed
through the sensitivity of expected cost.

</details>


### [89] [InvSim algorithm for pre-computing airplane flight controls in limited-range autonomous missions, and demonstration via double-roll maneuver of Mirage III fighters](https://arxiv.org/abs/2511.03745)
*Osama A. Marzouk*

Main category: eess.SY

TL;DR: 本文提出了一种基于六自由度飞行动力学通用数学框架的逆向飞行仿真方法，用于预测实现给定飞行轨迹所需的控制变量。通过符号数学、显式四阶龙格-库塔法和基于有限差分法的表达式，计算出四个必要的控制变量（推力、副翼偏转、升降舵偏转和方向舵偏转），以实现所要求的飞行路径。


<details>
  <summary>Details</summary>
Motivation: 建立一种适用于逆向飞行仿真的数学框架，以便预测实现特定飞行轨迹所需的最佳飞行控制策略，从而提高飞行操纵性能和优化航迹跟踪准确性。

Method: 首先建立了一个六自由度的飞行动力学数学框架；然后以此为基础，开发了一种逆向模拟（InvSim）系统，可以计算连续的控制输入以实现预定的飞行轨迹；最后使用符号数学和显式的龙格-库塔法进行数值积分。

Result: 提出了一种新方法，该方法可以计算出使飞机遵循预期的飞行轨迹所需的控制变量。这项技术通过控制变量的精确计算和动态调整，能够更准确地预测和实现期望的飞行路径。

Conclusion: 本文提出的方法为逆向模拟系统提供了一个强大的工具，能够预测和实现所需飞行轨迹的控制变量。这些结果对于飞行仿真、飞行器设计和操纵性能优化具有重要意义。

Abstract: In this work, we start with a generic mathematical framework for the
equations of motion (EOM) in flight mechanics with six degrees of freedom
(6-DOF) for a general (not necessarily symmetric) fixed-wing aircraft. This
mathematical framework incorporates (1) body axes (fixed in the airplane at its
center of gravity), (2) inertial axes (fixed in the earth/ground at the
take-off point), wind axes (aligned with the flight path/course), (3) spherical
flight path angles (azimuth angle measured clockwise from the geographic north,
and elevation angle measured above the horizon plane), and (4) spherical flight
angles (angle of attack and sideslip angle). We then manipulate these equations
of motion to derive a customized version suitable for inverse simulation flight
mechanics, where a target flight trajectory is specified while a set of
corresponding necessary flight controls to achieve that maneuver are predicted.
We then present a numerical procedure for integrating the developed inverse
simulation (InvSim) system in time; utilizing (1) symbolic mathematics, (2)
explicit fourth-order Runge-Kutta (RK4) numerical integration technique, and
(3) expressions based on the finite difference method (FDM); such that the four
necessary control variables (engine thrust force, ailerons' deflection angle,
elevators' deflection angle, and rudder's deflection angle) are computed as
discrete values over the entire maneuver time, and these calculated control
values enable the airplane to achieve the desired flight trajectory, which is
specified by three inertial Cartesian coordinates of the airplane, in addition
to the Euler's roll angle. We finally demonstrate the proposed numerical
procedure of flight mechanics inverse simulation (InvSim).

</details>


### [90] [Analytical modelling of a stop-less modular bus service with an application to charging strategies comparison](https://arxiv.org/abs/2511.03754)
*Haoran Zhao,Neema Nassir,Andres Fielbaum*

Main category: eess.SY

TL;DR: 研究通过分析集成V2V充电技术的SLAM公交服务的优化模型，发现了从低需求到高需求的运行阶段，这有助于操作者提供更高效的公交服务。


<details>
  <summary>Details</summary>
Motivation: 传统公交车服务存在效率问题，包括停站时间长。一种无停站的自动驾驶模块化（SLAM）公交服务已被提出作为解决方案，研究旨在通过集成车辆间充电技术来进一步优化这种服务。

Method: 建立了分析优化模型，比较不同运行场景下的最优设计和可行性，探讨了从低需求到高需求的运营阶段。

Result: 发现了在无充电场景和移动充电策略下，不同的运行阶段和对应的最优设计。识别了SLAM公交车服务的运行阶段序列，提出了独特的频率限制模式。在高需求下，即使在移动充电策略下也可能出现不可行性。

Conclusion: 这些结果帮助操作者提供更高效的公交车服务，并且展示了V2V充电技术如何影响SLAM公交服务的操作。

Abstract: Buses are a vital component of metropolitan public transport, yet
conventional bus services often struggle with inefficiencies including extended
dwelling time, which increases in-vehicle travel time for non-alighting
passengers. A stop-less autonomous modular (SLAM) bus service has emerged as a
solution, enabling dynamic capacity to reduce dwelling time. Meanwhile, the
electrification of buses is advancing as a strategy to mitigate greenhouse gas
emissions and reduces operators' costs, but introduces new operational
constraints due to charging requirements. This study develops analytical
optimization models for SLAM bus service that integrates vehicle-to-vehicle
(V2V) charging technology. By comparing the optimal designs and their
feasibility across non-charging case and charging strategies, we identify a
sequence of operational stages as ridership grows: from idle capacity under low
demand, to full small buses, full large buses, and a proposed frequency-capped
regime where only bus capacity expands. Under the mobile charging strategy,
this progression further includes an energy-limited regime, in which frequency
declines, and ultimately infeasibility under high demand. These findings enable
operators to deliver more efficient services.

</details>


### [91] [Removing Time-Scale Separation in Feedback-Based Optimization via Estimators](https://arxiv.org/abs/2511.03903)
*Niloufar Yousefi,John W. Simpson-Porco*

Main category: eess.SY

TL;DR: 提出了基于估计器的FBO方法，利用动态模型信息消除了传统FBO所需的时间尺度分离要求，提升了系统的闭环性能，特别是在使用近似模型进行系统设计时也能保证性能。该方法通过一个实际的快速电力系统频率控制应用进行了验证。


<details>
  <summary>Details</summary>
Motivation: 传统FBO方法的闭环稳定性需要控制器运行在比植物系统更慢的时间尺度上，这对闭环性能产生了显著限制。因此，提出了基于估计器的FBO方法来解决这一问题。 

Method: 引入了一个基于动态模型信息的估计器，使其能够消除传统FBO所需的时间尺度分离要求，并且在原始系统是奇摄动系统的情况下，通过近似模型进行设计也能保证性能。

Result: 该方法的闭环系统收敛速度仅受开环系统主要特征值限制，同时，通过快速电力系统频率控制的应用实例说明了该方法的有效性。

Conclusion: 通过使用基于估计器的FBO方法，消除了传统FBO方法的时间尺度分离要求，提高了闭环系统的性能，特别适用于使用近似模型进行设计的情况。

Abstract: Feedback-based optimization (FBO) provides a simple control framework for
regulating a stable dynamical system to the solution of a constrained
optimization problem in the presence of exogenous disturbances, and does so
without full knowledge of the plant dynamics. However, closed-loop stability
requires the controller to operate on a sufficiently slower timescale than the
plant, significantly constraining achievable closed-loop performance. Motivated
by this trade-off, we propose an estimator-based modification of FBO which
leverages dynamic plant model information to eliminate the time-scale
separation requirement of traditional FBO. Under this design, the convergence
rate of the closed-loop system is limited only by the dominant eigenvalue of
the open-loop system. We extend the approach to the case of design based on
only an approximate plant model when the original system is singularly
perturbed. The results are illustrated via an application to fast power system
frequency control using inverter-based resources.

</details>


### [92] [A Co-simulation Framework for Quadrotor Control System Design using ROS 2 and MATLAB/Simulink](https://arxiv.org/abs/2511.03969)
*Hangyu Teng*

Main category: eess.SY

TL;DR: 本文提出了一种基于ROS 2和MATLAB/Simulink的协同仿真框架，用于四旋翼无人机控制系统的开发和验证。该框架有效展示了其在无人机控制算法快速原型开发和软硬件在环验证中的高效标准化解决方案能力。


<details>
  <summary>Details</summary>
Motivation: 由于复杂系统的开发和分析中协同仿真的重要性，本文旨在通过引入ROS 2和MATLAB/Simulink的协同仿真框架，提升开发效率并减少成本，尤其是在四旋翼无人机控制系统的设计和验证方面展示其有效性。

Method: 首先，通过牛顿-欧拉方程推导出四旋翼无人机的六自由度非线性动态模型；其次，设计并实现了一个分层控制架构，通过状态反馈LQR控制器进行姿态控制，通过PID控制器进行位置控制，实现最优调节和鲁棒性；最后，详细描述该框架的架构，包括跨平台数据交换机制的实现细节。

Result: 仿真实验结果证实了该框架的有效性，表现出在无人机控制算法快速原型开发和软硬件在环验证中的高效和标准化解决方案的能力。

Conclusion: 基于ROS 2和MATLAB/Simulink的协同仿真框架为四旋翼无人机系统的控制算法开发和验证提供了有效的工具，展示了其在复杂系统开发中的潜在价值。

Abstract: Co-simulation is a critical approach for the design and analysis of complex
cyber-physical systems. It will enhance development efficiency and reduce
costs. This paper presents a co-simulation framework integrating ROS 2 and
MATLAB/Simulink for quadrotor unmanned aerial vehicle (UAV) control system
design and verification. First, a six-degree-of-freedom nonlinear dynamic model
of the quadrotor is derived accurately that based on Newton-Euler equations.
Second, within the proposed framework, a hierarchical control architecture was
designed and implemented: LQR controller for attitude control to achieve
optimal regulation performance, and PID controller for position control to
ensure robustness and practical applicability. Third, elaborated the
architecture of the framework, including the implementation details of the
cross-platform data exchange mechanism. Simulation results demonstrate the
effectiveness of the framework, highlighting its capability to provide an
efficient and standardized solution for rapid prototyping and
Software-in-the-Loop (SIL) validation of UAV control algorithms.

</details>


### [93] [Necessary and Sufficient Conditions for the Optimization-Based Concurrent Execution of Learned Robotic Tasks](https://arxiv.org/abs/2511.04054)
*Sheikh A. Tahmid,Gennaro Notomista*

Main category: eess.SY

TL;DR: 本文提出了用于同时执行由价值函数编码的多个任务的一个优化框架，并提供了关于这些任务在状态空间的子集内可以同时执行的必要和充分条件的定理。此外，还扩展了该框架以考虑具有折扣因子的价值函数，使其与标准的强化学习实践兼容。


<details>
  <summary>Details</summary>
Motivation: 现有的研究已经在开发执行多个任务的优化框架，但还没有解决如何同时执行通过强化学习学习到的价值函数表示的任务的问题。本文旨在填补这一空白，提供同时执行任务的理论基础，并增强框架的适用性。

Method: 本文通过提出定理来解决如何在状态空间的子集中同时执行任务的问题，并且开发了将折扣因子纳入价值函数的扩展方法。

Result: 研究提出了关于任务可以、已经可以、或是不可以变成并发执行的理论条件，并扩展了框架来确保其与带有折扣因子的常规强化学习兼容。

Conclusion: 这些发现为如何在复杂任务中实现高效并发执行提供了理论依据，并改善了当前强化学习方法的有效性和实用性。

Abstract: In this work, we consider the problem of executing multiple tasks encoded by
value functions, each learned through Reinforcement Learning, using an
optimization-based framework. Prior works develop such a framework, but left
unanswered a fundamental question of when learned value functions can be
concurrently executed. The main contribution of this work is to present
theorems which provide necessary and sufficient conditions to concurrently
execute sets of learned tasks within subsets of the state space, using a
previously proposed min-norm controller. These theorems provide insight into
when learned control tasks are possible to be made concurrently executable,
when they might already inherently be concurrently executable and when it is
not possible at all to make a set of learned tasks concurrently executable
using the previously proposed methods. Additional contributions of this work
include extending the optimization-based framework to execute multiple tasks
encoded by value functions to also account for value functions trained with a
discount factor, making the overall framework more compatible with standard RL
practices.

</details>


### [94] [Differential Flatness of Quasi-Static Slider-Pusher Models with Applications in Control](https://arxiv.org/abs/2511.04246)
*Sander De Witte,Tom Lefebvre,Thomas Neve,Andras Retzler,Guillaume Crevecoeur*

Main category: eess.SY

TL;DR: 本文研究了平面滑块-推块系统作为操作任务中的运动原语的动力学特性。建立了基于极限面方法的微分运动学模型，并在此基础上分析了系统的可展性，提出了两种轨迹跟踪控制策略，并通过仿真和实验验证了这些策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究平面滑块-推块系统作为操作任务中的一种基本运动形式的动力学特性，建立用于控制和规划的微分运动学模型，以提高系统性能和灵活性。

Method: 通过极限面方法建立了该系统的微分运动学模型，并证明了其可展性；基于可展性，提出了两种不同的轨迹跟踪控制策略。

Result: 理论分析和实验结果均表明所提出的控制策略有效，具有良好的跟踪性能和鲁棒性。

Conclusion: 研究表明设计的微分运动学模型和控制策略对于平面滑块-推块系统具有重要的适用性和可操作性，为实际应用提供了理论基础和实验支持。

Abstract: This paper investigates the dynamic properties of planar slider-pusher
systems as a motion primitive in manipulation tasks. To that end, we construct
a differential kinematic model deriving from the limit surface approach under
the quasi-static assumption and with negligible contact friction. The
quasi-static model applies to generic slider shapes and circular pusher
geometries, enabling a differential kinematic representation of the system.
From this model, we analyze differential flatness - a property advantageous for
control synthesis and planning - and find that slider-pusher systems with
polygon sliders and circular pushers exhibit flatness with the centre of mass
as a flat output. Leveraging this property, we propose two control strategies
for trajectory tracking: a cascaded quasi-static feedback strategy and a
dynamic feedback linearization approach. We validate these strategies through
closed-loop simulations incorporating perturbed models and input noise, as well
as experimental results using a physical setup with a finger-like pusher and
vision-based state detection. The real-world experiments confirm the
applicability of the simulation gains, highlighting the potential of the
proposed methods for

</details>


### [95] [ComEMS4Build: Comfort-Oriented Energy Management System for Residential Buildings using Hydrogen for Seasonal Storage](https://arxiv.org/abs/2511.04293)
*Jovana Kovačević,Felix Langner,Erfan Tajalli-Ardekani,Marvin Dorn,Simon Waczowicz,Ralf Mikut,Jörg Matthes,Hüseyin K. Çakmak,Veit Hagenmeyer*

Main category: eess.SY

TL;DR: 提出了一个适用于住宅建筑的基于模糊逻辑的舒适导向能源管理系统(ComEMS4Build)，结合了光伏、电池储能系统和氢气存储系统，并且考虑了与热泵的耦合，以减少氢气系统规模。在德国冬季12周的时间内对该系统进行了半合成模型评估，展示了该系统在不降低住户舒适度的同时，能有效降低能源成本和电网能源交换。但是，在燃料电池的操作中，传统的Rule-Based Control(RBC)表现更好，减少了开关次数以及运行时间。


<details>
  <summary>Details</summary>
Motivation: 引入Hydrogen (H2)存储系统和新的能源管理方法以提高住宅能源分配效率，适应季节性可再生能源分布。同时通过与Heat Pump (HP)的集成，降低成本，提高氢气存储系统的效率

Method: 发展了基于模糊逻辑的舒适导向能源管理系统(ComEMS4Build)，在这个系统中，光伏板、电池储能系统和氢气储能系统以及其他相关设备都被集成到了住宅建筑中。并将其与成本最优的Model Predictive Control (MPC)和简单控制策略的Rule-Based Control (RBC)进行比较

Result: 实验结果证明，ComEMS4Build在提升用户舒适度和节能目标间取得了较好的平衡。虽然与模型预测控制(MPC)相比，ComEMS4Build每周多增加12.06欧元的电费，但相比简单的Rule-Based Control(RBC)仍减少了30.14欧元的费用

Conclusion: 模糊逻辑导向的能源管理系统是提升住宅领域能源利用效率、应对季节变化带来的挑战的可行且有效的方法。同时，通过与Heat Pump的组合使用，可以显著降低高成本的Hydrogen存储系统的规模

Abstract: Integrating flexible loads and storage systems into the residential sector
contributes to the alignment of volatile renewable generation with demand.
Besides batteries serving as a short-term storage solution, residential
buildings can benefit from a Hydrogen (H2) storage system, allowing seasonal
shifting of renewable energy. However, as the initial costs of H2 systems are
high, coupling a Fuel Cell (FC) with a Heat Pump (HP) can contribute to the
size reduction of the H2 system. The present study develops a Comfort-Oriented
Energy Management System for Residential Buildings (ComEMS4Build) comprising
Photovoltaics (PV), Battery Energy Storage System (BESS), and H2 storage, where
FC and HP are envisioned as complementary technologies. The fuzzy-logic-based
ComEMS4Build is designed and evaluated over a period of 12 weeks in winter for
a family household building in Germany using a semi-synthetic modeling
approach. The Rule-Based Control (RBC), which serves as a lower benchmark, is a
scheduler designed to require minimal inputs for operation. The Model
Predictive Control (MPC) is intended as a cost-optimal benchmark with an ideal
forecast. The results show that ComEMS4Build, similar to MPC, does not violate
the thermal comfort of occupants in 10 out of 12 weeks, while RBC has a
slightly higher median discomfort of 0.68 Kh. The ComEMS4Build increases the
weekly electricity costs by 12.06 EUR compared to MPC, while RBC increases the
weekly costs by 30.14 EUR. The ComEMS4Build improves the Hybrid Energy Storage
System (HESS) utilization and energy exchange with the main grid compared to
the RBC. However, when it comes to the FC operation, the RBC has an advantage,
as it reduces the toggling counts by 3.48% and working hours by 7.59% compared
to MPC...

</details>


### [96] [Data-Driven Modeling of Photosynthesis Regulation Under Oscillating Light Condition - Part I: In-Silico Exploration](https://arxiv.org/abs/2511.04330)
*Christian Portilla,Arviandy G Aribowo,Ramachandran Anantharaman,César A Gómez-Pérez,Leyla Özkan*

Main category: eess.SY

TL;DR: 该论文探讨了在频率域内应用数据驱动的系统辨识技术来获取光合作用在振荡光照条件下的简化、可控模型。通过对基础DREAM模型的仿真生成数据，运用最佳线性近似法估计在不同操作条件下（由光强度的直流和调制频率定义）的二阶线性时不变模型，并构建基于直流光照强度的线性参数可变模型，提供了系统的紧凑状态空间表示法。



<details>
  <summary>Details</summary>
Motivation: 该论文旨在通过数据驱动的方法获取光合作用在不同光照条件下简化、可控的数学模型，以便更好地理解和控制这一复杂的生物学过程。


Method: 使用基础DREAM模型仿真生成数据，通过最佳线性近似法（BLA）估计二阶线性时不变（LTI）模型，并基于直流光照强度构建线性参数可变（LPV）模型。


Result: 成功地构建了不同光照条件下光合作用的简化数学模型，并提供了一种紧凑的状态空间表示方法。


Conclusion: 该研究证明了数据驱动方法在获取复杂生物过程简化模型方面的有效性，为进一步研究提供了基础。


Abstract: This paper explores the application of data-driven system identification
techniques in the frequency domain to obtain simplified, control-oriented
models of photosynthesis regulation under oscillating light conditions.
In-silico datasets are generated using simulations of the physics-based Basic
DREAM Model (BDM) Funete et al.[2024], with light intensity signals --
comprising DC (static) and AC (modulated) components as input and chlorophyll
fluorescence (ChlF) as output. Using these data, the Best Linear Approximation
(BLA) method is employed to estimate second-order linear time-invariant (LTI)
transfer function models across different operating conditions defined by DC
levels and modulation frequencies of light intensity. Building on these local
models, a Linear Parameter-Varying (LPV) representation is constructed, in
which the scheduling parameter is defined by the DC values of the light
intensity, providing a compact state-space representation of the system
dynamics.

</details>


### [97] [Overview and Performance Evaluation of Supervisory Controller Synthesis with Eclipse ESCET v4.0](https://arxiv.org/abs/2511.04370)
*Dennis Hendriks,Michel Reniers,Wan Fokkink,Wytse Oortwijn*

Main category: eess.SY

TL;DR: 本文介绍了CIF的符号监督控制器合成算法，包括防止运行时错误、处理不同类型的需求和支持输入变量等方面。同时，文章介绍了CIF的基准模型，这是一系列包含23个不同规模和复杂程度的工业和学术模型。此外，还评估了ESCET从v0.8到v4.0版本的改进，展示了当前CIF的合成性能。最后，文章探讨了多级合成的增益，并指出尽管这种非单片合成方法有助于进一步提高合成性能，但仍需进一步改进以合成复杂模型。


<details>
  <summary>Details</summary>
Motivation: 文章的动机在于介绍CIF的符号监督控制器合成算法，以及ESCET工具集的改进，特别是在防止运行时错误、处理不同类型的需求和支持输入变量方面，展示其在工业和学术模型上的应用和性能。

Method: 文中首先介绍了CIF的符号监督控制器合成算法，其次介绍了CIF的基准模型，然后评估了ESCET从v0.8到v4.0版本的改进对合成性能的影响，最后探讨了多级合成的增益。

Result: 研究结果显示了CIF的当前合成性能，并指出在合成复杂模型方面仍需进一步改善。

Conclusion: 文章总结了CIF在符号监督控制器合成方面的工作以及ESCET工具集的性能改进，强调了多级合成方法在提高合成性能上的潜力，但也提出了解决复杂模型合成问题的挑战。

Abstract: Supervisory controllers control cyber-physical systems to ensure their
correct and safe operation. Synthesis-based engineering (SBE) is an approach to
largely automate their design and implementation. SBE combines model-based
engineering with computer-aided design, allowing engineers to focus on 'what'
the system should do (the requirements) rather than 'how' it should do it
(design and implementation). In the Eclipse Supervisory Control Engineering
Toolkit (ESCET) open-source project, a community of users, researchers, and
tool vendors jointly develop a toolkit to support the entire SBE process,
particularly through the CIF modeling language and tools. In this paper, we
first provide a description of CIF's symbolic supervisory controller synthesis
algorithm, and thereby include aspects that are often omitted in the
literature, but are of great practical relevance, such as the prevention of
runtime errors, handling different types of requirements, and supporting input
variables (to connect to external inputs). Secondly, we introduce and describe
CIF's benchmark models, a collection of 23 freely available industrial and
academic models of various sizes and complexities. Thirdly, we describe recent
improvements between ESCET versions v0.8 (December 2022) and v4.0 (June 2024)
that affect synthesis performance, evaluate them on our benchmark models, and
show the current practical synthesis performance of CIF. Fourthly, we briefly
look at multi-level synthesis, a non-monolithic synthesis approach, evaluate
its gains, and show that while it can help to further improve synthesis
performance, further performance improvements are still needed to synthesize
complex models.

</details>


### [98] [Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear System with Input Delay](https://arxiv.org/abs/2511.04451)
*Patrik Valábek,Marek Wadinger,Michal Kvasnica,Martin Klaučo*

Main category: eess.SY

TL;DR: 本文提出了一种新的LSTM增强的Deep Koopman模型，用于近似Koopman算子，从而可以在时间延迟存在的情况下对非线性系统进行线性表示。该方法在预测准确性上超越了传统方法，并且在系统动态未知的情况下表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的线性控制技术在处理输入延迟的非线性系统时效果不佳，因此需要创新的方法来改善预测、估计和控制能力。

Method: 本文引入了一种LSTM增强的Deep Koopman模型，该模型使用LSTM层来捕获历史依赖性并高效地将时滞系统动态编码成潜在空间。这种方法是无字典的，避免了传统方法中对已知动态的依赖问题。

Result: 在模拟系统上的定量比较中，本文的方法在非线性系统动态未知的情况下，显示出显著的预测精度增益。即使在系统动态已知的情况下，该方法也能够获得与传统方法相当的结果。

Conclusion: LSTM增强的Deep Koopman模型为解决非线性系统输入延迟的问题提供了一种有效的解决方案，能够显著提高预测准确性。

Abstract: Nonlinear dynamical systems with input delays pose significant challenges for
prediction, estimation, and control due to their inherent complexity and the
impact of delays on system behavior. Traditional linear control techniques
often fail in these contexts, necessitating innovative approaches. This paper
introduces a novel approach to approximate the Koopman operator using an
LSTM-enhanced Deep Koopman model, enabling linear representations of nonlinear
systems with time delays. By incorporating Long Short-Term Memory (LSTM)
layers, the proposed framework captures historical dependencies and efficiently
encodes time-delayed system dynamics into a latent space. Unlike traditional
extended Dynamic Mode Decomposition (eDMD) approaches that rely on predefined
dictionaries, the LSTM-enhanced Deep Koopman model is dictionary-free, which
mitigates the problems with the underlying dynamics being known and
incorporated into the dictionary. Quantitative comparisons with extended eDMD
on a simulated system demonstrate highly significant performance gains in
prediction accuracy in cases where the true nonlinear dynamics are unknown and
achieve comparable results to eDMD with known dynamics of a system.

</details>


### [99] [Data-driven uncertainty-aware seakeeping prediction of the Delft 372 catamaran using ensemble Hankel dynamic mode decomposition](https://arxiv.org/abs/2511.04461)
*Giorgio Palma,Andrea Serani,Matteo Diez*

Main category: eess.SY

TL;DR: 本文提出并验证了一种基于Hankel动态模式分解的聚类方法(HDMDc)，用于基于不确定性感知的高速双体船的航行预测。通过对实验数据的分析，发现FHDMDc方法能显著提高预测精度，并且能够提供稳健的不确定性估计，与实验数据和URANS结果的运动概率密度函数匹配良好，证明了该方法在设计和运营支持方面的可靠性和计算效率；而BHDMDc方法在本案例中并未优于确定性模型。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为了提高高速双体船在复杂波浪条件下的航行预测准确性，特别是在不确定性较大的情况下，提出了一种新的不确定感知的航行预测方法。

Method: 本文采用了一种基于Hankel动态模式分解的聚类算法(HDMDc)，通过引入时间滞后的状态和输入来捕捉非线性和记忆效应。同时，应用两种集群策略：Bayesian HDMDc (BHDMDc) 和Frequentist HDMDc (FHDMDc) 来提供航行预测和不确定性量化。这些方法用于1:33.3比例的Delft 372模型的不规则波浪盆测试数据来验证模型的有效性。

Result: 与确定性模型相比，FHDMDc方法在航行预测上更准确，能够提供可靠的不确定性估计，与实验数据及URANS结果吻合良好；而BHDMDc方法并没有展现出优于确定性模型的效果。

Conclusion: 研究表明，FHDMDc方法在不确定性感知的航行预测中显示出极大的潜力，既可以提供准确的预测结果，又可以有效地评估预测的不确定性，是船体设计和运营支持的一个强大工具。

Abstract: In this study, we present and validate an ensemble-based Hankel Dynamic Mode
Decomposition with control (HDMDc) for uncertainty-aware seakeeping predictions
of a high-speed catamaran, namely the Delft 372 model. Experimental
measurements (time histories) of wave elevation at the longitudinal center of
gravity, heave, pitch, notional flight-deck velocity, notional bridge
acceleration, and total resistance were collected from irregular wave basin
tests on a 1:33.3 scale replica of the Delft 372 model under sea state 5
conditions at Fr = 0.425, and organized into training, validation, and test
sets. The HDMDc algorithm constructs an equation-free linear reduced-order
model of the seakeeping vessel by augmenting states and inputs with their
time-lagged copies to capture nonlinear and memory effects. Two ensembling
strategies, namely Bayesian HDMDc (BHDMDc), which samples hyperparameters
considered stochastic variables with prior distribution to produce posterior
mean forecasts with confidence intervals, and Frequentist HDMDc (FHDMDc), which
aggregates multiple model obtained over data subsets, are compared in providing
seakeeping prediction and uncertainty quantification. The FHDMDc approach is
found to improve the accuracy of the predictions compared to the deterministic
counterpart, also providing robust uncertainty estimation; whereas the
application of BHDMDc to the present test case is not found beneficial in
comparison to the deterministic model. FHDMDc-derived probability density
functions for the motions closely match both experimental data and URANS
results, demonstrating reliable and computationally efficient seakeeping
prediction for design and operational support.

</details>


### [100] [Synchronous Observer Design for Landmark-Inertial SLAM with Almost-Global Convergence](https://arxiv.org/abs/2511.04531)
*Arkadeep Saha,Pieter van Goor,Antonio Franchi,Ravi Banavar*

Main category: eess.SY

TL;DR: 本文提出了一个针对地标惯性同时定位与地图构建（LI-SLAM）问题的非线性观测器，并在基础空间中分析了观测器，证明了误差动力学的局部指数稳定性和几乎全局渐近稳定性，并通过仿真验证了这些结论。


<details>
  <summary>Details</summary>
Motivation: 解决地标惯性同时定位与地图构建（LI-SLAM）问题，提出一种非线性观测器，该观测器在基础空间中分析，可以利用地标位置测量和惯性测量单元（IMU）数据估计地标位置和机器人相对位置。

Method: 提出了一种在连续时间下针对LI-SLAM问题的非线性观测器，并在编码所有可观察状态的基础空间中分析了该观测器。通过证明局部指数稳定性和几乎全局渐近稳定性来验证方法的有效性，并通过仿真验证了理论分析。

Result: 证明了在基础空间中误差动力学的局部指数稳定性和几乎全局渐近稳定性，并通过仿真验证了这些稳定性。

Conclusion: 提出了一种新的针对LI-SLAM问题的非线性观测器，通过理论分析和仿真验证，证明了该方法的有效性和稳定性。

Abstract: Landmark Inertial Simultaneous Localisation and Mapping (LI-SLAM) is the
problem of estimating the locations of landmarks in the environment and the
robot's pose relative to those landmarks using landmark position measurements
and measurements from Inertial Measurement Unit (IMU). This paper proposes a
nonlinear observer for LI-SLAM posed in continuous time and analyses the
observer in a base space that encodes all the observable states of LI-SLAM. The
local exponential stability and almost-global asymptotic stability of the error
dynamics in base space is established in the proof section and validated using
simulations.

</details>


### [101] [Control Affine Hybrid Power Plant Subsystem Modeling for Supervisory Control Design](https://arxiv.org/abs/2511.04644)
*Stephen Ampleman,Himanshu Sharma,Sayak Mukherjee,Sonja Glavaski*

Main category: eess.SY

TL;DR: 本文提出了一种用于混合动力发电厂的建模和控制设计框架，该发电厂由风电场、太阳能发电厂和电池储能系统组成。通过非线性控制和控制障碍函数技术开发了控制律，以跟踪来自监管控制律的指令，同时保持安全稳定运行。该模型和控制框架的实用性通过一个测试案例得到了证明，该案例使用了公用需求信号、波动的风速和日照数据以及基于规则的监管控制律。


<details>
  <summary>Details</summary>
Motivation: 混合动力发电厂结合了多种发电单元（传统/可变）和储能能力，以支持发电不足和电网需求。本文的目的是为混合动力发电厂开发一种建模和控制设计框架。

Method: 本文适应了现有的风电场、太阳能发电场和电池模型，使它们适用于监管级别控制设计。具体来说，通过非线性控制和控制障碍函数技术开发了发电机扭矩和电池电流的控制律。

Result: 该建模和控制框架通过一个测试案例得到了证明，该案例中使用了波动的风速和日照数据以及基于规则的监管控制律，展示了系统的实用性。

Conclusion: 所提出的建模和控制设计框架为混合动力发电厂提供了一种有效的方法，可以保持稳定运行并满足动态需求。

Abstract: Hybrid power plants (HPPs) combine multiple power generators
(conventional/variable) and energy storage capabilities to support generation
inadequacy and grid demands. This paper introduces a modeling and control
design framework for hybrid power plants (HPPs) consisting of a wind farm,
solar plant, and battery storage. Specifically, this work adapts established
modeling paradigms for wind farms, solar plants and battery models into a
control affine form suitable for control design at the supervisory level. In
the case of wind and battery models, generator torque and cell current control
laws are developed using nonlinear control and control barrier function
techniques to track a command from a supervisory control law while maintaining
safe and stable operation. The utility of this modeling and control framework
is illustrated through a test case using a utility demand signal for tracking,
time varying wind and irradiance data, and a rule-based supervisory control
law.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [102] [Reconstruction-free segmentation from undersampled k-space using transformers](https://arxiv.org/abs/2511.03762)
*Yundi Zhang,Nil Stolt-Ansó,Jiazhen Pan,Wenqi Huang,Kerstin Hammernik,Daniel Rueckert*

Main category: eess.IV

TL;DR: 论文提出了一种直接从稀疏k空间测量中进行心脏分割的方法，而不需要中间的图像重建步骤，这在高加速因子下比基于图像的分割方法表现更好。


<details>
  <summary>Details</summary>
Motivation: 高加速因子限制了MRI图像重建，而将这些过程看作是独立的后续过程也限制了分割模型的应用范围。目标是直接从稀疏的k空间测量中生成分割结果，而不需要依赖于中间的图像重建。 

Method: 论文采用了一种Transformer架构，用于编码全局k空间的信息到潜在特征，并利用这些潜在向量在解码过程中对外查询的坐标进行条件化，以生成分割类别概率。这种方法使得模型能够从稀疏的k空间采样直接生成心脏分割结果，而不依赖于中间步骤的图像重建。

Result: 在高加速因子条件下，该模型的分割效果优于基于图像的分割基准模型。

Conclusion: 心脏分割直接从欠采样的k空间样本中进行，绕过了中间的图像重建步骤，从而能够在更高的加速因子上评估心肌的结构与功能，这比需要图像输入的方法更具有优势。

Abstract: Motivation: High acceleration factors place a limit on MRI image
reconstruction. This limit is extended to segmentation models when treating
these as subsequent independent processes.
  Goal: Our goal is to produce segmentations directly from sparse k-space
measurements without the need for intermediate image reconstruction.
  Approach: We employ a transformer architecture to encode global k-space
information into latent features. The produced latent vectors condition queried
coordinates during decoding to generate segmentation class probabilities.
  Results: The model is able to produce better segmentations across high
acceleration factors than image-based segmentation baselines.
  Impact: Cardiac segmentation directly from undersampled k-space samples
circumvents the need for an intermediate image reconstruction step. This allows
the potential to assess myocardial structure and function on higher
acceleration factors than methods that rely on images as input.

</details>


### [103] [Computed Tomography (CT)-derived Cardiovascular Flow Estimation Using Physics-Informed Neural Networks Improves with Sinogram-based Training: A Simulation Study](https://arxiv.org/abs/2511.03876)
*Jinyuxuan Guo,Gurnoor Singh Khurana,Alejandro Gonzalo Grande,Juan C. del Alamo,Francisco Contijoch*

Main category: eess.IV

TL;DR: 提出了一种基于CT影像的血流估计算法SinoFlow，该算法使用CT数据的原始投影数据（sinogram）直接进行血流估计，避免了基于重建图像中误差传播的问题，显示出在不同CT成像参数下更好的估计性能和准确性，对于非侵入性评估心功能结构具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 传统的CT成像技术虽然能够很好地评估心血管的解剖和功能，但缺少直接利用造影剂演变图像来估计血流速度的方法。因此，旨在通过加入一个改进的框架SinoFlow，利用CT成像的原始投影数据直接对其进行血流估计，提升估计的精确度和可靠性，避免误差的传播。

Method: 本研究使用计算流体动力学模拟生成了脉动血流场，通过CT模拟扫描，经受不同程度的断层扫描机旋转速度、管电流和脉冲模态扫描设置的影响。将PINN结合CT重建影像（ImageFlow）的方法与新的SinoFlow方法进行了性能的比较。SinoFlow方法直接从CT的原始投影数据中进行血流估计，从而提高了血流估计的性能。

Result: SinoFlow在所有测试的旋转速度下都显示出稳定的估计性能，且在误差指标，如平均平方误差和速度误差方面比ImageFlow表现得更好。此外，SinoFlow方法兼容脉冲模式的成像方式，并且即使脉冲宽度缩短也能保持稳定高的估计准确度。

Conclusion: 这项研究表明了SinoFlow方法对于CT影像中的血流估计的潜力，提供了一种比现有的PINN方法更加具有前景的非侵入性血流评估方法，未来可以应用到其他图像处理的任务上，从而提供准确的血流估计结果。

Abstract: Background: Non-invasive imaging-based assessment of blood flow plays a
critical role in evaluating heart function and structure. Computed Tomography
(CT) is a widely-used imaging modality that can robustly evaluate
cardiovascular anatomy and function, but direct methods to estimate blood flow
velocity from movies of contrast evolution have not been developed.
  Purpose: This study evaluates the impact of CT imaging on Physics-Informed
Neural Networks (PINN)-based flow estimation and proposes an improved
framework, SinoFlow, which uses sinogram data directly to estimate blood flow.
  Methods: We generated pulsatile flow fields in an idealized 2D vessel
bifurcation using computational fluid dynamics and simulated CT scans with
varying gantry rotation speeds, tube currents, and pulse mode imaging settings.
We compared the performance of PINN-based flow estimation using reconstructed
images (ImageFlow) to SinoFlow.
  Results: SinoFlow significantly improved flow estimation performance by
avoiding propagating errors introduced by filtered backprojection. SinoFlow was
robust across all tested gantry rotation speeds and consistently produced lower
mean squared error and velocity errors than ImageFlow. Additionally, SinoFlow
was compatible with pulsed-mode imaging and maintained higher accuracy with
shorter pulse widths.
  Conclusions: This study demonstrates the potential of SinoFlow for CT-based
flow estimation, providing a more promising approach for non-invasive blood
flow assessment. The findings aim to inform future applications of PINNs to CT
images and provide a solution for image-based estimation, with reasonable
acquisition parameters yielding accurate flow estimates.

</details>


### [104] [$μ$NeuFMT: Optical-Property-Adaptive Fluorescence Molecular Tomography via Implicit Neural Representation](https://arxiv.org/abs/2511.04510)
*Shihan Zhao,Jianru Zhang,Yanan Wu,Linlin Li,Siyuan Shen,Xingjun Zhu,Guoyan Zheng,Jiahua Jiang,Wuwei Ren*

Main category: eess.IV

TL;DR: 提出了一种新的无监督FMT重建框架（μNeuFMT），该框架结合了隐式神经元场景表示和显式光子传播物理建模，无需精确的组织光学先验知识或预条件训练数据。实验表明，μNeuFMT在各种异构场景中的性能优于传统方法和监督学习方法，特别是在初始值严重误差的情况下，仍能恢复准确的荧光体分布和光学系数。


<details>
  <summary>Details</summary>
Motivation: 目前的FMT重建方法面临使用不准确或未知组织光学性质所带来的挑战，而监督学习方法的泛化能力受限于训练数据。为了克服这些问题，本文提出了一个新的无监督FMT重建框架以提高重建的准确性和鲁棒性。

Method: 本研究提出一种结合隐式神经元场景表示和显式光子传播物理建模的FMT重建框架（μNeuFMT），关键是在重建过程中同时优化荧光分布和光学性质，无需精确的组织光学先验知识或预条件训练数据。

Result: μNeuFMT表现出了强大的鲁棒性，能够从严重的初始误差中恢复出准确的荧光体分布和光学系数。研究表明，μNeuFMT优于传统方法以及监督深度学习方法，尤其是在复杂的情况下，如荧光引导外科手术的分子成像。

Conclusion: μNeuFMT为准确和鲁棒的FMT重建提供了新的范例，为复杂临床相关场景如荧光引导手术的分子成像铺平了道路。

Abstract: Fluorescence Molecular Tomography (FMT) is a promising technique for
non-invasive 3D visualization of fluorescent probes, but its reconstruction
remains challenging due to the inherent ill-posedness and reliance on
inaccurate or often-unknown tissue optical properties. While deep learning
methods have shown promise, their supervised nature limits generalization
beyond training data. To address these problems, we propose $\mu$NeuFMT, a
self-supervised FMT reconstruction framework that integrates implicit
neural-based scene representation with explicit physical modeling of photon
propagation. Its key innovation lies in jointly optimize both the fluorescence
distribution and the optical properties ($\mu$) during reconstruction,
eliminating the need for precise prior knowledge of tissue optics or
pre-conditioned training data. We demonstrate that $\mu$NeuFMT robustly
recovers accurate fluorophore distributions and optical coefficients even with
severely erroneous initial values (0.5$\times$ to 2$\times$ of ground truth).
Extensive numerical, phantom, and in vivo validations show that $\mu$NeuFMT
outperforms conventional and supervised deep learning approaches across diverse
heterogeneous scenarios. Our work establishes a new paradigm for robust and
accurate FMT reconstruction, paving the way for more reliable molecular imaging
in complex clinically related scenarios, such as fluorescence guided surgery.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [105] [What's in Common? Multimodal Models Hallucinate When Reasoning Across Scenes](https://arxiv.org/abs/2511.03768)
*Candace Ross,Florian Bordes,Adina Williams,Polina Kirichenko,Mark Ibrahim*

Main category: cs.LG

TL;DR: 构建了一个名为Common-O的新基准，用于评估多模态语言模型在处理现实世界场景推理时的能力。结果显示即使在感知任务上表现优秀的模型在处理跨场景推理任务时也表现较差，且容易产生幻觉，尤其是当场景中存在相似对象时。这表明模型可能依赖于训练期间看到的对象共现来做出推理，暗示了更大规模的多图像输入训练可能会有所帮助。


<details>
  <summary>Details</summary>
Motivation: 现有多模态语言模型尽管在感知任务上表现优秀，但它们在处理现实世界场景推理时还存在幻觉问题，因此提出构建一个新的基准来明确这些问题并促进相关研究的发展。

Method: 构建了包含超过10500个独特场景的新基准Common-O，评估了领先多模态语言模型在该基准上的性能，包括那些专门为了链式思考推理而训练的模型。此外还在复杂场景下进行了实验。

Result: 发现大部分模型在感知单一图像中的对象时表现良好，但对于跨场景推理则面临很大挑战，最好的模型仅在Common-O上达到35%的准确率，而在更复杂的Common-O Complex上仅为1%。同时观察到当场景中存在相似对象时模型更易产生幻觉。增大模型规模能提供一些改进，但针对多图像输入明确训练的模型显示出了更显著的提升。

Conclusion: 提出了一个新的评估基准Common-O，揭示了多模态语言模型在跨场景推理中遇到的困难，并通过实验对比了现有模型的表现，提出可能的改进方向。

Abstract: Multimodal language models possess a remarkable ability to handle an
open-vocabulary's worth of objects. Yet the best models still suffer from
hallucinations when reasoning about scenes in the real world, revealing a gap
between their seemingly strong performance on existing perception benchmarks
that are saturating and their reasoning in the real world. To address this gap,
we build a novel benchmark of in-the-wild scenes that we call Common-O. With
more than 10.5k examples using exclusively new images not found in web training
data to avoid contamination, Common-O goes beyond just perception, inspired by
cognitive tests for humans, to probe reasoning across scenes by asking "what's
in common?". We evaluate leading multimodal language models, including models
specifically trained to perform chain-of-thought reasoning. We find that
perceiving objects in single images is tractable for most models, yet reasoning
across scenes is very challenging even for the best models, including reasoning
models. Despite saturating many leaderboards focusing on perception, the best
performing model only achieves 35% on Common-O -- and on Common-O Complex,
consisting of more complex scenes, the best model achieves only 1%. Curiously,
we find models are more prone to hallucinate when similar objects are present
in the scene, suggesting models may be relying on object co-occurrence seen
during training. Among the models we evaluated, we found scale can provide
modest improvements while models explicitly trained with multi-image inputs
show bigger improvements, suggesting scaled multi-image training may offer
promise. We make our benchmark publicly available to spur research into the
challenge of hallucination when reasoning across scenes.

</details>


### [106] [Contamination Detection for VLMs using Multi-Modal Semantic Perturbation](https://arxiv.org/abs/2511.03774)
*Jaden Park,Mu Cai,Feng Yao,Jingbo Shang,Soochahn Lee,Yong Jae Lee*

Main category: cs.LG

TL;DR: 最近的Vision-Language模型在众多基准任务上取得了最先进的性能，但存在由于测试集泄漏导致的性能膨胀问题。为了检测受污染的VLM模型，提出了一种基于多模态语义扰动的新方法，并验证了其在整个受污染策略中的稳健性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的VLM模型由于互联网规模的预训练语料库存在测试集泄漏的问题，导致性能膨胀，而针对这个问题的检测方法却很少被探索，因此需要提出一种新的检测方法来解决这个问题。

Method: 提出了一种基于多模态语义扰动的方法来检测受污染的VLM模型，通过在流行基准任务上故意污染开源VLM模型，并验证现有检测方法的有效性，展示新方法在各种实际污染策略验证中的稳健性和有效性。

Result: 新方法能够有效检测到受污染的VLM模型，验证了方法的稳健性和有效性。同时，公开了代码和扰动数据集。

Conclusion: 提出了一种新的基于多模态语义扰动的检测方法，通过控制下的扰动验证了其稳健性和有效性，该方法能够有效地检测受污染的VLM模型。

Abstract: Recent advances in Vision-Language Models (VLMs) have achieved
state-of-the-art performance on numerous benchmark tasks. However, the use of
internet-scale, often proprietary, pretraining corpora raises a critical
concern for both practitioners and users: inflated performance due to test-set
leakage. While prior works have proposed mitigation strategies such as
decontamination of pretraining data and benchmark redesign for LLMs, the
complementary direction of developing detection methods for contaminated VLMs
remains underexplored. To address this gap, we deliberately contaminate
open-source VLMs on popular benchmarks and show that existing detection
approaches either fail outright or exhibit inconsistent behavior. We then
propose a novel simple yet effective detection method based on multi-modal
semantic perturbation, demonstrating that contaminated models fail to
generalize under controlled perturbations. Finally, we validate our approach
across multiple realistic contamination strategies, confirming its robustness
and effectiveness. The code and perturbed dataset will be released publicly.

</details>


### [107] [FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features](https://arxiv.org/abs/2511.03806)
*Linghui Zeng,Ruixuan Liu,Atiquer Rahman Sarkar,Xiaoqian Jiang,Joyce C. Ho,Li Xiong*

Main category: cs.LG

TL;DR: Proposes FusionDP, a method to improve model utility under feature-level differential privacy by using large foundation models for sensitive feature imputation and a modified DP-SGD algorithm.


<details>
  <summary>Details</summary>
Motivation: The necessity to protect privacy on a subset of features in machine learning due to varying privacy risks among different data features, while avoiding excessive noise injection and utility degradation.

Method: FusionDP, a two-step framework: 1) imputes sensitive features using large foundation models based on non-sensitive features as external priors; 2) employs a modified DP-SGD algorithm to train models on original and imputed features.

Result: FusionDP outperforms privacy-preserving baselines on sepsis prediction and clinical note classification tasks in two different modalities.

Conclusion: FusionDP demonstrates high potential in enhancing privacy-utility trade-offs for various modalities, utilizing foundation model-driven imputation.

Abstract: Ensuring the privacy of sensitive training data is crucial in
privacy-preserving machine learning. However, in practical scenarios, privacy
protection may be required for only a subset of features. For instance, in ICU
data, demographic attributes like age and gender pose higher privacy risks due
to their re-identification potential, whereas raw lab results are generally
less sensitive. Traditional DP-SGD enforces privacy protection on all features
in one sample, leading to excessive noise injection and significant utility
degradation. We propose FusionDP, a two-step framework that enhances model
utility under feature-level differential privacy. First, FusionDP leverages
large foundation models to impute sensitive features given non-sensitive
features, treating them as external priors that provide high-quality estimates
of sensitive attributes without accessing the true values during model
training. Second, we introduce a modified DP-SGD algorithm that trains models
on both original and imputed features while formally preserving the privacy of
the original sensitive features. We evaluate FusionDP on two modalities: a
sepsis prediction task on tabular data from PhysioNet and a clinical note
classification task from MIMIC-III. By comparing against privacy-preserving
baselines, our results show that FusionDP significantly improves model
performance while maintaining rigorous feature-level privacy, demonstrating the
potential of foundation model-driven imputation to enhance the privacy-utility
trade-off for various modalities.

</details>


### [108] [Optimizing Reasoning Efficiency through Prompt Difficulty Prediction](https://arxiv.org/abs/2511.03808)
*Bo Zhao,Berkcan Kapusuzoglu,Kartik Balasubramaniam,Sambit Sahu,Supriyo Chakraborty,Genta Indra Winata*

Main category: cs.LG

TL;DR: 我们提出了一种路由方法，将每个问题分配给最小的可能解决该问题的模型，从而在不影响准确性的情况下减少计算成本。在多种数学基准测试中，这种路由方法证明了其效率和性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然在处理复杂任务时表现出色，但由于其体积庞大和长推理痕迹，部署成本较高。因此，我们希望通过将问题路由到最小的可能解决问题的模型来减少计算成本，同时不牺牲准确性。

Method: 通过使用来自s1.1-32B的中间表示，我们训练了轻量级的模型难度或正确性预测器，以指导在一组推理模型间的路由。

Result: 在多样化的数学基准测试中，我们的路由方法在效率上优于随机分配，并且在使用明显较少的计算资源的情况下与s1.1-32B的性能相匹配。

Conclusion: 我们的研究表明，困难感知路由对于推理模型的成本有效部署是有效的。

Abstract: Reasoning language models perform well on complex tasks but are costly to
deploy due to their size and long reasoning traces. We propose a routing
approach that assigns each problem to the smallest model likely to solve it,
reducing compute without sacrificing accuracy. Using intermediate
representations from s1.1-32B, we train lightweight predictors of problem
difficulty or model correctness to guide routing across a pool of reasoning
models. On diverse math benchmarks, routing improves efficiency over random
assignment and matches s1.1-32B's performance while using significantly less
compute. Our results demonstrate that difficulty-aware routing is effective for
cost-efficient deployment of reasoning models.

</details>


### [109] [Sketch-Augmented Features Improve Learning Long-Range Dependencies in Graph Neural Networks](https://arxiv.org/abs/2511.03824)
*Ryien Hosseini,Filippo Simini,Venkatram Vishwanath,Rebecca Willett,Henry Hoffmann*

Main category: cs.LG

TL;DR: 本文提出在GNN中注入称为“Sketched Random Features”的随机全局嵌入，以有效捕捉长距离依赖关系，缓解传统GNN中的信息过度压缩、节点表示过度平滑和表达能力有限的问题，实验结果表明，这一策略在实际图形学习任务中表现优异，优于基线GNN，并能够作为现有技术如图位置编码的补充增强方法使用。


<details>
  <summary>Details</summary>
Motivation: 解决GNN中信息过分压缩、节点表示过分平滑和表达能力有限这三大挑战

Method: 在标准GNN中注入称为“Sketched Random Features”的随机全局嵌入，该嵌入具有唯一性，距离敏感性和拓扑无关性，能够缓解GNN中的信息过分压缩、节点表示过分平滑和表达能力有限的问题

Result: 实验结果表明，此策略在实际图形学习任务中优于基线GNN，并能够作为现有技术如图位置编码的补充增强方法使用

Conclusion: 注入随机全局嵌入的方法在解决GNN中信息过分压缩、节点表示过分平滑和表达能力有限的问题上表现出色，并能够作为现有技术的补充增强方法使用

Abstract: Graph Neural Networks learn on graph-structured data by iteratively
aggregating local neighborhood information. While this local message passing
paradigm imparts a powerful inductive bias and exploits graph sparsity, it also
yields three key challenges: (i) oversquashing of long-range information, (ii)
oversmoothing of node representations, and (iii) limited expressive power. In
this work we inject randomized global embeddings of node features, which we
term \textit{Sketched Random Features}, into standard GNNs, enabling them to
efficiently capture long-range dependencies. The embeddings are unique,
distance-sensitive, and topology-agnostic -- properties which we analytically
and empirically show alleviate the aforementioned limitations when injected
into GNNs. Experimental results on real-world graph learning tasks confirm that
this strategy consistently improves performance over baseline GNNs, offering
both a standalone solution and a complementary enhancement to existing
techniques such as graph positional encodings. Our source code is available at
\href{https://github.com/ryienh/sketched-random-features}{https://github.com/ryienh/sketched-random-features}.

</details>


### [110] [From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification](https://arxiv.org/abs/2511.03828)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: 提出了一种新的方法Energy-Guided Diffusion Stratification (StratDiff)，用于平滑地从离线到在线强化学习的过渡。该方法利用扩散模型学习离线数据集的先验知识，并通过能量基函数改进策略模仿和生成在线类似的动作。实验证明StratDiff在D4RL基准测试上优于现有方法，具有更高的适应性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 由于离线数据集的固定行为策略与在线学习期间的策略之间存在分布差异，从离线到在线强化学习存在挑战。当前方法较少利用离线数据的分布结构，本文旨在弥补这一研究空白。

Method: 通过扩散模型从离线数据集中学习先验知识，并利用能量基函数细化知识，生成离线类似的动作以进行更好的策略模仿；根据生成的动作与采样动作之间的KL散度值将训练集划分成离线类似子集和在线类似子集；离线类似子集中使用离线优化目标更新，而在线类似子集则遵循在线学习策略。

Result: 在与现成方法Cal-QL和IQL集成后，在D4RL基准测试上显示出优异性能，证明了其在各种RL设置下的更强适应性和稳定性。

Conclusion: 通过提出Energy-Guided Diffusion Stratification (StratDiff)，我们提供了一种新的方法来提高离线到在线强化学习的适应性和表现稳定性。

Abstract: Transitioning from offline to online reinforcement learning (RL) poses
critical challenges due to distributional shifts between the fixed behavior
policy in the offline dataset and the evolving policy during online learning.
Although this issue is widely recognized, few methods attempt to explicitly
assess or utilize the distributional structure of the offline data itself,
leaving a research gap in adapting learning strategies to different types of
samples. To address this challenge, we propose an innovative method,
Energy-Guided Diffusion Stratification (StratDiff), which facilitates smoother
transitions in offline-to-online RL. StratDiff deploys a diffusion model to
learn prior knowledge from the offline dataset. It then refines this knowledge
through energy-based functions to improve policy imitation and generate
offline-like actions during online fine-tuning. The KL divergence between the
generated action and the corresponding sampled action is computed for each
sample and used to stratify the training batch into offline-like and
online-like subsets. Offline-like samples are updated using offline objectives,
while online-like samples follow online learning strategies. We demonstrate the
effectiveness of StratDiff by integrating it with off-the-shelf methods Cal-QL
and IQL. Extensive empirical evaluations on D4RL benchmarks show that StratDiff
significantly outperforms existing methods, achieving enhanced adaptability and
more stable performance across diverse RL settings.

</details>


### [111] [Higher-Order Causal Structure Learning with Additive Models](https://arxiv.org/abs/2511.03831)
*James Enouen,Yujia Zheng,Ignavier Ng,Yan Liu,Kun Zhang*

Main category: cs.LG

TL;DR: 本文提出了用于处理更高阶交互的因果加性模型（CAM）扩展，并通过类似CAM的假设来简化学习高阶有向无环图的结构，展示了改进的CAM算法在合成实验中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界过程的高阶机制未受到充分的因果发现研究，本文旨在处理因果结构学习中的高阶交互问题，通过引入有向无环超图来更好地表示因果结构。

Method: 本文定义了有向无环超图的必要定义和理论工具，提供了超图等价类的可辨识性结果，并开发了处理更复杂搜索空间的改进CAM算法。

Result: 在合成试验中，改进的CAM算法验证了该方法能够学习更高阶的有向无环超图结构，并得到了更好的经验结果。

Conclusion: 引入有向无环超图和改进算法可以更好地处理更高阶交互问题，提高因果结构学习的效果。

Abstract: Causal structure learning has long been the central task of inferring causal
insights from data. Despite the abundance of real-world processes exhibiting
higher-order mechanisms, however, an explicit treatment of interactions in
causal discovery has received little attention. In this work, we focus on
extending the causal additive model (CAM) to additive models with higher-order
interactions. This second level of modularity we introduce to the structure
learning problem is most easily represented by a directed acyclic hypergraph
which extends the DAG. We introduce the necessary definitions and theoretical
tools to handle the novel structure we introduce and then provide
identifiability results for the hyper DAG, extending the typical Markov
equivalence classes. We next provide insights into why learning the more
complex hypergraph structure may actually lead to better empirical results. In
particular, more restrictive assumptions like CAM correspond to easier-to-learn
hyper DAGs and better finite sample complexity. We finally develop an extension
of the greedy CAM algorithm which can handle the more complex hyper DAG search
space and demonstrate its empirical usefulness in synthetic experiments.

</details>


### [112] [Enhancing Q-Value Updates in Deep Q-Learning via Successor-State Prediction](https://arxiv.org/abs/2511.03836)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: 通过显式建模环境动态以及集成后继状态分布，SADQ能提供更稳定和政策对齐的价值更新，同时提高动作选择效率。实验结果显示，SADQ在标准RL基准和现实世界的向量控制任务上表现优异，优于DQN及其变体。


<details>
  <summary>Details</summary>
Motivation: 传统的DQN算法目标更新依赖于来自过去政策的状态，这可能导致不精确的学习信号，增加更新过程中的方差。为了避免这个问题，需要设计一种策略，能够更好地与当前政策对齐，并且减少训练中的方差。因此，我们提出了SADQ算法，它通过建立环境动态的模型来稳定价值更新并提高学习效率。

Method: SADQ利用随机转换模型显式地建模环境动态，并将后继状态分布整合到Q值估计过程中，从而实现稳定且与政策对齐的价值更新。同时，它还探索了一种更加高效的动作选择策略。理论分析表明，SADQ能够保持价值估计的无偏性，同时降低训练中的方差。

Result: 实验结果证明，SADQ在各个标准的RL基准测试以及基于真实世界向量控制任务上，都显示出优于DQN及其变体的稳定性和学习效率表现。

Conclusion: SADQ通过改进对环境动态和价值更新过程的处理，提高了强化学习算法的稳定性和效率。

Abstract: Deep Q-Networks (DQNs) estimate future returns by learning from transitions
sampled from a replay buffer. However, the target updates in DQN often rely on
next states generated by actions from past, potentially suboptimal, policy. As
a result, these states may not provide informative learning signals, causing
high variance into the update process. This issue is exacerbated when the
sampled transitions are poorly aligned with the agent's current policy. To
address this limitation, we propose the Successor-state Aggregation Deep
Q-Network (SADQ), which explicitly models environment dynamics using a
stochastic transition model. SADQ integrates successor-state distributions into
the Q-value estimation process, enabling more stable and policy-aligned value
updates. Additionally, it explores a more efficient action selection strategy
with the modeled transition structure. We provide theoretical guarantees that
SADQ maintains unbiased value estimates while reducing training variance. Our
extensive empirical results across standard RL benchmarks and real-world
vector-based control tasks demonstrate that SADQ consistently outperforms DQN
variants in both stability and learning efficiency.

</details>


### [113] [Benchmark Datasets for Lead-Lag Forecasting on Social Platforms](https://arxiv.org/abs/2511.03877)
*Kimia Kazemian,Zhenzhen Liu,Yangfanyu Yang,Katie Z Luo,Shuhan Gu,Audrey Du,Xinyu Yang,Jack Jansons,Kilian Q Weinberger,John Thickstun,Yian Yin,Sarah Dean*

Main category: cs.LG

TL;DR: 该研究提出了“先导-滞后预测”（LLF）的时间序列预测问题，提供了两个大规模基准数据集（arXiv和GitHub），并论证了其对于社会和交互数据预测的重要性和新颖性。此外，还进行了基准测试，确认了LLF的存在并通过统计和分类测试验证了这种预测模式的有效性。该研究将LLF确立为社交数据预测的新范式，并为其系统性探索奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列社区中，尽管存在广泛存在的先导-滞后现象，但没有将其作为统一的预测问题进行处理。这些问题主要由于缺少标准化的数据集造成。研究者希望通过提供高质量的数据集锚定研究，促进LLF作为统一预测问题的发展。此外，该研究还通过统计和分类测试确认了LLF的有效性，确认了其在社交和使用数据预测中扮演的独特角色。因此，建立LLF作为预测新范式的意义在于，可以系统地探索和解决其他具有类似动力学过程的问题，如维基百科、Spotify等。

Method: 研究构建了两个大规模基准数据集arXiv和GitHub，用于锚定和测试LLF预测问题。该方法以高精度的数据清洗和整体研究框架，验证了先导-滞后预测的有效性，并进行了分类和统计测试，确认了该模式的存在，基准测试了传统的参数模型和非参数模型的回归性能。同时，该研究还提供了共享的数据门户以促进进一步的研究。

Result: 该研究成功地构建了大规模基准数据集，并证明了先导-滞后预测的有效性。结果显示了先导和滞后效应之间的时间延迟，基准测试结果表明了非参数模型在处理这类预测问题上的优越性。研究结论确认了LLF作为预测新范式的存在，为其系统性探索提供了重要数据支持。

Conclusion: 研究验证了先导-滞后预测在时间序列预测中的重要性和有效性，并通过两个关系密切的数据集（arXiv和GitHub），建立了大量的高质训练数据。研究结果表明，LLF作为预测新范式，可以处理更广泛的预测问题并具有良好的预测性能。最终，该研究为LLF的系统性探索奠定了重要基础，并提供了可供进一步研究的数据门户。

Abstract: Social and collaborative platforms emit multivariate time-series traces in
which early interactions-such as views, likes, or downloads-are followed,
sometimes months or years later, by higher impact like citations, sales, or
reviews. We formalize this setting as Lead-Lag Forecasting (LLF): given an
early usage channel (the lead), predict a correlated but temporally shifted
outcome channel (the lag). Despite the ubiquity of such patterns, LLF has not
been treated as a unified forecasting problem within the time-series community,
largely due to the absence of standardized datasets. To anchor research in LLF,
here we present two high-volume benchmark datasets-arXiv (accesses -> citations
of 2.3M papers) and GitHub (pushes/stars -> forks of 3M repositories)-and
outline additional domains with analogous lead-lag dynamics, including
Wikipedia (page views -> edits), Spotify (streams -> concert attendance),
e-commerce (click-throughs -> purchases), and LinkedIn profile (views ->
messages). Our datasets provide ideal testbeds for lead-lag forecasting, by
capturing long-horizon dynamics across years, spanning the full spectrum of
outcomes, and avoiding survivorship bias in sampling. We documented all
technical details of data curation and cleaning, verified the presence of
lead-lag dynamics through statistical and classification tests, and benchmarked
parametric and non-parametric baselines for regression. Our study establishes
LLF as a novel forecasting paradigm and lays an empirical foundation for its
systematic exploration in social and usage data. Our data portal with downloads
and documentation is available at https://lead-lag-forecasting.github.io/.

</details>


### [114] [DecoHD: Decomposed Hyperdimensional Classification under Extreme Memory Budgets](https://arxiv.org/abs/2511.03911)
*Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Mohsen Imani*

Main category: cs.LG

TL;DR: DecoHD通过直接在压缩的HDC参数化中训练，实现了显著的内存节省，同时保持了一定的准确性和平稳的运行性能，尤其在硬件部署上获得了显著的能效和速度提升。与非减少的HDC基线相比，其准确性仅下降了0.1-0.15%（最差情况下为5.7%），并显示出更好的抗随机比特翻转噪声的能力，需要的训练参数也减少了约97%。在硬件上，与CPU、GPU和HDC ASIC相比，其能效和速度分别获得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 在HDC中，分解一般会减少特征轴，从而导致压缩度和鲁棒性的下降。传统的HDC分解通过固定的原子超向量分解，不适于压缩学习的类原型。DecoHD旨在解决在HDC中直接压缩类轴的问题，同时保持计算性能。

Method: DecoHD使用一个小的共用层的通道集合，通过跨层的乘积绑定和最终捆绑，从而在紧凑因素中生成大代表空间。通过轻量级捆绑头来压缩类轴，同时保持原始的捆绑-评分过程。训练和推理均是端到端的，能很好地与内存加速器兼容。

Result: DecoHD实现了极端的内存节省，在严格的部署预算下仅显示出轻微的精度下降。在硬件中，DecoHD相对于CPU、GPU和HDC ASIC在能效和速度方面有显著改善。

Conclusion: DecoHD在保持算法性能和加速器兼容性的同时，提高了内存压缩率和训练效率，尤其是在硬件实现中展示了巨大的优势。

Abstract: Decomposition is a proven way to shrink deep networks without changing I/O.
We bring this idea to hyperdimensional computing (HDC), where footprint cuts
usually shrink the feature axis and erode concentration and robustness. Prior
HDC decompositions decode via fixed atomic hypervectors, which are ill-suited
for compressing learned class prototypes. We introduce DecoHD, which learns
directly in a decomposed HDC parameterization: a small, shared set of per-layer
channels with multiplicative binding across layers and bundling at the end,
yielding a large representational space from compact factors. DecoHD compresses
along the class axis via a lightweight bundling head while preserving native
bind-bundle-score; training is end-to-end, and inference remains pure HDC,
aligning with in/near-memory accelerators. In evaluation, DecoHD attains
extreme memory savings with only minor accuracy degradation under tight
deployment budgets. On average it stays within about 0.1-0.15% of a strong
non-reduced HDC baseline (worst case 5.7%), is more robust to random bit-flip
noise, reaches its accuracy plateau with up to ~97% fewer trainable parameters,
and -- in hardware -- delivers roughly 277x/35x energy/speed gains over a CPU
(AMD Ryzen 9 9950X), 13.5x/3.7x over a GPU (NVIDIA RTX 4090), and 2.0x/2.4x
over a baseline HDC ASIC.

</details>


### [115] [On Predicting Sociodemographics from Mobility Signals](https://arxiv.org/abs/2511.03924)
*Ekin Uğurel,Cynthia Chen,Brian H. Y. Lee,Filipe Rodrigues*

Main category: cs.LG

TL;DR: 该研究通过引入基于定向移动图的行为定位的高级移动描述符，改进了从被动收集的移动数据中预测社会人口统计特征的准确性，并开发了一个多任务学习框架，提高了模型的泛化能力和样本效率。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过改善从移动数据预测社会人口统计特征的准确性、可用性和泛化性，帮助交通规划者更好地利用被动收集的数据集，并解决此前该任务因移动模式和社会人口特征之间的关系较弱且不一致，以及在不同上下文中泛化性较差的问题。

Method: 首先提出了一套基于定向移动图的行为定位的高级移动描述符以改进预测准确性。其次，引入了衡量模型自信度和准确性之间平衡的指标和可视化工具，最后开发了一种多任务学习框架，该框架通过共享表示从移动数据预测多个社会人口统计特征。

Result: 该研究提出的高级移动描述符显著提高了年龄、性别、收入和家庭结构的预测准确性，多任务学习框架在训练数据有限或在不同时间段应用模型时性能更强。

Conclusion: 该研究通过改进预测准确性、提升模型的通用性和样本效率，成功应对了从移动数据推断社会人口特征的挑战，这为交通规划者提供了宝贵的工具。

Abstract: Inferring sociodemographic attributes from mobility data could help
transportation planners better leverage passively collected datasets, but this
task remains difficult due to weak and inconsistent relationships between
mobility patterns and sociodemographic traits, as well as limited
generalization across contexts. We address these challenges from three angles.
First, to improve predictive accuracy while retaining interpretability, we
introduce a behaviorally grounded set of higher-order mobility descriptors
based on directed mobility graphs. These features capture structured patterns
in trip sequences, travel modes, and social co-travel, and significantly
improve prediction of age, gender, income, and household structure over
baselines features. Second, we introduce metrics and visual diagnostic tools
that encourage evenness between model confidence and accuracy, enabling
planners to quantify uncertainty. Third, to improve generalization and sample
efficiency, we develop a multitask learning framework that jointly predicts
multiple sociodemographic attributes from a shared representation. This
approach outperforms single-task models, particularly when training data are
limited or when applying models across different time periods (i.e., when the
test set distribution differs from the training set).

</details>


### [116] [NVIDIA Nemotron Nano V2 VL](https://arxiv.org/abs/2511.03929)
*NVIDIA,:,Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu,Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu,Xin,Di,Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin,Akshay Hazare,Kaustubh Purandare,Ann Guan,Anna Warno,Chen Cui,Yoshi Suhara,Shibani Likhite,Seph Mard,Meredith Price,Laya Sleiman,Saori Kaji,Udi Karpas,Kari Briski,Joey Conway,Michael Lightstone,Jan Kautz,Mohammad Shoeybi,Mostofa Patwary,Jonathen Cohen,Oleksii Kuchaiev,Andrew Tao,Bryan Catanzaro*

Main category: cs.LG

TL;DR: Nemotron Nano V2 VL 是一款最新的视觉-语言模型，用于增强现实世界中的文档理解、长视频理解和推理任务。在模型架构、数据集和训练方案上进行了重大改进，性能优于前一代模型。并且通过创新的令牌减少技术，增强了长文档和视频场景的推理吞吐量。


<details>
  <summary>Details</summary>
Motivation: 为了提高模型在现实世界文档理解、长视频理解和推理任务中的性能，引入了Nemotron Nano V2 VL。同时，通过改进模型架构和数据集，希望在视觉和文本领域获得更好的效果。

Method: Nemotron Nano V2 VL 基于Nemotron Nano V2，是一种Mamba-Transformer大语言模型，通过创新的令牌减少技术来提高长文档和视频场景中的推理吞吐量。此外，还分享了模型的检查点、数据集、训练配方和代码。

Result: Nemotron Nano V2 VL 相较于之前的模型在所有视觉和文本领域均有显著提升，特别是在推理吞吐量方面。通过提供不同的模型格式，包括BF16、FP8和FP4，进一步优化了实际应用性能。

Conclusion: 通过模型架构、数据集和训练方案的改进，Nemotron Nano V2 VL 在提高现实世界文档理解、长视频理解以及推理任务性能方面显示出了巨大潜力。同时，通过发布模型检查点、数据集和训练代码，推动了领域的开放性和创新性。

Abstract: We introduce Nemotron Nano V2 VL, the latest model of the Nemotron
vision-language series designed for strong real-world document understanding,
long video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers
significant improvements over our previous model,
Llama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major
enhancements in model architecture, datasets, and training recipes. Nemotron
Nano V2 VL builds on Nemotron Nano V2, a hybrid Mamba-Transformer LLM, and
innovative token reduction techniques to achieve higher inference throughput in
long document and video scenarios. We are releasing model checkpoints in BF16,
FP8, and FP4 formats and sharing large parts of our datasets, recipes and
training code.

</details>


### [117] [LogHD: Robust Compression of Hyperdimensional Classifiers via Logarithmic Class-Axis Reduction](https://arxiv.org/abs/2511.03938)
*Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Pietro Mercati,Nathaniel D. Bastian,Mohsen Imani*

Main category: cs.LG

TL;DR: LogHD 是一种新的 HDC 方法，通过减少类轴的维度，将内存需求从 $O(CD)$ 降低到 $O(D\log_k C)$ 而不降低特征轴的维度，提高了模型的存储效率和鲁棒性，同时保持了较高的准确性和在高错误率情况下的稳定性。此外，该方法还展示了在硬件实现上的高能效和快速性能，特别是在 ASIC 实现中。


<details>
  <summary>Details</summary>
Motivation: 传统 HDC 方法在处理大量类别时需要大量的存储空间，这限制了其在受限环境中的应用。LogHD 的设计目的是减少内存需求，同时保持或提高模型的准确性和鲁棒性，特别适用于内存、能耗和可靠性有限的系统。

Method: LogHD 使用一组 $n \approx \lceil\log_k C\rceil$ 个捆绑超向量来替代标准的每类原型，这将内存需求从 $O(CD)$ 降为 $O(D\log_k C)$。同时，LogHD 采用基于容量感知的代码本和基于配置文件的解码，以及特征轴稀疏化，以进一步优化内存使用和计算效率。这种方法不仅提升了模型的存储效率，也增强了模型对错误的容忍度。

Result: 实验结果表明，相比传统的特征轴压缩方法，在相同内存限制下，LogHD 可以在 2.5-3.0 倍的错误率下保持目标准确度。同时，LogHD 的 ASIC 实现提供了 498 倍的能效提升和 62.6 倍的计算加速，比 NVIDIA RTX 4090 和AMD Ryzen 9 9950X 更高效。相较于特征轴压缩的 HDC ASIC 基线，LogHD 在能效和速度方面也具有明显优势。

Conclusion: LogHD 是一个在保持高准确度的同时显著减少内存需求与提高能耗和速度性能的先进技术，适合于资源受限的应用场景。

Abstract: Hyperdimensional computing (HDC) suits memory, energy, and
reliability-constrained systems, yet the standard "one prototype per class"
design requires $O(CD)$ memory (with $C$ classes and dimensionality $D$). Prior
compaction reduces $D$ (feature axis), improving storage/compute but weakening
robustness. We introduce LogHD, a logarithmic class-axis reduction that
replaces the $C$ per-class prototypes with $n\!\approx\!\lceil\log_k C\rceil$
bundle hypervectors (alphabet size $k$) and decodes in an $n$-dimensional
activation space, cutting memory to $O(D\log_k C)$ while preserving $D$. LogHD
uses a capacity-aware codebook and profile-based decoding, and composes with
feature-axis sparsification. Across datasets and injected bit flips, LogHD
attains competitive accuracy with smaller models and higher resilience at
matched memory. Under equal memory, it sustains target accuracy at roughly
$2.5$-$3.0\times$ higher bit-flip rates than feature-axis compression; an ASIC
instantiation delivers $498\times$ energy efficiency and $62.6\times$ speedup
over an AMD Ryzen 9 9950X and $24.3\times$/$6.58\times$ over an NVIDIA RTX
4090, and is $4.06\times$ more energy-efficient and $2.19\times$ faster than a
feature-axis HDC ASIC baseline.

</details>


### [118] [RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods](https://arxiv.org/abs/2511.03939)
*Raghav Sharma,Manan Mehta,Sai Tiger Raina*

Main category: cs.LG

TL;DR: 该论文综述了从人类反馈中进行强化学习（RLHF）的最新研究，特别是在多模态对齐、文化公平性以及低延迟优化方面的新进展。同时，该论文还回顾了基础算法如PPO、DPO和GRPO，并提供了一个比较性的综合分析，同时也指出了开放性的挑战。


<details>
  <summary>Details</summary>
Motivation: 近年来，对齐大型语言模型（LLMs）的方法已经超出了传统的基于文本的方法，因此需要综述多模态对齐、文化公平性和低延迟优化的研究进展。同时，该论文的目的是填补这一领域中的研究空白，并对最新创新做出详细分析，从而为构建更强大、更有效且更具公平性的AI系统提供一个重要的指南。

Method: 首先回顾了基础算法如PPO、DPO和GRPO，然后对最新创新进行了详细分析，提供了比较性的综合分析，并指出了开放性的挑战。

Result: 文章综述了多模态对齐、文化公平性和低延迟优化的最新进展，提供了基础算法的回顾，对创新做出了详细分析，并指出了开放性的挑战。

Conclusion: 该论文为构建更强大、更高效且更具公平性的AI系统提供了一个重要的指南，强调了多模态对齐、文化公平性和低延迟优化的重要性，同时也指出在未来研究中需要克服的关键挑战。

Abstract: Reinforcement Learning from Human Feedback (RLHF) is the standard for
aligning Large Language Models (LLMs), yet recent progress has moved beyond
canonical text-based methods. This survey synthesizes the new frontier of
alignment research by addressing critical gaps in multi-modal alignment,
cultural fairness, and low-latency optimization. To systematically explore
these domains, we first review foundational algo- rithms, including PPO, DPO,
and GRPO, before presenting a detailed analysis of the latest innovations. By
providing a comparative synthesis of these techniques and outlining open
challenges, this work serves as an essential roadmap for researchers building
more robust, efficient, and equitable AI systems.

</details>


### [119] [Conditional Score Learning for Quickest Change Detection in Markov Transition Kernels](https://arxiv.org/abs/2511.03953)
*Wuxia Chen,Taposh Banerjee,Vahid Tarokh*

Main category: cs.LG

TL;DR: 本文提出了一种基于条件得分的最快变化检测方法，适用于高维马尔可夫过程，并且不需要显式计算似然值。通过Hoeffding不等式证明了在假警报时间上的指数下界和检测延迟上的渐进上限。这种方法既提供理论保证，又具有实际可行性。


<details>
  <summary>Details</summary>
Motivation: 文中旨在解决在马尔可夫过程中的未知转移核下的快速变化检测问题，通过直接学习条件得分来避免显式似然评估，并提供一种学习转移动态的实用方法。使用截断后的统计特征来确保有界增量，并在统一厄戈德马尔可夫过程中应用Hoeffding不等式。这种方法为高维马尔可夫模型中的基于得分的检测提供了理论保证和实际可行性。

Method: 通过从样本对$( 	extbf{x},	extbf{y})$中直接学习条件得分$
abla_{	extbf{y}} 	ext{log} p(	extbf{y}|	extbf{x})$，避免了似然评估，并且基于此估计开发了一种基于条件Hyvarinen得分差的C.USUM过程来检测核的变化。为了保证增量有界，提出了一种截断版本的统计特征。利用Hoeffding不等式证明假警报时间的指数下界，并证明了检测延迟的渐进上限。

Result: 证明了在高维马尔可夫模型中的基于得分的检测具有理论上的保证，并提供了良好的实用性。特别是，在假警报时间上提供了指数下界，在检测延迟上提供了渐进上限。

Conclusion: 通过学习马尔可夫过程的条件得分并基于Hoeffding不等式的理论结果，方法在高维数据背景下既具有理论上的说服力，又能够在实践中应用。

Abstract: We address the problem of quickest change detection in Markov processes with
unknown transition kernels. The key idea is to learn the conditional score
$\nabla_{\mathbf{y}} \log p(\mathbf{y}|\mathbf{x})$ directly from sample pairs
$( \mathbf{x},\mathbf{y})$, where both $\mathbf{x}$ and $\mathbf{y}$ are
high-dimensional data generated by the same transition kernel. In this way, we
avoid explicit likelihood evaluation and provide a practical way to learn the
transition dynamics. Based on this estimation, we develop a score-based CUSUM
procedure that uses conditional Hyvarinen score differences to detect changes
in the kernel. To ensure bounded increments, we propose a truncated version of
the statistic. With Hoeffding's inequality for uniformly ergodic Markov
processes, we prove exponential lower bounds on the mean time to false alarm.
We also prove asymptotic upper bounds on detection delay. These results give
both theoretical guarantees and practical feasibility for score-based detection
in high-dimensional Markov models.

</details>


### [120] [PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis](https://arxiv.org/abs/2511.03966)
*Mingliang Hou,Yinuo Wang,Teng Guo,Zitao Liu,Wenzhou Dou,Jiaqi Zheng,Renqiang Luo,Mi Tian,Weiqi Luo*

Main category: cs.LG

TL;DR: 本文提出了一个名为层次重要性指导遗忘（HIF）的新算法，用于认知诊断模型的数据移除，以应对用户“被遗忘权”的需求。HIF算法通过结合个体和层次的重要性，更精确地区分需要移除的数据相关的参数。实验表明，HIF在关键指标上优于基线算法，为认知诊断模型的隐私保护提供了有效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着用户对"被遗忘权"（right to be forgotten）要求的增加，从认知诊断模型中移除特定学生数据的需求变得迫切。现有的认知诊断模型在设计时通常没有考虑隐私问题，缺乏有效的数据移除机制。现有的通用数据移除算法在处理认知诊断模型的独特异构结构时，难以在移除完整性、模型性能和效率之间取得平衡。因此，本研究提出了一种新的有效的数据移除算法。

Method: 层次重要性指导遗忘（HIF）算法通过创新的平滑机制，结合了个体和层次的重要特征，能够更精准地识别与移除数据相关的参数，从而优化了认知诊断模型的数据移除过程。

Result: 在三个真实世界的数据集上的实验表明，HIF算法在关键指标上显著优于基线算法，展示了HIF在认知诊断模型中保护用户隐私方面的优越性和实用性。

Conclusion: 本文提出了层次重要性指导遗忘（HIF）算法，解决了认知诊断模型中关于用户数据移除的问题，同时也为实现高效、可保护隐私的AI系统提供了一种新的方法。

Abstract: The need to remove specific student data from cognitive diagnosis (CD) models
has become a pressing requirement, driven by users' growing assertion of their
"right to be forgotten". However, existing CD models are largely designed
without privacy considerations and lack effective data unlearning mechanisms.
Directly applying general purpose unlearning algorithms is suboptimal, as they
struggle to balance unlearning completeness, model utility, and efficiency when
confronted with the unique heterogeneous structure of CD models. To address
this, our paper presents the first systematic study of the data unlearning
problem for CD models, proposing a novel and efficient algorithm: hierarchical
importanceguided forgetting (HIF). Our key insight is that parameter importance
in CD models exhibits distinct layer wise characteristics. HIF leverages this
via an innovative smoothing mechanism that combines individual and layer, level
importance, enabling a more precise distinction of parameters associated with
the data to be unlearned. Experiments on three real world datasets show that
HIF significantly outperforms baselines on key metrics, offering the first
effective solution for CD models to respond to user data removal requests and
for deploying high-performance, privacy preserving AI systems

</details>


### [121] [PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction](https://arxiv.org/abs/2511.03976)
*Xu Zou*

Main category: cs.LG

TL;DR: 本文提出了PETRA，一个基于进化轨迹而非原始RNA序列的新型Transformer方法，用于有效预测未来SARS-CoV-2的突变。PETRA在预测未来突变方面表现出色，能够在加权召回率方面超越现有基线方法。代码开源于https://github.com/xz-keg/PETra。


<details>
  <summary>Details</summary>
Motivation: 直接将大规模生成预训练变换器应用于嘈杂的病毒基因组序列存在局限性，因此，开发了一种基于进化轨迹的新方法来缓解测序噪声并捕捉病毒进化的层次结构。此研究试图提高对未来SARS-CoV-2突变的预测准确性，进而增强疫苗研发与公共卫生应对措施的有效性。

Method: PETRA基于从系统发育树中推导出的进化轨迹，利用加权训练框架来应对全球序列数据中存在的大量地域和时间不平衡。它旨在预测SARS-CoV-2未来的突变，并帮助实时预测主要分支的突变情况，例如24F(XEC)和25A(LP.8.1)。

Result: 在nucleotide替换和Spike氨基酸突变的加权召回方面，PETRA的表现分别为9.45%和17.10%，而基准方法则分别为0.49%和6.64%。

Conclusion: PETRA通过构建进化轨迹，成功地缓解了测序噪音并捕获了病毒进化的层次结构，这使得它在预测未来SARS-CoV-2突变方面取得了显著的效果。此方法的应用可能为疫苗研制与疾病控制提供重要的信息支持。

Abstract: Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable
evolutionary trajectory, characterized by the continual emergence of
immune-evasive variants. This poses persistent challenges to public health and
vaccine development.
  While large-scale generative pre-trained transformers (GPTs) have
revolutionized the modeling of sequential data, their direct applications to
noisy viral genomic sequences are limited. In this paper, we introduce
PETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based
on evolutionary trajectories derived from phylogenetic trees rather than raw
RNA sequences. This method effectively mitigates sequencing noise and captures
the hierarchical structure of viral evolution.
  With a weighted training framework to address substantial geographical and
temporal imbalances in global sequence data, PETRA excels in predicting future
SARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide
mutations and 17.10\% for spike amino-acid mutations, compared to 0.49% and
6.64% respectively for the best baseline. PETRA also demonstrates its ability
to aid in the real-time mutation prediction of major clades like 24F(XEC) and
25A(LP.8.1). The code is open sourced on https://github.com/xz-keg/PETra

</details>


### [122] [Structural Priors and Modular Adapters in the Composable Fine-Tuning Algorithm of Large-Scale Models](https://arxiv.org/abs/2511.03981)
*Yuxiao Wang,Di Wu,Feng Liu,Zhimin Qiu,Chenrui Hu*

Main category: cs.LG

TL;DR: 论文提出了一种将图结构先验与模块化适配器集成的可组合微调方法，以解决大规模预训练模型在多任务适应中的高计算成本和结构不稳定性问题。该方法通过引入关系矩阵来建模任务间的依赖关系，提高模型的参数效率和训练稳定性，减少多任务环境下的路径冲突和冗余计算。实验表明，该方法在保持模型轻量级设计的同时，显著提高了任务预测精度与适配器权重分配精度，具有更高的计算效率和性能优势。


<details>
  <summary>Details</summary>
Motivation: 当前大规模预训练模型在多任务适应下的计算成本高昂且存在结构不稳定问题，缺乏一种有效的解决方案。本文旨在通过结合图结构先验和模块化适配器来改进这一现状，提高模型的参数效率、训练稳定性和计算效率，同时保持模型轻量级设计。

Method: 该研究提出了一种新的可组合微调方法，该方法通过引入关系矩阵来建模任务间的依赖关系，并将模块化适配器嵌入到不同的层中，通过低秩映射和可插拔机制实现模块化适配器的有效复用。这种方法将图结构先验和模块化机制结合，提高了模型的参数效率和训练稳定性，减少了多任务环境下的路径冲突和冗余计算。此外，针对关键因素如路由温度、门限设置和关系矩阵正则强度等进行了超参数敏感性、环境敏感性和数据敏感性的实验分析。

Result: 结果表明，该方法在保持模型轻量级设计的前提下，提高了任务预测准确率、适配器权重分配精度和整体计算效率，证实了其在结构约束下的性能优越性和一致性。实验的有效性也得到了验证，确立了图结构先验和模块化机制结合的优势。

Conclusion: 综上所述，本文提出的框架通过结合图结构先验和模块化机制在可组合微调中展示了显著优势，既有效地改善了模型的参数效率和计算效率，又增强了模型的稳定性和性能表现，具有重要的理论和实际应用价值。

Abstract: This paper proposes a composable fine-tuning method that integrates graph
structural priors with modular adapters to address the high computational cost
and structural instability faced by large-scale pre-trained models in
multi-task adaptation. The method introduces a relation matrix to model
dependencies among tasks, explicitly encoding correlations between nodes and
paths into graph structural priors, which provide unified structural
constraints for adapter weight allocation and path selection. Modular adapters
are embedded into different layers through low-rank mapping and a pluggable
mechanism, enabling efficient cross-task composition and reuse under prior
guidance. This mechanism not only improves parameter efficiency and training
stability but also alleviates path conflicts and redundant computation in
multi-task scenarios. Furthermore, experiments on hyperparameter sensitivity,
environmental sensitivity, and data sensitivity are conducted to systematically
analyze key factors such as routing temperature, gating thresholds, and
relation matrix regularization strength, verifying the consistency and superior
performance of the method under structural constraints. The results demonstrate
that the proposed framework significantly enhances task prediction accuracy,
adapter weight allocation precision, and overall computational efficiency while
maintaining model lightweight design, highlighting the synergistic advantages
of graph priors and modular mechanisms in composable fine-tuning.

</details>


### [123] [Use of Continuous Glucose Monitoring with Machine Learning to Identify Metabolic Subphenotypes and Inform Precision Lifestyle Changes](https://arxiv.org/abs/2511.03986)
*Ahmed A. Metwally,Heyjun Park,Yue Wu,Tracey McLaughlin,Michael P. Snyder*

Main category: cs.LG

TL;DR: 这篇综述展示了连续葡萄糖监测和可穿戴技术是如何推动非侵入性、动态代谢表型学的范式转变的。通过机器学习模型，高分辨率葡萄糖数据可以准确预测肌肉胰岛素抵抗和β细胞功能的黄金标准测量值。这种个性化的表征可以应用于日常饮食中，以准确预测标准餐食后的血糖反应。另外，结合可穿戴设备的数据可以揭示日常饮食、睡眠和身体活动模式对代谢功能的独特影响，从而为定制精确的生活方式干预提供信息。CGM可以将早期糖代谢异常分解为可操作的子表型，超越了简单的血糖控制，为精确的糖尿病预防措施铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 当前糖尿病和前期糖尿病的分类通过静态葡萄糖阈值来区分，这掩盖了由胰岛素抵抗、β细胞功能障碍及肠促胰素缺乏驱动的糖代谢异质性。论文旨在通过连续葡萄糖监测与可穿戴技术捕捉动态的糖代谢状态，实现更精准的糖尿病前期预防和治疗策略。

Method: 通过高分辨率连续葡萄糖监测和可穿戴技术获取个体数据，应用机器学习模型来分析这些数据，以预测肌肉胰岛素抵抗和β细胞功能，并通过这些数据探究日常饮食、睡眠和身体活动与特定代谢障碍之间的联系。

Result: 研究结果表明，CGM能够准确预测肌肉胰岛素抵抗和β细胞功能的黄金标准测量值。此外，通过CGM还能够动态检测日常饮食和生活方式对代谢的影响，揭示了个体特有的餐后血糖反应可作为其代谢亚型的生物标志物。这些发现为精确的糖尿病预防提供了重要依据。

Conclusion: 连续葡萄糖监测和可穿戴技术的应用是推动糖尿病前期精准预防和治疗策略的强有力工具，可以从多维度解析早期糖代谢异常，并据此提出个性化的营养、行为和药物干预策略，开启了糖尿病预防的新纪元。

Abstract: The classification of diabetes and prediabetes by static glucose thresholds
obscures the pathophysiological dysglycemia heterogeneity, primarily driven by
insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This
review demonstrates that continuous glucose monitoring and wearable
technologies enable a paradigm shift towards non-invasive, dynamic metabolic
phenotyping. We show evidence that machine learning models can leverage
high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance
tests to accurately predict gold-standard measures of muscle IR and beta-cell
function. This personalized characterization extends to real-world nutrition,
where an individual's unique postprandial glycemic response (PPGR) to
standardized meals, such as the relative glucose spike to potatoes versus
grapes, could serve as a biomarker for their metabolic subtype. Moreover,
integrating wearable data reveals that habitual diet, sleep, and physical
activity patterns, particularly their timing, are uniquely associated with
specific metabolic dysfunctions, informing precision lifestyle interventions.
The efficacy of dietary mitigators in attenuating PPGR is also shown to be
phenotype-dependent. Collectively, this evidence demonstrates that CGM can
deconstruct the complexity of early dysglycemia into distinct, actionable
subphenotypes. This approach moves beyond simple glycemic control, paving the
way for targeted nutritional, behavioral, and pharmacological strategies
tailored to an individual's core metabolic defects, thereby paving the way for
a new era of precision diabetes prevention.

</details>


### [124] [Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations](https://arxiv.org/abs/2511.04000)
*Kyaw Hpone Myint,Zhe Wu,Alexandre G. R. Day,Giri Iyengar*

Main category: cs.LG

TL;DR: 本文提出了一种通过生成合成预训练数据来实现决策树元学习的方法，该方法可以生成大规模的、现实的决策树数据集，且性能可与昂贵的计算资源获取的最佳决策树相媲美。这种方法大幅减少了计算成本，提高了数据生成的灵活性，为可解释性决策树模型的规模化和高效元学习铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 决策树由于其可解释性，在金融和医疗等高风险领域得到了广泛的应用。但是，生成适用于元学习的大型预训练数据集通常是昂贵且具有挑战性的。因此，本文旨在提出一种更有效和可扩展的方法来生成这样的数据集，从而降低元学习的成本并提高其灵活性。

Method: 本文的方法包括创建合成决策树数据集和使用MetaTree架构进行元学习。合成决策树数据集是通过采样接近最优决策树的方法生成的。然后，使用MetaTree架构进行训练和测试。

Result: 实验结果显示，该方法在性能上与使用真实世界数据或计算昂贵的最佳决策树预训练的方法相近，但能够显著减少计算成本和提高数据生成的灵活性。

Conclusion: 本文提出的方法对决策树元学习提供了重要的影响，为生成大量、现实的数据集提供了一种成本效益高的方案，并为未来大规模应用提供了可能性。这种方法还为有效、灵活的元学习探索开设了研究的新领域。

Abstract: Decision trees are widely used in high-stakes fields like finance and
healthcare due to their interpretability. This work introduces an efficient,
scalable method for generating synthetic pre-training data to enable
meta-learning of decision trees. Our approach samples near-optimal decision
trees synthetically, creating large-scale, realistic datasets. Using the
MetaTree transformer architecture, we demonstrate that this method achieves
performance comparable to pre-training on real-world data or with
computationally expensive optimal decision trees. This strategy significantly
reduces computational costs, enhances data generation flexibility, and paves
the way for scalable and efficient meta-learning of interpretable decision tree
models.

</details>


### [125] [Accelerating scientific discovery with the common task framework](https://arxiv.org/abs/2511.04001)
*J. Nathan Kutz,Peter Battaglia,Michael Brenner,Kevin Carlberg,Aric Hagberg,Shirley Ho,Stephan Hoyer,Henning Lange,Hod Lipson,Michael W. Mahoney,Frank Noe,Max Welling,Laure Zanna,Francis Zhu,Steven L. Brunton*

Main category: cs.LG

TL;DR: 本文介绍了用于科学和工程的CTF框架，它是一个包含多样实践目标的数据集集合，旨在为快速发展的机器学习和人工智能算法提供客观的比较标准，类似于在语音识别、语言处理和计算机视觉等传统应用中已经成功实施的CTF框架。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习和人工智能算法在动态系统的描述和控制方面显示出巨大的潜力，但是在这些领域的应用需要客观且综合的评估标准，特别在面对有限的数据和噪声测量时。CTF框架的引入是为了应对这一需求，为新算法提供一个公平且全面的测试环境。

Method: 文中没有详细介绍具体的方法，主要是提出了CTF框架的概念和它的重要性，没有提供具体的算法或技术手段。

Result: 通过引入CTF框架，希望能够提供一个合理的比较工具，用于评估机器学习和人工智能算法在科学和工程中的表现。

Conclusion: CTF框架的引入是应对当前机器学习和人工智能算法快速发展下的一种解决方案，为确保这些算法的有效性提供了必要的评估工具。

Abstract: Machine learning (ML) and artificial intelligence (AI) algorithms are
transforming and empowering the characterization and control of dynamic systems
in the engineering, physical, and biological sciences. These emerging modeling
paradigms require comparative metrics to evaluate a diverse set of scientific
objectives, including forecasting, state reconstruction, generalization, and
control, while also considering limited data scenarios and noisy measurements.
We introduce a common task framework (CTF) for science and engineering, which
features a growing collection of challenge data sets with a diverse set of
practical and common objectives. The CTF is a critically enabling technology
that has contributed to the rapid advance of ML/AI algorithms in traditional
applications such as speech recognition, language processing, and computer
vision. There is a critical need for the objective metrics of a CTF to compare
the diverse algorithms being rapidly developed and deployed in practice today
across science and engineering.

</details>


### [126] [Memory- and Latency-Constrained Inference of Large Language Models via Adaptive Split Computing](https://arxiv.org/abs/2511.04002)
*Mingyu Sung,Vikas Palakonda,Suhwan Im,Sunghwan Moon,Il-Min Kim,Sangseok Yun,Jae-Mo Kang*

Main category: cs.LG

TL;DR: 本文提出了一个针对大语言模型在边缘设备上的自回归感知分层计算框架，包括one-point split compression (OPSC)、双阶段中间压缩管道以及联合优化框架，以解决模型分层计算带来的内存和延迟问题，在保持或提高模型准确性的前提下，实现显著的推理加速和通信开销减少。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的参数尺寸和内存需求极大，导致其难以在资源受限的物联网设备上部署。现有的分层计算方法虽提出了一定解决方案，但仍未解决自回归推理所带来的内存消耗和迭代生成过程中的缓存需求问题。因此本文提出一种方案解决上述问题，实现大型语言模型在边缘设备上的高效部署。

Method: 方法包括one-point split compression (OPSC)、双阶段中间压缩管道以及联合优化框架。OPSC是一种混合精度量化方案，能够将模型划分为前端和后端并采用不同的量化精度；双阶段中间压缩管道由阈值划分和量化解决方案组成，以便在减少通信开销的同时保障关键激活；联合优化框架则搜索最优的划分点、量化配置以及序列长度以满足严格的内存和延迟要求。

Result: 实验结果表明，新提出的框架能够在满足严格内存和延迟要求的同时保持或提高模型准确性，相对于现有的多种量化方法，实现了更好的推理速度和显著减少的通信开销。具体来说，框架实现了1.49倍的推理加速。

Conclusion: 本文提出了一种针对大型语言模型在物联网设备上的自回归分层计算框架。通过OPSC、双阶段中间压缩管道和联合优化框架，成功解决了自回归推理中内存和延迟需求的冲突，并显著提升了推理速度。

Abstract: Large language models (LLMs) have achieved near-human performance across
diverse reasoning tasks, yet their deployment on resource-constrained
Internet-of-Things (IoT) devices remains impractical due to massive parameter
footprints and memory-intensive autoregressive decoding. While split computing
offers a promising solution by partitioning model execution between edge
devices and cloud servers, existing approaches fail to address the unique
challenges of autoregressive inference, particularly the iterative token
generation process and expanding key-value (KV) cache requirements. This work
introduces the first autoregressive-aware split computing framework designed
explicitly for LLM deployment on edge devices. Our approach makes three key
contributions. First, we develop one-point split compression (OPSC), a
mixed-precision quantization scheme that prevents out-of-memory failures by
strategically partitioning models into front-end and back-end segments with
different precision levels. Second, we propose a two-stage intermediate
compression pipeline that combines threshold splitting (TS) and token-wise
adaptive bit quantization (TAB-Q) to preserve accuracy-critical activations
while dramatically reducing communication overhead. Third, we formulate a
unified optimization framework that jointly selects optimal split points,
quantization settings, and sequence lengths to satisfy strict memory and
latency constraints. Extensive evaluations across diverse LLMs and hardware
platforms demonstrate superior performance compared to state-of-the-art
quantization methods, including SmoothQuant, OmniQuant, and Atom. The framework
achieves a 1.49 inference speedup and significant communication overhead
reduction while maintaining or improving model accuracy.

</details>


### [127] [DartQuant: Efficient Rotational Distribution Calibration for LLM Quantization](https://arxiv.org/abs/2511.04063)
*Yuantian Shao,Yuanteng Chen,Peisong Wang,Jianlin Yu,Jing Lin,Yiwu Yao,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: 提出了一种高效的基于分布感知的旋转校准方法DartQuant，通过约束旋转后的激活分布，减少了旋转优化的复杂性，降低了对任务特定损失的依赖，从而减少了过拟合的风险。引入了QR-Orth优化方案，使得旋转优化更加高效。在各种模型量化实验中，DartQuant表现出了优越的性能，并且在资源受限的环境中首次成功地完成了70B模型的旋转校准任务。


<details>
  <summary>Details</summary>
Motivation: 在大规模模型的推断加速中，量化发挥着关键作用。现有的旋转优化算法虽然能有效改进量化性能，但其端到端的微调策略面临计算成本高昂和易过拟合的问题。因此需要一种能有效减少旋转优化复杂性并降低过拟合风险的方法，使之适用于资源受限的场合。这种方法不仅能提高性能，还能降低成本和内存消耗。

Method: 提出了一种分布感知的旋转校准方法DartQuant，通过约束旋转后的激活分布来降低旋转优化的复杂性，减少对任务特定损失的依赖。此外，引入了QR-Orth优化方案，用更加高效的方案替代了昂贵的交替优化。这种方法在降低旋转优化的计算成本和内存使用的同时，提高了旋转校准的性能。

Result: 在各种模型量化实验中，DartQuant的表现优于现有方法，实现了旋转优化的加速和内存节省的效果。特别是在资源受限的环境中，首次实现了70B模型的旋转校准。相比现有方法，DartQuant可以在单个3090 GPU上完成70B模型的旋转校准，避免了过拟合的风险。

Conclusion: DartQuant通过分布感知的旋转校准方法和QR-Orth优化方案，在降低计算成本和内存使用的同时，提高了旋转校准的性能，并且适用于资源受限的环境，使得大规模语言模型的量化成为可能。

Abstract: Quantization plays a crucial role in accelerating the inference of
large-scale models, and rotational matrices have been shown to effectively
improve quantization performance by smoothing outliers. However, end-to-end
fine-tuning of rotational optimization algorithms incurs high computational
costs and is prone to overfitting. To address this challenge, we propose an
efficient distribution-aware rotational calibration method, DartQuant, which
reduces the complexity of rotational optimization by constraining the
distribution of the activations after rotation. This approach also effectively
reduces reliance on task-specific losses, thereby mitigating the risk of
overfitting. Additionally, we introduce the QR-Orth optimization scheme, which
replaces expensive alternating optimization with a more efficient solution. In
a variety of model quantization experiments, DartQuant demonstrates superior
performance. Compared to existing methods, it achieves 47$\times$ acceleration
and 10$\times$ memory savings for rotational optimization on a 70B model.
Furthermore, it is the first to successfully complete rotational calibration
for a 70B model on a single 3090 GPU, making quantization of large language
models feasible in resource-constrained environments. Code is available at
https://github.com/CAS-CLab/DartQuant.git.

</details>


### [128] [Pediatric Appendicitis Detection from Ultrasound Images](https://arxiv.org/abs/2511.04069)
*Fatemeh Hosseinabadi,Seyedhassan Sharifi*

Main category: cs.LG

TL;DR: 研究开发了一种基于预训练ResNet架构的深度学习模型，通过自动分析超声图像来检测儿童急性阑尾炎。该模型在识别阑尾炎方面显示出强劲的性能，准确率为93.44%，精确率为91.53%，召回率为89.8%。


<details>
  <summary>Details</summary>
Motivation: 儿科急性阑尾炎是儿童中最常见导致急性腹痛的原因之一，但由于症状重叠和成像质量的变化，其诊断对临床医生来说一直是一个挑战。这项研究旨在通过发展基于深度学习的方法来提高诊断准确性，特别是利用超声图像。

Method: 研究使用了Regensburg儿科阑尾炎数据集，包括超声扫描、实验室数据和临床评分。为了基于图像的任务分类，研究团队对ResNet进行微调，以区分阑尾炎与非阑尾炎案例。图像通过规范化、重新调整大小和增强来处理，以提升泛化能力。

Result: 所提出的ResNet模型具有93.44%的整体准确率，91.53%的精度和89.8%的召回率，表明其在识别儿童的阑尾炎方面表现优异，特别是在处理低对比度、斑点噪声和解剖变异等挑战时。

Conclusion: 该模型能有效学习鉴别空间特征，从而克服儿科成像中的多种挑战，显示了基于预训练深度学习技术在儿科急性阑尾炎检测中的潜力。

Abstract: Pediatric appendicitis remains one of the most common causes of acute
abdominal pain in children, and its diagnosis continues to challenge clinicians
due to overlapping symptoms and variable imaging quality. This study aims to
develop and evaluate a deep learning model based on a pretrained ResNet
architecture for automated detection of appendicitis from ultrasound images. We
used the Regensburg Pediatric Appendicitis Dataset, which includes ultrasound
scans, laboratory data, and clinical scores from pediatric patients admitted
with abdominal pain to Children Hospital. Hedwig in Regensburg, Germany. Each
subject had 1 to 15 ultrasound views covering the right lower quadrant,
appendix, lymph nodes, and related structures. For the image based
classification task, ResNet was fine tuned to distinguish appendicitis from
non-appendicitis cases. Images were preprocessed by normalization, resizing,
and augmentation to enhance generalization. The proposed ResNet model achieved
an overall accuracy of 93.44, precision of 91.53, and recall of 89.8,
demonstrating strong performance in identifying appendicitis across
heterogeneous ultrasound views. The model effectively learned discriminative
spatial features, overcoming challenges posed by low contrast, speckle noise,
and anatomical variability in pediatric imaging.

</details>


### [129] [Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with Multiple Filters](https://arxiv.org/abs/2511.04073)
*Ananya Sutradhar,Suryansh Gupta,Ravishankar Krishnaswamy,Haiyang Xu,Aseem Rastogi,Gopal Srinivasa*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法，通过从数据中学习最优的距离和过滤器匹配的权衡，解决了传统的固定惩罚方法在面对不同数据集时的泛化能力不足的问题。实验表明，这种方法可以提高5-10%的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的方法使用固定的数据独立惩罚，导致在面对不同标签和向量分布的数据集时泛化能力不足。因此，需要一种数据驱动的方法，以提高过滤近邻搜索的准确性和泛化能力。

Method: 本文将问题形式化为一个约束线性优化问题，通过从数据中学习权重，而不是使用固定惩罚，来更好地反映过滤分布，从而更有效地解决过滤近邻搜索问题。这些学习到的权重指导搜索过程和索引构建，使构建的图结构更能有效捕捉过滤分布和过滤语义。

Result: 实验结果表明，自适应距离函数的方法在准确性上比固定惩罚方法提高了5-10%。

Conclusion: 本文提出了一种更加灵活和泛化的框架来解决过滤近邻搜索问题。

Abstract: Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest
vectors for a query vector from a dataset. It enforces that a specified set of
discrete labels $S$ for the query must be included in the labels of each
retrieved vector. Existing graph-based methods typically incorporate filter
awareness by assigning fixed penalties or prioritizing nodes based on filter
satisfaction. However, since these methods use fixed, data in- dependent
penalties, they often fail to generalize across datasets with diverse label and
vector distributions. In this work, we propose a principled alternative that
learns the optimal trade-off between vector distance and filter match directly
from the data, rather than relying on fixed penalties. We formulate this as a
constrained linear optimization problem, deriving weights that better reflect
the underlying filter distribution and more effectively address the filtered
ANN search problem. These learned weights guide both the search process and
index construction, leading to graph structures that more effectively capture
the underlying filter distribution and filter semantics. Our experiments
demonstrate that adapting the distance function to the data significantly im-
proves accuracy by 5-10% over fixed-penalty methods, providing a more flexible
and generalizable framework for the filtered ANN search problem.

</details>


### [130] [KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and Governance in Korea](https://arxiv.org/abs/2511.04094)
*Hyungjong Na,Wonho Song,Seungyong Han,Donghyeon Jo,Sejin Myung,Hyungjoon Kim*

Main category: cs.LG

TL;DR: KoTaP 是一个2011至2024年间韩国科斯比和科斯达克上市的非金融企业长期面板数据集，用于研究企业税收规避与其他领域，如盈利能力和公司治理之间的关系。数据集包括多项调整后的税收规避指标，确保国际文献的一致性和韩国企业的独特性。它支持多种研究应用，加强会计、金融等领域研究质量。


<details>
  <summary>Details</summary>
Motivation: 希望通过KoTaP数据集来研究企业税收规避对于企业其他经济指标的影响，同时强调企业税收规避与其他领域（如盈利与增长、财务稳定性、公司治理等）之间的联系，并展示韩国公司特有的治理结构和财务特性。

Method: KoTaP是通过从金融和财务报表中提取数据形成的一个长期面板数据集，包括了2011年到2024年间12,653个企业的年度观察结果，同时利用CETR、GETR和TSTA等指标来衡量税收规避行为。此外，还进行了标准化处理，确保数据的核心指标的分布及联系与国际文献的通用性一致，但又能反映韩国企业特有的治理特点。

Result: 该数据集使得研究者能够评估税收规避对企业盈利、稳定性、增长、治理等方面的影响，以及这些指标的相关性。此外，它还能用于政策评估、审计计划和投资分析等领域的应用研究。

Conclusion: KoTaP为学者提供了一个有价值的资源，用于深入理解税收规避行为及其对企业各方面影响的机制，同时支持国际比较研究及针对韩国市场特点的理论发展。这个数据集将在促进会计、金融及其他跨学科领域的前沿研究中发挥重要作用。

Abstract: This study introduces the Korean Tax Avoidance Panel (KoTaP), a long-term
panel dataset of non-financial firms listed on KOSPI and KOSDAQ between 2011
and 2024. After excluding financial firms, firms with non-December fiscal year
ends, capital impairment, and negative pre-tax income, the final dataset
consists of 12,653 firm-year observations from 1,754 firms. KoTaP is designed
to treat corporate tax avoidance as a predictor variable and link it to
multiple domains, including earnings management (accrual- and activity-based),
profitability (ROA, ROE, CFO, LOSS), stability (LEV, CUR, SIZE, PPE, AGE,
INVREC), growth (GRW, MB, TQ), and governance (BIG4, FORN, OWN). Tax avoidance
itself is measured using complementary indicators cash effective tax rate
(CETR), GAAP effective tax rate (GETR), and book-tax difference measures (TSTA,
TSDA) with adjustments to ensure interpretability. A key strength of KoTaP is
its balanced panel structure with standardized variables and its consistency
with international literature on the distribution and correlation of core
indicators. At the same time, it reflects distinctive institutional features of
Korean firms, such as concentrated ownership, high foreign shareholding, and
elevated liquidity ratios, providing both international comparability and
contextual uniqueness. KoTaP enables applications in benchmarking econometric
and deep learning models, external validity checks, and explainable AI
analyses. It further supports policy evaluation, audit planning, and investment
analysis, making it a critical open resource for accounting, finance, and
interdisciplinary research.

</details>


### [131] [Exploring the Feasibility of End-to-End Large Language Model as a Compiler](https://arxiv.org/abs/2511.04132)
*Hongbin Zhang,Shihao Gao,Yang Liu,Mingjie Xing,Yanjun Wu,Chen Zhao*

Main category: cs.LG

TL;DR: 本文探讨了大型语言模型作为编译器的可行性及其未来方向。研究设计了CompilerEval数据集和框架来评估大型语言模型在源代码理解和汇编代码生成中的能力，并提出了优化模型和服务的策略，对大型语言模型作为编译器的未来发展持乐观态度。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型技术在各个领域展现巨大优势的同时，其作为编译器的潜力仍然被忽视。为了探索大型语言模型作为编译器的可行性和未来研究方向，本研究通过设计数据集和框架来评估其能力并尝试改善其生成代码的质量。目的是挖掘大型语言模型在编译过程中的潜力。

Method: 设计了一个名为CompilerEval的数据集和框架用于测试主流语言模型在源代码理解和汇编代码生成中的能力，并探索了通过优化提示词、扩大模型规模和引入推理方法等方式提高生成代码质量的方法。

Result: 实验结果显示，语言模型显示出基本的编译器功能，但是成功率较低。通过优化提示词、扩大模型和使用推理方法，可以显著提高生成汇编代码的质量。

Conclusion: 通过对大型语言模型作为编译器的评估和策略改进，研究团队显示了对未来LaLaC的乐观态度，提出了一系列设计架构和未来研究方向，认为其在经过针对性训练后能够生成高质量的汇编代码，引领编译领域的新一轮技术革新。

Abstract: In recent years, end-to-end Large Language Model (LLM) technology has shown
substantial advantages across various domains. As critical system software and
infrastructure, compilers are responsible for transforming source code into
target code. While LLMs have been leveraged to assist in compiler development
and maintenance, their potential as an end-to-end compiler remains largely
unexplored. This paper explores the feasibility of LLM as a Compiler (LaaC) and
its future directions. We designed the CompilerEval dataset and framework
specifically to evaluate the capabilities of mainstream LLMs in source code
comprehension and assembly code generation. In the evaluation, we analyzed
various errors, explored multiple methods to improve LLM-generated code, and
evaluated cross-platform compilation capabilities. Experimental results
demonstrate that LLMs exhibit basic capabilities as compilers but currently
achieve low compilation success rates. By optimizing prompts, scaling up the
model, and incorporating reasoning methods, the quality of assembly code
generated by LLMs can be significantly enhanced. Based on these findings, we
maintain an optimistic outlook for LaaC and propose practical architectural
designs and future research directions. We believe that with targeted training,
knowledge-rich prompts, and specialized infrastructure, LaaC has the potential
to generate high-quality assembly code and drive a paradigm shift in the field
of compilation.

</details>


### [132] [Exchange Policy Optimization Algorithm for Semi-Infinite Safe Reinforcement Learning](https://arxiv.org/abs/2511.04147)
*Jiaming Zhang,Yujie Yang,Haoning Wang,Liping Zhang,Shengbo Eben Li*

Main category: cs.LG

TL;DR: 本文提出了交换策略优化（EPO）算法框架，用于解决半无限安全强化学习（SI-safe RL）问题，可实现最优策略性能和确定性的有界安全性。EPO通过迭代求解具有有限约束集的安全强化学习子问题，并通过约束集的动态调整来优化策略。理论分析表明，EPO训练的策略性能接近最优解，并且全局约束违规量保持在一定限值内。


<details>
  <summary>Details</summary>
Motivation: 安全强化学习的目标是在满足安全要求的同时优化长期性能，但在许多实际应用中，存在无限数量的约束，即半无限安全强化学习问题。这些问题普遍存在连续参数空间上的安全条件，如确保每处位置的资源分布适当。现有的方法无法有效处理这类问题，因此需要一个全新的算法框架来解决半无限安全强化学习问题。本文的动机在于提出交换策略优化算法框架(EPO)，以解决半无限安全强化学习，确保最优的策略性能和有界的确定安全性。

Method: EPO算法通过迭代求解具有有限约束集的安全强化学习子问题，每一步迭代中，先将违反预设容差的约束加入到当前策略需满足的约束集中，再将零拉格朗日乘子的约束从约束集中剔除，这样的交换规则避免了当前需满足的约束集的无序增长，最终促进了政策的有效训练。通过不断更新策略，EPO能够逐步逼近最优策略。

Result: 理论分析显示，基于EPO方法训练的策略在性能上接近于最优策略，同时全局约束违规量被严格地保持在预设的限值以内。这表明EPO方法能够在满足安全要求的同时，实现接近最优的性能，因此能够在涉及连续参数空间的安全强化学习中广泛应用。

Conclusion: 交换策略优化（EPO）算法框架克服了现有方法无法处理半无限安全强化学习存在的问题，通过高效的策略优化，实现了最优的策略性能和有界的确定的安全性，为处理具有复杂约束条件的安全强化学习问题提供了一个有效的解决方案。

Abstract: Safe reinforcement learning (safe RL) aims to respect safety requirements
while optimizing long-term performance. In many practical applications,
however, the problem involves an infinite number of constraints, known as
semi-infinite safe RL (SI-safe RL). Such constraints typically appear when
safety conditions must be enforced across an entire continuous parameter space,
such as ensuring adequate resource distribution at every spatial location. In
this paper, we propose exchange policy optimization (EPO), an algorithmic
framework that achieves optimal policy performance and deterministic bounded
safety. EPO works by iteratively solving safe RL subproblems with finite
constraint sets and adaptively adjusting the active set through constraint
expansion and deletion. At each iteration, constraints with violations
exceeding the predefined tolerance are added to refine the policy, while those
with zero Lagrange multipliers are removed after the policy update. This
exchange rule prevents uncontrolled growth of the working set and supports
effective policy training. Our theoretical analysis demonstrates that, under
mild assumptions, strategies trained via EPO achieve performance comparable to
optimal solutions with global constraint violations strictly remaining within a
prescribed bound.

</details>


### [133] [Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories](https://arxiv.org/abs/2511.04155)
*Olav Finne Praesteng Larsen,Massimiliano Ruocco,Michail Spitieris,Abdulmajid Murad,Martina Ragosta*

Main category: cs.LG

TL;DR: 本文研究了是否可以通过迁移学习将训练于数据丰富的机场的生成模型应用于数据稀缺的机场。实验结果表明，基于扩散的模型在5%的目标机场数据上就能达到良好的性能，并且随着目标机场数据量的增加，性能持续提升，优于从零训练的模型。这表明迁移学习可以显著降低轨迹生成所需的训练数据量，有助于在数据有限的环境中生成逼真的合成数据，进而提高空中交通管理（ATM）解决方案的开发和验证能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于开发空管解决方案时，尤其是次级和区域机场，面临着轨迹数据严重不足的问题，这限制了机器学习方法的应用和大规模仿真分析的进行。本文旨在研究通过迁移学习，是否能够充分利用数据丰富的机场的数据来辅助数据稀缺机场的模型训练和性能提升。

Method: 本研究将状态-of-the-art的扩散模型和潜在流匹配架构应用到航空领域，以苏黎世机场作为数据丰富的来源机场，都柏林机场作为数据稀缺的目标机场，进行模型预训练和微调的实验。微调的数据占比从0%到100%不等，以此来研究不同比例的本地数据对模型生成能力的影响。

Result: 实验结果表明，基于扩散的模型即使仅使用都柏林机场5%的数据也能达到性能基准，并且随着使用目标机场数据量增加，性能持续提升，表现出色。而流匹配模型和潜在扩散模型也能从预训练中获益，但表现不如基于扩散的模型稳定。整体而言，基于扩散的模型显著优于从零训练的模型。

Conclusion: 研究得出结论，迁移学习在轨迹生成中显示出巨大潜力，能够显著降低对丰富训练数据的依赖，特别是在数据稀缺的航空环境中。这为生成逼真的合成轨迹数据提供了可能性，进而推动了空中交通管理（ATM）系统开发和验证过程的进一步发展。

Abstract: Access to trajectory data is a key requirement for developing and validating
Air Traffic Management (ATM) solutions, yet many secondary and regional
airports face severe data scarcity. This limits the applicability of machine
learning methods and the ability to perform large-scale simulations or
"what-if" analyses. In this paper, we investigate whether generative models
trained on data-rich airports can be efficiently adapted to data-scarce
airports using transfer learning. We adapt state-of-the-art diffusion- and
flow-matching-based architectures to the aviation domain and evaluate their
transferability between Zurich (source) and Dublin (target) landing trajectory
datasets. Models are pretrained on Zurich and fine-tuned on Dublin with varying
amounts of local data, ranging from 0% to 100%. Results show that
diffusion-based models achieve competitive performance with as little as 5% of
the Dublin data and reach baseline-level performance around 20%, consistently
outperforming models trained from scratch across metrics and visual
inspections. Latent flow matching and latent diffusion models also benefit from
pretraining, though with more variable gains, while flow matching models show
weaker generalization. Despite challenges in capturing rare trajectory
patterns, these findings demonstrate the potential of transfer learning to
substantially reduce data requirements for trajectory generation in ATM,
enabling realistic synthetic data generation even in environments with limited
historical records.

</details>


### [134] [Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data](https://arxiv.org/abs/2511.04158)
*Anzhuo Xie,Wei-Chen Chang*

Main category: cs.LG

TL;DR: 提出了一种基于Transformer的纵向建模方法，旨在解决电子健康记录数据异质性带来的临床风险分类挑战。通过自注意力机制和可学习的时间编码机制，模型能够处理不规则的时间模式和复杂的语义结构，优于传统机器学习和时序深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 为了应对电子健康记录数据中的异质性挑战，包括不规则时间模式、模态差异性和复杂的语义结构，该研究提出了一种新的纵向建模方法。此项研究的主要动机是提高临床风险分类的准确性，特别适用于处理多源异质电子健康记录数据。

Method: 此方法采用特征嵌入层来实现结构化和非结构化数据的统一表示，并通过可学习的时间编码机制捕获不均等时间间隔下的动态演化。核心模型采用多头自注意力结构，进行纵向序列的全局依赖建模，有效的融合了长时间趋势和短时间波动。此外，设计了语义加权池化模块，以自适应的重要性分配关键医疗事件，增强语义表示。最后，通过线性映射层生成个体级别的风险评分。

Result: 实验结果表明，提出的模型在准确性、召回率、精确率和F1分数方面优于传统机器学习和时序深度学习模型，展现了在多源异质EHR环境下，稳定的出色风险识别能力。

Conclusion: 该研究提出了一种基于Transformer的纵向建模方法，为解决临床风险分类中的不规则时间模式、模态差异性和复杂的语义结构挑战提供了有效的解决方案，成为临床智能化决策的可靠框架。

Abstract: This study proposes a Transformer-based longitudinal modeling method to
address challenges in clinical risk classification with heterogeneous
Electronic Health Record (EHR) data, including irregular temporal patterns,
large modality differences, and complex semantic structures. The method takes
multi-source medical features as input and employs a feature embedding layer to
achieve a unified representation of structured and unstructured data. A
learnable temporal encoding mechanism is introduced to capture dynamic
evolution under uneven sampling intervals. The core model adopts a multi-head
self-attention structure to perform global dependency modeling on longitudinal
sequences, enabling the aggregation of long-term trends and short-term
fluctuations across different temporal scales. To enhance semantic
representation, a semantic-weighted pooling module is designed to assign
adaptive importance to key medical events, improving the discriminative ability
of risk-related features. Finally, a linear mapping layer generates
individual-level risk scores. Experimental results show that the proposed model
outperforms traditional machine learning and temporal deep learning models in
accuracy, recall, precision, and F1-Score, achieving stable and precise risk
identification in multi-source heterogeneous EHR environments and providing an
efficient and reliable framework for clinical intelligent decision-making.

</details>


### [135] [On Joint Regularization and Calibration in Deep Ensembles](https://arxiv.org/abs/2511.04160)
*Laurits Fredsgaard,Mikkel N. Schmidt*

Main category: cs.LG

TL;DR: 本文研究了联合调优权重衰减、温度缩放和提前停止对深度集成模型的预测性能和不确定性量化的影响，并提出了一种部分重叠的留出策略作为权衡方案。结果表明，联合调优通常能够匹配或提升性能，且有显著的跨任务和指标的效果差异。


<details>
  <summary>Details</summary>
Motivation: 虽然一般通过独立训练和调优单独的模型来形成集成，但研究表明，联合调优整个集成可以带来更好的性能。这项研究的动机是探索在深度集成模型中联合调优参数对预测性能和不确定性量化的影响，以及为那些希望优化深度集成模型的提供有价值的见解和指导。

Method: 本文的方法探索了联合优化权重衰减、温度缩放、提前停止等参数，提出了一种部分重叠的留出策略作为权衡方案，以实现联合评估和最大化训练数据的使用之间的平衡。

Result: 结果表明，联合调优集成模型可以匹配或提升性能，不同任务和指标之间存在显著的效果差异。使用部分重叠的留出策略可以作为一个有效的实践解决方案。

Conclusion: 本文得出了在深度集成模型中，联合调优可以带来性能提升或相匹配的结论，强调了个体优化和联合优化之间的权衡，在实践中推荐使用部分重叠的留出策略来优化深度集成模型。

Abstract: Deep ensembles are a powerful tool in machine learning, improving both model
performance and uncertainty calibration. While ensembles are typically formed
by training and tuning models individually, evidence suggests that jointly
tuning the ensemble can lead to better performance. This paper investigates the
impact of jointly tuning weight decay, temperature scaling, and early stopping
on both predictive performance and uncertainty quantification. Additionally, we
propose a partially overlapping holdout strategy as a practical compromise
between enabling joint evaluation and maximizing the use of data for training.
Our results demonstrate that jointly tuning the ensemble generally matches or
improves performance, with significant variation in effect size across
different tasks and metrics. We highlight the trade-offs between individual and
joint optimization in deep ensemble training, with the overlapping holdout
strategy offering an attractive practical solution. We believe our findings
provide valuable insights and guidance for practitioners looking to optimize
deep ensemble models. Code is available at:
https://github.com/lauritsf/ensemble-optimality-gap

</details>


### [136] [Block Rotation is All You Need for MXFP4 Quantization](https://arxiv.org/abs/2511.04214)
*Yuantian Shao,Peisong Wang,Yuanteng Chen,Chang Xu,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: 研究提出了一种针对MXFP4格式的后训练量化策略，改善了现有方法在MXFP4上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法针对INT4格式设计，但在新兴的MXFP4格式上存在性能问题，尤其是旋转基方法无法很好地适配MXFP4格式。研究旨在建立MXFP4下的量化基准，并解决量化基准与MXFP4兼容性问题。

Method: 研究评估了现有的量化方法在MXFP4格式下的性能，分析了旋转基方法与MXFP4的不兼容性，提出了针对MXFP4的适应性旋转策略。

Result: 提出的适应性旋转策略在多种大模型上取得了显著的精度改善。

Conclusion: 研究为实际应用提供了宝贵的指导，并为新兴低精度格式下的量化研究奠定了基础。

Abstract: Large language models (LLMs) have achieved remarkable success, but their
rapidly growing scale imposes prohibitive costs in memory, computation, and
energy. Post-training quantization (PTQ) is a promising solution for efficient
deployment, yet achieving accurate W4A4 quantization remains an open challenge.
While most existing methods are designed for INT4 formats, the emergence of
MXFP4 -- a new FP4 format with various hardware support (NVIDIA, AMD, Intel)--
raises questions about the applicability of current techniques. In this work,
we establish a comprehensive benchmark of PTQ methods under the MXFP4 format.
Through systematic evaluation, we find that methods like GPTQ consistently
deliver strong performance, whereas rotation-based approaches, which are almost
used by all state-of-the-art approaches, suffer from severe incompatibility
with MXFP4. We further provide the first in-depth analysis of this conflict,
tracing its root to a fundamental mismatch between MXFP4's PoT (power-of-two)
block scaling and the redistribution of outlier energy via global rotation.
Building on this insight, we propose a simple yet effective block rotation
strategy that adapts rotation-based methods to MXFP4, leading to substantial
accuracy improvements across diverse LLMs. Our findings not only offer clear
guidance for practitioners but also set a foundation for advancing PTQ research
under emerging low-precision formats.

</details>


### [137] [The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms](https://arxiv.org/abs/2511.04217)
*Hikari Otsuka,Daiki Chijiwa,Yasuyuki Okoshi,Daichi Fujiki,Susumu Takeuchi,Masato Motomura*

Main category: cs.LG

TL;DR: 本文提出了一种关于多头注意力机制（MHA）存在强彩票假设（SLTH）的理论分析，并证明了随机初始化的MHA包含有近似任意相同输入维度的MHA的SLT的概率很高，同时将SLTH扩展到没有归一化层的Transformer上，并通过实验验证了理论发现，即源模型的隐藏维度增大时，SLT与目标近似模型之间的近似误差会呈指数级下降。


<details>
  <summary>Details</summary>
Motivation: 尽管最近的理论研究在各种神经架构上已经建立了强彩票假设，但转换器架构上的强彩票假设理论理解仍然不足。特别是在现有的SLTH理论中，没有考虑多头注意力这种转换器的核心组成部分。因此，提出了MHA中存在的SLTH的理论分析，以填补这一空白。

Method: 通过证明随机初始化的MHA包含一个可以近似任意具有相同输入维度的MHA的SLT的概率很高，验证SLTH在没有归一化层的转换器上传递。

Result: 实验结果表明，通过增加源模型的隐藏维度，SLT和目标近似模型之间的近似误差呈指数级下降。

Conclusion: 该研究首次对多头注意力机制中的强彩票假设的存在性进行了理论分析，并通过实验验证了这一理论假设。

Abstract: The strong lottery ticket hypothesis (SLTH) conjectures that high-performing
subnetworks, called strong lottery tickets (SLTs), are hidden in randomly
initialized neural networks. Although recent theoretical studies have
established the SLTH across various neural architectures, the SLTH for
transformer architectures still lacks theoretical understanding. In particular,
the current theory of the SLTH does not yet account for the multi-head
attention (MHA) mechanism, a core component of transformers. To address this
gap, we introduce a theoretical analysis of the existence of SLTs within MHAs.
We prove that, if a randomly initialized MHA of $H$ heads and input dimension
$d$ has the hidden dimension $O(d\log(Hd^{3/2}))$ for the key and value, it
contains an SLT that approximates an arbitrary MHA with the same input
dimension with high probability. Furthermore, by leveraging this theory for
MHAs, we extend the SLTH to transformers without normalization layers. We
empirically validate our theoretical findings, demonstrating that the
approximation error between the SLT within a source model (MHA and transformer)
and an approximate target counterpart decreases exponentially by increasing the
hidden dimension of the source model.

</details>


### [138] [seqme: a Python library for evaluating biological sequence design](https://arxiv.org/abs/2511.04239)
*Rasmus Møller-Larsen,Adam Izdebski,Jan Olszewski,Pankhil Gawade,Michal Kmicikiewicz,Wojciech Zarzecki,Ewa Szczurek*

Main category: cs.LG

TL;DR: 介绍了seqme，一个适用于评估生物序列设计计算方法的模块化、高度可扩展的开源Python库。该库包含基于序列、嵌入和属性的三组指标，并提供了广泛的生物序列评估功能，适用于不同的设计方法。


<details>
  <summary>Details</summary>
Motivation: 在生物序列设计的计算方法方面，需要一种软件库来评估这些方法的性能，包括序列设计的保真度及其期望的属性，但这一工具仍然缺失。seqme应运而生，填补了这一空白。

Method: seqme库集合了三类评估指标（序列基、嵌入基和属性基），并提供了一系列模型和工具，用于评估和可视化各种生物序列（如小分子、DNA、ncRNA等）的设计方法。

Result: seqme是一个动态的开源库，支持广泛类型的生物序列及其设计方法的评估。它既适用于单次设计，也适用于迭代设计过程。

Conclusion: seqme的发布，为主流的生物序列设计提供了强有力的工具支持，可以提升对这些设计方法的理解，并促进相关领域的发展。

Abstract: Recent advances in computational methods for designing biological sequences
have sparked the development of metrics to evaluate these methods performance
in terms of the fidelity of the designed sequences to a target distribution and
their attainment of desired properties. However, a single software library
implementing these metrics was lacking. In this work we introduce seqme, a
modular and highly extendable open-source Python library, containing
model-agnostic metrics for evaluating computational methods for biological
sequence design. seqme considers three groups of metrics: sequence-based,
embedding-based, and property-based, and is applicable to a wide range of
biological sequences: small molecules, DNA, ncRNA, mRNA, peptides and proteins.
The library offers a number of embedding and property models for biological
sequences, as well as diagnostics and visualization functions to inspect the
results. seqme can be used to evaluate both one-shot and iterative
computational design methods.

</details>


### [139] [Guided by Stars: Interpretable Concept Learning Over Time Series via Temporal Logic Semantics](https://arxiv.org/abs/2511.04244)
*Irene Ferfoglia,Simone Silvetti,Gaia Saveri,Laura Nenzi,Luca Bortolussi*

Main category: cs.LG

TL;DR: STELLE 是一种结合分类和解释的时间序列分类方法，通过将时间序列直接嵌入到时态逻辑概念空间中实现。它提供准确的预测和可理解的逻辑解释，提高了模型的透明度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 时间序列分类任务在安全关键应用中非常重要，但传统的深度学习方法很难理解其预测背后的逻辑。为了克服这一挑战，研究提出了一种新的方法来增强模型的可解释性，同时保持高精度。

Method: STELLE 提出一个神经符号框架，通过新型的时态逻辑灵感核函数将原始时间序列映射到它们与预定义时态逻辑公式对齐的程度，从而共同优化准确性和可解释性。每项预测都会伴随有最相关的逻辑概念以解释它。

Result: 实验表明，STELLE 不仅达到了竞争性的准确性，还提供了逻辑忠实的解释，并在多种现实世界基准上进行了验证。

Conclusion: STELLE 展示了在时间序列分类中提供可解释性的重要步骤，以逻辑概念作为物理意义和预测结果之间的桥梁，提高了模型的可理解和验证性。

Abstract: Time series classification is a task of paramount importance, as this kind of
data often arises in safety-critical applications. However, it is typically
tackled with black-box deep learning methods, making it hard for humans to
understand the rationale behind their output. To take on this challenge, we
propose a novel approach, STELLE (Signal Temporal logic Embedding for
Logically-grounded Learning and Explanation), a neuro-symbolic framework that
unifies classification and explanation through direct embedding of trajectories
into a space of temporal logic concepts. By introducing a novel STL-inspired
kernel that maps raw time series to their alignment with predefined STL
formulae, our model jointly optimises accuracy and interpretability, as each
prediction is accompanied by the most relevant logical concepts that
characterise it. This yields (i) local explanations as human-readable STL
conditions justifying individual predictions, and (ii) global explanations as
class-characterising formulae. Experiments demonstrate that STELLE achieves
competitive accuracy while providing logically faithful explanations, validated
on diverse real-world benchmarks.

</details>


### [140] [Efficient Reinforcement Learning from Human Feedback via Bayesian Preference Inference](https://arxiv.org/abs/2511.04286)
*Matteo Cercola,Valeria Capretti,Simone Formentin*

Main category: cs.LG

TL;DR: 本研究提出了一种结合RLHF（强化学习的基于人类反馈）和PBO（偏好优化）的混合框架，旨在更有效地收集人类偏好数据，并在高维偏好优化和LLM（大语言模型）微调任务中表现出了更好的样本效率和整体性能提升。 


<details>
  <summary>Details</summary>
Motivation: 学习人类偏好是将机器学习模型与主观人类判断相结合的关键，但收集偏好数据往往成本高且耗时，促使人们需要更高效的机器学习范式。 

Method: 本研究结合了RLHF的大规模适用性和PBO的样本效率，通过在RLHF管道中集成基于获取的模块，以实现活跃且样本高效的偏好收集。该框架在一个高维偏好优化和一个大语言模型微调任务中得到了验证。 

Result: 实验结果表明，该方法在样本效率和整体表现上取得了持续改进。 

Conclusion: 研究展示了一种结合了RLHF的优点和PBO高效样本收集能力的混合框架，为高效学习人类偏好提供了有效的方法。 

Abstract: Learning from human preferences is a cornerstone of aligning machine learning
models with subjective human judgments. Yet, collecting such preference data is
often costly and time-consuming, motivating the need for more efficient
learning paradigms. Two established approaches offer complementary advantages:
RLHF scales effectively to high-dimensional tasks such as LLM fine-tuning,
while PBO achieves greater sample efficiency through active querying. We
propose a hybrid framework that unifies RLHF's scalability with PBO's query
efficiency by integrating an acquisition-driven module into the RLHF pipeline,
thereby enabling active and sample-efficient preference gathering. We validate
the proposed approach on two representative domains: (i) high-dimensional
preference optimization and (ii) LLM fine-tuning. Experimental results
demonstrate consistent improvements in both sample efficiency and overall
performance across these tasks.

</details>


### [141] [Differentially Private In-Context Learning with Nearest Neighbor Search](https://arxiv.org/abs/2511.04332)
*Antti Koskela,Tejas Kulkarni,Laith Zumot*

Main category: cs.LG

TL;DR: 本文提出了一种新的隐私保护框架用于在上下文学习（ICL）中整合最近邻搜索，以保持数据隐私，并改善隐私保护与性能之间的权衡。实验显示，新方法优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习方法存在隐私保护不足的问题，特别是在使用最近邻检索上下文数据时。为了提高隐私保护水平并改善性能，本文提出了一种新的隐私保护框架与最近邻检索结合的方法。

Method: 本文提出了一个隐私保护的框架，该框架通过从上下文数据数据库中进行最近邻检索，并结合隐私过滤机制，追踪所选样本的累计隐私成本，确保遵守中心差分隐私预算。

Result: 实验结果表明，所提出的方法在文本分类和文档问答任务上优于现有基线方法，显示出更好的隐私保护与性能之间的权衡。

Conclusion: 本文提出了一种新的隐私保护框架用于改善ICL中的隐私保护与性能之间的权衡，这将有助于推动隐私保护技术在大规模语言模型中的应用和发展。

Abstract: Differentially private in-context learning (DP-ICL) has recently become an
active research topic due to the inherent privacy risks of in-context learning.
However, existing approaches overlook a critical component of modern large
language model (LLM) pipelines: the similarity search used to retrieve relevant
context data. In this work, we introduce a DP framework for in-context learning
that integrates nearest neighbor search of relevant examples in a privacy-aware
manner. Our method outperforms existing baselines by a substantial margin
across all evaluated benchmarks, achieving more favorable privacy-utility
trade-offs. To achieve this, we employ nearest neighbor retrieval from a
database of context data, combined with a privacy filter that tracks the
cumulative privacy cost of selected samples to ensure adherence to a central
differential privacy budget. Experimental results on text classification and
document question answering show a clear advantage of the proposed method over
existing baselines.

</details>


### [142] [Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness](https://arxiv.org/abs/2511.04401)
*Subeen Park,Joowang Kim,Hakyung Lee,Sunjae Yoo,Kyungwoo Song*

Main category: cs.LG

TL;DR: 本文提出了SCER方法，通过在嵌入空间施加约束，抑制模型对虚假线索的依赖，使模型更专注于核心特征，以提高在少数群体中的模型鲁棒性。该方法在视觉和语言领域的系统评估中优于现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在解决模型依赖虚假相关性的问题上存在不足，缺乏理论框架将嵌入空间表示与少数群体错误联系起来，导致其在少数群体中的性能依然受限。

Method: 提出了Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness (SCER) 方法，该方法通过在嵌入空间施加约束，抑制模型对虚假线索的依赖，提高模型在少数群体中的鲁棒性。

Result: 通过在多个视觉和语言领域的系统评估中，证明了SCER可以提高少数群体中的模型准确率，优于现有最佳方法。

Conclusion: 通过在嵌入空间施加理论约束，SCER方法可以显著提高在少数群体中的模型鲁棒性，并且优于现有方法。

Abstract: Deep learning models achieve strong performance across various domains but
often rely on spurious correlations, making them vulnerable to distribution
shifts. This issue is particularly severe in subpopulation shift scenarios,
where models struggle in underrepresented groups. While existing methods have
made progress in mitigating this issue, their performance gains are still
constrained. They lack a rigorous theoretical framework connecting the
embedding space representations with worst-group error. To address this
limitation, we propose Spurious Correlation-Aware Embedding Regularization for
Worst-Group Robustness (SCER), a novel approach that directly regularizes
feature representations to suppress spurious cues. We show theoretically that
worst-group error is influenced by how strongly the classifier relies on
spurious versus core directions, identified from differences in group-wise mean
embeddings across domains and classes. By imposing theoretical constraints at
the embedding level, SCER encourages models to focus on core features while
reducing sensitivity to spurious patterns. Through systematic evaluation on
multiple vision and language, we show that SCER outperforms prior
state-of-the-art studies in worst-group accuracy. Our code is available at
\href{https://github.com/MLAI-Yonsei/SCER}{https://github.com/MLAI-Yonsei/SCER}.

</details>


### [143] [The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity](https://arxiv.org/abs/2511.04418)
*Tim Tomov,Dominik Fuchsgruber,Tom Wollschläger,Stephan Günnemann*

Main category: cs.LG

TL;DR: 当前不确定性量化方法在处理含糊数据时表现不佳，作者提出了两个新的数据集来测试不确定性量化模型在含糊情况下的表现，并理论分析了为何当前的方法在处理不确定性时存在局限性。该研究指出了大型语言模型中不确定性量化方法的关键不足，并提出了重新思考当前建模范式的需求。


<details>
  <summary>Details</summary>
Motivation: 当前的不确定性量化方法在评估时通常使用不含模糊性的情况进行基准测试，而实际上真实世界中的语言具有内在的模糊性。作者的动机是展示当前的不确定性估计方法在处理含糊数据时的不足，并提出新的数据集来更准确地评估不确定性量化方法。

Method: 作者提出了MAQA*和AmbigQA*两个新的含有模糊信息的问题回答数据集，同时使用了三种不同的估计范式来测试不确定性量化方法：预测分布自身、模型中的内部表示以及模型集合。

Result: 结果显示，所有三种估计范式在处理含糊数据时性能均下降至接近随机水平。研究理论分析了这种现象，并指出了预测分布和集合估计方法在这类情况下的固有局限性。

Conclusion: 研究揭示了当前大型语言模型中的不确定性量化方法存在的关键不足，并强调了重新思考和改进当前建模方法的重要性。

Abstract: Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is
critical for trustworthy deployment. While real-world language is inherently
ambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically
benchmarked against tasks with no ambiguity. In this work, we demonstrate that
while current uncertainty estimators perform well under the restrictive
assumption of no ambiguity, they degrade to close-to-random performance on
ambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first
ambiguous question-answering (QA) datasets equipped with ground-truth answer
distributions estimated from factual co-occurrence. We find this performance
deterioration to be consistent across different estimation paradigms: using the
predictive distribution itself, internal representations throughout the model,
and an ensemble of models. We show that this phenomenon can be theoretically
explained, revealing that predictive-distribution and ensemble-based estimators
are fundamentally limited under ambiguity. Overall, our study reveals a key
shortcoming of current UQ methods for LLMs and motivates a rethinking of
current modeling paradigms.

</details>


### [144] [Federated Stochastic Minimax Optimization under Heavy-Tailed Noises](https://arxiv.org/abs/2511.04456)
*Xinwen Zhang,Hongchang Gao*

Main category: cs.LG

TL;DR: 研究重尾噪声下的非凸PL最小最大优化问题，提出两种新算法Fed-NSGDA-M和FedMuon-DA，理论和实验验证了它们的有效性。


<details>
  <summary>Details</summary>
Motivation: 重尾噪声比标准方差假设更符合现实，研究其在联邦学习中的最小化最大值优化问题。目标是找到有效解决这一问题的算法。 

Method: 提出两种新的算法Fed-NSGDA-M和FedMuon-DA，用规范化梯度和Muon优化器解决重尾噪声。并且证明了算法的收敛速度为$O({1}/{(TNp)^{rac{s-1}{2s}}})$。 

Result: 新算法在理论上和实验上都显示出有效性，解决了重尾噪声下的联邦最小化最大值优化问题。 

Conclusion: 首次提出在重尾噪声下具有理论保障的联邦最小化最大值优化算法，这为现实问题提供了新的解决方案。

Abstract: Heavy-tailed noise has attracted growing attention in nonconvex stochastic
optimization, as numerous empirical studies suggest it offers a more realistic
assumption than standard bounded variance assumption. In this work, we
investigate nonconvex-PL minimax optimization under heavy-tailed gradient noise
in federated learning. We propose two novel algorithms: Fed-NSGDA-M, which
integrates normalized gradients, and FedMuon-DA, which leverages the Muon
optimizer for local updates. Both algorithms are designed to effectively
address heavy-tailed noise in federated minimax optimization, under a milder
condition. We theoretically establish that both algorithms achieve a
convergence rate of $O({1}/{(TNp)^{\frac{s-1}{2s}}})$. To the best of our
knowledge, these are the first federated minimax optimization algorithms with
rigorous theoretical guarantees under heavy-tailed noise. Extensive experiments
further validate their effectiveness.

</details>


### [145] [Towards Causal Market Simulators](https://arxiv.org/abs/2511.04469)
*Dennis Thumm,Luis Ontaneda Mijares*

Main category: cs.LG

TL;DR: 该论文提出了一种结合变分自编码器和结构因果模型的时间序列神经因果模型 (TNCM-VAE)，生成符合因果关系和时间依赖的合成金融市场数据，特别是在反事实概率估计方面表现出色，可用于金融压力测试、情景分析和增强回测等场景分析任务。


<details>
  <summary>Details</summary>
Motivation: 现有市场生成器缺乏因果推理能力，影响了反事实分析和风险评估。

Method: 提出结合变分自编码器和结构因果模型的时间序列神经因果模型（TNCM-VAE），在生成器解码器架构中引入因果限制，使用因果Wasserstein距离进行训练。

Result: 在合成自回归模型上进行验证，展示出在反事实概率估计上的优越表现，与其他方法相比，L1距离低至0.03-0.10。

Conclusion: 所提模型能生成符合因果机理的反事实的市场轨迹，从而增强金融市场分析，支持金融压力测试、情景分析和增强回测等任务。

Abstract: Market generators using deep generative models have shown promise for
synthetic financial data generation, but existing approaches lack causal
reasoning capabilities essential for counterfactual analysis and risk
assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that
combines variational autoencoders with structural causal models to generate
counterfactual financial time series while preserving both temporal
dependencies and causal relationships. Our approach enforces causal constraints
through directed acyclic graphs in the decoder architecture and employs the
causal Wasserstein distance for training. We validate our method on synthetic
autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating
superior performance in counterfactual probability estimation with L1 distances
as low as 0.03-0.10 compared to ground truth. The model enables financial
stress testing, scenario analysis, and enhanced backtesting by generating
plausible counterfactual market trajectories that respect underlying causal
mechanisms.

</details>


### [146] [Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge Graph Augmented LLMs](https://arxiv.org/abs/2511.04473)
*Alberto Cattaneo,Carlo Luschi,Daniel Justus*

Main category: cs.LG

TL;DR: SynthKGQA 是一个框架，用于从知识图中生成高质量的合成知识图问答数据集。该框架可以用于生成GTSQA数据集，以测试KG检索器的零样本泛化能力。通过该数据集可以更好地评估和支持LLMs的改进。


<details>
  <summary>Details</summary>
Motivation: 缺乏挑战性和具有真实目标的QA数据集，使得比较图检索方法变得困难。因此，开发了一个可以生成高质量合成数据集的框架，以支持LLMs的改进，提高其事实性。同时，证明该数据集本身可以用来训练更优秀的模型。

Method: 提出了SynthKGQA框架，能够从任何知识图中生成高质量的合成KGA问答数据集，并提供每个问题的完整的真实目标事实。

Result: 所生成的GTSQA数据集用于测试KG检索器的零样本泛化能力，同时，该数据集能够促进对方法的更全面和深入的理解。在该数据集上对比了流行的KG增强的LLMs解决方案的表现。

Conclusion: 通过实验展示了SynthKGQA框架可以有效地生成具有挑战性的数据集，这不仅可以支持更有效的KG检索方法的开发，同时也提高了LLMs的事实性。

Abstract: Retrieval of information from graph-structured knowledge bases represents a
promising direction for improving the factuality of LLMs. While various
solutions have been proposed, a comparison of methods is difficult due to the
lack of challenging QA datasets with ground-truth targets for graph retrieval.
We present SynthKGQA, a framework for generating high-quality synthetic
Knowledge Graph Question Answering datasets from any Knowledge Graph, providing
the full set of ground-truth facts in the KG to reason over each question. We
show how, in addition to enabling more informative benchmarking of KG
retrievers, the data produced with SynthKGQA also allows us to train better
models. We apply SynthKGQA to Wikidata to generate GTSQA, a new dataset
designed to test zero-shot generalization abilities of KG retrievers with
respect to unseen graph structures and relation types, and benchmark popular
solutions for KG-augmented LLMs on it.

</details>


### [147] [Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training](https://arxiv.org/abs/2511.04485)
*Ipsita Ghosh,Ethan Nguyen,Christian Kümmerle*

Main category: cs.LG

TL;DR: 提出了一种新的低秩训练策略Q3R，能够在保持低秩结构的同时有效地进行预训练，并在多个任务上实现了与密集模型相当的预测性能，其中包括Tranformers模型在图像和语言任务上的低秩微调任务。Q3R能够在不影响模型性能的情况下删除60%-80%的参数，计算开销小，与现有架构兼容。


<details>
  <summary>Details</summary>
Motivation: 现有基于低秩优化的参数高效训练方法在低秩预训练任务中表现不佳，需要一个新的方法来解决这一问题，以实现更好的低秩模型训练效果。Q3R旨在通过引入新的正则化机制来解决该问题，同时保持低秩结构和实现良好的预测性能。

Method: 提出了一种基于二次加权秩正则化的低秩训练策略Q3R，该策略受到了迭代重加权最小二乘法（IRLS）框架的启发。Q3R通过二次正则化项来近似替代一个平滑的对数行列式作为秩替代目标函数。Q3R能够训练出具有预定低秩目标的权重矩阵，同时保持与密集模型相当的预测性能和计算开销小。其方法能够在保持良好的预测性能的同时删除模型的大量参数。此外，方法对于现有的模型架构是完全兼容的。实验表明，在图像和语言任务上，包括低秩微调，Q3R均表现出了良好的效果。

Result: 实验表明，Q3R可以在不显著影响预测性能的情况下删除ViT-Tiny模型60%和80%的参数，分别仅在CIFAR-10任务上导致约1.3%和4%的准确率下降。另外，Q3R也在多个其他任务中表现出了优秀的效果，包括图像分类和自然语言处理等领域的任务。这些成果证实了Q3R在低秩训练中的有效性和通用性。

Conclusion: Q3R提供了一种新的低秩训练策略，能够显著降低大型深度学习模型的计算开销和参数量，同时保持良好的预测性能，且完全兼容现有的模型架构。未来的工作可以探索将Q3R应用于更多的任务和模型中，并进一步提高其性能。

Abstract: Parameter-efficient training, based on low-rank optimization, has become a
highly successful tool for fine-tuning large deep-learning models. However,
these methods fail at low-rank pre-training tasks where maintaining the
low-rank structure and the objective remains a challenging task. We propose the
Quadratic Reweighted Rank Regularizer dubbed Q3R, which leads to a novel
low-rank inducing training strategy inspired by the iteratively reweighted
least squares (IRLS) framework. Q3R is based on a quadratic regularizer term
which majorizes a smoothed log determinant serving as rank surrogate objective.
Unlike other low-rank training techniques, Q3R is able to train weight matrices
with prescribed, low target ranks of models that achieve comparable predictive
performance as dense models, with small computational overhead, while remaining
fully compatible with existing architectures. For example, we demonstrated one
experiment where we are able to truncate $60\%$ and $80\%$ of the parameters of
a ViT-Tiny model with $~1.3\%$ and $~4\%$ accuracy drop in CIFAR-10 performance
respectively. The efficacy of Q3R is confirmed on Transformers across both
image and language tasks, including for low-rank fine-tuning.

</details>


### [148] [Alternative Fairness and Accuracy Optimization in Criminal Justice](https://arxiv.org/abs/2511.04505)
*Shaolong Wu,James Blume,Geshi Yeung*

Main category: cs.LG

TL;DR: 本文提出了一种算法公平性的简单修改方法，通过最小化加权误差损失而不是追求标准群体间的绝对公平性，同时确保假阴性率在一定范围内。这一方法不仅可以减少解决方案的难度，提高预测准确性，还可以促进对错误成本的伦理选择。本文将其框架定位在三类批评中，并提出了一个具有三个支柱的实用框架用于公共决策系统：基于需求的决策，透明度与问责制，以及严格定义和解决的策略。


<details>
  <summary>Details</summary>
Motivation: 算法公平性研究快速发展，但在刑事司法领域，许多关键概念仍未得到明确。本文旨在探索群体公平、个体公平以及过程公平的概念，并探讨它们之间的冲突条件。

Method: 提出了一种新的算法模型，即最小化加权误差损失，同时将假阴性率保持在一定范围内，旨在调整标准的群体公平性。本文还讨论了此模型的三类批评，并提出了一个实用框架的应用，该框架由三个支柱组成：基于需求的决策，透明度与问责制，以及严格定义和解决的策略。

Result: 此方法不仅可以减少解决方案的搜索难度，还可以提高预测准确性，更重要的是，它推动了对错误成本的伦理选择。

Conclusion: 本文提供了算法公平性研究到实际应用之间的重要连接，为使用风险评估和相关工具的机构提供了实用的建议。

Abstract: Algorithmic fairness has grown rapidly as a research area, yet key concepts
remain unsettled, especially in criminal justice. We review group, individual,
and process fairness and map the conditions under which they conflict. We then
develop a simple modification to standard group fairness. Rather than exact
parity across protected groups, we minimize a weighted error loss while keeping
differences in false negative rates within a small tolerance. This makes
solutions easier to find, can raise predictive accuracy, and surfaces the
ethical choice of error costs. We situate this proposal within three classes of
critique: biased and incomplete data, latent affirmative action, and the
explosion of subgroup constraints. Finally, we offer a practical framework for
deployment in public decision systems built on three pillars: need-based
decisions, Transparency and accountability, and narrowly tailored definitions
and solutions. Together, these elements link technical design to legitimacy and
provide actionable guidance for agencies that use risk assessment and related
tools.

</details>


### [149] [Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers](https://arxiv.org/abs/2511.04514)
*C. Hepburn,T. Zielke,A. P. Raulf*

Main category: cs.LG

TL;DR: 本文实验研究了线性模式连接性(LMC)在数据偏移下的影响，并探讨了减缓其影响的条件。通过小学习率和大规模批量大小可减少噪声，从而让模型易于收敛到同一局部最小值或不同平滑度和泛化性能的区域。尽管通过LMC采样的模型比那些收敛到不同盆地的模型更容易犯相同的错误，但LMC的好处在于平衡训练效率与更大、更多样化的模型组合所带来的收益。代码和补充材料将在https://github.com/DLR-KI/LMC上公开发布。


<details>
  <summary>Details</summary>
Motivation: 研究线性模式连接性(LMC)在数据偏移下的影响，探讨如何减小此类偏移的影响，并平衡训练效率与模型多样性之间的关系

Method: 通过实验研究LMC在数据偏移下的影响,并探讨学习率、批量大小对模型收敛的影响

Result: 发现小学习率和大规模批量大小可以帮助模型更容易收敛到同一局部最小值或不同平滑度和泛化能力的区域；通过LMC采样的模型容易犯相同的错误但能平衡训练效率与模型多样性

Conclusion: 尽管LMC采样的模型容易犯相同的错误，但在平衡训练效率与更大、更多样性的模型组合之间的收益上，LMC具有优势

Abstract: The phenomenon of linear mode connectivity (LMC) links several aspects of
deep learning, including training stability under noisy stochastic gradients,
the smoothness and generalization of local minima (basins), the similarity and
functional diversity of sampled models, and architectural effects on data
processing. In this work, we experimentally study LMC under data shifts and
identify conditions that mitigate their impact. We interpret data shifts as an
additional source of stochastic gradient noise, which can be reduced through
small learning rates and large batch sizes. These parameters influence whether
models converge to the same local minimum or to regions of the loss landscape
with varying smoothness and generalization. Although models sampled via LMC
tend to make similar errors more frequently than those converging to different
basins, the benefit of LMC lies in balancing training efficiency against the
gains achieved from larger, more diverse ensembles. Code and supplementary
materials will be made publicly available at https://github.com/DLR-KI/LMC in
due course.

</details>


### [150] [Uncertainty Quantification for Reduced-Order Surrogate Models Applied to Cloud Microphysics](https://arxiv.org/abs/2511.04534)
*Jonas E. Katona,Emily K. de Jong,Nipun Gunawardena*

Main category: cs.LG

TL;DR: 介绍了一个适用于降阶模型（ROMs）的后验不确定性量化框架，该框架可以在不修改原始架构或训练过程的情况下估算降阶模型各个组件的预测区间。该方法在云微物理动态模型中进行了演示，展示了其准确性及适用性。


<details>
  <summary>Details</summary>
Motivation: 现有的不确定性量化方法通常依赖于特定的模型架构或训练方法，缺乏灵活性和通用性。为此，本文提出了一种新的不确定性量化框架，适用于广泛的ROMs。该框架具有后验性和模型无关性。

Method: 通过使用一致性预测，该框架可以为降阶模型的各个部分——潜态动力学、重建和端到端预测——估算统计预测区间。这个框架不需要修改原始架构或训练过程。

Result: 该方法在云微物理动态模型中得出了准确的预测，并且能够量化各个部分的不确定性。展示了其在ROMs不确定性量化中的潜力和鲁棒性。

Conclusion: 提出了一种在无需修改原始架构或训练过程的情况下进行的不确定性量化的后验模型无关框架，表明了该框架在诸如云微物理动态模型等应用中的有效性。

Abstract: Reduced-order models (ROMs) can efficiently simulate high-dimensional
physical systems, but lack robust uncertainty quantification methods. Existing
approaches are frequently architecture- or training-specific, which limits
flexibility and generalization. We introduce a post hoc, model-agnostic
framework for predictive uncertainty quantification in latent space ROMs that
requires no modification to the underlying architecture or training procedure.
Using conformal prediction, our approach estimates statistical prediction
intervals for multiple components of the ROM pipeline: latent dynamics,
reconstruction, and end-to-end predictions. We demonstrate the method on a
latent space dynamical model for cloud microphysics, where it accurately
predicts the evolution of droplet-size distributions and quantifies uncertainty
across the ROM pipeline.

</details>


### [151] [Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning](https://arxiv.org/abs/2511.04557)
*Divyansha Lachi,Mahmoud Mohammadi,Joe Meyer,Vinam Arora,Tom Palczewski,Eva L. Dyer*

Main category: cs.LG

TL;DR: 该论文提出了一种新的图模型Relational Graph Perceiver (RGP)，旨在处理富含时空动态的图数据，并支持多任务预测。RGP通过跨注意力机制将不同类型的节点和边信息整合到共同的潜在空间中，从而在时空上下文中高效地整合信息。实验表明，RGP在多种数据集上均表现出色，达到了最先进的性能水平。


<details>
  <summary>Details</summary>
Motivation: 当前的图模型主要关注空间结构，而忽视了时间信息的作用，且大多只支持单一任务预测，这无法充分处理复杂的关系数据。因此，本论文旨在开发一种既能处理时空依赖又能支持多任务预测的图模型。

Method: 该论文提出了Temporal Subgraph Sampler，用于捕获节点的临时相关关系，增强了全局上下文。此外，还提出了Relational Graph Perceiver (RGP)，一种基于跨注意力机制的图变换器架构，能在结构和时间背景下高效地整合信息。RGP的跨注意力解码器能支持在单一模型中同时学习具有不相交标签空间的任务。

Result: 实验结果表明，RGP在RelBench、SALT和CTU数据集上都达到了最先进的性能水平，展示了其处理多样预测任务的能力。

Conclusion: RGP提供了一种广泛适用且可扩展的解决方案，适用于包含多任务预测支持的关系深度学习。

Abstract: In domains such as healthcare, finance, and e-commerce, the temporal dynamics
of relational data emerge from complex interactions-such as those between
patients and providers, or users and products across diverse categories. To be
broadly useful, models operating on these data must integrate long-range
spatial and temporal dependencies across diverse types of entities, while also
supporting multiple predictive tasks. However, existing graph models for
relational data primarily focus on spatial structure, treating temporal
information merely as a filtering constraint to exclude future events rather
than a modeling signal, and are typically designed for single-task prediction.
To address these gaps, we introduce a temporal subgraph sampler that enhances
global context by retrieving nodes beyond the immediate neighborhood to capture
temporally relevant relationships. In addition, we propose the Relational Graph
Perceiver (RGP), a graph transformer architecture for relational deep learning
that leverages a cross-attention-based latent bottleneck to efficiently
integrate information from both structural and temporal contexts. This latent
bottleneck integrates signals from different node and edge types into a common
latent space, enabling the model to build global context across the entire
relational system. RGP also incorporates a flexible cross-attention decoder
that supports joint learning across tasks with disjoint label spaces within a
single model. Experiments on RelBench, SALT, and CTU show that RGP delivers
state-of-the-art performance, offering a general and scalable solution for
relational deep learning with support for diverse predictive tasks.

</details>


### [152] [ARETE: an R package for Automated REtrieval from TExt with large language models](https://arxiv.org/abs/2511.04573)
*Vasco V. Branco,Jandó Benedek,Lidia Pivovarova,Luís Correia,Pedro Cardoso*

Main category: cs.LG

TL;DR: 本文介绍了一个名为ARETE的R软件包，该软件包利用大型语言模型（如chatGPT API）实现了物种发生数据的自动化提取。ARETE在整个数据提取和验证过程中更加方便，从光学字符识别到异常值检测，最终输出为表格格式。通过系统地验证结果显示，ARETE的提取与人工注释的工作相当，利用ARETE软件包从100种蜘蛛中提取的数据可扩展物种的分布范围，揭示物种过去的发现区域。这对空间保护规划和灭绝风险评估具有重要意义。ARETE能更快地获取之前未开发的发生数据，提高资源优先级，使得研究人员能够集中精力手动验证选择的物种，同时保持大部分数据的自动化提取，还允许在项目规划期间预测可用的文献数据。


<details>
  <summary>Details</summary>
Motivation: 文章旨在解决由于人为活动加速了所需数据收集和处理的速度而导致的关键物种数据缺乏问题，尤其是发生的物种数据。现有的相关数据大多不被机器读取，需要大量的人力工作提取。为了克服这一难题，提出了使用大型语言模型的ARETE R软件包来自动化数据提取。

Method: ARETE R软件包利用大型语言模型（如chatGPT API）来自动化数据提取，涵盖了从光学字符识别到异常值检测的过程，并将结果输出为表格格式。同时，通过与人工注释的工作成果进行比较，来验证ARETE的有效性。研究人员利用ARETE从100种蜘蛛的文献中提取出现数据，显示了ARETE的应用场景和潜力。

Result: 借助ARETE软件包，扩展了100种蜘蛛物种的分布范围，新提取的数据将已知的物种发生区域平均扩展了三个数量级，揭示了过去物种发现的新区域，这对空间保护规划和灭绝风险评估具有重要意义。ARETE允许更快地获取之前未开发的数据，能够帮助研究人员更好地优先处理资源，同时大大提高了数据处理的效率。系统的验证也显示了ARETE的提取准确性与人工注释相当。

Conclusion: ARETE是一种有力的工具，它能够更快地访问过去难以利用的数据，这可能会改变需要这些数据的项目。这种工作流程也允许在项目规划期间预测可用的文献数据，这样可以更好地节省人力资源。同时，ARETE也为大规模的数据提取和验证提供了一种标准化和自动化的方法，有助于推进物种保护的科学工作。

Abstract: 1. A hard stop for the implementation of rigorous conservation initiatives is
our lack of key species data, especially occurrence data. Furthermore,
researchers have to contend with an accelerated speed at which new information
must be collected and processed due to anthropogenic activity. Publications
ranging from scientific papers to gray literature contain this crucial
information but their data are often not machine-readable, requiring extensive
human work to be retrieved. 2. We present the ARETE R package, an open-source
software aiming to automate data extraction of species occurrences powered by
large language models, namely using the chatGPT Application Programming
Interface. This R package integrates all steps of the data extraction and
validation process, from Optical Character Recognition to detection of outliers
and output in tabular format. Furthermore, we validate ARETE through systematic
comparison between what is modelled and the work of human annotators. 3. We
demonstrate the usefulness of the approach by comparing range maps produced
using GBIF data and with those automatically extracted for 100 species of
spiders. Newly extracted data allowed to expand the known Extent of Occurrence
by a mean three orders of magnitude, revealing new areas where the species were
found in the past, which mayhave important implications for spatial
conservation planning and extinction risk assessments. 4. ARETE allows faster
access to hitherto untapped occurrence data, a potential game changer in
projects requiring such data. Researchers will be able to better prioritize
resources, manually verifying selected species while maintaining automated
extraction for the majority. This workflow also allows predicting available
bibliographic data during project planning.

</details>


### [153] [Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest Path Problems](https://arxiv.org/abs/2511.04594)
*Utkarsh U. Chavan,Prashant Trivedi,Nandyala Hemachandra*

Main category: cs.LG

TL;DR: 本文研究了线性函数近似条件下的分布式多智能体最短路径问题，识别了最优策略的结构，并提出了首个针对该问题的遗憾下界，突出了分布式控制在多智能体系统中的学习难度.


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在单智能体的最短路径问题学习上，而分布式多智能体系统的该问题尚未被充分探索.

Method: 应用了基于对称性的新论证方法，构造了具有挑战性学习难度的实例.

Result: 识别了最优策略的结构，并提出了首个针对线性函数近似下的分布式多智能体最短路径问题的遗憾下界.

Conclusion: 这些结论澄清了分布式控制的学习复杂性，并可以进一步指导多智能体系统的高效学习算法的设计.

Abstract: Multi-agent systems (MAS) are central to applications such as swarm robotics
and traffic routing, where agents must coordinate in a decentralized manner to
achieve a common objective. Stochastic Shortest Path (SSP) problems provide a
natural framework for modeling decentralized control in such settings. While
the problem of learning in SSP has been extensively studied in single-agent
settings, the decentralized multi-agent variant remains largely unexplored. In
this work, we take a step towards addressing that gap. We study decentralized
multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the
transition dynamics and costs are represented using linear models. Applying
novel symmetry-based arguments, we identify the structure of optimal policies.
Our main contribution is the first regret lower bound for this setting based on
the construction of hard-to-learn instances for any number of agents, $n$. Our
regret lower bound of $\Omega(\sqrt{K})$, over $K$ episodes, highlights the
inherent learning difficulty in Dec-MASSPs. These insights clarify the learning
complexity of decentralized control and can further guide the design of
efficient learning algorithms in multi-agent systems.

</details>


### [154] [Efficient probabilistic surrogate modeling techniques for partially-observed large-scale dynamical systems](https://arxiv.org/abs/2511.04641)
*Hans Harder,Abhijeet Vishwasrao,Luca Guastoni,Ricardo Vinuesa,Sebastian Peitz*

Main category: cs.LG

TL;DR: 本文研究并比较了流匹配范式下的几种减少采样步骤的方法，包括直接蒸馏、逐步蒸馏、对抗扩散蒸馏、Wasserstein GANs 和修正流，并针对一系列具有挑战性的系统进行了实验，尤其是直接预测大规模 3D 模拟的 2D 切片，以实现高效生成的流入解算器的可能途径


<details>
  <summary>Details</summary>
Motivation: 减少预测复杂动力系统的采样步骤，尤其是在处理大型 3D 模拟时的复杂性

Method: 研究并比较了直接蒸馏、逐步蒸馏、对抗扩散蒸馏、Wasserstein GANs 和修正流等方法，并通过实验进行验证

Result: 实验结果表明，这些方法能够减少采样步骤，更有效地预测复杂的动力系统

Conclusion: 提出了有效减少采样步骤的预测方法，这些方法可以应用于大规模 3D 模拟的预测，实现更高效的注入解算器

Abstract: This paper is concerned with probabilistic techniques for forecasting
dynamical systems described by partial differential equations (such as, for
example, the Navier-Stokes equations). In particular, it is investigating and
comparing various extensions to the flow matching paradigm that reduce the
number of sampling steps. In this regard, it compares direct distillation,
progressive distillation, adversarial diffusion distillation, Wasserstein GANs
and rectified flows. Moreover, experiments are conducted on a set of
challenging systems. In particular, we also address the challenge of directly
predicting 2D slices of large-scale 3D simulations, paving the way for
efficient inflow generation for solvers.

</details>


### [155] [Optimal Inference Schedules for Masked Diffusion Models](https://arxiv.org/abs/2511.04647)
*Sitan Chen,Kevin Cong,Jerry Li*

Main category: cs.LG

TL;DR: 本文研究了扩散语言模型在逐次采样时，如何在不影响采样性能的情况下进行并行采样，并通过理论分析给出了采样步骤的上界，表明在某些自然场景下，可以以$O(log n)$的步骤进行采样而没有性能损失，其中$n$是序列的总长度。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的推理过程是逐次的，导致推理时间很长且昂贵。扩散语言模型试图通过并行采样来解决这一问题，但在性能无下降的前提下能实现多大程度的并行化，目前还没有严格的理解。本文旨在解决这一问题。

Method: 作者使用函数近似理论进行分析，给出了采样分布与真实分布之间的预期偏差的精确特征，并获得了不同分布和采样调度下的一些新颖的上下界。

Result: 结果表明，虽然一般情况下没有先验知识，无法在不牺牲性能的情况下竞争最优的采样调度，但在某些自然场景下，可以以$O(log n)$的步骤进行采样而没有性能损失。

Conclusion: 本文通过理论分析揭示了在不影响采样的前提下，扩散语言模型可以实现的并行采样能力，并提供了在一些自然情况下加速采样的新方法。

Abstract: A major bottleneck of standard auto-regressive large language models is that
their inference process is inherently sequential, resulting in very long and
costly inference times. To circumvent this, practitioners proposed a class of
language models called diffusion language models, of which the masked diffusion
model (MDM) is the most successful. The MDM is able to sample tokens
out-of-order and, ostensibly, many tokens at once and in parallel. However,
there is very limited rigorous understanding of how much parallel sampling
these models can perform without noticeable degradation in their sampling
performance. Prior work of Li and Cai obtained some preliminary bounds, but
these are not tight for many natural classes of distributions. In this work, we
give a new, exact characterization of the expected divergence between the true
distribution and the sampled distribution, for any distribution and any
unmasking schedule for the sampler, showing an elegant connection to the theory
of univariate function approximation.
  By leveraging this connection, we then attain a number of novel lower and
upper bounds for this problem. While the connection to function approximation
in principle gives the optimal unmasking schedule for any distribution, we show
that it is in general impossible to compete with it without strong a priori
knowledge of the distribution, even in seemingly benign settings. However, we
also demonstrate new upper bounds and new sampling schedules in terms of
well-studied information-theoretic properties of the base distribution, namely,
its total correlation and dual total correlation, which show that in some
natural settings, one can sample in $O(log n)$ steps without any visible loss
in performance, where $n$ is the total sequence length.

</details>


### [156] [TT-Prune: Joint Model Pruning and Resource Allocation for Communication-efficient Time-triggered Federated Learning](https://arxiv.org/abs/2511.04653)
*Xinlu Zhang,Yansha Deng,Toktam Mahmoodi*

Main category: cs.LG

TL;DR: 本文提出了在无线时间触发联邦学习（TT-Fed）系统中使用自适应模型修剪的方法，以优化修剪比率和带宽分配，从而在保证最小学习延迟的同时，最小化训练损失。实验结果显示，模型修剪可以减少40%的通信开销而不影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中存在由于设备数量增加和带宽有限导致的延迟和通信开销问题，特别是在时间触发联邦学习（TT-Fed）中。本文旨在通过自适应模型修剪技术解决这些问题，优化资源分配以提高效率和模型性能。

Method: 通过模型修剪和带宽优化来解决通信开销和延迟问题，分别在给定的延迟阈值下联合优化模型修剪比率和无线带宽分配。利用KKT条件导出最优带宽和修剪比率的封闭形式解，并对TT-Fed模型基于模型修剪的梯度L2范数进行收敛性分析。

Result: 实验结果显示，所提议的方法能够将通信开销减少40%，同时保持模型性能不变，从而成功地实现了训练损失的最小化和延迟的最小化目标。

Conclusion: 本文研究了无线时间触发联邦学习系统中的模型修剪和带宽优化问题，并提出了一种优化模型修剪比率和带宽分配的方法，证明了这种方法的有效性。

Abstract: Federated learning (FL) offers new opportunities in machine learning,
particularly in addressing data privacy concerns. In contrast to conventional
event-based federated learning, time-triggered federated learning (TT-Fed), as
a general form of both asynchronous and synchronous FL, clusters users into
different tiers based on fixed time intervals. However, the FL network consists
of a growing number of user devices with limited wireless bandwidth,
consequently magnifying issues such as stragglers and communication overhead.
In this paper, we introduce adaptive model pruning to wireless TT-Fed systems
and study the problem of jointly optimizing the pruning ratio and bandwidth
allocation to minimize the training loss while ensuring minimal learning
latency. To answer this question, we perform convergence analysis on the
gradient l_2 norm of the TT-Fed model based on model pruning. Based on the
obtained convergence upper bound, a joint optimization problem of pruning ratio
and wireless bandwidth is formulated to minimize the model training loss under
a given delay threshold. Then, we derive closed-form solutions for wireless
bandwidth and pruning ratio using Karush-Kuhn-Tucker(KKT) conditions. The
simulation results show that model pruning could reduce the communication cost
by 40% while maintaining the model performance at the same level.

</details>


### [157] [Nowcast3D: Reliable precipitation nowcasting via gray-box learning](https://arxiv.org/abs/2511.04659)
*Huaguan Chen,Wei Han,Haofei Sun,Ning Lin,Xingtao Song,Yunfan Yang,Jie Tian,Yang Liu,Ji-Rong Wen,Xiaoye Zhang,Xueshun Shen,Hao Sun*

Main category: cs.LG

TL;DR: 该论文提出了一种灰盒、全三维的强降水短时预报框架，能够直接处理体积雷达反射率，结合物理约束的神经算子和基于数据驱动的学习方法。该框架通过引入随机布朗运动来表示未解析的运动，学习垂直变化的三维平流场，估计不确定性。此方法在盲测试中排名第一，准确率高达57%的案例中优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 现有强降水短时预报方法存在精度低、时间分辨率不足等问题，论文提出了结合物理约束与数据驱动的混合方法以提高预报精度和可靠性。

Method: 通过引入灰盒模型，结合物理约束的神经算子与数据驱动的学习方法，直接处理体积雷达反射率，学习垂直变化的三维平流场，并引入随机布朗运动来表示未解析的运动，同时采用扩散基的随机模块估计不确定性。

Result: 该模型能够更准确地进行三小时之内的强降水预报，并在盲测试中获得160名气象学家排名第一的成绩。

Conclusion: 通过恢复完整三维动力学并保持物理一致性，此方法提供了一种可扩展且稳健的强降水短时预报途径。

Abstract: Extreme precipitation nowcasting demands high spatiotemporal fidelity and
extended lead times, yet existing approaches remain limited. Numerical Weather
Prediction (NWP) and its deep-learning emulations are too slow and coarse for
rapidly evolving convection, while extrapolation and purely data-driven models
suffer from error accumulation and excessive smoothing. Hybrid 2D radar-based
methods discard crucial vertical information, preventing accurate
reconstruction of height-dependent dynamics. We introduce a gray-box, fully
three-dimensional nowcasting framework that directly processes volumetric radar
reflectivity and couples physically constrained neural operators with
datadriven learning. The model learns vertically varying 3D advection fields
under a conservative advection operator, parameterizes spatially varying
diffusion, and introduces a Brownian-motion--inspired stochastic term to
represent unresolved motions. A residual branch captures small-scale convective
initiation and microphysical variability, while a diffusion-based stochastic
module estimates uncertainty. The framework achieves more accurate forecasts up
to three-hour lead time across precipitation regimes and ranked first in 57\%
of cases in a blind evaluation by 160 meteorologists. By restoring full 3D
dynamics with physical consistency, it offers a scalable and robust pathway for
skillful and reliable nowcasting of extreme precipitation.

</details>


### [158] [Forgetting is Everywhere](https://arxiv.org/abs/2511.04666)
*Ben Sanati,Thomas L. Lee,Trevor McInroe,Aidan Scannell,Nikolay Malkin,David Abel,Amos Storkey*

Main category: cs.LG

TL;DR: 该论文提出了一种针对学习者在预测未来体验中的自身一致性缺乏定义遗忘的理论，并设计了多种实验验证遗忘现象普遍存在所有学习设置中，并影响学习效率。从而建立了一种原理性的理解遗忘的方法，并为分析和改善通用学习算法的信息保留能力奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有的对于解决学习算法遗忘问题的研究缺乏一个统一的定义来理解遗忘的本质，因此，文章的动机在于探索并定义遗忘现象，以期为学习算法的改进提供理论依据。

Method: 提出了一种理论来定义遗忘，该理论认为遗忘是由于学习者的预测分布缺乏自我一致性导致的，缺失预测信息。并且通过一系列实验验证了该理论的正确性，这些实验涵盖了分类、回归、生成模型以及强化学习等领域。

Result: 实验结果证明遗忘现象广泛存在于不同学习设置中，并严重影响学习效率。这一结果建立了对遗忘的原理性理解，为分析和改善通用学习算法的信息保留能力奠定了基础。

Conclusion: 论文提出了一种新的遗忘定义，并通过实验验证了遗忘在多个学习领域的普遍存在性和影响性，建立了一个关于遗忘的原理性理解，为分析和改善通用学习算法的信息保留能力提供了理论基础。

Abstract: A fundamental challenge in developing general learning algorithms is their
tendency to forget past knowledge when adapting to new data. Addressing this
problem requires a principled understanding of forgetting; yet, despite decades
of study, no unified definition has emerged that provides insights into the
underlying dynamics of learning. We propose an algorithm- and task-agnostic
theory that characterises forgetting as a lack of self-consistency in a
learner's predictive distribution over future experiences, manifesting as a
loss of predictive information. Our theory naturally yields a general measure
of an algorithm's propensity to forget. To validate the theory, we design a
comprehensive set of experiments that span classification, regression,
generative modelling, and reinforcement learning. We empirically demonstrate
how forgetting is present across all learning settings and plays a significant
role in determining learning efficiency. Together, these results establish a
principled understanding of forgetting and lay the foundation for analysing and
improving the information retention capabilities of general learning
algorithms.

</details>


### [159] [Multi-Method Analysis of Mathematics Placement Assessments: Classical, Machine Learning, and Clustering Approaches](https://arxiv.org/abs/2511.04667)
*Julian D. Allagan,Dasia A. Singleton,Shanae N. Perry,Gabrielle C. Morgan,Essence A. Morgan*

Main category: cs.LG

TL;DR: 研究通过结合经典测试理论、机器学习和无监督聚类方法评估了一个40项的数学 placement examination，发现55%的题目具有良好的区分度，但30%的题目区分度差，需要替换。机器学习算法表现出色，准确率达到97.5%。聚类分析表明，学生的表现具有自然的二元能力结构，与机构设定的门槛有差异，建议对考试进行调整，以便更精确地定位学生的能力水平。



<details>
  <summary>Details</summary>
Motivation: 研究的动机在于评估一个40项的数学 placement examination 的有效性，使用多方法框架来更准确地理解每个题目的性能和学生的数学能力，以优化数学 placement 流程。


Method: 该研究使用了经典测试理论，机器学习算法（包括随机森林和梯度提升），以及无监督聚类（K-means）的方法来评估40项的数学 placement examination。


Result: 结果显示，部分题目需要替换，因为它们的区分度不足。机器学习算法提供了高准确率的预测，聚类分析揭示了学生的二元能力结构，这与机构设定的门槛有所不同。


Conclusion: 研究发现表明，多方法结合可以为数学 placement 的优化提供一个坚实的实证基础。具体来说，替换低区分度的题目，实施两阶段评估，以及将机器学习预测与透明机制相结合的做法都能提高 placement 的准确性。


Abstract: This study evaluates a 40-item mathematics placement examination administered
to 198 students using a multi-method framework combining Classical Test Theory,
machine learning, and unsupervised clustering. Classical Test Theory analysis
reveals that 55\% of items achieve excellent discrimination ($D \geq 0.40$)
while 30\% demonstrate poor discrimination ($D < 0.20$) requiring replacement.
Question 6 (Graph Interpretation) emerges as the examination's most powerful
discriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA
F-statistic ($F = 4609.1$), and maximum Random Forest feature importance
(0.206), accounting for 20.6\% of predictive power. Machine learning algorithms
demonstrate exceptional performance, with Random Forest and Gradient Boosting
achieving 97.5\% and 96.0\% cross-validation accuracy. K-means clustering
identifies a natural binary competency structure with a boundary at 42.5\%,
diverging from the institutional threshold of 55\% and suggesting potential
overclassification into remedial categories. The two-cluster solution exhibits
exceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster
purity. Convergent evidence across methods supports specific refinements:
replace poorly discriminating items, implement a two-stage assessment, and
integrate Random Forest predictions with transparency mechanisms. These
findings demonstrate that multi-method integration provides a robust empirical
foundation for evidence-based mathematics placement optimization.

</details>
