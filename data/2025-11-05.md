<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 50]
- [cs.LG](#cs.LG) [Total: 66]
- [eess.IV](#eess.IV) [Total: 2]
- [cs.IT](#cs.IT) [Total: 11]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.NI](#cs.NI) [Total: 3]
- [eess.SY](#eess.SY) [Total: 11]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [iFlyBot-VLA Technical Report](https://arxiv.org/abs/2511.01914)
*Yuan Zhang,Chenyu Xue,Wenjie Xu,Chao Ji,Jiajia wu,Jia Pan*

Main category: cs.CV

TL;DR: 提出了iFlyBot-VLA模型，一个大规模的视觉-语言-动作模型，借助新的训练框架，实现了对大规模人类和机器人操作视频的深度训练，结合通用问答和空间问答数据集提升了3D感知和推理能力，并在实验中取得了较好的表现。


<details>
  <summary>Details</summary>
Motivation: 为了提升视觉-语言模型对于3D感知和推理的能力，引入了全新的视觉-语言-动作模型训练框架，结合大规模操作视频和混合训练策略。

Method: 提出了一个多层次动作表示框架，对视觉-语言模型以及动作专家进行联合监督训练；设计了混合训练策略将机器人轨迹数据与通用问答和空间问答数据集结合；训练视觉-语言模型预测两种形式的动作：隐式动作和结构性离散动作。

Result: 实验结果显示，该框架在LIBERO Franka数据集上表现出良好的性能，且在实际应用中对于各种复杂操作任务也有很高的成功率。

Conclusion: 该模型和训练框架展示了在3D感知和动作生成方面的优势，计划开源部分自行构建的数据集以支持未来研究。

Abstract: We introduce iFlyBot-VLA, a large-scale Vision-Language-Action (VLA) model
trained under a novel framework. The main contributions are listed as follows:
(1) a latent action model thoroughly trained on large-scale human and robotic
manipulation videos; (2) a dual-level action representation framework that
jointly supervises both the Vision-Language Model (VLM) and the action expert
during training; (3) a mixed training strategy that combines robot trajectory
data with general QA and spatial QA datasets, effectively enhancing the 3D
perceptual and reasoning capabilities of the VLM backbone. Specifically, the
VLM is trained to predict two complementary forms of actions: latent actions,
derived from our latent action model pretrained on cross-embodiment
manipulation data, which capture implicit high-level intentions; and structured
discrete action tokens, obtained through frequency-domain transformations of
continuous control signals, which encode explicit low-level dynamics. This dual
supervision aligns the representation spaces of language, vision, and action,
enabling the VLM to directly contribute to action generation. Experimental
results on the LIBERO Franka benchmark demonstrate the superiority of our
frame-work, while real-world evaluations further show that iFlyBot-VLA achieves
competitive success rates across diverse and challenging manipulation tasks.
Furthermore, we plan to open-source a portion of our self-constructed dataset
to support future research in the community

</details>


### [2] [Challenging DINOv3 Foundation Model under Low Inter-Class Variability: A Case Study on Fetal Brain Ultrasound](https://arxiv.org/abs/2511.01915)
*Edoardo Conti,Riccardo Rosati,Lorenzo Federici,Adriano Mancini,Maria Chiara Fiorentin*

Main category: cs.CV

TL;DR: 该研究评估了基础模型在低类别间差异条件下的胎儿超声影像性能，特别是在胎儿大脑标准平面方面的能力，发现预训练的模型在胎儿超声数据上的表现优于自然图像预训练的模型，性能提升了最多20%。结果表明，特定领域的预训练对于胎儿脑超声成像至关重要，而一般基础模型在这种条件下无法泛化。


<details>
  <summary>Details</summary>
Motivation: 研究目的是评估基础模型在低类别间差异条件下的胎儿超声影像性能，特别是针对胎儿大脑标准平面（如跨交叉部脑、跨室脑和跨小脑平面）的精度，这些区域具有高重叠的解剖特征。解决的是基础模型是否能在具有挑战性的解剖相似结构识别中进行可靠表现的问题。

Method: 收集并聚合了所有的公开胎儿超声数据集，形成一个包含超过188,000张注释图像的统一多中心基准FetalUS-188K。DINOv3通过自监督学习过程对超声影像的内容表示进行预训练，通过线性探查（冻结了主干）和完全微调的标准适应方案进行评估，其初始方式包括预训练在FetalUS-188K和使用自然图像DINOv3的权重初始化。

Result: 无论是从自然图像初始化还是从胎儿超声数据初始化的模型，结果显示这些模型在预训练的数据类型中表现更好，特别是在FetalUS-188K上，性能相对于从自然图像初始化的模型来说提升了多达20%。这种方法保存了区分中间层面的关键超声图像特征，提高了准确度。

Conclusion: 结论是基础模型在低类别间差异条件下的泛化能力较差，而预训练特定领域的模型对于胎儿脑超声成像是必需的，能够生成可靠和临床实用的图像表示。

Abstract: Purpose: This study provides the first comprehensive evaluation of foundation
models in fetal ultrasound (US) imaging under low inter-class variability
conditions. While recent vision foundation models such as DINOv3 have shown
remarkable transferability across medical domains, their ability to
discriminate anatomically similar structures has not been systematically
investigated. We address this gap by focusing on fetal brain standard
planes--transthalamic (TT), transventricular (TV), and transcerebellar
(TC)--which exhibit highly overlapping anatomical features and pose a critical
challenge for reliable biometric assessment.
  Methods: To ensure a fair and reproducible evaluation, all publicly available
fetal ultrasound datasets were curated and aggregated into a unified
multicenter benchmark, FetalUS-188K, comprising more than 188,000 annotated
images from heterogeneous acquisition settings. DINOv3 was pretrained in a
self-supervised manner to learn ultrasound-aware representations. The learned
features were then evaluated through standardized adaptation protocols,
including linear probing with frozen backbone and full fine-tuning, under two
initialization schemes: (i) pretraining on FetalUS-188K and (ii) initialization
from natural-image DINOv3 weights.
  Results: Models pretrained on fetal ultrasound data consistently outperformed
those initialized on natural images, with weighted F1-score improvements of up
to 20 percent. Domain-adaptive pretraining enabled the network to preserve
subtle echogenic and structural cues crucial for distinguishing intermediate
planes such as TV.
  Conclusion: Results demonstrate that generic foundation models fail to
generalize under low inter-class variability, whereas domain-specific
pretraining is essential to achieve robust and clinically reliable
representations in fetal brain ultrasound imaging.

</details>


### [3] [Estimation of Segmental Longitudinal Strain in Transesophageal Echocardiography by Deep Learning](https://arxiv.org/abs/2511.02210)
*Anders Austlid Taskén,Thierry Judge,Erik Andreas Rye Berg,Jinyang Yu,Bjørnar Grenne,Frank Lindseth,Svend Aakhus,Pierre-Marc Jodoin,Nicolas Duchateau,Olivier Bernard,Gabriel Kiss*

Main category: cs.CV

TL;DR: 本文提出了一种称为autoStrain的自动化管道，使用深度学习方法进行经食道超声心动图中左心室节段纵向应变的估计。通过将TeeTracker和TeeFlow两种方法与临床参考进行比较，以及通过合成TEE数据集验证，TeeTracker在运动估计准确度方面表现出色。研究结果表明，这种AI驱动的运动估计技术可以显著提升临床心脏功能评估的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 当前左心室节段纵向应变估算技术需要大量的手动干预和专业知识，这限制了其效率，并使其过于资源密集化不适合监测。因此，本文旨在开发一种使用深度学习方法自动进行经食道超声心动图中应变估算的新方法。

Method: 本文提出了一种名为autoStrain的自动化管道，使用深度学习方法进行运动估计。具体来说，该研究比较了两种深度学习方法：基于RAFT光学流模型的TeeFlow，和基于CoTracker轨迹模型的TeeTracker。由于现实中获取真实运动数据非常困难，研究者利用了一种模拟管线生成具有真实运动数据的合成TEE数据集。

Result: 在合成TEE数据集上，TeeTracker的运动估算准确性优于TeeFlow。临床验证也表明，autoStrain方法与临床参照相符，同时，在模拟缺血的数据中，模型在量化异常变形上的准确性也得到提高。

Conclusion: 研究表明，通过将AI驱动的运动估算技术与经食道超声心动图集成，可以显著提升临床心脏功能评估的精度和效率。

Abstract: Segmental longitudinal strain (SLS) of the left ventricle (LV) is an
important prognostic indicator for evaluating regional LV dysfunction, in
particular for diagnosing and managing myocardial ischemia. Current techniques
for strain estimation require significant manual intervention and expertise,
limiting their efficiency and making them too resource-intensive for monitoring
purposes. This study introduces the first automated pipeline, autoStrain, for
SLS estimation in transesophageal echocardiography (TEE) using deep learning
(DL) methods for motion estimation. We present a comparative analysis of two DL
approaches: TeeFlow, based on the RAFT optical flow model for dense
frame-to-frame predictions, and TeeTracker, based on the CoTracker point
trajectory model for sparse long-sequence predictions.
  As ground truth motion data from real echocardiographic sequences are hardly
accessible, we took advantage of a unique simulation pipeline (SIMUS) to
generate a highly realistic synthetic TEE (synTEE) dataset of 80 patients with
ground truth myocardial motion to train and evaluate both models. Our
evaluation shows that TeeTracker outperforms TeeFlow in accuracy, achieving a
mean distance error in motion estimation of 0.65 mm on a synTEE test dataset.
  Clinical validation on 16 patients further demonstrated that SLS estimation
with our autoStrain pipeline aligned with clinical references, achieving a mean
difference (95\% limits of agreement) of 1.09% (-8.90% to 11.09%).
Incorporation of simulated ischemia in the synTEE data improved the accuracy of
the models in quantifying abnormal deformation. Our findings indicate that
integrating AI-driven motion estimation with TEE can significantly enhance the
precision and efficiency of cardiac function assessment in clinical settings.

</details>


### [4] [Assessing the value of Geo-Foundational Models for Flood Inundation Mapping: Benchmarking models for Sentinel-1, Sentinel-2, and Planetscope for end-users](https://arxiv.org/abs/2511.01990)
*Saurabh Kaushik,Lalit Maurya,Elizabeth Tellman,ZhiJie Zhang*

Main category: cs.CV

TL;DR: 本文对三种Geo-Foundational Models（Prithvi 2.0、Clay V1.5、DOFA）和一种变体UViT，与传统模型（TransNorm、U-Net、Attention U-Net）在洪水淹没图制作中的表现进行了评估。实验结果表明，Clay在多个传感器中表现最优，尤其是在PlanetScope和Sentinel-2上表现突出，同时在少样本学习中也展现了优异性能，模型计算量和标注需求相对较少。


<details>
  <summary>Details</summary>
Motivation: 传统的U-Net等模型在洪水淹没图制作中存在局限，本研究旨在通过系统性比较验证Geo-Foundational Models在不同传感器和数据可用性场景下的性能表现，以指导终端用户选择合适的模型。

Method: 通过PlanetScope、Sentinel-1和Sentinel-2卫星数据，在五地交叉验证和19个地点的少量样本实验中比较了三种Geo-Foundational Models及其变体UViT与传统模型的性能。此外，还考量了模型的计算时间、参数规模等因素。

Result: Clay模型在大多数传感器中表现最优，相较于传统U-Net，在测试集上显示出4%的性能提升，并在计算时间和标注需求上更为高效。GFMs相比传统模型，提供了较小到中等水平的洪水制图准确性改进，同时降低计算成本和标注工作量。

Conclusion: 研究表明，尽管GFMs没有表现出对传统模型的重大突破，但在特定场景下展现出了比传统模型更高的效率和准确性，特别是Clay模型。这为未来研究和实际应用提供了指导和启示。

Abstract: Geo-Foundational Models (GFMs) enable fast and reliable extraction of
spatiotemporal information from satellite imagery, improving flood inundation
mapping by leveraging location and time embeddings. Despite their potential, it
remains unclear whether GFMs outperform traditional models like U-Net. A
systematic comparison across sensors and data availability scenarios is still
lacking, which is an essential step to guide end-users in model selection. To
address this, we evaluate three GFMs, Prithvi 2.0, Clay V1.5, DOFA, and UViT (a
Prithvi variant), against TransNorm, U-Net, and Attention U-Net using
PlanetScope, Sentinel-1, and Sentinel-2. We observe competitive performance
among all GFMs, with only 2-5% variation between the best and worst models
across sensors. Clay outperforms others on PlanetScope (0.79 mIoU) and
Sentinel-2 (0.70), while Prithvi leads on Sentinel-1 (0.57). In
leave-one-region-out cross-validation across five regions, Clay shows slightly
better performance across all sensors (mIoU: 0.72(0.04), 0.66(0.07),
0.51(0.08)) compared to Prithvi (0.70(0.05), 0.64(0.09), 0.49(0.13)) and DOFA
(0.67(0.07), 0.64(0.04), 0.49(0.09)) for PlanetScope, Sentinel-2, and
Sentinel-1, respectively. Across all 19 sites, leave-one-region-out
cross-validation reveals a 4% improvement by Clay compared to U-Net. Visual
inspection highlights Clay's superior ability to retain fine details. Few-shot
experiments show Clay achieves 0.64 mIoU on PlanetScope with just five training
images, outperforming Prithvi (0.24) and DOFA (0.35). In terms of computational
time, Clay is a better choice due to its smaller model size (26M parameters),
making it ~3x faster than Prithvi (650M) and 2x faster than DOFA (410M).
Contrary to previous findings, our results suggest GFMs offer small to moderate
improvements in flood mapping accuracy at lower computational cost and labeling
effort compared to traditional U-Net.

</details>


### [5] [Locally-Supervised Global Image Restoration](https://arxiv.org/abs/2511.01998)
*Benjamin Walder,Daniel Toader,Robert Nuster,Günther Paltauf,Peter Burgholzer,Gregor Langer,Lukas Krainer,Markus Haltmeier*

Main category: cs.CV

TL;DR: 本文提出了一种基于学习的图像重建方法，用于从不完整测量中恢复图像，包括上采样和修补。该方法利用图像分布的多重不变性，从而在需要较少的地面实况数据的情况下，能够实现与完全监督方法相媲美的重建性能。我们通过光声显微成像上的光学分辨率上采样验证了该方法的有效性，结果令人满意或优越，同时减少了对地面实况数据的需求。 


<details>
  <summary>Details</summary>
Motivation: 经典的监督学习方法需要完全采样的地面实况数据，而自监督方法虽然可以使用不完整的地面实况数据，但通常依赖随机采样，这在预期中覆盖整个图像，难以解决固定和确定性采样模式中的不完整覆盖问题。因此，研究者们开发了一种可以克服这种限制的新方法。 

Method: 该方法利用图像分布的多重不变性，理论上可以实现与完全监督方法相近的图像重建性能，同时大大减少对地面实况数据的需求。 

Result: 我们在光声显微成像的光学分辨率上采样任务中对方法的有效性进行了验证，结果显示，该方法可以得到与完全监督方法相近或者更好的上采样效果，但需要的地面实况数据少。 

Conclusion: 提出的方法通过利用图像分布的多重不变性，达到了在减少地面实况数据需求的情况下提供出色的图像重建性能的目的，具有重要的实用价值。

Abstract: We address the problem of image reconstruction from incomplete measurements,
encompassing both upsampling and inpainting, within a learning-based framework.
Conventional supervised approaches require fully sampled ground truth data,
while self-supervised methods allow incomplete ground truth but typically rely
on random sampling that, in expectation, covers the entire image. In contrast,
we consider fixed, deterministic sampling patterns with inherently incomplete
coverage, even in expectation. To overcome this limitation, we exploit multiple
invariances of the underlying image distribution, which theoretically allows us
to achieve the same reconstruction performance as fully supervised approaches.
We validate our method on optical-resolution image upsampling in photoacoustic
microscopy (PAM), demonstrating competitive or superior results while requiring
substantially less ground truth data.

</details>


### [6] [Towards Selection of Large Multimodal Models as Engines for Burned-in Protected Health Information Detection in Medical Images](https://arxiv.org/abs/2511.02014)
*Tuan Truong,Guillermo Jimenez Perez,Pedro Osorio,Matthias Lenga*

Main category: cs.CV

TL;DR: 研究通过系统性地评估三种大型多模态模型在医学影像中检测受保护的健康信息（PHI）的表现，发现这些模型在OCR效果上优于传统模型，但在整体PHI检测准确度提升方面并不一致。提出了针对特定操作条件的选择建议和部署策略。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估大型多模态模型在医学影像中PHI检测任务中的性能，特别是在OCR效果和整体PHI检测准确度之间的关系，以及探讨这些模型在特定场景下的适用性。

Method: 研究使用了三种大型多模态模型（GPT-4o, Gemini 2.5 Flash 和 Qwen 2.5 7B），用两种不同的pipeline：仅文本分析与OCR结合语义分析。

Result: 结果表明，在复杂印记图案的测试案例中，大型多模态模型表现出最强的性能提升。在文本区域清晰可读且对比度充足的情况下，不同的pipeline配置产生相似的结果。

Conclusion: 研究建议了基于特定操作条件的大型多模态模型选择，并提出了依赖于模块化和可扩展基础设施的部署策略，以适应不同情况下部署和使用大型多模态模型的需求。

Abstract: The detection of Protected Health Information (PHI) in medical imaging is
critical for safeguarding patient privacy and ensuring compliance with
regulatory frameworks. Traditional detection methodologies predominantly
utilize Optical Character Recognition (OCR) models in conjunction with named
entity recognition. However, recent advancements in Large Multimodal Model
(LMM) present new opportunities for enhanced text extraction and semantic
analysis. In this study, we systematically benchmark three prominent closed and
open-sourced LMMs, namely GPT-4o, Gemini 2.5 Flash, and Qwen 2.5 7B, utilizing
two distinct pipeline configurations: one dedicated to text analysis alone and
another integrating both OCR and semantic analysis. Our results indicate that
LMM exhibits superior OCR efficacy (WER: 0.03-0.05, CER: 0.02-0.03) compared to
conventional models like EasyOCR. However, this improvement in OCR performance
does not consistently correlate with enhanced overall PHI detection accuracy.
The strongest performance gains are observed on test cases with complex imprint
patterns. In scenarios where text regions are well readable with sufficient
contrast, and strong LMMs are employed for text analysis after OCR, different
pipeline configurations yield similar results. Furthermore, we provide
empirically grounded recommendations for LMM selection tailored to specific
operational constraints and propose a deployment strategy that leverages
scalable and modular infrastructure.

</details>


### [7] [StrengthSense: A Dataset of IMU Signals Capturing Everyday Strength-Demanding Activities](https://arxiv.org/abs/2511.02027)
*Zeyu Yang,Clayton Souza Leite,Yu Xiao*

Main category: cs.CV

TL;DR: 介绍了一个名为StrengthSense的公开数据集，该数据集包含了来自29名健康参与者在进行11项耗力活动时的IMU信号，并包括了2项非耗力活动作为对比。数据集用于验证IMU信号的准确性和可靠性，并辅助研发人类活动识别算法及健身健康监测应用等。



<details>
  <summary>Details</summary>
Motivation: 由于缺乏全面记录耗力活动的数据集，致使无法有效监控肌肉力量、耐力和爆发力。此研究旨在填补这一空白，提供带标注的IMU信号数据集，支持传感器以及其他健身与健康应用的研发。


Method: 利用10个IMU传感器捕捉29名参与者的11项耗力活动的数据，并包括2项非耗力活动作为对比。利用视频记录对IMU信号进行标注，并对各自估算的关节角度进行比较，以评测数据的准确性和可靠性。


Result: 数据集有效地验证了IMU信号的准确性和可靠性，可作为进一步研究健康和健身应用的资源。


Conclusion: StrengthSense数据集对于未来发展人类活动识别算法和健康相关应用具有重要价值。

Abstract: Tracking strength-demanding activities with wearable sensors like IMUs is
crucial for monitoring muscular strength, endurance, and power. However, there
is a lack of comprehensive datasets capturing these activities. To fill this
gap, we introduce \textit{StrengthSense}, an open dataset that encompasses IMU
signals capturing 11 strength-demanding activities, such as sit-to-stand,
climbing stairs, and mopping. For comparative purposes, the dataset also
includes 2 non-strength demanding activities. The dataset was collected from 29
healthy subjects utilizing 10 IMUs placed on limbs and the torso, and was
annotated using video recordings as references. This paper provides a
comprehensive overview of the data collection, pre-processing, and technical
validation. We conducted a comparative analysis between the joint angles
estimated by IMUs and those directly extracted from video to verify the
accuracy and reliability of the sensor data. Researchers and developers can
utilize \textit{StrengthSense} to advance the development of human activity
recognition algorithms, create fitness and health monitoring applications, and
more.

</details>


### [8] [Text-VQA Aug: Pipelined Harnessing of Large Multimodal Models for Automated Synthesis](https://arxiv.org/abs/2511.02046)
*Soham Joshi,Shwet Kamal Mishra,Viswanath Gopalakrishnan*

Main category: cs.CV

TL;DR: 提出了一种自动化合成和验证大规模文本VQA数据集的管道，该管道结合了OCR检测和识别、ROI检测、标题生成和问题生成等方法，以此创建了一个包含72K Q&A对和44K图像的数据集


<details>
  <summary>Details</summary>
Motivation: 现有创建大型数据库以进行有关场景文本的视觉问答任务，需要繁琐且耗时的人工标注，随着视觉语言基础模型和OCR系统的成熟，提出了一个可以自动生成基于场景文本的问答数据集的管道

Method: 该方法利用了多个模型和算法，包括OCR检测和识别（文本检测）、区域检测、标题生成和问题生成，这些组件被整合成一个统一的流水线以自动化合成和验证问答对

Result: 创建了包含大约72000个问答对和44000张图像的第一个大规模文本VQA数据集

Conclusion: 成功地开发了一种可以自动化合成并验证大规模文本VQA数据集的模块化管道，克服了传统方法在时间和人力资源方面的挑战

Abstract: Creation of large-scale databases for Visual Question Answering tasks
pertaining to the text data in a scene (text-VQA) involves skilful human
annotation, which is tedious and challenging. With the advent of foundation
models that handle vision and language modalities, and with the maturity of OCR
systems, it is the need of the hour to establish an end-to-end pipeline that
can synthesize Question-Answer (QA) pairs based on scene-text from a given
image. We propose a pipeline for automated synthesis for text-VQA dataset that
can produce faithful QA pairs, and which scales up with the availability of
scene text data. Our proposed method harnesses the capabilities of multiple
models and algorithms involving OCR detection and recognition (text spotting),
region of interest (ROI) detection, caption generation, and question
generation. These components are streamlined into a cohesive pipeline to
automate the synthesis and validation of QA pairs. To the best of our
knowledge, this is the first pipeline proposed to automatically synthesize and
validate a large-scale text-VQA dataset comprising around 72K QA pairs based on
around 44K images.

</details>


### [9] [Markerless Augmented Reality Registration for Surgical Guidance: A Multi-Anatomy Clinical Accuracy Study](https://arxiv.org/abs/2511.02086)
*Yue Yang,Fabian Necker,Christoph Leuze,Michelle Chen,Andrey Finegersh,Jake Lee,Vasu Divi,Bruce Daniel,Brian Hargreaves,Jie Ying Wu,Fred M Baik*

Main category: cs.CV

TL;DR: 本文开发并临床验证了一种无需标记的头戴式立体显示（HMD）上的仅深度增强现实（AR）配准流水线，并在真实手术环境中对小或低曲率解剖结构的准确性进行了评估。临床使用时可以在无需标记的情况下达到约3-4毫米中位误差。这提高了无需标记的AR导引在临床手术中的可用性，通过人为引导初始化及从全局到局部对准实现了在小或低曲率目标的高度准确对准。


<details>
  <summary>Details</summary>
Motivation: 在真实手术环境中，对小或低曲率解剖结构的AR配准准确性提出了挑战。作者旨在开发一种无需标记、仅基于深度的AR配准管道，使得在真实手术环境中能够精确地对准这些解剖结构。通过这种方法，可以让临床医生在无需使用物理标记的情况下，实现对患者的精确导航。

Method: 在HoloLens 2上，通过深度偏差校正、人类参与的简化初始化系统和全局及局部配准步骤，实现了Articulated HAnd Tracking (AHAT) 深度图像与Computed Tomography (CT) 活体模型皮肤网格的对准。然后在一个活体内首次纤维骨移植和下颌骨重塑手术过程中进行了七个器械追踪目标实验，收集了超过500条数据。通过比较“皮肤到骨骼”的相对距离和CT真实的地面地毯距离来验证表面追踪误差指标。在临床验证阶段，收集了超过500条数据并进行了多项内部比较。

Result: 在预临床验证中，AR追踪和CT距离之间有紧密的一致性。临床数据表明，按照具体的解剖位置，每点误差的中位数为3.2毫米（脚部）、4.3毫米（耳朵）以及5.3毫米（小腿）。解剖部位的5毫米覆盖范围达到了92-95%（脚部），84-90%（耳朵），和72-86%（小腿）。脚部和小腿相比有统计学意义的差异（p < 0.001）。

Conclusion: 一系列真实手术测试中，本文开发的无需标记的仅深度流水线在具有小或低曲率解剖结构的真实手术环境中实现了约3-4毫米中位误差，能够满足中等风险手术的精度要求，在没有标志物的情况下，实现了厘米级别的精度。这种方法为无需标记的AR导引增加了可靠的临床积极性。

Abstract: Purpose: In this paper, we develop and clinically evaluate a depth-only,
markerless augmented reality (AR) registration pipeline on a head-mounted
display, and assess accuracy across small or low-curvature anatomies in
real-life operative settings. Methods: On HoloLens 2, we align Articulated HAnd
Tracking (AHAT) depth to Computed Tomography (CT)-derived skin meshes via (i)
depth-bias correction, (ii) brief human-in-the-loop initialization, (iii)
global and local registration. We validated the surface-tracing error metric by
comparing "skin-to-bone" relative distances to CT ground truth on leg and foot
models, using an AR-tracked tool. We then performed seven intraoperative target
trials (feet x2, ear x3, leg x2) during the initial stage of fibula free-flap
harvest and mandibular reconstruction surgery, and collected 500+ data per
trial. Results: Preclinical validation showed tight agreement between AR-traced
and CT distances (leg: median |Delta d| 0.78 mm, RMSE 0.97 mm; feet: 0.80 mm,
1.20 mm). Clinically, per-point error had a median of 3.9 mm. Median errors by
anatomy were 3.2 mm (feet), 4.3 mm (ear), and 5.3 mm (lower leg), with 5 mm
coverage 92-95%, 84-90%, and 72-86%, respectively. Feet vs. lower leg differed
significantly (Delta median ~1.1 mm; p < 0.001). Conclusion: A depth-only,
markerless AR pipeline on HMDs achieved ~3-4 mm median error across feet, ear,
and lower leg in live surgical settings without fiducials, approaching typical
clinical error thresholds for moderate-risk tasks. Human-guided initialization
plus global-to-local registration enabled accurate alignment on small or
low-curvature targets, improving the clinical readiness of markerless AR
guidance.

</details>


### [10] [From Instance Segmentation to 3D Growth Trajectory Reconstruction in Planktonic Foraminifera](https://arxiv.org/abs/2511.02142)
*Huahua Lin,Xiaohao Cai,Mark Nixon,James M. Mulqueeney,Thomas H. G. Ezard*

Main category: cs.CV

TL;DR: 本研究提出了一种从高分辨率计算机断层扫描图像中全自动重构浮游有孔虫三维生长轨迹的管道，集成了实例分割技术与专门的室顺序算法，有效减少了手动工作量同时保持了生物学意义的准确性。尽管分割模型在较小室中出现欠分割的情况，但室顺序算法依然能够稳健工作，实现了部分分割情况下生长轨迹的一致性重构，从而为大规模数据驱动的生态研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 浮游有孔虫的复杂室结构可以作为过去和当前环境条件的指示器，但对其室生长轨迹的研究依赖于手动分割，过于耗时且主观。本研究旨在通过自动化管道解决这一问题，提高效率和客观性，同时保留生物学意义的精度。此研究还希望为大规模生态数据分析提供基础。

Method: 本研究采用了实例分割技术与专门的室顺序算法来自动化重构浮游有孔虫的生长轨迹。三种实例分割方法被引入并分别针对室的空间特征进行优化，进而评估其对生长顺序重建准确性的影响。实验证明，此管道能够显著减少手工劳动，同时保持生物意义的准确性。尽管较小室由于较小的像素精度导致欠分割，但室顺序算法仍然稳健，部分分割时也能保持生长轨迹的一致性。

Result: 实验结果表明，本研究的管道可以显著减少手工劳动，同时保持高精度。尽管在较小室中分割模型可能出现欠分割现象，但室顺序算法仍能够提供稳健的解决方案。

Conclusion: 本研究为浮游有孔虫生长轨迹的全自动分析提供了首个可重复的管道，从而为数据驱动的大规模生态研究打下坚实的基础。

Abstract: Planktonic foraminifera, marine protists characterized by their intricate
chambered shells, serve as valuable indicators of past and present
environmental conditions. Understanding their chamber growth trajectory
provides crucial insights into organismal development and ecological adaptation
under changing environments. However, automated tracing of chamber growth from
imaging data remains largely unexplored, with existing approaches relying
heavily on manual segmentation of each chamber, which is time-consuming and
subjective. In this study, we propose an end-to-end pipeline that integrates
instance segmentation, a computer vision technique not extensively explored in
foraminifera, with a dedicated chamber ordering algorithm to automatically
reconstruct three-dimensional growth trajectories from high-resolution computed
tomography scans. We quantitatively and qualitatively evaluate multiple
instance segmentation methods, each optimized for distinct spatial features of
the chambers, and examine their downstream influence on growth-order
reconstruction accuracy. Experimental results on expert-annotated datasets
demonstrate that the proposed pipeline substantially reduces manual effort
while maintaining biologically meaningful accuracy. Although segmentation
models exhibit under-segmentation in smaller chambers due to reduced voxel
fidelity and subtle inter-chamber connectivity, the chamber-ordering algorithm
remains robust, achieving consistent reconstruction of developmental
trajectories even under partial segmentation. This work provides the first
fully automated and reproducible pipeline for digital foraminiferal growth
analysis, establishing a foundation for large-scale, data-driven ecological
studies.

</details>


### [11] [Fast Measuring Pavement Crack Width by Cascading Principal Component Analysis](https://arxiv.org/abs/2511.02144)
*Zhicheng Wang,Junbiao Pang*

Main category: cs.CV

TL;DR: 研究提出了一种基于主成分分析(PCA)和鲁棒主成分分析(RPCA)的级联框架，用于从数字图像中提取路面裂缝宽度。此方法在计算效率和测量精度上优于现有技术


<details>
  <summary>Details</summary>
Motivation: 当前路面裂缝宽度测量面临复杂形态和快速测量的需求，常规方法难以满足

Method: 研究提出了一种级联框架，包括初始裂缝分割、主方向轴的确定和主要传播轴的提取

Result: 方法在三个公开数据集上的测试表明其性能优于现有技术

Conclusion: 研究提供了一种能在计算效率和测量精度上都有良好表现的方法来提取路面裂缝宽度

Abstract: Accurate quantification of pavement crack width plays a pivotal role in
assessing structural integrity and guiding maintenance interventions. However,
achieving precise crack width measurements presents significant challenges due
to: (1) the complex, non-uniform morphology of crack boundaries, which limits
the efficacy of conventional approaches, and (2) the demand for rapid
measurement capabilities from arbitrary pixel locations to facilitate
comprehensive pavement condition evaluation. To overcome these limitations,
this study introduces a cascaded framework integrating Principal Component
Analysis (PCA) and Robust PCA (RPCA) for efficient crack width extraction from
digital images. The proposed methodology comprises three sequential stages: (1)
initial crack segmentation using established detection algorithms to generate a
binary representation, (2) determination of the primary orientation axis for
quasi-parallel cracks through PCA, and (3) extraction of the Main Propagation
Axis (MPA) for irregular crack geometries using RPCA. Comprehensive evaluations
were conducted across three publicly available datasets, demonstrating that the
proposed approach achieves superior performance in both computational
efficiency and measurement accuracy compared to existing state-of-the-art
techniques.

</details>


### [12] [Pinpointing Trigger Moment for Grounded Video QA: Enhancing Spatio-temporal Grounding in Multimodal Large Language Models](https://arxiv.org/abs/2511.02182)
*Jinhwan Seo,Yoonki Cho,Junhyug Noh,Sung-eui Yoon*

Main category: cs.CV

TL;DR: 我们提出了一个框架来解决ICCV 2025感知测试挑战中的Grounded Video Question Answering (GVQA) 任务，通过三项核心技术（视频推理与问答、时空定位和目标跟踪）实现视觉定位和跟踪，引入了CORTEX提示符产生触发时刻，实现了HOTA评分为0.4968，超过去年最高分数0.2704。


<details>
  <summary>Details</summary>
Motivation: 为了能够处理复杂环境下的视频问答，并进行视觉定位和跟踪，解决GVQA任务对多模态模型的需求，特别是视频内容推理和对象的时间追踪需求，提出了这项研究。

Method: 通过将GVQA任务分解为三个阶段的管道：（1）视频推理与问答，（2）时空定位和（3）跟踪。我们引入了CORTEX提示符产生触发时刻，为定位和跟踪提供了一个坚实的参考点。

Result: 我们的方法实现了HOTA评分为0.4968，相较于上一年度的最高分数0.2704有了显著提高，证明了我们的模型在GVQA任务上的有效性。

Conclusion: 我们的研究为GVQA任务提供了一种新的框架，引入了基于CORTEX提示符的触发时刻概念，并在测试中展示了显著的性能提升。

Abstract: In this technical report, we introduce a framework to address Grounded Video
Question Answering (GVQA) task for the ICCV 2025 Perception Test Challenge. The
GVQA task demands robust multimodal models capable of complex reasoning over
video content, grounding the resulting answers visually, and tracking the
referenced objects temporally. To achieve this capability, our proposed
approach decomposes the GVQA task into a three-stage pipeline: (1) Video
Reasoning \& QA, (2) Spatio-temporal Grounding and (3) Tracking. Our key
contribution is the introduction of a trigger moment, derived from our proposed
CORTEX prompt, which pinpoints the single most visible frame of a target object
to serve as a robust anchor for grounding and tracking. To this end, we achieve
the HOTA score of 0.4968, which marks a significant improvement over the
previous year's winning score of 0.2704 on GVQA task.

</details>


### [13] [MM-UNet: Morph Mamba U-shaped Convolutional Networks for Retinal Vessel Segmentation](https://arxiv.org/abs/2511.02193)
*Jiawen Liu,Yuanbo Zeng,Jiaming Liang,Yizhen Yang,Yiheng Zhang,Enhui Cai,Xiaoqi Sheng,Hongmin Cai*

Main category: cs.CV

TL;DR: 论文提出了一种新的架构MM-UNet，旨在提高视网膜血管分割的精度和鲁棒性。MM-UNet包含Morph Mamba卷积层和Reverse Selective State Guidance模块，它们在形态感知和解码效率上提高了性能。实验结果表明，MM-UNet在DRIVE和STARE数据集上分别比现有方法提高了1.64%和1.25%的F1得分准确性。


<details>
  <summary>Details</summary>
Motivation: 视网膜血管的准确分割对于临床眼科疾病的定量分析非常重要。然而，由于其极其细长和分支结构的性质，现有的分割模型在精确度和鲁棒性方面存在挑战，因此需要一种新的方法来解决这些问题。

Method: 论文提出了一种新型架构MM-UNet，该架构包括Morph Mamba卷积层和RSG模块。Morph Mamba卷积层通过形态感知特性替换了一般的逐点卷积，而RSG模块则通过逆向引导理论解决了几何边界感知和解码效率问题。

Result: 实验结果显示，MM-UNet在DRIVE和STARE数据集上均表现出了更为优秀的分割精度，F1得分分别比现有方法提高了1.64%和1.25%。

Conclusion: MM-UNet架构具有明显的性能改进，能够更准确地进行视网膜血管分割，为临床眼科疾病的研究提供了有价值的工具。

Abstract: Accurate detection of retinal vessels plays a critical role in reflecting a
wide range of health status indicators in the clinical diagnosis of ocular
diseases. Recently, advances in deep learning have led to a surge in retinal
vessel segmentation methods, which have significantly contributed to the
quantitative analysis of vascular morphology. However, retinal vasculature
differs significantly from conventional segmentation targets in that it
consists of extremely thin and branching structures, whose global morphology
varies greatly across images. These characteristics continue to pose challenges
to segmentation precision and robustness. To address these issues, we propose
MM-UNet, a novel architecture tailored for efficient retinal vessel
segmentation. The model incorporates Morph Mamba Convolution layers, which
replace pointwise convolutions to enhance branching topological perception
through morph, state-aware feature sampling. Additionally, Reverse Selective
State Guidance modules integrate reverse guidance theory with state-space
modeling to improve geometric boundary awareness and decoding efficiency.
Extensive experiments conducted on two public retinal vessel segmentation
datasets demonstrate the superior performance of the proposed method in
segmentation accuracy. Compared to the existing approaches, MM-UNet achieves
F1-score gains of 1.64 $\%$ on DRIVE and 1.25 $\%$ on STARE, demonstrating its
effectiveness and advancement. The project code is public via
https://github.com/liujiawen-jpg/MM-UNet.

</details>


### [14] [Language-Enhanced Generative Modeling for PET Synthesis from MRI and Blood Biomarkers](https://arxiv.org/abs/2511.02206)
*Zhengjie Zhang,Xiaoxie Mao,Qihao Guo,Shaoting Zhang,Qi Huang,Mu Zhou,Fang Xie,Mianxin Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于大规模语言模型和多模态信息融合的语言增强生成模型，用于合成与真实PET扫描相似度高的阿尔茨海默病（AD）相关的amyloid-beta PET图像，从而提高了基于MRI和血液生物标志物的诊断效用和工作效率。合成的PET图像在结构细节和区域模式上与真实PET扫描非常接近，并且在全自动诊断流水线中展现了很高的诊断准确性和性能，优于单一模态的诊断模型。


<details>
  <summary>Details</summary>
Motivation: 基于amyloid-beta PET的阿尔茨海默病诊断存在成本高和可及性低的问题，研究旨在探索是否可以通过血液生物标志物和MRI扫描预测amyloid-beta PET的空间模式，以提高诊断的可行性和效率。

Method: 开发一个由大规模语言模型和多模态信息融合驱动的语言增强生成模型来合成与真实PET扫描相近的图像，具体是从566名参与者收集的amyloid-beta PET图像、T1加权MRI扫描和血液生物标志物数据中进行模型构建和评估。

Result: 合成的PET图像在结构细节上与真实PET扫描的SSIM达到0.920±0.003，在区域模式上的Pearson相关系数达到0.955±0.007。利用合成PET进行的算法诊断结果与真实PET进行的算法诊断结果一致性高，准确度达到0.80。整个全自动AD诊断流程中，基于合成PET的模型（AUC=0.78）优于基于T1的（AUC=0.68）和基于血液生物标志物的模型（AUC=0.73），且结合合成PET和血液生物标志物改善了诊断性能（AUC=0.79）。

Conclusion: 利用语言增强的方法可以合成高逼真的PET图像，对于基于MRI和血液生物标志物的amyloid-beta空间模式评估有所增强，优化了阿尔茨海默病的诊断流程。

Abstract: Background: Alzheimer's disease (AD) diagnosis heavily relies on amyloid-beta
positron emission tomography (Abeta-PET), which is limited by high cost and
limited accessibility. This study explores whether Abeta-PET spatial patterns
can be predicted from blood-based biomarkers (BBMs) and MRI scans. Methods: We
collected Abeta-PET images, T1-weighted MRI scans, and BBMs from 566
participants. A language-enhanced generative model, driven by a large language
model (LLM) and multimodal information fusion, was developed to synthesize PET
images. Synthesized images were evaluated for image quality, diagnostic
consistency, and clinical applicability within a fully automated diagnostic
pipeline. Findings: The synthetic PET images closely resemble real PET scans in
both structural details (SSIM = 0.920 +/- 0.003) and regional patterns
(Pearson's r = 0.955 +/- 0.007). Diagnostic outcomes using synthetic PET show
high agreement with real PET-based diagnoses (accuracy = 0.80). Using synthetic
PET, we developed a fully automatic AD diagnostic pipeline integrating PET
synthesis and classification. The synthetic PET-based model (AUC = 0.78)
outperforms T1-based (AUC = 0.68) and BBM-based (AUC = 0.73) models, while
combining synthetic PET and BBMs further improved performance (AUC = 0.79).
Ablation analysis supports the advantages of LLM integration and prompt
engineering. Interpretation: Our language-enhanced generative model synthesizes
realistic PET images, enhancing the utility of MRI and BBMs for Abeta spatial
pattern assessment and improving the diagnostic workflow for Alzheimer's
disease.

</details>


### [15] [Object-Centric 3D Gaussian Splatting for Strawberry Plant Reconstruction and Phenotyping](https://arxiv.org/abs/2511.02207)
*Jiajia Li,Keyi Zhu,Qianwen Zhang,Dong Chen,Qi Sun,Zhaojian Li*

Main category: cs.CV

TL;DR: 该研究提出了一种新的基于对象的3D重建框架，用于草莓植物表型分析，这种框架比现有方法更准确、更高效。通过结合Segment Anything Model v2和alpha通道背景掩膜，它实现了无背景的3D重建，并能自动估计草莓植物的高度和冠幅等重要特性。这项技术为草莓植物表型分析提供了一种可扩展的和无损的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统植物表型分析方法耗时且劳动密集，且往往是破坏性的。新兴的神经渲染技术，如NeRF和3DGS，是高保真3D重建的强大工具，但大多数应用在农业领域的3DGS仍需重建整个场景，这引入了噪声，增加了计算成本，并复杂了后续特性分析。

Method: 提出了一个对象为中心的3D重建框架，通过使用Segment Anything Model v2和alpha通道背景掩膜，实现了无背景的草莓植物3D重建。这种方法还能通过DBSCAN聚类和主成分分析自动估计植物特性，如高度和冠幅。

Result: 实验结果表明，该方法比传统方法在准确性、效率方面表现更佳，提供了草莓植物表型分析的一种可扩展、无损的解决方案。

Conclusion: 通过定位对象并去除背景，所提出的方法提高了草莓植物的3D重建精度和效率，为植物表型分析提供了一种新颖的方法。

Abstract: Strawberries are among the most economically significant fruits in the United
States, generating over $2 billion in annual farm-gate sales and accounting for
approximately 13% of the total fruit production value. Plant phenotyping plays
a vital role in selecting superior cultivars by characterizing plant traits
such as morphology, canopy structure, and growth dynamics. However, traditional
plant phenotyping methods are time-consuming, labor-intensive, and often
destructive. Recently, neural rendering techniques, notably Neural Radiance
Fields (NeRF) and 3D Gaussian Splatting (3DGS), have emerged as powerful
frameworks for high-fidelity 3D reconstruction. By capturing a sequence of
multi-view images or videos around a target plant, these methods enable
non-destructive reconstruction of complex plant architectures. Despite their
promise, most current applications of 3DGS in agricultural domains reconstruct
the entire scene, including background elements, which introduces noise,
increases computational costs, and complicates downstream trait analysis. To
address this limitation, we propose a novel object-centric 3D reconstruction
framework incorporating a preprocessing pipeline that leverages the Segment
Anything Model v2 (SAM-2) and alpha channel background masking to achieve clean
strawberry plant reconstructions. This approach produces more accurate
geometric representations while substantially reducing computational time. With
a background-free reconstruction, our algorithm can automatically estimate
important plant traits, such as plant height and canopy width, using DBSCAN
clustering and Principal Component Analysis (PCA). Experimental results show
that our method outperforms conventional pipelines in both accuracy and
efficiency, offering a scalable and non-destructive solution for strawberry
plant phenotyping.

</details>


### [16] [Can Foundation Models Revolutionize Mobile AR Sparse Sensing?](https://arxiv.org/abs/2511.02215)
*Yiqin Zhao,Tian Guo*

Main category: cs.CV

TL;DR: 研究探讨了使用基础模型（foundation models）提升移动设备中稀疏传感（sparse sensing）的质量和效率，通过实际的移动AR数据验证了其在几何感知图像扭曲上的改进，并展示了其在3D场景重建中的优越性能。该研究揭示了将基础模型集成到移动稀疏传感系统中的潜在优势和挑战。


<details>
  <summary>Details</summary>
Motivation: 移动传感系统在计算、电力等限制下，稀疏传感被用作降低数据处理负担的关键策略，但现有方法通常会牺牲准确性。研究的动机是探索基础模型是否可以改善这一状况，提升移动设备中稀疏传感的效率和质量。

Method: 研究使用了现实世界的移动AR数据，评估了基于基础模型的稀疏传感技术在几何感知图像扭曲上的改进，并展示了其可扩展性及在3D场景重建中的性能。

Result: 研究结果表明，基于基础模型的稀疏传感技术在几何感知图像扭曲上取得了显著改进，并在3D场景重建中表现优秀。此外，研究还揭示了将基础模型集成到移动稀疏传感系统中的潜力和挑战。

Conclusion: 研究结论是，使用基础模型可以改变移动稀疏传感的格局，尽管还存在一些开放性挑战，但基础模型在移动传感系统中的应用展示了很大的潜力。

Abstract: Mobile sensing systems have long faced a fundamental trade-off between
sensing quality and efficiency due to constraints in computation, power, and
other limitations. Sparse sensing, which aims to acquire and process only a
subset of sensor data, has been a key strategy for maintaining performance
under such constraints. However, existing sparse sensing methods often suffer
from reduced accuracy, as missing information across space and time introduces
uncertainty into many sensing systems. In this work, we investigate whether
foundation models can change the landscape of mobile sparse sensing. Using
real-world mobile AR data, our evaluations demonstrate that foundation models
offer significant improvements in geometry-aware image warping, a central
technique for enabling accurate reuse of cross-frame information. Furthermore,
our study demonstrates the scalability of foundation model-based sparse sensing
and shows its leading performance in 3D scene reconstruction. Collectively, our
study reveals critical aspects of the promises and the open challenges of
integrating foundation models into mobile sparse sensing systems.

</details>


### [17] [Collaborative Attention and Consistent-Guided Fusion of MRI and PET for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2511.02228)
*Delin Ma,Menghui Zhou,Jun Qi,Yun Yang,Po Yang*

Main category: cs.CV

TL;DR: 本文提出了一种基于MRI和PET的阿尔茨海默病诊断协作注意和一致引导融合框架，通过引入可学习参数表示（LPR）块，共享编码器和模态独立编码器，以保持共享和特定的表示，并通过一致性引导机制来明确对齐模态间的潜在分布。该方法在ADNI数据集上的实验结果优于现有的融合策略，提高了诊断性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要强调跨模态互补性，忽略了特定模态特征的诊断重要性。模态之间的固有分布差异通常会导致偏差和噪声的表示，降低分类性能。本文旨在解决这些问题，通过融合MRI和PET数据，增强阿尔茨海默病的早期诊断能力。

Method: 提出了一种带有可学习参数表示（LPR）块、共享编码器和模态独立编码器的框架。LPR块用于弥补缺失的模态信息，同时保持共享和特定的表示。引入一致性引导机制，使模态间的潜在分布对齐。

Result: 实验结果展示了该方法在ADNI数据集上的诊断性能优于现有融合策略。证明了该模型能够有效解决模态间分布差异的问题，提高诊断准确性。

Conclusion: 该文提出了一种基于MRI和PET的阿尔茨海默病诊断新方法，通过引入可学习参数表示（LPR）块、共享编码器和模态独立编码器，并通过一致性引导机制进行模态间潜在分布对齐，有效提高了诊断性能。

Abstract: Alzheimer's disease (AD) is the most prevalent form of dementia, and its
early diagnosis is essential for slowing disease progression. Recent studies on
multimodal neuroimaging fusion using MRI and PET have achieved promising
results by integrating multi-scale complementary features. However, most
existing approaches primarily emphasize cross-modal complementarity while
overlooking the diagnostic importance of modality-specific features. In
addition, the inherent distributional differences between modalities often lead
to biased and noisy representations, degrading classification performance. To
address these challenges, we propose a Collaborative Attention and
Consistent-Guided Fusion framework for MRI and PET based AD diagnosis. The
proposed model introduces a learnable parameter representation (LPR) block to
compensate for missing modality information, followed by a shared encoder and
modality-independent encoders to preserve both shared and specific
representations. Furthermore, a consistency-guided mechanism is employed to
explicitly align the latent distributions across modalities. Experimental
results on the ADNI dataset demonstrate that our method achieves superior
diagnostic performance compared with existing fusion strategies.

</details>


### [18] [Medical Report Generation: A Hierarchical Task Structure-Based Cross-Modal Causal Intervention Framework](https://arxiv.org/abs/2511.02271)
*Yucheng Song,Yifan Ge,Junhao Li,Zhining Liao,Zhifang Liao*

Main category: cs.CV

TL;DR: HTSC-CIF是一个新的框架，用于改进医学报告生成模型，它通过层次任务分解方法解决了不足的领域知识理解、不良的文视觉实体对齐和模态偏差带来的虚假相关性三个主要挑战。实验结果显示HTSC-CIF显著优于最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 当前医学报告生成模型在处理放射图像时面临的主要挑战包括领域知识理解不足、文视觉实体对齐不良和模态偏差引入的虚假相关性。现有研究仅能解决上述挑战中的一个，而本研究尝试通过一个创新框架HTSC-CIF解决所有三个问题，提高模型的效率和准确性。

Method: HTSC-CIF将以上三个挑战分为三个层次的任务，并设计了对应的解决方案：1）低级任务：将医学实体特征与空间位置对齐以增强视觉编码器的领域知识；2）中级任务：利用前缀语言建模和掩码图片建模来提升跨模态对齐；3）高级任务：引入跨模态因果干预模块减少混淆变量并改进模型可解释性。

Result: 实验表明，HTSC-CIF框架显著优于现有的医学报告生成模型，提高了模型的性能和准确性。

Conclusion: HTSC-CIF通过层次任务分解方法解决了医学报告生成中的主要挑战，有效提升了模型对领域知识的理解、文视觉实体对齐和跨模态数据处理能力。

Abstract: Medical Report Generation (MRG) is a key part of modern medical diagnostics,
as it automatically generates reports from radiological images to reduce
radiologists' burden. However, reliable MRG models for lesion description face
three main challenges: insufficient domain knowledge understanding, poor
text-visual entity embedding alignment, and spurious correlations from
cross-modal biases. Previous work only addresses single challenges, while this
paper tackles all three via a novel hierarchical task decomposition approach,
proposing the HTSC-CIF framework. HTSC-CIF classifies the three challenges into
low-, mid-, and high-level tasks: 1) Low-level: align medical entity features
with spatial locations to enhance domain knowledge for visual encoders; 2)
Mid-level: use Prefix Language Modeling (text) and Masked Image Modeling
(images) to boost cross-modal alignment via mutual guidance; 3) High-level: a
cross-modal causal intervention module (via front-door intervention) to reduce
confounders and improve interpretability. Extensive experiments confirm
HTSC-CIF's effectiveness, significantly outperforming state-of-the-art (SOTA)
MRG methods. Code will be made public upon paper acceptance.

</details>


### [19] [Are Euler angles a useful rotation parameterisation for pose estimation with Normalizing Flows?](https://arxiv.org/abs/2511.02277)
*Giorgos Sfikas,Konstantina Nikolaidou,Foteini Papadopoulou,George Retsinas,Anastasios L. Kesidis*

Main category: cs.CV

TL;DR: 本文探讨了使用Euler角参数化作为Normalizing Flows模型基础来估计3D姿态的有用性，特别是在姿态不明确的情况下。与更复杂的参数化相比，Euler角可能在多个方面产生有用的模型。


<details>
  <summary>Details</summary>
Motivation: 目标姿态估计在3D计算机视觉中非常重要。在某些情况下，例如传感器和投影限制或物体对称性导致姿态不明确时，提供概率姿态输出有诸多益处。本文探讨了Euler角参数化在姿态估计中的应用价值。

Method: 本文提出了使用Euler角作为Normalizing Flows模型基础的方法来估计3D姿态，这种方法简单但可能在某些方面比复杂参数化更有效。

Result: 研究表明，Euler角参数化可以作为Normalizing Flows模型的基础来估计3D姿态，并且在某些情况下可能比复杂参数化更有效。但是，还需要进一步实验来证实这一结果。

Conclusion: 本文研究了Euler角参数化在3D姿态估计中的应用，表明Euler角尽管有不足，但在某些情况下可能比复杂参数化更有效。

Abstract: Object pose estimation is a task that is of central importance in 3D Computer
Vision. Given a target image and a canonical pose, a single point estimate may
very often be sufficient; however, a probabilistic pose output is related to a
number of benefits when pose is not unambiguous due to sensor and projection
constraints or inherent object symmetries. With this paper, we explore the
usefulness of using the well-known Euler angles parameterisation as a basis for
a Normalizing Flows model for pose estimation. Isomorphic to spatial rotation,
3D pose has been parameterized in a number of ways, either in or out of the
context of parameter estimation. We explore the idea that Euler angles, despite
their shortcomings, may lead to useful models in a number of aspects, compared
to a model built on a more complex parameterisation.

</details>


### [20] [SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL Tuning](https://arxiv.org/abs/2511.02280)
*Fangxun Shu,Yongjie Ye,Yue Liao,Zijian Kang,Weijie Yin,Jiacong Wang,Xiao Liang,Shuicheng Yan,Chao Feng*

Main category: cs.CV

TL;DR: SAIL-RL是一个强化学习框架，通过教授大型多模态语言模型如何和何时进行推理来提升其推理能力。该框架通过双重奖励系统——思虑奖励和判断奖励——解决了现有方法只能基于结果进行监督的问题，提升了模型在4B和8B规模上的推理能力和多模态理解能力，减少了幻觉，使其成为构建更可靠和适应性强的多模态大型语言模型的原理框架。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通过仅基于输出结果的监督来指导大型多模态模型的推理，这可能导致模型无法确保推理过程的质量，且无法适应不同任务所需的思考深度。因此，作者提出SAIL-RL，旨在通过更加细致的奖励机制来提升模型的推理能力和多模态理解能力。

Method: SAIL-RL采用了一个双轨奖励系统，一个监测推理的质量，另一个决定何时直接给出答案何时进行深思。通过这种方式，SAIL-RL希望克服现有模型在简单任务中过度推敲和复杂任务中思考不足的问题。

Result: 实验表明，SAIL-RL显著提升了基准模型（如SAIL-VL2）在多模态理解和推理能力方面的性能，并且在一定程度上减少了模型的幻觉错误，证明了它可以与商业上的封闭源代码模型（如GPT-4o）竞争。

Conclusion: SAIL-RL通过引入创新的奖励机制，使得大型多模态语言模型能够更好地理解和解决多模态任务，减少了不合理的推理错误，显示了该框架在多模态理解和推理方面的潜在价值。

Abstract: We introduce SAIL-RL, a reinforcement learning (RL) post-training framework
that enhances the reasoning capabilities of multimodal large language models
(MLLMs) by teaching them when and how to think. Existing approaches are limited
by outcome-only supervision, which rewards correct answers without ensuring
sound reasoning, and by uniform thinking strategies, which often lead to
overthinking on simple tasks and underthinking on complex ones. SAIL-RL
addresses these challenges with a dual reward system: the Thinking Reward,
which evaluates reasoning quality through factual grounding, logical coherence,
and answer consistency, and the Judging Reward, which adaptively determines
whether deep reasoning or direct answering is appropriate. Experiments on the
state-of-the-art SAIL-VL2 show that SAIL-RL improves reasoning and multimodal
understanding benchmarks at both 4B and 8B scales, achieving competitive
performance against commercial closed-source models such as GPT-4o, and
substantially reduces hallucinations, establishing it as a principled framework
for building more reliable and adaptive MLLMs. The code will be available at
https://github.com/BytedanceDouyinContent/SAIL-RL.

</details>


### [21] [Cycle-Sync: Robust Global Camera Pose Estimation through Enhanced Cycle-Consistent Synchronization](https://arxiv.org/abs/2511.02329)
*Shaohan Li,Yunpeng Shi,Gilad Lerman*

Main category: cs.CV

TL;DR: Cycle-Sync 是一种用于估计相机姿态（包括旋转和平移）的鲁棒且全局性的框架。该框架通过改良消息传递最小二乘（MPLS）方法，强调循环一致性，并展示了在相机位置估计领域最强的精确恢复保证。此外，它引入了异常值拒绝模块和全局方法来进一步增强鲁棒性和性能，实验表明其优于其他姿势估计器，包括带有捆绑调整的结构从运动管道。


<details>
  <summary>Details</summary>
Motivation: 引入 Cycle-Sync 是为了克服传统方法在估计相机姿态时由于局部优化带来的限制，提供鲁棒且整体的解决方案。该框架专注于通过强调循环一致性提高位置估计精度和鲁棒性，同时确保旋转同步对整体性能的影响最小化。

Method: Cycle-Sync 的核心方法是使用改良的 MPLS（消息传递最小二乘法），强调循环一致性并利用估计的距离进行迭代重新定义一致性，同时引入基于 Welsch 失效函数的鲁棒损失。此外，该方法进一步增强了鲁棒性，通过引入异常值拒绝模块，该模块借鉴了鲁棒子空间恢复的思想，并且将循环一致性完全整合到 MPLS 中以实现旋转同步。此外，全局方法避免了对捆绑调整的需要。

Result: 实验结果表明，Cycle-Sync 在合成数据和真实数据集上均优于其他姿态估计器，包括带有捆绑调整的全结构从运动管道。这表明 Cycle-Sync 在估计相机姿态时具有更高的准确性、鲁棒性和效率。此外，在不需要捆绑调整的情况下，Cycle-Sync 设法提高了整体性能。

Conclusion: Cycle-Sync 代表了一种有效且全局性的相机姿态估计方法，它不仅提供了鲁棒的解算器和在不使用额外距离信息的情况下实现循环一致性的能力，而且还通过引入罕见的全局方法避免了捆绑调整的需要。在众多实验中，它证明了在估计相机位置和旋转时具有优越的性能。

Abstract: We introduce Cycle-Sync, a robust and global framework for estimating camera
poses (both rotations and locations). Our core innovation is a location solver
that adapts message-passing least squares (MPLS) -- originally developed for
group synchronization -- to camera location estimation. We modify MPLS to
emphasize cycle-consistent information, redefine cycle consistencies using
estimated distances from previous iterations, and incorporate a Welsch-type
robust loss. We establish the strongest known deterministic exact-recovery
guarantee for camera location estimation, showing that cycle consistency alone
-- without access to inter-camera distances -- suffices to achieve the lowest
sample complexity currently known. To further enhance robustness, we introduce
a plug-and-play outlier rejection module inspired by robust subspace recovery,
and we fully integrate cycle consistency into MPLS for rotation
synchronization. Our global approach avoids the need for bundle adjustment.
Experiments on synthetic and real datasets show that Cycle-Sync consistently
outperforms leading pose estimators, including full structure-from-motion
pipelines with bundle adjustment.

</details>


### [22] [GAFD-CC: Global-Aware Feature Decoupling with Confidence Calibration for OOD Detection](https://arxiv.org/abs/2511.02335)
*Kun Zou,Yongheng Xu,Jianxing Yu,Yan Pan,Jian Yin,Hanjiang Lai*

Main category: cs.CV

TL;DR: GAFD-CC通过结合全球分类权重和多尺度信心校准，将特征与逻辑校准，以提高在分布和离分布边界区分性能，从而提升OOD检测能力


<details>
  <summary>Details</summary>
Motivation: 现有的OOD检测方法往往忽略特征和逻辑之间的内在相关性，影响了检测效果。GAFD-CC旨在通过引入这种相关性，改进检测方法

Method: 首先，GAFD-CC通过分类权重的指导，进行全局感知的特征解耦。然后，它将这种解耦的特征与多尺度逻辑信心校准融合，以实现全面而鲁棒的OOD检测

Result: 广泛的实验表明，GAFD-CC在大范围基准上具有竞争优势和强大的泛化能力，优于最先进的方法

Conclusion: GAFD-CC通过引入特征和逻辑的全局相关性校准，提升OOD检测的准确性和鲁棒性，是一个有效的解决方案

Abstract: Out-of-distribution (OOD) detection is paramount to ensuring the reliability
and robustness of learning models in real-world applications. Existing post-hoc
OOD detection methods detect OOD samples by leveraging their features and
logits information without retraining. However, they often overlook the
inherent correlation between features and logits, which is crucial for
effective OOD detection. To address this limitation, we propose Global-Aware
Feature Decoupling with Confidence Calibration (GAFD-CC). GAFD-CC aims to
refine decision boundaries and increase discriminative performance. Firstly, it
performs global-aware feature decoupling guided by classification weights. This
involves aligning features with the direction of global classification weights
to decouple them. From this, GAFD-CC extracts two types of critical
information: positively correlated features that promote in-distribution
(ID)/OOD boundary refinement and negatively correlated features that suppress
false positives and tighten these boundaries. Secondly, it adaptively fuses
these decoupled features with multi-scale logit-based confidence for
comprehensive and robust OOD detection. Extensive experiments on large-scale
benchmarks demonstrate GAFD-CC's competitive performance and strong
generalization ability compared to those of state-of-the-art methods.

</details>


### [23] [CoCoVa: Chain of Continuous Vision-Language Thought for Latent Space Reasoning](https://arxiv.org/abs/2511.02360)
*Jizheng Ma,Xiaofei Zhou,Yanlong Song,Han Yan*

Main category: cs.CV

TL;DR: 提出了CoCoVa框架，利用连续跨模态推理来改进视觉语言任务。CoCoVa的核心是一个迭代推理周期，其中Latent Q-Former作为动态推理引擎，通过跨模态融合迭代地细化链式潜在思维向量。实验显示CoCoVa在各种基准测试中表现出色，并且具有良好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有Vision-Language Models（VLMs）局限于离散和僵化的语言标记空间中进行推理，无法充分发挥视觉感知的丰富性和高维度特性。为解决此问题，提出了CoCoVa框架，以连续跨模态推理架设语言处理和视觉理解之间的表示间隙桥梁。

Method: CoCoVa的核心是一个迭代推理周期，其中Latent Q-Former（LQ-Former）作为动态推理引擎，迭代地细化链式潜在思维向量，同时利用一个注意力聚合机制选择显著视觉区域，并通过对比学习和基于扩散的重构训练模型，确保潜在思维向量与视觉和文本模态的一致性。

Result: CoCoVa实验结果表明，该模型在各种基准测试中优于或可匹敌更大规模的语言模型，显示出高精度的推理和资源效率。

Conclusion: 该研究证明了CoCoVa能够有效提高视觉语言任务的表现，并提供了可能重构语言处理和视觉理解间表示间隙的方法。

Abstract: In human cognition, there exist numerous thought processes that are tacit and
beyond verbal expression, enabling us to understand and interact with the world
in multiple ways. However, contemporary Vision-Language Models (VLMs) remain
constrained to reasoning within the discrete and rigid space of linguistic
tokens, thereby bottlenecking the rich, high-dimensional nature of visual
perception. To bridge this gap, we propose CoCoVa (Chain of Continuous
Vision-Language Thought), a novel framework for vision-language model that
leverages continuous cross-modal reasoning for diverse vision-language tasks.
The core of CoCoVa is an iterative reasoning cycle, where a novel Latent
Q-Former (LQ-Former) acts as a dynamic reasoning engine, iteratively refining a
chain of latent thought vectors through cross-modal fusion. To focus this
process, a token selection mechanism dynamically identifies salient visual
regions, mimicking attentional focus. To ensure these latent thoughts remain
grounded, we train the model with a multi-task objective that combines
contrastive learning and diffusion-based reconstruction, enforcing alignment
between latent representations and both visual and textual modalities.
Evaluations show CoCoVa improves accuracy and token efficiency over strong
baselines. With a 1.5B backbone, it competes with or surpasses larger 7B-9B
models on almost all benchmarks. When scaled to 7B LLM backbones, it remains
competitive with state-of-the-art models. Qualitative analysis validates that
learned latent space captures interpretable and structured reasoning patterns,
highlighting the potential of CoCoVa to bridge the representational gap between
discrete language processing and the continuous nature of visual understanding.

</details>


### [24] [RxnCaption: Reformulating Reaction Diagram Parsing as Visual Prompt Guided Captioning](https://arxiv.org/abs/2511.02384)
*Jiahe Song,Chuang Wang,Bowen Jiang,Yinfan Wang,Hao Zheng,Xingjian Wei,Chengjin Liu,Junyuan Gao,Yubin Wang,Lijun Wu,Jiang Wu,Qian Yu,Conghui He*

Main category: cs.CV

TL;DR: 提出了RxnCaption框架，将化学反应图谱解析任务转化为图像字幕生成问题，引入了BIVP策略，提升了结构提取的质量。构建了RxnCaption-11k数据集，展示了优秀的性能，预计将促进化学文献中的结构信息提取和化学领域的人工智能应用。


<details>
  <summary>Details</summary>
Motivation: 现有的化学反应数据多以图像形式出现在论文中，不可机读，不可用于训练机器学习模型，本研究旨在解决这一问题，促进化学领域的人工智能研究和应用。

Method: RxnCaption框架重新定义了传统的坐标预测驱动的解析过程，将其转化为图像字幕生成问题，引入了BBox和Index作为视觉提示(BIVP)策略，使用最新的分子检测器MolYOLO来预测分子边界框和索引，实现了从图像到自然语言描述的转换。

Result: 实验表明，BIVP策略显著提升了结构提取的质量，简化了模型的设计，RxnCaption-VL模型在多个指标上达到了最先进的性能水平。

Conclusion: RxnCaption框架，BIVP策略，以及RxnCaption-11k数据集的构建为化学文献中的结构信息提取提供了一个高质量的解决方案，并推动了化学领域的人工智能研究。

Abstract: Large-scale chemical reaction datasets are crucial for AI research in
chemistry. However, existing chemical reaction data often exist as images
within papers, making them not machine-readable and unusable for training
machine learning models. In response to this challenge, we propose the
RxnCaption framework for the task of chemical Reaction Diagram Parsing (RxnDP).
Our framework reformulates the traditional coordinate prediction driven parsing
process into an image captioning problem, which Large Vision-Language Models
(LVLMs) handle naturally. We introduce a strategy termed "BBox and Index as
Visual Prompt" (BIVP), which uses our state-of-the-art molecular detector,
MolYOLO, to pre-draw molecular bounding boxes and indices directly onto the
input image. This turns the downstream parsing into a natural-language
description problem. Extensive experiments show that the BIVP strategy
significantly improves structural extraction quality while simplifying model
design. We further construct the RxnCaption-11k dataset, an order of magnitude
larger than prior real-world literature benchmarks, with a balanced test subset
across four layout archetypes. Experiments demonstrate that RxnCaption-VL
achieves state-of-the-art performance on multiple metrics. We believe our
method, dataset, and models will advance structured information extraction from
chemical literature and catalyze broader AI applications in chemistry. We will
release data, models, and code on GitHub.

</details>


### [25] [A Novel Grouping-Based Hybrid Color Correction Algorithm for Color Point Clouds](https://arxiv.org/abs/2511.02397)
*Kuo-Liang Chung,Ting-Chung Tang*

Main category: cs.CV

TL;DR: 本文提出了一种基于分组的混合颜色校正算法，用于颜色点云，该算法针对不同类型的颜色点使用不同的校正方法来实现颜色一致性校正。通过实验验证了该算法的优势。源代码可在GitHub上访问。


<details>
  <summary>Details</summary>
Motivation: 传统颜色校正方法主要适用于色彩图像，但在3D渲染和压缩应用中，颜色点云的校正需求更为复杂。为此，本文提出一种新的针对颜色点云的颜色校正算法。

Method: 算法首先估计源和目标点云的重叠率，根据重叠率将目标点分为不同组，并对每组点云使用不同的颜色校正方法。这些方法包括基于K最邻近的双边插值（KBI）方法、联合KBI和直方图均衡化（JKHE）方法以及直方图均衡化（HE）方法。算法还具备分组效果无关属性，并进行了消融研究。

Result: 通过对比当前最先进的方法，本文算法在1086组测试数据集上表现优异，支持提供源代码链接。

Conclusion: 我们的分组混合校正算法可以有效解决颜色点云校正的问题，优于现有的校正方法。同时，我们提倡共享研究代码，以利于进一步的研究和应用。

Abstract: Color consistency correction for color point clouds is a fundamental yet
important task in 3D rendering and compression applications. In the past, most
previous color correction methods aimed at correcting color for color images.
The purpose of this paper is to propose a grouping-based hybrid color
correction algorithm for color point clouds. Our algorithm begins by estimating
the overlapping rate between the aligned source and target point clouds, and
then adaptively partitions the target points into two groups, namely the close
proximity group Gcl and the moderate proximity group Gmod, or three groups,
namely Gcl, Gmod, and the distant proximity group Gdist, when the estimated
overlapping rate is low or high, respectively. To correct color for target
points in Gcl, a K-nearest neighbors based bilateral interpolation (KBI) method
is proposed. To correct color for target points in Gmod, a joint KBI and the
histogram equalization (JKHE) method is proposed. For target points in Gdist, a
histogram equalization (HE) method is proposed for color correction. Finally,
we discuss the grouping-effect free property and the ablation study in our
algorithm. The desired color consistency correction benefit of our algorithm
has been justified through 1086 testing color point cloud pairs against the
state-of-the-art methods. The C++ source code of our algorithm can be accessed
from the website: https://github.com/ivpml84079/Point-cloud-color-correction.

</details>


### [26] [ChartM$^3$: A Multi-Stage Code-Driven Pipeline for Constructing Multi-Dimensional and Multi-Step Visual Reasoning Data in Chart Comprehension](https://arxiv.org/abs/2511.02415)
*Duo Xu,Hao Cheng,Xin Lin,Zhen Xie,Hao Wang*

Main category: cs.CV

TL;DR: 提出了一种自动生成视觉推理数据集的多阶段代码驱动管道，用于提升多模态大型语言模型在复杂图表理解上的表现，构建了ChartM^3数据集，包含38K图表和142K问答对，以及2,871高质量评估样本。该数据集显著提升了模型的推理能力和跨领域泛化性。


<details>
  <summary>Details</summary>
Motivation: 当前研究在复杂图表场景和计算密集型推理任务上的覆盖不足，限制了多模态大型语言模型的表现。因此，需要一种系统的方法来生成高质量的视觉推理数据集，以提升模型理解复杂图表的能力。

Method: 通过集成检索增强生成（RAG）来获取专业图表模板，并利用链式思考（CoT）策略生成模仿真实数据分布的推理代码，进而实现图表渲染和问题相关的统计计算。该方法还通过模型基于评估来提高图表多样性及数据质量。该流程最终构建了一个包含38K张图表和142K个问答对的多维、多步ChartM^3数据集，并通过2,871个高质量评价样本来测量模型表现。

Result: 数据集通过监督微调（SFT）和强化学习（RL）实验显示，显著提高了推理能力和跨领域泛化表现，使更小的模型在复杂的图表理解能力上达到了与大型模型相媲美的性能水平。

Conclusion: 所构建的ChartM^3数据集提供了丰富的图表和高质量的问答对，增强了语言模型在复杂图表理解任务上的表现，特别是在简化模型所需处理能力方面取得了显著进展。

Abstract: Complex chart understanding tasks demand advanced visual recognition and
reasoning capabilities from multimodal large language models (MLLMs). However,
current research provides limited coverage of complex chart scenarios and
computation-intensive reasoning tasks prevalent in real-world applications.
This study proposes an automated multi-stage code-driven pipeline for
systematically generating visual reasoning datasets to address these
limitations. The pipeline integrates retrieval-augmented generation (RAG) to
retrieve professional chart templates and employs chain-of-thought (CoT)
strategies to generate reasoning codes that simulate real data distributions,
thereby driving chart rendering and question-related statistical computations.
Through model-based evaluation, the pipeline enhances chart diversity and data
quality. Using this framework, we construct ChartM$^3$, a multi-dimensional and
multi-step dataset containing 38K charts and 142K Q&A pairs for training, along
with 2,871 high-quality evaluation samples for enabling practical performance
assessment. Supervised fine-tuning (SFT) and reinforcement learning (RL)
experiments demonstrate that our dataset significantly improves reasoning
capabilities and cross-domain generalization performance, enabling smaller
models to achieve performance comparable to larger-scale models in complex
chart comprehension.

</details>


### [27] [Synthetic Crop-Weed Image Generation and its Impact on Model Generalization](https://arxiv.org/abs/2511.02417)
*Garen Boyadjian,Cyrille Pierre,Johann Laconte,Riccardo Bertoglio*

Main category: cs.CV

TL;DR: 本文提出了一种通过Blender生成合成作物和杂草图像的方法，以减少真实场景中获取注释数据集的成本。实验表明，基于合成图像的训练模型在实际应用中的性能与现有最佳方法相比有10%的提升，并且在跨域泛化方面表现出更好的性能。这表明合成农业数据集的潜在应用价值，并支持混合策略以实现更高效的模型训练。


<details>
  <summary>Details</summary>
Motivation: 精确的作物和杂草语义分割对于农业除草机器人是必需的，但真实田野中的大量标注数据集获取成本高昂。合成数据可以减轻这一负担，然而模拟图像与真实图像之间的差距仍然存在挑战。因此，本研究旨在开发一种生成多样化条件下的作物杂草合成图像的有效方法，以解决上述问题。

Method: 方法是利用Blender进行程序化生成合成作物-杂草图像，从而创建注释数据集，涵盖了各种植物生长、杂草密度、光照和相机角度等条件。随后在合成数据集和真实数据集上对最先进的分割模型进行评估，并分析它们的跨域泛化能力。

Result: 结果表明，在真实的任务中，基于合成数据训练的模型表现出的效果比现有最佳的方法高出10%。而且，在跨域泛化方面，合成数据的表现也优于真实数据。这表明了合成农业数据集在这一研究中的潜力。

Conclusion: 研究结论是合成农业数据集有助于创建高效的数据集，并支持了使用混合策略以提高模型训练的效率。

Abstract: Precise semantic segmentation of crops and weeds is necessary for
agricultural weeding robots. However, training deep learning models requires
large annotated datasets, which are costly to obtain in real fields. Synthetic
data can reduce this burden, but the gap between simulated and real images
remains a challenge. In this paper, we present a pipeline for procedural
generation of synthetic crop-weed images using Blender, producing annotated
datasets under diverse conditions of plant growth, weed density, lighting, and
camera angle. We benchmark several state-of-the-art segmentation models on
synthetic and real datasets and analyze their cross-domain generalization. Our
results show that training on synthetic images leads to a sim-to-real gap of
10%, surpassing previous state-of-the-art methods. Moreover, synthetic data
demonstrates good generalization properties, outperforming real datasets in
cross-domain scenarios. These findings highlight the potential of synthetic
agricultural datasets and support hybrid strategies for more efficient model
training.

</details>


### [28] [From the Laboratory to Real-World Application: Evaluating Zero-Shot Scene Interpretation on Edge Devices for Mobile Robotics](https://arxiv.org/abs/2511.02427)
*Nicolas Schuler,Lea Dewald,Nick Baldig,Jürgen Graf*

Main category: cs.CV

TL;DR: 该论文研究了在移动机器人边缘设备上部署视觉语言模型（VLMs）的能力，特别是针对场景解释和动作识别任务的小型VLM模型。实验在多样化的数据集上进行，探讨了小型模型在边缘设备上的潜力及其挑战、弱点和固有偏差。补充材料可从指定的网址获得。


<details>
  <summary>Details</summary>
Motivation: 研究目的是探索在移动机器人边缘设备上，使用小型视觉语言模型完成场景解释和动作识别任务的可行性，同时分析这些模型在资源受限设备上的性能、挑战、弱点等。

Method: 论文使用了最先进的视觉语言模型，对于场景解释和动作识别任务进行评估，特别关注可部署在边缘设备上的小型模型。实验数据集包含了现实世界的多种场景。

Result: 实验表明，小型VLM模型在边缘设备上具有一定的潜力，但也存在挑战和弱点，如准确性和推理时间之间的权衡问题。论文详细讨论了这些模型的固有偏差，并探讨了如何利用这些发现的信息进行改进。

Conclusion: 小型VLM模型在移动机器人边缘设备上具有应用潜力，但也需考虑模型的准确性、推理时间和固有偏差等问题，以优化性能和适应性。

Abstract: Video Understanding, Scene Interpretation and Commonsense Reasoning are
highly challenging tasks enabling the interpretation of visual information,
allowing agents to perceive, interact with and make rational decisions in its
environment. Large Language Models (LLMs) and Visual Language Models (VLMs)
have shown remarkable advancements in these areas in recent years, enabling
domain-specific applications as well as zero-shot open vocabulary tasks,
combining multiple domains. However, the required computational complexity
poses challenges for their application on edge devices and in the context of
Mobile Robotics, especially considering the trade-off between accuracy and
inference time. In this paper, we investigate the capabilities of
state-of-the-art VLMs for the task of Scene Interpretation and Action
Recognition, with special regard to small VLMs capable of being deployed to
edge devices in the context of Mobile Robotics. The proposed pipeline is
evaluated on a diverse dataset consisting of various real-world cityscape,
on-campus and indoor scenarios. The experimental evaluation discusses the
potential of these small models on edge devices, with particular emphasis on
challenges, weaknesses, inherent model biases and the application of the gained
information. Supplementary material is provided via the following repository:
https://datahub.rz.rptu.de/hstr-csrl-public/publications/scene-interpretation-on-edge-devices/

</details>


### [29] [KAO: Kernel-Adaptive Optimization in Diffusion for Satellite Image](https://arxiv.org/abs/2511.02462)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: 提出了一种新的卫星图像修复框架KAO，利用核自适应优化和扩散模型来处理高分辨率卫星图像中的缺失或被遮挡区域。实验结果表明，KAO在处理非常高分辨率的卫星图像时具有更高的稳定性和准确性，同时也更高效。


<details>
  <summary>Details</summary>
Motivation: 修复卫星图像中的缺失或被遮挡区域是遥感分析中的一个重要问题。现有的方法在处理非常高分辨率的图像时存在大量的再训练需求或计算开销，而KAO旨在解决这些问题，提供一种效率高且准确的解决方案。

Method: KAO框架采用了隐空间条件优化来优化一个紧凑的隐空间，同时也引入了显式传播过程以提高算法的稳定性和精度。这一方法专门为处理高分辨率卫星图像设计。

Result: 实验结果显示，KAO在处理非常高分辨率的卫星图像时，其稳定性和准确性优于当前方法，同时保持了较高的效率，达到了一个新的技术基准。

Conclusion: KAO提供了一个平衡了前处理模型效率和后处理模型灵活性的解决方案，可以用于处理非常高分辨率的卫星图像。

Abstract: Satellite image inpainting is a crucial task in remote sensing, where
accurately restoring missing or occluded regions is essential for robust image
analysis. In this paper, we propose KAO, a novel framework that utilizes
Kernel-Adaptive Optimization within diffusion models for satellite image
inpainting. KAO is specifically designed to address the challenges posed by
very high-resolution (VHR) satellite datasets, such as DeepGlobe and the
Massachusetts Roads Dataset. Unlike existing methods that rely on
preconditioned models requiring extensive retraining or postconditioned models
with significant computational overhead, KAO introduces a Latent Space
Conditioning approach, optimizing a compact latent space to achieve efficient
and accurate inpainting. Furthermore, we incorporate Explicit Propagation into
the diffusion process, facilitating forward-backward fusion, which improves the
stability and precision of the method. Experimental results demonstrate that
KAO sets a new benchmark for VHR satellite image restoration, providing a
scalable, high-performance solution that balances the efficiency of
preconditioned models with the flexibility of postconditioned models.

</details>


### [30] [MVAFormer: RGB-based Multi-View Spatio-Temporal Action Recognition with Transformer](https://arxiv.org/abs/2511.02473)
*Taiga Yamane,Satoshi Suzuki,Ryo Masumura,Shotaro Tora*

Main category: cs.CV

TL;DR: 本文提出了一种新的多视图动作识别方法MVAFormer，用于Spatio-Temporal Action Recognition (STAR) 设置，其通过引入基于transformer的视图协作模块来提高性能，该模块利用保存空间信息的特征图进行有效协作，并在自注意力机制上进行创新来建模多视图之间的关系。实验结果表明，MVAFormer比基线方法在F-measure上高出约4.4个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅适用于识别整个视频中的单一动作，不适用于STAR设置，即对视频中的每个行为逐个识别。因此，提出了MVAFormer，以解决现有方法在STAR任务中的局限性。

Method: 提出了MVAFormer，它包含一个基于Transformer的视图协作模块，该模块采用含有空间信息的特征图来维持多视图任务中的有效协作，并且在此模块中将自注意力区分不同视图训练成模型相互间的关系。

Result: 在新的数据集上进行的实验表明，MVAFormer相较于基线方法，在F-measure上高出约4.4个百分点，从而证明了其有效性。

Conclusion: 本文的方法MVAFormer有效地解决了现有的多视图动作识别方法无法解决的STAR设置下的挑战，通过创新的Transformer协作模块实现了显著性能的提升。

Abstract: Multi-view action recognition aims to recognize human actions using multiple
camera views and deals with occlusion caused by obstacles or crowds. In this
task, cooperation among views, which generates a joint representation by
combining multiple views, is vital. Previous studies have explored promising
cooperation methods for improving performance. However, since their methods
focus only on the task setting of recognizing a single action from an entire
video, they are not applicable to the recently popular spatio-temporal action
recognition~(STAR) setting, in which each person's action is recognized
sequentially. To address this problem, this paper proposes a multi-view action
recognition method for the STAR setting, called MVAFormer. In MVAFormer, we
introduce a novel transformer-based cooperation module among views. In contrast
to previous studies, which utilize embedding vectors with lost spatial
information, our module utilizes the feature map for effective cooperation in
the STAR setting, which preserves the spatial information. Furthermore, in our
module, we divide the self-attention for the same and different views to model
the relationship between multiple views effectively. The results of experiments
using a newly collected dataset demonstrate that MVAFormer outperforms the
comparison baselines by approximately $4.4$ points on the F-measure.

</details>


### [31] [OLATverse: A Large-scale Real-world Object Dataset with Precise Lighting Control](https://arxiv.org/abs/2511.02483)
*Xilong Zhou,Jianchun Chen,Pramod Rao,Timo Teufel,Linjie Lyu,Tigran Minasian,Oleksandr Sotnychenko,Xiaoxiao Long,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: OLATverse是一个大规模现实世界物体数据集，包含约900万张765个不同物体的图像，这些图像来自多个视角，并在多种精确控制的光照条件下拍摄。它能够提供现实主义和泛化的能力，为未来逆向渲染和光照方法的发展提供支持。


<details>
  <summary>Details</summary>
Motivation: 现有关于逆向渲染、新视图合成和重新光照的方法虽然已在合成数据集上取得显著进展，但主要依赖于合成数据集进行训练和小规模现实世界数据集进行基准测试，这限制了其真实性和泛化能力。因此，我们需要一个大规模的现实世界数据集以解决这一问题，OLATverse数据集正是为了弥补这一空白应运而生的。它不仅提供了大规模的真实物体覆盖，还提供了在精确控制光照情况下的高保真外观。

Method: 通过使用35部DSLR相机和331个独立控制的光源来捕捉约765个不同的真实世界物体，每个物体的亮度都经过校准，提供了准确的物体遮罩，光照表面法线和散射反射率作为辅助资源。除此之外，还构建了一个广泛的评估集，用于逆向渲染和法线估计的现实世界的物体中心基准评估。这些都会在网站https://vcai.mpi-inf.mpg.de/projects/OLATverse/上提供。

Result: OLATverse数据集的建立，作为新的逆向渲染和重新光照方法与现实世界数据集集成的关键步骤。它首次提供了现实世界的物体中心基准测试，并且展示了在多个视角和不同光照条件下的精确控制下的高保真外观。

Conclusion: OLATverse数据集将是推动未来逆向渲染和重新光照方法的重要一步，因为它可以更准确地模拟现实世界的复杂性。

Abstract: We introduce OLATverse, a large-scale dataset comprising around 9M images of
765 real-world objects, captured from multiple viewpoints under a diverse set
of precisely controlled lighting conditions. While recent advances in
object-centric inverse rendering, novel view synthesis and relighting have
shown promising results, most techniques still heavily rely on the synthetic
datasets for training and small-scale real-world datasets for benchmarking,
which limits their realism and generalization. To address this gap, OLATverse
offers two key advantages over existing datasets: large-scale coverage of real
objects and high-fidelity appearance under precisely controlled illuminations.
Specifically, OLATverse contains 765 common and uncommon real-world objects,
spanning a wide range of material categories. Each object is captured using 35
DSLR cameras and 331 individually controlled light sources, enabling the
simulation of diverse illumination conditions. In addition, for each object, we
provide well-calibrated camera parameters, accurate object masks, photometric
surface normals, and diffuse albedo as auxiliary resources. We also construct
an extensive evaluation set, establishing the first comprehensive real-world
object-centric benchmark for inverse rendering and normal estimation. We
believe that OLATverse represents a pivotal step toward integrating the next
generation of inverse rendering and relighting methods with real-world data.
The full dataset, along with all post-processing workflows, will be publicly
released at https://vcai.mpi-inf.mpg.de/projects/OLATverse/.

</details>


### [32] [DetectiumFire: A Comprehensive Multi-modal Dataset Bridging Vision and Language for Fire Understanding](https://arxiv.org/abs/2511.02495)
*Zixuan Liu,Siavash H. Khajavi,Guangkai Jiang*

Main category: cs.CV

TL;DR: 这篇论文介绍了DetectiumFire，这是一个大型的多模态数据集，包含22.5k高分辨率的火灾相关图片和2.5k火灾相关视频，为火灾研究和智能安全系统的发展提供资源。数据集被用来验证在多项任务中的实用性，并通过这些任务，强调了该数据集在推进火灾相关研究方面的潜力。数据集可通过提供的链接获取.


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏高质量的公共火灾领域数据集，这限制了多模态模型在火灾领域的应用。为了填补这一空白，本文构建了DetectiumFire数据集，以促进火灾理解的研究和智能安全系统的开发。 

Method: 创建DetectiumFire数据集，包括火灾类型多样的22.5k高分辨率图片和2.5k真实场景视频。数据集中的数据使用了传统的计算机视觉标签和描述场景的详细文字描述进行标注，用于图像生成和推理等任务。此外，还评估了数据集在对象检测、基于扩散的图像生成和视觉语言推理等任务中的有效性。 

Result: 通过多项任务的验证，研究指出DetectiumFire数据集不仅在规模、多样性和数据质量方面优于现有的基准，还显著减少了冗余并提升了现实世界场景覆盖度，对推进火灾相关研究具有潜在价值。 

Conclusion: DetectiumFire数据集为火灾相关的研究和智能安全系统的开发提供了一个高质量的资源。本工作通过释放该数据集到公开社区，促进了AI社区对火灾主题的更广泛探索。

Abstract: Recent advances in multi-modal models have demonstrated strong performance in
tasks such as image generation and reasoning. However, applying these models to
the fire domain remains challenging due to the lack of publicly available
datasets with high-quality fire domain annotations. To address this gap, we
introduce DetectiumFire, a large-scale, multi-modal dataset comprising of 22.5k
high-resolution fire-related images and 2.5k real-world fire-related videos
covering a wide range of fire types, environments, and risk levels. The data
are annotated with both traditional computer vision labels (e.g., bounding
boxes) and detailed textual prompts describing the scene, enabling applications
such as synthetic data generation and fire risk reasoning. DetectiumFire offers
clear advantages over existing benchmarks in scale, diversity, and data
quality, significantly reducing redundancy and enhancing coverage of real-world
scenarios. We validate the utility of DetectiumFire across multiple tasks,
including object detection, diffusion-based image generation, and
vision-language reasoning. Our results highlight the potential of this dataset
to advance fire-related research and support the development of intelligent
safety systems. We release DetectiumFire to promote broader exploration of fire
understanding in the AI community. The dataset is available at
https://kaggle.com/datasets/38b79c344bdfc55d1eed3d22fbaa9c31fad45e27edbbe9e3c529d6e5c4f93890

</details>


### [33] [LiteVoxel: Low-memory Intelligent Thresholding for Efficient Voxel Rasterization](https://arxiv.org/abs/2511.02510)
*Jee Won Lee,Jongseong Brad Choi*

Main category: cs.CV

TL;DR: LiteVoxel 是一种自适应训练流程，改进了稀疏体素栅格化技术，使其更稳定且减少内存使用，同时保持图像质量和性能。通过特定的损耗函数和自适应剪枝策略来优化低频区域和边界稳定性。实验显示与强SVRaster流程相比，LiteVoxel 的内存消耗减少了40%-60%且不会牺牲图像质量或性能。


<details>
  <summary>Details</summary>
Motivation: 优化基于优化的场景重建中的稀疏体素栅格化技术，解决其在低频内容下的欠拟合问题以及内存消耗过大的问题。

Method: 通过引入自适应剪枝逻辑、逆Sobel权重调整和训练中的gamma曲线来优化低频区域和边界稳定性。采用基于射线足迹和优先级的细分策略，在明确的增长预算下细化结构。该方法使稀疏体素栅格化更稳定且高效。

Result: 对比强SVRaster流程，LiteVoxel减少了40%-60%的峰值VRAM使用，并且在保持PSNR/SSIM、训练时间和FPS的同时改善了低频区域。

Conclusion: LiteVoxel提供了一种优化稀疏体素栅格化的方法，实现了更高效的训练流程，减少了内存消耗，同时保持了图像质量和性能。

Abstract: Sparse-voxel rasterization is a fast, differentiable alternative for
optimization-based scene reconstruction, but it tends to underfit low-frequency
content, depends on brittle pruning heuristics, and can overgrow in ways that
inflate VRAM. We introduce LiteVoxel, a self-tuning training pipeline that
makes SV rasterization both steadier and lighter. Our loss is made
low-frequency aware via an inverse-Sobel reweighting with a mid-training
gamma-ramp, shifting gradient budget to flat regions only after geometry
stabilize. Adaptation replaces fixed thresholds with a depth-quantile pruning
logic on maximum blending weight, stabilized by EMA-hysteresis guards and
refines structure through ray-footprint-based, priority-driven subdivision
under an explicit growth budget. Ablations and full-system results across
Mip-NeRF 360 (6scenes) and Tanks & Temples (3scenes) datasets show mitigation
of errors in low-frequency regions and boundary instability while keeping
PSNR/SSIM, training time, and FPS comparable to a strong SVRaster pipeline.
Crucially, LiteVoxel reduces peak VRAM by ~40%-60% and preserves low-frequency
detail that prior setups miss, enabling more predictable, memory-efficient
training without sacrificing perceptual quality.

</details>


### [34] [Forecasting Future Anatomies: Longitudianl Brain Mri-to-Mri Prediction](https://arxiv.org/abs/2511.02558)
*Ali Farki,Elaheh Moradi,Deepika Koundal,Jussi Tohka*

Main category: cs.CV

TL;DR: 该研究使用五种深度学习架构预测未来的脑部MRI图像，准确率高且能在独立数据集上泛化，为个性化预后提供了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 预测脑部状态对未来神经影像研究至关重要，尤其是在认知退化性疾病的早期诊断如阿尔茨海默病中，现有的方法主要集中在预测未来认知分数或临床结果，而本研究旨在通过预测未来的MRI来直接建模复杂的神经退行性模式。

Method: 该研究综合并评估了五种深度学习架构（UNet、U2-Net、UNETR、Time-Embedding UNet 和 ODE-UNet）在两个纵向队列（ADNI 和 AIBL）上的表现，直接对比预测出的MRI与实际扫描结果，采用评估全局相似性和局部差异的指标。

Result: 结果表明，表现最好的模型能够达到高保真度的预测，所有模型都很好的泛化到了一个独立外部数据集，显示出良好的跨队列性能。

Conclusion: 研究结果表明，深度学习能够可靠地预测个体的脑部MRI图像，为个性化预后提供了新的可能性。

Abstract: Predicting future brain state from a baseline magnetic resonance image (MRI)
is a central challenge in neuroimaging and has important implications for
studying neurodegenerative diseases such as Alzheimer's disease (AD). Most
existing approaches predict future cognitive scores or clinical outcomes, such
as conversion from mild cognitive impairment to dementia. Instead, here we
investigate longitudinal MRI image-to-image prediction that forecasts a
participant's entire brain MRI several years into the future, intrinsically
modeling complex, spatially distributed neurodegenerative patterns. We
implement and evaluate five deep learning architectures (UNet, U2-Net, UNETR,
Time-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL).
Predicted follow-up MRIs are directly compared with the actual follow-up scans
using metrics that capture global similarity and local differences. The best
performing models achieve high-fidelity predictions, and all models generalize
well to an independent external dataset, demonstrating robust cross-cohort
performance. Our results indicate that deep learning can reliably predict
participant-specific brain MRI at the voxel level, offering new opportunities
for individualized prognosis.

</details>


### [35] [The Urban Vision Hackathon Dataset and Models: Towards Image Annotations and Accurate Vision Models for Indian Traffic](https://arxiv.org/abs/2511.02563)
*Akash Sharma,Chinmay Mhatre,Sankalp Gawali,Ruthvik Bokkasam,Brij Kishore,Vishwajeet Pattanaik,Tarun Rambha,Abdul R. Pinjari,Vijay Kovvali,Anirban Chakraborty,Punit Rathore,Raghu Krishnapuram,Yogesh Simmhan*

Main category: cs.CV

TL;DR: UVH-26是一个包含印度班加罗尔2800个Safe-City CCTV摄像头拍摄的26,646张高分辨率交通图片的数据集，标注了1.8百万个边界框，涵盖了14种印度常见车辆类型。通过对比训练，基于UVH-26的数据集训练的检测模型在常用类别的mAP50:95值上比使用COCO数据集训练的模型提高了8.4%到31.5%。这表明对于特定领域的交通场景，使用特定领域的训练数据能获得更好的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了提供更适合印度特定交通环境的交通识别模型，开发人员构建了一个大规模的、特定领域的交通图像数据集UVH-26，旨在填补当前全球基准测试中的空白，推动在复杂交通条件下智能交通系统的检测、分类和应用的进展。

Method: 从印度班加罗尔城市的Safe-City CCTV摄像头中收集了2800个摄像头4周内的26,646张高分辨率图片，使用众包黑客马拉松活动让565名印度大学生进行图片标注，总共标注了1.8百万个边界框。通过算法对标注数据进行共识处理，并在此基础上训练了Yolo、RT-DETR等现代检测器模型，评估了模型在验证集中的精度。

Result: 相比使用COCO数据集训练的模型，使用UVH-26数据集训练的模型在mAP50、mAP75和mAP50:95上的指标提高了8.4%-31.5%。RT-DETR-X模型在常用的类目中表现最佳，在mAP50:95上的得分达到0.67。这表明在特定领域使用特定领域数据集进行训练，可以显著提升模型的性能，特别是在印度复杂的交通环境下。

Conclusion: UVH-26数据集展示了在复杂交通环境下进行智能交通系统应用的可能性，特别是对于像印度这样的发展中国家，其通过直接从操作中的交通摄像头获取数据，填补了现有全球基准数据集的不足，为后续的研究和应用提供了坚实的基础。

Abstract: This report describes the UVH-26 dataset, the first public release by
AIM@IISc of a large-scale dataset of annotated traffic-camera images from
India. The dataset comprises 26,646 high-resolution (1080p) images sampled from
2800 Bengaluru's Safe-City CCTV cameras over a 4-week period, and subsequently
annotated through a crowdsourced hackathon involving 565 college students from
across India. In total, 1.8 million bounding boxes were labeled across 14
vehicle classes specific to India: Cycle, 2-Wheeler (Motorcycle), 3-Wheeler
(Auto-rickshaw), LCV (Light Commercial Vehicles), Van, Tempo-traveller,
Hatchback, Sedan, SUV, MUV, Mini-bus, Bus, Truck and Other. Of these, 283k-316k
consensus ground truth bounding boxes and labels were derived for distinct
objects in the 26k images using Majority Voting and STAPLE algorithms. Further,
we train multiple contemporary detectors, including YOLO11-S/X, RT-DETR-S/X,
and DAMO-YOLO-T/L using these datasets, and report accuracy based on mAP50,
mAP75 and mAP50:95. Models trained on UVH-26 achieve 8.4-31.5% improvements in
mAP50:95 over equivalent baseline models trained on COCO dataset, with
RT-DETR-X showing the best performance at 0.67 (mAP50:95) as compared to 0.40
for COCO-trained weights for common classes (Car, Bus, and Truck). This
demonstrates the benefits of domain-specific training data for Indian traffic
scenarios. The release package provides the 26k images with consensus
annotations based on Majority Voting (UVH-26-MV) and STAPLE (UVH-26-ST) and the
6 fine-tuned YOLO and DETR models on each of these datasets. By capturing the
heterogeneity of Indian urban mobility directly from operational traffic-camera
streams, UVH-26 addresses a critical gap in existing global benchmarks, and
offers a foundation for advancing detection, classification, and deployment of
intelligent transportation systems in emerging nations with complex traffic
conditions.

</details>


### [36] [Seeing Across Time and Views: Multi-Temporal Cross-View Learning for Robust Video Person Re-Identification](https://arxiv.org/abs/2511.02564)
*Md Rashidunnabi,Kailash A. Hambarde,Vasco Lopes,Joao C. Neves,Hugo Proenca*

Main category: cs.CV

TL;DR: MTF-CVReID 是一种参数高效的框架，用于解决视频交叉视角领域的人重识别问题，通过引入七个互补模块，它在AG-VPReID等基准数据集上的表现超越了当前最佳，并且具有良好跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前在视频交叉视角领域（例如，空中-地面监控），由于极端视角变化、尺度差异和时间不一致，人重识别任务仍然是一个未解决的问题。为了应对这些挑战，我们提出了MTF-CVReID框架来解决这些问题。

Method: MTF-CVReID框架包含了七个互补模块：跨流特征归一化（CSFN），为纠正相机和视图偏差；多分辨率特征调和（MRFH），用于跨高度稳定比例；身份感知记忆模块（IAMM），用于增强持久身份特征；时间动态建模（TDM），用于运动感知的短期时间编译；跨视图特征对齐（IVFA），用于不变视图表示对齐；分层时间模式学习（HTPL），用于捕获多尺度时间规则；多视图识别一致性学习（MVICL），用于利用对比学习范式的跨视图识别一致性强制执行。添加的参数和计算约为基线上的2百万参数和0.7 GFLOPs，而实时效率为189帧/秒的效率持续保持。

Result: 在AG-VPReID基准数据集的所有高度水平上，MTF-CVReID达到了最先进的性能，具有较强的数据集泛化能力。实验结果表明，通过精心设计的适配器基类模块可以显著增强处理效率，跨视图鲁棒性和时间一致性，同时不损害计算效率。

Conclusion: MTF-CVReID在交叉视角人重识别问题中显示出优越的性能和时间效率。重要的是，它显示了对抗视角变化、尺度差异和时间不一致保持稳定性的能力，这证明了其模块化设计的有效性。

Abstract: Video-based person re-identification (ReID) in cross-view domains (for
example, aerial-ground surveillance) remains an open problem because of extreme
viewpoint shifts, scale disparities, and temporal inconsistencies. To address
these challenges, we propose MTF-CVReID, a parameter-efficient framework that
introduces seven complementary modules over a ViT-B/16 backbone. Specifically,
we include: (1) Cross-Stream Feature Normalization (CSFN) to correct camera and
view biases; (2) Multi-Resolution Feature Harmonization (MRFH) for scale
stabilization across altitudes; (3) Identity-Aware Memory Module (IAMM) to
reinforce persistent identity traits; (4) Temporal Dynamics Modeling (TDM) for
motion-aware short-term temporal encoding; (5) Inter-View Feature Alignment
(IVFA) for perspective-invariant representation alignment; (6) Hierarchical
Temporal Pattern Learning (HTPL) to capture multi-scale temporal regularities;
and (7) Multi-View Identity Consistency Learning (MVICL) that enforces
cross-view identity coherence using a contrastive learning paradigm. Despite
adding only about 2 million parameters and 0.7 GFLOPs over the baseline,
MTF-CVReID maintains real-time efficiency (189 FPS) and achieves
state-of-the-art performance on the AG-VPReID benchmark across all altitude
levels, with strong cross-dataset generalization to G2A-VReID and MARS
datasets. These results show that carefully designed adapter-based modules can
substantially enhance cross-view robustness and temporal consistency without
compromising computational efficiency. The source code is available at
https://github.com/MdRashidunnabi/MTF-CVReID

</details>


### [37] [A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain Visual Decoding](https://arxiv.org/abs/2511.02565)
*Jingyu Lu,Haonan Wang,Qixiang Zhang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 提出了VCFlow，一种新颖的层次解码框架，用于从fMRI中重建连续的视觉体验，无需受试者特定的训练。VCFlow通过显式建模视觉系统的腹侧-背侧架构来学习多维表示，并引入了一种特征级别对比学习策略，以增强提取受试者不可变的语义表示，提高了对新受试者的适用性。该模型只牺牲了7%的准确率，在10秒内生成每个重建视频，不需要重新训练，提供了一个快速且临床可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 无受试者特定训练的连续视觉体验解码在临床应用中具有巨大的潜力，但由于跨受试者泛化和大脑信号复杂性的挑战，该领域仍然受到限制。研究者希望通过改进解码框架来增强解码器的适用性和效率，从而实现在不同受试者间的稳健表现。

Method: 提出了VCFlow框架，该框架通过建模人类视觉系统的腹侧-背侧架构，来学习多维表示，并通过特征级别对比学习策略增强提取受试者不可变的语义表示，从而提高解码器的泛化能力。与其他需要超过12小时受试者数据的传统管道相比，VCFlow在仅降低7%准确率的情况下，可以在10秒内生成每个重建视频，且无需重新训练。

Result: 该模型能够在重建连续视觉体验的同时，显著提高泛化性，并能在更短的时间内生成每个重建视频，而无需重新训练，从而实现快速和临床可扩展的解决方案。在新受试者中的表现也显示出相对较好的鲁棒性。

Conclusion: VCFlow提供了一种新颖的方法来改善无受试者特定训练的连续视觉体验解码的泛化性和效率，使用这种方法生成的解码器无需针对每个受试者重新训练，而且在新受试者中的表现也显示出一定的稳健性。这使得该模型能够在临床应用中实现快速、高效和可扩展的解决方案。

Abstract: Subject-agnostic brain decoding, which aims to reconstruct continuous visual
experiences from fMRI without subject-specific training, holds great potential
for clinical applications. However, this direction remains underexplored due to
challenges in cross-subject generalization and the complex nature of brain
signals. In this work, we propose Visual Cortex Flow Architecture (VCFlow), a
novel hierarchical decoding framework that explicitly models the ventral-dorsal
architecture of the human visual system to learn multi-dimensional
representations. By disentangling and leveraging features from early visual
cortex, ventral, and dorsal streams, VCFlow captures diverse and complementary
cognitive information essential for visual reconstruction. Furthermore, we
introduce a feature-level contrastive learning strategy to enhance the
extraction of subject-invariant semantic representations, thereby enhancing
subject-agnostic applicability to previously unseen subjects. Unlike
conventional pipelines that need more than 12 hours of per-subject data and
heavy computation, VCFlow sacrifices only 7\% accuracy on average yet generates
each reconstructed video in 10 seconds without any retraining, offering a fast
and clinically scalable solution. The source code will be released upon
acceptance of the paper.

</details>


### [38] [TAUE: Training-free Noise Transplant and Cultivation Diffusion Model](https://arxiv.org/abs/2511.02580)
*Daichi Nagai,Ryugo Morita,Shunsuke Kitada,Hitoshi Iyatomi*

Main category: cs.CV

TL;DR: 本文介绍了一种名为Training-free Noise Transplantation and Cultivation Diffusion Model (TAUE)的新框架，用于零样本情况下，多层图像生成。TAUE通过一种名为Noise Transplantation and Cultivation (NTC) 的技术，从前景和复合生成过程中抽取中间表示，并将其植入初始噪声中，为后续层进行跨层的语义和结构一致性处理，从而能生成包含前景、背景和合成层的一致多层输出。实验结果表明TAUE实现了与微调方法相当的性能，提高了层间一致性，同时保持了高质量图像，且无需训练和数据集需求，开启了新的下游应用，如复杂组合编辑。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案存在依赖大量可获取难的训练数据集或不能生成完整和连贯的场景的问题，需要一种高效且无需训练与数据集的方式进行层间控制的图像生成方式，从而解决专业应用中多层控制的瓶颈问题。

Method: 引入了Training-free Noise Transplantation and Cultivation Diffusion Model (TAUE)，它使用Noise Transplantation and Cultivation (NTC) 技术，通过抽取中间图形生成过程中的表示用于生成层间的表示，使得层间具备了语义和结构一致性。TAUE能够生成包含前景、背景和合成层的一致多层输出，并且无需训练与数据集需求，保持高性能的同时更易于进行编辑应用。

Result: 实验结果显示TAUE实现与微调方法相当的性能，提高了层间生成的一致性，同时保持较高图像质量和一致性。探索了下游生成应用领域，为专业用户提供了更加便捷和有效的层控制方法。

Conclusion: 本文提出了一个零样本图像分层生成的方法TAUE，使得既无训练和数据集需求，又能生成具有连贯结构和语义的多层图像，为专业图像生成拓展了新的应用领域，如复杂组合和支持编辑。

Abstract: Despite the remarkable success of text-to-image diffusion models, their
output of a single, flattened image remains a critical bottleneck for
professional applications requiring layer-wise control. Existing solutions
either rely on fine-tuning with large, inaccessible datasets or are
training-free yet limited to generating isolated foreground elements, failing
to produce a complete and coherent scene. To address this, we introduce the
Training-free Noise Transplantation and Cultivation Diffusion Model (TAUE), a
novel framework for zero-shot, layer-wise image generation. Our core technique,
Noise Transplantation and Cultivation (NTC), extracts intermediate latent
representations from both foreground and composite generation processes,
transplanting them into the initial noise for subsequent layers. This ensures
semantic and structural coherence across foreground, background, and composite
layers, enabling consistent, multi-layered outputs without requiring
fine-tuning or auxiliary datasets. Extensive experiments show that our
training-free method achieves performance comparable to fine-tuned methods,
enhancing layer-wise consistency while maintaining high image quality and
fidelity. TAUE not only eliminates costly training and dataset requirements but
also unlocks novel downstream applications, such as complex compositional
editing, paving the way for more accessible and controllable generative
workflows.

</details>


### [39] [Zero-Shot Multi-Animal Tracking in the Wild](https://arxiv.org/abs/2511.02591)
*Jan Frederik Meier,Timo Lüddecke*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉基础模型的零样本多动物追踪框架，结合了Grounding Dino和SAM 2，并使用精心设计的启发式方法，无需重新训练或调整超参数即可适用于新数据集。实验结果在多个数据集上显示了强大的性能和一致性。


<details>
  <summary>Details</summary>
Motivation: 多动物追踪在动物生态和行为研究中至关重要，但因栖息地、运动模式和物种特征的变化而具有挑战性。传统的多动物追踪方法需要针对每个应用情景进行大量的模型调优和启发式设计。本文探索了近期视觉基础模型在多动物追踪中的应用，以实现在新数据集上的零样本应用，无需重新训练或调整超参数。

Method: 本文结合了Grounding Dino和SAM 2模型，并使用精心设计的启发式方法开发了一种新的多动物追踪框架，旨在实现零样本的多动物追踪，无需再对模型进行微调或超参数的调整。

Result: 实验结果在ChimpAct，鸟群追踪，AnimalTrack和GMOT-40的子集数据集上显示了强大的性能和一致性，表明所提方法在多种物种和环境中都表现出稳定且优秀的追踪性能。

Conclusion: 本文展示了视觉基础模型在零样本多动物追踪中的应用潜力，开发出了一种无需重新训练或调整超参数即可应用于新数据集的框架。这为未来的多动物行为研究提供了新的思路和技术支持。

Abstract: Multi-animal tracking is crucial for understanding animal ecology and
behavior. However, it remains a challenging task due to variations in habitat,
motion patterns, and species appearance. Traditional approaches typically
require extensive model fine-tuning and heuristic design for each application
scenario. In this work, we explore the potential of recent vision foundation
models for zero-shot multi-animal tracking. By combining a Grounding Dino
object detector with the Segment Anything Model 2 (SAM 2) tracker and carefully
designed heuristics, we develop a tracking framework that can be applied to new
datasets without any retraining or hyperparameter adaptation. Evaluations on
ChimpAct, Bird Flock Tracking, AnimalTrack, and a subset of GMOT-40 demonstrate
strong and consistent performance across diverse species and environments. The
code is available at https://github.com/ecker-lab/SAM2-Animal-Tracking.

</details>


### [40] [UniChange: Unifying Change Detection with Multimodal Large Language Model](https://arxiv.org/abs/2511.02607)
*Xu Zhang,Danyang Li,Xiaohang Dong,Tianhao Wu,Hualong Yu,Jianye Wang,Qicheng Li,Xiang Li*

Main category: cs.CV

TL;DR: UniChange是一款基于多模态大型语言模型的统一变化检测模型，它能够同时处理二元变化检测和语义变化检测任务，表现出色于多项公开基准测试中。


<details>
  <summary>Details</summary>
Motivation: 当前的变化检测模型大多仅使用单一类型的标注数据，限制了模型的泛化能力和多样性。为了解决这一问题，UniChange利用了大型语言模型的多模态处理潜力，开发了一种统一的变化检测框架，能同时处理不同类型的标签变化检测任务，提高模型的适用性。

Method: UniChange通过引入三个特别的令牌([T1], [T2], 和 [CHANGE])，结合文本提示，指导模型识别变化类别，无需预先定义分类头。这样，UniChange可以从多个来源的数据集中获取知识，即使这些数据集的类别定义存在冲突。

Result: 在WHU-CD, S2Looking, LEVIR-CD+, 和 SECOND 四个公开基准数据集上均取得了良好的性能表现，分别获得了90.41, 53.04, 78.87, 和 57.62 的交并比分数，超过了所有之前的方法。

Conclusion: UniChange展示了大型语言模型在统一变化检测框架中的应用潜力，特别是在解决多源数据集多样性和冲突性标签定义的问题上。

Abstract: Change detection (CD) is a fundamental task for monitoring and analyzing land
cover dynamics. While recent high performance models and high quality datasets
have significantly advanced the field, a critical limitation persists. Current
models typically acquire limited knowledge from single-type annotated data and
cannot concurrently leverage diverse binary change detection (BCD) and semantic
change detection (SCD) datasets. This constraint leads to poor generalization
and limited versatility. The recent advancements in Multimodal Large Language
Models (MLLMs) introduce new possibilities for a unified CD framework. We
leverage the language priors and unification capabilities of MLLMs to develop
UniChange, the first MLLM-based unified change detection model. UniChange
integrates generative language abilities with specialized CD functionalities.
Our model successfully unifies both BCD and SCD tasks through the introduction
of three special tokens: [T1], [T2], and [CHANGE]. Furthermore, UniChange
utilizes text prompts to guide the identification of change categories,
eliminating the reliance on predefined classification heads. This design allows
UniChange to effectively acquire knowledge from multi-source datasets, even
when their class definitions conflict. Experiments on four public benchmarks
(WHU-CD, S2Looking, LEVIR-CD+, and SECOND) demonstrate SOTA performance,
achieving IoU scores of 90.41, 53.04, 78.87, and 57.62, respectively,
surpassing all previous methods. The code is available at
https://github.com/Erxucomeon/UniChange.

</details>


### [41] [Robust Face Liveness Detection for Biometric Authentication using Single Image](https://arxiv.org/abs/2511.02645)
*Poulami Raha,Yeongnam Chae*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级CNN框架，用于识别打印/显示、视频和包裹攻击，以增强面部识别系统的安全性。该框架包括一个新的2D欺骗攻击数据集，并展示了检测欺骗攻击的视频演示。此架构可在1-2秒内完成生物特征认证，确保了快速准确的验证过程。


<details>
  <summary>Details</summary>
Motivation: 由于面部识别系统的脆弱性，恶意用户可以通过伪造面部图像或视频来绕过身份验证。这可能导致安全漏洞，因此有必要开发一种轻量级的、实时的攻击检测系统来增强面部识别的安全性。

Method: 提出了一种轻量级的CNN架构，用于检测打印/显示、视频和包裹攻击。该模型在包含500多段视频的新数据集上进行训练和验证，以区分真实面部和欺骗攻击。此外，该研究还提供了一个展示检测结果的示例视频。

Result: 实验结果表明，该轻量级CNN架构在各种欺骗攻击下表现出了高准确率和实时性，能够在1-2秒内完成生物特征认证。相比于现有的方法，该架构更轻量且更快速。

Conclusion: 本文提出了一种新的轻量级CNN框架，可以在保证准确性的同时提高实时性。通过新创建的2D欺骗攻击数据集和视频演示证明了该架构的有效性。

Abstract: Biometric technologies are widely adopted in security, legal, and financial
systems. Face recognition can authenticate a person based on the unique facial
features such as shape and texture. However, recent works have demonstrated the
vulnerability of Face Recognition Systems (FRS) towards presentation attacks.
Using spoofing (aka.,presentation attacks), a malicious actor can get
illegitimate access to secure systems. This paper proposes a novel light-weight
CNN framework to identify print/display, video and wrap attacks. The proposed
robust architecture provides seamless liveness detection ensuring faster
biometric authentication (1-2 seconds on CPU). Further, this also presents a
newly created 2D spoof attack dataset consisting of more than 500 videos
collected from 60 subjects. To validate the effectiveness of this architecture,
we provide a demonstration video depicting print/display, video and wrap attack
detection approaches. The demo can be viewed in the following link:
https://rak.box.com/s/m1uf31fn5amtjp4mkgf1huh4ykfeibaa

</details>


### [42] [Can Visual Input Be Compressed? A Visual Token Compression Benchmark for Large Multimodal Models](https://arxiv.org/abs/2511.02650)
*Tianfan Peng,Yuntao Du,Pengzhou Ji,Shijie Dong,Kailin Jiang,Mingchuan Ma,Yijun Tian,Jinhe Bi,Qian Li,Wei Du,Feng Xiao,Lizhen Cui*

Main category: cs.CV

TL;DR: UniPruneBench是一个用于评测视觉token剪枝方法的统一基准，覆盖了多个数据集和模型，提供了一种标准化的评估方式，不仅考量准确性，还包括系统级指标。实验发现随机剪枝是一个强劲基线，不同方法在不同场景下的表现不一致，某些任务对剪枝敏感度更高，主要影响因素是剪枝比例。


<details>
  <summary>Details</summary>
Motivation: 由于视觉编码器引入的大量视觉token，多模态大型模型在推理过程中效率低下。现有token压缩方法（如剪枝、合并）的评估标准碎片化、不一致，因此研究者提出UniPruneBench这样一个统一且可扩展的基准，用于评测视觉token剪枝方法，为未来研究提供稳健的基础。

Method: 该研究提出的UniPruneBench涵盖了包括随机剪枝在内的十种代表性压缩算法以及LLaVA-v1.5、Intern-VL3和Qwen2.5-VL三个多模态大型模型家族，采用六种标准评估协议和十个数据集进行评测，不仅考量准确性，还考虑系统级指标如运行时间和预填充延迟等。

Result: 该研究发现随机剪枝作为一个基准效果令人惊讶；没有单一方法在所有测试结果中都优于其他方法；敏感度在任务之间存在很大差异，文图识别(OCR)最容易受到剪枝的影响；剪枝比例成为决定性能下降的主要因素。

Conclusion: 未来在高效多模态建模研究中，UniPruneBench将作为固若金汤的可靠基础，支持各种研究需求，并可以帮助确定最有效的剪枝方案。

Abstract: Large multimodal models (LMMs) often suffer from severe inference
inefficiency due to the large number of visual tokens introduced by image
encoders. While recent token compression methods, such as pruning and merging,
have shown promise in reducing redundancy, their evaluation remains fragmented
and inconsistent. In this work, we present UniPruneBench, a unified and
extensible benchmark for visual token pruning in multimodal LLMs. UniPruneBench
provides standardized protocols across six ability dimensions and ten datasets,
covering ten representative compression algorithms and three families of LMMs
(LLaVA-v1.5, Intern-VL3, and Qwen2.5-VL). Beyond task accuracy, it incorporates
system-level metrics such as runtime and prefilling latency to provide a
holistic view. Our experiments uncover several key findings: (1) random pruning
is a surprisingly strong baseline, (2) no single method consistently
outperforms others across scenarios, (3) pruning sensitivity varies
significantly across tasks, with OCR being most vulnerable, and (4) pruning
ratio is the dominant factor governing performance degradation. We believe
UniPruneBench will serve as a reliable foundation for future research on
efficient multimodal modeling.

</details>


### [43] [Differentiable Hierarchical Visual Tokenization](https://arxiv.org/abs/2511.02652)
*Marius Aasan,Martine Hjelkrem-Tan,Nico Catalano,Changkyu Choi,Adín Ramírez Rivera*

Main category: cs.CV

TL;DR: 提出了一种可微分的 token 化器，能根据图像内容以像素级别的粒度适应视觉变化，并且保持向下兼容性，可以用于图像分类和密集预测任务，并支持图像到矢量的转换。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉变换器使用固定的 patch tokens 忽视了图像的空间和语义结构，因此提出了一种新的 token 化器来解决这个问题。

Method: 这种方法使用了分层模型选择和信息标准，使得 token 化器能够适应图像内容并保持与现有架构的兼容性。

Result: 实验表明，这种 token 化器在图像分类和密集预测任务中表现出色，并且还支持图像到矢量的转换。

Conclusion: 新的 token 化器提高了视觉变换器在处理图像数据时的效果，不仅保留了原始架构的特点，还增强了数据的适应性。

Abstract: Vision Transformers rely on fixed patch tokens that ignore the spatial and
semantic structure of images. In this work, we introduce an end-to-end
differentiable tokenizer that adapts to image content with pixel-level
granularity while remaining backward-compatible with existing architectures for
retrofitting pretrained models. Our method uses hierarchical model selection
with information criteria to provide competitive performance in both
image-level classification and dense-prediction tasks, and even supports
out-of-the-box raster-to-vector conversion.

</details>


### [44] [VidEmo: Affective-Tree Reasoning for Emotion-Centric Video Foundation Models](https://arxiv.org/abs/2511.02712)
*Zhicheng Zhang,Weicheng Wang,Yongjie Zhu,Wenyu Qin,Pengfei Wan,Di Zhang,Jufeng Yang*

Main category: cs.CV

TL;DR: 提出了一种新的情绪引导推理框架，利用视频情感基础模型（VidEmo）来感知基本属性、分析表达和理解高层次情感。该模型通过两种调优过程改进：情感课程学习和情感树强化学习，从而提高情绪推理的能力。同时建立了一个包含2.1M样本的情绪中心细粒度数据集（Emo-CFG），并取得了在15个面部感知任务中的竞争性结果，创下新的里程碑。


<details>
  <summary>Details</summary>
Motivation: 先进的方法在视频情感分析上取得了进步，但情感的动态和线索依赖性使得理解复杂和不断变化的情感状态变得困难。因此，需要一个能够统一感知、分析和理解的方法来解决这些挑战。

Method: 提出了一种新的情绪引导推理框架，该框架包含视频情感基础模型（VidEmo），通过情绪课程学习和情感树强化学习进行两阶段调优，以及一个新的细粒度情绪数据集Emo-CFG，包括情绪相关的问题回答、细粒度的描述和相关原因。

Result: 实验结果表明，该方法在15个面部感知任务中取得了有竞争力的结果，创下新的里程碑。

Conclusion: 该研究通过一个新的推理框架和数据集，提供了一种新的方法来解决视频情绪分析中的挑战，显著提高了理解和预测情绪的能力。

Abstract: Understanding and predicting emotion from videos has gathered significant
attention in recent studies, driven by advancements in video large language
models (VideoLLMs). While advanced methods have made progress in video emotion
analysis, the intrinsic nature of emotions poses significant challenges.
Emotions are characterized by dynamic and cues-dependent properties, making it
difficult to understand complex and evolving emotional states with reasonable
rationale. To tackle these challenges, we propose a novel affective cues-guided
reasoning framework that unifies fundamental attribute perception, expression
analysis, and high-level emotional understanding in a stage-wise manner. At the
core of our approach is a family of video emotion foundation models (VidEmo),
specifically designed for emotion reasoning and instruction-following. These
models undergo a two-stage tuning process: first, curriculum emotion learning
for injecting emotion knowledge, followed by affective-tree reinforcement
learning for emotion reasoning. Moreover, we establish a foundational data
infrastructure and introduce a emotion-centric fine-grained dataset (Emo-CFG)
consisting of 2.1M diverse instruction-based samples. Emo-CFG includes
explainable emotional question-answering, fine-grained captions, and associated
rationales, providing essential resources for advancing emotion understanding
tasks. Experimental results demonstrate that our approach achieves competitive
performance, setting a new milestone across 15 face perception tasks.

</details>


### [45] [Dynamic Reflections: Probing Video Representations with Text Alignment](https://arxiv.org/abs/2511.02767)
*Tyler Zhu,Tengda Han,Leonidas Guibas,Viorica Pătrăucean,Maks Ovsjanikov*

Main category: cs.CV

TL;DR: 这项工作首次全面研究了视频-文本表示对齐，探讨了现代视频和语言编码器的能力。研究表明，跨模态对齐高度依赖于测试时提供的视觉和文本数据的丰富性，提出了参数化测试时间缩放定律，显示了对实证观察的显著预测能力。此外，研究还探讨了语义对齐与下游任务性能之间的关联，并将时间推理与跨模态对齐相关联，引入了视频-文本对齐作为探究不同编码器表示能力的零样本方法。


<details>
  <summary>Details</summary>
Motivation: 研究视频-文本表示对齐，探索现代视频和语言编码器的能力，填补在视频数据的跨模态对齐研究方面的空白。

Method: 进行视频-文本表示对齐的全面研究，分析不同类型视觉和文本数据对对齐的影响，提出参数化测试时间缩放定律，研究语义对齐与下游任务性能之间的关联，并探讨时间推理与跨模态对齐的关系。

Result: 研究表明，跨模态对齐高度依赖于测试时提供的视觉和文本数据的丰富性。同时，语义对齐与下游任务性能之间存在关联，时间推理在跨模态对齐中起重要作用。

Conclusion: 研究引入了视频-文本对齐作为一种探究不同编码器表示能力的零样本方法，为视频和语言模型的进一步研究提供了新方向。

Abstract: The alignment of representations from different modalities has recently been
shown to provide insights on the structural similarities and downstream
capabilities of different encoders across diverse data types. While significant
progress has been made in aligning images with text, the temporal nature of
video data remains largely unexplored in this context. In this work, we conduct
the first comprehensive study of video-text representation alignment, probing
the capabilities of modern video and language encoders. Our findings reveal
several key insights. First, we demonstrate that cross-modal alignment highly
depends on the richness of both visual (static images vs. multi-frame videos)
and text (single caption vs. a collection) data provided at test time,
especially when using state-of-the-art video encoders. We propose parametric
test-time scaling laws that capture this behavior and show remarkable
predictive power against empirical observations. Secondly, we investigate the
correlation between semantic alignment and performance on both semantic and
non-semantic downstream tasks, providing initial evidence that strong alignment
against text encoders may be linked to general-purpose video representation and
understanding. Finally, we correlate temporal reasoning with cross-modal
alignment providing a challenging test-bed for vision and language models.
Overall, our work introduces video-text alignment as an informative zero-shot
way to probe the representation power of different encoders for spatio-temporal
data. Project page can be found at https://video-prh.github.io/

</details>


### [46] [PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction & Editing](https://arxiv.org/abs/2511.02777)
*Antonio Oroz,Matthias Nießner,Tobias Kirschstein*

Main category: cs.CV

TL;DR: PercHead 是单张图像3D头部重建和语义3D编辑的方法，通过双分支编码器和基于ViT的解码器，实现从单图像视图一致的3D头部重建。该模型还实现了强大的3D编辑能力，能根据用户输入的分割图和样式控制提取出的3D模型。其具备新型的感知监督策略，并可实现语义3D编辑任务，同时基于轻量级交互式GUI支持用户对生成3D模型的几何和样式进行修改


<details>
  <summary>Details</summary>
Motivation: 解决单张图像3D头部重建和编辑的挑战，包括严重的视角遮挡、弱感知监督和3D空间编辑的模糊性

Method: 提出一种基于双分支编码器和基于ViT的解码器的模型，通过迭代交叉注意力将2D特征提升到3D空间中，采用了Gaussian Splatting进行渲染，并提出基于DINOv2和SAM2.1的新型感知监督策略

Result: 模型在新视图合成中实现了最先进的性能，并且与现有基线相比，在极端视角的角度下具有强大的鲁棒性；同时还提供了两个输入方式分割图和样式输入（文本提示或参考图像）进行独立控制来完成3D编辑任务

Conclusion: PercHead实现了从单张图像到视图一致3D头部重建和语义编辑的强大编辑能力，并通过一种轻量级交互式GUI支持用户操作

Abstract: We present PercHead, a method for single-image 3D head reconstruction and
semantic 3D editing - two tasks that are inherently challenging due to severe
view occlusions, weak perceptual supervision, and the ambiguity of editing in
3D space. We develop a unified base model for reconstructing view-consistent 3D
heads from a single input image. The model employs a dual-branch encoder
followed by a ViT-based decoder that lifts 2D features into 3D space through
iterative cross-attention. Rendering is performed using Gaussian Splatting. At
the heart of our approach is a novel perceptual supervision strategy based on
DINOv2 and SAM2.1, which provides rich, generalized signals for both geometric
and appearance fidelity. Our model achieves state-of-the-art performance in
novel-view synthesis and, furthermore, exhibits exceptional robustness to
extreme viewing angles compared to established baselines. Furthermore, this
base model can be seamlessly extended for semantic 3D editing by swapping the
encoder and finetuning the network. In this variant, we disentangle geometry
and style through two distinct input modalities: a segmentation map to control
geometry and either a text prompt or a reference image to specify appearance.
We highlight the intuitive and powerful 3D editing capabilities of our model
through a lightweight, interactive GUI, where users can effortlessly sculpt
geometry by drawing segmentation maps and stylize appearance via natural
language or image prompts.
  Project Page: https://antoniooroz.github.io/PercHead Video:
https://www.youtube.com/watch?v=4hFybgTk4kE

</details>


### [47] [VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual Representation](https://arxiv.org/abs/2511.02778)
*Kevin Qinghong Lin,Yuhao Zheng,Hangyu Ran,Dantong Zhu,Dongxing Mao,Linjie Li,Philip Torr,Alex Jinpeng Wang*

Main category: cs.CV

TL;DR: 本文提出了VCode，一个将多模态理解转化为代码生成任务的基准，要求模型基于图像生成忠实保持符号意义的SVG代码。同时，研究者引入了评估方法CodeVQA，提出了增强模型生成SVG能力的VCoder框架，以缓解语言为中心的和视觉为中心的编码之间的差距。实验表明前沿视觉语言模型在这一任务上表现出较高的潜力，但仍有改进空间。研究结果表明符号化视觉表示具有应用前景。


<details>
  <summary>Details</summary>
Motivation: 当前的编程相关研究主要针对语言中心的任务，而视觉中心的编程尚未得到充分探索。本文旨在填补语言理解和视觉理解之间的差距，通过引入SVG代码作为视觉和语言之间的桥梁，建立一个多模态理解和代码生成的任务基准，考察模型的符号保真度，探索如何改善当前模型在生成真实性和忠实性更高的SVG代码的能力。

Method: 提出VCode基准，要求模型根据输入的图像生成SVG代码；提出CodeVQA作为评估模型生成SVG代码的协议；开发了VCoder框架以改进VLm生成符号保真SVG代码的能力。VCoder分为两个方面：（i）通过修订迭代地分析并改进SVG代码；（ii）使用检测器和解析器提供模型原始能力之外的结构化信息。

Result: 通过实验表明，目前最先进的视觉语言模型在符号保真SVG代码生成任务上效率不高，这表明在语言为中心和视觉为中心的编码之间存在需要探索的差距。VCode方法和VCoder框架显示出了改善模型生成质量的潜力。人类研究一致表明渲染SVG对于人类和VLM来说都是一个挑战，这也揭示了符号化视觉表示的意义。

Conclusion: 通过建立VCode基准和使用CodeVQA评估视觉语言模型的代码生成能力，研究发现当前模型在生成符号保真SVG方面存在局限性。通过VCoder框架，可以显著提高模型生成高质量SVG的能力，这表明符号化视觉表示在多模态理解中有应用前景。

Abstract: Code has emerged as a precise and executable medium for reasoning and action
in the agent era. Yet, progress has largely focused on language-centric tasks
such as program synthesis and debugging, leaving visual-centric coding
underexplored. Inspired by how humans reason over sketches, we advocate SVG
code as a compact, interpretable, and executable visual representation. We
introduce VCode, a benchmark that reframes multimodal understanding as code
generation: given an image, a model must produce SVG that preserves symbolic
meaning for downstream reasoning. VCode covers three domains - general
commonsense (MM-Vet), professional disciplines (MMMU), and visual-centric
perception (CV-Bench). To assess symbolic fidelity, we propose CodeVQA, a novel
evaluation protocol in which a policy model answers questions over rendered
SVGs; correct answers indicate faithful symbolic preservation. Empirically,
frontier VLMs struggle to generate faithful SVGs, revealing a persistent gap
between language-centric and visual-centric coding. To close this gap, we
introduce VCoder, an agentic framework that augments VLMs along two axes: (i)
Thinking with Revision, which iteratively analyzes discrepancies and refines
SVG code; and (ii) Acting with Visual Tools, where detectors and parsers supply
structured cues such as objects, shapes, and text beyond the model's intrinsic
capacity. Across benchmarks, frontier VLMs with strong reasoning capabilities
score well overall yet remain limited in professional knowledge and 3D
reasoning. VCoder delivers a 12.3-point overall gain over the top-performing
Claude-4-Opus. Human studies show that both humans and VLMs perform worse on
rendered SVGs, their consistency reveals the promise of symbolic visual
representation. The benchmark and code are available at
https://github.com/CSU-JPG/VCode.

</details>


### [48] [When Visualizing is the First Step to Reasoning: MIRA, a Benchmark for Visual Chain-of-Thought](https://arxiv.org/abs/2511.02779)
*Yiyang Zhou,Haoqin Tu,Zijun Wang,Zeyu Wang,Niklas Muennighoff,Fan Nie,Yejin Choi,James Zou,Chaorui Deng,Shen Yan,Haoqi Fan,Cihang Xie,Huaxiu Yao,Qinghao Ye*

Main category: cs.CV

TL;DR: MIRA是一个新的基准测试，用于评估生成中间视觉图像对成功推理至关重要的模型。与依赖纯文本进行合理推理的传统方法不同，MIRA的任务要求模型生成并利用中间图像。该基准包含546个难题，实验表明当前多模态语言模型在纯文本提示中表现不佳，但在中间视觉提示中性能有所提高，平均提升33.7%。这突显了可视化信息在推理中的重要性。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是评估和提高模型在需要生成和利用中间视觉图像的情况下进行推理的能力。传统的CoT方法只依赖文本，而这不是最有效的人类解决问题的方法。因此，新基准MIRA试图通过模拟人类通过“画图思考”来解决复杂问题的方式，改善这种状况。

Method: MIRA基准测试包括546个高度注释的多模态问题，设计不同层次的评估输入，以涵盖直接输入、纯文本CoT输入、视觉-CoT输入。作者还报告了pass@k和多数投票准确性下的模型上限表现。实验中使用了现有的多模态大型语言模型，包括最强的私人模型和开源模型。评估表明，在视觉提示下性能得到了显著提升。

Result: 实验结果表明，当前的多模态大型语言模型在依赖纯文本提示的情况下表现平平，但在使用中间视觉提示时表现出明显改进，平均性能提升了33.7%。扩展搜索空间和与Visual-CoT一致的文本提示的尝试仅产生了有限的改进，这表明中间视觉图像在推理过程中起着关键作用。

Conclusion: 这个研究强调了想象中的视觉信息在MIRA基准测试上的推理任务中起着关键作用，同时也展示了现有的多模态模型在只有视觉提示的情况下能显著提高性能。这突显了想象和生成中间视觉图像在未来推理模型中的重要性。

Abstract: We propose MIRA, a new benchmark designed to evaluate models in scenarios
where generating intermediate visual images is essential for successful
reasoning. Unlike traditional CoT methods that rely solely on text, tasks in
MIRA require models to generate and utilize intermediate images - such as
sketches, structural diagrams, or path drawings - to guide their reasoning
process. This setup closely mirrors how humans solve complex problems through
"drawing to think". To solve this, MIRA focuses on tasks that are intrinsically
challenging and involve complex structures, spatial relationships, or reasoning
steps that are difficult to express through language alone. To ensure that our
evaluation data is of high-quality, we include 546 multimodal problems,
annotated with intermediate visual images and final answers. We also propose a
unified evaluation protocol for MIRA that spans three levels of evaluation
input: direct input with image and question only, text-only CoT input with
image and thinking prompts, and Visual-CoT input with both annotated image
clues and textual thinking prompts. To probe the upper bound of model capacity
on our benchmark, we also report pass@k and majority voting accuracies under
different k settings. Experimental results show that existing multimodal large
language models, including strongest private models as well as strong
open-weight models, perform poorly when relying solely on textual prompts.
However, when intermediate visual cues are provided, model performance improves
consistently, yielding an average relative gain of 33.7% across all models and
tasks. We also probe the upper bound by expanding the search space and
designing textual prompts aligned with Visual-CoT, but both yield only limited
improvements compared to our Visual-CoT setting. These results underscore the
critical role of imagined visual information in enabling successful reasoning
on MIRA.

</details>


### [49] [AI-Generated Image Detection: An Empirical Study and Future Research Directions](https://arxiv.org/abs/2511.02791)
*Nusrat Tasnim,Kutub Uddin,Khalid Mahmood Malik*

Main category: cs.CV

TL;DR: 本文介绍了一个统一的基准测试框架，用于在受控且可重复的条件下系统地评估取证方法。针对十种最先进的取证方法和七个公开数据集进行了广泛的系统评估，并使用多种指标进行评估，包括准确性、平均精度、ROC-AUC、误报率和类别的敏感度。结果表明，当前的方法在泛化能力上有显著差异，部分方法在同类数据上的表现强劲，但跨模型的迁移能力较弱。这项研究旨在引导研究社区更深入地理解当前取证方法的优势和局限性，以及激发更强大，更具解释性和泛化性的解决方案的发展。


<details>
  <summary>Details</summary>
Motivation: 目前，由AI生成的媒体尤其是深度伪造所带来的威胁正在为多媒体取证、误信息检测和生物识别系统带来重大挑战，并导致公众对法律体系的信任下降，欺诈和社交工程攻击增多。尽管已提出几种取证方法，但它们遭受三个关键差距：非标准化基准，不一致的训练协议，和限制性的评估指标。这些限制阻碍了公平比较，隐藏了真正稳健性，并限制了在安全关键应用中的部署。因此，需要一个统一的基准测试框架来解决这些问题。

Method: 该研究提出了一种统一的基准测试框架，用于在受控且可重复的条件下进行系统评估。该框架包括十个最先进的取证方法和七个公开数据集，涵盖GAN和扩散生成的图像，涉及从头训练、冻结、微调等多种训练协议。使用准确性、平均精度、ROC-AUC、误报率和类别敏感度等不同指标进行表现评估，并使用置信曲线和Grad-CAM热图进一步分析模型的可解释性。

Result: 评估表明，某些方法在同类数据上的表现强劲，但跨模型的迁移能力较弱，这意味着现有的取证方法在泛化能力和迁移学习方面存在挑战。此外，目前的评估指标可能不足以捕捉模型的解释性和泛化能力。

Conclusion: 该研究提供了详细的实证分析，揭示了现代视觉取证方法的局限性，并为未来的研究指明方向：开发出更强大，更具解释性和泛化性的解决方案是必要的。此外，研究强调了公开基准的重要性，可用作跨研究连续性测量的参考。

Abstract: The threats posed by AI-generated media, particularly deepfakes, are now
raising significant challenges for multimedia forensics, misinformation
detection, and biometric system resulting in erosion of public trust in the
legal system, significant increase in frauds, and social engineering attacks.
Although several forensic methods have been proposed, they suffer from three
critical gaps: (i) use of non-standardized benchmarks with GAN- or
diffusion-generated images, (ii) inconsistent training protocols (e.g.,
scratch, frozen, fine-tuning), and (iii) limited evaluation metrics that fail
to capture generalization and explainability. These limitations hinder fair
comparison, obscure true robustness, and restrict deployment in
security-critical applications. This paper introduces a unified benchmarking
framework for systematic evaluation of forensic methods under controlled and
reproducible conditions. We benchmark ten SoTA forensic methods (scratch,
frozen, and fine-tuned) and seven publicly available datasets (GAN and
diffusion) to perform extensive and systematic evaluations. We evaluate
performance using multiple metrics, including accuracy, average precision,
ROC-AUC, error rate, and class-wise sensitivity. We also further analyze model
interpretability using confidence curves and Grad-CAM heatmaps. Our evaluations
demonstrate substantial variability in generalization, with certain methods
exhibiting strong in-distribution performance but degraded cross-model
transferability. This study aims to guide the research community toward a
deeper understanding of the strengths and limitations of current forensic
approaches, and to inspire the development of more robust, generalizable, and
explainable solutions.

</details>


### [50] [PLUTO-4: Frontier Pathology Foundation Models](https://arxiv.org/abs/2511.02826)
*Harshith Padigela,Shima Nofallah,Atchuth Naveen Chilaparasetti,Ryun Han,Andrew Walker,Judy Shen,Chintan Shah,Blake Martin,Aashish Sood,Elliot Miller,Ben Glass,Andy Beck,Harsha Pokkalla,Syed Ashar Javed*

Main category: cs.CV

TL;DR: PLUTO-4 是新一代的病理基础模型，通过训练两个互补的Vision Transformer架构模型，即高效的PLUTO-4S模型和表现前沿的PLUTO-4G模型，在多个病理任务上取得了最先进的性能，并在实际应用和转化研究中具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 当前病理图像数据集训练的基础模型在跨多种病理任务上展示出强大的迁移能力。为了推动这一领域的进步，我们推出了能够扩展到更大数据集的PLUTO-4模型，旨在通过前沿架构提升病理图像理解的准确率和效率。

Method: PLUTO-4系列包含两种互补架构模型：一种是高效的PLUTO-4S模型，这种模型使用FlexiViT设置并应用2D-RoPE嵌入以实现多尺度部署；另一种是单补丁输入的最大化表示能力和稳定性的PLUTO-4G模型。这两个模型均在大型多机构数据集上进行预训练，在此过程中，引入了自监督学习的目标，使用DINOv2推出版本监督多个视图的一致性。

Result: 在多个公开和内部基准上的全面评估显示，PLUTO-4成功地在需要不同空间和生物上下文的任务上达到了最先进的表现，包括斑块级别的分类，分割和幻灯片级别的诊断。具体而言，PLUTO-4G在多种基准上提高了11%的皮肤病学诊断准确性。

Conclusion: PLUTO-4通过展示其在多个关键病理任务上的卓越性能，突显了作为推动实际应用和转化研究必要基础架构的巨大潜力。

Abstract: Foundation models trained on large-scale pathology image corpora have
demonstrated strong transfer capabilities across diverse histopathology tasks.
Building on this progress, we introduce PLUTO-4, our next generation of
pathology foundation models that extend the Pathology-Universal Transformer
(PLUTO) to frontier scale. We share two complementary Vision Transformer
architectures in the PLUTO-4 family: a compact and efficient PLUTO-4S model
optimized for multi-scale deployment using a FlexiViT setup with 2D-RoPE
embeddings, and a frontier-scale PLUTO-4G model trained with a single patch
size to maximize representation capacity and stability. Both models are
pretrained using a self-supervised objective derived from DINOv2 on a large
multi-institutional corpus containing 551,164 WSIs from 137,144 patients across
over 50 institutions, spanning over 60 disease types and over 100 stains.
Comprehensive evaluation across public and internal benchmarks demonstrates
that PLUTO-4 achieves state-of-the-art performance on tasks requiring varying
spatial and biological context, including patch-level classification,
segmentation, and slide-level diagnosis. The compact PLUTO-4S provides
high-throughput and robust performance for practical deployment, while PLUTO-4G
establishes new performance frontiers across multiple pathology benchmarks,
including an 11% improvement in dermatopathology diagnosis. These diverse
improvements underscore PLUTO-4's potential to transform real-world
applications as a backbone for translational research and diagnostic use cases.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [51] [Retrieval-Augmented Multimodal Depression Detection](https://arxiv.org/abs/2511.01892)
*Ruibo Hou,Shiyu Teng,Jiaqing Liu,Shurong Chai,Yinhao Li,Lanfen Lin,Yen-Wei Chen*

Main category: cs.LG

TL;DR: 通过检索增强生成框架（RAG）结合情感文本和大型语言模型生成的Emotion Prompt，改进了抑郁症检测的性能，达到了SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 传统的方法虽然通过情感分析提高了情感理解能力，但存在计算成本高、领域不匹配以及静态知识限制的问题。提出RAG框架来解决这些问题，以提高抑郁症检测的准确性和可解析性。

Method: 给定一段与抑郁症相关的文本，该方法从情感数据集中检索出语义相关的文本，并借助大型语言模型生成Emotion Prompt。此Emotion Prompt被用作辅助模态，增强情感表示。

Result: 在AVEC 2019数据集上的实验证明，这种方法的性能优于之前的迁移学习和多任务学习基准，实现了CCC 0.593和MAE 3.95的SOTA性能。

Conclusion: 所提出的方法通过引入情感提示，改进了抑郁症检测的效果，表明RAG框架对于抑郁症检测是一个有效的解决方案。

Abstract: Multimodal deep learning has shown promise in depression detection by
integrating text, audio, and video signals. Recent work leverages sentiment
analysis to enhance emotional understanding, yet suffers from high
computational cost, domain mismatch, and static knowledge limitations. To
address these issues, we propose a novel Retrieval-Augmented Generation (RAG)
framework. Given a depression-related text, our method retrieves semantically
relevant emotional content from a sentiment dataset and uses a Large Language
Model (LLM) to generate an Emotion Prompt as an auxiliary modality. This prompt
enriches emotional representation and improves interpretability. Experiments on
the AVEC 2019 dataset show our approach achieves state-of-the-art performance
with CCC of 0.593 and MAE of 3.95, surpassing previous transfer learning and
multi-task learning baselines.

</details>


### [52] [The Eigenvalues Entropy as a Classifier Evaluation Measure](https://arxiv.org/abs/2511.01904)
*Doulaye Dembélé*

Main category: cs.LG

TL;DR: 该论文提出使用特征值熵作为评估分类问题的一种新方法，特别是对于不平衡类别数据集，这种方法表现更好。对于二分类问题，论文建立了特征值与灵敏度、特异度、ROC曲线下的面积和Gini系数之间的关系。同时，该方法还提供了处理不平衡类别问题时混淆矩阵的估计方法。几个数据示例显示了该方法相对于文献中标准评估指标的优越性。


<details>
  <summary>Details</summary>
Motivation: 现存的评估指标在处理不平衡类别数据集时不够准确，因此需要开发一个新的评估指标来解决这一问题，特别是在分类任务中的表现。

Method: 论文使用特征值熵作为评估分类模型的新方法，特别是针对不平衡类别问题。并且，对于二分类问题，论文建立了特征值与一些常用评估指标之间的关系，给出了特征值和特征向量的意义和用途。此外，还提出了一种新的混淆矩阵估计方法来处理不平衡类别问题。

Result: 论文提出的特征值熵评估方法在处理不平衡类别数据集上比现有的标准评估指标表现更好，几个数据示例都证明了这一点。同时，论文还提供了一种新方法来估计不平衡类别问题的混淆矩阵。

Conclusion: 特征值熵作为评估分类模型的方法在处理不平衡类别数据集上非常有效，可以更好地反映模型的实际性能。同时，论文还提出了一种新方法来估计混淆矩阵，这种新方法在不平衡类别数据集上的表现优于传统方法。

Abstract: Classification is a machine learning method used in many practical
applications: text mining, handwritten character recognition, face recognition,
pattern classification, scene labeling, computer vision, natural langage
processing. A classifier prediction results and training set information are
often used to get a contingency table which is used to quantify the method
quality through an evaluation measure. Such measure, typically a numerical
value, allows to choose a suitable method among several. Many evaluation
measures available in the literature are less accurate for a dataset with
imbalanced classes. In this paper, the eigenvalues entropy is used as an
evaluation measure for a binary or a multi-class problem. For a binary problem,
relations are given between the eigenvalues and some commonly used measures,
the sensitivity, the specificity, the area under the operating receiver
characteristic curve and the Gini index. A by-product result of this paper is
an estimate of the confusion matrix to deal with the curse of the imbalanced
classes. Various data examples are used to show the better performance of the
proposed evaluation measure over the gold standard measures available in the
literature.

</details>


### [53] [Accounting for Underspecification in Statistical Claims of Model Superiority](https://arxiv.org/abs/2511.02453)
*Thomas Sanchez,Pedro M. Gordaliza,Meritxell Bach Cuadra*

Main category: cs.LG

TL;DR: 机器学习在医学影像领域的应用日益增多，但很多报告的性能提升缺乏统计学意义。新研究表明，即使稍微增加随机初始化或训练动态的差异，也需更多证据来支持其优越性。这表明需要明确建模训练方差以验证医学影像系统性能。


<details>
  <summary>Details</summary>
Motivation: 在医学影像中，尽管很多研究声称改进了机器学习方法，但这些改进的实际统计学意义有待商榷。此外，模型在未见数据上的表现可能因为随机初始化或训练动态并不会如预期一般稳健。因此，有必要通过引入训练的不确定因素，以更加稳健的方式来评估这些系统的性能。

Method: 该研究扩展了一种统计框架，通过加入对不明确性的建模，将模型训练中的随机性因素考虑进来，并通过模拟来展示这些因素对验证性能的影响。研究表明，即使是小的种子变异性也会大幅增加证明超常表现所需的证据量。

Result: 即使稍微提高随机初始化或训练动态的差异化，都需要更多的证据来支持性能的提升，说明医学影像系统验证中需要明确考虑训练方差的影响。

Conclusion: 本研究证明了训练方差作为验证医学影像系统性能时的一项重要因素，在未来的工作中，应当被充分考虑。

Abstract: Machine learning methods are increasingly applied in medical imaging, yet
many reported improvements lack statistical robustness: recent works have
highlighted that small but significant performance gains are highly likely to
be false positives. However, these analyses do not take
\emph{underspecification} into account -- the fact that models achieving
similar validation scores may behave differently on unseen data due to random
initialization or training dynamics. Here, we extend a recent statistical
framework modeling false outperformance claims to include underspecification as
an additional variance component. Our simulations demonstrate that even modest
seed variability ($\sim1\%$) substantially increases the evidence required to
support superiority claims. Our findings underscore the need for explicit
modeling of training variance when validating medical imaging systems.

</details>


### [54] [Superpositional Gradient Descent: Harnessing Quantum Principles for Model Training](https://arxiv.org/abs/2511.01918)
*Ahmet Erdem Pamuk,Emir Kaan Özdemir,Şuayp Talha Kocabay*

Main category: cs.LG

TL;DR: 提出了一种新的优化器Superpositional Gradient Descent (SGD)，通过在梯度更新中注入量子电路扰动来连接量子叠加，提升了经典训练的效果。在合成序列分类和大规模LLM微调任务中，SGD的收敛速度更快，最终损失更低。尽管结果有前景，但可扩展性和硬件限制仍然需要克服。


<details>
  <summary>Details</summary>
Motivation: 当前，大型语言模型 (LLM) 使用诸如 AdamW 的传统优化算法进行训练。然而，量子启发式方法如何增强经典训练仍然鲜为人知。因此，研究量子计算和深度学习之间的联系具有重要意义，能够为控制和增强模型行为提供实际途径。

Method: 提出了一种名为 Superpositional Gradient Descent (SGD) 的新优化器，通过在梯度更新中注入量子电路扰动来连接量子叠加，提出数学框架并在 PyTorch 和 Qiskit 中实现混合量子-经典电路。

Result: 在合成序列分类和大规模 LLM 微调任务中，SGD 的收敛速度更快，最终损失更低。然而，可扩展性和硬件限制限制了其广泛应用。

Conclusion: 这项工作提供了量子计算和深度学习之间的新见解，建议了利用量子原则来控制和增强模型行为的方法。

Abstract: Large language models (LLMs) are increasingly trained with classical
optimization techniques like AdamW to improve convergence and generalization.
However, the mechanisms by which quantum-inspired methods enhance classical
training remain underexplored. We introduce Superpositional Gradient Descent
(SGD), a novel optimizer linking gradient updates with quantum superposition by
injecting quantum circuit perturbations. We present a mathematical framework
and implement hybrid quantum-classical circuits in PyTorch and Qiskit. On
synthetic sequence classification and large-scale LLM fine-tuning, SGD
converges faster and yields lower final loss than AdamW. Despite promising
results, scalability and hardware constraints limit adoption. Overall, this
work provides new insights into the intersection of quantum computing and deep
learning, suggesting practical pathways for leveraging quantum principles to
control and enhance model behavior.

</details>


### [55] [DeepContour: A Hybrid Deep Learning Framework for Accelerating Generalized Eigenvalue Problem Solving via Efficient Contour Design](https://arxiv.org/abs/2511.01927)
*Yeqiu Chen,Ziyan Liu,Hong Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为DeepContour的新框架，它结合了深度学习和传统的数值方法来解决大规模广义特征值问题。通过快速预测频谱分布并自动确定积分轮廓，该方法在多个数据集上实现了高达5.63倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 解决大规模广义特征值问题时，函数轮廓的选择对性能至关重要。缺乏可靠的先验知识会导致计算开销和数值精度下降。为此，我们提出了一种新的框架来解决这个问题。

Method: 我们的方法首先使用傅里叶神经算子（FNO）来预测给定广义特征值问题的频谱分布，然后使用核密度估计（KDE）来确定适当的积分轮廓，最后使用优化后的轮廓来指导CI解算器找到所需的特征值。

Result: 实验结果表明，与传统的CIRR算法相比，我们的方法在多个数据集上实现了高达5.63倍的速度提升。

Conclusion: 该工作引入了一种将深度学习与传统数值求解器相结合的新方法，为大规模广义特征值问题提供了一种高效且稳健的解决方案。

Abstract: Solving large-scale Generalized Eigenvalue Problems (GEPs) is a fundamental
yet computationally prohibitive task in science and engineering. As a promising
direction, contour integral (CI) methods, such as the CIRR algorithm, offer an
efficient and parallelizable framework. However, their performance is
critically dependent on the selection of integration contours -- improper
selection without reliable prior knowledge of eigenvalue distribution can incur
significant computational overhead and compromise numerical accuracy. To
address this challenge, we propose DeepContour, a novel hybrid framework that
integrates a deep learning-based spectral predictor with Kernel Density
Estimation for principled contour design. Specifically, DeepContour first
employs a Fourier Neural Operator (FNO) to rapidly predict the spectral
distribution of a given GEP. Subsequently, Kernel Density Estimation (KDE) is
applied to the predicted spectrum to automatically and systematically determine
proper integration contours. Finally, these optimized contours guide the CI
solver to efficiently find the desired eigenvalues. We demonstrate the
effectiveness of our method on diverse challenging scientific problems. In our
main experiments, DeepContour accelerates GEP solving across multiple datasets,
achieving up to a 5.63$\times$ speedup. By combining the predictive power of
deep learning with the numerical rigor of classical solvers, this work pioneers
an efficient and robust paradigm for tackling difficult generalized eigenvalue
involving matrices of high dimension.

</details>


### [56] [Deciphering Personalization: Towards Fine-Grained Explainability in Natural Language for Personalized Image Generation Models](https://arxiv.org/abs/2511.01932)
*Haoming Wang,Wei Gao*

Main category: cs.LG

TL;DR: 本文提出了一种新方法 FineXL，能够用自然语言提供个性化图像生成模型在各个方面的详细解释，包括个性化的程度，并且实验表明FineXL在不同个性化场景下提高了解释准确性的56%。


<details>
  <summary>Details</summary>
Motivation: 当前的个性化图像生成模型缺乏具体的可解释性，尤其是用自然语言进行精细层面的解释。现有方法只能提供粗糙的解释，无法详细说明每个个性化方面的具体程度。为了改善这一点，提出了FineXL方法。

Method: FineXL方法通过自然语言描述每个个性化方面的具体情况，并提供量化得分来指示每个方面的个性化程度。它适用于多种个性化场景下的多种类型图像生成模型。

Result: 实验结果表明，在多个个性化场景下，FineXL提高了解释准确性的56%，表明它能够有效提升个性化图像生成模型的可解释性。

Conclusion: FineXL通过提供个性化图像生成模型在各个方面的精细解释，有效地提高了现有模型的可解释性，是一个有前景的方法。

Abstract: Image generation models are usually personalized in practical uses in order
to better meet the individual users' heterogeneous needs, but most personalized
models lack explainability about how they are being personalized. Such
explainability can be provided via visual features in generated images, but is
difficult for human users to understand. Explainability in natural language is
a better choice, but the existing approaches to explainability in natural
language are limited to be coarse-grained. They are unable to precisely
identify the multiple aspects of personalization, as well as the varying levels
of personalization in each aspect. To address such limitation, in this paper we
present a new technique, namely \textbf{FineXL}, towards \textbf{Fine}-grained
e\textbf{X}plainability in natural \textbf{L}anguage for personalized image
generation models. FineXL can provide natural language descriptions about each
distinct aspect of personalization, along with quantitative scores indicating
the level of each aspect of personalization. Experiment results show that
FineXL can improve the accuracy of explainability by 56\%, when different
personalization scenarios are applied to multiple types of image generation
models.

</details>


### [57] [Tool Zero: Training Tool-Augmented LLMs via Pure RL from Scratch](https://arxiv.org/abs/2511.01934)
*Yirong Zeng,Xiao Ding,Yutai Hou,Yuxian Wang,Li Du,Juyi Dai,Qiuyang Ding,Duyu Tang,Dandan Tu,Weiwen Liu,Bing Qin,Ting Liu*

Main category: cs.LG

TL;DR: 本文提出了一种基于规则的强化学习中的动态泛化引导奖励设计，并引入了Tool-Zero系列模型。这些模型能够使LLM自主使用通用工具，且在实验中表现优于监督微调(SFT)和结合SFT的强化学习模型，具有超过7%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs的训练依赖大量领域特定数据集，这使得模型在处理未知或复杂工具应用场景时效果不佳。本文试图通过纯强化学习方法来提升模型的推理能力和工具无关泛化能力。

Method: 提出一种动态泛化引导奖励设计，该设计使奖励从探索性工具使用模式逐步转向利用性模式。基于此设计，引入了Tool-Zero系列模型，通过直接在零模型上进行强化学习来训练LLM自主使用通用工具。

Result: 实验结果显示，与监督微调(SFT)及结合SFT的强化学习模型相比，Tool-Zero系列模型在相同条件下实现了超过7%的性能提升，且在跨数据集和数据集内评估中均表现出稳定的效果。

Conclusion: 研究验证了所提出方法的有效性和鲁棒性，表明基于纯强化学习的训练方法能提升语言模型的工具无关泛化能力和推理能力。

Abstract: Training tool-augmented LLMs has emerged as a promising approach to enhancing
language models' capabilities for complex tasks. The current supervised
fine-tuning paradigm relies on constructing extensive domain-specific datasets
to train models. However, this approach often struggles to generalize
effectively to unfamiliar or intricate tool-use scenarios. Recently,
reinforcement learning (RL) paradigm can endow LLMs with superior reasoning and
generalization abilities. In this work, we address a key question: Can the pure
RL be used to effectively elicit a model's intrinsic reasoning capabilities and
enhance the tool-agnostic generalization? We propose a dynamic
generalization-guided reward design for rule-based RL, which progressively
shifts rewards from exploratory to exploitative tool-use patterns. Based on
this design, we introduce the Tool-Zero series models. These models are trained
to enable LLMs to autonomously utilize general tools by directly scaling up RL
from Zero models (i.e., base models without post-training). Experimental
results demonstrate that our models achieve over 7% performance improvement
compared to both SFT and RL-with-SFT models under the same experimental
settings. These gains are consistently replicated across cross-dataset and
intra-dataset evaluations, validating the effectiveness and robustness of our
methods.

</details>


### [58] [Q-Sat AI: Machine Learning-Based Decision Support for Data Saturation in Qualitative Studies](https://arxiv.org/abs/2511.01935)
*Hasan Tutar,Caner Erden,Ümit Şentürk*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的模型，以替代传统的、依赖于主观数据饱和度的样本量确定方法，提高质性研究中的样本量确定过程的客观性。使用五种质性研究方法的衍生数据集，通过集成学习模型，开发了一种新的样本量确定方法。经过特征工程和模型训练，多种机器学习算法表现出较高的解释能力。研究开发了一个概念框架，旨在为质性研究人员、期刊审稿人和论文导师提供一个决策支持系统，从而标准化样本量确认，提高质性研究的透明性和严谨性。


<details>
  <summary>Details</summary>
Motivation: 当前，质性研究中的样本量确定依赖于主观的数据饱和度，导致一致性不足，影响方法论严谨性。提出基于机器学习的新模型，旨在提高样本量确定的客观性和效率，增强质性研究的方法论基础。

Method: 本文使用来自五种质性研究方法的数据集，通过十种关键参数作为输入特征，建立了集成学习模型。采用K-最近邻、梯度提升、随机森林等机器学习算法进行训练和比较，最终确定性能最佳的算法。并进行了特征重要性分析，确认了研究设计类型和信息力量的重要性。

Result: KNN、GB、RF、XGBoost和DT算法在测试集中展现出约0.85左右的解释能力，验证了基于机器学习的样本量确定模型对于质性研究中的复杂性、非线性关系判断有效性。特征重要性分析进一步证明了研究设计类型和信息力量在样本量确定中的重要性，支持关键理论假设。

Conclusion: 本文提出了基于ML算法的质性研究样本量确定模型，并建议开发一个基于Web的应用程序，作为质性研究人员、期刊审稿人和论文导师的决策支持系统，推动质性研究领域的标准化、透明化和严谨性。

Abstract: The determination of sample size in qualitative research has traditionally
relied on the subjective and often ambiguous principle of data saturation,
which can lead to inconsistencies and threaten methodological rigor. This study
introduces a new, systematic model based on machine learning (ML) to make this
process more objective. Utilizing a dataset derived from five fundamental
qualitative research approaches - namely, Case Study, Grounded Theory,
Phenomenology, Narrative Research, and Ethnographic Research - we developed an
ensemble learning model. Ten critical parameters, including research scope,
information power, and researcher competence, were evaluated using an ordinal
scale and used as input features. After thorough preprocessing and outlier
removal, multiple ML algorithms were trained and compared. The K-Nearest
Neighbors (KNN), Gradient Boosting (GB), Random Forest (RF), XGBoost, and
Decision Tree (DT) algorithms showed the highest explanatory power (Test R2 ~
0.85), effectively modeling the complex, non-linear relationships involved in
qualitative sampling decisions. Feature importance analysis confirmed the vital
roles of research design type and information power, providing quantitative
validation of key theoretical assumptions in qualitative methodology. The study
concludes by proposing a conceptual framework for a web-based computational
application designed to serve as a decision support system for qualitative
researchers, journal reviewers, and thesis advisors. This model represents a
significant step toward standardizing sample size justification, enhancing
transparency, and strengthening the epistemological foundation of qualitative
inquiry through evidence-based, systematic decision-making.

</details>


### [59] [Shorter but not Worse: Frugal Reasoning via Easy Samples as Length Regularizers in Math RLVR](https://arxiv.org/abs/2511.01937)
*Abdelaziz Bounhar,Hadi Abdine,Evan Dufraisse,Ahmad Chamma,Amr Mohamed,Dani Bouch,Michalis Vazirgiannis,Guokan Shang*

Main category: cs.LG

TL;DR: 该论文提出了一种方法，通过保留并适度增加简单问题的权重来防止大型语言模型在训练过程中的冗长输出。使用这种方法，模型在不增加任何显式长度惩罚的情况下，能够解决更复杂的问题并生成更短的答案。实验显示，其在AIME25基准测试中的准确率与基线相同，但生成的解决方案平均长度缩短了近一倍。代码和数据集在GitHub和Hugging Face上是公开的。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习验证奖励的训练方法在过滤掉简单问题后，模型倾向于生成过多冗长的答案，从而增加推理成本。因此，需要一种方法来防止模型输出过度冗长的答案。

Method: 通过保留并适度增加简单问题的权重，使模型接触到可解决的短链任务，以此间接地约束模型输出长度。通过这种方法，模型获得了解决复杂问题所需的能力，同时降低了输出的冗余。

Result: 实验结果表明，采用这种方法后，模型在不引入显式长度惩罚的情况下，生成的答案长度平均缩短了约50%。模型在AIME25基准测试中的pass@1准确率与基线相同。

Conclusion: 该工作展示了一种新的训练策略，能在维持模型性能的同时减少其输出的冗余，从而降低推理成本。该策略可以作为未来大规模语言模型训练的参考方法。

Abstract: Large language models (LLMs) trained for step-by-step reasoning often become
excessively verbose, raising inference cost. Standard Reinforcement Learning
with Verifiable Rewards (RLVR) pipelines filter out ``easy'' problems for
training efficiency, leaving the model to train primarily on harder problems
that require longer reasoning chains. This skews the output length distribution
upward, resulting in a \textbf{model that conflates ``thinking longer'' with
``thinking better''}. In this work, we show that retaining and modestly
up-weighting moderately easy problems acts as an implicit length regularizer.
Exposing the model to solvable short-chain tasks constrains its output
distribution and prevents runaway verbosity. The result is
\textbf{\emph{emergent brevity for free}}: the model learns to solve harder
problems without inflating the output length, \textbf{ despite the absence of
any explicit length penalization}. RLVR experiments using this approach on
\textit{Qwen3-4B-Thinking-2507} (with a 16k token limit) achieve baseline
pass@1 AIME25 accuracy while generating solutions that are, on average, nearly
twice as short. The code is available at
\href{https://github.com/MBZUAI-Paris/Frugal-AI}{GitHub}, with datasets and
models on
\href{https://huggingface.co/collections/MBZUAI-Paris/k2-think-mini-68dcfa8b114686a4bd3dc2bc}{Hugging
Face}.

</details>


### [60] [Learning a Distance for the Clustering of Patients with Amyotrophic Lateral Sclerosis](https://arxiv.org/abs/2511.01945)
*Guillaume Tejedor,Veronika Peralta,Nicolas Labroche,Patrick Marcel,Hélène Blasco,Hugo Alarcan*

Main category: cs.LG

TL;DR: 本文提出了一种基于疾病进展声明评分的序列聚类方法，以解决ALS患者临床意义集群定义的缺乏、现有聚类方法的局限性等问题。该方法结合了多个描述性变量，通过使用现成的距离度量和弱监督学习方法，提高了结果的相关性和可解释性，并在生存分析中优于现有的最先进的技术。


<details>
  <summary>Details</summary>
Motivation: ALS患者的临床表现差异大，现有治疗方法疗效有限，且缺乏系统化、可解释性强的患者群定义方法。本文旨在通过提出一种新的聚类方法，解决这些问题，以促进ALS患者的个性化治疗。

Method: 本文提出了一种使用疾病进展声明评分进行序列聚类的方法，整合了多个描述性变量，使用了几种距离度量（包括现成的距离度量和弱监督学习方法），并通过聚类方法评估了该方法的有效性。

Result: 实验结果表明，本文提出的聚类方法在生存分析中优于现有的最先进的方法，并且具有相似的轮廓分数。此外，这种方法增强了结果的相关性和解释性，对医学专家更有意义。

Conclusion: 本文提出了一种新的聚类方法，克服了当前ALS研究中的挑战，为ALS患者的个性化治疗提供了更多的可能性。

Abstract: Amyotrophic lateral sclerosis (ALS) is a severe disease with a typical
survival of 3-5 years after symptom onset. Current treatments offer only
limited life extension, and the variability in patient responses highlights the
need for personalized care. However, research is hindered by small,
heterogeneous cohorts, sparse longitudinal data, and the lack of a clear
definition for clinically meaningful patient clusters. Existing clustering
methods remain limited in both scope and number. To address this, we propose a
clustering approach that groups sequences using a disease progression
declarative score. Our approach integrates medical expertise through multiple
descriptive variables, investigating several distance measures combining such
variables, both by reusing off-the-shelf distances and employing a
weak-supervised learning method. We pair these distances with clustering
methods and benchmark them against state-of-the-art techniques. The evaluation
of our approach on a dataset of 353 ALS patients from the University Hospital
of Tours, shows that our method outperforms state-of-the-art methods in
survival analysis while achieving comparable silhouette scores. In addition,
the learned distances enhance the relevance and interpretability of results for
medical experts.

</details>


### [61] [COFAP: A Universal Framework for COFs Adsorption Prediction through Designed Multi-Modal Extraction and Cross-Modal Synergy](https://arxiv.org/abs/2511.01946)
*Zihan Li,Mingyang Wan,Mingyu Gao,Zhongshan Chen,Xiangke Wang,Feifan Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为COFAP的通用预测框架，用于预测共价有机框架(COFs)的吸附性能。该框架通过深度学习提取多模态结构和化学特征，并通过跨模态注意力机制融合这些互补特征。在没有亨利系数或吸附热的情况下，COFAP在hypoCOFs数据集上优于先前方法。此外，还发现了性能高的COFs集中在孔径和表面积的狭窄范围内，并开发了一种权重可调的优先级方案以支持应用特定的COFs排序。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习预测器依靠特定的气体相关特征，这些特征耗时且限制了规模，导致效率低下和劳动密集型过程。因此，开发了一种新的通用COFs吸附预测框架COFAP，以克服这些问题，并提高COFs筛选的效率和准确性。

Method: COFAP利用深度学习技术从COFs中提取多模态结构和化学特征，并通过跨模态注意力机制融合这些特征，从而提高了预测效率和准确性。此外，还开发了一种权重可调的优先级方案以支持应用特定的COFs排名。

Result: COFAP大幅提高了预测准确性，在hypoCOFs数据集中优于先前的方法，并发现了性能高的COFs集中在孔径和表面积的狭窄范围内。

Conclusion: 此方法提高了预测COFs性能的效率和准确性，为研究者提供了一种灵活、高效的工具，可直接应用于结晶多孔材料的研究。

Abstract: Covalent organic frameworks (COFs) are promising adsorbents for gas
adsorption and separation, while identifying the optimal structures among their
vast design space requires efficient high-throughput screening. Conventional
machine-learning predictors rely heavily on specific gas-related features.
However, these features are time-consuming and limit scalability, leading to
inefficiency and labor-intensive processes. Herein, a universal COFs adsorption
prediction framework (COFAP) is proposed, which can extract multi-modal
structural and chemical features through deep learning, and fuse these
complementary features via cross-modal attention mechanism. Without Henry
coefficients or adsorption heat, COFAP sets a new SOTA by outperforming
previous approaches on hypoCOFs dataset. Based on COFAP, we also found that
high-performing COFs for separation concentrate within a narrow range of pore
size and surface area. A weight-adjustable prioritization scheme is also
developed to enable flexible, application-specific ranking of candidate COFs
for researchers. Superior efficiency and accuracy render COFAP directly
deployable in crystalline porous materials.

</details>


### [62] [Measuring the Intrinsic Dimension of Earth Representations](https://arxiv.org/abs/2511.02101)
*Arjun Rao,Marc Rußwurm,Konstantin Klemmer,Esther Rolf*

Main category: cs.LG

TL;DR: 该研究首次探讨了地理隐式神经表示法（INRs）的内在维度性，发现其内在维度随着空间分辨率和输入模态的变化而变化，并且该维度与下游任务性能相关，可用作模型评估和诊断的指标。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏对地理INRs内部信息量及其分布的理解，该研究旨在探讨地球观察数据在多大程度上被压缩并集中在这些地理INRs中，并探讨其内在维度的重要性。

Method: 研究分析了具有256至512维空间的地理INRs，评估其内在维度与空间分辨率和输入模式的关系及其与下游任务性能的关联。

Result: 地理INRs的内在维度介于2到10之间，与其空间分辨率和输入模式有关，且该维度与模型在下游任务中的性能相关，能够捕捉空间异常情况。

Conclusion: 研究提供了一种与体系结构无关、无标签的信息内容评估指标，可用于无监督评估、模型选择和INRs的预训练设计。

Abstract: Within the context of representation learning for Earth observation,
geographic Implicit Neural Representations (INRs) embed low-dimensional
location inputs (longitude, latitude) into high-dimensional embeddings, through
models trained on geo-referenced satellite, image or text data. Despite the
common aim of geographic INRs to distill Earth's data into compact,
learning-friendly representations, we lack an understanding of how much
information is contained in these Earth representations, and where that
information is concentrated. The intrinsic dimension of a dataset measures the
number of degrees of freedom required to capture its local variability,
regardless of the ambient high-dimensional space in which it is embedded. This
work provides the first study of the intrinsic dimensionality of geographic
INRs. Analyzing INRs with ambient dimension between 256 and 512, we find that
their intrinsic dimensions fall roughly between 2 and 10 and are sensitive to
changing spatial resolution and input modalities during INR pre-training.
Furthermore, we show that the intrinsic dimension of a geographic INR
correlates with downstream task performance and can capture spatial artifacts,
facilitating model evaluation and diagnostics. More broadly, our work offers an
architecture-agnostic, label-free metric of information content that can enable
unsupervised evaluation, model selection, and pre-training design across INRs.

</details>


### [63] [EchoLSTM: A Self-Reflective Recurrent Network for Stabilizing Long-Range Memory](https://arxiv.org/abs/2511.01950)
*Prasanth K K,Shubham Sharma*

Main category: cs.LG

TL;DR: 提出了一种新的架构原则，Output-Conditioned Gating，它允许模型通过基于其过去推断调整其内部记忆门来实现自我反省。这种机制增强了记忆力，并与注意力机制结合成EchoLSTM。在挑战性的基准测试中，EchoLSTM在准确率和效率上都优于标准LSTM和现代Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 标准的Recurrent Neural Networks，包括LSTM，在处理长序列依赖时，特别是在含有噪音或误导性信息的数据中，表现不佳。为解决这个问题，提出了一种新的架构原则，以增强模型记忆能力。

Method: 提出了Output-Conditioned Gating，该方法允许模型通过基于其过去推断调整记忆门来进行自我反省。此外，还提出了一种名为EchoLSTM的模型，将该原则与注意力机制结合。

Result: 在定制的Distractor Signal Task中，EchoLSTM在准确率上明显优于标准LSTM。在ListOps基准上，EchoLSTM与现代Transformer模型竞争，同时其参数效率超过现代Transformer模型5倍以上。在Trigger Sensitivity Test中，提供了对模型自我反省机制增强记忆力效果的定性证据。

Conclusion: 提出的EchoLSTM模型通过自我反省机制有效地加强了记忆力，使模型在不同任务中表现出色，特别是在处理含有噪音或误导性信息的数据中。

Abstract: Standard Recurrent Neural Networks, including LSTMs, struggle to model
long-range dependencies, particularly in sequences containing noisy or
misleading information. We propose a new architectural principle,
Output-Conditioned Gating, which enables a model to perform self-reflection by
modulating its internal memory gates based on its own past inferences. This
creates a stabilizing feedback loop that enhances memory retention. Our final
model, the EchoLSTM, integrates this principle with an attention mechanism. We
evaluate the EchoLSTM on a series of challenging benchmarks. On a
custom-designed Distractor Signal Task, the EchoLSTM achieves 69.0% accuracy,
decisively outperforming a standard LSTM baseline by 33 percentage points.
Furthermore, on the standard ListOps benchmark, the EchoLSTM achieves
performance competitive with a modern Transformer model, 69.8% vs. 71.8%, while
being over 5 times more parameter-efficient. A final Trigger Sensitivity Test
provides qualitative evidence that our model's self-reflective mechanism leads
to a fundamentally more robust memory system.

</details>


### [64] [NeuroClean: A Generalized Machine-Learning Approach to Neural Time-Series Conditioning](https://arxiv.org/abs/2511.01951)
*Manuel A. Hernandez Alonso,Michael Depass,Stephan Quessy,Numa Dancause,Ignasi Cos*

Main category: cs.LG

TL;DR: 本文介绍了一种新的EEG/LFP预处理方法NeuroClean，通过自动化的流程减轻了人工干预带来的可重复性和偏差问题，提高了信号的质量和机器学习模型的性能。NeuroClean在不同类型的数据集上表现出了很好的效果，可以应用于未来的研究中以提高性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 本文提出了NeuroClean的方法，是为了应对EEG和LFP数据中存在的各种噪声和其他干扰源，实现数据的自动化处理，从而减轻人工干预的影响，提高数据质量和后续分析的可靠性。

Method: NeuroClean采用了无监督的方式，包括频带通滤波、线噪声滤波和坏通道剔除等步骤，同时结合了基于聚类算法的独立成分分析及机器学习分类器，确保在去除噪声的同时保留有用信息。

Result: 在验证数据集上，NeuroClean成功地移除了多种常见的干扰信号，并在更复杂的任务中比原始数据提高了30多个百分点的准确率，表明该方法的有效性和优越性。

Conclusion: 总体来说，NeuroClean为EEG和LFP数据的预处理提供了一种高效可靠的解决方案，可能在未来的机器学习任务和研究中发挥重要作用。

Abstract: Electroencephalography (EEG) and local field potentials (LFP) are two widely
used techniques to record electrical activity from the brain. These signals are
used in both the clinical and research domains for multiple applications.
However, most brain data recordings suffer from a myriad of artifacts and noise
sources other than the brain itself. Thus, a major requirement for their use is
proper and, given current volumes of data, a fully automatized conditioning. As
a means to this end, here we introduce an unsupervised, multipurpose EEG/LFP
preprocessing method, the NeuroClean pipeline. In addition to its completeness
and reliability, NeuroClean is an unsupervised series of algorithms intended to
mitigate reproducibility issues and biases caused by human intervention. The
pipeline is designed as a five-step process, including the common bandpass and
line noise filtering, and bad channel rejection. However, it incorporates an
efficient independent component analysis with an automatic component rejection
based on a clustering algorithm. This machine learning classifier is used to
ensure that task-relevant information is preserved after each step of the
cleaning process. We used several data sets to validate the pipeline.
NeuroClean removed several common types of artifacts from the signal. Moreover,
in the context of motor tasks of varying complexity, it yielded more than 97%
accuracy (vs. a chance-level of 33.3%) in an optimized Multinomial Logistic
Regression model after cleaning the data, compared to the raw data, which
performed at 74% accuracy. These results show that NeuroClean is a promising
pipeline and workflow that can be applied to future work and studies to achieve
better generalization and performance on machine learning pipelines.

</details>


### [65] [TapOut: A Bandit-Based Approach to Dynamic Speculative Decoding](https://arxiv.org/abs/2511.02017)
*Aditya Sridhar,Nish Sinnadurai,Sean Lie,Vithursan Thangarasa*

Main category: cs.LG

TL;DR: TapOut 是一种在线、无需训练的动态投机策略选择算法，使用多臂赌博机方法来提高大型语言模型的解码速度，无需手动调整阈值，就能获得最佳加速效果。


<details>
  <summary>Details</summary>
Motivation: 当前的动态投机解码方法依赖于手调的敏感阈值，这些阈值设置成本高且泛化能力差。因此，需要一种自动、无需训练的方法来确定最佳投机策略。

Method: TapOut 使用多臂赌博机方法，利用元算法基于过去的奖励和探索选择最优的参数自由动态投机策略。此方法可以直接在现有模型上应用，无需额外的训练。

Result: 实验证明，TapOut 在不同的模型组合和数据集上实现了与现有动态投机基线相当或更好的加速效果，并且无需任何超参数调整。

Conclusion: TapOut 提供了一种有效的、易于使用的策略来优化大型语言模型的动态投机解码，使得加速效果更高效且更易于实现。

Abstract: Speculative decoding accelerates LLMs by using a lightweight draft model to
generate tokens autoregressively before verifying them in parallel with a
larger target model. However, determining the optimal number of tokens to draft
remains a key challenge limiting the approach's effectiveness. Dynamic
speculative decoding aims to intelligently decide how many tokens to draft to
achieve maximum speedups. Existing methods often rely on hand-tuned, sensitive
thresholds (e.g., token entropy), which are costly to set and generalize poorly
across models and domains. We propose TapOut, an online, training-free,
plug-and-play algorithm for dynamic speculation policy selection using
multi-armed bandits. Our approach employs a meta-algorithm that selects among
multiple parameter-free dynamic speculation strategies based on past reward and
exploration. We conduct extensive experiments across diverse model pairs and
datasets, showing that TapOut achieves competitive or superior speedups
compared to well-established dynamic speculation baselines without any
hyperparameter tuning.

</details>


### [66] [Shared Parameter Subspaces and Cross-Task Linearity in Emergently Misaligned Behavior](https://arxiv.org/abs/2511.02022)
*Daniel Aarao Reis Arturi,Eric Zhang,Andrew Ansah,Kevin Zhu,Ashwinee Panda,Aishwarya Balwani*

Main category: cs.LG

TL;DR: 本文通过几何视角研究了大型语言模型在狭义有害数据集上微调后出现的有害泛化现象，发现这种现象具有跨任务的线性结构，并揭示了有害行为在参数空间中的组织方式，为理解EM现象提供了新的思路，推动了参数空间可解释性和基于权重的干预措施的研究。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解大型语言模型在狭义有害数据集上微调后出现有害泛化的根本机制，本文从几何角度研究了EM现象。

Method: 研究采用几何方法，通过分析模型在不同任务上的微调权重更新，量化了微调权重的收敛性，并通过线性模式连接性展示了任务之间的功能性等价。

Result: 结果表明，EM现象具有跨任务的线性结构，有害行为在参数空间中有组织地分布于特定区域，模型在狭义任务间的插值仍然展现出广泛的有害行为。

Conclusion: 通过揭示参数空间中行为组织方式的基本连接，本文希望进一步推动参数空间可解释性及基于权重的干预措施的研究。

Abstract: Recent work has discovered that large language models can develop broadly
misaligned behaviors after being fine-tuned on narrowly harmful datasets, a
phenomenon known as emergent misalignment (EM). However, the fundamental
mechanisms enabling such harmful generalization across disparate domains remain
poorly understood. In this work, we adopt a geometric perspective to study EM
and demonstrate that it exhibits a fundamental cross-task linear structure in
how harmful behavior is encoded across different datasets. Specifically, we
find a strong convergence in EM parameters across tasks, with the fine-tuned
weight updates showing relatively high cosine similarities, as well as shared
lower-dimensional subspaces as measured by their principal angles and
projection overlaps. Furthermore, we also show functional equivalence via
linear mode connectivity, wherein interpolated models across narrow
misalignment tasks maintain coherent, broadly misaligned behavior. Our results
indicate that EM arises from different narrow tasks discovering the same set of
shared parameter directions, suggesting that harmful behaviors may be organized
into specific, predictable regions of the weight landscape. By revealing this
fundamental connection between parametric geometry and behavioral outcomes, we
hope our work catalyzes further research on parameter space interpretability
and weight-based interventions.

</details>


### [67] [Natural-gas storage modelling by deep reinforcement learning](https://arxiv.org/abs/2511.02646)
*Tiziano Balaconi,Aldo Glielmo,Marco Taboga*

Main category: cs.LG

TL;DR: 介绍了一个名为GasRL的模拟器，它结合了天然气市场的校准表示和通过深度强化学习培训的存储运营商策略模型。我们使用它来分析最优库存管理如何影响均衡价格以及需求和供应的动力学。结果表明，软行为者评论者（SAC）在GasRL环境中表现出优越性能，能成功实现存储运营商的多重目标，包括利润、稳定清算和价格稳定，而生成的价格动力学与现实世界价格相似，无需校准价格数据。同时，证明了模拟器可以评估欧盟规定的最低库存阈值对市场冲击的影响，发现这些阈值增强了市场对未预期的供给冲击的恢复力。


<details>
  <summary>Details</summary>
Motivation: 研究存储运营商在天然气市场中的最优库存管理策略对均衡价格的影响，并评估最低存储阈值对市场恢复力的影响，以优化天然气市场的稳定性。目的在于验证深度强化学习模型在天然气市场中的应用可行性及其带来的优势。

Method: 开发了一个结合天然气市场模拟和强化学习模型的GasRL环境，并测试了几种强化学习算法。结果发现，Soft Actor Critic算法在GasRL环境中表现最优，可以实现存储运营商的多重目标，并生成与实际市场价格特性相近的价格动力学。同时，使用该模拟器评估了欧盟规定的最低存储阈值对市场恢复力的影响。

Result: 通过在GasRL环境中使用不同的强化学习算法，发现Soft Actor Critic算法表现最优，可以实现多项目标，生成的价格动力学与实际市场价格特性相符。同时，研究还展示了欧盟规定的最低存储阈值可以增强市场对未预期的供给冲击的恢复力，提高市场稳定性和恢复性。

Conclusion: GasRL模拟器结合天然气市场模拟和强化学习模型，不仅提高了存储运营商的盈利能力，而且增强了市场价格稳定性和市场恢复力。此外，还证明了基于深度强化学习的模拟器在评估能源市场政策中的潜力和价值。

Abstract: We introduce GasRL, a simulator that couples a calibrated representation of
the natural gas market with a model of storage-operator policies trained with
deep reinforcement learning (RL). We use it to analyse how optimal stockpile
management affects equilibrium prices and the dynamics of demand and supply. We
test various RL algorithms and find that Soft Actor Critic (SAC) exhibits
superior performance in the GasRL environment: multiple objectives of storage
operators - including profitability, robust market clearing and price
stabilisation - are successfully achieved. Moreover, the equilibrium price
dynamics induced by SAC-derived optimal policies have characteristics, such as
volatility and seasonality, that closely match those of real-world prices.
Remarkably, this adherence to the historical distribution of prices is obtained
without explicitly calibrating the model to price data. We show how the
simulator can be used to assess the effects of EU-mandated minimum storage
thresholds. We find that such thresholds have a positive effect on market
resilience against unanticipated shifts in the distribution of supply shocks.
For example, with unusually large shocks, market disruptions are averted more
often if a threshold is in place.

</details>


### [68] [Quantum-Enhanced Generative Models for Rare Event Prediction](https://arxiv.org/abs/2511.02042)
*M. Z. Haider,M. U. Ghouri,Tayyaba Noreen,M. Salman*

Main category: cs.LG

TL;DR: 研究提出了一种结合经典深度学习和量子算法的新型生成模型QEGM，该模型通过混合损失函数和量子噪声增强采样多样性，成功提高了罕见事件预测的准确性和鲁棒性，比现有方法有了显著提高，特别是在罕见事件的尾部区域表现更加出色


<details>
  <summary>Details</summary>
Motivation: 由于罕见事件的发生频率低且呈长尾分布，传统的深度生成模型很难准确捕捉这些事件，导致难以建模的问题，因此提出了量子增强生成模型QEGM

Method: QEGM通过混合损失函数优化重构准确度和尾部可能性，并通过量子噪声增加样本多样性，防止模式崩溃。模型训练时，经典参数通过反向传播更新，而量子参数则利用参数转移梯度进行优化

Result: 在合成高斯混合物和真实世界的数据集上，QEGM将尾部KL散度降低最多50%与最先进的基线（GAN，VAE，Diffusion）相比，罕见事件回溯和覆盖校准均有所提高

Conclusion: 研究表明QEGM不仅具有捕捉罕见事件的能力，并显著提高了准确性和鲁棒性，展示了在罕见事件预测中基于经典方法的改进潜力

Abstract: Rare events such as financial crashes, climate extremes, and biological
anomalies are notoriously difficult to model due to their scarcity and
heavy-tailed distributions. Classical deep generative models often struggle to
capture these rare occurrences, either collapsing low-probability modes or
producing poorly calibrated uncertainty estimates. In this work, we propose the
Quantum-Enhanced Generative Model (QEGM), a hybrid classical-quantum framework
that integrates deep latent-variable models with variational quantum circuits.
The framework introduces two key innovations: (1) a hybrid loss function that
jointly optimizes reconstruction fidelity and tail-aware likelihood, and (2)
quantum randomness-driven noise injection to enhance sample diversity and
mitigate mode collapse. Training proceeds via a hybrid loop where classical
parameters are updated through backpropagation while quantum parameters are
optimized using parameter-shift gradients. We evaluate QEGM on synthetic
Gaussian mixtures and real-world datasets spanning finance, climate, and
protein structure. Results demonstrate that QEGM reduces tail KL divergence by
up to 50 percent compared to state-of-the-art baselines (GAN, VAE, Diffusion),
while improving rare-event recall and coverage calibration. These findings
highlight the potential of QEGM as a principled approach for rare-event
prediction, offering robustness beyond what is achievable with purely classical
methods.

</details>


### [69] [Flashlight: PyTorch Compiler Extensions to Accelerate Attention Variants](https://arxiv.org/abs/2511.02043)
*Bozhi You,Irene Wang,Zelal Su Mustafaoglu,Abhinav Jangda,Angélica Moreira,Roshan Dathathri,Divya Mahajan,Keshav Pingali*

Main category: cs.LG

TL;DR: Flashlight是一个在PyTorch生态系统内的编译器原生框架，能够自动生成融合的、类似FlashAttention的内核，用于任意基于注意力的程序，支持所有FlexAttention可以支持的注意力变体，甚至更复杂的、数据依赖的注意力模式，同时保持与FlexAttention相同或更好的性能，提供原生的PyTorch代码灵活性，让开发者可以快速探索新的注意力模型而无需牺牲性能。


<details>
  <summary>Details</summary>
Motivation: 目前存在很多注意力机制的变体，这些变体通常需要专用内核或手写实现，以有效地运行。现有的FlexAttention框架使用静态编程模板来支持类似FlashAttention的内核，但还不支持所有变体。因此，该研究表明通过使用PyTorch的编译工作流提高效率，可以自动生成适用于所有注意力变体的内核，增加灵活性和性能。

Method: 提出Flashlight框架，该框架在PyTorch生态系统下，使用编译器原生方法生成FlashAttention风格的融合内核。与FlexAttention不同的是，Flashlight不依赖于静态编程模板，能够支持更广泛的注意力变体，并且可以产生符合各种注意力模式的内核，如数据依赖的注意力模式。

Result: 实验证明，Flashlight生成的内核在性能上与FlexAttention相当或更好，同时给予更灵活的原生PyTorch代码支持，使开发人员能够高效地探索新的注意力模型。

Conclusion: Flashlight为基于注意力机制的深度学习模型提供了一个高效的解决方案，能够自动生成融合的、高效执行的内核，支持广泛的数据依赖的注意力模型，同时保持高性能和代码灵活性。

Abstract: Bad charactors when submitting to arXiv: Attention is a fundamental building
block of large language models (LLMs), so there have been many efforts to
implement it efficiently. For example, FlashAttention leverages tiling and
kernel fusion to optimize attention. Recently, a number of variants of
attention have been introduced to enhance model quality or efficiency.
Supporting them efficiently remains difficult since they usually require
specialized kernels or hand-tuned implementations. FlexAttention recently
addressed part of this gap by using static programming templates to support
FlashAttention-like kernels for a subset of attention variants.
  In this paper, we introduce Flashlight, a compiler-native framework within
the PyTorch ecosystem that automatically generates fused, FlashAttention-style
kernels for arbitrary attention-based programs, without relying on static
templates or predefined kernel specializations. Flashlight leverages PyTorch's
compilation workflow to fuse and tile attention computations transparently,
enabling efficient execution for diverse attention patterns. Not only does it
support all variants expressible in the FlexAttention model but it also handles
more general, data-dependent attention formulations that are beyond the
capabilities of FlexAttention.
  Our results show that Flashlight produces kernels with competitive or
superior performance to FlexAttention, while offering the flexibility of native
PyTorch code, enabling developers to rapidly explore new attention models
without sacrificing performance.

</details>


### [70] [Regularization Through Reasoning: Systematic Improvements in Language Model Classification via Explanation-Enhanced Fine-Tuning](https://arxiv.org/abs/2511.02044)
*Vivswan Shah,Randy Cogill,Hanwei Yue,Gopinath Chennupati,Rinat Khaziev*

Main category: cs.LG

TL;DR: 在fine-tuning大型语言模型进行分类时，给标签附加简短的解释可以提升模型的性能，特别是对于对话质量的自然性、全面性和主题相关性。实验结果表明，即使这些解释只是随机词汇排列而非有意义的内容，也能提升模型的准确性，这主要是因为额外的token预算鼓励了更丰富的中间计算，并减少了过于自信的捷径。


<details>
  <summary>Details</summary>
Motivation: 探索在fine-tuning过程中给每个标签附加简短的解释是否可以提升模型的性能，特别是在对话质量方面的天然性、全面性和主题相关性的改进上。

Method: 通过使用来自多个大型语言模型的ensemble生成数据，对一个7B参数的模型进行fine-tuning，并在六个不同的对话数据集上进行测试。与只使用标签的baseline相比，带有标签加解释的数据集的训练效果更好。此外，使用随机生成的但词汇与原解释对齐的伪解释也显示出了提升效果。

Result: 实验表明，即使使用随机词汇排列的伪解释，也能比单纯的标签训练显著提升模型准确性和可靠性，并且这种效果在不同的数据集和训练种子条件下都能保持一致。

Conclusion: 解释增强的fine-tuning，无论是使用真实的理由还是精心制作的随机token序列，都可以提升大型语言模型在分类任务上的准确性和可靠性，同时也揭示了token层级的结构如何塑造推理过程中的计算。

Abstract: Fine-tuning LLMs for classification typically maps inputs directly to labels.
We ask whether attaching brief explanations to each label during fine-tuning
yields better models. We evaluate conversational response quality along three
axes: naturalness, comprehensiveness, and on-topic adherence, each rated on
5-point scales. Using ensemble-generated data from multiple LLMs, we fine-tune
a 7B-parameter model and test across six diverse conversational datasets.
Across 18 dataset, task settings, label-plus-explanation training outperforms
label-only baselines.
  A central and unexpected result concerns random tokens. We replace
human-written explanations with text that is syntactically incoherent yet
vocabulary-aligned with the originals (e.g., shuffled or bag-of-words
variants). Despite lacking semantics, these pseudo-explanations still improve
accuracy over label-only training and often narrow much of the gap to true
explanations. The effect persists across datasets and training seeds,
indicating that gains arise less from meaning than from structure: the extra
token budget encourages richer intermediate computation and acts as a
regularizer that reduces over-confident shortcuts.
  Internal analyses support this view: explanation-augmented models exhibit
higher activation entropy in intermediate layers alongside sharper predictive
mass at the output layer, consistent with increased deliberation before
decision. Overall, explanation-augmented fine-tuning, whether with genuine
rationales or carefully constructed random token sequences, improves accuracy
and reliability for LLM classification while clarifying how token-level
scaffolding shapes computation during inference.

</details>


### [71] [A Dual-Use Framework for Clinical Gait Analysis: Attention-Based Sensor Optimization and Automated Dataset Auditing](https://arxiv.org/abs/2511.02047)
*Hamidreza Sadeghsalehi*

Main category: cs.LG

TL;DR: 本文提出了一种多流注意力机制的深度学习框架，不仅可以优化传感器，还能自动审核数据集完整性。在应用于特定数据集时，该框架揭示了数据集中的严重偏倚问题，并提出了优化的传感器协同作业假设。


<details>
  <summary>Details</summary>
Motivation: 穿戴式传感器和AI进行步态分析对于管理神经和骨科疾病至关重要。然而，模型容易受到数据集合偏见的影响，任务特定的传感器优化仍然是一个挑战。因此，本文提出了旨在解决这些问题的多流注意力机制的深度学习框架。

Method: 所提出的模型基于多流注意力机制，可以优化传感器设置，同时还能自动审核数据集质量。该模型在Voisard等人的多群组步态数据集上进行了测试，该数据集涵盖了帕金森病、关节炎、中风筛查以及帕金森病与中风的不同筛查任务。通过注意力机制量化地发现了一个严重的数据集中偏差：右脚传感器获得了比左脚高70倍以上的关注度，这其实是由于公开数据集中内置的严重对侧偏差所造成的（所有关节炎患者都是右脚影响）。

Result: 通过所提出的模型，揭示了数据集中严重的左-右脚偏差并在任务特定的生物力学测量中提出了新的传感器协同假设，例如帕金森病筛查中的头部加脚协同作用。这些新发现对未来的优化协议有着重要的参考价值。

Conclusion: 本文的重要贡献在于设计了一个可以自动审计数据集完整性的可解释框架。此外，模型生成的数据驱动的传感器协同作用假设，为未来优化的筛查协议提供了重要参考。

Abstract: Objective gait analysis using wearable sensors and AI is critical for
managing neurological and orthopedic conditions. However, models are vulnerable
to hidden dataset biases, and task-specific sensor optimization remains a
challenge. We propose a multi-stream attention-based deep learning framework
that functions as both a sensor optimizer and an automated data auditor.
Applied to the Voisard et al. (2025) multi-cohort gait dataset on four clinical
tasks (PD, OA, CVA screening; PD vs CVA differential), the model's attention
mechanism quantitatively discovered a severe dataset confound. For OA and CVA
screening, tasks where bilateral assessment is clinically essential, the model
assigned more than 70 percent attention to the Right Foot while statistically
ignoring the Left Foot (less than 0.1 percent attention, 95 percent CI
[0.0-0.1]). This was not a clinical finding but a direct reflection of a severe
laterality bias (for example, 15 of 15 right-sided OA) in the public dataset.
The primary contribution of this work is methodological, demonstrating that an
interpretable framework can automatically audit dataset integrity. As a
secondary finding, the model proposes novel, data-driven sensor synergies (for
example, Head plus Foot for PD screening) as hypotheses for future optimized
protocols.

</details>


### [72] [Finding Probably Approximate Optimal Solutions by Training to Estimate the Optimal Values of Subproblems](https://arxiv.org/abs/2511.02048)
*Nimrod Megiddo,Segev Wasserkrug,Orit Davidovich,Shimrit Shtern*

Main category: cs.LG

TL;DR: 开发了一种求解器，用于最大化二进制变量的实值函数。该求解器依赖于一种算法，该算法估计从目标函数分布及其相应子实例中实例的目标函数最优值。训练估算器基于一个不等式，该不等式促进了使用预期的总最优条件偏差作为损失函数，而不是目标函数本身。因此，它不计算策略值，也不依赖于已解决的实例。


<details>
  <summary>Details</summary>
Motivation: 开发一个不依赖于已解决实例的求解器，用于最大化二进制变量的实值函数，并且不计算策略值，而是基于目标函数分布及其相应子实例进行优化。

Method: 该方法依赖于一个算法，该算法估计从目标函数分布及其相应子实例中实例的目标函数最优值，并且使用基于不等式的期望总偏差作为损失函数进行训练。

Result: 成功开发了一种新的求解器，该求解器能够估计最大化二进制变量的实值函数的目标函数最优值，而不需要计算策略值或依赖于已解决的实例。

Conclusion: 通过使用新的估计方法和损失函数，可以有效地最大化二进制变量的实值函数，同时也证明了这种方法的有效性和与其他方法相比的优势。

Abstract: The paper is about developing a solver for maximizing a real-valued function
of binary variables. The solver relies on an algorithm that estimates the
optimal objective-function value of instances from the underlying distribution
of objectives and their respective sub-instances. The training of the estimator
is based on an inequality that facilitates the use of the expected total
deviation from optimality conditions as a loss function rather than the
objective-function itself. Thus, it does not calculate values of policies, nor
does it rely on solved instances.

</details>


### [73] [Energy Loss Functions for Physical Systems](https://arxiv.org/abs/2511.02087)
*Sékou-Oumar Kaba,Kusha Sareen,Daniel Levy,Siamak Ravanbakhsh*

Main category: cs.LG

TL;DR: 提出了一种框架，将物理信息直接纳入损失函数，用于预测和生成建模任务。该框架通过假设数据样本处于近似能量景观的热平衡状态来得出能量损失函数，改进了传统目标如MSE，并在分子生成和自旋基态预测任务中取得了显著改善。


<details>
  <summary>Details</summary>
Motivation: 有效地利用系统的物理先验知识对于机器学习在科学领域的应用至关重要。以前的方法主要关注于在架构层面融合物理直觉。本文提出了一种新框架，直接让物理信息在损失函数中发挥作用，以提高预测和生成建模任务的效果。

Method: 通过假设每个数据样本处于近似能量景观的热平衡状态，导出了能量损失函数。使用逆KL散度和围绕数据的玻尔兹曼分布，获取了数据和模型预测之间的能量差异作为损失函数。这种视角将传统目标如MSE重新定性为基于能量的损失，但具有物理意义的能量。这种形式化的方式产生具有物理基础的损失函数，具有与有效配置更好的对齐的梯度，同时在架构上是无关紧要的，并且计算上是高效的。

Result: 实验结果显示，在分子生成和自旋基态预测任务中，这种方法比基线方法有了显著的进步。

Conclusion: 本文提出的能量损失函数框架有潜力改善各种物理系统的机器学习任务，特别是那些需要尊重物理对称性的重要情况。

Abstract: Effectively leveraging prior knowledge of a system's physics is crucial for
applications of machine learning to scientific domains. Previous approaches
mostly focused on incorporating physical insights at the architectural level.
In this paper, we propose a framework to leverage physical information directly
into the loss function for prediction and generative modeling tasks on systems
like molecules and spins. We derive energy loss functions assuming that each
data sample is in thermal equilibrium with respect to an approximate energy
landscape. By using the reverse KL divergence with a Boltzmann distribution
around the data, we obtain the loss as an energy difference between the data
and the model predictions. This perspective also recasts traditional objectives
like MSE as energy-based, but with a physically meaningless energy. In
contrast, our formulation yields physically grounded loss functions with
gradients that better align with valid configurations, while being
architecture-agnostic and computationally efficient. The energy loss functions
also inherently respect physical symmetries. We demonstrate our approach on
molecular generation and spin ground-state prediction and report significant
improvements over baselines.

</details>


### [74] [LLM Probing with Contrastive Eigenproblems: Improving Understanding and Applicability of CCS](https://arxiv.org/abs/2511.02089)
*Stefan F. Schouten,Peter Bloem*

Main category: cs.LG

TL;DR: 研究提出了一种新的探究大型语言模型内部激活表示二元特征的方法，称为相对对比一致性，并通过特征值问题重构了Contrast-Consistent Search (CCS)，提出了更自然的多变量扩展，这种方法不仅提高了对CCS的理解，而且为更广泛的探究和机制解释方法铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 该论文重新审视了Contrast-Consistent Search (CCS)方法，旨在澄清其机制并扩展其适用范围。当前的CCS方法存在部分未被完全理解的问题，而在本文中，作者强调了相对对比一致性的优化，认为这将是探究大型语言模型认知机制的关键。

Method: 研究将CCS重新构建为特征值问题，通过这种方式可以得到可解释的特征值，并能够自然地推广到多个变量，这可以更好地避免随机初始化问题，且为CCS理解提供了一个新层面。

Result: 实验证明了新方法与原始CCS相比能恢复类似的表现，但更能避免对随机初始化的敏感性，说明相对化对比一致性不仅能加深对CCS的理解，也为更广泛的探究和机制解释方法开辟了道路。

Conclusion: 研究得出了相对对比一致性对于提高对CCS的理解和更广泛的探究有效性的结论，推进了我们对以无监督方式探究大型语言模型内部结构的理解。

Abstract: Contrast-Consistent Search (CCS) is an unsupervised probing method able to
test whether large language models represent binary features, such as sentence
truth, in their internal activations. While CCS has shown promise, its two-term
objective has been only partially understood. In this work, we revisit CCS with
the aim of clarifying its mechanisms and extending its applicability. We argue
that what should be optimized for, is relative contrast consistency. Building
on this insight, we reformulate CCS as an eigenproblem, yielding closed-form
solutions with interpretable eigenvalues and natural extensions to multiple
variables. We evaluate these approaches across a range of datasets, finding
that they recover similar performance to CCS, while avoiding problems around
sensitivity to random initialization. Our results suggest that relativizing
contrast consistency not only improves our understanding of CCS but also opens
pathways for broader probing and mechanistic interpretability methods.

</details>


### [75] [Uncertainty Guided Online Ensemble for Non-stationary Data Streams in Fusion Science](https://arxiv.org/abs/2511.02092)
*Kishansingh Rajput,Malachi Schram,Brian Sammuli,Sen Lin*

Main category: cs.LG

TL;DR: 在线学习方法被应用于连续适应于漂移数据流的托罗伊德场线圈偏移预测，相比于静态模型，其误差减少了80%。一个基于不确定性引导的在线集成方法被提出，进一步提高了性能，分别比标准单模型在线学习减少了6%和10%的预测误差。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型在面对非稳态数据流时性能下降，本文旨在通过在线学习解决这一问题，并提出了基于不确定性引导的在线集成方法以进一步提高模型性能。

Method: 利用在线学习技术处理非稳态数据流，并通过基于深高斯过程近似算法的不确定性引导在线集成技术，提高了预测的准确性和可解释性。

Result: 在线学习方法使TF线圈偏移预测的误差减少了80%，而基于不确定性引导的在线集成方法进一步减少了6%和10%的预测误差，分别优于标准单模型在线学习。

Conclusion: 在线学习对维持模型在非稳态数据流中的性能至关重要，基于不确定性引导的在线集成方法能够进一步提高模型的性能，为决策者提供了更加准确的预测和不确定性的估计。

Abstract: Machine Learning (ML) is poised to play a pivotal role in the development and
operation of next-generation fusion devices. Fusion data shows non-stationary
behavior with distribution drifts, resulted by both experimental evolution and
machine wear-and-tear. ML models assume stationary distribution and fail to
maintain performance when encountered with such non-stationary data streams.
Online learning techniques have been leveraged in other domains, however it has
been largely unexplored for fusion applications. In this paper, we present an
application of online learning to continuously adapt to drifting data stream
for prediction of Toroidal Field (TF) coils deflection at the DIII-D fusion
facility. The results demonstrate that online learning is critical to maintain
ML model performance and reduces error by 80% compared to a static model.
Moreover, traditional online learning can suffer from short-term performance
degradation as ground truth is not available before making the predictions. As
such, we propose an uncertainty guided online ensemble method to further
improve the performance. The Deep Gaussian Process Approximation (DGPA)
technique is leveraged for calibrated uncertainty estimation and the
uncertainty values are then used to guide a meta-algorithm that produces
predictions based on an ensemble of learners trained on different horizon of
historical data. The DGPA also provides uncertainty estimation along with the
predictions for decision makers. The online ensemble and the proposed
uncertainty guided online ensemble reduces predictions error by about 6%, and
10% respectively over standard single model based online learning.

</details>


### [76] [Geometric Data Valuation via Leverage Scores](https://arxiv.org/abs/2511.02100)
*Rodrigo Mendoza-Smith*

Main category: cs.LG

TL;DR: 本文提出了一种基于统计杠杆分数的几何替代方法来计算数据点的重要性，该方法解决了Shapley数据估值在大规模数据集上计算不可行的问题。该方法满足Shapley估值的假设定理、有效性公理和对称性公理，并展示了与经典A-和D-最优设计标准的联系。实验表明，这样的采样方法可以有效地提高模型预测的准确性，同时无需访问梯度或后向传递信息。


<details>
  <summary>Details</summary>
Motivation: 现有的Shapley数据估值方法计算复杂度高，对于大规模数据集不可行，因此本文提出了一种基于统计杠杆分数的替代方法，以解决计算复杂度高的问题，并提高数据集选择和优化的有效性。

Method: 采用统计杠杆分数作为几何替代方法，以量化数据点在表示空间中的结构影响力，并证明这种方法满足Shapley估值的公理。进一步分析如何通过Ridge杠杆分数扩展这种方法以得到严格正的边际收益，同时证明这种方法可以改进训练参数和预测风险。实验采用主动学习实验来验证方法的有效性。

Result: 证明该方法满足Shapley估值的公理，同时能够改进训练参数和预测风险，并在实际实验中显示其表现优于传统的基准方法，且不需要访问梯度或其他复杂计算信息。

Conclusion: 本文提出了一种新颖有效的数据点重要性计算方法，并通过理论推导和实验验证了其对于提高数据集选择和优化的有效性。

Abstract: Shapley data valuation provides a principled, axiomatic framework for
assigning importance to individual datapoints, and has gained traction in
dataset curation, pruning, and pricing. However, it is a combinatorial measure
that requires evaluating marginal utility across all subsets of the data,
making it computationally infeasible at scale. We propose a geometric
alternative based on statistical leverage scores, which quantify each
datapoint's structural influence in the representation space by measuring how
much it extends the span of the dataset and contributes to the effective
dimensionality of the training problem. We show that our scores satisfy the
dummy, efficiency, and symmetry axioms of Shapley valuation and that extending
them to \emph{ridge leverage scores} yields strictly positive marginal gains
that connect naturally to classical A- and D-optimal design criteria. We
further show that training on a leverage-sampled subset produces a model whose
parameters and predictive risk are within $O(\varepsilon)$ of the full-data
optimum, thereby providing a rigorous link between data valuation and
downstream decision quality. Finally, we conduct an active learning experiment
in which we empirically demonstrate that ridge-leverage sampling outperforms
standard baselines without requiring access gradients or backward passes.

</details>


### [77] [Matrix Sensing with Kernel Optimal Loss: Robustness and Optimization Landscape](https://arxiv.org/abs/2511.02122)
*Xinyuan Song,Jiaye Teng,Ziye Ma*

Main category: cs.LG

TL;DR: 本文研究了非凸优化问题中的损失函数选择如何影响问题的鲁棒性和优化地形，通过分析带噪声的矩阵感应任务。介绍了在非高斯或重型尾噪声条件下，传统均方误差（MSE）损失的缺点，并提出了一种基于非参数回归的鲁棒损失函数。这种方法在高斯误差下与MSE等效，但在更广泛的情况下更加稳定。结果表明，新损失函数可以在各种噪声分布中提高模型鲁棒性和处理大规模噪声的能力。这项工作为如何通过改变损失函数来增强机器学习任务的鲁棒性提供了初步见解，为这一领域的研究提供了一个直观且广泛适用的分析框架。


<details>
  <summary>Details</summary>
Motivation: 传统的MSE损失函数在非高斯或重型尾噪声下表现不佳，因此研究一种适合更广泛噪声分布的鲁棒损失函数，以提高机器学习任务的鲁棒性及优化效率。具体目标为在考虑带噪声矩阵感应问题时，寻找并分析一个全面且稳定的损失函数，该函数能够处理高斯误差，并在更多噪声情况下保持稳定。

Method: 提出了一种基于核估计残差密度的非参数回归损失函数，替代传统MSE损失。该方法利用核估计的残差密度最大化估计对数似然。然后通过理论和实证分析新的损失函数如何塑造优化地形，具体分析了虚假局部极小值的受限制等距性质的上限。

Result: 实证和理论工作表明，新的损失函数表现优秀，尤其在大噪声环境下，具有较强的鲁棒性，能处理不同噪声分布。验证了通过采用新的损失形式可以增强模型的抗噪能力，提出了适用于广泛噪声分布的鲁棒损失函数。

Conclusion: 这项工作显示了通过简单地改变损失函数可以选择性地提高优化过程的鲁棒性和优化效率。通过分析非凸优化问题中损失函数的选择，为解决非高斯或重型尾噪声环境中的机器学习问题提供了初步但重要的见解，推广了鲁棒性理论的应用范围。

Abstract: In this paper we study how the choice of loss functions of non-convex
optimization problems affects their robustness and optimization landscape,
through the study of noisy matrix sensing. In traditional regression tasks,
mean squared error (MSE) loss is a common choice, but it can be unreliable for
non-Gaussian or heavy-tailed noise. To address this issue, we adopt a robust
loss based on nonparametric regression, which uses a kernel-based estimate of
the residual density and maximizes the estimated log-likelihood. This robust
formulation coincides with the MSE loss under Gaussian errors but remains
stable under more general settings. We further examine how this robust loss
reshapes the optimization landscape by analyzing the upper-bound of restricted
isometry property (RIP) constants for spurious local minima to disappear.
Through theoretical and empirical analysis, we show that this new loss excels
at handling large noise and remains robust across diverse noise distributions.
This work offers initial insights into enhancing the robustness of machine
learning tasks through simply changing the loss, guided by an intuitive and
broadly applicable analytical framework.

</details>


### [78] [Variance-Aware Feel-Good Thompson Sampling for Contextual Bandits](https://arxiv.org/abs/2511.02123)
*Xuheng Li,Quanquan Gu*

Main category: cs.LG

TL;DR: 该论文提出了一种新的Thompson采样算法FGTSVA，针对上下文关联的带隙问题，具有泛化的奖励函数和最优的遗憾界。该算法在大规模模型空间中实现了高效的性能。在上下文线性带隙问题中，其遗憾界与基于UCB的算法相匹配。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多集中在基于UCB的上下文带隙算法上，而以Thompson采样为代表的采样型带隙算法研究相对较少。此外，已有的带方差意识的Thompson采样算法仅限于线性奖励函数，且其遗憾界不是最优的。因此，本文旨在提出一种新的Thompson采样算法FGTSVA，它适用于通用奖励函数并具有最优遗憾界。

Method: 论文提出了一种新的带方差意识的Thompson采样算法FGTSVA，该算法通过扩展解耦系数来估计模型复杂度，实现对所有模型空间的高效探索和利用。算法在每个回合中使用解耦系数和各个回合的噪声方差进行采样决策，旨在实现最优的遗憾界。

Result: 该算法的遗憾界为$	ilde{O}(	ext{dc}	imes	ext{log}|	ext{F}|	imes	ext{Sum}(	ext{$	ext{σ}_t^2$})+	ext{dc})$，其中$|	ext{F}|$是模型空间大小，$	ext{T}$是回合总数，$	ext{$	ext{σ}_t^2$}$是第$	ext{t}$个回合的噪声方差。在上下文线性带隙问题中，算法的遗憾界与使用加权线性回归的UCB算法相匹配。

Conclusion: FGTSVA算法以其高效的性能和最优的遗憾界，展示了在上下文带隙问题中的强大潜力，特别适用于大规模模型空间中的带方差意识的决策问题。

Abstract: Variance-dependent regret bounds have received increasing attention in recent
studies on contextual bandits. However, most of these studies are focused on
upper confidence bound (UCB)-based bandit algorithms, while sampling based
bandit algorithms such as Thompson sampling are still understudied. The only
exception is the LinVDTS algorithm (Xu et al., 2023), which is limited to
linear reward function and its regret bound is not optimal with respect to the
model dimension. In this paper, we present FGTSVA, a variance-aware Thompson
Sampling algorithm for contextual bandits with general reward function with
optimal regret bound. At the core of our analysis is an extension of the
decoupling coefficient, a technique commonly used in the analysis of Feel-good
Thompson sampling (FGTS) that reflects the complexity of the model space. With
the new decoupling coefficient denoted by $\mathrm{dc}$, FGTS-VA achieves the
regret of
$\tilde{O}(\sqrt{\mathrm{dc}\cdot\log|\mathcal{F}|\sum_{t=1}^T\sigma_t^2}+\mathrm{dc})$,
where $|\mathcal{F}|$ is the size of the model space, $T$ is the total number
of rounds, and $\sigma_t^2$ is the subgaussian norm of the noise (e.g.,
variance when the noise is Gaussian) at round $t$. In the setting of contextual
linear bandits, the regret bound of FGTSVA matches that of UCB-based algorithms
using weighted linear regression (Zhou and Gu, 2022).

</details>


### [79] [Disentangling Causal Substructures for Interpretable and Generalizable Drug Synergy Prediction](https://arxiv.org/abs/2511.02146)
*Yi Luo,Haochen Zhao,Xiao Liang,Yiwei Liu,Yuye Zhang,Xinyu Li,Jianxin Wang*

Main category: cs.LG

TL;DR: 阐述了CausalDDS框架通过分解药物分子以识别因果关系和虚假子结构，提升了药物协同作用预测的准确性和可解释性，并通过条件干预机制和新的优化目标显著提高了模型性能，特别是在冷启动和出界分布设置中。该框架还确定了药物协同作用背后的关键子结构，加深了对药物组合在分子水平上的理解。


<details>
  <summary>Details</summary>
Motivation: 当前药物协同作用预测方法多数为黑盒预测指标，依赖于药物特性与结果之间的统计相关性。这导致模型对冗余特征敏感，并限制了其准确性和可解释性。因此，本研究提出CausalDDS框架来克服这一局限性，提升药物协同作用预测的准确性与可解释性。

Method: CausalDDS框架通过将药物分子分解为因果和虚假子结构两部分，使用因果子结构的表示来预测药物协同作用。此外，它引入了一个条件干预机制，并设定了一个基于充足性和独立性原则的新优化目标。

Result: 实验结果表明，CausalDDS框架在提升预测准确性与可解释性方面显著优于基线模型，尤其是在冷启动和出界分布情况中。更重要的是，CausalDDS能够明确识别出药物协同作用背后的最关键子结构，从而加深对药物组合在分子层面的理解。

Conclusion: CausalDDS展示了其作为预测药物协同作用及其促进药物发现的有效工具的巨大潜力。

Abstract: Drug synergy prediction is a critical task in the development of effective
combination therapies for complex diseases, including cancer. Although existing
methods have shown promising results, they often operate as black-box
predictors that rely predominantly on statistical correlations between drug
characteristics and results. To address this limitation, we propose CausalDDS,
a novel framework that disentangles drug molecules into causal and spurious
substructures, utilizing the causal substructure representations for predicting
drug synergy. By focusing on causal sub-structures, CausalDDS effectively
mitigates the impact of redundant features introduced by spurious
substructures, enhancing the accuracy and interpretability of the model. In
addition, CausalDDS employs a conditional intervention mechanism, where
interventions are conditioned on paired molecular structures, and introduces a
novel optimization objective guided by the principles of sufficiency and
independence. Extensive experiments demonstrate that our method outperforms
baseline models, particularly in cold start and out-of-distribution settings.
Besides, CausalDDS effectively identifies key substructures underlying drug
synergy, providing clear insights into how drug combinations work at the
molecular level. These results underscore the potential of CausalDDS as a
practical tool for predicting drug synergy and facilitating drug discovery.

</details>


### [80] [CFL: On the Use of Characteristic Function Loss for Domain Alignment in Machine Learning](https://arxiv.org/abs/2511.02148)
*Abdullah Almansour,Ozan Tonguz*

Main category: cs.LG

TL;DR: 本文提出使用特征函数（CF）作为一种频率域方法来量化解空间转移问题，并用于领域适应，特别是在高维空间中。这种方法被证明是强大的替代方案之一。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在实际部署时常常由于分布偏移（distribution shift）问题而性能不佳，尤其是在高风险应用中可能导致严重后果。现有的研究主要采用统计技术来量化分布偏移，本文的动机是寻找一种新的有效方法，即使用特征函数（CF）来解决该问题。

Method: 本文提出使用特征函数（CF）作为频率域方法来量化和解决分布偏移问题。特征函数能够有效地捕捉分布的统计特征，特别适用于高维空间，并且可以用于领域适应。这种方法与传统的统计方法相比，具有更高的准确性和更广泛的适用性。

Result: 研究结果显示，使用特征函数（CF）方法能够准确地量化分布偏移，并且在领域适应中表现出色，特别是对于高维空间的数据集。这种方法在解决分布偏移问题上提供了强大的工具，可以提高机器学习模型在实际应用中的性能和可靠性。

Conclusion: 本文提出的方法利用特征函数（CF）作为频率域方法，为量化和解决分布偏移问题提供了一个有力的工具。该方法相比于传统统计方法，更适合于高维空间的数据处理，能够提高机器学习模型在实际应用中的性能。

Abstract: Machine Learning (ML) models are extensively used in various applications due
to their significant advantages over traditional learning methods. However, the
developed ML models often underperform when deployed in the real world due to
the well-known distribution shift problem. This problem can lead to a
catastrophic outcomes when these decision-making systems have to operate in
high-risk applications. Many researchers have previously studied this problem
in ML, known as distribution shift problem, using statistical techniques (such
as Kullback-Leibler, Kolmogorov-Smirnov Test, Wasserstein distance, etc.) to
quantify the distribution shift. In this letter, we show that using
Characteristic Function (CF) as a frequency domain approach is a powerful
alternative for measuring the distribution shift in high-dimensional space and
for domain adaptation.

</details>


### [81] [ProtoTSNet: Interpretable Multivariate Time Series Classification With Prototypical Parts](https://arxiv.org/abs/2511.02152)
*Bartłomiej Małkus,Szymon Bobek,Grzegorz J. Nalepa*

Main category: cs.LG

TL;DR: 本文提出了ProtoTSNet，一种通过增强ProtoPNet架构来提高时间序列数据可解释性的分类方法。该方法通过使用修改后的卷积编码器（包括组卷积）来应对时间序列分析的挑战，并在UEA档案的30个多变量时间序列数据集上进行了测试，展示了其在可解释方法中最佳性能以及与不可解释和后验可解释方法的竞争性能


<details>
  <summary>Details</summary>
Motivation: 在工业和医疗等关键领域，需要既高精度又可解释的算法，以避免决策带来的重大后果。本文旨在提高时间序列数据的分类准确性与可解释性，以满足这些领域的需求

Method: 通过引入改进的卷积编码器来捕捉动态模式和处理不同的特征重要性，主要创新在于使用了包括组卷积的卷积编码器，并可在作为自动编码器的一部分进行预训练以量化特征的重要性

Result: 与现有的可解释和不可解释基准方法相比，通过广泛的评估和消融研究，ProtoTSNet在可解释的方法中展示出最佳性能，同时在性能与不可解释和后验可解释方法保持竞争力

Conclusion: ProtoTSNet提供了可解释的分类结果，便于领域专家理解，为时间序列数据的分类提供了一种新的方法

Abstract: Time series data is one of the most popular data modalities in critical
domains such as industry and medicine. The demand for algorithms that not only
exhibit high accuracy but also offer interpretability is crucial in such
fields, as decisions made there bear significant consequences. In this paper,
we present ProtoTSNet, a novel approach to interpretable classification of
multivariate time series data, through substantial enhancements to the
ProtoPNet architecture. Our method is tailored to overcome the unique
challenges of time series analysis, including capturing dynamic patterns and
handling varying feature significance. Central to our innovation is a modified
convolutional encoder utilizing group convolutions, pre-trainable as part of an
autoencoder and designed to preserve and quantify feature importance. We
evaluated our model on 30 multivariate time series datasets from the UEA
archive, comparing our approach with existing explainable methods as well as
non-explainable baselines. Through comprehensive evaluation and ablation
studies, we demonstrate that our approach achieves the best performance among
ante-hoc explainable methods while maintaining competitive performance with
non-explainable and post-hoc explainable approaches, providing interpretable
results accessible to domain experts.

</details>


### [82] [Tackling Incomplete Data in Air Quality Prediction: A Bayesian Deep Learning Framework for Uncertainty Quantification](https://arxiv.org/abs/2511.02175)
*Yuzhuang Pian,Taiyu Wang,Shiqi Zhang,Rui Xu,Yonghong Liu*

Main category: cs.LG

TL;DR: 提出了一种针对空气质量不可靠预测问题的解决方案，即基于通道门控学习单元的时空贝叶斯神经场（CGLUBNF）框架，它可以处理多尺度的空间依赖和季节性的时间动态，并通过贝叶斯推理进行参数不确定性优化，评估结果显示此模型在预测准确度和置信区间上比其他基准方法更优。


<details>
  <summary>Details</summary>
Motivation: 为了提供准确的空气质量预测，用于公共健康警报、暴露评估和排放控制，解决观测数据缺失问题，提高可靠推断和风险评估的能力，减少过度自信的外推。

Method: 使用傅里叶特征与图注意力编码器来捕捉多尺度的空间依赖和季节性的时间动态，并通过配置有可学习激活和门控残差连接的通道门控学习单元来自适应过滤和放大信息特征。借助贝叶斯推断联合优化预测分布和参数不确定性，生成点估计和校准的预测区间。

Result: 系统评估显示，与五个先进的基线相比，CGLUBNF达到更高的预测准确性并具有更锐利的置信区间。此外，它在多个预测地平线上也证明了鲁棒性，并分析了额外变量的贡献。

Conclusion: 此研究为可靠基于深度学习的时空预测奠定基础，特别是在存在不完整观察的新兴传感范式中，如真实世界的车载移动监测。

Abstract: Accurate air quality forecasts are vital for public health alerts, exposure
assessment, and emissions control. In practice, observational data are often
missing in varying proportions and patterns due to collection and transmission
issues. These incomplete spatiotemporal records impede reliable inference and
risk assessment and can lead to overconfident extrapolation. To address these
challenges, we propose an end to end framework, the channel gated learning unit
based spatiotemporal bayesian neural field (CGLUBNF). It uses Fourier features
with a graph attention encoder to capture multiscale spatial dependencies and
seasonal temporal dynamics. A channel gated learning unit, equipped with
learnable activations and gated residual connections, adaptively filters and
amplifies informative features. Bayesian inference jointly optimizes predictive
distributions and parameter uncertainty, producing point estimates and
calibrated prediction intervals. We conduct a systematic evaluation on two real
world datasets, covering four typical missing data patterns and comparing
against five state of the art baselines. CGLUBNF achieves superior prediction
accuracy and sharper confidence intervals. In addition, we further validate
robustness across multiple prediction horizons and analysis the contribution of
extraneous variables. This research lays a foundation for reliable deep
learning based spatio-temporal forecasting with incomplete observations in
emerging sensing paradigms, such as real world vehicle borne mobile monitoring.

</details>


### [83] [OmniField: Conditioned Neural Fields for Robust Multimodal Spatiotemporal Learning](https://arxiv.org/abs/2511.02205)
*Kevin Valencia,Thilina Balasooriya,Xihaier Luo,Shinjae Yoo,David Keetae Park*

Main category: cs.LG

TL;DR: OmniField 是一种连续性感知框架，用于学习连续的神经场并融合跨模态上下文，能够统一进行重建、插值、预测等操作，即使在传感器噪声严重的条件下，其性能也能保持在较高水平。


<details>
  <summary>Details</summary>
Motivation: 受限于实际实验数据中的跨模态测量稀疏、不规则、噪声多等问题，需要一种可以适应在训练和测试时任意子集的跨模态模型来提升数据可用性。此研究旨在提出一种既能处理这些问题又能实现统一的重建、插值、预测等功能的模型。

Method: OmniField 通过设计连续性感知的框架来学习受可用模式条件下的连续神经场，采用跨模态对话区块架构搭配迭代的跨模态改进来对齐信号并在解码器前进行统一处理，无需网格或替代预处理。

Result: 在受噪声严重模拟传感器的数据中，OmniField 的性能依然能够维持在良好水平，显示出对损坏测量的鲁棒性。与八个强大的多模态时空基线相比，OmniField 表现出了持续的优越性。

Conclusion: OmniField 是一种在处理稀疏、不规则、噪声多的模态测量中表现出色的模型，不仅能够处理这些问题，同时还能实现重建、插值、预测等统一功能，并且对于噪声和损坏测量有着良好的鲁棒性。

Abstract: Multimodal spatiotemporal learning on real-world experimental data is
constrained by two challenges: within-modality measurements are sparse,
irregular, and noisy (QA/QC artifacts) but cross-modally correlated; the set of
available modalities varies across space and time, shrinking the usable record
unless models can adapt to arbitrary subsets at train and test time. We propose
OmniField, a continuity-aware framework that learns a continuous neural field
conditioned on available modalities and iteratively fuses cross-modal context.
A multimodal crosstalk block architecture paired with iterative cross-modal
refinement aligns signals prior to the decoder, enabling unified
reconstruction, interpolation, forecasting, and cross-modal prediction without
gridding or surrogate preprocessing. Extensive evaluations show that OmniField
consistently outperforms eight strong multimodal spatiotemporal baselines.
Under heavy simulated sensor noise, performance remains close to clean-input
levels, highlighting robustness to corrupted measurements.

</details>


### [84] [Learning Interactive World Model for Object-Centric Reinforcement Learning](https://arxiv.org/abs/2511.02225)
*Fan Feng,Phillip Lippe,Sara Magliacane*

Main category: cs.LG

TL;DR: 介绍了Factored Interactive Object-Centric World Model(FIOC-WM)，一个能学习结构化表示物体及其交互的世界模型框架，提高了策略学习的样本效率及泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多数以对象为中心的强化学习方法将状态按照单独的对象进行分解，但是忽略了这些对象之间的交互。因此提出了FIOC-WM，一个统一的世界模型框架，能够学习到世界中物体及其交互的结构化表示。

Method: FIOC-WM首先通过预训练的视觉编码器从像素中学习出对象中心的潜在表示和相互作用的结构。之后将任务分解为交互的可组合基础，并训练了分层策略，选取相互作用的类型和顺序以及执行它们。

Result: 在模拟的机器人和展示AI基准上，FIOC-WM提高了策略学习的样本效率和泛化能力。实验表明，显式的模块化交互学习对于鲁棒控制至关重要。

Conclusion: 通过FIOC-WM的实验结果表明，显式的模块化交互对于模型的鲁棒控制和提升样本效率具有重要意义。

Abstract: Agents that understand objects and their interactions can learn policies that
are more robust and transferable. However, most object-centric RL methods
factor state by individual objects while leaving interactions implicit. We
introduce the Factored Interactive Object-Centric World Model (FIOC-WM), a
unified framework that learns structured representations of both objects and
their interactions within a world model. FIOC-WM captures environment dynamics
with disentangled and modular representations of object interactions, improving
sample efficiency and generalization for policy learning. Concretely, FIOC-WM
first learns object-centric latents and an interaction structure directly from
pixels, leveraging pre-trained vision encoders. The learned world model then
decomposes tasks into composable interaction primitives, and a hierarchical
policy is trained on top: a high level selects the type and order of
interactions, while a low level executes them. On simulated robotic and
embodied-AI benchmarks, FIOC-WM improves policy-learning sample efficiency and
generalization over world-model baselines, indicating that explicit, modular
interaction learning is crucial for robust control.

</details>


### [85] [Opportunistic Expert Activation: Batch-Aware Expert Routing for Faster Decode Without Retraining](https://arxiv.org/abs/2511.02237)
*Costin-Andrei Oncescu,Qingyang Wu,Wai Tong Chung,Robert Wu,Bryan Gopal,Junxiong Wang,Tri Dao,Ben Athiwaratkun*

Main category: cs.LG

TL;DR: 本文介绍了一种动态重新路由token-to-expert映射的框架，以减少MoE模型的解码延迟，同时保持相似的质量。在Qwen3-30B和Qwen3-235B模型上进行实验，结果表明，与原有的方法相比，解码延迟分别降低了39％和15％，而没有显著降低准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地采用混合专家架构，这种架构导致在自回归生成过程中，即使在中等批次大小下也会进入内存受限状态，这是由于平均专家负载增长速度慢于等效的密集前馈层。我们的动机是为此类模型减少解码延迟，同时保持较高的质量。

Method: 提出了一个动态重路由框架，通过使得令牌占据已在内存中加载的专家（这些专家是因为对同一批次内的其他令牌至关重要而加载的），来降低令牌激活的专家数量，因此也降低了解码延迟。实验是在Qwen3-30B和Qwen3-235B模型上进行的，批量大小为16。结果表明，我们的方法在不显著降低准确性的情况下，显著降低了模型的解码延迟。

Result: 实验结果表明，与原有的方法相比，我们提出的方法在Qwen3-30B和Qwen3-235B模型上的解码延迟分别减少了39％和15％，且没有统计显著性地影响准确性。这表明我们的方法有效地降低了MoE层的解码延迟。

Conclusion: 通过批意识路由技术，动态重新路由token-to-expert映射，有效降低了MoE模型的解码延迟，提高了模型处理速度和效率，且没有显著影响模型输出质量。

Abstract: An increasing number of LLMs employ Mixture-of-Experts (MoE) architectures
where the feed-forward layer is replaced by a pool of experts and each token
only activates a small subset of them. During autoregressive generation, these
models often enter a memory-bound regime even for moderate batch sizes because
the average expert load grows more slowly than in an equivalent dense
feedforward layer. Consequently, MoE latency is governed by the number of
activated experts. We introduce a framework for dynamically re-routing
token-to-expert mapping to lower this number (and thus, the decode latency)
while preserving a comparable quality. Our best results use a batch-aware
routing that works by having tokens piggyback experts that have already been
loaded into memory due to being crucial to other tokens within the same batch.
Empirically, we evaluate our method on the Qwen3-30B and Qwen3-235B models with
a batch size of $16$. Without any statistically significant loss in accuracy,
our approach achieves latency reductions of $39\%$ and $15\%$ in the MoE layer
decode latency, respectively.

</details>


### [86] [Probabilistic Graph Cuts](https://arxiv.org/abs/2511.02272)
*Ayoub Ghriss*

Main category: cs.LG

TL;DR: 该论文提出了一种统一的概率框架，用于覆盖包括归一化割在内的宽泛的图割类型，提供了严格的数值稳定的图分区基础，可以进行可微分的图分区，适用于广泛的聚类和对比学习目标。


<details>
  <summary>Details</summary>
Motivation: 当前工作的主要动机是提供一种可微分的方法来替代传统的图割和谱聚类方法，同时解决现有研究中缺乏一般性理论保证和原理性梯度的问题。

Method: 该论文通过概率松弛和紧致的解析上界，提出了一种统一的框架来处理包括归一化割在内的各类图割。该框架使用积分表示和高斯超几何函数来提供数值稳定性的基础，并具有封闭形式的前向和反向传播。

Result: 结果表明，论文中提出的方法可以提供严格的数值稳定性基础，适用于可微分的图分区，使大规模的聚类和对比学习任务成为可能。

Conclusion: 该研究提供了一种新颖的概率框架，用于处理复杂的图分割任务，不仅具有理论上的意义，而且在实际应用中也有广泛的作用。

Abstract: Probabilistic relaxations of graph cuts offer a differentiable alternative to
spectral clustering, enabling end-to-end and online learning without
eigendecompositions, yet prior work centered on RatioCut and lacked general
guarantees and principled gradients. We present a unified probabilistic
framework that covers a wide class of cuts, including Normalized Cut. Our
framework provides tight analytic upper bounds on expected discrete cuts via
integral representations and Gauss hypergeometric functions with closed-form
forward and backward. Together, these results deliver a rigorous, numerically
stable foundation for scalable, differentiable graph partitioning covering a
wide range of clustering and contrastive learning objectives.

</details>


### [87] [Gradient-Variation Online Adaptivity for Accelerated Optimization with Hölder Smoothness](https://arxiv.org/abs/2511.02276)
*Yuheng Zhao,Yu-Hu Yan,Kfir Yehuda Levy,Peng Zhao*

Main category: cs.LG

TL;DR: 研究通过在线学习探索Hölder平滑函数对离线优化的影响，开发了一种无需事先知道平滑参数的算法，该算法在线转离线后可以实现最优的普遍方法。在解决离线强凸优化问题时，通过集成在线自适应和检测过程，首次实现了加速收敛和平滑与非平滑情况下的近最优收敛的统一方法。


<details>
  <summary>Details</summary>
Motivation: 探讨Hölder平滑函数在线学习对离线优化的影响，提出一种基于梯度变动的在线学习算法，无需事先知道平滑参数，且在线转离线后可实现最优普遍方法，特别是在离线强凸优化中，首次提出实现加速收敛和平滑与非平滑情况下的近最优收敛的统一方法。

Method: 通过设计针对(strongly)凸在线函数的梯度变动在线学习算法，进一步实现了无需事先知到Hölder平滑性参数的自适应，通过对在线学习的离线转化，实现了最优的普遍方法，特别是在解决离线强凸优化时，整合在线自适应与检测供应过程实现了加速平滑性收敛与非平滑情况下的近最佳收敛的统一方法。

Result: 开发出了无需事先知道Hölder平滑性参数的梯度变动在线学习算法，通过在线转离线可实现最优普遍方法，特别是在离线强凸优化上，通过检测结合的在线自适应过程实现了平滑情况下的加速收敛和平滑与非平滑情况下的近最优收敛的统一方法。

Conclusion: 通过研究Hölder平滑函数的在线学习，为离线优化提供了新的视角和方法，不仅解决了离线优化的问题，还首次实现了平滑与非平滑情况下的近最优收敛的统一方法。

Abstract: Smoothness is known to be crucial for acceleration in offline optimization,
and for gradient-variation regret minimization in online learning.
Interestingly, these two problems are actually closely connected -- accelerated
optimization can be understood through the lens of gradient-variation online
learning. In this paper, we investigate online learning with H\"older smooth
functions, a general class encompassing both smooth and non-smooth (Lipschitz)
functions, and explore its implications for offline optimization. For
(strongly) convex online functions, we design the corresponding
gradient-variation online learning algorithm whose regret smoothly interpolates
between the optimal guarantees in smooth and non-smooth regimes. Notably, our
algorithms do not require prior knowledge of the H\"older smoothness parameter,
exhibiting strong adaptivity over existing methods. Through online-to-batch
conversion, this gradient-variation online adaptivity yields an optimal
universal method for stochastic convex optimization under H\"older smoothness.
However, achieving universality in offline strongly convex optimization is more
challenging. We address this by integrating online adaptivity with a
detection-based guess-and-check procedure, which, for the first time, yields a
universal offline method that achieves accelerated convergence in the smooth
regime while maintaining near-optimal convergence in the non-smooth one.

</details>


### [88] [Federated Quantum Kernel Learning for Anomaly Detection in Multivariate IoT Time-Series](https://arxiv.org/abs/2511.02301)
*Kuan-Cheng Chen,Samuel Yen-Chi Chen,Chen-Yu Liu,Kin K. Leung*

Main category: cs.LG

TL;DR: 提出了一个联邦量子核学习框架（FQKL），利用量子特征映射和联邦聚合进行分布式、隐私保护的物联网异常检测，实验结果表明相比经典联邦方法，FQKL在捕获复杂时间相关性方面具有更好的泛化性能，并显著降低了通信开销。


<details>
  <summary>Details</summary>
Motivation: 传统的联邦学习方法在处理高度非线性的决策边界和不平衡的异常分布时存在困难，为此提出一个融合量子特征映射与联邦聚合的FQKL框架，用以解决工业物联网系统中的异常检测挑战。该框架适用于数据分布不均、隐私保护和通信效率要求高的场景。

Method: FQKL框架允许边缘节点使用参数化量子电路计算压缩后的核统计量，并只将这些摘要与中心服务器共享，中心服务器构建全局Gram矩阵并训练决策函数。这种方式在分布式、保护隐私的同时又提高了检测性能。

Result: 实验表明，FQKL在捕获复杂时间相关性方面的泛化性能优于经典联邦方法，同时显著降低通信开销，展示了量子核在联邦学习中的潜力。

Conclusion: FQKL框架为下一代物联网基础设施提供一种新的可能，有助于实现规模更大、更稳定、量子增强的智能系统。

Abstract: The rapid growth of industrial Internet of Things (IIoT) systems has created
new challenges for anomaly detection in high-dimensional, multivariate
time-series, where privacy, scalability, and communication efficiency are
critical. Classical federated learning approaches mitigate privacy concerns by
enabling decentralized training, but they often struggle with highly non-linear
decision boundaries and imbalanced anomaly distributions. To address this gap,
we propose a Federated Quantum Kernel Learning (FQKL) framework that integrates
quantum feature maps with federated aggregation to enable distributed,
privacy-preserving anomaly detection across heterogeneous IoT networks. In our
design, quantum edge nodes locally compute compressed kernel statistics using
parameterized quantum circuits and share only these summaries with a central
server, which constructs a global Gram matrix and trains a decision function
(e.g., Fed-QSVM). Experimental results on synthetic IIoT benchmarks demonstrate
that FQKL achieves superior generalization in capturing complex temporal
correlations compared to classical federated baselines, while significantly
reducing communication overhead. This work highlights the promise of quantum
kernels in federated settings, advancing the path toward scalable, robust, and
quantum-enhanced intelligence for next-generation IoT infrastructures.

</details>


### [89] [FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error](https://arxiv.org/abs/2511.02302)
*Fengjuan Wang,Zhiyi Su,Xingzhu Hu,Cheng Wang,Mou Sun*

Main category: cs.LG

TL;DR: 提出了FP8-Flow-MoE，一种FP8训练配方，通过使用量化一致的FP8为中心的数据流，带有感知缩放的转置和融合的FP8操作，从而提高吞吐量并减少内存使用。在671B参数的MoE模型上，与BF16和简化的FP8基准相比，FP8-Flow-MoE提高了21%的吞吐量，同时保持了数值稳定性。该方法适用于TransformerEngine和Megatron-LM，计划开源。


<details>
  <summary>Details</summary>
Motivation: 训练大规模MoE模型在计算和内存方面的成本很高，低精度训练虽有望加速和减少内存使用，但现存的低精度数据流仍有偏差，而完全使用FP8又会导致精度损失。因此，需要一种更高效、更稳定的FP8训练方案来解决这些问题。

Method: 提出了一种新的FP8训练方案FP8-Flow-MoE，它利用了一种量化一致的FP8数据流，并实现了一个缩放感知的转置和融合的FP8操作，从而大幅度减少显式转换操作，提高计算效率。

Result: 实验结果显示，FP8-Flow-MoE在671B参数的模型上表现出高于21%的吞吐量和减少的约16.5GB每GPU的内存使用，同时保持了数值稳定性。该方法与两种低精度训练基准相比，展示了显著的性能优势。

Conclusion: FP8-Flow-MoE提供了一种新的、高效的低精度训练方案，特别适用于大规模的MoE模型训练。该方法不仅提高了训练效率，同时也降低了硬件资源的需求，提高了模型开发的可持续性。

Abstract: Training large Mixture-of-Experts (MoE) models remains computationally
prohibitive due to their extreme compute and memory demands. Although
low-precision training promises to accelerate computation and reduce memory
footprint, existing implementations still rely on BF16-dominated dataflows with
frequent quantize-dequantize (Q/DQ) conversions. These redundant casts erode
much of FP8's theoretical efficiency. However, naively removing these casts by
keeping dataflows entirely in FP8 introduces double quantization error: tensors
quantized along different dimensions accumulate inconsistent scaling factors,
degrading numerical stability.
  We propose FP8-Flow-MoE, an FP8 training recipe featuring a
quantization-consistent FP8-centric dataflow with a scaling-aware transpose and
fused FP8 operators that streamline computation and eliminate explicit cast
operations from 12 to 2. Evaluations on a 671B-parameter MoE model demonstrate
up to 21\% higher throughput and 16.5 GB lower memory usage per GPU compared to
BF16 and na\"ive FP8 baselines, while maintaining stable convergence. We
provide a plug-and-play FP8 recipe compatible with TransformerEngine and
Megatron-LM, which will be open-sourced soon.

</details>


### [90] [The Sequential Edge: Inverse-Entropy Voting Beats Parallel Self-Consistency at Matched Compute](https://arxiv.org/abs/2511.02309)
*Aman Sharma,Paras Chopra*

Main category: cs.LG

TL;DR: 在相同代币预算和计算资源下，迭代增强的串行扩展方法比并行自一致性方法在95.6%的配置中表现更优，最高可提升46.7%的准确率。此外，提出了一种新的训练自由方法——逆熵加权投票，显著提高了串行扩展的准确率，证明串行强化方法是最佳测试时间扩展策略。此研究挑战了以并行推理为主导的传统思想，并提出需要进行推理优化方法的范式转变。


<details>
  <summary>Details</summary>
Motivation: 研究在相同的代币预算和计算资源条件下，串行扩展是否比并行自一致性方法表现更优，进而探索更优的测试时间扩展策略。

Method: 通过跨5个最先进开源模型以及3个挑战性推理基准的全面评估，对比并行自一致性与建立在过去尝试之上的迭代增强串行方法的性能；进一步引入一种无需训练的新方法——逆熵加权投票，来增强串行扩展方法的准确率。

Result: 串行扩展方法在95.6%的配置中都优于并行自一致性方法，尤其是交互式文本任务上，准确率提升高达46.7%；并且逆熵加权投票法进一步提升串行方法的表现，成为最佳的测试时间扩展策略。

Conclusion: 研究结果挑战了现有的并行推理正统方法，证明了串行强化测试方法是更为稳健和适用的方式，需要对推理优化策略进行重新审视和转变。

Abstract: We revisit test-time scaling for language model reasoning and ask a
fundamental question: at equal token budget and compute, is it better to run
multiple independent chains in parallel, or to run fewer chains that
iteratively refine through sequential steps? Through comprehensive evaluation
across 5 state-of-the-art open source models and 3 challenging reasoning
benchmarks, we find that sequential scaling where chains explicitly build upon
previous attempts consistently outperforms the dominant parallel
self-consistency paradigm in 95.6% of configurations with gains in accuracy
upto 46.7%. Further, we introduce inverse-entropy weighted voting, a novel
training-free method to further boost the accuracy of sequential scaling. By
weighing answers in proportion to the inverse entropy of their reasoning
chains, we increase our success rate over parallel majority and establish it as
the optimal test-time scaling strategy. Our findings fundamentally challenge
the parallel reasoning orthodoxy that has dominated test-time scaling since
Wang et al.'s self-consistency decoding (Wang et al., 2022), positioning
sequential refinement as the robust default for modern LLM reasoning and
necessitating a paradigm shift in how we approach inference-time optimization.

</details>


### [91] [Large-scale automatic carbon ion treatment planning for head and neck cancers via parallel multi-agent reinforcement learning](https://arxiv.org/abs/2511.02314)
*Jueye Zhang,Chao Yang,Youfang Lai,Kai-Wen Li,Wenting Yan,Yunzhou Xia,Haimei Zhang,Jingjing Zhou,Gen Yang,Chen Lin,Tian Li,Yibao Zhang*

Main category: cs.LG

TL;DR: 提出了一个可扩展的多智能体强化学习框架来优化强度调控碳离子疗法中的多个治疗规划参数，生成的治疗计划在多个关键器官保护方面优于手动计划，并达到了与专家手动计划相当或更好的结果分数。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有深度学习和强化学习方法在治疗计划参数优化中的限制，新方法旨在加快和扩大复杂TPP搜索空间的探索任务，同时提高器官保护效果。

Method: 采用基于中心式训练和分散式执行的QMIX架构，同时引入双重DQN、对分DQN和循环编码（DRQN）以稳定学习过程。使用历史剂量体积直方图向量作为状态输入，并设计了一个绝对、基于临床知识的分段奖励，增强了搜索效率，并通过同步多进程工作系统与治疗计划系统进行交互。

Result: 该方法在头部和颈部癌症治疗中优化的TPP取得了与人工设置相比相当或更好的计划分数，并在多个关键器官保存方面取得了显著改善。

Conclusion: 创新的学习框架通过与治疗计划系统的直接交互，成功地生成了临床可比的高强度调控碳离子治疗计划，显著改善了器官保护效果。

Abstract: Head-and-neck cancer (HNC) planning is difficult because multiple critical
organs-at-risk (OARs) are close to complex targets. Intensity-modulated
carbon-ion therapy (IMCT) offers superior dose conformity and OAR sparing but
remains slow due to relative biological effectiveness (RBE) modeling, leading
to laborious, experience-based, and often suboptimal tuning of many
treatment-planning parameters (TPPs). Recent deep learning (DL) methods are
limited by data bias and plan feasibility, while reinforcement learning (RL)
struggles to efficiently explore the exponentially large TPP search space. We
propose a scalable multi-agent RL (MARL) framework for parallel tuning of 45
TPPs in IMCT. It uses a centralized-training decentralized-execution (CTDE)
QMIX backbone with Double DQN, Dueling DQN, and recurrent encoding (DRQN) for
stable learning in a high-dimensional, non-stationary environment. To enhance
efficiency, we (1) use compact historical DVH vectors as state inputs, (2)
apply a linear action-to-value transform mapping small discrete actions to
uniform parameter adjustments, and (3) design an absolute, clinically informed
piecewise reward aligned with plan scores. A synchronous multi-process worker
system interfaces with the PHOENIX TPS for parallel optimization and
accelerated data collection. On a head-and-neck dataset (10 training, 10
testing), the method tuned 45 parameters simultaneously and produced plans
comparable to or better than expert manual ones (relative plan score: RL
$85.93\pm7.85%$ vs Manual $85.02\pm6.92%$), with significant (p-value $<$ 0.05)
improvements for five OARs. The framework efficiently explores high-dimensional
TPP spaces and generates clinically competitive IMCT plans through direct TPS
interaction, notably improving OAR sparing.

</details>


### [92] [RoME: Domain-Robust Mixture-of-Experts for MILP Solution Prediction across Domains](https://arxiv.org/abs/2511.02331)
*Tianle Pu,Zijie Geng,Haoyang Liu,Shixuan Liu,Jie Wang,Li Zeng,Chao Chen,Changjun Fan*

Main category: cs.LG

TL;DR: 提出了RoME框架，用于跨域预测MILP解。RoME利用任务嵌入和分布鲁棒优化策略，并且模型单域训练效果有显著提升，甚至在零样本测试上实现了实际性能的提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多是在单一领域进行开发和测试，限制了其泛化能力，限制了它们构建可扩展、通用的基于学习的求解器的能力。因此，本研究的动机是通过构建一个跨域鲁棒的模型来克服这一局限性，提高模型的泛化能力。

Method: 介绍了RoME框架，该框架利用任务嵌入和分布鲁棒优化策略进行模型训练，包括跨域和单域两个层次的优化策略, 以增强模型的泛化能力和局部鲁棒性。

Result: 单域训练的RoME模型在零样本测试上实现了真实世界实例的实际性能提升，相比现有方法有更好的泛化能力。具体而言，单域训练的RoME模型在三个领域上进行训练，评估结果能覆盖五种不同的领域时，总体性能提升了67.7%。

Conclusion: 研究提出了一种跨域鲁棒的RoME模型，能够显著提高MILP问题的求解效率和泛化能力，增强了基于学习的求解器在实际应用中的有效性和可扩展性。

Abstract: Mixed-Integer Linear Programming (MILP) is a fundamental and powerful
framework for modeling complex optimization problems across diverse domains.
Recently, learning-based methods have shown great promise in accelerating MILP
solvers by predicting high-quality solutions. However, most existing approaches
are developed and evaluated in single-domain settings, limiting their ability
to generalize to unseen problem distributions. This limitation poses a major
obstacle to building scalable and general-purpose learning-based solvers. To
address this challenge, we introduce RoME, a domain-Robust Mixture-of-Experts
framework for predicting MILP solutions across domains. RoME dynamically routes
problem instances to specialized experts based on learned task embeddings. The
model is trained using a two-level distributionally robust optimization
strategy: inter-domain to mitigate global shifts across domains, and
intra-domain to enhance local robustness by introducing perturbations on task
embeddings. We reveal that cross-domain training not only enhances the model's
generalization capability to unseen domains but also improves performance
within each individual domain by encouraging the model to capture more general
intrinsic combinatorial patterns. Specifically, a single RoME model trained on
three domains achieves an average improvement of 67.7% then evaluated on five
diverse domains. We further test the pretrained model on MIPLIB in a zero-shot
setting, demonstrating its ability to deliver measurable performance gains on
challenging real-world instances where existing learning-based approaches often
struggle to generalize.

</details>


### [93] [Human-Machine Ritual: Synergic Performance through Real-Time Motion Recognition](https://arxiv.org/abs/2511.02351)
*Zhuodi Cai,Ziyu Xu,Juan Pampin*

Main category: cs.LG

TL;DR: 介绍了一种轻量级、实时的动作识别系统，通过穿戴式IMU传感器数据、MiniRocket时间序列分类和响应式多媒体控制，实现了协同的人机性能。


<details>
  <summary>Details</summary>
Motivation: 旨在通过将舞蹈特定动作映射到声音，通过体感记忆和关联，提出了一种替代的人机协作方法，这种设计保存了表演身体的表现力，同时利用机器学习进行关注观察和响应性。

Method: 方法包括使用穿戴式IMU传感器数据、MiniRocket时间序列分类技术以及响应式多媒体控制技术，来实现实时的人机协同性能。该系统使舞蹈动作能够映射到声音，从而实现了人机协同的深度交互。

Result: 该系统能够以小于50毫秒的延迟进行高精度分类，展示了在创意、教育和现场表演环境中将舞蹈专家的机器集成的可复制框架的可靠性。

Conclusion: 提出的人机协作方法保持了表演身体的表现力，同时通过机器学习提供了对表演者的关注和响应性，这种系统适用于同时具有创意、教育和现场表演价值的人机交互环境。

Abstract: We introduce a lightweight, real-time motion recognition system that enables
synergic human-machine performance through wearable IMU sensor data, MiniRocket
time-series classification, and responsive multimedia control. By mapping
dancer-specific movement to sound through somatic memory and association, we
propose an alternative approach to human-machine collaboration, one that
preserves the expressive depth of the performing body while leveraging machine
learning for attentive observation and responsiveness. We demonstrate that this
human-centered design reliably supports high accuracy classification (<50 ms
latency), offering a replicable framework to integrate dance-literate machines
into creative, educational, and live performance contexts.

</details>


### [94] [Evolving Graph Learning for Out-of-Distribution Generalization in Non-stationary Environments](https://arxiv.org/abs/2511.02354)
*Qingyun Sun,Jiayi Luo,Haonan Yuan,Xingcheng Fu,Hao Peng,Jianxin Li,Philip S. Yu*

Main category: cs.LG

TL;DR: 本文提出了一种新的Evolving Graph Learning框架（EvoOOD），旨在通过环境感知的不变模式识别来解决动态图下的OOD泛化问题。该框架包括一个环境序列变分自动编码器，用于建模环境演化并推断潜在的环境分布，进而设计环境感知的不变模式识别机制，最终通过个体节点的细粒度因果干预来进行OOD预测。实验结果表明EvoOOD在真实的和合成的动态数据集下，在分布转移的情况下表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有GNN在动态图中面对分布转移时泛化能力不足，尤其是在不断变化的环境中，需要研究动态图ODD泛化问题。

Method: 设计了环境序列变分自动编码器来建模环境演化和推断环境分布，并提出了环境感知的不变模式识别机制来应对环境的多样性。同时，通过个体节点的细粒度因果干预来实现OOD预测任务。

Result: 在真实世界和合成数据集上，实验结果表明EvoOOD在分布转移的情况下具有优越性能。

Conclusion: EvoOOD是首个从环境演化的角度研究动态图OOD泛化问题的尝试，展示了在不断变化的环境中解决OOD问题的有效性。

Abstract: Graph neural networks have shown remarkable success in exploiting the spatial
and temporal patterns on dynamic graphs. However, existing GNNs exhibit poor
generalization ability under distribution shifts, which is inevitable in
dynamic scenarios. As dynamic graph generation progresses amid evolving latent
non-stationary environments, it is imperative to explore their effects on
out-of-distribution (OOD) generalization. This paper proposes a novel Evolving
Graph Learning framework for OOD generalization (EvoOOD) by environment-aware
invariant pattern recognition. Specifically, we first design an environment
sequential variational auto-encoder to model environment evolution and infer
the underlying environment distribution. Then, we introduce a mechanism for
environment-aware invariant pattern recognition, tailored to address
environmental diversification through inferred distributions. Finally, we
conduct fine-grained causal interventions on individual nodes using a mixture
of instantiated environment samples. This approach helps to distinguish
spatio-temporal invariant patterns for OOD prediction, especially in
non-stationary environments. Experimental results demonstrate the superiority
of EvoGOOD on both real-world and synthetic dynamic datasets under distribution
shifts. To the best of our knowledge, it is the first attempt to study the
dynamic graph OOD generalization problem from the environment evolution
perspective.

</details>


### [95] [LUMA-RAG: Lifelong Multimodal Agents with Provably Stable Streaming Alignment](https://arxiv.org/abs/2511.02371)
*Rohan Wandre,Yash Gajewar,Namrata Patel,Vivek Dhalkari*

Main category: cs.LG

TL;DR: LUMA-RAG 是一个多模态持续学习框架，解决了多模态环境下索引更新和多模态语义一致性的问题。实验表明其在文本到图像检索、产品量化卸载和音频到图像排名等方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着知识库从静态转向持续的多模态流，维护索引的新鲜度和多模态语义一致性成为挑战。LUMA-RAG 旨在解决这些问题，理解并保持跨模态下的语义一致性，同时控制由于索引更新而导致的漂移和量化误差。

Method: LUMA-RAG 包含三个创新点：(i) 动态管理多级存储系统，通过严格内存量预算从热的 HNSW 层溢出嵌入到压缩的 IVFPQ 层；(ii) 持续的 CLAP->CLIP 对齐桥，通过增量正交 Procrustes 更新维护跨模态一致性；(iii) 稳定性感知的检索遥测，通过联合绑定漂移和量化误差提供安全保证。

Result: 实验表明，LUMA-RAG 能够实现高质量的文本到图像检索，即使在量化卸载情况下也能表现良好，并且可以提供稳定的音频到图像排名。具体数字表示有 Recall@10=0.94 和 Safe@1=1.0。

Conclusion: LUMA-RAG 通过管理多级存储系统、保持跨模态一致性和稳定性感知的检索遥测提供了一种有效的多模态 RAG 系统解决方案。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as the dominant paradigm for
grounding large language model outputs in verifiable evidence. However, as
modern AI agents transition from static knowledge bases to continuous
multimodal streams encompassing text, images, video, and audio, two critical
challenges arise: maintaining index freshness without prohibitive re-indexing
costs, and preserving cross-modal semantic consistency across heterogeneous
embedding spaces. We present LUMA-RAG, a lifelong multimodal agent architecture
featuring three key innovations: (i) a streaming, multi-tier memory system that
dynamically spills embeddings from a hot HNSW tier to a compressed IVFPQ tier
under strict memory budgets; (ii) a streaming CLAP->CLIP alignment bridge that
maintains cross-modal consistency through incremental orthogonal Procrustes
updates; and (iii) stability-aware retrieval telemetry providing Safe@k
guarantees by jointly bounding alignment drift and quantization error.
Experiments demonstrate robust text-to-image retrieval (Recall@10 = 0.94),
graceful performance degradation under product quantization offloading, and
provably stable audio-to-image rankings (Safe@1 = 1.0), establishing LUMA-RAG
as a practical framework for production multimodal RAG systems.

</details>


### [96] [Improving Unlearning with Model Updates Probably Aligned with Gradients](https://arxiv.org/abs/2511.02435)
*Virgile Dine,Teddy Furon,Charly Faure*

Main category: cs.LG

TL;DR: 该论文将机器遗忘问题定义为一个约束优化问题，并引入了可行更新的概念，即在不影响初始模型效用的前提下，有助于遗忘的模型参数更新方向。这种设计基于掩码技术，仔细选择模型参数，并考虑到梯度估计噪声，以提供统计保证，从而推导出局部可行更新。该技术可以作为任何一阶近似遗忘方法的附加组件使用，并通过计算机视觉分类器的实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是解决机器学习模型在忘记特定数据时的效用退化问题，这通常发生在需要遵守隐私或合规性要求时。作者希望提出一种新的方法，可以在不显著降低模型效用的情况下，使模型遗忘特定的数据。

Method: 论文提出了一个基于掩码技术（即选择特定模型参数进行更新）的方法，这种方法可以作为一个附加组件，与任何一阶近似遗忘方法结合使用。它还可以通过考虑梯度估计噪声来提供统计保证，从而推导出局部可行更新。这一方法的创新在于既保证了模型效用不受显著影响，又能有效地使模型忘记特定数据。

Result: 实验结果表明，所提出的方法在不影响计算机视觉分类器整体性能的情况下，能够有效执行机器遗忘操作（即移除特定数据后的再训练）操作。相比其他方法，该方法表现出更好的效用保持性能。

Conclusion: 结论是，将机器遗忘表述为一个约束优化问题，并引入可行更新机制，可以帮助机器学习模型在忘记特定数据时保留较好的整体效用。该方法通过选择适当的模型参数（基于掩码技术）和利用统计方法处理梯度估计噪声来实现这一目标，与现有的近似遗忘方法相比具有明显的优势。

Abstract: We formulate the machine unlearning problem as a general constrained
optimization problem. It unifies the first-order methods from the approximate
machine unlearning literature. This paper then introduces the concept of
feasible updates as the model's parameter update directions that help with
unlearning while not degrading the utility of the initial model. Our design of
feasible updates is based on masking, \ie\ a careful selection of the model's
parameters worth updating. It also takes into account the estimation noise of
the gradients when processing each batch of data to offer a statistical
guarantee to derive locally feasible updates. The technique can be plugged in,
as an add-on, to any first-order approximate unlearning methods. Experiments
with computer vision classifiers validate this approach.

</details>


### [97] [SKGE: Spherical Knowledge Graph Embedding with Geometric Regularization](https://arxiv.org/abs/2511.02460)
*Xuan-Truong Quan,Xuan-Son Quan,Duc Do Minh,Vinh Nguyen Van*

Main category: cs.LG

TL;DR: 本文提出了球形知识图嵌入模型（SKGE），该模型将实体表示约束到球面上，从而提高了复杂关系建模和训练效率。实验表明，SKGE在大规模基准数据集上的性能优于传统的TransE模型。


<details>
  <summary>Details</summary>
Motivation: 现有许多KGE模型（如TransE）使用未被限制的欧几里得空间进行表示学习，这使得它们在处理复杂关系和训练效率上存在局限性。因此，本文提出了SKGE模型，利用球面约束来提高表示学习的能力和效率。 

Method: SKGE采用可学习的非线性Spherization Layer将实体映射到球面上，并将关系解释为先平移后投影的变换。通过实验展示了SKGE在三个基准数据集上的优越性能。 

Result: 实验结果表明SKGE在大规模基准数据集FB15k-237和CoDEx-M上显著优于TransE。此外，圆几何约束作为强大的正则化器，有助于获得更强大和语义相关的表示。

Conclusion: 我们的研究结果表明，在设计下一代KGE模型时，坐标的几何先验知识是非常重要的，它不仅可以提高模型的稳定性和表达能力，同时也为模型在未来研究中提供了新的方向。

Abstract: Knowledge graph embedding (KGE) has become a fundamental technique for
representation learning on multi-relational data. Many seminal models, such as
TransE, operate in an unbounded Euclidean space, which presents inherent
limitations in modeling complex relations and can lead to inefficient training.
In this paper, we propose Spherical Knowledge Graph Embedding (SKGE), a model
that challenges this paradigm by constraining entity representations to a
compact manifold: a hypersphere. SKGE employs a learnable, non-linear
Spherization Layer to map entities onto the sphere and interprets relations as
a hybrid translate-then-project transformation. Through extensive experiments
on three benchmark datasets, FB15k-237, CoDEx-S, and CoDEx-M, we demonstrate
that SKGE consistently and significantly outperforms its strong Euclidean
counterpart, TransE, particularly on large-scale benchmarks such as FB15k-237
and CoDEx-M, demonstrating the efficacy of the spherical geometric prior. We
provide an in-depth analysis to reveal the sources of this advantage, showing
that this geometric constraint acts as a powerful regularizer, leading to
comprehensive performance gains across all relation types. More fundamentally,
we prove that the spherical geometry creates an "inherently hard negative
sampling" environment, naturally eliminating trivial negatives and forcing the
model to learn more robust and semantically coherent representations. Our
findings compellingly demonstrate that the choice of manifold is not merely an
implementation detail but a fundamental design principle, advocating for
geometric priors as a cornerstone for designing the next generation of powerful
and stable KGE models.

</details>


### [98] [BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring](https://arxiv.org/abs/2511.02490)
*Rajan Das Gupta,Md Kishor Morol,Nafiz Fahad,Md Tanzib Hosain,Sumaya Binte Zilani Choya,Md Jakir Hossen*

Main category: cs.LG

TL;DR: BRAINS系统运用大型语言模型进行阿尔茨海默病的早期检测和监控，包含认知诊断模块和案例检索模块，通过真实的临床数据验证了其在疾病严重程度分类和认知下降早期迹象识别方面的有效性，提供了阿尔茨海默病早期诊断辅助工具的潜在应用方向


<details>
  <summary>Details</summary>
Motivation: 提出BRAINS系统是为了应对阿尔茨海默病（AD）负担日益严重的挑战，在受限于先进诊断工具的地区进行早期和准确的检测变得尤为重要

Method: BRAINS系统采用了双模块架构，包括认知诊断模块和案例检索模块。认知诊断模块利用在认知和神经成像数据集上微调的大型语言模型进行阿尔茨海默病风险的结构化评估，案例检索模块将患者资料编码为潜在表示，从整理的知识库中检索相似案例，通过案例融合层融合辅助案例和输入档案，增强上下文理解，最终进行推理

Result: 在真实世界数据集的评估中，BRAINS系统显示出在分类疾病严重程度和识别认知衰退早期迹象方面的有效性，成为一种可扩展、可解释性的早期阿尔茨海默病检测辅助工具

Conclusion: BRAINS系统在早期阿尔茨海默病检测中的强大潜力使其成为下一代辅助诊断工具的理想候选，为未来在相关领域的应用带来希望

Abstract: As the global burden of Alzheimer's disease (AD) continues to grow, early and
accurate detection has become increasingly critical, especially in regions with
limited access to advanced diagnostic tools. We propose BRAINS (Biomedical
Retrieval-Augmented Intelligence for Neurodegeneration Screening) to address
this challenge. This novel system harnesses the powerful reasoning capabilities
of Large Language Models (LLMs) for Alzheimer's detection and monitoring.
BRAINS features a dual-module architecture: a cognitive diagnostic module and a
case-retrieval module. The Diagnostic Module utilizes LLMs fine-tuned on
cognitive and neuroimaging datasets -- including MMSE, CDR scores, and brain
volume metrics -- to perform structured assessments of Alzheimer's risk.
Meanwhile, the Case Retrieval Module encodes patient profiles into latent
representations and retrieves similar cases from a curated knowledge base.
These auxiliary cases are fused with the input profile via a Case Fusion Layer
to enhance contextual understanding. The combined representation is then
processed with clinical prompts for inference. Evaluations on real-world
datasets demonstrate BRAINS effectiveness in classifying disease severity and
identifying early signs of cognitive decline. This system not only shows strong
potential as an assistive tool for scalable, explainable, and early-stage
Alzheimer's disease detection, but also offers hope for future applications in
the field.

</details>


### [99] [Variational Geometric Information Bottleneck: Learning the Shape of Understanding](https://arxiv.org/abs/2511.02496)
*Ronald Katende*

Main category: cs.LG

TL;DR: 提出了一种统一的信息几何框架，将理解学习作为信息丰富性和几何简单性之间的权衡。通过实验验证了理论假设，在数据稀缺情况下，该方法能保持预测能力，提高了信息几何效率。最终提供的V-GIB方法为获得与人类理解结构对齐的数据有效且几何上一致的表示提供了途径。


<details>
  <summary>Details</summary>
Motivation: 动机在于将几何和信息理论结合起来，建立一种新的学习理解的方法论框架，通过几何的方法提升了解的学习效率和稳定性。

Method: 该方法引入了变分几何信息瓶颈(V-GIB)，结合压缩互信息和曲率正则化，并通过诸如Hutchinson迹，雅各布范数等可计算的几何替代物实现。该方法在合成流形，少量样本设置和现实世界数据集上进行了试验。

Result: 实验结果展示了信息几何效率的稳健前沿，稳定的估计器，并在解释效率上取得了实质性的提升。特别地，在数据稀缺的情况下，该方法保持了预测能力，验证了预测效率-曲率律。

Conclusion: 综上所述，V-GIB方法为获得具有几何连贯性，数据效率并符合人类可理解结构的表示提供了一条原理和度量并行的道路。

Abstract: We propose a unified information-geometric framework that formalizes
understanding in learning as a trade-off between informativeness and geometric
simplicity. An encoder phi is evaluated by U(phi) = I(phi(X); Y) - beta *
C(phi), where C(phi) penalizes curvature and intrinsic dimensionality,
enforcing smooth, low-complexity manifolds. Under mild manifold and regularity
assumptions, we derive non-asymptotic bounds showing that generalization error
scales with intrinsic dimension while curvature controls approximation
stability, directly linking geometry to sample efficiency. To operationalize
this theory, we introduce the Variational Geometric Information Bottleneck
(V-GIB), a variational estimator that unifies mutual-information compression
and curvature regularization through tractable geometric proxies such as the
Hutchinson trace, Jacobian norms, and local PCA. Experiments across synthetic
manifolds, few-shot settings, and real-world datasets (Fashion-MNIST, CIFAR-10)
reveal a robust information-geometry Pareto frontier, stable estimators, and
substantial gains in interpretive efficiency. Fractional-data experiments on
CIFAR-10 confirm that curvature-aware encoders maintain predictive power under
data scarcity, validating the predicted efficiency-curvature law. Overall,
V-GIB provides a principled and measurable route to representations that are
geometrically coherent, data-efficient, and aligned with human-understandable
structure.

</details>


### [100] [An End-to-End Learning Approach for Solving Capacitated Location-Routing Problems](https://arxiv.org/abs/2511.02525)
*Changhao Miao,Yuntian Zhang,Tongyu Wu,Fang Deng,Chen Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度强化学习的异构查询方法（DRLHQ）来解决有容量限制的选址路问题（CLRPs）及其相关变种问题。通过使用编码器-解码器结构，本文首次提出了一种端到端学习方法，可以解决CLRPs问题。实验结果表明，所提出的方法在合成数据和基准数据集上都优于传统方法和深度强化学习方法，在解决CLRPs和开放CLRPs方面具有更高的解的质量和更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 近年来，深度强化学习被广泛应用于解决车辆路径问题及其变种，但在处理有容量限制的选址路由问题上，相关研究尚处于初级阶段。因此，引入新的深度强化学习方法成为必要。

Method: 本文提出了DRLHQ方法，使用编码器-解码器框架，以解决CLRPs问题。该方法使用马尔可夫决策过程来建模，并引入了一种新颖的异构查询注意力机制来处理选址和路径决策之间的相互依赖关系。

Result: 实验结果表明，所提出的DRLHQ方法在解决CLRPs和开放CLRPs问题上，具有更好的解的质量和泛化性能，优于传统优化方法和深度强化学习方法。

Conclusion: 本文通过提出一个端到端的深度强化学习方法，解决了有容量限制的选址路线问题。该方法在实验中表现出色，展示了深度强化学习在处理复杂决策问题上的潜力。

Abstract: The capacitated location-routing problems (CLRPs) are classical problems in
combinatorial optimization, which require simultaneously making location and
routing decisions. In CLRPs, the complex constraints and the intricate
relationships between various decisions make the problem challenging to solve.
With the emergence of deep reinforcement learning (DRL), it has been
extensively applied to address the vehicle routing problem and its variants,
while the research related to CLRPs still needs to be explored. In this paper,
we propose the DRL with heterogeneous query (DRLHQ) to solve CLRP and open CLRP
(OCLRP), respectively. We are the first to propose an end-to-end learning
approach for CLRPs, following the encoder-decoder structure. In particular, we
reformulate the CLRPs as a markov decision process tailored to various
decisions, a general modeling framework that can be adapted to other DRL-based
methods. To better handle the interdependency across location and routing
decisions, we also introduce a novel heterogeneous querying attention mechanism
designed to adapt dynamically to various decision-making stages. Experimental
results on both synthetic and benchmark datasets demonstrate superior solution
quality and better generalization performance of our proposed approach over
representative traditional and DRL-based baselines in solving both CLRP and
OCLRP.

</details>


### [101] [Rawlsian many-to-one matching with non-linear utility](https://arxiv.org/abs/2511.02533)
*Hortence Nana,Andreas Athanasopoulos,Christos Dimitrakakis*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study a many-to-one matching problem, such as the college admission
problem, where each college can admit multiple students. Unlike classical
models, colleges evaluate sets of students through non-linear utility functions
that capture diversity between them. In this setting, we show that classical
stable matchings may fail to exist. To address this, we propose alternative
solution concepts based on Rawlsian fairness, aiming to maximize the minimum
utility across colleges. We design both deterministic and stochastic algorithms
that iteratively improve the outcome of the worst-off college, offering a
practical approach to fair allocation when stability cannot be guaranteed.

</details>


### [102] [Adaptive Neighborhood-Constrained Q Learning for Offline Reinforcement Learning](https://arxiv.org/abs/2511.02567)
*Yixiu Mao,Yun Qu,Qi Wang,Xiangyang Ji*

Main category: cs.LG

TL;DR: 提出了一个新的邻域约束，限制贝尔曼目标中的动作选择，以减少离线强化学习中的外推误差。这种约束结合了支持约束的优点，而不需要行为策略建模，并且适应每个数据点的邻域半径，提高了灵活性和保守性。实验表明，ANQ算法在标准离线RL基准上取得了最先进的性能，且在有噪声或数据有限的情况下表现稳健。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习中，动作选择的约束限制（密度约束、样本约束和支持约束）都有各自的局限性。因此，提出了一个新的邻域约束，以克服这些局限性，减少外推误差，并提高算法的鲁棒性。

Method: 提出了一种自适应邻域约束，即Adaptive Neighborhood-constrained Q learning (ANQ)算法。该算法在不进行行为策略建模的情况下，通过邻域约束限制贝尔曼目标中动作的选择，并通过数据质量作为适应标准，采用二层优化框架完成Q值学习。

Result: ANQ算法在标准离线RL基准上取得了最先进的性能，并在数据有噪声或数据有限的情况下表现稳健，显示出较好的鲁棒性。

Conclusion: 新提出的邻域约束能够有效减少离线强化学习中的外推误差，并在实际应用中表现出色。

Abstract: Offline reinforcement learning (RL) suffers from extrapolation errors induced
by out-of-distribution (OOD) actions. To address this, offline RL algorithms
typically impose constraints on action selection, which can be systematically
categorized into density, support, and sample constraints. However, we show
that each category has inherent limitations: density and sample constraints
tend to be overly conservative in many scenarios, while the support constraint,
though least restrictive, faces challenges in accurately modeling the behavior
policy. To overcome these limitations, we propose a new neighborhood constraint
that restricts action selection in the Bellman target to the union of
neighborhoods of dataset actions. Theoretically, the constraint not only bounds
extrapolation errors and distribution shift under certain conditions, but also
approximates the support constraint without requiring behavior policy modeling.
Moreover, it retains substantial flexibility and enables pointwise conservatism
by adapting the neighborhood radius for each data point. In practice, we employ
data quality as the adaptation criterion and design an adaptive neighborhood
constraint. Building on an efficient bilevel optimization framework, we develop
a simple yet effective algorithm, Adaptive Neighborhood-constrained Q learning
(ANQ), to perform Q learning with target actions satisfying this constraint.
Empirically, ANQ achieves state-of-the-art performance on standard offline RL
benchmarks and exhibits strong robustness in scenarios with noisy or limited
data.

</details>


### [103] [Directional-Clamp PPO](https://arxiv.org/abs/2511.02577)
*Gilad Karpel,Ruida Zhou,Shoham Sabach,Mohammad Ghavamzadeh*

Main category: cs.LG

TL;DR: 提出了Directional-Clamp PPO算法(DClamp-PPO)，通过在重要性比率朝“错误”方向移动时施加更严厉的惩罚，增强了PPO算法，使其在多个MuJoCo环境中表现优于原始PPO及其变体。理论和实验都证明了该方法可以更好地避免更新朝向“错误”方向，同时使重要性比率更接近1。


<details>
  <summary>Details</summary>
Motivation: 观察到PPO算法在优化过程中，重要性比率经常转向‘错误’的方向，成为限制PPO性能改进的关键因素。为了解决这个问题，提出了新的方法来避免这些比率朝向‘错误’方向移动，旨在提高算法在MuJoCo环境中的性能。

Method: 提出了Directional-Clamp PPO，引入了一种新的优化策略，在重要性比率过度向‘错误’方向（优势为正且重要性比率<1−β，反之亦然）时施加更严厉的惩罚，从而提升了PPO的性能。该方法通过调整重要性比率在“正确”方向的行为，避免不利的更新。

Result: 该研究证明，DClamp-PPO在使用不同随机种子的多个MuJoCo环境中均表现优于原始PPO和其他变体版本。实验证明，该方法能够更好地避免更新朝向‘错误’方向，同时使重要性比率接近1。

Conclusion: 此项工作增强了PPO算法，特别是在防止重要性比率朝‘错误’方向移动方面取得了显著进展，表明该方法论比现有的任何形式的PPO都有更高的稳定性与性能表现。

Abstract: Proximal Policy Optimization (PPO) is widely regarded as one of the most
successful deep reinforcement learning algorithms, known for its robustness and
effectiveness across a range of problems.
  The PPO objective encourages the importance ratio between the current and
behavior policies to move to the "right" direction -- starting from importance
sampling ratios equal to 1, increasing the ratios for actions with positive
advantages and decreasing those with negative advantages. A clipping function
is introduced to prevent over-optimization when updating the importance ratio
in these "right" direction regions. Many PPO variants have been proposed to
extend its success, most of which modify the objective's behavior by altering
the clipping in the "right" direction regions. However, due to randomness in
the rollouts and stochasticity of the policy optimization, we observe that the
ratios frequently move to the "wrong" direction during the PPO optimization.
This is a key factor hindering the improvement of PPO, but it has been largely
overlooked. To address this, we propose the Directional-Clamp PPO algorithm
(DClamp-PPO), which further penalizes the actions going to the strict "wrong"
direction regions, where the advantage is positive (negative) and importance
ratio falls below (above) $1 - \beta$ ($1+\beta$),
  for a tunable parameter $\beta \in (0, 1)$. The penalty is by enforcing a
steeper loss slope, i.e., a clamp, in those regions. We demonstrate that
DClamp-PPO consistently outperforms PPO, as well as its variants, by focusing
on modifying the objective's behavior in the "right" direction, across various
MuJoCo environments, using different random seeds. The proposed method is
shown, both theoretically and empirically, to better avoid "wrong" direction
updates while keeping the importance ratio closer to 1.

</details>


### [104] [A Non-Adversarial Approach to Idempotent Generative Modelling](https://arxiv.org/abs/2511.02614)
*Mohammed Al-Jaff,Giovanni Luca Marchetti,Michael C Welle,Jens Lundell,Mats G. Gustafsson,Gustav Eje Henter,Hossein Azizpour,Danica Kragic*

Main category: cs.LG

TL;DR: NAIGNs是一种改进的Idempotent Generative Networks（IGNs），通过结合重建损失与非对抗性的生成目标（即Implicit Maximum Likelihood Estimation，IMLE），有效解决了IGNs存在的模式坍塌等问题，并提升对数据的恢复能力和生成样本的质量。同时，NAIGNs还能隐式学习数据流形的距离场以及能量模型。


<details>
  <summary>Details</summary>
Motivation: 现有Idempotent Generative Networks（IGNs）存在模式坍塌、模式丢失以及训练不稳定等问题，这些问题归因于其中包含的对抗成分，导致模型无法完全覆盖数据流形。为解决这些问题，提出了非对抗性的Idempotent Generative Networks（NAIGNs）。

Method: NAIGNs在训练中采用了一个结合了重建损失与Non-Adversarial (非对抗性的) 生成目标（IMLE）的损失函数，这改进了IGNs处理数据集问题的能力，并提升了其恢复被破坏的数据和生成新的样本的能力。同时，训练过程还表明，NAIGNs具有隐式学习数据流形距离场和能量模型的能力。

Result: NAIGNs能够在不使用对抗性学习的情况下，更好地覆盖数据流形，并生成更接近实际数据分布的样本，对于复原受损数据和生成新的样本表现更佳。此外，与IGNs相比较，NAIGNs具有隐式学习数据流形距离场与能量模型的能力，提高了对数据流形的理解，增强了模型的泛化能力。

Conclusion: 通过引入非对抗性损失函数，NAIGNs成功解决了IGNs中由于使用对抗性方法所遇到的问题。它不仅改进了数据的恢复能力和样本生成效果，而且能够更全面地学习和表征数据流形，具有潜在的广泛应用前景。

Abstract: Idempotent Generative Networks (IGNs) are deep generative models that also
function as local data manifold projectors, mapping arbitrary inputs back onto
the manifold. They are trained to act as identity operators on the data and as
idempotent operators off the data manifold. However, IGNs suffer from mode
collapse, mode dropping, and training instability due to their objectives,
which contain adversarial components and can cause the model to cover the data
manifold only partially -- an issue shared with generative adversarial
networks. We introduce Non-Adversarial Idempotent Generative Networks (NAIGNs)
to address these issues. Our loss function combines reconstruction with the
non-adversarial generative objective of Implicit Maximum Likelihood Estimation
(IMLE). This improves on IGN's ability to restore corrupted data and generate
new samples that closely match the data distribution. We moreover demonstrate
that NAIGNs implicitly learn the distance field to the data manifold, as well
as an energy-based model.

</details>


### [105] [Recursively Enumerably Representable Classes and Computable Versions of the Fundamental Theorem of Statistical Learning](https://arxiv.org/abs/2511.02644)
*David Kattermann,Lothar Sebastian Krapp*

Main category: cs.LG

TL;DR: 该论文研究了计算概率近似正确（CPAC）学习，探讨了CPAC学习与递归可枚举表示（RER）类之间的联系，并讨论了CPAC学习的一些特性及其学习能力。


<details>
  <summary>Details</summary>
Motivation: 论文动机在于研究在计算框架下，概率近似正确学习的新特性，探索CPAC学习中的有效VC维数与传统VC维数的关系以及递归可枚举表示类之间的联系与区别，试图找到有效的学习方法论。

Method: 通过分析CPAC学习的特征，引入递归可枚举表示类的概念，以及不同类型CPAC学习的有效VC维数之间的关系，研究了CPAC学习中的学习能力和特性。

Result: 结果表明，在更强的CPAC学习条件下，两者的一维和维数可以相等。另外，两种学习能力可以通过包含实现相同样本的RER类来描述，并且满足唯一识别属性的CPAC可学类必定是RER类。最后，通过考虑非均匀CPAC学习的放松概念，可以保证RER类的良态学习。

Conclusion: 论文得出结论，CPAC学习与RER类之间存在密切的联系，进一步的理论分析可以增进对学习理论的理解与应用。

Abstract: We study computable probably approximately correct (CPAC) learning, where
learners are required to be computable functions. It had been previously
observed that the Fundamental Theorem of Statistical Learning, which
characterizes PAC learnability by finiteness of the Vapnik-Chervonenkis
(VC-)dimension, no longer holds in this framework. Recent works recovered
analogs of the Fundamental Theorem in the computable setting, for instance by
introducing an effective VC-dimension. Guided by this, we investigate the
connection between CPAC learning and recursively enumerable representable (RER)
classes, whose members can be algorithmically listed. Our results show that the
effective VC-dimensions can take arbitrary values above the traditional one,
even for RER classes, which creates a whole family of (non-)examples for
various notions of CPAC learning. Yet the two dimensions coincide for classes
satisfying sufficiently strong notions of CPAC learning. We then observe that
CPAC learnability can also be characterized via containment of RER classes that
realize the same samples. Furthermore, it is shown that CPAC learnable classes
satisfying a unique identification property are necessarily RER. Finally, we
establish that agnostic learnability can be guaranteed for RER classes, by
considering the relaxed notion of nonuniform CPAC learning.

</details>


### [106] [Nesterov-Accelerated Robust Federated Learning Over Byzantine Adversaries](https://arxiv.org/abs/2511.02657)
*Lihan Xu,Yanjie Dong,Gang Wang,Runhao Zeng,Xiaoyi Fan,Xiping Hu*

Main category: cs.LG

TL;DR: 提出了一种名为Byrd-NAFL的算法，用于在拜占庭对手存在的环境中提高联邦学习的通信效率和抗干扰能力。Byrd-NAFL结合了Nesterov加速度和拜占庭抗性聚合规则，确保了在非凸且平滑损失函数下的快速且稳定的收敛性。实验结果表明，该算法在收敛速度、准确性和对抗多种拜占庭攻击策略方面优于现有基准算法。


<details>
  <summary>Details</summary>
Motivation: 在存在拜占庭对手的情况下，提高联邦学习的通信效率和抗干扰能力。

Method: 提出了一种名为Byrd-NAFL的算法，该算法将Nesterov加速度和拜占庭抗性聚合规则整合到联邦学习过程中，以实现快速收敛并抵御梯度腐蚀。

Result: 建立了Byrd-NAFL在非凸且平滑损失函数下的有限时间收敛性保证，实验验证了该算法的有效性并证明了其在收敛速度、精度和对抗多种拜占庭攻击策略方面的优越性。

Conclusion: Byrd-NAFL算法提供了一种有效的解决联邦学习中拜占庭问题的方法，能够提高模型的准确性和抗干扰能力，同时保持快速收敛。

Abstract: We investigate robust federated learning, where a group of workers
collaboratively train a shared model under the orchestration of a central
server in the presence of Byzantine adversaries capable of arbitrary and
potentially malicious behaviors. To simultaneously enhance communication
efficiency and robustness against such adversaries, we propose a
Byzantine-resilient Nesterov-Accelerated Federated Learning (Byrd-NAFL)
algorithm. Byrd-NAFL seamlessly integrates Nesterov's momentum into the
federated learning process alongside Byzantine-resilient aggregation rules to
achieve fast and safeguarding convergence against gradient corruption. We
establish a finite-time convergence guarantee for Byrd-NAFL under non-convex
and smooth loss functions with relaxed assumption on the aggregated gradients.
Extensive numerical experiments validate the effectiveness of Byrd-NAFL and
demonstrate the superiority over existing benchmarks in terms of convergence
speed, accuracy, and resilience to diverse Byzantine attack strategies.

</details>


### [107] [Does Interpretability of Knowledge Tracing Models Support Teacher Decision Making?](https://arxiv.org/abs/2511.02718)
*Adia Khalid,Alina Deriyeva,Benjamin Paassen*

Main category: cs.LG

TL;DR: 研究探讨了解释性知识追踪模型是否有助于教师的教学决策，通过模拟研究发现，基于解释性模型的教学决策能够更快达到教学目标；但在真实教师参与的实验中，不同模型所需的教学任务数量差异不大，表明模型的解释性与实际教学决策之间的关系并不直接，需要进一步研究两者如何影响教学决策和应用理解。


<details>
  <summary>Details</summary>
Motivation: 目前没有研究探讨过知识追踪模型的可解释性是否能帮助教师做出更好的教学决策。这一研究旨在填补这一空白，验证可解释模型在实际教学决策中的作用。

Method: 首先，进行了一项模拟研究，结果显示，基于可解释模型的教学决策比基于不可解释模型的决策更快达成教学目标。其次，在12位真实教师参与的实验中，教师们认为可解释的模型更可信赖和易用，但不同模型之间所需的教学任务数量差异并不明显。

Result: 实验显示，基于可解模型的决策比不可解释模型的决策更有效。然而，当教师们参与实际决策时，不同模型之间的差异不明显，表明可解释性对决策的影响可能有限。

Conclusion: 研究结果表明，虽然可解释模型在理论上具有优势，但它们的实际影响可能不如预期的那样明显。这意味着模型的解释性和实际教学决策之间的关系更加复杂，有待进一步研究。

Abstract: Knowledge tracing (KT) models are a crucial basis for pedagogical
decision-making, namely which task to select next for a learner and when to
stop teaching a particular skill. Given the high stakes of pedagogical
decisions, KT models are typically required to be interpretable, in the sense
that they should implement an explicit model of human learning and provide
explicit estimates of learners' abilities. However, to our knowledge, no study
to date has investigated whether the interpretability of KT models actually
helps human teachers to make teaching decisions. We address this gap. First, we
perform a simulation study to show that, indeed, decisions based on
interpretable KT models achieve mastery faster compared to decisions based on a
non-interpretable model. Second, we repeat the study but ask $N=12$ human
teachers to make the teaching decisions based on the information provided by KT
models. As expected, teachers rate interpretable KT models higher in terms of
usability and trustworthiness. However, the number of tasks needed until
mastery hardly differs between KT models. This suggests that the relationship
between model interpretability and teacher decisions is not straightforward:
teachers do not solely rely on KT models to make decisions and further research
is needed to investigate how learners and teachers actually understand and use
KT models.

</details>


### [108] [TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models](https://arxiv.org/abs/2511.02802)
*Aditya Tanna,Pratinav Seth,Mohamed Bouadi,Utsav Avaiya,Vinay Kumar Sankarapu*

Main category: cs.LG

TL;DR: TabTune是一个统一的库，标准化了表格基础模型的完整工作流程，通过单一接口提供一致的访问和自动化预处理，适应策略评估等。


<details>
  <summary>Details</summary>
Motivation: 现有表格基础模型的采用受限于异构预处理管道、分散的API、不一致的微调过程和部署指标标准化评估的缺失。因此，需要一个统一的库来解决这些问题，提高模型的可访问性和标准化。

Method: TabTune提供了一站式的工作流程管理，支持包括零样本推理、元学习、监督微调（SFT）和参数高效微调（PEFT）等适应策略。同时，它自动执行模型感知的预处理，内部管理架构异构性，并集成了用于性能、校准和公平性的评估模块。

Result: TabTune实现了表格基础模型适应策略的可扩展性和可重复性，促进了适应策略的基准测试，并且已开源，位于https://github.com/Lexsi-Labs/TabTune 。

Conclusion: TabTune通过标准化表格基础模型的整个工作流程，提高了模型的使用效率和研究可重复性。

Abstract: Tabular foundation models represent a growing paradigm in structured data
learning, extending the benefits of large-scale pretraining to tabular domains.
However, their adoption remains limited due to heterogeneous preprocessing
pipelines, fragmented APIs, inconsistent fine-tuning procedures, and the
absence of standardized evaluation for deployment-oriented metrics such as
calibration and fairness. We present TabTune, a unified library that
standardizes the complete workflow for tabular foundation models through a
single interface. TabTune provides consistent access to seven state-of-the-art
models supporting multiple adaptation strategies, including zero-shot
inference, meta-learning, supervised fine-tuning (SFT), and parameter-efficient
fine-tuning (PEFT). The framework automates model-aware preprocessing, manages
architectural heterogeneity internally, and integrates evaluation modules for
performance, calibration, and fairness. Designed for extensibility and
reproducibility, TabTune enables consistent benchmarking of adaptation
strategies of tabular foundation models. The library is open source and
available at https://github.com/Lexsi-Labs/TabTune .

</details>


### [109] [Calibration improves detection of mislabeled examples](https://arxiv.org/abs/2511.02738)
*Ilies Chibane,Thomas George,Pierre Nodet,Vincent Lemaire*

Main category: cs.LG

TL;DR: 该论文研究了对基础机器学习模型进行校准以提升识别错误标签实例的准确性和鲁棒性的效果。


<details>
  <summary>Details</summary>
Motivation: 错误标签数据对现实世界中机器学习系统的性能产生负面影响，通过检测和处理错误标签实例可以缓解这个问题。现有的自动检测错误标签方法依赖于基础机器学习模型生成的信任分数，而基础模型的属性至关重要。因此，本文探索了对基础模型进行校准的影响。

Method: 该方法通过使用校准技术来改进用于检测误标签实例的基础机器学习模型。具体来说，通过使用校准方法来提高模型对标签真实性的评估准确性和鲁棒性。

Result: 实验证明，通过使用校准技术可以提高错误标签实例检测的准确性和稳定性，从而提供了一种实用有效的工业解决方案。

Conclusion: 这篇文章展示了通过校准基础模型可以改善错误标签检测的效果，提高了工业应用中的准确性和鲁棒性。

Abstract: Mislabeled data is a pervasive issue that undermines the performance of
machine learning systems in real-world applications. An effective approach to
mitigate this problem is to detect mislabeled instances and subject them to
special treatment, such as filtering or relabeling. Automatic mislabeling
detection methods typically rely on training a base machine learning model and
then probing it for each instance to obtain a trust score that each provided
label is genuine or incorrect. The properties of this base model are thus of
paramount importance. In this paper, we investigate the impact of calibrating
this model. Our empirical results show that using calibration methods improves
the accuracy and robustness of mislabeled instance detection, providing a
practical and effective solution for industrial applications.

</details>


### [110] [Assessing win strength in MLB win prediction models](https://arxiv.org/abs/2511.02815)
*Morgan Allen,Paul Savala*

Main category: cs.LG

TL;DR: 我们扩展了之前的研究，通过使用一组全面的机器学习模型训练，并将这些模型产生的胜率与实际得分差异进行关联分析。我们还利用预测的胜率作为决策机制分析跑分赌注，并证明利用适当的赌注策略可以获得正收益，而盲目使用机器学习模型进行赌博会导致显著损失


<details>
  <summary>Details</summary>
Motivation: 通过使用一组全面的机器学习模型训练并分析预测的胜率与实际得分差异的关系，为棒球比赛的结果提供更深入的理解和决策支持

Method: 训练一组全面的机器学习模型，使用相同的数据集预测棒球比赛的胜者，将这些模型产生的胜率与实际得分差异进行关联分析，并分析预测胜率作为决策机制在跑分赌注上的效果

Result: 证明了最常见的机器学习模型确实能展示预测胜率与获胜强度之间的关系；利用预测胜率作为跑分赌注的决策机制，适当的赌注策略可以获得正收益，而盲目使用机器学习模型进行赌博会导致显著损失

Conclusion: 我们通过分析得出，适当利用机器学习模型预测结果并在赌博决策中应用可以带来正收益，但盲目使用会导致损失。因此，需要谨慎使用这些模型，并建立适当的策略

Abstract: In Major League Baseball, strategy and planning are major factors in
determining the outcome of a game. Previous studies have aided this by building
machine learning models for predicting the winning team of any given game. We
extend this work by training a comprehensive set of machine learning models
using a common dataset. In addition, we relate the win probabilities produced
by these models to win strength as measured by score differential. In doing so
we show that the most common machine learning models do indeed demonstrate a
relationship between predicted win probability and the strength of the win.
Finally, we analyze the results of using predicted win probabilities as a
decision making mechanism on run-line betting. We demonstrate positive returns
when utilizing appropriate betting strategies, and show that naive use of
machine learning models for betting lead to significant loses.

</details>


### [111] [ConMeZO: Adaptive Descent-Direction Sampling for Gradient-Free Finetuning of Large Language Models](https://arxiv.org/abs/2511.02757)
*Lejs Deen Behric,Liang Zhang,Bingcong Li,Kiran Koshy Thekumparampil*

Main category: cs.LG

TL;DR: 一种新的零阶优化器ConMeZO通过自适应方向采样加速大型语言模型（LLM）的微调收敛速度，同时保持低内存消耗。实验表明，其收敛速度可比传统方法快2倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的微调过程中，在高维参数空间内搜索下降方向时，零阶优化策略由于维数灾难会导致收敛缓慢。因此提出了适应性方向采样的ConMeZO优化器。其优势是既能加速收敛，还保持零阶优化策略的低内存开销。

Method: ConMeZO优化器将方向采样限制在以动量估计为中心的锥体内部，从而更加集中在真实的梯度方向上。理论分析表明ConMeZO的最坏情况下的收敛速度和传统的零阶优化方法相同。

Result: 在自然语言任务上的实验表明，与传统零阶优化方法相比，ConMeZO能将收敛速度提升至2倍，同时依旧保持了低内存开销的特点。

Conclusion: ConMeZO优化器是解决大型语言模型微调过程中，因高维参数空间影响导致的收敛速度问题的有效方法。

Abstract: Zeroth-order or derivative-free optimization (MeZO) is an attractive strategy
for finetuning large language models (LLMs) because it eliminates the memory
overhead of backpropagation. However, it converges slowly due to the inherent
curse of dimensionality when searching for descent directions in the
high-dimensional parameter space of billion-scale LLMs. We propose ConMeZO, a
novel zeroth-order optimizer that accelerates convergence by adaptive
directional sampling. Instead of drawing the direction uniformly at random,
ConMeZO restricts the sampling to a cone centered around a momentum estimate.
This concentrates the search in directions where the true gradient is more
likely to lie and thus reduces the effect of high dimensions. We prove that
ConMeZO achieves the same worst-case convergence rate as MeZO. Empirically,
when finetuning LLMs on natural language tasks, ConMeZO is up to 2X faster than
MeZO while retaining the low-memory footprint of zeroth-order methods.

</details>


### [112] [VecComp: Vector Computing via MIMO Digital Over-the-Air Computation](https://arxiv.org/abs/2511.02765)
*Saeed Razavikia,José Mairton Barros Da Silva Junior,Carlo Fischione*

Main category: cs.LG

TL;DR: 提出了一种新的框架VecComp，它是ChannelComp的扩展，整合了多天线技术，能够支持向量函数计算，并且即使在信道衰落的情况下也能保持高效的计算效率。VecComp在高维数据应用中表现出色，能够在噪声和多址衰落信道中有效补偿衰落，提高向量函数的计算精度。


<details>
  <summary>Details</summary>
Motivation: 现有的ChannelComp仅支持标量函数计算，而很多数据密集型应用需要支持向量函数计算。此外，ChannelComp容易受到信道衰落的影响。因此，需要一种新的框架来解决这些问题，即VecComp，它结合了ChannelComp和多天线技术，扩大了其在实际应用中的适用性。

Method: 通过引入VecComp框架，结合多天线技术，能够在信道衰落的情况下仍能实现高效率的向量函数计算。理论和实验验证了VecComp的有效性，如给出了关于VecComp均方误差的非渐近上限，以及在有噪声的多址信道中的执行情况。

Result: 实现了VecComp框架，它不仅在信道衰落情况下也能维持高效的计算效率，而且能够有效进行向量函数计算。实验结果证实了，在多天线系统下，VecComp提高了矢量函数计算的精度，同时增强了对多址衰落信道的补偿能力。

Conclusion: VecComp作为ChannelComp的一个扩展，解决了通道衰落可能带来的计算效率下降，并且使得通道能够支持向量函数计算，这表明VecComp框架对于未来的数据密集型应用有着潜在的应用价值。

Abstract: Recently, the ChannelComp framework has proposed digital over-the-air
computation by designing digital modulations that enable the computation of
arbitrary functions. Unlike traditional analog over-the-air computation, which
is restricted to nomographic functions, ChannelComp enables a broader range of
computational tasks while maintaining compatibility with digital communication
systems. This framework is intended for applications that favor local
information processing over the mere acquisition of data. However, ChannelComp
is currently designed for scalar function computation, while numerous
data-centric applications necessitate vector-based computations, and it is
susceptible to channel fading. In this work, we introduce a generalization of
the ChannelComp framework, called VecComp, by integrating ChannelComp with
multiple-antenna technology. This generalization not only enables vector
function computation but also ensures scalability in the computational
complexity, which increases only linearly with the vector dimension. As such,
VecComp remains computationally efficient and robust against channel
impairments, making it suitable for high-dimensional, data-centric
applications. We establish a non-asymptotic upper bound on the mean squared
error of VecComp, affirming its computation efficiency under fading channel
conditions. Numerical experiments show the effectiveness of VecComp in
improving the computation of vector functions and fading compensation over
noisy and fading multiple-access channels.

</details>


### [113] [Enhancing Federated Learning Privacy with QUBO](https://arxiv.org/abs/2511.02785)
*Andras Ferenczi,Sutapa Samanta,Dagen Wang,Todd Hodges*

Main category: cs.LG

TL;DR: 通过使用量子计算启发的二次无约束二进制优化（QUBO）方法来选择每轮训练中最相关的少量客户端更新，减少每次客户端暴露的风险。实验表明，这种方法可以显著降低隐私泄露的风险，同时保持甚至提高整体聚合精度，适用于更复杂的数据集和模型。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在保护隐私的同时实现了模型的分布式训练。然而，先前的研究显示随着参与迭代次数的增加，隐私风险也在增加。本文旨在通过选择性地包含更少的客户端更新，来减少这一风险，从而提高联邦学习的安全性。

Method: 提出了一种基于二次无约束二进制优化（QUBO）的客户端更新选择方法，该方法在每一轮训练中选择最相关的少量客户端更新加入到全局模型中，以减少信息泄漏和提高隐私保护。实验中，使用了MNIST和CINIC-10数据集来验证此方法的有效性。

Result: 实验结果显示，针对MNIST数据集，相比全聚合方法，本方法实现了每轮95.2%的隐私曝光率降低，并且在20轮中每轮平均隐私累计提高达49%。对于CINIC-10数据集，每轮隐私改善了82%，累计33%。同时验证了方法对于较小规模和更复杂模型的有效性，其仍能保持甚至提高模型的整体精度。

Conclusion: 通过对客户端更新的选择性加入，该方法可以在确保模型精度的同时显著提升联邦学习过程中的隐私保护。该方法不仅适用于大规模分布训练，也能应用于更复杂的数据集和模型中。

Abstract: Federated learning (FL) is a widely used method for training machine learning
(ML) models in a scalable way while preserving privacy (i.e., without
centralizing raw data). Prior research shows that the risk of exposing
sensitive data increases cumulatively as the number of iterations where a
client's updates are included in the aggregated model increase. Attackers can
launch membership inference attacks (MIA; deciding whether a sample or client
participated), property inference attacks (PIA; inferring attributes of a
client's data), and model inversion attacks (MI; reconstructing inputs),
thereby inferring client-specific attributes and, in some cases, reconstructing
inputs. In this paper, we mitigate risk by substantially reducing per client
exposure using a quantum computing-inspired quadratic unconstrained binary
optimization (QUBO) formulation that selects a small subset of client updates
most relevant for each training round. In this work, we focus on two threat
vectors: (i) information leakage by clients during training and (ii)
adversaries who can query or obtain the global model. We assume a trusted
central server and do not model server compromise. This method also assumes
that the server has access to a validation/test set with global data
distribution. Experiments on the MNIST dataset with 300 clients in 20 rounds
showed a 95.2% per-round and 49% cumulative privacy exposure reduction, with
147 clients' updates never being used during training while maintaining in
general the full-aggregation accuracy or even better. The method proved to be
efficient at lower scale and more complex model as well. A CINIC-10
dataset-based experiment with 30 clients resulted in 82% per-round privacy
improvement and 33% cumulative privacy.

</details>


### [114] [Can LLMs subtract numbers?](https://arxiv.org/abs/2511.02795)
*Mayank Jobanputra,Nils Philipp Walter,Maitrey Mehta,Blerta Veseli,Evan Parker Kelly Chapple,Yifan Wang,Sneha Chetani,Ellie Pavlick,Antonio Vergari,Vera Demberg*

Main category: cs.LG

TL;DR: 研究团队评估了大语言模型在减法任务上的表现，发现其准确率远低于加法。特别是在 a<b 的情况下，模型往往能正确识别结果的大小，但忽略负号。模型内部确实编码了结果应该为负的信息，但输出却未体现。通过 few-shot 学习和指令调优，团队找到改进方法，表明了 LLM 在减法任务上的局限性和改进空间。


<details>
  <summary>Details</summary>
Motivation: 此前的研究主要集中在大语言模型的加法和乘法能力上，而对减法能力的关注较少。考虑到减法作为非交换运算的独特性，研究团队以此为动机进行详细研究，探究模型在减法任务中的表现及背后原因。

Method: 研究团队选取了八个预训练的LLM，覆盖四大模型家族，通过设置加减法任务测试模型的计算能力，并通过探针分析和已知的技术手段（如少样本学习和指令调优）来评估模型性能。

Result: 研究表明，LLM 在减法任务上的准确性远低于加法，尤其是在处理 a<b 的情况时，错误集中在忽略了负号。但是通过指令调优技术，模型在生成负号时可以达到较高的准确度。

Conclusion: 研究揭示了 LLM 在减法任务上的局限性，并展示了通过技术手段可能实现的改进空间，这将有助于提升 LLM 的算术能力，特别是在处理非交换运算层面的性能。

Abstract: We present a systematic study of subtraction in large language models (LLMs).
While prior benchmarks emphasize addition and multiplication, subtraction has
received comparatively little attention despite being structurally distinct as
a non-commutative operation. We evaluate eight pretrained LLMs spanning four
families on addition and subtraction problems. Our experiments reveal that
subtraction accuracy lags behind addition by a wide margin. We find that the
errors for ($a-b$) are concentrated in cases where ($a<b$). In such cases, LLMs
frequently produce the correct magnitude but omit the negative sign. Probing
analyses show that LLMs internally encode whether results should be negative,
yet this information is often not reflected in generated outputs. We further
test well-known techniques such as few-shot learning and instruction-tuning to
see if they can improve the LLMs' performance. Our results suggest that while
few-shot prompting yields modest gains, the instruction-tuned models achieve
near-perfect accuracies in generating the negative sign. Together, these
findings provide a clearer characterization of the limitations and
recoverability of LLMs' arithmetic capabilities in subtraction.

</details>


### [115] [Fast, Private, and Protected: Safeguarding Data Privacy and Defending Against Model Poisoning Attacks in Federated Learning](https://arxiv.org/abs/2511.02797)
*Nicolas Riccieri Gardin Assumpcao,Leandro Villas*

Main category: cs.LG

TL;DR: 提出了一种名为FPP的新方法，旨在保护联邦学习的安全性，同时保持数据隐私。FPP通过采用参与者评估和训练恢复机制来应对攻击，并采用声誉机制来减少攻击者的参与。实验显示，无论是否存在恶意参与者，FPP均能快速收敛。


<details>
  <summary>Details</summary>
Motivation: 现有保护联邦学习中数据隐私的方法在面对潜在攻击者时存在安全挑战，因此提出了FPP以在保护隐私的同时增强系统的安全性。

Method: FPP引入了参与者评估和训练恢复机制，并采用了声誉机制来减少受到攻击的风险。并通过Docker环境验证了FPP在不同条件下的性能。

Result: 实验表明，FPP在有无攻击情况下均能达到快速收敛，证明了其在保护联邦学习安全性和隐私性方面的有效性。

Conclusion: FPP是一个有效的解决方案，可保护联邦学习的隐私和安全，在面对攻击时仍能保持良好的性能。

Abstract: Federated Learning (FL) is a distributed training paradigm wherein
participants collaborate to build a global model while ensuring the privacy of
the involved data, which remains stored on participant devices. However,
proposals aiming to ensure such privacy also make it challenging to protect
against potential attackers seeking to compromise the training outcome. In this
context, we present Fast, Private, and Protected (FPP), a novel approach that
aims to safeguard federated training while enabling secure aggregation to
preserve data privacy. This is accomplished by evaluating rounds using
participants' assessments and enabling training recovery after an attack. FPP
also employs a reputation-based mechanism to mitigate the participation of
attackers. We created a dockerized environment to validate the performance of
FPP compared to other approaches in the literature (FedAvg, Power-of-Choice,
and aggregation via Trimmed Mean and Median). Our experiments demonstrate that
FPP achieves a rapid convergence rate and can converge even in the presence of
malicious participants performing model poisoning attacks.

</details>


### [116] [GeoCrossBench: Cross-Band Generalization for Remote Sensing](https://arxiv.org/abs/2511.02831)
*Hakob Tamazyan,Ani Vanyan,Alvard Barseghyan,Anna Khosrovyan,Evan Shelhamer,Hrant Khachatrian*

Main category: cs.LG

TL;DR: 这篇论文提出了GeoCrossBench，一个新的评估基准，用于测试模型在遥感任务中的跨卫星泛化能力，并提出了一种改进的自监督方法ChiViT。研究发现，即使是最优的遥感基础模型在跨卫星场景下的表现也存在大幅下降，而ChiViT在某些任务下显著优于其他模型。此外，通过仅微调模型的最后一个线性层即可达到相对一致的好表现，表明当前的基准远未饱和。


<details>
  <summary>Details</summary>
Motivation: 随着遥感卫星数量和多样性的增加，训练和再训练支持新卫星的成本也在增长。目前的基础模型在面对新卫星时的泛化能力显得尤为重要。因此，研究目的是为了开发出具有更强跨卫星泛化能力的未来遥感模型。

Method: 论文引入了一个新的评估基准GeoCrossBench，以测试模型的跨卫星泛化能力，并提出了对于ChannelViT的自监督扩展方法ChiViT。通过这种新方法，可以更好地解决跨卫星场景下的性能问题。

Result: 实验结果显示，即使是最优的遥感基础模型，在跨卫星场景下的表现也有显著下降。而提出的自我监控方法ChiViT在跨卫星泛化性能上，显著优于其他模型。此外，微调模型的最后一个线性层可以达到在所有卫星上的相对一致的表现。

Conclusion: 根据研究结果，当前的基础模型在跨卫星泛化任务上有很大的改进空间，提出了GeoCrossBench基准可以进一步帮助研究此类问题。并且，代码和数据集公开发布以帮助未来的研究开发更加强大且跨卫星泛化性能良好的模型。

Abstract: The number and diversity of remote sensing satellites grows over time, while
the vast majority of labeled data comes from older satellites. As the
foundation models for Earth observation scale up, the cost of (re-)training to
support new satellites grows too, so the generalization capabilities of the
models towards new satellites become increasingly important. In this work we
introduce GeoCrossBench, an extension of the popular GeoBench benchmark with a
new evaluation protocol: it tests the in-distribution performance;
generalization to satellites with no band overlap; and generalization to
satellites with additional bands with respect to the training set. We also
develop a self-supervised extension of ChannelViT, ChiViT, to improve its
cross-satellite performance. First, we show that even the best foundation
models for remote sensing (DOFA, TerraFM) do not outperform general purpose
models like DINOv3 in the in-distribution setting. Second, when generalizing to
new satellites with no band overlap, all models suffer 2-4x drop in
performance, and ChiViT significantly outperforms the runner-up DINOv3. Third,
the performance of all tested models drops on average by 5-25\% when given
additional bands during test time. Finally, we show that fine-tuning just the
last linear layer of these models using oracle labels from all bands can get
relatively consistent performance across all satellites, highlighting that the
benchmark is far from being saturated. We publicly release the code and the
datasets to encourage the development of more future-proof remote sensing
models with stronger cross-satellite generalization.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [117] [Resource-efficient Automatic Refinement of Segmentations via Weak Supervision from Light Feedback](https://arxiv.org/abs/2511.02576)
*Alix de Langlais,Benjamin Billot,Théo Aguilar Vidal,Marc-Olivier Gauci,Hervé Delingette*

Main category: eess.IV

TL;DR: SCORE是一种弱监督框架，用于改进初始分割预测，它通过使用区域质量评分和过度或不足分割误差标签进行训练，而不是依赖密集的图像标注。在肱骨CT扫描上，SCORE显著提高了初始分割的准确性，同时减少了标注时间和监督要求。


<details>
  <summary>Details</summary>
Motivation: 当前分割精炼方法依赖于大量的用户交互或完全监督的分割训练，要求较高。作者希望提出一种仅依赖轻量反馈的分割精炼策略。

Method: 提出了一种名为SCORE的弱监督框架，该框架通过引入区域质量评分和过度/不足分割误差标签进行训练，以精炼初始分割预测。

Result: 实验显示，SCORE在肱骨CT扫描上提高了由TotalSegmentator生成的初始分割的准确性。它实现的性能达到现有精炼方法的水平，但所需的监督和注释时间大大减少。

Conclusion: SCORE通过采用轻量的反馈机制，能够有效提高分割精度，同时大幅降低训练所需的人力和注释工作。

Abstract: Delineating anatomical regions is a key task in medical image analysis.
Manual segmentation achieves high accuracy but is labor-intensive and prone to
variability, thus prompting the development of automated approaches. Recently,
a breadth of foundation models has enabled automated segmentations across
diverse anatomies and imaging modalities, but these may not always meet the
clinical accuracy standards. While segmentation refinement strategies can
improve performance, current methods depend on heavy user interactions or
require fully supervised segmentations for training. Here, we present SCORE
(Segmentation COrrection from Regional Evaluations), a weakly supervised
framework that learns to refine mask predictions only using light feedback
during training. Specifically, instead of relying on dense training image
annotations, SCORE introduces a novel loss that leverages region-wise quality
scores and over/under-segmentation error labels. We demonstrate SCORE on
humerus CT scans, where it considerably improves initial predictions from
TotalSegmentator, and achieves performance on par with existing refinement
methods, while greatly reducing their supervision requirements and annotation
time. Our code is available at: https://gitlab.inria.fr/adelangl/SCORE.

</details>


### [118] [Diffusion Models are Robust Pretrainers](https://arxiv.org/abs/2511.02793)
*Mika Yagoda,Shady Abu-Hussein,Raja Giryes*

Main category: eess.IV

TL;DR: 研究利用扩散模型进行图像分类和目标检测任务中的对抗鲁棒性，展示了扩散模型在提供低成本的鲁棒表达方面的重要性，同时在计算成本方面具有优势。


<details>
  <summary>Details</summary>
Motivation: 标准模型在图像分类和目标检测任务中面对对抗攻击时表现不佳，现有方法增加训练成本以提高模型鲁棒性，而本研究旨在探索扩散模型在实现对抗鲁棒性的同时减少计算成本的方法。

Method: 在预训练的扩散模型基础上构建新模型，并在固定特征上训练轻量级头部，避免了完整的对抗训练。

Result: 扩散模型在ImageNet，CIFAR-10和PASCAL VOC上的评估结果表明，在计算成本极低的情况下，基于扩散的分类器和检测器能实现具有意义的对抗鲁棒性。虽然模型的准确率低于现流行的对抗训练的CNN或ViT，但在计算资源受限的情况下，这种模型提供了一个更好的效率和鲁棒性的平衡点。

Conclusion: 这项工作为将扩散模型整合到资源有限的鲁棒性部署中提供了新的思路。

Abstract: Diffusion models have gained significant attention for high-fidelity image
generation. Our work investigates the potential of exploiting diffusion models
for adversarial robustness in image classification and object detection.
Adversarial attacks challenge standard models in these tasks by perturbing
inputs to force incorrect predictions. To address this issue, many approaches
use training schemes for forcing the robustness of the models, which increase
training costs. In this work, we study models built on top of off-the-shelf
diffusion models and demonstrate their practical significance: they provide a
low-cost path to robust representations, allowing lightweight heads to be
trained on frozen features without full adversarial training. Our empirical
evaluations on ImageNet, CIFAR-10, and PASCAL VOC show that diffusion-based
classifiers and detectors achieve meaningful adversarial robustness with
minimal compute. While clean and adversarial accuracies remain below
state-of-the-art adversarially trained CNNs or ViTs, diffusion pretraining
offers a favorable tradeoff between efficiency and robustness. This work opens
a promising avenue for integrating diffusion models into resource-constrained
robust deployments.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [119] [Analysis of Beam Misalignment Effect in Inter-Satellite FSO Links](https://arxiv.org/abs/2511.02189)
*Minje Kim,Hongjae Nam,Beomsoo Ko,Hyeongjun Park,Hwanjin Kim,Dong-Hyun Jung,Junil Choi*

Main category: cs.IT

TL;DR: 本文研究了自由空间光通信中的光束偏移问题，提出了一个新型的分析模型，该模型能够有效地计算中断概率，并且非常适用于实际的卫星间自由空间光通信系统的设计。


<details>
  <summary>Details</summary>
Motivation: 现有的自由空间光通信系统的性能极易受到光束偏移的影响，而现有的指向提前角度补偿方法依赖于精确的轨道知识和高级的对准硬件。这使得实际应用中难以实现高效对准。因此，该论文旨在改进现有的光束对准方法，使其适用于实际应用。

Method: 文章推导了自由空间光信道下联合抖动和偏移引起的指向误差的累计分布函数（CDF）的封闭式表达，使用截断CDF以及使用二分法算法计算中断概率。此外，通过轨道动力学量化了位移。

Result: 数值结果显示，所提出的模型与蒙特卡洛模拟结果非常接近，表明该模型在设计实际的卫星间自由空间光通信系统时非常实用。

Conclusion: 该论文提出的方法较现有技术而言，是更加准确和实用的，为优化卫星间的自由空间光通信系统的性能提供了新的途径。

Abstract: Free-space optical (FSO) communication has emerged as a promising technology
for inter-satellite links (ISLs) due to its high data rate, low power
consumption, and reduced interference. However, the performance of
inter-satellite FSO systems is highly sensitive to beam misalignment. While
pointing-ahead angle (PAA) compensation is commonly employed, the effectiveness
of PAA compensation depends on precise orbital knowledge and advanced alignment
hardware, which are not always feasible in practice. To address this challenge,
this paper investigates the impact of beam misalignment on inter-satellite FSO
communication. We derive a closed-form expression for the cumulative
distribution function (CDF) of the FSO channel under the joint jitter and
misalignment-induced pointing error, and introduce a truncated CDF formulation
with a bisection algorithm to efficiently compute outage probabilities with
guaranteed convergence and minimal computational overhead. To make the analysis
more practical, we quantify displacement based on orbital dynamics. Numerical
results demonstrate that the proposed model closely matches Monte Carlo
simulations, making the proposed model highly useful to design inter-satellite
FSO systems in practice.

</details>


### [120] [Fairness-Aware Computation Offloading in Wireless-Powered MEC Systems with Cooperative Energy Recycling](https://arxiv.org/abs/2511.02287)
*Haohao Qin,Bowen Gu,Dong Li,Xianhua Yu,Liejun Wang,Yuanwei Liu,Sumei Sun*

Main category: cs.IT

TL;DR: 本文研究了无线供电移动边缘计算系统中的合作能量回收(CER)。通过集成本地计算和计算卸载，形成一个优化问题，以平衡总体可计算数据和用户公平性，同时满足能量、延迟和任务大小的限制。通过变量替换技术将问题转化为凸结构，进而通过Lagrange对偶性和交替优化有效地解决。提出的方法在吞吐量和适应性上显着优于基准方案，且Alpha公平机制可灵活地在性能与公平性之间进行权衡。


<details>
  <summary>Details</summary>
Motivation: 现有架构通常依赖专门的电源。本文引入无线传感器能量回收机制，增加能源供应手段，旨在通过合作能量回收系统提高资源利用效率，优化计算性能，特别是在能量、延迟和任务大小约束下的系统性能。

Method: 本文将本地计算和计算卸载集成形成优化问题，通过变量替换技术将原问题转化为凸结构，使用Lagrange对偶性和交替优化算法求解。此外，为表征公平性与效率之间的权衡，推导了三种典型情况的闭式解：零公平性，常见公平性和最大最小公平性，以获得系统的层级洞察。

Result: 提出的CER框架在吞吐量和可适应性上明显优于基准方案。特别是通过alpha公平机制可以在不同的场景提供性能和公平性的灵活控制。联合计算优化问题能平衡总体计算数据和用户公平性，同时满足资源限制。根据拉格朗日对偶性和交替优化算法，得出的闭式解为系统性能提供了良好的理论支持和验证了优异的系统性能。

Conclusion: 合作能量回收策略在无线供电移动边缘计算系统中具有明显的优势，通过联合计算和卸载优化问题解决问题的同时，提供了更灵活、更高效的资源管理方式。系统在不同公平性设置下的表现表明了其优异的性能，展示了该框架在未来的实际应用中的巨大潜力。

Abstract: In this paper, cooperative energy recycling (CER) is investigated in
wireless-powered mobile edge computing systems. Unlike conventional
architectures that rely solely on a dedicated power source, wireless sensors
are additionally enabled to recycle energy from peer transmissions. To evaluate
system performance, a joint computation optimization problem is formulated that
integrates local computing and computation offloading, under an alpha-fairness
objective that balances total computable data and user fairness while
satisfying energy, latency, and task size constraints. Due to the inherent
non-convexity introduced by coupled resource variables and fairness
regularization, a variable-substitution technique is employed to transform the
problem into a convex structure, which is then efficiently solved using
Lagrangian duality and alternating optimization. To characterize the
fairness-efficiency tradeoff, closed-form solutions are derived for three
representative regimes: zero fairness, common fairness, and max-min fairness,
each offering distinct system-level insights. Numerical results validate the
effectiveness of the proposed CER-enabled framework, demonstrating significant
gains in throughput and adaptability over benchmark schemes. The tunable alpha
fairness mechanism provides flexible control over performance-fairness
trade-offs across diverse scenarios.

</details>


### [121] [Downlink Channel Estimation for mmWave Systems with Impulsive Interference](https://arxiv.org/abs/2511.02291)
*Kwonyeol Park,Gyoseung Lee,Hyeongtaek Lee,Hwanjin Kim,Junil Choi*

Main category: cs.IT

TL;DR: 本文提出了一种基于变分推理的贝叶斯信道估计技术，用于毫米波多输入多输出系统中的信道估计问题，该问题受到由硬件非理想性或外部干扰引起的脉冲干扰的影响。实验结果表明，所提出的算法在信道估计精度上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 研究中的问题是毫米波多输入多输出系统中由硬件非理想性或外部干扰引起的脉冲干扰导致的信道估计挑战。该干扰由于其突发性、不可预测性和高功率性质，导致信道估计误差较大。

Method: 提出的方法是基于变分推理的贝叶斯信道估计技术，利用毫米波信道在角度域的稀疏性和脉冲干扰的间歇性，通过均值场近似，将变分推理与稀疏贝叶斯学习框架相结合，以减少信道估计误差。

Result: 仿真结果显示，所提出的方法比基线方法在信道估计精度上表现更优。

Conclusion: 所提出的方法能够有效减少脉冲干扰引入的误差，提高毫米波MIMO系统的信道估计精度。

Abstract: In this paper, we investigate a channel estimation problem in a downlink
millimeter-wave (mmWave) multiple-input multiple-output (MIMO) system, which
suffers from impulsive interference caused by hardware non-idealities or
external disruptions. Specifically, impulsive interference presents a
significant challenge to channel estimation due to its sporadic, unpredictable,
and high-power nature. To tackle this issue, we develop a Bayesian channel
estimation technique based on variational inference (VI) that leverages the
sparsity of the mmWave channel in the angular domain and the intermittent
nature of impulsive interference to minimize channel estimation errors. The
proposed technique employs mean-field approximation to approximate posterior
inference and integrates VI into the sparse Bayesian learning (SBL) framework.
Simulation results demonstrate that the proposed technique outperforms
baselines in terms of channel estimation accuracy.

</details>


### [122] [Two-Parameter Rényi Information Quantities with Applications to Privacy Amplification and Soft Covering](https://arxiv.org/abs/2511.02297)
*Shi-Bing Li,Ke Li,Lei Yu*

Main category: cs.IT

TL;DR: 本文研究了两种参数的Rényi条件熵和两个参数的Rényi互信息，其中条件熵与Hayashi和Tan提出的定义一致，并且与量子Rényi条件熵的关系密切。提出了这些信息量的一些基本性质，并证明了它们在隐私放大和软覆盖问题中的应用可以表征强对偶指数。


<details>
  <summary>Details</summary>
Motivation: 在文献中，尽管受到不同应用的启发，但关于Rényi条件熵和Rényi互信息还没有被普遍接受的定义。本文旨在填补这一空白，引入并研究了两种参数的Rényi条件熵和两个参数的Rényi互信息。

Method: 通过变量变换研究了两种参数的Rényi条件熵，找到了它与Hayashi和Tan定义的一致性。且它是三个参数量子Rényi条件熵在经典情况下的特例。还研究了其基本属性，包括参数单调性，变分表达式等。并对相关Rényi互信息证明了非负性，可加性，数据处理不等式，参数单调性，变分表达式，以及凸性和凹性。

Result: 证明了这些信息量拥有多种重要特性，并展示了它们在隐私放大和软覆盖问题中基于Rényi散度的强对偶指数方面的表征能力。

Conclusion: 研究证实了提出的两种参数Rényi信息量在多个领域内的应用潜力，并表明它们提供了一种新的方式来理解隐私放大和软覆盖问题。

Abstract: There are no universally accepted definitions of R\'enyi conditional entropy
and R\'enyi mutual information, although motivated by different applications,
several definitions have been proposed in the literature. In this paper, we
consider a family of two-parameter R\'enyi conditional entropy and a family of
two-parameter R\'enyi mutual information. By performing a change of variables
for the parameters, the two-parameter R\'enyi conditional entropy we study
coincides precisely with the definition introduced by Hayashi and Tan [IEEE
Trans. Inf. Theory, 2016], and it also emerges naturally as the classical
specialization of the three-parameter quantum R\'enyi conditional entropy
recently put forward by Rubboli, Goodarzi, and Tomamichel [arXiv:2410.21976
(2024)]. We establish several fundamental properties of the two-parameter
R\'enyi conditional entropy, including monotonicity with respect to the
parameters and variational expression. The associated two-parameter R\'enyi
mutual information considered in this paper is new and it unifies three
commonly used variants of R\'enyi mutual information. For this quantity, we
prove several important properties, including the non-negativity, additivity,
data processing inequality, monotonicity with respect to the parameters,
variational expression, as well as convexity and concavity. Finally, we
demonstrate that these two-parameter R\'enyi information quantities can be used
to characterize the strong converse exponents in privacy amplification and soft
covering problems under R\'enyi divergence of order $\alpha \in (0, \infty)$.

</details>


### [123] [Anomaly Detection-Based UE-Centric Inter-Cell Interference Suppression](https://arxiv.org/abs/2511.02320)
*Kwonyeol Park,Hyuckjin Choi,Beomsoo Ko,Minje Kim,Gyoseung Lee,Daecheol Kwon,Hyunjae Park,Byungseung Kim,Min-Ho Shin,Junil Choi*

Main category: cs.IT

TL;DR: 提出了一种基于UE的干扰抑制方案，使用Z-refined深度支持向量数据描述来检测和抑制跨小区干扰，实验结果显示该方案在多种条件下优于基线方案并与理想辅助方案性能相当


<details>
  <summary>Details</summary>
Motivation: 在频谱重用不断增加的场景下，干扰会导致性能降低，需要有效的抑制方案来改进系统性能

Method: 提出了一种新的基于UE的干扰抑制方案，使用一种基于一类分类的异常检测技术，即Z-refined深度支持向量数据描述，用于检测和抑制跨小区干扰

Result: 该方案在不同的条件下比基线方案表现更好，实验表明该方案在实际测试中可以改善多种3GPP信道环境下的性能

Conclusion: Z-refined深度支持向量数据描述作为干扰抑制方案的有效性被验证，结合实际测试展示了其优越性

Abstract: The increasing spectral reuse can cause significant performance degradation
due to interference from neighboring cells. In such scenarios, developing
effective interference suppression schemes is necessary to improve overall
system performance. To tackle this issue, we propose a novel user
equipment-centric interference suppression scheme, which effectively detects
inter-cell interference (ICI) and subsequently applies interference whitening
to mitigate ICI. The proposed scheme, named Z-refined deep support vector data
description, exploits a one-class classification-based anomaly detection
technique. Numerical results verify that the proposed scheme outperforms
various baselines in terms of interference detection performance with limited
time or frequency resources for training and is comparable to the performance
based on an ideal genie-aided interference suppression scheme. Furthermore, we
demonstrate through test equipment experiments using a commercial
fifth-generation modem chipset that the proposed scheme shows performance
improvements across various 3rd generation partnership project standard channel
environments, including tapped delay line-A, -B, and -C models.

</details>


### [124] [$\mathbb{F}_q\mathbb{F}_{q^2}$-additive cyclic codes and their Gray images](https://arxiv.org/abs/2511.02325)
*Ankit Yadav,Ritumoni Sarma*

Main category: cs.IT

TL;DR: 研究了在字母表"mathbb{F}_{q}"mathbb{F}_{q^2}


<details>
  <summary>Details</summary>
Motivation: 研究"mathbb{F}_{q}"mathbb{F}_{q^2}

Method: 首先确定生成多项式和最小生成集，然后构造满足Singleton界的一些"mathbb{F}_{q^2}

Result: 通过Gray映射，产生了一些最佳的三元线性码。最后，从"mathbb{F}_{3}"mathbb{F}_{9}

Conclusion: 从"mathbb{F}_{q}"mathbb{F}_{q^2}

Abstract: We investigate additive cyclic codes over the alphabet
$\mathbb{F}_{q}\mathbb{F}_{q^2}$, where $q$ is a prime power. First, its
generator polynomials and minimal spanning set are determined. Then, examples
of $\mathbb{F}_{q^2}$-additive cyclic codes that satisfy the well-known
Singleton bound are constructed. Using a Gray map, we produce certain optimal
linear codes over $\mathbb{F}_{3}$. Finally, we obtain a few optimal ternary
linear complementary dual (LCD) codes from
$\mathbb{F}_{3}\mathbb{F}_{9}$-additive codes.

</details>


### [125] [Generalized informational functionals and new monotone measures of statistical complexity](https://arxiv.org/abs/2511.02502)
*Razvan Gabriel Iagar,David Puertas-Centeno*

Main category: cs.IT

TL;DR: 这篇论文引入了一种双参数变换族，这个新的变换类允许我们引入新的信息泛函，如\textit{down-moments}和\textit{累积upper-moments}。这类变换在一些情况下对$p$-矩和幂Rényi熵提供了一个插值，同时建立了新的不等式并将这些新泛函与经典的信息测度如矩、Rényi和Shannon熵以及Fisher信息测度联系起来。文章还定义了新的统计复杂性测度类，并确立了这些测度类的单调性，揭示了功能不等式的复杂结构。


<details>
  <summary>Details</summary>
Motivation: 动机是引入新的信息泛函\textit{down-moments}和\textit{累积upper-moments}，并通过它们建立与经典信息测度的联系以及不等式，揭示统计复杂性中的新特性。

Method: 通过构造一种双参数框式变换族，提供了\textit{down-moments}和\textit{累积upper-moments}的新定义，并通过它们与$p$-矩和幂Rényi熵建立了插值关系。进一步，定义了新的统计复杂性测度类并通过新的泛函建立了不等式。

Result: 获得了新的不等式关系并建立了新的信息功能类，揭示了功能测度中的新特性。此外，还找到了正在一些情况下以广义三角函数形式表达出优化界限的最佳密度函数。

Conclusion: 论文通过引入新的信息泛函和新定义的统计复杂性测度，揭示了功能不等式和统计复杂性的新特点和结构。

Abstract: In this paper we introduce a biparametric family of transformations which can
be seen as an extension of the so-called up and down transformations. This new
class of transformations allows to us to introduce new informational
functionals, which we have called \textit{down-moments} and \textit{cumulative
upper-moments}. A remarkable fact is that the down-moments provide, in some
cases, an interpolation between the $p$-th moments and the power R\'enyi
entropies of a probability density. We establish new and sharp inequalities
relating these new functionals to the classical informational measures such as
moments, R\'enyi and Shannon entropies and Fisher information measures. We also
give the optimal bounds as well as the minimizing densities, which are in some
cases expressed in terms of the generalized trigonometric functions. We
furthermore define new classes of measures of statistical complexity obtained
as quotients of the new functionals, and establish monotonicity properties for
them through an algebraic conjugation of up and down transformations. All of
these properties highlight an intricate structure of functional inequalities.

</details>


### [126] [Improved AntiGriesmer Bounds for Linear Anticodes and Applications](https://arxiv.org/abs/2511.02519)
*Guanghui Zhang,Bocong Chen,Liren Lin,Hongwei Liu*

Main category: cs.IT

TL;DR: 本文改进了Chen和Xie之前关于线性反码的antiGriesmer界。新结果消除了原码长限制，并放松了对偶距离条件至至少2。证明了对于任何$q$上的$[n,k]$线性反码$	extcal{C}$，若其直径为$	extdelta$且$	extmathbb{D}(	extcal{C}^	extperp) 	extgreater= 2$，则$n 	extless= 	extsum_{i=0}^{k-1} 	extlfloor 	extfrac{	extdelta}{q^i} 	extrfloor$。本文还推导了进一步的结果并讨论了线性反码的一些应用案例。


<details>
  <summary>Details</summary>
Motivation: 改进Chen和Xie关于反码的antiGriesmer界的限制，使之更广泛适用，同时推广线性反码的研究框架。

Method: 通过放松原有的距离条件，建立新的antiGriesmer不等式，取消了长度限制，降低了对偶距离的要求。证明了新不等式适用于任意线性反码。

Result: 提出的新antiGriesmer界放宽条件，提供更广泛的适用性。证明了相关的推论，如直径下界、码长上界等，并展示了实例表明新结果的优越性。

Conclusion: 本文改进了antiGriesmer界，提供了一个更加全面的框架来研究线性反码及其性质，并讨论了其在码类构造和分类中的应用。

Abstract: This paper improves the antiGriesmer bound for linear anticodes previously
established by Chen and Xie (Journal of Algebra, 673 (2025) 304-320). While the
original bound required the code length to satisfy $n < q^{k-1}$ and the dual
code to have minimum distance at least 3, our main result removes the length
restriction and relaxes the dual distance condition to at least 2.
Specifically, we prove that for any $[n,k]_q$ linear anticode $\mathcal{C}$
over $\mathbb{F}_q$ with diameter $\delta$ and $d(\mathcal{C}^\perp) \geq 2$,
the inequality \[ n \leq \sum_{i=0}^{k-1} \left\lfloor \frac{\delta}{q^i}
\right\rfloor \] holds. This generalization significantly broadens the
applicability of the antiGriesmer bound. We derive several corollaries,
including lower bounds on the diameter $\delta$ in terms of $n$ and $k$, upper
bounds on the code length $n$, and constraints on the dimension $k$.
Applications to the construction and classification of linear codes with few
weights are also discussed, along with examples demonstrating that our new
bound can be sharper than previous ones. Our work unifies and extends earlier
findings, providing a more comprehensive framework for studying linear
anticodes and their properties.

</details>


### [127] [Performance Analysis of Single-Antenna Fluid Antenna Systems via Extreme Value Theory](https://arxiv.org/abs/2511.02572)
*Rui Xu,Yinghui Ye,Xiaoli Chu,Guangyue Lu,Kai-Kit Wong,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 本文提出了一种新的单天线液体天线系统(FAS)在完全相关Rayleigh衰落下的性能评估框架，通过极大似然准则将FAS信道近似为耿贝尔分布来提高链路可靠性。然而，对于极端概率区域的小偏差，本文进一步改进框架，采用广义极值(GEV)分布，确保更准确的计算。仿真结果表明，基于GEV的框架优于基于耿贝尔的模型，而两种EVD方法均可提供计算效率和数学分析性手段来评估FAS在现实相关衰落条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 为了在完全相关衰落环境下精确且可操作地表达单天线液体天线系统(FAS)的性能，本文开发了一种新的性能评估框架，通过采用极值分布(EVDs)来解决由于没有封闭形式的FAS信道分布导致的性能表达困难。

Method: 该模型首先通过极大似然准则将FAS信道近似为耿贝尔分布，其参数与端口数和天线孔径大小有关。然后根据广义极值(GEV)分布进一步改进此框架，以提高在极端概率区域的准确性。使用模拟结果验证了GEV方法的改进效果。

Result: 该文成功建立了基于GEV的框架，实现了比基于Gumbel模型更高的准确性，同时两种EVD方法均可作为计算效率高且数学分析性强的工具，可用于评估FAS在真实条件下相关衰落的性能。

Conclusion: 该研究为评估单天线液体天线系统在完全相关衰落下的性能提供了一种新的方法论，通过采用广义极值分布提高了模型的精度和实用性。

Abstract: In single-antenna fluid antenna systems (FASs), the transceiver dynamically
selects the antenna port with the strongest instantaneous channel to enhance
link reliability. However, deriving accurate yet tractable performance
expressions under fully correlated fading remains challenging, primarily due to
the absence of a closed-form distribution for the FAS channel. To address this
gap, this paper develops a novel performance evaluation framework for FAS
operating under fully correlated Rayleigh fading, by modeling the FAS channel
through extreme value distributions (EVDs). We first justify the suitability of
EVD modeling and approximate the FAS channel through the Gumbel distribution,
with parameters expressed as functions of the number of ports and the antenna
aperture size via the maximum likelihood (ML) criterion. Closed-form
expressions for the outage probability (OP) and ergodic capacity (EC) are then
derived. While the Gumbel model provides an excellent fit, minor deviations
arise in the extreme-probability regions. To further improve accuracy, we
extend the framework using the generalized extreme value (GEV) distribution and
obtain closed-form OP and EC approximations based on ML-derived parameters.
Simulation results confirm that the proposed GEV-based framework achieves
superior accuracy over the Gumbel-based model, while both EVD-based approaches
offer computationally efficient and analytically tractable tools for evaluating
the performance of FAS under realistic correlated fading conditions.

</details>


### [128] [Optimal Source Coding of Markov Chains for Real-Time Remote Estimation](https://arxiv.org/abs/2511.02803)
*Ismail Cosandal,Sennur Ulukus*

Main category: cs.IT

TL;DR: 本文重新审视了Markov链在相同时间尺度下的源编码问题，旨在通过基于最后传输符号及其传输时长的策略，最小化无限时间框架内的平均传输时长。通过引入Markov决策过程（MDP）模型，最终提出了最优策略并对比了基于Huffman的基准策略，发现所提出的最优策略在某些随机生成的流程中减少了平均传输时长。


<details>
  <summary>Details</summary>
Motivation: 问题在于对于Markov链，在相同的时隙中进行比特传输及状态更新时，如何有效编码以减少平均传输时长。这一问题未被充分探讨，具有重要的实际意义和理论价值。因此，论文尝试提出新的源编码策略来解决这一问题。

Method: 论文通过将符号及其传输时长加入到Markov决策过程（MDP）中，构建了问题模型。提出了基于最后传输符号及其传输时长的最优源编码策略，并将其性能与两种基于Huffman编码的基准策略进行了比较。

Result: 随机生成流程的实例展示了，所提出的策略有助于减少平均传输时长，并且这种性能增益在不同程度的Markov过程参数下有所不同。

Conclusion: 本文成功提出了一种新的源编码策略，实现了在时间资源的高效利用，验证了在特定条件下使用该策略的优越性，未来的研究可以进一步优化并扩展这一模型。

Abstract: We revisit the source coding problem for a Markov chain under the assumption
that the transmission times and how fast the Markov chain transitions its state
happen at the same time-scale. Specifically, we assume that the transmission of
each bit takes a single time slot, and the Markov chain updates its state in
the same time slot. Thus, the length of the codeword assigned to a symbol
determines the number of non-transmitted symbols, as well as, the probability
of the realization of the next symbol to be transmitted. We aim to minimize the
average transmission duration over an infinite horizon by proposing an optimal
source coding policy based on the last transmitted symbol and its transmission
duration. To find the optimal policy, we formulate the problem with a Markov
decision process (MDP) by augmenting the symbols alongside the transmission
duration of the symbols. Finally, we analyze two Huffman-based benchmark
policies and compare their performances with the proposed optimal policy. We
observe that, in randomly generated processes, our proposed optimal policy
decreases the average transmission duration compared to benchmark policies. The
performance gain varies based on the parameters of the Markov process.

</details>


### [129] [A Construction of Infinite Families of Self-Orthogonal Quasi-Cyclic Codes Using Constituent Codes.pdf](https://arxiv.org/abs/2511.02813)
*Gustavo Terra Bastos,Angelynn Álvarez,Cameron Williams*

Main category: cs.IT

TL;DR: 提出了一种构造自正交准循环码的方法，这些准循环码相对于欧几里得和海伦内积而言，并通过其构成代码计算了它们的维度和最小距离的下界。同时使用CSS构造展示了量子纠错码的存在性及其参数表现良好。


<details>
  <summary>Details</summary>
Motivation: 准循环码被用于量子纠错码的构造之中，旨在提出新的构造方法来获得性能更好的量子纠错码。特别是，这种新的构造方法涉及自正交准循环码，相关参数条件被明确给出。

Method: 通过定义在	extbf{$	ext{F}_q$的扩域}上的构成码来构造一系列准循环码，它们在欧几里得和Hermitian内积下是自正交的，并计算了它们的维度和最小距离的下界。此外，展示了自对偶准循环码的构造方法，并利用该方法构造了一系列量子纠错码。

Result: 获得了自正交准循环码的参数，并证明了最小距离的下界满足平方根样下界条件。同时，利用CSS构造方法展示了一系列具有良好参数的量子纠错码的存在性。

Conclusion: 这项研究提出了一种新的构造自正交准循环码的方法，并展示了这些码在量子纠错码构造中的潜力。

Abstract: Quasi-cyclic codes have been recently employed in the constructions of
quantum error-correcting codes. In this paper, we propose a construction of
infinite families of quasi-cyclic codes which are self-orthogonal with respect
to the Euclidean and Hermitian inner products. In particular, their dimension
and a lower bound for their minimum distance are computed using their
constituent codes defined over field extensions of $\mathbb{F}_q$. We also show
that the lower bound for the minimum distance satisfies the square-root-like
lower bound and also show how self-dual quasi-cyclic codes can arise from our
construction. Using the CSS construction, we show the existence of quantum
error-correcting codes with good parameters.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [130] [Deep Value Benchmark: Measuring Whether Models Generalize Deep values or Shallow Preferences](https://arxiv.org/abs/2511.02109)
*Joshua Ashkinaze,Hua Shen,Sai Avula,Eric Gilbert,Ceren Budak*

Main category: cs.AI

TL;DR: 本文介绍了Deep Value Benchmark (DVB)，这是一种评估大语言模型是否学习到了基本人类价值观而非表层偏好偏好的框架。该框架通过引入一种新的实验设计来测试模型是否能根据深层价值观进行选择，而不是仅仅表层特征。研究发现，所有模型的深层价值观泛化率（DVGR）都低于随机水平，且更大规模的模型泛化率更低。DVB 提供了一个可解释的度量标准，用于衡量对齐的核心特征。


<details>
  <summary>Details</summary>
Motivation: 动机是区分语言模型是否学习到了深层价值观，而不是表面偏好，这一区别对于人工智能的对齐至关重要。具有深层价值观的系统更能够更好地理解人类意图，而仅捕获偏好数据表面图案的系统可能产生不对齐的行为。

Method: 方法是使用一种新型实验设计，通过控制深层价值观与浅层特征之间的混淆，在训练阶段让语言模型接触到被人为相关联的深层价值观和浅层特征之间的偏好数据，在测试阶段则忽略这些相关性。从而精确测量语言模型的深层价值观泛化率（DVGR）。

Result: 实验结果显示，在9个不同模型中进行测试后，平均 DVGR 仅为0.30。所有模型都将深层价值观泛化低于随机水平，规模更大的模型DVGR更低。

Conclusion: 结论是，DVB 是一种可解释的度量标准，可以用来检测系统对齐的核心特征以及语言模型学习深层价值观的能力。

Abstract: We introduce the Deep Value Benchmark (DVB), an evaluation framework that
directly tests whether large language models (LLMs) learn fundamental human
values or merely surface-level preferences. This distinction is critical for AI
alignment: Systems that capture deeper values are likely to generalize human
intentions robustly, while those that capture only superficial patterns in
preference data risk producing misaligned behavior. The DVB uses a novel
experimental design with controlled confounding between deep values (e.g.,
moral principles) and shallow features (e.g., superficial attributes). In the
training phase, we expose LLMs to human preference data with deliberately
correlated deep and shallow features -- for instance, where a user consistently
prefers (non-maleficence, formal language) options over (justice, informal
language) alternatives. The testing phase then breaks these correlations,
presenting choices between (justice, formal language) and (non-maleficence,
informal language) options. This design allows us to precisely measure a
model's Deep Value Generalization Rate (DVGR) -- the probability of
generalizing based on the underlying value rather than the shallow feature.
Across 9 different models, the average DVGR is just 0.30. All models generalize
deep values less than chance. Larger models have a (slightly) lower DVGR than
smaller models. We are releasing our dataset, which was subject to three
separate human validation experiments. DVB provides an interpretable measure of
a core feature of alignment.

</details>


### [131] [InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance](https://arxiv.org/abs/2511.02119)
*Ziheng Geng,Jiachen Liu,Ran Cao,Lu Cheng,Dan M. Frangopol,Minghui Cheng*

Main category: cs.AI

TL;DR: 研究构建了一个数据集来捕捉影响保险购买概率的因素，并提出了一种名为InsurAgent的模型，该模型结合了大型语言模型（LLMs）来模拟人类决策，提高保险购买概率的估计准确性。


<details>
  <summary>Details</summary>
Motivation: 美国面临洪水风险的人口参与洪水保险的比率仍然非常低。利用大型语言模型（LLMs）的潜力来理解和模拟保险购买决策的行为机制。

Method: 构建了一个基准数据集，评估了大型语言模型在理解和估算保险购买概率方面的能力，发现尽管模型对因素的理解定性上准确，但在定量估计方面存在不足。提出了一个包含五个模块（感知、检索、推理、行动和记忆）的InsurAgent，其中检索模块使用检索增强生成（RAG）来支撑决策，推理模块利用LLM的常识能力进行外推，记忆模块帮助模拟时间上的决策演变。

Result: InsurAgent能够准确估计边际和双变量概率，通过模拟现实生活轨迹，捕捉上下文信息，提高了保险购买概率的估计准确性。

Conclusion: 结果表明，InsurAgent可以为行为建模和政策分析提供有价值的工具。

Abstract: Flood insurance is an effective strategy for individuals to mitigate
disaster-related losses. However, participation rates among at-risk populations
in the United States remain strikingly low. This gap underscores the need to
understand and model the behavioral mechanisms underlying insurance decisions.
Large language models (LLMs) have recently exhibited human-like intelligence
across wide-ranging tasks, offering promising tools for simulating human
decision-making. This study constructs a benchmark dataset to capture insurance
purchase probabilities across factors. Using this dataset, the capacity of LLMs
is evaluated: while LLMs exhibit a qualitative understanding of factors, they
fall short in estimating quantitative probabilities. To address this
limitation, InsurAgent, an LLM-empowered agent comprising five modules
including perception, retrieval, reasoning, action, and memory, is proposed.
The retrieval module leverages retrieval-augmented generation (RAG) to ground
decisions in empirical survey data, achieving accurate estimation of marginal
and bivariate probabilities. The reasoning module leverages LLM common sense to
extrapolate beyond survey data, capturing contextual information that is
intractable for traditional models. The memory module supports the simulation
of temporal decision evolutions, illustrated through a roller coaster life
trajectory. Overall, InsurAgent provides a valuable tool for behavioral
modeling and policy analysis.

</details>


### [132] [Re-FORC: Adaptive Reward Prediction for Efficient Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.02130)
*Renos Zabounidis,Aditya Golatkar,Michael Kleinman,Alessandro Achille,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: Re-FORC 是一种自适应的奖励预测方法，可以预测未来奖励，从而提高推理模型的性能和效率。它可以在不牺牲准确性的前提下减少计算量，或者在相同计算量下提高准确性，并支持测试时的自适应调整以进一步提高准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的推理模型难以自适应地优化奖励预测和计算资源使用，导致计算资源浪费或准确性损失。解决这个问题是Re-FORC方法提出的动机。

Method: Re-FORC 方法通过训练轻量级适配器来预测给定上下文下的预期未来奖励，并实现动态地停止无望的推理序列，选择合适的模型大小和思考长度，以及在测试时自适应地调整模型的规模，减少计算资源大量消耗。

Result: 实验结果显示，Re-FORC 方法在减少计算资源使用的同时保持准确性，且在相同计算量下提高了4%的准确性，以及在计算量相同的情况下减少了55%的计算资源使用，从而验证了其有效性。此外，在高计算资源和低计算资源环境下，准确性分别提高了11%和7%。

Conclusion: Re-FORC 通过自适应预测未来奖励和动态调整模型推理过程中的参数选择，有效地优化了计算资源分配，提高了模型的运行效率和准确性。

Abstract: We propose Re-FORC, an adaptive reward prediction method that, given a
context, enables prediction of the expected future rewards as a function of the
number of future thinking tokens. Re-FORC trains a lightweight adapter on
reasoning models, demonstrating improved prediction with longer reasoning and
larger models. Re-FORC enables: 1) early stopping of unpromising reasoning
chains, reducing compute by 26% while maintaining accuracy, 2) optimized model
and thinking length selection that achieves 4% higher accuracy at equal compute
and 55% less compute at equal accuracy compared to the largest model, 3)
adaptive test-time scaling, which increases accuracy by 11% in high compute
regime, and 7% in low compute regime. Re-FORC allows dynamic reasoning with
length control via cost-per-token thresholds while estimating computation time
upfront.

</details>


### [133] [Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic Reasoning](https://arxiv.org/abs/2511.02194)
*Yibo Zhao,Yang Zhao,Hongru Du,Hao Frank Yang*

Main category: cs.AI

TL;DR: ATHENA框架通过结合符号效用发现和语义适应，提出了一种新的针对人类中心决策的建模方案。在真实世界的旅行模式和疫苗选择任务上，ATHENA的表现优于效用模型、机器学习以及其他基于LLM的模型，F1分数提高了至少6.5%。


<details>
  <summary>Details</summary>
Motivation: 传统决策模型在某些情况下（例如疫苗接种）的预测与实际情况存在差距。这是由于个体决策过程的独特性，受到数值属性和语言影响的影响。ATHENA框架旨在解决个体决策过程中信息整合的最佳方式，以更准确地预测和理解人类决策行为。

Method: ATHENA框架结合了两个阶段：第一阶段，通过基于LLM的符号发现来获取稳定的群体级别的效用函数；第二阶段，实现个性化语义适应，通过最优效用创建个性化的语义模板来模拟个性化决策。

Result: 实验结果表明，ATHENA在真实世界任务上的表现优于基于效用的、机器学习和其他基于LLM的模型，F1分数提高了至少6.5%。此外，剔除ATHENA的任一阶段都会降低预测性能，这说明了两个阶段的重要性。

Conclusion: ATHENA提供了一种新的人类中心决策建模方法，通过有机整合符号效用模型和语义适应，ATHENA能够更准确地模拟和预测人类决策。

Abstract: Decision-making models for individuals, particularly in high-stakes scenarios
like vaccine uptake, often diverge from population optimal predictions. This
gap arises from the uniqueness of the individual decision-making process,
shaped by numerical attributes (e.g., cost, time) and linguistic influences
(e.g., personal preferences and constraints). Developing upon Utility Theory
and leveraging the textual-reasoning capabilities of Large Language Models
(LLMs), this paper proposes an Adaptive Textual-symbolic Human-centric
Reasoning framework (ATHENA) to address the optimal information integration.
ATHENA uniquely integrates two stages: First, it discovers robust, group-level
symbolic utility functions via LLM-augmented symbolic discovery; Second, it
implements individual-level semantic adaptation, creating personalized semantic
templates guided by the optimal utility to model personalized choices.
Validated on real-world travel mode and vaccine choice tasks, ATHENA
consistently outperforms utility-based, machine learning, and other LLM-based
models, lifting F1 score by at least 6.5% over the strongest cutting-edge
models. Further, ablation studies confirm that both stages of ATHENA are
critical and complementary, as removing either clearly degrades overall
predictive performance. By organically integrating symbolic utility modeling
and semantic adaptation, ATHENA provides a new scheme for modeling
human-centric decisions. The project page can be found at
https://yibozh.github.io/Athena.

</details>


### [134] [TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning in Tabular Data](https://arxiv.org/abs/2511.02219)
*Changjiang Jiang,Fengchang Yu,Haihua Chen,Wei Lu,Jin Zeng*

Main category: cs.AI

TL;DR: 提出了一种名为\method的框架，以改善大型语言模型在处理复杂问题和噪声数据时的表现，尤其是在处理复杂表格数值推理任务中。实验表明，该框架在多个数据集上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理复杂查询、噪声数据及数值能力受限时表现不佳，因此提出了一种新方法来解决这些问题。

Method: \method框架包括：（1）查询分解器，用于分解复杂的问题；（2）表格净化器，用于清理和过滤噪声表格；以及（3）基于程序思维（PoT）的推理器，用于生成代码以从净化后的表格中得出最终答案。我们还介绍了一个新的数据集CalTab151，专门用于复杂的数值推理。

Result: \method框架在TAT-QA、TableBench和其他数据集中比现有方法表现出色，分别提高了8.79%，6.08%和19.87%的准确性。此外，该框架还能够与主流语言模型无缝集成。

Conclusion: 我们的工作展示了在复杂表格数值推理任务中，\method框架可以显著提升大型语言模型的性能。

Abstract: Complex reasoning over tabular data is crucial in real-world data analysis,
yet large language models (LLMs) often underperform due to complex queries,
noisy data, and limited numerical capabilities. To address these issues, we
propose \method, a framework consisting of: (1) a query decomposer that breaks
down complex questions, (2) a table sanitizer that cleans and filters noisy
tables, and (3) a program-of-thoughts (PoT)-based reasoner that generates
executable code to derive the final answer from the sanitized table. To ensure
unbiased evaluation and mitigate data leakage, we introduce a new dataset,
CalTab151, specifically designed for complex numerical reasoning over tables.
Experimental results demonstrate that \method consistently outperforms existing
methods, achieving state-of-the-art (SOTA) performance with 8.79%, 6.08%, and
19.87% accuracy improvement on TAT-QA, TableBench, and \method, respectively.
Moreover, our framework integrates seamlessly with mainstream LLMs, providing a
robust solution for complex tabular numerical reasoning. These findings
highlight the effectiveness of our framework in enhancing LLM performance for
complex tabular numerical reasoning. Data and code are available upon request.

</details>


### [135] [When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs Preference Dynamics in MLLMs](https://arxiv.org/abs/2511.02243)
*Zhuoran Zhang,Tengyue Wang,Xilin Gong,Yang Shi,Haotian Wang,Di Wang,Lijie Hu*

Main category: cs.AI

TL;DR: 本文提出了一个新框架来分解多模态跟随行为，将其归结为相对推理不确定性和固有模态偏好两个基本因素，并通过建立可控数据集验证此框架，揭示了模态跟随的内在机制。


<details>
  <summary>Details</summary>
Motivation: 以前的工作只是粗略地用数据集级别的统计数据来测量多模态大语言模型（MLLMs）处理模态冲突的行为，但忽略了模型在单模态推理中的置信度的影响。本文旨在通过引入一个新框架，更深入地研究模态跟随行为背后的原因和机制。

Method: 作者构建了一个可控数据集，该数据集系统地变化了视觉和文本输入的推理难度，并使用熵作为精细的不确定性度量来捕获相对不确定性，同时也探究了模型内部的层级预测来揭示模态跟随的波动机制。

Result: 通过实验验证，作者发现一种普遍规律：随着某一模态的相对不确定性增加，模型遵循该模态的概率单调减少。在双模态平衡点处，模型在两模态间切换，呈现出决策不决的状态。这一发现有助于更合理地理解与描述模型的固有偏好，而非依赖宏观比例。

Conclusion: 本文提出了相对不确定性和固有偏好作为多模态跟随行为的两个支配原则，为理解MLLMs如何处理模态冲突提供了定量框架和机制性见解。

Abstract: Multimodal large language models (MLLMs) must resolve conflicts when
different modalities provide contradictory information, a process we term
modality following. Prior work measured this behavior only with coarse
dataset-level statistics, overlooking the influence of model's confidence in
unimodal reasoning. In this paper, we introduce a new framework that decomposes
modality following into two fundamental factors: relative reasoning uncertainty
(the case-specific confidence gap between unimodal predictions) and inherent
modality preference( a model's stable bias when uncertainties are balanced). To
validate this framework, we construct a controllable dataset that
systematically varies the reasoning difficulty of visual and textual inputs.
Using entropy as a fine-grained uncertainty metric, we uncover a universal law:
the probability of following a modality decreases monotonically as its relative
uncertainty increases. At the relative difficulty level where the model tends
to follow both modalities with comparable probability what we call the balance
point, a practical indicator of the model's inherent preference. Unlike
traditional macro-level ratios, this measure offers a more principled and less
confounded way to characterize modality bias, disentangling it from unimodal
capabilities and dataset artifacts. Further, by probing layer-wise predictions,
we reveal the internal mechanism of oscillation: in ambiguous regions near the
balance point, models vacillate between modalities across layers, explaining
externally observed indecision. Together, these findings establish relative
uncertainty and inherent preference as the two governing principles of modality
following, offering both a quantitative framework and mechanistic insight into
how MLLMs resolve conflicting information.

</details>


### [136] [Chronic Kidney Disease Prognosis Prediction Using Transformer](https://arxiv.org/abs/2511.02340)
*Yohan Lee,DongGyun Kang,SeHoon Park,Sa-Yoon Park,Kwangsoo Kim*

Main category: cs.AI

TL;DR: 本文提出了一种基于变压器框架的慢性肾脏疾病（CKD）进展预测方法，利用多模态电子健康记录数据，取得了较高的预测准确性。该方法对个性化CKD护理具有前景。


<details>
  <summary>Details</summary>
Motivation: 慢性肾脏疾病（CKD）影响全球约10%的人口，常进展为终末期肾功能衰竭。准确的预后预测对于及时干预和资源优化至关重要。当前基于电子健康记录（EHR）的模型预测效果不理想，因此提出ProQ-BERT模型，以提高CKD进展预测的准确性。

Method: ProQ-BERT模型使用多模态电子健康记录（EHR）作为输入，包括人口统计、临床和实验室数据，并采用量化基元标记化方法处理连续的实验室值和注意力机制提高可解释性。模型先通过掩码语言模型进行预训练，然后针对从3a阶段进展到5阶段的二元分类任务进行微调。

Result: 在91,816名患者队列的评估中，ProQ-BERT模型在短期内预测方面优于CEHR-BERT，实现了高达0.995的ROC-AUC和0.989的PR-AUC。这些结果突显了变压器架构和时间层面设计选择在临床预后建模中的有效性。

Conclusion: 研究证明了ProQ-BERT模型在CKD进展预测上的优越性能，为个性化CKD护理提供了一条有希望的发展方向。

Abstract: Chronic Kidney Disease (CKD) affects nearly 10\% of the global population and
often progresses to end-stage renal failure. Accurate prognosis prediction is
vital for timely interventions and resource optimization. We present a
transformer-based framework for predicting CKD progression using multi-modal
electronic health records (EHR) from the Seoul National University Hospital
OMOP Common Data Model. Our approach (\textbf{ProQ-BERT}) integrates
demographic, clinical, and laboratory data, employing quantization-based
tokenization for continuous lab values and attention mechanisms for
interpretability. The model was pretrained with masked language modeling and
fine-tuned for binary classification tasks predicting progression from stage 3a
to stage 5 across varying follow-up and assessment periods. Evaluated on a
cohort of 91,816 patients, our model consistently outperformed CEHR-BERT,
achieving ROC-AUC up to 0.995 and PR-AUC up to 0.989 for short-term prediction.
These results highlight the effectiveness of transformer architectures and
temporal design choices in clinical prognosis modeling, offering a promising
direction for personalized CKD care.

</details>


### [137] [Fuzzy Soft Set Theory based Expert System for the Risk Assessment in Breast Cancer Patients](https://arxiv.org/abs/2511.02392)
*Muhammad Sheharyar Liaqat*

Main category: cs.AI

TL;DR: 提出了一种基于模糊软集理论的专家系统，用于评估患者乳腺癌的风险，该系统利用易于获取的临床和生理参数进行风险评估，以帮助医生识别高风险患者并决定是否需要进一步的诊断程序如活检。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是导致女性死亡的主要原因之一，早期诊断对于有效治疗和改进生存率至关重要。然而，由于疾病复杂性和患者风险因素的变化，及时检测仍然是一个挑战。因此，开发了一个专家系统来帮助识别高风险患者，从而提高早期诊断的可能性。

Method: 该系统使用模糊推理规则和软集计算，结合体重指数、胰岛素水平、瘦素水平、脂联素水平和年龄等参数，这些参数可以通过常规血液分析获取，从而实现了非侵入性和易于访问的初步评估方法。模型开发和验证的数据集来自UCI机器学习资源库。

Result: 通过使用上述方法，该系统能够在很大程度上准确地预测乳腺癌的风险，有助于优化医疗资源的分配，提高患者的治疗效果。

Conclusion: 该研究提出了一种基于模糊软集理论的专家系统，该系统可用于评估患者乳腺癌的风险，并可能有助于改进早期诊断过程。

Abstract: Breast cancer remains one of the leading causes of mortality among women
worldwide, with early diagnosis being critical for effective treatment and
improved survival rates. However, timely detection continues to be a challenge
due to the complex nature of the disease and variability in patient risk
factors. This study presents a fuzzy soft set theory-based expert system
designed to assess the risk of breast cancer in patients using measurable
clinical and physiological parameters. The proposed system integrates Body Mass
Index, Insulin Level, Leptin Level, Adiponectin Level, and age as input
variables to estimate breast cancer risk through a set of fuzzy inference rules
and soft set computations. These parameters can be obtained from routine blood
analyses, enabling a non-invasive and accessible method for preliminary
assessment. The dataset used for model development and validation was obtained
from the UCI Machine Learning Repository. The proposed expert system aims to
support healthcare professionals in identifying high-risk patients and
determining the necessity of further diagnostic procedures such as biopsies.

</details>


### [138] [A New Perspective on Precision and Recall for Generative Models](https://arxiv.org/abs/2511.02414)
*Benjamin Sykes,Loïc Simon,Julien Rabin,Jalal Fadili*

Main category: cs.AI

TL;DR: 本文提出了一种基于二分类的新框架来估计生成模型的Precision和Recall曲线，进行了彻底的统计分析，并为PR估计风险获得了最小最大上界，同时该框架还扩展了文献中一些著名且仅限于曲线端点的PR度量标准。实验中研究了在各种设置下获得的曲线的不同行为。


<details>
  <summary>Details</summary>
Motivation: 文章旨在解决基于生成模型的评估问题，尤其是在使用Precision和Recall评估方法时存在的挑战。提出的新框架可以更全面地分析生成模型性能。

Method: 基于二分类的方法来估计生成模型的Precision和Recall曲线。进行了详细的统计分析并提出了一个关于PR估计风险的最小最大上界。此外，该方法能扩展文献中的一些著名且仅限于曲线端点的PR度量标准。

Result: 新框架能够估计完整的Precision和Recall曲线，理论上和实践上都证明了该方法的有效性。实验结果表明框架能很好地处理不同设置下的曲线行为。

Conclusion: 本文提出的新框架为评估生成模型提供了一个有力的工具，不仅在理论上证明了其有效性，同时实验也验证了该方法在不同情况下的通用性和准确性。

Abstract: With the recent success of generative models in image and text, the question
of their evaluation has recently gained a lot of attention. While most methods
from the state of the art rely on scalar metrics, the introduction of Precision
and Recall (PR) for generative model has opened up a new avenue of research.
The associated PR curve allows for a richer analysis, but their estimation
poses several challenges. In this paper, we present a new framework for
estimating entire PR curves based on a binary classification standpoint. We
conduct a thorough statistical analysis of the proposed estimates. As a
byproduct, we obtain a minimax upper bound on the PR estimation risk. We also
show that our framework extends several landmark PR metrics of the literature
which by design are restrained to the extreme values of the curve. Finally, we
study the different behaviors of the curves obtained experimentally in various
settings.

</details>


### [139] [Auditable-choice reframing unlocks RL-based verification for open-ended tasks](https://arxiv.org/abs/2511.02463)
*Mengyu Zhang,Xubo Liu,Siyu Ding,Weichong Yin,Yu Sun,Hua Wu,Wenya Guo,Ying Zhang*

Main category: cs.AI

TL;DR: 此研究提出一种新的训练策略，即可验证的多选题重构（VMR），将开放性任务转换为可验证的多选题格式，从而在没有明确标准答案的情况下也能有效地进行训练。实验在多个基准测试集上验证了该方法的有效性，在8个开放性任务基准测试集上，与基准相比，平均增益为5.99分。 


<details>
  <summary>Details</summary>
Motivation: 现有的研究通常将缺乏标准答案的开放性任务视为非推理场景，忽略了推理能力的潜在价值。本研究尝试将RLVR范式应用于开放性任务，探索增强推理能力是否可以提升开放性任务的表现。 

Method: 提出了一种新的训练策略——可验证的多选题重构（VMR），以解决RLVR范式在开放性任务中的应用难题，该策略将开放性任务数据转化为可验证的多选题格式，以便在没有明确标准答案的情况下进行有效的训练。 

Result: 实验结果表明，该方法在多个开放性任务基准测试集上表现出色，与基准相比，平均增益达到了5.99分。这证明了VMR策略的有效性。 

Conclusion: 研究成功将RLVR范式应用于开放性任务中，通过VMR策略证明了加强推理能力可以提升开放性任务的表现。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated great
potential in enhancing the reasoning capabilities of large language models
(LLMs), achieving remarkable progress in domains such as mathematics and
programming where standard answers are available. However, for open-ended tasks
lacking ground-truth solutions (e.g., creative writing and instruction
following), existing studies typically regard them as non-reasoning scenarios,
thereby overlooking the latent value of reasoning capabilities. This raises a
key question: Can strengthening reasoning improve performance in open-ended
tasks? To address this, we explore the transfer of the RLVR paradigm to the
open domain. Yet, since RLVR fundamentally relies on verifiers that presuppose
the existence of standard answers, it cannot be directly applied to open-ended
tasks. To overcome this challenge, we introduce Verifiable Multiple-Choice
Reformulation (VMR), a novel training strategy that restructures open-ended
data into verifiable multiple-choice formats, enabling effective training even
in the absence of explicit ground truth. Experimental results on multiple
benchmarks validate the effectiveness of our method in improving LLM
performance on open-ended tasks. Notably, across eight open-ended benchmarks,
our VMR-based training delivers an average gain of 5.99 points over the
baseline. Code will be released upon acceptance to facilitate reproducibility.

</details>


### [140] [Knowledge Graph-enhanced Large Language Model for Incremental Game PlayTesting](https://arxiv.org/abs/2511.02534)
*Enhong Mu,Jinyu Cai,Yijun Lu,Mingyue Zhang,Kenji Tei,Jialong Li*

Main category: cs.AI

TL;DR: 本文提出了一种基于知识图谱的框架KLPEG，用于提高现代游戏的精细和高效的测试。该框架使用大型语言模型解析更新日志，结合知识图谱进行推理，从而生成针对更新定制的测试用例。在Overcooked和Minecraft两个游戏中的实验表明，KLPEG提高了测试的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现代视频游戏中快速迭代和频繁更新带来了测试效率和精确度上的挑战。尽管基于大型语言模型的自动化测试方法显示出潜力，但它们通常缺乏结构性的知识积累机制，使得针对增量游戏更新的精准且高效的测试难以实现。为了解决这个问题，本文提出了一种框架。

Method: 该框架通过构建和维护一个知识图谱，系统地建模游戏元素，任务依赖关系和因果关系，实现知识的积累和重用。与此同时，该框架使用大型语言模型解析自然语言更新记录，通过多跳推理来确定更新范围，生成更新特化测试用例。

Result: 在两个代表性的游戏环境（Overcooked和Minecraft）中进行的实验表明，KLPEG能够更准确地定位更新影响的功能，并且以更少的步骤完成测试，从而显著提高了测试的有效性和效率。

Conclusion: 本研究提出了KLPEG框架，以解决现代游戏频繁更新带来的测试挑战，通过构造和推理知识图谱来生成有针对性的测试脚本，从而提高测试的效果和效率。

Abstract: The rapid iteration and frequent updates of modern video games pose
significant challenges to the efficiency and specificity of testing. Although
automated playtesting methods based on Large Language Models (LLMs) have shown
promise, they often lack structured knowledge accumulation mechanisms, making
it difficult to conduct precise and efficient testing tailored for incremental
game updates. To address this challenge, this paper proposes a KLPEG framework.
The framework constructs and maintains a Knowledge Graph (KG) to systematically
model game elements, task dependencies, and causal relationships, enabling
knowledge accumulation and reuse across versions. Building on this foundation,
the framework utilizes LLMs to parse natural language update logs, identify the
scope of impact through multi-hop reasoning on the KG, enabling the generation
of update-tailored test cases. Experiments in two representative game
environments, Overcooked and Minecraft, demonstrate that KLPEG can more
accurately locate functionalities affected by updates and complete tests in
fewer steps, significantly improving both playtesting effectiveness and
efficiency.

</details>


### [141] [The ORCA Benchmark: Evaluating Real-World Calculation Accuracy in Large Language Models](https://arxiv.org/abs/2511.02589)
*Claudia Herambourg,Dawid Siuda,Anna Szczepanek,Julia Kopczyńska,Joao R. L. Santos,Wojciech Sas,Joanna Śmietańska-Nowak*

Main category: cs.AI

TL;DR: ORCA Benchmark 是一个评估大型语言模型在多领域实际量化推理中表现的测试，结果显示现有顶尖模型在数学和工程领域较强，但在物理和自然科学领域较弱，模型间存在部分互补性但也有重复性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 动机是评估大型语言模型在跨领域真实问题中的多步推理、数值精确度和泛化能力，尤其是它们在量化推理中的表现，以及它们在处理金融、物理、健康和统计等领域问题时的准确性、稳定性和互补性。

Method: 通过在包括金融、物理、健康、统计在内的500个自然语言任务中测试ChatGPT-5等五种最先进的系统，来评价大型语言模型在多领域真实量化推理中的表现。重点是测试其在这些问题上的准确性、稳定性以及模型间的互补性。

Result: 这些先进的系统在这些测试中的总体准确率在45%到63%之间，主要错误原因在于四舍五入（35%）和计算错误（33%），表现出来在数学和工程领域较强，但在物理和自然科学领域较弱的特性。另外，发现不同模型在犯错误类型上的差异，这表明他们之间部分互补而非冗余。

Conclusion: 与标准数学数据集不同，ORCA Benchmark 测试模型的逐步推理、数值精度和跨真实问题领域的泛化能力。结果表明，现有模型在此类任务上的表现还不理想，为进一步研究指明了方向。

Abstract: We present ORCA (Omni Research on Calculation in AI) Benchmark -- a novel
benchmark that evaluates large language models (LLMs) on multi-domain,
real-life quantitative reasoning using verified outputs from Omni's calculator
engine. In 500 natural-language tasks across domains such as finance, physics,
health, and statistics, the five state-of-the-art systems (ChatGPT-5,
Gemini~2.5~Flash, Claude~Sonnet~4.5, Grok~4, and DeepSeek~V3.2) achieved only
$45\text{--}63\,\%$ accuracy, with errors mainly related to rounding ($35\,\%$)
and calculation mistakes ($33\,\%$). Results in specific domains indicate
strengths in mathematics and engineering, but weaknesses in physics and natural
sciences. Correlation analysis ($r \approx 0.40\text{--}0.65$) shows that the
models often fail together but differ in the types of errors they make,
highlighting their partial complementarity rather than redundancy. Unlike
standard math datasets, ORCA evaluates step-by-step reasoning, numerical
precision, and domain generalization across real problems from finance,
physics, health, and statistics.

</details>


### [142] [LLM-Supported Formal Knowledge Representation for Enhancing Control Engineering Content with an Interactive Semantic Layer](https://arxiv.org/abs/2511.02759)
*Julius Fiedler,Carsten Knoll,Klaus Röbenack*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLM支持的半自动方法，用于生成结合了人类可读性和机器可解释性的形式化知识表示。该方法基于Imperative Representation of Knowledge框架，可以将自然语言描述和数学定义转换为形式化知识图谱，用于增强原始文档的知识转移能力。


<details>
  <summary>Details</summary>
Motivation: 面对控制工程领域研究输出的快速增长，需要新的方法来结构化和形式化领域的知识，本文旨在提出一种新的知识表示方法来解决这一问题，使得知识更容易获取、协作和验证。

Method: 基于Imperative Representation of Knowledge框架，本文提出了一种LLM支持的半自动化方法，可以将自然语言描述和数学定义转换为形式化知识图谱，增加了知识的表达性，同时也保持了机器的可解释性。

Result: 本文展示了一种生成“交互式语义层”的方法，增强了原始文档的知识转移能力，这对于实现控制工程领域易于访问、协作和验证的知识库的愿景具有重要意义。

Conclusion: 该方法是结构化和形式化领域知识的一种新途径，它可以有效地促进知识的转移，并支持易于访问、协作和验证的知识库的建立。

Abstract: The rapid growth of research output in control engineering calls for new
approaches to structure and formalize domain knowledge. This paper briefly
describes an LLM-supported method for semi-automated generation of formal
knowledge representations that combine human readability with machine
interpretability and increased expressiveness. Based on the Imperative
Representation of Knowledge (PyIRK) framework, we demonstrate how language
models can assist in transforming natural-language descriptions and
mathematical definitions (available as LaTeX source code) into a formalized
knowledge graph. As a first application we present the generation of an
``interactive semantic layer'' to enhance the source documents in order to
facilitate knowledge transfer. From our perspective this contributes to the
vision of easily accessible, collaborative, and verifiable knowledge bases for
the control engineering domain.

</details>


### [143] [DecompSR: A dataset for decomposed analyses of compositional multihop spatial reasoning](https://arxiv.org/abs/2511.02627)
*Lachlan McPheat,Navdeep Kaur,Robert Blackwell,Alessandra Russo,Anthony G. Cohn,Pranava Madhyastha*

Main category: cs.AI

TL;DR: DecompSR是一个用于分析组合空间推理能力的大型基准数据集（超过500万个数据点）和生成框架。它允许用户独立改变几个组合性的方面，如生产性、替代性、过度概括和系统性。它通过对几个关键组合性方面的独立变化，提供了对大型语言模型（LLMs）的组合推理能力的详细检测工具。


<details>
  <summary>Details</summary>
Motivation: 动机是通过提供一个既能变化又正确构建的数据集来评估大型语言模型的空间推理能力。DeompSR旨在通过改变数据集中不同组合性要素的程度，更好地理解语言模型的能力和限制。

Method: DecompSR是通过一种构建方式生成的，这种方式让数据集是通过结构化的方法正确构建。该框架的正确性已经被通过符号求解器独立验证。接着，DecompSR在广泛的大型语言模型上进行了基准测试，尤其是在生产性推广和系统性推广方面，结果显示大型语言模型在这两项上特别挣扎，但在语言变异方面表现较为稳定。

Result: 结果显示大型语言模型在空间推理任务的生产性和系统性推广方面挣扎，但在语言变化方面表现更为稳固。该研究证实了DecompSR作为一个准确的基准测试数据集，具有独特的能力，可以独立变化几个关键组合性方面的程度，可以对大型语言模型的组合推理能力进行全面细致的检验。

Conclusion: 结论是DecompSR提供了一个可靠的方法来微调检测大型语言模型在组合空间推理上的能力，从而推动研究向更深入、更细致的组合建模方向发展。

Abstract: We introduce DecompSR, decomposed spatial reasoning, a large benchmark
dataset (over 5m datapoints) and generation framework designed to analyse
compositional spatial reasoning ability. The generation of DecompSR allows
users to independently vary several aspects of compositionality, namely:
productivity (reasoning depth), substitutivity (entity and linguistic
variability), overgeneralisation (input order, distractors) and systematicity
(novel linguistic elements). DecompSR is built procedurally in a manner which
makes it is correct by construction, which is independently verified using a
symbolic solver to guarantee the correctness of the dataset. DecompSR is
comprehensively benchmarked across a host of Large Language Models (LLMs) where
we show that LLMs struggle with productive and systematic generalisation in
spatial reasoning tasks whereas they are more robust to linguistic variation.
DecompSR provides a provably correct and rigorous benchmarking dataset with a
novel ability to independently vary the degrees of several key aspects of
compositionality, allowing for robust and fine-grained probing of the
compositional reasoning abilities of LLMs.

</details>


### [144] [Optimizing AI Agent Attacks With Synthetic Data](https://arxiv.org/abs/2511.02823)
*Chloe Loughridge,Paul Colognese,Avery Griffin,Tyler Tracy,Jon Kutasov,Joe Benton*

Main category: cs.AI

TL;DR: 本文提出了一种优化攻击策略的方法，以评估AI系统的风险控制。通过在SHADE-Arena环境中分解攻击能力并优化每个部分，即使在数据稀缺的情况下也能提高攻击策略的强度，从而更准确地评估AI系统的安全性。这项研究将安全评分从0.87降低到0.41，显著提高了风险评估能力。


<details>
  <summary>Details</summary>
Motivation: 随着AI部署变得越来越复杂和重要，评估AI系统风险的能力也变得越来越重要。一个好的风险评估需要强有力的攻击策略，然而在复杂环境中，数据稀缺导致难以实现这一目标。为了克服这个问题，论文提出了一种新的方法来优化攻击策略。

Method: 论文通过将攻击能力分解成五个组成部分——怀疑建模、攻击选择、计划合成、执行和隐秘——并在SHADE-Arena环境中分别优化每个部分。他们还开发了一种概率模型来模拟攻击动态，并使用模拟来优化攻击超参数，然后证明这些结果可以转移到SHADE-Arena环境中。

Result: 该方法显著提高了攻击策略的强度，使安全评分从0.87降低到0.41，展示了其在有限数据条件下的有效性。

Conclusion: 该研究提出了一种优化攻击策略的方法，显著提高了评估AI系统安全性的能力，即使在数据稀缺的情况下也能产生有成效的结果。

Abstract: As AI deployments become more complex and high-stakes, it becomes
increasingly important to be able to estimate their risk. AI control is one
framework for doing so. However, good control evaluations require eliciting
strong attack policies. This can be challenging in complex agentic environments
where compute constraints leave us data-poor. In this work, we show how to
optimize attack policies in SHADE-Arena, a dataset of diverse realistic control
environments. We do this by decomposing attack capability into five constituent
skills -- suspicion modeling, attack selection, plan synthesis, execution and
subtlety -- and optimizing each component individually. To get around the
constraint of limited data, we develop a probabilistic model of attack
dynamics, optimize our attack hyperparameters using this simulation, and then
show that the results transfer to SHADE-Arena. This results in a substantial
improvement in attack strength, reducing safety score from a baseline of 0.87
to 0.41 using our scaffold.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [145] [Permissioned Blockchain in Advanced Air Mobility: A Performance Analisys for UTM](https://arxiv.org/abs/2511.02171)
*Rodrigo Nunes,André Melo,Rafael Albarello,Reinaldo Gomes,Cesar Marcondes,Lourenço Pereira Jr*

Main category: cs.NI

TL;DR: 该研究对比了两个符合当前监管框架的分布式架构：Linux基金会的InterUSS平台和基于Hyperledger Fabric的私有账本。结果表明，区块链系统需要针对航空性能约束进行专门设计的架构。


<details>
  <summary>Details</summary>
Motivation: 随着无人驾驶航空器的快速采用，航空管理部门提出了分布式无人驾驶空中交通管理架构。区块链被提议作为满足这些要求的有前景的技术，但是由于UTM是一个安全关键且高度监管的领域，合规性与性能和安全性一样重要。

Method: 研究比较了两个分布式架构：Linux基金会的InterUSS平台和基于Hyperledger Fabric的私有账本，评估区块链系统在航空性能约束下的表现。

Result: 发现基于区块链的系统需要专门设计以满足航空性能约束的架构。

Conclusion: 为了使区块链技术在UTM领域成功应用，需要开发适应航空性能要求的特定架构。

Abstract: The rapid adoption of Uncrewed Aerial Vehicles (UAVs) has driven aviation
authorities to propose distributed Uncrewed Traffic Management (UTM)
architectures. Several studies have advocated blockchain as a promising
technology to meet these requirements. However, since UTM is a safety-critical
and highly regulated domain, compliance with standards and regulatory
frameworks is as crucial as performance and security. This work benchmarks two
distributed architectures aligned with current regulatory frameworks: the Linux
Foundation's InterUSS platform and a Hyperledger Fabric-based private ledger.
Our findings reveal that blockchain-based systems require architectures
specifically designed for aeronautical performance constraints.

</details>


### [146] [Optimizing Multi-UAV 3D Deployment for Energy-Efficient Sensing over Uneven Terrains](https://arxiv.org/abs/2511.02368)
*Rushi Moliya,Dhaval K. Patel,Brijesh Soni,Miguel López-Benítez*

Main category: cs.NI

TL;DR: 这篇文章提出了一种高效评估线性视距（LoS）的方案，并结合遗传算法（GA）和粒子群优化（PSO）来解决多无人机协同感知系统中的问题，以提高检测概率并减少能量消耗。实验表明，该方案比传统方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 为了提高无人机（UAV）在不平坦地形中协同感知多个目标的性能，解决地形引起的线性视距（LoS）阻塞问题，本文提出了一种新的方案并且结合了GA和PSO算法。通过这种方法，可以有效提高检测概率和减少能量消耗。

Method: 提出了一种结合探索阶段的GA和每个无人机进行微调的PSO的分层启发式框架。该框架中的适应度评价是基于惩罚的，以指导解决方案趋向可行性, 并在约束范围内优化。这项研究还提出了一种基于Borders Volume Hierarchy的自适应方案，该方案能有效进行LoS评估。

Result: 在真实世界的地形数据集上进行的蒙特卡洛仿真表明，GA+PSO框架比单一PSO优化方法检测概率提高了37.02%和36.5%，并且在两个无人机和三个无人机的情况下，减少了45.0%和48.9%的平均多余停留能量。而和非优化方案相比，进一步提高了59.5%和54.2%的检测概率，减少了59.8%和65.9%的多余停留能量。这表明在不平坦地形中，使用少量的UAV可以实现更优的性能。

Conclusion: 本文提出了一种新的解决方案，它通过GA和PSO组合的方法来优化检测概率和能量消耗，从而提高了无人机的协同检测性能。这种方法在复杂的空间和定向约束中有效，且对于少于4架无人机的情况，表现尤为出色。

Abstract: In this work, we consider a multi-unmanned aerial vehicle (UAV) cooperative
sensing system where UAVs are deployed to sense multiple targets in
terrain-aware line of sight (LoS) conditions in uneven terrain equipped with
directional antennas. To mitigate terrain-induced LoS blockages that degrade
detection performance, we incorporate a binary LoS indicator and propose a
bounding volume hierarchy (BHV)-based adaptive scheme for efficient LoS
evaluation. We formulate a bi-objective problem that maximizes the probability
of cooperative detection with minimal hover energy constraints governing
spatial, orientational, and safety constraints. To address the problem, which
is inherently non-convex, we propose a hierarchical heuristic framework that
combines exploration through a genetic algorithm (GA) with per-UAV refinement
via particle swarm optimization (PSO), where a penalty-based fitness evaluation
guides solutions toward feasibility, bounded within constraints. The proposed
methodology is an effective trade-off method of traversing through a complex
search space and maintaining terrain-aware LoS connectivity and energy aware
deployment. Monte Carlo simulations on real-world terrain data show that the
proposed GA+PSO framework improves detection probability by 37.02% and 36.5%
for 2 and 3 UAVs, respectively, while reducing average excess hover energy by
45.0% and 48.9% compared to the PSO-only baseline. Relative to the
non-optimized scheme, it further achieves 59.5% and 54.2% higher detection
probability with 59.8% and 65.9% lower excess hover energy, thereby showing its
effectiveness with a small number of UAVs over uneven terrain.

</details>


### [147] [Janus: Leveraging Incremental Computation for Efficient DNS Verification](https://arxiv.org/abs/2511.02559)
*Yao Wang,Kexin Yu,Wenyun Xu,Kaiqiang Hu,Ziyi Wang,Lizhao You,Qiang Su,Dong Guo,Haizhou Du,Wanjian Feng,Qingyu Song,Linghe Kong,Qiao Xiang,Jiwu Shu*

Main category: cs.NI

TL;DR: Janus 是一种新的DNS验证工具，通过将查询过程转化为匹配过程以及使用高效的分区查询空间方法和增量验证机制来解决当前DNS配置验证工具有效性低和不支持增量验证的问题


<details>
  <summary>Details</summary>
Motivation: 解决现有DNS配置验证工具效率低且无法支持增量验证的问题

Method: 通过引入Janus工具，将name server处理查询的过程转变成匹配过程，利用高效的分区查询空间的方法，使用符号执行算法以确保覆盖所有可能查询并保证准确性，以及支持增量验证的机制

Result: 实验结果证明，Janus在真实数据集上实现了显著的加速，峰值改进高达255.7倍，并且将LEC数量降至最多6046倍

Conclusion: Janus通过改进DNS配置验证过程，大大提高了验证的效率和准确性

Abstract: Existing DNS configuration verification tools face significant issues (e.g.,
inefficient and lacking support for incremental verification). Inspired by the
advancements in recent work of distributed data plane verification and the
resemblance be- tween the data plane and DNS configuration, we tackle the
challenge of DNS misconfiguration by introducing Janus, a DNS verification
tool. Our key insight is that the process of a nameserver handling queries can
be transformed into a matching process on a match-action table. With this
insight, Janus consists of (1) an efficient data structure for partition query
space based on the behaviors, (2) a symbolic execution algorithm that specifies
how a single nameserver can efficiently cover all possible queries and ensure
the accuracy of verification, (3) a mechanism to support incremental
verification with less computational effort. Extensive experiments on
real-world datasets (with over 6 million resource records) show that Janus
achieves significant speedups, with peak improvements of up to 255.7x and a
maximum 6046x reduction in the number of LECs.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [148] [Gas Fire Power Plant Management Through Numerical Approximation of Spark Spread Options](https://arxiv.org/abs/2511.01880)
*Babacar Seck,Anas Abdullah*

Main category: eess.SY

TL;DR: 本文探讨了在现货价格服从跳跃扩散过程的情况下，如何利用近似方法来评估电力和天然气现货价格的火花价差期权。具体来说，作者研究了当电力和天然气的现货价格不能用对数正态分布来建模时的火花价差期权估值方法。这个问题特别关注电力和天然气现货价格中的尖峰现象，这是由于季节性等因素造成的。


<details>
  <summary>Details</summary>
Motivation: 电力和天然气现货价格中的尖峰现象影响了火花价差期权的估值，特别是在现货价格不能用对数正态分布来建模的情况下。当前的估值方法多基于对数正态分布假设下的公式或近似公式，如Kirk的近似方法。然而，当电力和天然气的现货价格出现尖峰时，这种方法可能不再适用，因此提出了一种适用于跳跃扩散过程的新方法来评估火花价差期权。 

Method: 采用了跳跃扩散过程建模现货价格，并提出了一种近似方法来评估当现货价格不满足对数正态分布特点时的火花价差期权。此外，研究中还考虑了电力和天然气现货价格中的尖峰现象。

Result: 提出了近似方法来评估电力和天然气现货价格服从跳跃扩散过程的火花价差期权。这种方法能更准确地处理尖峰现象等特殊情况下的现货价格变化，从而提升估值的准确性和实用性。 

Conclusion: 研究证明了，在现货价格不能用对数正态分布来建模的情况下，采用跳跃扩散过程建模现货价格，并通过更精确的方法估计火花价差期权，可以更有效地处理尖峰现象。这个方法为风险管理和估值提供了新的工具。

Abstract: Cross-commodity valuation approaches to value gas fire power plants are well
studied in the literature. Hence, the value of the gas fire power plant is
identical to the value of a spark spread option wherein the underlying are
electricity and gas with a strike price assimilated to operating and
maintenance costs. Power and fuels spot prices account for uncertain futures
cash-flows for power-plant generator owners. For instance, for gas-fired
turbine plant, spot prices of electricity and gas determine the random
cash-flows of the power-plant. Other than the spot prices, the valuation of
such plant involves among other deterministic cost the plant heat rate and
operating costs. Recently, the cost of emissions is considered into the
valuation to tackle environmental issues. Given some simplifications in the
plant cash-flow modelling, the value of such plant can either be expressed as
the price of i) a cross-commodity option or ii) the price of a real option.
Here, we focus on cross-commodity option valuation approach where the value of
the power plant is approached as the value of a spark spread option. When spot
prices of the underlying commodities are log-normal, closed formulae or
approximations can be obtained using Kirk's approximation. Naturally, the spot
price of electricity and gas present spikes due to seasonality among other
factors. However, in that case it is not possible to get a closed formula for
the spark spread option. In this paper we explore possibilities to approximate
spark spread options when spot prices fall into a class of jump diffusion
processes.

</details>


### [149] [Second-Order Policy Gradient Methods for the Linear Quadratic Regulator](https://arxiv.org/abs/2511.02095)
*Amirreza Valaei,Arash Bahari Kordabad,Sadegh Soudjani*

Main category: eess.SY

TL;DR: 本文开发了线性二次调节器(LQR)中的二阶策略梯度算法，通过推导高斯-牛顿法和牛顿法中近似和精确Hessian矩阵的显式公式，实现了更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 标准的一阶方法在强化学习中的连续控制策略优化中收敛速度慢，而二阶方法能通过使用曲率信息加速学习，但通常计算量大。因此，本文旨在通过在LQR环境下应用二阶策略梯度方法来加速学习过程。

Method: 推导了适用于高斯-牛顿法和牛顿法的近似和精确Hessian矩阵的显式公式，从而在LQR环境中实现了二阶策略梯度算法。

Result: 数值实验表明，提出的二阶方法在收敛速度上超越了标准的一阶策略梯度基线方法。

Conclusion: 提出了适用于LQR环境的二阶策略梯度算法，以加速策略优化过程。

Abstract: Policy gradient methods are a powerful family of reinforcement learning
algorithms for continuous control that optimize a policy directly. However,
standard first-order methods often converge slowly. Second-order methods can
accelerate learning by using curvature information, but they are typically
expensive to compute. The linear quadratic regulator (LQR) is a practical
setting in which key quantities, such as the policy gradient, admit closed-form
expressions. In this work, we develop second-order policy gradient algorithms
for LQR by deriving explicit formulas for both the approximate and exact
Hessians used in Gauss--Newton and Newton methods, respectively. Numerical
experiments show a faster convergence rate for the proposed second-order
approach over the standard first-order policy gradient baseline.

</details>


### [150] [Model Predictive Control with Multiple Constraint Horizons](https://arxiv.org/abs/2511.02114)
*Allan Andre do Nascimento,Han Wang,Antonis Papachristodoulou,Kostas Margellos*

Main category: eess.SY

TL;DR: 提出了将约束分为两种类型的新MPC方法，为非线性MPC提供了闭环次优结果。此外，还提供了关于约束选择如何影响系统闭环的第一个下界。通过仿真验证了这些结果在非线性和线性安全关键系统中的有效性.


<details>
  <summary>Details</summary>
Motivation: 提出一种分两类型约束的MPC方法，旨在解决由安全考虑引发的问题，特别是在非线性MPC中的闭环次优性分析.

Method: 将MPC的约束分为控制不变集和非控制不变集，通过调整约束范围和衰减率，推导出短范围比以前工作更紧的次优性上限，给出闭环次优性的第一个下界.

Result: 推导出了考虑不同约束集、范围和衰减率的次优性上限，首次提出了闭环次优性的下界，提供了一种强大的分析框架，可以帮助设计者评估MPC次优性中的范围影响。通过模拟在非线性和线性安全关键系统中验证了结果.

Conclusion: 本工作提出了新的MPC方法，它能够分析不同约束选择如何影响系统的闭环状态，为设计者提供了一个评估MPC次优性中的范围影响的框架.

Abstract: In this work we propose a Model Predictive Control (MPC) formulation that
splits constraints in two different types. Motivated by safety considerations,
the first type of constraint enforces a control-invariant set, while the second
type could represent a less restrictive constraint on the system state. This
distinction enables closed-loop sub- optimality results for nonlinear MPC with
heterogeneous state constraints (distinct constraints across open loop
predicted states), and no terminal elements. Removing the non-invariant
constraint recovers the partially constrained case. Beyond its theoretical
interest, heterogeneous constrained MPC shows how constraint choices shape the
system's closed loop. In the partially constrained case, adjusting the
constraint horizon (how many predicted- state constraints are enforced) trades
estimation accuracy for computational cost. Our analysis yields first, a sub-
optimality upper-bound accounting for distinct constraint sets, their horizons
and decay rates, that is tighter for short horizons than prior work. Second, to
our knowledge, we give the first lower bound (beyond open-loop cost) on
closed-loop sub-optimality. Together these bounds provide a powerful analysis
framework, allowing designers to evaluate the effect of horizons in MPC
sub-optimality. We demonstrate our results via simulations on nonlinear and
linear safety-critical systems.

</details>


### [151] [Online Distributed Zeroth-Order Optimization With Non-Zero-Mean Adverse Noises](https://arxiv.org/abs/2511.02183)
*Yanfu Qin,Kaihong Lu*

Main category: eess.SY

TL;DR: 该论文研究了带有非零均值不利噪声的在线分布式零阶最优化问题，并提出了一个新的基于核函数估计器和剪切策略的在线分布式零阶镜像下降算法。该算法通过动态后悔度量性能，且在弱假设条件下，证明了动态后悔的增长率次线性，在实验中验证了理论结果的有效性。


<details>
  <summary>Details</summary>
Motivation: 存在的在线分布式零阶最优化算法不能很好处理非零均值不利噪声。为此，研究者提出了一种新的算法来改进这个问题。

Method: 提出了一个新的基于核心函数估计器和剪切策略的在线分布式零阶镜像下降算法。该算法通过动态后悔度进行性能评估，特别是在估计器中采用核函数策略来处理不利噪声并消除目标函数泰勒展开中的低阶项。在弱假设条件下，证明了算法的动态后悔度次线性增长。

Result: 证明了在假设条件下的改进算法的动态后悔度次线性增长，通过实验也验证了理论结果的有效性。

Conclusion: 通过改进的算法和理论证明，该论文解决了带有不利噪声的在线分布式零阶最优化问题，并验证了算法的有效性和理论的准确性。

Abstract: In this paper, the problem of online distributed zeroth-order optimization
subject to a set constraint is studied via a multi-agent network, where each
agent can communicate with its immediate neighbors via a time-varying directed
graph. Different from the existing works on online distributed zeroth- order
optimization, we consider the case where the estimate on the gradients are
influenced by some non-zero-mean adverse noises. To handle this problem, we
propose a new online dis- tributed zeroth-order mirror descent algorithm
involving a kernel function-based estimator and a clipped strategy.
Particularly, in the estimator, the kernel function-based strategy is provided
to deal with the adverse noises, and eliminate the low-order terms in the
Taylor expansions of the objective functions. Furthermore, the performance of
the presented algorithm is measured by employing the dynamic regrets, where the
offline benchmarks are to find the optimal point at each time. Under the mild
assumptions on the graph and the objective functions, we prove that if the
variation in the optimal point sequence grows at a certain rate, then the high
probability bound of the dynamic regrets increases sublinearly. Finally, a
simulation experiment is worked out to demonstrate the effectiveness of our
theoretical results.

</details>


### [152] [Performance Analysis of NOMA-Assisted Optical OFDM ISAC Systems with Clipping Distortion](https://arxiv.org/abs/2511.02282)
*Nam N. Luong,Chuyen T. Nguyen,Thanh V. Pham*

Main category: eess.SY

TL;DR: 该论文研究了基于OFDM的多用户集成感知与通信（ISAC）系统中非正交多址接入（NOMA）的表现，并提出了一种新的发射机架构来减轻削波失真的影响。分析了功率分配对通信和感知子系统性能的影响，并通过仿真验证了功率分配策略对系统性能的影响。


<details>
  <summary>Details</summary>
Motivation: 由于OFDM波形的削波失真对系统的性能有显著影响，该论文的动机在于提出一种新的发射机架构，从而减少这种失真的负面影响，更有效的实现通信和感知任务。

Method: 提出了一种新的发射机架构，在NOMA叠加编码之前进行波形削波处理，分析了这种处理对通信和感知性能的影响，并通过仿真验证了不同功率分配策略下的系统性能。

Result: 研究结果表明，将更多功率分配给强用户可以提高总吞吐量，降低误码率，并改善感知性能；而将功率在用户间平均分配则会导致误码率和感知性能下降。

Conclusion: 论文提出了一种新的OFDM-ISAC系统架构，通过合理的功率分配策略，能够提高系统的通信和感知性能，具有实用价值。

Abstract: This paper studies the performance of optical orthogonal frequency-division
multiplexing (OFDM)-based multi-user integrated sensing and communication
(ISAC) systems employing non-orthogonal multiple access (NOMA). Due to their
inherent high peak-to-average power ratio (PAPR), OFDM waveforms are clipped to
fit the limited dynamic range of the optical transmitters (e.g., light-emitting
diodes (LEDs)), resulting in clipping distortion. To alleviate the impact of
the distortion, we propose a novel transmitter architecture where the clipping
processes are performed before NOMA superposition coding. We then analyze the
performance of the proposed optical ISAC systems considering the effects of
power allocation and clipping distortion. For the communication subsystem, we
analyze the effect of NOMA on the achievable sum rate and bit error rate (BER).
For the sensing subsystem, the root mean square error (RMSE) and Cram\'er-Rao
bound (CRB) of estimating the transmission distance accuracy are obtained.
Simulation results reveal that allocating more power to the strong user yields
a higher sum rate, lower BER, and better sensing performance, whereas a more
balanced power allocation among users results in degraded BER and sensing
performance.

</details>


### [153] [Explicit MPC for the constrained zonotope case with low-rank matrix updates](https://arxiv.org/abs/2511.02433)
*Stefan S. Mihai,Florin Stoican,Martin Monnigmann,Bogdan D. Ciubotaru*

Main category: eess.SY

TL;DR: 提出了一种基于约束维形体（constrained-zonotope）表示的几何属性来加速显式模型预测控制（MPC）问题求解的方法，包括在提升生成空间中用二阶最优性条件求解多参数问题，使用低秩矩阵更新减少计算时间，以及引入候选激活集的解析枚举得到显式解的树形结构。


<details>
  <summary>Details</summary>
Motivation: 传统的显式模型预测控制问题随着系统维度和预测地平线的增加，需要枚举所有关键区域和反馈规律，这种方法随着维度增加呈指数增加，效率低下。因此，针对此类问题寻求更高效的解析解法，以适应更复杂的控制系统。利用约束维形体的几何特性的方法，来加速显式模型预测控制问题的解析求解。

Method: 利用低秩矩阵更新减少计算时间，引入候选激活集的解析枚举，提出在提升生成空间中用二阶最优性条件来求解多参数问题的方法，得到显式解树形结构。

Result: 通过采用提出的基于几何属性的方法，能够加速显式模型预测控制问题的求解速度，减少计算时间。这是通过对所提出方法的有效性进行数学证明和仿真实验验证所得，并通过与传统方法对比展示其在效率上的改进。在文中未直接明确给出具体结果指标，但提供了解析求解方法上的创新策略和理论保证。

Conclusion: 本研究利用约束维形体的几何属性提出了有效地加速显式模型预测控制问题求解的新方法，对于高维系统和长预测地平线的控制问题具有重要的应用价值。

Abstract: Solving the explicit Model Predictive Control (MPC) problem requires
enumerating all critical regions and their associated feedback laws, a task
that scales exponentially with the system dimension and the prediction horizon,
as well. When the problem's constraints are boxes or zonotopes, the feasible
domain admits a compact constrained-zonotope representation. Building on this
insight, we exploit the geometric properties of the equivalent
constrained-zonotope reformulation to accelerate the computation of the
explicit solution. Specifically, we formulate the multi-parametric problem in
the lifted generator space and solve it using second-order optimality
conditions, employ low-rank matrix updates to reduce computation time, and
introduce an analytic enumeration of candidate active sets that yields the
explicit solution in tree form.

</details>


### [154] [Coherency among Power System Devices](https://arxiv.org/abs/2511.02486)
*Ignacio Ponce,Rodrigo Bernal,Federico Milano*

Main category: eess.SY

TL;DR: 该论文提出了电力系统设备之间一致性的一个新定义，该定义不仅适用于同步电机，还适用于任何类型的设备。定义基于任何两个连接到同一电网的设备的电流注入的复频率差异，因此是模型无关的，适合现代电力系统中各种技术的混合。文章还提供了一种系统化的分析程序，用于研究特定设备模必须满足的一致性属性，并通过三种情况研究的模拟结果来说明该定义的有效性。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是为电力系统中任何类型的设备之间的一致性提出一个通用且模型无关的新定义，使其适用于现代电力系统。

Method: 该文章基于任何两个连接到同一电网的设备的电流注入的复频率差异，提出了一个新的一致性定义。还提供了一种系统化的分析方法，用于研究特定设备模型的一致性属性。进行时间域模拟来验证定义的有效性。

Result: 通过时间域的模拟结果，研究展示了该提出的一致性定义在各种设备间的应用能力。

Conclusion: 研究表明，该提出的一致性定义可以适用于所有类型设备的一致性评估，并且通过系统化的分析方法，有助于识别设备一致性属性的必要条件。

Abstract: The paper proposes a novel general definition of coherency among power system
devices of any type. The proposed approach is thus not limited to synchronous
machines. With this aim, the paper shows that coherency can be formally based
on the difference in the complex frequency of the current injections of any two
devices electrically connected to the same grid. The proposed definition is
model-agnostic, making it general and suitable for modern power systems
composed of a heterogeneous mix of technologies. The paper also provides a
systematic analytical procedure to study the properties that specific device
models must satisfy to be coherent. Time-domain simulations are conducted in
three case studies whose results illustrate the ability of our definition to
evaluate coherency among any type of device.

</details>


### [155] [Decentralized Approach to Detect and Eliminate Flapping Phenomena due to Flexible Resources](https://arxiv.org/abs/2511.02497)
*Angel Vaca,Federico Milano*

Main category: eess.SY

TL;DR: 提出了一种分布式方法，用于检测和减轻由离散设备操作引起的电网系统中的反复现象。这种方法通过移动窗口自相关性分析本地测量数据，使得每个设备能够自主识别持续的振荡，并在检测到振荡后执行设备特定的抑制策略。结果显示该方法能够有效地区分衰减振荡与持续性反复，让设备独立识别问题操作情景并采取相应的纠正措施。


<details>
  <summary>Details</summary>
Motivation: 电力系统的反复问题是由于离散设备操作所导致的，对电网稳定性和可靠性产生负面影响。为了实现自主检测和抑制这些反复现象，提出了一个基于移动窗口自相关的分布式处理方案，以减少对中央控制的依赖，提高系统稳定性和鲁棒性。

Method: 通过使用移动窗口自相关性分析本地测量数据，每一个功率系统中的设备都能够自主识别持续振荡，并根据识别结果采取相应的抑制策略。此方案利用了多种类型的设备，如DFRs、ULTCs和AVRs来协调减少振荡或反复的现象。

Result: 结果显示，所提出的方案在识别和抑制振荡现象方面表现出了良好的性能，正确地区分了衰减振荡和持续性反复，使得设备能够独立地识别出问题的操作情景，并采取相应的纠正措施。

Conclusion: 所提出的基于移动窗口自相关的分布控制方案在电源系统中的反复现象检测与抑制方面表现出了良好的效果。该方法是在分布式电源系统中实现独立识别并采取纠正措施的关键步骤，显示了广泛应用的潜力。

Abstract: This paper presents a decentralized methodology for detecting and mitigating
flapping phenomena in power systems, primarily caused by the operation of
discrete devices. The proposed approach applies moving-window autocorrelation
to local measurements, enabling each device to autonomously identify sustained
oscillations. Upon detection, a probabilistic, device-specific mitigation
strategy is executed. Flexible demand resources (DFRs), under-load tap changers
(ULTCs), and automatic voltage regulators (AVRs) are utilised to illustrate the
performance of the proposed approach to both discrete and continuous-operation
devices. Results show that the proposed method is robust and properly
distinguishes damped oscillations from persistent flapping, allowing devices to
independently recognize problematic operating scenarios and implement
corrective actions accordingly.

</details>


### [156] [Many-vs-Many Missile Guidance via Virtual Targets](https://arxiv.org/abs/2511.02526)
*Marc Schneider,Walter Fichter*

Main category: eess.SY

TL;DR: 该论文提出了一种基于正常化流（Normalizing Flows）的方法来生成虚拟目标，以此指导导弹防御中的多对多拦截问题。这种新型方法包括使用虚拟目标的轨迹预测，以及利用拦截器的分布优势，相较于现有方法，它在数量优势明显的场景下提高了拦截概率。


<details>
  <summary>Details</summary>
Motivation: 现有直接利用武器目标分配算法将拦截器分配到实际目标上的方法在多对多防御场景中表现不佳。为此，本论文企图提出一种新的基于虚拟目标且能利用拦截器数量优势的方法，来提高多对多拦截概率。

Method: 研究提出使用正常化流生成虚拟目标的轨迹预测。每个拦截器被引导到一组虚拟目标中的一个，这组虚拟目标代表了针对特定目标的多种可能轨迹。他们还使用了零努力偏移（Zero-Effort-Miss）和比例导航（Proportional Navigation）两种制导策略。这种新型方法被视为将多对多防御情景转变为多对分布情景，进而利用多一个的分布优势。通过Monte Carlo仿真，测试了虚拟目标方法对抗线性预测的性能。仿真结果显示，在n等于m时，虚拟目标方法的性能与现有预测性能相当或更好；而在n大于m时，虚拟目标方法的性能提高了5.8-14.4%。

Result: 提出的新方法成功地利用多个拦截器的数量优势，从而使得多对多防御能力得到了显著提高。在不同情景模拟中，虚拟目标预测方法能够匹配或超越直线预测基准线，并且当拦截器数量比目标多时表现出了更大的提升效应，提高了拦截概率5.8-14.4%。

Conclusion: 虚拟目标生成方法能够有效提高多对多防御情景下的拦截概率，特别是在拦截器数量上具有优势时。

Abstract: This paper presents a novel approach to many-vs-many missile guidance using
virtual targets (VTs) generated by a Normalizing Flows-based trajectory
predictor. Rather than assigning n interceptors directly to m physical targets
through conventional weapon target assignment algorithms, we propose a
centralized strategy that constructs n VT trajectories representing
probabilistic predictions of maneuvering target behavior. Each interceptor is
guided toward its assigned VT using Zero-Effort-Miss guidance during midcourse
flight, transitioning to Proportional Navigation guidance for terminal
interception. This approach treats many-vs-many engagements as
many-vs-distribution scenarios, exploiting numerical superiority (n > m) by
distributing interceptors across diverse trajectory hypotheses rather than
pursuing identical deterministic predictions. Monte Carlo simulations across
various target-interceptor configurations (1-6 targets, 1-8 interceptors)
demonstrate that the VT method matches or exceeds baseline straight-line
prediction performance by 0-4.1% when n = m, with improvements increasing to
5.8-14.4% when n > m. The results confirm that probabilistic VTs enable
effective exploitation of numerical superiority, significantly increasing
interception probability in many-vs-many scenarios.

</details>


### [157] [ISAC Empowered Air-Sea Collaborative System: A UAV-USV Joint Inspection Framework](https://arxiv.org/abs/2511.02592)
*Rui Zhang,Fuwang Dong,Wei Wang*

Main category: eess.SY

TL;DR: 基于ISAC技术，我们构建了一个海空协作系统框架，该系统利用无人机和无人艇联合监控目标并同时保持通信。我们解决了轨迹耦合和异质性的问题，提出了一种三层分层方法和一种半定松弛及逐次凸逼近方法解决强耦合变量问题，并通过仿真验证了所提方案的优越性。


<details>
  <summary>Details</summary>
Motivation: 解决无人机和无人艇联合监控目标过程中遇到的如同步性、轨迹耦合和异质性等独特挑战，提高海空协作系统的效率和效益。

Method: 采用能量消耗最小化问题的方法，提出一种分层方法解决耦合变量问题。该方法分为两部分：第一部分是选择航点和确定访问顺序，第二部分是在每一个飞行和悬停阶段完成轨迹规划和波束成形设计。

Result: 我们通过一系列仿真展示了所提方案优于现有的序列访问和领导跟随策略。

Conclusion: 提出了基于ISAC技术的海空协作系统框架，以及解决其内在挑战的方法，并通过仿真验证了所提方案的有效性。

Abstract: In this paper, we construct an air-sea collaborative system framework based
on the Integrated Sensing and Communication (ISAC) techniques, where the
Unmanned Aerial Vehicle (UAV) and Unmanned Surface Vehicle (USV) jointly
inspect targets of interest while keeping communication with each other
simultaneously. First, we demonstrate the unique challenges encountered in this
collaborative system, i.e., the coupling and heterogeneity of the UAV/USV's
trajectories. Then, we formulate a total energy consumption minimization
problem to jointly optimize the trajectories, flying and hovering times, target
scheduling, and beamformers under the constraints of water currents, collision
avoidance, and Sensing and Communication (S\&C) requirements. To address the
strong coupling of the variables, we divide the original problem into two
subproblems, namely, the hover point selection and the joint trajectory
planning and beamforming design. In the first subproblem, we propose a
three-step hierarchical method including: (1) a virtual base station coverage
(VBSC) and clustering algorithm to obtain the target scheduling and rough
position of hover points; (2) a Bi-traveling salesman problem with neighborhood
(Bi-TSPN)-based algorithm to determine the visiting order sequence of the hover
points; (3) a hover point refinement and time allocation algorithm to further
optimize the time allocation. In the latter subproblem, we complete the
remaining trajectory planning and beamforming design in each flying and
hovering stage by developing a semi-definite relaxation (SDR) and successive
convex approximation (SCA) method. Finally, we conduct a series of simulations
to demonstrate the superiority of the proposed scheme over existing sequential
access and leader-follower strategies.

</details>


### [158] [Policy Gradient Methods for Information-Theoretic Opacity in Markov Decision Processes](https://arxiv.org/abs/2511.02704)
*Chongyang Shi,Sumukha Udupa,Michael R. Dorothy,Shuo Han,Jie Fu*

Main category: eess.SY

TL;DR: 该研究提出了一种基于信息论的不透明度衡量标准，能够量化保密信息的泄露程度，并设计算法来寻找最大化不透明度的控制策略。基于马尔可夫决策过程模型，证明了有限记忆策略在优化信息不透明度方面优于马尔可夫策略，并开发了用于计算最大不透明度马尔可夫策略的算法。提出了在隐藏马尔可夫模型中计算条件熵关于策略参数的梯度的新方法，实验结果验证了所提方法的有效性和最优性。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在开发一种信息论上的不透明度衡量标准来量化保密信息的泄露，并设计算法以寻求能够最大化不透明度的控制策略，同时保证任务的性能。适用于存在知情观察者的系统中，其中观察者熟悉控制策略和系统动态。

Method: 通过证明有限记忆策略在优化信息论不透明度方面优于马尔可夫策略，设计了一种算法来计算最大不透明度的马尔可夫策略，并开发了计算条件熵关于策略参数梯度的新的方法，从而实现了不透明度优化。该算法基于可观察算子在隐藏马尔可夫模型中计算梯度，采用原始-对偶梯度算法。

Result: 证明了有限记忆策略在优化信息论不透明度方面优于马尔可夫策略；提出了一种新颖的梯度计算方法；实验验证了所提算法的有效性和最优性；开发了一种新的方法来处理无法直接转换为累计成本的不透明度优化问题。

Conclusion: 通过信息论方法量化保密信息泄露，提出了优化不透明度的策略，并开发了新方法来计算不透明度优化过程中的条件熵梯度，这为复杂系统中的保密性问题提供了新的解决方案。

Abstract: Opacity, or non-interference, is a property ensuring that an external
observer cannot infer confidential information (the "secret") from system
observations. We introduce an information-theoretic measure of opacity, which
quantifies information leakage using the conditional entropy of the secret
given the observer's partial observations in a system modeled as a Markov
decision process (MDP). Our objective is to find a control policy that
maximizes opacity while satisfying task performance constraints, assuming that
an informed observer is aware of the control policy and system dynamics.
Specifically, we consider a class of opacity called state-based opacity, where
the secret is a propositional formula about the past or current state of the
system, and a special case of state-based opacity called language-based
opacity, where the secret is defined by a temporal logic formula (LTL) or a
regular language recognized by a finite-state automaton. First, we prove that
finite-memory policies can outperform Markov policies in optimizing
information-theoretic opacity. Second, we develop an algorithm to compute a
maximally opaque Markov policy using a primal-dual gradient-based algorithm,
and prove its convergence. Since opacity cannot be expressed as a cumulative
cost, we develop a novel method to compute the gradient of conditional entropy
with respect to policy parameters using observable operators in hidden Markov
models. The experimental results validate the effectiveness and optimality of
our proposed methods.

</details>
