<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 43]
- [cs.LG](#cs.LG) [Total: 44]
- [cs.AI](#cs.AI) [Total: 11]
- [cs.IT](#cs.IT) [Total: 13]
- [cs.NI](#cs.NI) [Total: 4]
- [eess.SY](#eess.SY) [Total: 12]
- [eess.IV](#eess.IV) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [GR3EN: Generative Relighting for 3D Environments](https://arxiv.org/abs/2601.16272)
*Xiaoyan Xing,Philipp Henzler,Junhwa Hur,Runze Li,Jonathan T. Barron,Pratul P. Srinivasan,Dor Verbin*

Main category: cs.CV

TL;DR: 提出了从大规模房间尺度3D重建中提取视频到视频重光照扩散模型输出的新方法，实现了复杂真实场景的高质量可控重光照。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景重光照方法常需求解病态逆渲染问题，难以在复杂真实场景中获得高质量结果；现有生成模型方法仅限2D或单个物体重光照。

Method: 核心思想：通过蒸馏视频到视频重光照扩散模型的输出到3D重建中，避免直接求解逆渲染问题。具体步骤包括：构建3D场景表示，利用视频扩散模型生成不同光照下的2D视图，通过蒸馏将这些视图转换到3D空间中。

Result: 在合成和真实数据集上验证，该方法能忠实渲染新视角下新光照条件的场景。

Conclusion: 该方法通过巧妙避开直接逆渲染问题，实现了复杂真实房间规模环境的可控3D重光照。

Abstract: We present a method for relighting 3D reconstructions of large room-scale environments. Existing solutions for 3D scene relighting often require solving under-determined or ill-conditioned inverse rendering problems, and are as such unable to produce high-quality results on complex real-world scenes. Though recent progress in using generative image and video diffusion models for relighting has been promising, these techniques are either limited to 2D image and video relighting or 3D relighting of individual objects. Our approach enables controllable 3D relighting of room-scale scenes by distilling the outputs of a video-to-video relighting diffusion model into a 3D reconstruction. This side-steps the need to solve a difficult inverse rendering problem, and results in a flexible system that can relight 3D reconstructions of complex real-world scenes. We validate our approach on both synthetic and real-world datasets to show that it can faithfully render novel views of scenes under new lighting conditions.

</details>


### [2] [Memory-V2V: Augmenting Video-to-Video Diffusion Models with Memory](https://arxiv.org/abs/2601.16296)
*Dohun Lee,Chun-Hao Paul Huang,Xuelin Chen,Jong Chul Ye,Duygu Ceylan,Hyeonho Jeong*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent foundational video-to-video diffusion models have achieved impressive results in editing user provided videos by modifying appearance, motion, or camera movement. However, real-world video editing is often an iterative process, where users refine results across multiple rounds of interaction. In this multi-turn setting, current video editors struggle to maintain cross-consistency across sequential edits. In this work, we tackle, for the first time, the problem of cross-consistency in multi-turn video editing and introduce Memory-V2V, a simple, yet effective framework that augments existing video-to-video models with explicit memory. Given an external cache of previously edited videos, Memory-V2V employs accurate retrieval and dynamic tokenization strategies to condition the current editing step on prior results. To further mitigate redundancy and computational overhead, we propose a learnable token compressor within the DiT backbone that compresses redundant conditioning tokens while preserving essential visual cues, achieving an overall speedup of 30%. We validate Memory-V2V on challenging tasks including video novel view synthesis and text-conditioned long video editing. Extensive experiments show that Memory-V2V produces videos that are significantly more cross-consistent with minimal computational overhead, while maintaining or even improving task-specific performance over state-of-the-art baselines. Project page: https://dohunlee1.github.io/MemoryV2V

</details>


### [3] [FeTTL: Federated Template and Task Learning for Multi-Institutional Medical Imaging](https://arxiv.org/abs/2601.16302)
*Abhijeet Parida,Antonia Alomar,Zhifan Jiang,Pooneh Roshanitabrizi,Austin Tapp,Ziyue Xu,Syed Muhammad Anwar,Maria J. Ledesma-Carbayo,Holger R. Roth,Marius George Linguraru*

Main category: cs.CV

TL;DR: 论文提出了一种名为FeTTL（联邦模板与任务学习）的新框架，旨在解决联邦学习中由领域偏移和数据异质性导致的性能下降问题，重点应用于医疗影像分析。


<details>
  <summary>Details</summary>
Motivation: 在医疗影像联邦学习中，不同医疗中心的数据分布往往存在显著差异（如采集协议、设备类型、病人群体等），这种数据异质性和领域偏移会严重影响模型性能。

Method: FeTTL框架通过联合学习全局模板和任务模型来对齐客户端之间的数据分布。该方法学习一个共享的全局模板，用于调和各机构的异质数据，同时训练任务特定的模型。

Result: 在两个具有挑战性的多机构医疗影像任务（视网膜视盘分割和病理性转移分类）上，FeTTL显著优于现有联邦学习方法（p值<0.002）。实验还证明了联合学习模板与任务模型的重要性。

Conclusion: FeTTL为解决联邦学习中的分布偏移问题提供了一个原则性、可扩展的解决方案，能够支持在真实、多机构环境中进行鲁棒的模型部署。

Abstract: Federated learning enables collaborative model training across geographically distributed medical centers while preserving data privacy. However, domain shifts and heterogeneity in data often lead to a degradation in model performance. Medical imaging applications are particularly affected by variations in acquisition protocols, scanner types, and patient populations. To address these issues, we introduce Federated Template and Task Learning (FeTTL), a novel framework designed to harmonize multi-institutional medical imaging data in federated environments. FeTTL learns a global template together with a task model to align data distributions among clients. We evaluated FeTTL on two challenging and diverse multi-institutional medical imaging tasks: retinal fundus optical disc segmentation and histopathological metastasis classification. Experimental results show that FeTTL significantly outperforms the state-of-the-art federated learning baselines (p-values <0.002) for optical disc segmentation and classification of metastases from multi-institutional data. Our experiments further highlight the importance of jointly learning the template and the task. These findings suggest that FeTTL offers a principled and extensible solution for mitigating distribution shifts in federated learning, supporting robust model deployment in real-world, multi-institutional environments.

</details>


### [4] [Where is the multimodal goal post? On the Ability of Foundation Models to Recognize Contextually Important Moments](https://arxiv.org/abs/2601.16333)
*Aditya K Surikuchi,Raquel Fernández,Sandro Pezzelle*

Main category: cs.CV

TL;DR: 该研究评估了多模态模型在识别足球视频关键事件方面的能力，发现当前模型表现接近随机水平，且存在依赖单一模态、多源信息融合无效等问题


<details>
  <summary>Details</summary>
Motivation: 基础模型在涉及时序多模态事件的语言生成应用中被广泛使用，需要评估模型识别视频关键子事件的能力——这是叙述或总结多模态事件的基本前提。研究聚焦足球比赛，评估模型区分重要与非重要子事件的能力

Method: 构建了一个新数据集，通过足球比赛精彩回放视频中隐含的人类重要性偏好来获取数据，无需额外标注成本。使用该数据集比较了多种最先进的多模态模型，并就标准评估指标之外进行了深入分析

Result: 现有多模态模型的表现接近随机水平。分析显示这些模型倾向于依赖单一主导模态，且在综合多源必要信息方面效果不佳。模型性能在不同情境下波动较大，存在明显的样本级异质性挑战

Conclusion: 研究强调了处理多模态数据样本级异质性的模块化架构的重要性，以及需要能够最大化跨模态协同作用的补充训练程序，以改进多模态事件理解能力

Abstract: Foundation models are used for many real-world applications involving language generation from temporally-ordered multimodal events. In this work, we study the ability of models to identify the most important sub-events in a video, which is a fundamental prerequisite for narrating or summarizing multimodal events. Specifically, we focus on football games and evaluate models on their ability to distinguish between important and non-important sub-events in a game. To this end, we construct a new dataset by leveraging human preferences for importance implicit in football game highlight reels, without any additional annotation costs. Using our dataset, which we will publicly release to the community, we compare several state-of-the-art multimodal models and show that they are not far from chance level performance. Analyses of models beyond standard evaluation metrics reveal their tendency to rely on a single dominant modality and their ineffectiveness in synthesizing necessary information from multiple sources. Our findings underline the importance of modular architectures that can handle sample-level heterogeneity in multimodal data and the need for complementary training procedures that can maximize cross-modal synergy.

</details>


### [5] [Coarse-to-Fine Non-rigid Multi-modal Image Registration for Historical Panel Paintings based on Crack Structures](https://arxiv.org/abs/2601.16348)
*Aline Sindel,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Art technological investigations of historical panel paintings rely on acquiring multi-modal image data, including visual light photography, infrared reflectography, ultraviolet fluorescence photography, x-radiography, and macro photography. For a comprehensive analysis, the multi-modal images require pixel-wise alignment, which is still often performed manually. Multi-modal image registration can reduce this laborious manual work, is substantially faster, and enables higher precision. Due to varying image resolutions, huge image sizes, non-rigid distortions, and modality-dependent image content, registration is challenging. Therefore, we propose a coarse-to-fine non-rigid multi-modal registration method efficiently relying on sparse keypoints and thin-plate-splines. Historical paintings exhibit a fine crack pattern, called craquelure, on the paint layer, which is captured by all image systems and is well-suited as a feature for registration. In our one-stage non-rigid registration approach, we employ a convolutional neural network for joint keypoint detection and description based on the craquelure and a graph neural network for descriptor matching in a patch-based manner, and filter matches based on homography reprojection errors in local areas. For coarse-to-fine registration, we introduce a novel multi-level keypoint refinement approach to register mixed-resolution images up to the highest resolution. We created a multi-modal dataset of panel paintings with a high number of keypoint annotations, and a large test set comprising five multi-modal domains and varying image resolutions. The ablation study demonstrates the effectiveness of all modules of our refinement method. Our proposed approaches achieve the best registration results compared to competing keypoint and dense matching methods and refinement methods.

</details>


### [6] [Cognitively-Inspired Tokens Overcome Egocentric Bias in Multimodal Models](https://arxiv.org/abs/2601.16378)
*Bridget Leonard,Scott O. Murray*

Main category: cs.CV

TL;DR: 本文通过引入'视角令牌'机制解决多模态语言模型的空间推理缺陷，提升视觉视角采纳能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态语言模型在语义视觉任务表现良好，但在需要采纳其他智能体视角进行空间推理时存在局限。这些错误反映了顽固的自我中心偏差，引发了对模型是否支持非自我中心推理的疑问。本文受到人类空间认知启发，旨在探索轻量化的机制来增强模型的视角采纳能力。

Method: 提出视角令牌——专门化的嵌入表示，通过两种方式编码方向：（1）具身体关键点线索；（2）支持心理旋转的抽象表示。将这种令牌集成到LLaVA-1.5-13B模型中。在合成和自然基准测试（Isle Bricks V2、COCO、3DSRBench）上评估性能。

Result: 视角令牌显著提升了二级视觉视角采纳任务的性能，特别是基于旋转的令牌能够泛化到非人类参考智能体。表征分析显示微调增强了基础模型中已有的潜在方向敏感性，表明多模态语言模型已包含非自我中心推理的雏形但缺乏适当内部结构。

Conclusion: 直接将认知基础的空间结构嵌入令牌空间，为视角采纳和更接近人类的空间推理提供了一种轻量、模型无关的机制。

Abstract: Multimodal language models (MLMs) perform well on semantic vision-language tasks but fail at spatial reasoning that requires adopting another agent's visual perspective. These errors reflect a persistent egocentric bias and raise questions about whether current models support allocentric reasoning. Inspired by human spatial cognition, we introduce perspective tokens, specialized embeddings that encode orientation through either (1) embodied body-keypoint cues or (2) abstract representations supporting mental rotation. Integrating these tokens into LLaVA-1.5-13B yields performance on level-2 visual perspective-taking tasks. Across synthetic and naturalistic benchmarks (Isle Bricks V2, COCO, 3DSRBench), perspective tokens improve accuracy, with rotation-based tokens generalizing to non-human reference agents. Representational analyses reveal that fine-tuning enhances latent orientation sensitivity already present in the base model, suggesting that MLMs contain precursors of allocentric reasoning but lack appropriate internal structure. Overall, embedding cognitively grounded spatial structure directly into token space provides a lightweight, model-agnostic mechanism for perspective-taking and more human-like spatial reasoning.

</details>


### [7] [ResAgent: Entropy-based Prior Point Discovery and Visual Reasoning for Referring Expression Segmentation](https://arxiv.org/abs/2601.16394)
*Yihao Wang,Jusheng Zhang,Ziyi Tang,Keze Wang,Meng Yang*

Main category: cs.CV

TL;DR: 本文提出了一个名为EVD的Referring Expression Segmentation框架，用于解决现有方法存在的两个主要问题：粗糙边界框导致冗余或不具区分性的点提示，以及文本坐标推理的不可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前基于多模态大语言模型的Referring Expression Segmentation方法存在两个关键局限：1) MLLMs生成的粗糙边界框导致点提示冗余或不具区分性；2) 依赖文本坐标推理的方法在处理视觉相似干扰物时不可靠。这影响了像素级目标理解的准确性，限制了应用效果。

Method: 提出EVD框架，包含基于熵的点发现和基于视觉的推理两个核心组件：1) 基于熵的点发现通过建模粗糙边界框内的空间不确定性，将点选择视为信息最大化过程；2) 基于视觉的推理通过联合视觉-语义对齐验证点正确性，放弃纯文本坐标推理。整个框架采用由粗到细的工作流程。

Result: 在RefCOCO、RefCOCO+、RefCOCOg和ReasonSeg四个基准数据集上的广泛评估表明，EVD在所有四个基准上均达到了最先进的性能。

Conclusion: EVD框架通过将基于熵的点发现和基于视觉的推理相结合，能够在最小提示下生成准确且语义接地的分割掩码，显著提升了Referring Expression Segmentation任务的性能。

Abstract: Referring Expression Segmentation (RES) is a core vision-language segmentation task that enables pixel-level understanding of targets via free-form linguistic expressions, supporting critical applications such as human-robot interaction and augmented reality. Despite the progress of Multimodal Large Language Model (MLLM)-based approaches, existing RES methods still suffer from two key limitations: first, the coarse bounding boxes from MLLMs lead to redundant or non-discriminative point prompts; second, the prevalent reliance on textual coordinate reasoning is unreliable, as it fails to distinguish targets from visually similar distractors. To address these issues, we propose \textbf{\model}, a novel RES framework integrating \textbf{E}ntropy-\textbf{B}ased Point \textbf{D}iscovery (\textbf{EBD}) and \textbf{V}ision-\textbf{B}ased \textbf{R}easoning (\textbf{VBR}). Specifically, EBD identifies high-information candidate points by modeling spatial uncertainty within coarse bounding boxes, treating point selection as an information maximization process. VBR verifies point correctness through joint visual-semantic alignment, abandoning text-only coordinate inference for more robust validation. Built on these components, \model implements a coarse-to-fine workflow: bounding box initialization, entropy-guided point discovery, vision-based validation, and mask decoding. Extensive evaluations on four benchmark datasets (RefCOCO, RefCOCO+, RefCOCOg, and ReasonSeg) demonstrate that \model achieves new state-of-the-art performance across all four benchmarks, highlighting its effectiveness in generating accurate and semantically grounded segmentation masks with minimal prompts.

</details>


### [8] [A Cosine Network for Image Super-Resolution](https://arxiv.org/abs/2601.16413)
*Chunwei Tian,Chengyuan Zhang,Bob Zhang,Zhiwu Li,C. L. Philip Chen,David Zhang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep convolutional neural networks can use hierarchical information to progressively extract structural information to recover high-quality images. However, preserving the effectiveness of the obtained structural information is important in image super-resolution. In this paper, we propose a cosine network for image super-resolution (CSRNet) by improving a network architecture and optimizing the training strategy. To extract complementary homologous structural information, odd and even heterogeneous blocks are designed to enlarge the architectural differences and improve the performance of image super-resolution. Combining linear and non-linear structural information can overcome the drawback of homologous information and enhance the robustness of the obtained structural information in image super-resolution. Taking into account the local minimum of gradient descent, a cosine annealing mechanism is used to optimize the training procedure by performing warm restarts and adjusting the learning rate. Experimental results illustrate that the proposed CSRNet is competitive with state-of-the-art methods in image super-resolution.

</details>


### [9] [DCCS-Det: Directional Context and Cross-Scale-Aware Detector for Infrared Small Target](https://arxiv.org/abs/2601.16428)
*Shuying Li,Qiang Ma,San Zhang,Chuang Yang*

Main category: cs.CV

TL;DR: 本文提出DCCS-Det检测器，通过双流显著性增强模块和潜在感知语义提取聚合模块解决红外小目标检测中局部-全局特征关联不足和特征退化问题


<details>
  <summary>Details</summary>
Motivation: 现有红外小目标检测方法在局部-全局特征联合建模不足（影响目标-背景区分）或存在特征冗余和语义稀释（降低目标表示质量），需要创新方法提升检测性能

Method: 提出DCCS-Det检测器，包含：1）双流显著性增强模块，整合局部感知和方向感知上下文聚合；2）潜在感知语义提取聚合模块，通过跨尺度特征提取和随机池化采样缓解特征退化

Result: 在多个数据集上实现了最先进的检测精度和具有竞争力的效率，消融实验验证了DSE和LaSEA模块在复杂场景下对目标感知和特征表示的改进贡献

Conclusion: DCCS-Det有效解决了红外小目标检测中的关键挑战，为复杂背景下的低对比度小目标检测提供了创新解决方案，代码已开源

Abstract: Infrared small target detection (IRSTD) is critical for applications like remote sensing and surveillance, which aims to identify small, low-contrast targets against complex backgrounds. However, existing methods often struggle with inadequate joint modeling of local-global features (harming target-background discrimination) or feature redundancy and semantic dilution (degrading target representation quality). To tackle these issues, we propose DCCS-Det (Directional Context and Cross-Scale Aware Detector for Infrared Small Target), a novel detector that incorporates a Dual-stream Saliency Enhancement (DSE) block and a Latent-aware Semantic Extraction and Aggregation (LaSEA) module. The DSE block integrates localized perception with direction-aware context aggregation to help capture long-range spatial dependencies and local details. On this basis, the LaSEA module mitigates feature degradation via cross-scale feature extraction and random pooling sampling strategies, enhancing discriminative features and suppressing noise. Extensive experiments show that DCCS-Det achieves state-of-the-art detection accuracy with competitive efficiency across multiple datasets. Ablation studies further validate the contributions of DSE and LaSEA in improving target perception and feature representation under complex scenarios. \href{https://huggingface.co/InPeerReview/InfraredSmallTargetDetection-IRSTD.DCCS}{DCCS-Det Official Code is Available Here!}

</details>


### [10] [AlphaFace: High Fidelity and Real-time Face Swapper Robust to Facial Pose](https://arxiv.org/abs/2601.16429)
*Jongmin Yu,Hyeontaek Oh,Zhongtian Sun,Angelica I Aviles-Rivero,Moongu Jeon,Jinhong Yang*

Main category: cs.CV

TL;DR: AlphaFace是基于视觉语言模型的新型换脸方法，引入视觉和文本语义对比损失，在极端面部姿态下也能保持高质量实时换脸。


<details>
  <summary>Details</summary>
Motivation: 现有换脸方法在受限场景下效果良好，但在极端面部姿态时质量明显下降。几何特征方法增加额外依赖和计算成本，而基于扩散的方法难以实时处理。

Method: 利用开源视觉语言模型和CLIP图像文本嵌入，应用新颖的视觉和文本语义对比损失，增强身份表示和属性保持，同时保持实时性能。

Result: 在FF++、MPIE和LPFF数据集上的综合实验表明，AlphaFace在姿态挑战性情况下超越现有最优方法，公开代码于GitHub。

Conclusion: AlphaFace通过语义对比损失解决了极端姿态下的换脸质量下降问题，实现了高质量实时换脸性能。

Abstract: Existing face-swapping methods often deliver competitive results in constrained settings but exhibit substantial quality degradation when handling extreme facial poses. To improve facial pose robustness, explicit geometric features are applied, but this approach remains problematic since it introduces additional dependencies and increases computational cost. Diffusion-based methods have achieved remarkable results; however, they are impractical for real-time processing. We introduce AlphaFace, which leverages an open-source vision-language model and CLIP image and text embeddings to apply novel visual and textual semantic contrastive losses. AlphaFace enables stronger identity representation and more precise attribute preservation, all while maintaining real-time performance. Comprehensive experiments across FF++, MPIE, and LPFF demonstrate that AlphaFace surpasses state-of-the-art methods in pose-challenging cases. The project is publicly available on `https://github.com/andrewyu90/Alphaface_Official.git'.

</details>


### [11] [VISTA-PATH: An interactive foundation model for pathology image segmentation and quantitative analysis in computational pathology](https://arxiv.org/abs/2601.16451)
*Peixian Liang,Songhao Li,Shunsuke Koga,Yutong Li,Zahra Alipour,Yucheng Tang,Daguang Xu,Zhi Huang*

Main category: cs.CV

TL;DR: VISTA-PATH是一款交互式、类别感知的病理分割基础模型，通过整合视觉上下文、语义组织描述和专家空间提示，实现了跨异构病理图像的精确多类别分割。


<details>
  <summary>Details</summary>
Motivation: 当前的分割基础模型虽然通过大规模预训练提高了通用性，但仍将分割视为静态视觉预测任务，与病理学需求不符。病理图像中存在异质性结构，需要融入专家反馈并产生对临床解释有直接意义的像素级分割。

Method: 提出了VISTA-PATH模型，联合条件化分割于视觉上下文、语义组织描述和可选专家提供的空间提示。构建了VISTA-PATH Data数据集，包含超过160万图像-掩码-文本三元组，涵盖9个器官和93个组织类别。支持动态人机交互细化，通过稀疏补丁级边界框标注反馈传播到全玻片分割。

Result: 在大量保留测试集和外部基准测试中，VISTA-PATH始终优于现有分割基础模型。通过提出的肿瘤相互作用评分(TIS)改进组织微环境分析，该评分与患者生存率呈现强且显著的关联。

Conclusion: VISTA-PATH将病理图像分割从静态预测提升为交互式且临床基础的表征，为数字病理学建立了基础模型。其高保真、类别感知的分割是计算病理学的优选模型。

Abstract: Accurate semantic segmentation for histopathology image is crucial for quantitative tissue analysis and downstream clinical modeling. Recent segmentation foundation models have improved generalization through large-scale pretraining, yet remain poorly aligned with pathology because they treat segmentation as a static visual prediction task. Here we present VISTA-PATH, an interactive, class-aware pathology segmentation foundation model designed to resolve heterogeneous structures, incorporate expert feedback, and produce pixel-level segmentation that are directly meaningful for clinical interpretation. VISTA-PATH jointly conditions segmentation on visual context, semantic tissue descriptions, and optional expert-provided spatial prompts, enabling precise multi-class segmentation across heterogeneous pathology images. To support this paradigm, we curate VISTA-PATH Data, a large-scale pathology segmentation corpus comprising over 1.6 million image-mask-text triplets spanning 9 organs and 93 tissue classes. Across extensive held-out and external benchmarks, VISTA-PATH consistently outperforms existing segmentation foundation models. Importantly, VISTA-PATH supports dynamic human-in-the-loop refinement by propagating sparse, patch-level bounding-box annotation feedback into whole-slide segmentation. Finally, we show that the high-fidelity, class-aware segmentation produced by VISTA-PATH is a preferred model for computational pathology. It improve tissue microenvironment analysis through proposed Tumor Interaction Score (TIS), which exhibits strong and significant associations with patient survival. Together, these results establish VISTA-PATH as a foundation model that elevates pathology image segmentation from a static prediction to an interactive and clinically grounded representation for digital pathology. Source code and demo can be found at https://github.com/zhihuanglab/VISTA-PATH.

</details>


### [12] [Order from Chaos: Physical World Understanding from Glitchy Gameplay Videos](https://arxiv.org/abs/2601.16471)
*Meng Cao,Haoran Tang,Haoze Zhao,Mingfei Han,Ruyang Liu,Qiang Sun,Xiaojun Chang,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: 利用游戏视频中的视觉异常作为监督信号的物理世界理解新范式：PhysGame数据集和GameBench基准


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在物理世界理解方面仍不足，现有数据集要么标注成本高，要么真实性和多样性有限，因此需要寻找更丰富、可扩展的监督源。

Method: 提出PhysGame数据集，包含140,057个基于游戏故障的问答对，覆盖5个物理领域和16个细分类别，利用游戏元数据引导高质量QA生成；同时构建GameBench专家标注基准进行评估。

Result: 实验表明，PhysGame显著提升了Qwen2.5VL在真实世界物理推理性能（PhysBench上提升2.5%），在MVBench基准上提升1.9%，在GameBench上提升3.7%。

Conclusion: 从游戏异常中学习为多模态智能的物理世界理解提供了可扩展且有效的途径。

Abstract: Understanding the physical world, including object dynamics, material properties, and causal interactions, remains a core challenge in artificial intelligence. Although recent multi-modal large language models (MLLMs) have demonstrated impressive general reasoning capabilities, they still fall short of achieving human-level understanding of physical principles. Existing datasets for physical reasoning either rely on real-world videos, which incur high annotation costs, or on synthetic simulations, which suffer from limited realism and diversity. In this paper, we propose a novel paradigm that leverages glitches in gameplay videos, referring to visual anomalies that violate predefined physical laws, as a rich and scalable supervision source for physical world understanding. We introduce PhysGame, an meta information guided instruction-tuning dataset containing 140,057 glitch-centric question-answer pairs across five physical domains and sixteen fine-grained categories. To ensure data accuracy, we design a prompting strategy that utilizes gameplay metadata such as titles and descriptions to guide high-quality QA generation. Complementing PhysGame, we construct GameBench, an expert-annotated benchmark with 880 glitch-identified gameplay videos designed to evaluate physical reasoning capabilities. Extensive experiments show that PhysGame significantly enhances both Game2Real transferability, improving the real world physical reasoning performance of Qwen2.5VL by 2.5% on PhysBench, and Game2General transferability, yielding a 1.9% gain on the MVBench benchmark. Moreover, PhysGame-tuned models achieve a 3.7% absolute improvement on GameBench, demonstrating enhanced robustness in detecting physical implausibilities. These results indicate that learning from gameplay anomalies offers a scalable and effective pathway toward advancing physical world understanding in multimodal intelligence.

</details>


### [13] [Multi-View Consistent Wound Segmentation With Neural Fields](https://arxiv.org/abs/2601.16487)
*Remi Chierchia,Léo Lebrat,David Ahmedt-Aristizabal,Yulia Arzhaeva,Olivier Salvado,Clinton Fookes,Rodrigo Santa Cruz*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Wound care is often challenged by the economic and logistical burdens that consistently afflict patients and hospitals worldwide. In recent decades, healthcare professionals have sought support from computer vision and machine learning algorithms. In particular, wound segmentation has gained interest due to its ability to provide professionals with fast, automatic tissue assessment from standard RGB images. Some approaches have extended segmentation to 3D, enabling more complete and precise healing progress tracking. However, inferring multi-view consistent 3D structures from 2D images remains a challenge. In this paper, we evaluate WoundNeRF, a NeRF SDF-based method for estimating robust wound segmentations from automatically generated annotations. We demonstrate the potential of this paradigm in recovering accurate segmentations by comparing it against state-of-the-art Vision Transformer networks and conventional rasterisation-based algorithms. The code will be released to facilitate further development in this promising paradigm.

</details>


### [14] [SALAD: Achieve High-Sparsity Attention via Efficient Linear Attention Tuning for Video Diffusion Transformer](https://arxiv.org/abs/2601.16515)
*Tongcheng Fang,Hanling Zhang,Ruiqi Xie,Zhuo Han,Xin Tao,Tianchen Zhao,Pengfei Wan,Wenbo Ding,Wanli Ouyang,Xuefei Ning,Yu Wang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Diffusion Transformers have recently demonstrated remarkable performance in video generation. However, the long input sequences result in high computational latency due to the quadratic complexity of full attention. Various sparse attention mechanisms have been proposed. Training-free sparse attention is constrained by limited sparsity and thus offers modest acceleration, whereas training-based methods can reach much higher sparsity but demand substantial data and computation for training. In this work, we propose SALAD, introducing a lightweight linear attention branch in parallel with the sparse attention. By incorporating an input-dependent gating mechanism to finely balance the two branches, our method attains 90% sparsity and 1.72x inference speedup, while maintaining generation quality comparable to the full attention baseline. Moreover, our finetuning process is highly efficient, requiring only 2,000 video samples and 1,600 training steps with a batch size of 8.

</details>


### [15] [TangramPuzzle: Evaluating Multimodal Large Language Models with Compositional Spatial Reasoning](https://arxiv.org/abs/2601.16520)
*Daixian Liu,Jiayi Kuang,Yinghui Li,Yangning Li,Di Yin,Haoyu Cao,Xing Sun,Ying Shen,Hai-Tao Zheng,Liang Lin,Philip S. Yu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable progress in visual recognition and semantic understanding. Nevertheless, their ability to perform precise compositional spatial reasoning remains largely unexplored. Existing benchmarks often involve relatively simple tasks and rely on semantic approximations or coarse relative positioning, while their evaluation metrics are typically limited and lack rigorous mathematical formulations. To bridge this gap, we introduce TangramPuzzle, a geometry-grounded benchmark designed to evaluate compositional spatial reasoning through the lens of the classic Tangram game. We propose the Tangram Construction Expression (TCE), a symbolic geometric framework that grounds tangram assemblies in exact, machine-verifiable coordinate specifications, to mitigate the ambiguity of visual approximation. We design two complementary tasks: Outline Prediction, which demands inferring global shapes from local components, and End-to-End Code Generation, which requires solving inverse geometric assembly problems. We conduct extensive evaluation experiments on advanced open-source and proprietary models, revealing an interesting insight: MLLMs tend to prioritize matching the target silhouette while neglecting geometric constraints, leading to distortions or deformations of the pieces.

</details>


### [16] [OnlineSI: Taming Large Language Model for Online 3D Understanding and Grounding](https://arxiv.org/abs/2601.16538)
*Zixian Liu,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In recent years, researchers have increasingly been interested in how to enable Multimodal Large Language Models (MLLM) to possess spatial understanding and reasoning capabilities. However, most existing methods overlook the importance of the ability to continuously work in an ever-changing world, and lack the possibility of deployment on embodied systems in real-world environments. In this work, we introduce OnlineSI, a framework that can continuously improve its spatial understanding of its surroundings given a video stream. Our core idea is to maintain a finite spatial memory to retain past observations, ensuring the computation required for each inference does not increase as the input accumulates. We further integrate 3D point cloud information with semantic information, helping MLLM to better locate and identify objects in the scene. To evaluate our method, we introduce the Fuzzy $F_1$-Score to mitigate ambiguity, and test our method on two representative datasets. Experiments demonstrate the effectiveness of our method, paving the way towards real-world embodied systems.

</details>


### [17] [Semi-Supervised Hierarchical Open-Set Classification](https://arxiv.org/abs/2601.16541)
*Erik Wallin,Fredrik Kahl,Lars Hammarstrand*

Main category: cs.CV

TL;DR: 提出了一种基于伪标签的师生框架，实现了层次化开放集合半监督分类，可在未标注数据中处理已知和未知类别


<details>
  <summary>Details</summary>
Motivation: 现有的层次化开放集合分类方法无法利用大规模、未标注的数据集来提升性能。半监督设置能够充分利用包含已知和未知类别的未标注数据，从而改进层次化开放集合分类的效果

Method: 提出基于伪标签的师生框架，包含两个关键组件：1) 子树伪标签：在存在未知数据时提供可靠监督；2) 年龄门控机制：缓解伪标签的过自信问题

Result: 在iNaturalist19基准测试上，框架性能优于自监督预训练后监督适应的基线方法，在使用每类仅20个标注样本的情况下，性能甚至匹配完全监督的对标方法

Conclusion: 提出的半监督框架通过有效利用未标注数据，显著提升了层次化开放集合分类的性能，特别是在标注数据有限的情况下能够达到完全监督的性能水平

Abstract: Hierarchical open-set classification handles previously unseen classes by assigning them to the most appropriate high-level category in a class taxonomy. We extend this paradigm to the semi-supervised setting, enabling the use of large-scale, uncurated datasets containing a mixture of known and unknown classes to improve the hierarchical open-set performance. To this end, we propose a teacher-student framework based on pseudo-labeling. Two key components are introduced: 1) subtree pseudo-labels, which provide reliable supervision in the presence of unknown data, and 2) age-gating, a mechanism that mitigates overconfidence in pseudo-labels. Experiments show that our framework outperforms self-supervised pretraining followed by supervised adaptation, and even matches the fully supervised counterpart when using only 20 labeled samples per class on the iNaturalist19 benchmark. Our code is available at https://github.com/walline/semihoc.

</details>


### [18] [HA2F: Dual-module Collaboration-Guided Hierarchical Adaptive Aggregation Framework for Remote Sensing Change Detection](https://arxiv.org/abs/2601.16573)
*Shuying Li,Yuchen Wang,San Zhang,Chuang Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为HA2F的双模块协作引导的层次自适应聚合框架，用于遥感变化检测，通过动态层次特征校准和噪声自适应特征细化解决多时相特征对齐偏差和噪声干扰问题。


<details>
  <summary>Details</summary>
Motivation: 现有遥感变化检测方法要么专注于局部补丁特征提取，要么追求整体图像处理，导致跨时相特征匹配偏差和对辐射、几何噪声敏感。为了解决这些问题，本文设计了双模块协作框架。

Method: HA2F包含动态层次特征校准模块（DHFCM）和噪声自适应特征细化模块（NAFRM）。DHFCM通过感知特征选择动态融合相邻层次特征，抑制无关差异以解决多时相特征对齐偏差；NAFRM采用双重特征选择机制突出变化敏感区域并生成空间掩码，抑制无关区域或阴影干扰。

Result: 在LEVIR-CD、WHU-CD和SYSU-CD三个数据集上的实验表明，HA2F在精度指标和计算效率方面均优于现有对比方法，达到了最先进的性能。消融实验验证了DHFCM和NAFRM模块的有效性。

Conclusion: HA2F框架通过双模块协作机制有效解决了遥感变化检测中的特征对齐偏差和噪声干扰问题，在多个基准数据集上表现出优越的性能和良好的应用潜力。

Abstract: Remote sensing change detection (RSCD) aims to identify the spatio-temporal changes of land cover, providing critical support for multi-disciplinary applications (e.g., environmental monitoring, disaster assessment, and climate change studies). Existing methods focus either on extracting features from localized patches, or pursue processing entire images holistically, which leads to the cross temporal feature matching deviation and exhibiting sensitivity to radiometric and geometric noise. Following the above issues, we propose a dual-module collaboration guided hierarchical adaptive aggregation framework, namely HA2F, which consists of dynamic hierarchical feature calibration module (DHFCM) and noise-adaptive feature refinement module (NAFRM). The former dynamically fuses adjacent-level features through perceptual feature selection, suppressing irrelevant discrepancies to address multi-temporal feature alignment deviations. The NAFRM utilizes the dual feature selection mechanism to highlight the change sensitive regions and generate spatial masks, suppressing the interference of irrelevant regions or shadows. Extensive experiments verify the effectiveness of the proposed HA2F, which achieves state-of-the-art performance on LEVIR-CD, WHU-CD, and SYSU-CD datasets, surpassing existing comparative methods in terms of both precision metrics and computational efficiency. In addition, ablation experiments show that DHFCM and NAFRM are effective. \href{https://huggingface.co/InPeerReview/RemoteSensingChangeDetection-RSCD.HA2F}{HA2F Official Code is Available Here!}

</details>


### [19] [X-Aligner: Composed Visual Retrieval without the Bells and Whistles](https://arxiv.org/abs/2601.16582)
*Yuqian Zheng,Mariana-Iuliana Georgescu*

Main category: cs.CV

TL;DR: 提出了一种新颖的视频检索框架，通过跨注意力模块和两阶段训练策略，显著提升了组合视频检索性能，并在零样本图像检索任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有组合视频检索框架通常采用单阶段多模态融合，相对于初始基线只能获得有限的性能提升。为了充分利用视觉语言模型的表征能力，需要设计更有效的融合机制来增强多模态查询的表征质量。

Method: 基于BLIP系列架构，引入新颖的跨注意力模块X-Aligner，通过多层跨注意力逐步融合视觉和文本查询，并与目标视频表征对齐。此外，还将视觉查询的标题作为额外输入。采用两阶段训练：第一阶段仅训练新增模块，第二阶段微调文本查询编码器，以保持预训练的视觉语言模型表征。在Webvid-CoVR数据集上训练。

Result: 在Webvid-CoVR-Test上达到Recall@1 63.93%的state-of-the-art性能。在CIRCO和Fashion-IQ等组合图像检索数据集上的零样本评估也表现出强大的泛化能力。

Conclusion: 提出的框架通过渐进式多模态融合和两阶段训练策略，有效提升了组合视频检索的性能，并展示了在相关任务上的良好泛化能力。

Abstract: Composed Video Retrieval (CoVR) facilitates video retrieval by combining visual and textual queries. However, existing CoVR frameworks typically fuse multimodal inputs in a single stage, achieving only marginal gains over initial baseline. To address this, we propose a novel CoVR framework that leverages the representational power of Vision Language Models (VLMs). Our framework incorporates a novel cross-attention module X-Aligner, composed of cross-attention layers that progressively fuse visual and textual inputs and align their multimodal representation with that of the target video. To further enhance the representation of the multimodal query, we incorporate the caption of the visual query as an additional input. The framework is trained in two stages to preserve the pretrained VLM representation. In the first stage, only the newly introduced module is trained, while in the second stage, the textual query encoder is also fine-tuned. We implement our framework on top of BLIP-family architecture, namely BLIP and BLIP-2, and train it on the Webvid-CoVR data set. In addition to in-domain evaluation on Webvid-CoVR-Test, we perform zero-shot evaluations on the Composed Image Retrieval (CIR) data sets CIRCO and Fashion-IQ. Our framework achieves state-of-the-art performance on CoVR obtaining a Recall@1 of 63.93% on Webvid-CoVR-Test, and demonstrates strong zero-shot generalization on CIR tasks.

</details>


### [20] [A Lightweight Medical Image Classification Framework via Self-Supervised Contrastive Learning and Quantum-Enhanced Feature Modeling](https://arxiv.org/abs/2601.16608)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Intelligent medical image analysis is essential for clinical decision support but is often limited by scarce annotations, constrained computational resources, and suboptimal model generalization. To address these challenges, we propose a lightweight medical image classification framework that integrates self-supervised contrastive learning with quantum-enhanced feature modeling. MobileNetV2 is employed as a compact backbone and pretrained using a SimCLR-style self-supervised paradigm on unlabeled images. A lightweight parameterized quantum circuit (PQC) is embedded as a quantum feature enhancement module, forming a hybrid classical-quantum architecture, which is subsequently fine-tuned on limited labeled data. Experimental results demonstrate that, with only approximately 2-3 million parameters and low computational cost, the proposed method consistently outperforms classical baselines without self-supervised learning or quantum enhancement in terms of Accuracy, AUC, and F1-score. Feature visualization further indicates improved discriminability and representation stability. Overall, this work provides a practical and forward-looking solution for high-performance medical artificial intelligence under resource-constrained settings.

</details>


### [21] [Boundary and Position Information Mining for Aerial Small Object Detection](https://arxiv.org/abs/2601.16617)
*Rongxin Huang,Guangfeng Lin,Wenbo Zhou,Zhirong Li,Wenhuan Wu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Unmanned Aerial Vehicle (UAV) applications have become increasingly prevalent in aerial photography and object recognition. However, there are major challenges to accurately capturing small targets in object detection due to the imbalanced scale and the blurred edges. To address these issues, boundary and position information mining (BPIM) framework is proposed for capturing object edge and location cues. The proposed BPIM includes position information guidance (PIG) module for obtaining location information, boundary information guidance (BIG) module for extracting object edge, cross scale fusion (CSF) module for gradually assembling the shallow layer image feature, three feature fusion (TFF) module for progressively combining position and boundary information, and adaptive weight fusion (AWF) module for flexibly merging the deep layer semantic feature. Therefore, BPIM can integrate boundary, position, and scale information in image for small object detection using attention mechanisms and cross-scale feature fusion strategies. Furthermore, BPIM not only improves the discrimination of the contextual feature by adaptive weight fusion with boundary, but also enhances small object perceptions by cross-scale position fusion. On the VisDrone2021, DOTA1.0, and WiderPerson datasets, experimental results show the better performances of BPIM compared to the baseline Yolov5-P2, and obtains the promising performance in the state-of-the-art methods with comparable computation load.

</details>


### [22] [SCHIGAND: A Synthetic Facial Generation Mode Pipeline](https://arxiv.org/abs/2601.16627)
*Ananya Kadali,Sunnie Jehan-Morrison,Orasiki Wellington,Barney Evans,Precious Durojaiye,Richard Guest*

Main category: cs.CV

TL;DR: 提出SCHIGAND合成人脸生成流水线，通过融合多种先进生成模型实现高质量、可控的面部数据集生成，以解决真实数据隐私和稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 面部识别系统训练需要大量高质量人脸数据，但面临隐私法规、数据稀缺和伦理问题。现有的生成模型在真实性、多样性和身份保持方面存在局限性。

Method: 整合StyleCLIP、HyperStyle、InterfaceGAN和Diffusion模型构建SCHIGAND流水线，增强身份保持能力，同时生成真实的类内变化并保持类间区分性。

Result: 使用ArcFace评估显示，SCHIGAND在图像质量和多样性方面达到平衡，能有效替代真实数据集用于生物识别测试。

Conclusion: SCHIGAND为面部生物识别应用提供了隐私合规且可扩展的合成数据解决方案，有潜力补充甚至替代真实数据。

Abstract: The growing demand for diverse and high-quality facial datasets for training and testing biometric systems is challenged by privacy regulations, data scarcity, and ethical concerns. Synthetic facial images offer a potential solution, yet existing generative models often struggle to balance realism, diversity, and identity preservation. This paper presents SCHIGAND, a novel synthetic face generation pipeline integrating StyleCLIP, HyperStyle, InterfaceGAN, and Diffusion models to produce highly realistic and controllable facial datasets. SCHIGAND enhances identity preservation while generating realistic intra-class variations and maintaining inter-class distinctiveness, making it suitable for biometric testing. The generated datasets were evaluated using ArcFace, a leading facial verification model, to assess their effectiveness in comparison to real-world facial datasets. Experimental results demonstrate that SCHIGAND achieves a balance between image quality and diversity, addressing key limitations of prior generative models. This research highlights the potential of SCHIGAND to supplement and, in some cases, replace real data for facial biometric applications, paving the way for privacy-compliant and scalable solutions in synthetic dataset generation.

</details>


### [23] [Edge-Aware Image Manipulation via Diffusion Models with a Novel Structure-Preservation Loss](https://arxiv.org/abs/2601.16645)
*Minsu Gong,Nuri Ryu,Jungseul Ok,Sunghyun Cho*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in image editing leverage latent diffusion models (LDMs) for versatile, text-prompt-driven edits across diverse tasks. Yet, maintaining pixel-level edge structures-crucial for tasks such as photorealistic style transfer or image tone adjustment-remains as a challenge for latent-diffusion-based editing. To overcome this limitation, we propose a novel Structure Preservation Loss (SPL) that leverages local linear models to quantify structural differences between input and edited images. Our training-free approach integrates SPL directly into the diffusion model's generative process to ensure structural fidelity. This core mechanism is complemented by a post-processing step to mitigate LDM decoding distortions, a masking strategy for precise edit localization, and a color preservation loss to preserve hues in unedited areas. Experiments confirm SPL enhances structural fidelity, delivering state-of-the-art performance in latent-diffusion-based image editing. Our code will be publicly released at https://github.com/gongms00/SPL.

</details>


### [24] [ReWeaver: Towards Simulation-Ready and Topology-Accurate Garment Reconstruction](https://arxiv.org/abs/2601.16672)
*Ming Li,Hui Shan,Kai Zheng,Chentao Shen,Siyu Liu,Yanwei Fu,Zhen Chen,Xiangru Huang*

Main category: cs.CV

TL;DR: ReWeaver是一种从稀疏多视角RGB图像重建拓扑精确3D服装和缝纫图案的新框架，可预测接缝和衣片及其在2D UV空间和3D空间中的连接性，适用于物理仿真和机器人操作。


<details>
  <summary>Details</summary>
Motivation: 现有服装重建方法通常依赖非结构化表示，难以准确重建服装拓扑和缝纫结构，导致重建结果不适合高保真物理模拟。高质量3D服装重建对于缩小数字虚拟、虚拟试穿和机器人操作等领域中仿真与现实的差距至关重要。

Method: 提出ReWeaver框架，仅需最少4个输入视图，就能预测接缝和衣片及其连接性。构建了大规模数据集GCD-TS，包含多视角RGB图像、3D服装几何、纹理化人体网格和标注的缝纫图案，超过10万个合成样本。该框架预测的接缝和衣片与多视角图像精确对齐，生成结构化的2D-3D服装表示。

Result: 在广泛的实验中，ReWeaver在拓扑精度、几何对齐和接缝-衣片一致性方面始终优于现有方法，重建结果适用于高保真物理模拟和机器人操作。

Conclusion: ReWeaver解决了现有方法在服装拓扑和缝纫结构重建方面的局限性，提供了适合物理仿真和机器人应用的拓扑精确服装重建，为缩小仿真与现实差距提供了有效解决方案。

Abstract: High-quality 3D garment reconstruction plays a crucial role in mitigating the sim-to-real gap in applications such as digital avatars, virtual try-on and robotic manipulation. However, existing garment reconstruction methods typically rely on unstructured representations, such as 3D Gaussian Splats, struggling to provide accurate reconstructions of garment topology and sewing structures. As a result, the reconstructed outputs are often unsuitable for high-fidelity physical simulation. We propose ReWeaver, a novel framework for topology-accurate 3D garment and sewing pattern reconstruction from sparse multi-view RGB images. Given as few as four input views, ReWeaver predicts seams and panels as well as their connectivities in both the 2D UV space and the 3D space. The predicted seams and panels align precisely with the multi-view images, yielding structured 2D--3D garment representations suitable for 3D perception, high-fidelity physical simulation, and robotic manipulation. To enable effective training, we construct a large-scale dataset GCD-TS, comprising multi-view RGB images, 3D garment geometries, textured human body meshes and annotated sewing patterns. The dataset contains over 100,000 synthetic samples covering a wide range of complex geometries and topologies. Extensive experiments show that ReWeaver consistently outperforms existing methods in terms of topology accuracy, geometry alignment and seam-panel consistency.

</details>


### [25] [Affinity Contrastive Learning for Skeleton-based Human Activity Understanding](https://arxiv.org/abs/2601.16694)
*Hongda Liu,Yunfan Liu,Min Ren,Lin Sui,Yunlong Wang,Zhenan Sun*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In skeleton-based human activity understanding, existing methods often adopt the contrastive learning paradigm to construct a discriminative feature space. However, many of these approaches fail to exploit the structural inter-class similarities and overlook the impact of anomalous positive samples. In this study, we introduce ACLNet, an Affinity Contrastive Learning Network that explores the intricate clustering relationships among human activity classes to improve feature discrimination. Specifically, we propose an affinity metric to refine similarity measurements, thereby forming activity superclasses that provide more informative contrastive signals. A dynamic temperature schedule is also introduced to adaptively adjust the penalty strength for various superclasses. In addition, we employ a margin-based contrastive strategy to improve the separation of hard positive and negative samples within classes. Extensive experiments on NTU RGB+D 60, NTU RGB+D 120, Kinetics-Skeleton, PKU-MMD, FineGYM, and CASIA-B demonstrate the superiority of our method in skeleton-based action recognition, gait recognition, and person re-identification. The source code is available at https://github.com/firework8/ACLNet.

</details>


### [26] [CER-HV: A CER-Based Human-in-the-Loop Framework for Cleaning Datasets Applied to Arabic-Script HTR](https://arxiv.org/abs/2601.16713)
*Sana Al-azzawi,Elisa Barney,Marcus Liwicki*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Handwritten text recognition (HTR) for Arabic-script languages still lags behind Latin-script HTR, despite recent advances in model architectures, datasets, and benchmarks. We show that data quality is a significant limiting factor in many published datasets and propose CER-HV (CER-based Ranking with Human Verification) as a framework to detect and clean label errors. CER-HV combines a CER-based noise detector, built on a carefully configured Convolutional Recurrent Neural Network (CRNN) with early stopping to avoid overfitting noisy samples, and a human-in-the-loop (HITL) step that verifies high-ranking samples. The framework reveals that several existing datasets contain previously underreported problems, including transcription, segmentation, orientation, and non-text content errors. These have been identified with up to 90 percent precision in the Muharaf and 80-86 percent in the PHTI datasets.
  We also show that our CRNN achieves state-of-the-art performance across five of the six evaluated datasets, reaching 8.45 percent Character Error Rate (CER) on KHATT (Arabic), 8.26 percent on PHTI (Pashto), 10.66 percent on Ajami, and 10.11 percent on Muharaf (Arabic), all without any data cleaning. We establish a new baseline of 11.3 percent CER on the PHTD (Persian) dataset. Applying CER-HV improves the evaluation CER by 0.3-0.6 percent on the cleaner datasets and 1.0-1.8 percent on the noisier ones. Although our experiments focus on documents written in an Arabic-script language, including Arabic, Persian, Urdu, Ajami, and Pashto, the framework is general and can be applied to other text recognition datasets.

</details>


### [27] [Using Shadows in Circular Synthetic Aperture Sonar Imaging for Target Analysis](https://arxiv.org/abs/2601.16733)
*Yann Le Gall,Nicolas Burlet,Mathieu Simon,Fabien Novella,Samantha Dugelay,Jean-Philippe Malkasse*

Main category: cs.CV

TL;DR: 本文探索从圆合成孔径声纳数据中提取阴影信息的方法，用于改善目标分析和三维重建。通过子孔径滤波获取多视角图像，应用固定聚焦阴影增强技术，并设计交互界面进行可视化，最终通过空间雕刻方法实现目标三维形状重建。


<details>
  <summary>Details</summary>
Motivation: 传统CSAS处理会产生高分辨率二维图像，但圆形轨迹带来的视差会填充阴影区域，而阴影对于目标识别具有重要的形状信息。本文旨在从CSAS数据中恢复阴影信息，以提升目标分析和三维重建能力。

Method: 1. 使用子孔径滤波从圆形轨迹不同位置获取多视角图像集合
2. 应用固定聚焦阴影增强技术获取清晰阴影
3. 设计交互界面供操作员沿圆形轨迹可视化阴影
4. 采用空间雕刻重建方法从分割阴影中推断目标三维形状

Result: 研究结果表明，从圆合成孔径声纳数据中提取的阴影信息在改善目标分析和三维重建方面具有显著潜力。

Conclusion: 阴影信息在圆合成孔径声纳目标识别中具有重要价值，本文提出的方法能够有效提取和利用这些信息，为目标分析和三维重建提供了新的技术途径。

Abstract: Circular Synthetic Aperture Sonar (CSAS) provides a 360° azimuth view of the seabed, surpassing the limited aperture and mono-view image of conventional side-scan SAS. This makes CSAS a valuable tool for target recognition in mine warfare where the diversity of point of view is essential for reducing false alarms. CSAS processing typically produces a very high-resolution two-dimensional image. However, the parallax introduced by the circular displacement of the illuminator fill-in the shadow regions, and the shadow cast by an object on the seafloor is lost in favor of azimuth coverage and resolution. Yet the shadows provide complementary information on target shape useful for target recognition. In this paper, we explore a way to retrieve shadow information from CSAS data to improve target analysis and carry 3D reconstruction. Sub-aperture filtering is used to get a collection of images at various points of view along the circular trajectory and fixed focus shadow enhancement (FFSE) is applied to obtain sharp shadows. An interactive interface is also proposed to allow human operators to visualize these shadows along the circular trajectory. A space-carving reconstruction method is applied to infer the 3D shape of the object from the segmented shadows. The results demonstrate the potential of shadows in circular SAS for improving target analysis and 3D reconstruction.

</details>


### [28] [A Step to Decouple Optimization in 3DGS](https://arxiv.org/abs/2601.16736)
*Renjie Ding,Yaonan Wang,Min Liu,Jialin Zhu,Jiazheng Wang,Jiahao Zhao,Wenting Shen,Feixiang He,Xiang Che*

Main category: cs.CV

TL;DR: 论文回顾了3DGS优化过程中的耦合问题，提出了解耦与重组优化组件，并最终提出AdamW-GS优化器以实现更好的优化效率与表示能力


<details>
  <summary>Details</summary>
Motivation: 针对当前3DGS优化中存在的两个被忽视的细节——更新步长耦合导致的状态缩放问题和梯度耦合导致的正则化问题，作者希望重新审视优化过程以获得更好的性能

Method: 重新审视3DGS优化过程，将其分解为三个组件：稀疏Adam、重新状态正则化和解耦属性正则化，基于实验分析重新设计优化流程并提出AdamW-GS

Result: 在3DGS和3DGS-MCMC框架下进行大量实验验证，新提出的AdamW-GS同时实现了更好的优化效率和表示有效性

Conclusion: 通过系统分析3DGS优化中的耦合机制并重新设计优化策略，AdamW-GS在效率和质量方面均有显著提升，为3DGS优化提供了新的理解

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful technique for real-time novel view synthesis. As an explicit representation optimized through gradient propagation among primitives, optimization widely accepted in deep neural networks (DNNs) is actually adopted in 3DGS, such as synchronous weight updating and Adam with the adaptive gradient. However, considering the physical significance and specific design in 3DGS, there are two overlooked details in the optimization of 3DGS: (i) update step coupling, which induces optimizer state rescaling and costly attribute updates outside the viewpoints, and (ii) gradient coupling in the moment, which may lead to under- or over-effective regularization. Nevertheless, such a complex coupling is under-explored. After revisiting the optimization of 3DGS, we take a step to decouple it and recompose the process into: Sparse Adam, Re-State Regularization and Decoupled Attribute Regularization. Taking a large number of experiments under the 3DGS and 3DGS-MCMC frameworks, our work provides a deeper understanding of these components. Finally, based on the empirical analysis, we re-design the optimization and propose AdamW-GS by re-coupling the beneficial components, under which better optimization efficiency and representation effectiveness are achieved simultaneously.

</details>


### [29] [Curated endoscopic retrograde cholangiopancreatography images dataset](https://arxiv.org/abs/2601.16759)
*Alda João Andrade,Mónica Martins,André Ferreira,Tarcísio Araújo,Luís Lopes,Victor Alves*

Main category: cs.CV

TL;DR: 本研究为解决ERCP图像数据集稀缺问题，提供了一个包含19,018张原始图像和19,317张处理后图像的大型标注数据集，来自1,602名患者。所有图像均由经验丰富的胃肠病学家标注，并通过分类实验验证了数据集的有效性。


<details>
  <summary>Details</summary>
Motivation: 内窥镜逆行胰胆管造影术（ERCP）是诊断和治疗胆道和胰腺疾病的关键技术，人工智能被认为是实现自动诊断的解决方案之一。然而目前公开的ERCP数据集稀缺，限制了AI方法的应用，因此本研究旨在填补这一空白。

Method: 收集了来自1,602名患者的19,018张原始ERCP图像和19,317张处理后图像。其中5,519张图像由两名具有5年以上经验的胃肠病学家手动标注，并由一名具有20年以上经验的资深专家审查。所有专家每年进行超过400例ERCP手术。

Result: 创建了一个大型、经过精心整理的ERCP图像数据集，并通过分类实验验证了数据集的实用性和有效性，证明其可用于机器学习模型的训练和评估。

Conclusion: 该数据集为自动ERCP分析和胆道胰腺疾病诊断提供了基准资源，有助于推动AI在ERCP领域的应用和发展。数据集将作为公开资源供研究社区使用。

Abstract: Endoscopic Retrograde Cholangiopancreatography (ERCP) is a key procedure in the diagnosis and treatment of biliary and pancreatic diseases. Artificial intelligence has been pointed as one solution to automatize diagnosis. However, public ERCP datasets are scarce, which limits the use of such approach. Therefore, this study aims to help fill this gap by providing a large and curated dataset. The collection is composed of 19.018 raw images and 19.317 processed from 1.602 patients. 5.519 images are labeled, which provides a ready to use dataset. All images were manually inspected and annotated by two gastroenterologist with more than 5 years of experience and reviewed by another gastroenterologist with more than 20 years of experience, all with more than 400 ERCP procedures annually. The utility and validity of the dataset is proven by a classification experiment. This collection aims to provide or contribute for a benchmark in automatic ERCP analysis and diagnosis of biliary and pancreatic diseases.

</details>


### [30] [AutoRegressive Generation with B-rep Holistic Token Sequence Representation](https://arxiv.org/abs/2601.16771)
*Jiahao Li,Yunpeng Bai,Yongkang Dai,Hao Guo,Hongping Gan,Yilei Shi*

Main category: cs.CV

TL;DR: BrepARG将B-rep的几何和拓扑编码为统一的token序列表示，实现首个基于序列的B-rep生成方法，使用自回归变压器架构在几何建模任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统B-rep表示方法将几何和拓扑特征解耦处理，无法应用序列生成框架，而基于transformer的序列生成模型在许多领域表现出色，因此需要新的表示方法。

Method: 1. 将B-rep编码为三类token：几何、位置和面索引token；2. 分层构建整体token序列：先构建几何块（面和边），再进行几何块排序；3. 使用仅解码器的多层变压器架构，通过因果掩码和下一个token预测学习序列分布。

Result: 实验表明BrepARG在B-rep生成任务上达到了最先进的性能，验证了将B-rep表示为整体token序列的可行性。

Conclusion: BrepARG通过将B-rep编码为整体token序列，开辟了B-rep生成的新方向，实现了基于序列的B-rep生成，为几何建模提供了新方法。

Abstract: Previous representation and generation approaches for the B-rep relied on graph-based representations that disentangle geometric and topological features through decoupled computational pipelines, thereby precluding the application of sequence-based generative frameworks, such as transformer architectures that have demonstrated remarkable performance. In this paper, we propose BrepARG, the first attempt to encode B-rep's geometry and topology into a holistic token sequence representation, enabling sequence-based B-rep generation with an autoregressive architecture. Specifically, BrepARG encodes B-rep into 3 types of tokens: geometry and position tokens representing geometric features, and face index tokens representing topology. Then the holistic token sequence is constructed hierarchically, starting with constructing the geometry blocks (i.e., faces and edges) using the above tokens, followed by geometry block sequencing. Finally, we assemble the holistic sequence representation for the entire B-rep. We also construct a transformer-based autoregressive model that learns the distribution over holistic token sequences via next-token prediction, using a multi-layer decoder-only architecture with causal masking. Experiments demonstrate that BrepARG achieves state-of-the-art (SOTA) performance. BrepARG validates the feasibility of representing B-rep as holistic token sequences, opening new directions for B-rep generation.

</details>


### [31] [CASP: Few-Shot Class-Incremental Learning with CLS Token Attention Steering Prompts](https://arxiv.org/abs/2601.16773)
*Shuai Huang,Xuhan Lin,Yuwu Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为CLS Token Attention Steering Prompts (CASP)的新方法，用于解决小样本类增量学习（FSCIL）中的挑战。该方法通过引入可训练的偏置参数来显式调控自注意力权重，并设计了注意力扰动策略和流形 Token Mixup，从而提高了模型的泛化能力和表征能力。


<details>
  <summary>Details</summary>
Motivation: 在极端小样本增量学习设置下，模型的迁移和泛化能力变得至关重要。现有的基于提示的方法虽然取得了进展，但仍需要更好地利用预训练知识来学习可在基础会话中跨未来类别共享的特征表示。受CLS token的注意力机制启发，本文旨在开发一种能够有效调控注意力、提升泛化能力并减少参数开销的FSCIL方法。

Method: 提出了CLS Token Attention Steering Prompts (CASP): 
1. 在CLS token的查询、键和值投影中引入类共享的可训练偏置参数，以显式调制自注意力权重。
2. 设计了注意力扰动策略。
3. 在浅层特征空间中执行Manifold Token Mixup，合成潜在的新类别特征以提升泛化能力，并为后续任务保留表征容量。

Result: 在CUB200、CIFAR100和ImageNet-R数据集上的实验表明，CASP在标准和细粒度FSCIL设置下均优于现有最先进方法，且在增量阶段无需微调，并显著降低了参数开销。

Conclusion: CASP方法通过注意力调控和特征混合策略，有效提升了小样本类增量学习中的泛化能力，同时保持了较低的参数复杂度，为FSCIL问题提供了有效的解决方案。

Abstract: Few-shot class-incremental learning (FSCIL) presents a core challenge in continual learning, requiring models to rapidly adapt to new classes with very limited samples while mitigating catastrophic forgetting. Recent prompt-based methods, which integrate pretrained backbones with task-specific prompts, have made notable progress. However, under extreme few-shot incremental settings, the model's ability to transfer and generalize becomes critical, and it is thus essential to leverage pretrained knowledge to learn feature representations that can be shared across future categories during the base session. Inspired by the mechanism of the CLS token, which is similar to human attention and progressively filters out task-irrelevant information, we propose the CLS Token Attention Steering Prompts (CASP). This approach introduces class-shared trainable bias parameters into the query, key, and value projections of the CLS token to explicitly modulate the self-attention weights. To further enhance generalization, we also design an attention perturbation strategy and perform Manifold Token Mixup in the shallow feature space, synthesizing potential new class features to improve generalization and reserve the representation capacity for upcoming tasks. Experiments on the CUB200, CIFAR100, and ImageNet-R datasets demonstrate that CASP outperforms state-of-the-art methods in both standard and fine-grained FSCIL settings without requiring fine-tuning during incremental phases and while significantly reducing the parameter overhead.

</details>


### [32] [Incorporating Eye-Tracking Signals Into Multimodal Deep Visual Models For Predicting User Aesthetic Experience In Residential Interiors](https://arxiv.org/abs/2601.16811)
*Chen-Ying Chien,Po-Chih Kuo*

Main category: cs.CV

TL;DR: 该研究提出了一种双分支CNN-LSTM框架，结合视觉特征与眼动追踪信号来预测住宅内部空间的美学评估。


<details>
  <summary>Details</summary>
Motivation: 设计能促进福祉的环境需要理解人们对室内空间的感知和评价，但美学体验的预测仍很困难，因为感知具有主观性且视觉反应复杂。

Method: 研究收集了224个室内设计视频及28名参与者的同步眼动数据，参与者对15个美学维度进行了评分。提出了双分支CNN-LSTM框架，融合视觉特征与眼动信号。

Result: 模型在客观维度（如光线）上达到72.2%准确率，主观维度（如放松度）上达到66.8%，优于现有视频基准方法，在主观评估任务上表现更佳。实验发现，使用眼动数据训练的模型仅用视觉输入也能保持可比性能。消融实验显示瞳孔反应对客观评估贡献最大，而注视与视觉线索结合能提升主观评估。

Conclusion: 研究结果表明，在训练中融入眼动追踪作为特权信息具有价值，能为室内设计美学评估提供更实用的工具。

Abstract: Understanding how people perceive and evaluate interior spaces is essential for designing environments that promote well-being. However, predicting aesthetic experiences remains difficult due to the subjective nature of perception and the complexity of visual responses. This study introduces a dual-branch CNN-LSTM framework that fuses visual features with eye-tracking signals to predict aesthetic evaluations of residential interiors. We collected a dataset of 224 interior design videos paired with synchronized gaze data from 28 participants who rated 15 aesthetic dimensions. The proposed model attains 72.2% accuracy on objective dimensions (e.g., light) and 66.8% on subjective dimensions (e.g., relaxation), outperforming state-of-the-art video baselines and showing clear gains on subjective evaluation tasks. Notably, models trained with eye-tracking retain comparable performance when deployed with visual input alone. Ablation experiments further reveal that pupil responses contribute most to objective assessments, while the combination of gaze and visual cues enhances subjective evaluations. These findings highlight the value of incorporating eye-tracking as privileged information during training, enabling more practical tools for aesthetic assessment in interior design.

</details>


### [33] [SLD: Segmentation-Based Landmark Detection for Spinal Ligaments](https://arxiv.org/abs/2601.16782)
*Lara Blomenkamp,Ivanna Kramer,Sabine Bauer,Theresa Schöche*

Main category: cs.CV

TL;DR: 提出了韧带附着点检测新方法：先分割椎体，再用特定规则识别附着点，实现了跨脊柱区域的高精度自动检测。


<details>
  <summary>Details</summary>
Motivation: 目前自动检测方法局限性大——要么只适用于特定脊柱区域，要么精度不足，无法满足精确模拟椎间应力的生物力学建模需求。

Method: 两步法：先基于形状进行椎体三维分割，后应用特定规则识别各类附着点；兼顾自动化与领域知识，方法具有较强泛化能力。

Result: 在两个独立脊柱数据集上的交叉验证中，关键点的平均绝对误差（MAE）为0.7毫米，均方根误差（RMSE）为1.1毫米，性能超越现有方法。

Conclusion: 该方法准确、鲁棒且具有较优的泛化性，可提高脊柱模型的建模精度，为更可靠的生物力学分析提供有力支持。

Abstract: In biomechanical modeling, the representation of ligament attachments is crucial for a realistic simulation of the forces acting between the vertebrae. These forces are typically modeled as vectors connecting ligament landmarks on adjacent vertebrae, making precise identification of these landmarks a key requirement for constructing reliable spine models. Existing automated detection methods are either limited to specific spinal regions or lack sufficient accuracy. This work presents a novel approach for detecting spinal ligament landmarks, which first performs shape-based segmentation of 3D vertebrae and subsequently applies domain-specific rules to identify different types of attachment points. The proposed method outperforms existing approaches by achieving high accuracy and demonstrating strong generalization across all spinal regions. Validation on two independent spinal datasets from multiple patients yielded a mean absolute error (MAE) of 0.7 mm and a root mean square error (RMSE) of 1.1 mm.

</details>


### [34] [No Validation, No Problem: Predicting Model Performance from a Single Gradient](https://arxiv.org/abs/2601.16874)
*Fangzheng Wu,Brian Summa*

Main category: cs.CV

TL;DR: 研究者提出了一种无需验证集的快速检查点选择方法，使用单个批次前向-反向传播计算分类器头的梯度Frobenius范数，其负相关性在多种架构中得到验证。


<details>
  <summary>Details</summary>
Motivation: 传统检查点选择依赖验证集，消耗计算资源，且在某些任务中难以获得。本文旨在开发一种轻量级的无验证检查点选择指标。

Method: 通过单批次计算分类器头梯度的Frobenius范数 (||dL/dW||_F)，设计标准化方案：CNN家族使用头部尺度归一化，Transformer和现代CNN使用特征尺度归一化。将此方法推广到检测、分割和扩散模型中作为进度监控指标。

Result: 在ImageNet-1k的CNN和Transformer上，该方法接近理论最优检查点效果，平均差距仅4.24%（轻微调整后约1.12%）。在COCO上的检测和分割、以及CIFAR-10上的扩散模型中也验证了有效性。

Conclusion: 该方法提供了一种计算成本极低的无验证检查点选择和早期停止机制，只需单批次计算，无需标签，可作为标准训练流程的即插即用组件。

Abstract: We propose a validation-free checkpointing signal from a single forward-backward pass: the Frobenius norm of the classifier-head gradient on one detached-feature batch, ||g||_F = ||dL/dW||_F. Across ImageNet-1k CNNs and Transformers, this proxy is strongly negative with Top-1 and positive with loss. Selecting the checkpoint with the minimum head gradient in a short tail window closes most of the gap to the oracle (4.24% +/- 2.00% with a universal setup, about 1.12% with light per-family tuning). For practical deployment, a head-scale normalization is more stable within classic CNN families (e.g., ResNets), while a feature-scale normalization works well for Transformers and modern CNNs. The same one-batch probe also predicts COCO detection/segmentation mAP. In diffusion (UNet/DDPM on CIFAR-10), it tracks progress and enables near-oracle tail-window selection; it is positively correlated with same-distribution probe MSE and negatively with FID (lower is better), so it can be used as a lightweight, label-free monitor. Validation labels are never used beyond reporting. The probe adds much less than 0.1% of an epoch and works as a drop-in for validation-free checkpoint selection and early stopping.

</details>


### [35] [Evaluating Large Vision-language Models for Surgical Tool Detection](https://arxiv.org/abs/2601.16895)
*Nakul Poudel,Richard Simon,Cristian A. Linte*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Surgery is a highly complex process, and artificial intelligence has emerged as a transformative force in supporting surgical guidance and decision-making. However, the unimodal nature of most current AI systems limits their ability to achieve a holistic understanding of surgical workflows. This highlights the need for general-purpose surgical AI systems capable of comprehensively modeling the interrelated components of surgical scenes. Recent advances in large vision-language models that integrate multimodal data processing offer strong potential for modeling surgical tasks and providing human-like scene reasoning and understanding. Despite their promise, systematic investigations of VLMs in surgical applications remain limited. In this study, we evaluate the effectiveness of large VLMs for the fundamental surgical vision task of detecting surgical tools. Specifically, we investigate three state-of-the-art VLMs, Qwen2.5, LLaVA1.5, and InternVL3.5, on the GraSP robotic surgery dataset under both zero-shot and parameter-efficient LoRA fine-tuning settings. Our results demonstrate that Qwen2.5 consistently achieves superior detection performance in both configurations among the evaluated VLMs. Furthermore, compared with the open-set detection baseline Grounding DINO, Qwen2.5 exhibits stronger zero-shot generalization and comparable fine-tuned performance. Notably, Qwen2.5 shows superior instrument recognition, while Grounding DINO demonstrates stronger localization.

</details>


### [36] [ColorConceptBench: A Benchmark for Probabilistic Color-Concept Understanding in Text-to-Image Models](https://arxiv.org/abs/2601.16836)
*Chenxi Ruan,Yu Xiao,Yihan Hou,Guosheng Hu,Wei Zeng*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While text-to-image (T2I) models have advanced considerably, their capability to associate colors with implicit concepts remains underexplored. To address the gap, we introduce ColorConceptBench, a new human-annotated benchmark to systematically evaluate color-concept associations through the lens of probabilistic color distributions. ColorConceptBench moves beyond explicit color names or codes by probing how models translate 1,281 implicit color concepts using a foundation of 6,369 human annotations. Our evaluation of seven leading T2I models reveals that current models lack sensitivity to abstract semantics, and crucially, this limitation appears resistant to standard interventions (e.g., scaling and guidance). This demonstrates that achieving human-like color semantics requires more than larger models, but demands a fundamental shift in how models learn and represent implicit meaning.

</details>


### [37] [LoL: Longer than Longer, Scaling Video Generation to Hour](https://arxiv.org/abs/2601.16914)
*Justin Cui,Jie Wu,Ming Li,Tao Yang,Xiaojie Li,Rui Wang,Andrew Bai,Yuanhao Ban,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: 一篇研究视频生成中“汇崩”现象的论文，通过创新的RoPE扰动方法解决注意力汇帧导致的场景重置问题，实现长达12小时的连续视频生成。


<details>
  <summary>Details</summary>
Motivation: 当前长视频生成方法存在误差累积和长期一致性丢失问题，特别是注意力汇帧机制会导致“汇崩”现象，即生成内容反复回退到汇帧，造成场景重置和循环运动模式。

Method: 提出轻量级、无需训练的方法：引入多头RoPE扰动，打破多头注意力同质化，缓解长期视野崩溃。

Result: 方法有效抑制汇崩现象，同时保持生成质量，实现实时、流式、无限长度视频生成，成功生成长达12小时的连续视频。

Conclusion: 该研究首次展示了实时、流式、无限长度视频生成且质量衰减极小，解决了视频生成中的长期一致性难题，为超长视频生成提供了有效解决方案。

Abstract: Recent research in long-form video generation has shifted from bidirectional to autoregressive models, yet these methods commonly suffer from error accumulation and a loss of long-term coherence. While attention sink frames have been introduced to mitigate this performance decay, they often induce a critical failure mode we term sink-collapse: the generated content repeatedly reverts to the sink frame, resulting in abrupt scene resets and cyclic motion patterns. Our analysis reveals that sink-collapse originates from an inherent conflict between the periodic structure of Rotary Position Embedding (RoPE) and the multi-head attention mechanisms prevalent in current generative models. To address it, we propose a lightweight, training-free approach that effectively suppresses this behavior by introducing multi-head RoPE jitter that breaks inter-head attention homogenization and mitigates long-horizon collapse. Extensive experiments show that our method successfully alleviates sink-collapse while preserving generation quality. To the best of our knowledge, this work achieves the first demonstration of real-time, streaming, and infinite-length video generation with little quality decay. As an illustration of this robustness, we generate continuous videos up to 12 hours in length, which, to our knowledge, is among the longest publicly demonstrated results in streaming video generation.

</details>


### [38] [GPA-VGGT:Adapting VGGT to Large scale Localization by self-Supervised learning with Geometry and Physics Aware loss](https://arxiv.org/abs/2601.16885)
*Yangfan Xu,Lilian Zhang,Xiaofeng He,Pengdong Wu,Wenqi Wu,Jun Mao*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Transformer-based general visual geometry frameworks have shown promising performance in camera pose estimation and 3D scene understanding. Recent advancements in Visual Geometry Grounded Transformer (VGGT) models have shown great promise in camera pose estimation and 3D reconstruction. However, these models typically rely on ground truth labels for training, posing challenges when adapting to unlabeled and unseen scenes. In this paper, we propose a self-supervised framework to train VGGT with unlabeled data, thereby enhancing its localization capability in large-scale environments. To achieve this, we extend conventional pair-wise relations to sequence-wise geometric constraints for self-supervised learning. Specifically, in each sequence, we sample multiple source frames and geometrically project them onto different target frames, which improves temporal feature consistency. We formulate physical photometric consistency and geometric constraints as a joint optimization loss to circumvent the requirement for hard labels. By training the model with this proposed method, not only the local and global cross-view attention layers but also the camera and depth heads can effectively capture the underlying multi-view geometry. Experiments demonstrate that the model converges within hundreds of iterations and achieves significant improvements in large-scale localization. Our code will be released at https://github.com/X-yangfan/GPA-VGGT.

</details>


### [39] [Reward-Forcing: Autoregressive Video Generation with Reward Feedback](https://arxiv.org/abs/2601.16933)
*Jingran Zhang,Ning Li,Yuanhao Ban,Andrew Bai,Justin Cui*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While most prior work in video generation relies on bidirectional architectures, recent efforts have sought to adapt these models into autoregressive variants to support near real-time generation. However, such adaptations often depend heavily on teacher models, which can limit performance, particularly in the absence of a strong autoregressive teacher, resulting in output quality that typically lags behind their bidirectional counterparts. In this paper, we explore an alternative approach that uses reward signals to guide the generation process, enabling more efficient and scalable autoregressive generation. By using reward signals to guide the model, our method simplifies training while preserving high visual fidelity and temporal consistency. Through extensive experiments on standard benchmarks, we find that our approach performs comparably to existing autoregressive models and, in some cases, surpasses similarly sized bidirectional models by avoiding constraints imposed by teacher architectures. For example, on VBench, our method achieves a total score of 84.92, closely matching state-of-the-art autoregressive methods that score 84.31 but require significant heterogeneous distillation.

</details>


### [40] [Domain-invariant Mixed-domain Semi-supervised Medical Image Segmentation with Clustered Maximum Mean Discrepancy Alignment](https://arxiv.org/abs/2601.16954)
*Ba-Thinh Lam,Thanh-Huy Nguyen,Hoang-Thien Nguyen,Quang-Khai Bui-Tran,Nguyen Lan Vi Vu,Phat K. Huynh,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep learning has shown remarkable progress in medical image semantic segmentation, yet its success heavily depends on large-scale expert annotations and consistent data distributions. In practice, annotations are scarce, and images are collected from multiple scanners or centers, leading to mixed-domain settings with unknown domain labels and severe domain gaps. Existing semi-supervised or domain adaptation approaches typically assume either a single domain shift or access to explicit domain indices, which rarely hold in real-world deployment. In this paper, we propose a domain-invariant mixed-domain semi-supervised segmentation framework that jointly enhances data diversity and mitigates domain bias. A Copy-Paste Mechanism (CPM) augments the training set by transferring informative regions across domains, while a Cluster Maximum Mean Discrepancy (CMMD) block clusters unlabeled features and aligns them with labeled anchors via an MMD objective, encouraging domain-invariant representations. Integrated within a teacher-student framework, our method achieves robust and precise segmentation even with very few labeled examples and multiple unknown domain discrepancies. Experiments on Fundus and M&Ms benchmarks demonstrate that our approach consistently surpasses semi-supervised and domain adaptation methods, establishing a potential solution for mixed-domain semi-supervised medical image segmentation.

</details>


### [41] [VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents](https://arxiv.org/abs/2601.16973)
*Zirui Wang,Junyi Zhang,Jiaxin Ge,Long Lian,Letian Fu,Lisa Dunlap,Ken Goldberg,XuDong Wang,Ion Stoica,David M. Chan,Sewon Min,Joseph E. Gonzalez*

Main category: cs.CV

TL;DR: VisGym: 一个包含17个环境的视觉语言模型交互评估训练框架，揭示了当前VLMs在多步长视野视觉交互中的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在多步视觉交互、感知-记忆-行动的长期整合方面缺乏系统评估和深入理解。

Method: 设计VisGym框架，涵盖符号推理、真实图像理解、导航和操作任务，提供可调节难度、输入表示、规划视野和反馈控制，并开发了结构化演示生成的多步求解器支持监督微调。

Result: 评估显示所有前沿模型在交互环境中表现不佳，在简单和困难配置下成功率分别仅为46.6%和26.0%；模型在长上下文利用、文本到视觉表示转换方面存在明显缺陷。

Conclusion: VisGym系统性地揭示了VLMs的多步视觉决策限制，同时指出了明确的目标观察、文本反馈和部分可观测环境下的探索性演示等多种改进途径。

Abstract: Modern Vision-Language Models (VLMs) remain poorly characterized in multi-step visual interactions, particularly in how they integrate perception, memory, and action over long horizons. We introduce VisGym, a gymnasium of 17 environments for evaluating and training VLMs. The suite spans symbolic puzzles, real-image understanding, navigation, and manipulation, and provides flexible controls over difficulty, input representation, planning horizon, and feedback. We also provide multi-step solvers that generate structured demonstrations, enabling supervised finetuning. Our evaluations show that all frontier models struggle in interactive settings, achieving low success rates in both the easy (46.6%) and hard (26.0%) configurations. Our experiments reveal notable limitations: models struggle to effectively leverage long context, performing worse with an unbounded history than with truncated windows. Furthermore, we find that several text-based symbolic tasks become substantially harder once rendered visually. However, explicit goal observations, textual feedback, and exploratory demonstrations in partially observable or unknown-dynamics settings for supervised finetuning yield consistent gains, highlighting concrete failure modes and pathways for improving multi-step visual decision-making. Code, data, and models can be found at: https://visgym.github.io/.

</details>


### [42] [SyncLight: Controllable and Consistent Multi-View Relighting](https://arxiv.org/abs/2601.16981)
*David Serrano-Lozano,Anand Bhattad,Luis Herranz,Jean-François Lalonde,Javier Vazquez-Corral*

Main category: cs.CV

TL;DR: SyncLight首次实现了在未标定的多视角下对静态场景进行一致、参数化的重光照。它通过单次推理即可对整个图像集进行高质量重光照，且无需相机姿态信息。


<details>
  <summary>Details</summary>
Motivation: 解决了现有生成式方法在多视角重光照时难以保持严格光照一致性的问题，这对于多相机广播、立体电影和虚拟制作等应用至关重要。

Method: 采用基于隐空间桥接匹配公式的多视角扩散变换器，通过单次推理实现整个图像集的高保真重光照。训练使用大规模混合数据集，包括合成环境和真实世界多视角采集数据。

Result: 尽管仅用图像对进行训练，SyncLight能以零样本方式推广到任意数量的视角，有效在所有视图中传播光照变化，无需相机姿态信息。

Conclusion: SyncLight为多视角采集系统提供了实用的重光照工作流程，在保持光照一致性的同时实现了高质量的多视角重光照。

Abstract: We present SyncLight, the first method to enable consistent, parametric relighting across multiple uncalibrated views of a static scene. While single-view relighting has advanced significantly, existing generative approaches struggle to maintain the rigorous lighting consistency essential for multi-camera broadcasts, stereoscopic cinema, and virtual production. SyncLight addresses this by enabling precise control over light intensity and color across a multi-view capture of a scene, conditioned on a single reference edit. Our method leverages a multi-view diffusion transformer trained using a latent bridge matching formulation, achieving high-fidelity relighting of the entire image set in a single inference step. To facilitate training, we introduce a large-scale hybrid dataset comprising diverse synthetic environments -- curated from existing sources and newly designed scenes -- alongside high-fidelity, real-world multi-view captures under calibrated illumination. Surprisingly, though trained only on image pairs, SyncLight generalizes zero-shot to an arbitrary number of viewpoints, effectively propagating lighting changes across all views, without requiring camera pose information. SyncLight enables practical relighting workflows for multi-view capture systems.

</details>


### [43] [AnyView: Synthesizing Any Novel View in Dynamic Scenes](https://arxiv.org/abs/2601.16982)
*Basile Van Hoorick,Dian Chen,Shun Iwase,Pavel Tokmakov,Muhammad Zubair Irshad,Igor Vasiljevic,Swati Gupta,Fangzhou Cheng,Sergey Zakharov,Vitor Campagnolo Guizilini*

Main category: cs.CV

TL;DR: AnyView是一种新的扩散基视频生成框架，专注于动态视点合成，减少几何假设，利用多源数据训练，能在任意相机轨迹下生成零样本新视频，并在极端动态场景中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在多视角和时空一致性方面存在不足，特别是在高度动态的现实场景中。为克服这一问题，需要开发一种能处理任意视点、减少归纳偏差的动态视图合成方法。

Method: 使用扩散框架，融合单目（2D）、多视角静态（3D）和多视角动态（4D）数据集，训练一个通用的时空隐式表示模型，支持从任意相机位置和轨迹生成零样本新视频。

Result: 在标准基准测试中表现竞争性，在提出的新基准AnyViewBench（针对极端动态场景）中，相比需要视点大量重叠的基线方法，AnyView能生成更真实、合理且时空一致的视频。

Conclusion: AnyView通过多源数据训练和最小化几何假设，实现了在任意视点下的高质量动态视图合成，尤其在极端动态场景中优于现有方法，为通用视频生成提供了新方向。

Abstract: Modern generative video models excel at producing convincing, high-quality outputs, but struggle to maintain multi-view and spatiotemporal consistency in highly dynamic real-world environments. In this work, we introduce \textbf{AnyView}, a diffusion-based video generation framework for \emph{dynamic view synthesis} with minimal inductive biases or geometric assumptions. We leverage multiple data sources with various levels of supervision, including monocular (2D), multi-view static (3D) and multi-view dynamic (4D) datasets, to train a generalist spatiotemporal implicit representation capable of producing zero-shot novel videos from arbitrary camera locations and trajectories. We evaluate AnyView on standard benchmarks, showing competitive results with the current state of the art, and propose \textbf{AnyViewBench}, a challenging new benchmark tailored towards \emph{extreme} dynamic view synthesis in diverse real-world scenarios. In this more dramatic setting, we find that most baselines drastically degrade in performance, as they require significant overlap between viewpoints, while AnyView maintains the ability to produce realistic, plausible, and spatiotemporally consistent videos when prompted from \emph{any} viewpoint. Results, data, code, and models can be viewed at: https://tri-ml.github.io/AnyView/

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [44] [Ordering-based Causal Discovery via Generalized Score Matching](https://arxiv.org/abs/2601.16249)
*Vy Vo,He Zhao,Trung Le,Edwin V. Bonilla,Dinh Phung*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.

</details>


### [45] [Student Mental Health Screening via Fitbit Data Collected During the COVID-19 Pandemic](https://arxiv.org/abs/2601.16324)
*Rebecca Lopez,Avantika Shrestha,ML Tlachac,Kevin Hickey,Xingtong Guo,Shichao Liu,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 提出基于Fitbit生理数据的心理健康预测模型，评估心率与睡眠对抑郁、焦虑和压力筛查的效果，F1分数最高达0.79。


<details>
  <summary>Details</summary>
Motivation: 大学生心理健康问题凸显，现有可穿戴心理评估研究有限，疫情期间需无创监测手段，建立综合评估框架。

Method: 收集学生心理健康与环境健康(StudentMEH) Fitbit数据集，建立预测性机器学习模型，评估不同生理模态参数对抑郁/焦虑/压力的筛查能力。

Result: 心率模态在压力筛查达0.77 F1分数，睡眠模态在抑郁筛查达0.78 F1分数，焦虑筛查最高达0.79 F1分数。

Conclusion: 可穿戴设备具有持续心理监测潜力，需针对不同心理疾病确定最佳数据聚合水平和适宜生理模态，为心理健康筛查提供新途径。

Abstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited concerning the variety of psychological instruments administered, physiological modalities, and time series parameters. In this research, we collect the Student Mental and Environmental Health (StudentMEH) Fitbit dataset from students at our institution during the pandemic. We provide a comprehensive assessment of the ability of predictive machine learning models to screen for depression, anxiety, and stress using different Fitbit modalities. Our findings indicate potential in physiological modalities such as heart rate and sleep to screen for mental illness with the F1 scores as high as 0.79 for anxiety, the former modality reaching 0.77 for stress screening, and the latter modality achieving 0.78 for depression. This research highlights the potential of wearable devices to support continuous mental health monitoring, the importance of identifying best data aggregation levels and appropriate modalities for screening for different mental ailments.

</details>


### [46] [Efficient Gaussian process learning via subspace projections](https://arxiv.org/abs/2601.16332)
*Felipe Tobar,Elsa Cazelles*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.

</details>


### [47] [Analyzing Neural Network Information Flow Using Differential Geometry](https://arxiv.org/abs/2601.16366)
*Shuhang Tan,Jayson Sia,Paul Bogdan,Radoslav Ivanov*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper provides a fresh view of the neural network (NN) data flow problem, i.e., identifying the NN connections that are most important for the performance of the full model, through the lens of graph theory. Understanding the NN data flow provides a tool for symbolic NN analysis, e.g.,~robustness analysis or model repair. Unlike the standard approach to NN data flow analysis, which is based on information theory, we employ the notion of graph curvature, specifically Ollivier-Ricci curvature (ORC). The ORC has been successfully used to identify important graph edges in various domains such as road traffic analysis, biological and social networks. In particular, edges with negative ORC are considered bottlenecks and as such are critical to the graph's overall connectivity, whereas positive-ORC edges are not essential. We use this intuition for the case of NNs as well: we 1)~construct a graph induced by the NN structure and introduce the notion of neural curvature (NC) based on the ORC; 2)~calculate curvatures based on activation patterns for a set of input examples; 3)~aim to demonstrate that NC can indeed be used to rank edges according to their importance for the overall NN functionality. We evaluate our method through pruning experiments and show that removing negative-ORC edges quickly degrades the overall NN performance, whereas positive-ORC edges have little impact. The proposed method is evaluated on a variety of models trained on three image datasets, namely MNIST, CIFAR-10 and CIFAR-100. The results indicate that our method can identify a larger number of unimportant edges as compared to state-of-the-art pruning methods.

</details>


### [48] [A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning](https://arxiv.org/abs/2601.16399)
*Sihan Zeng,Sujay Bhatt,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: 本文提出了一种用于双层优化的单循环演员-评论家算法，通过惩罚重构和衰减熵正则化解决MDP中上层次奖励参数化和下层次策略优化的问题，无需二阶信息或强正则化。


<details>
  <summary>Details</summary>
Motivation: 现有的双层优化和强化学习方法往往需要二阶信息、对下层施加强正则化，或通过嵌套循环过程低效地使用样本，因此需要更高效的单循环一阶算法。

Method: 提出了单循环一阶演员-评论家算法，通过惩罚重构优化双层目标，在下层RL目标中引入衰减熵正则化，实现渐进无偏的上层超梯度估计。

Result: 在特定类型的Polyak-Lojasiewicz条件下，通过新的下层残差分析，建立了算法在原始无正则化双层优化问题中收敛到稳定点的有限时间和有限样本收敛性。

Conclusion: 算法在GridWorld目标位置问题和基于人类反馈的强化学习（RLHF）的快乐推文生成实验中验证了有效性，为解决双层优化问题提供了实用方法。

Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).

</details>


### [49] [Towards a Theoretical Understanding to the Generalization of RLHF](https://arxiv.org/abs/2601.16403)
*Zhaochun Li,Mingyang Yi,Yue Wang,Shisheng Cui,Yong Liu*

Main category: cs.LG

TL;DR: 该论文为基于人类反馈的强化学习(RLHF)在高维环境中的泛化性提供了理论分析，在假设线性的奖励模型和特征覆盖条件下，证明了策略模型的泛化界为O(n^{-1/2})。


<details>
  <summary>Details</summary>
Motivation: RLHF及其变体已成为对齐大型语言模型与人类意图的主要方法，虽然经验上有效，但在高维设置下的理论泛化性质尚未被充分探索，作者旨在填补这一空白。

Method: 在线性奖励模型的背景下，通过算法稳定性的框架，对RLHF进行端到端的学习建模分析，不同于现有基于奖励模型最大似然估计一致性的工作。

Result: 在关键的特征覆盖条件下，策略模型的极值点具有O(n^{-1/2})阶的泛化界，且该结果可以拓展到梯度上升(GA)和随机梯度上升(SGA)等梯度学习方法。

Conclusion: 该研究为RLHF后大型语言模型经验观察到的泛化性提供了理论证据，为理解其在高维设置中的应用提供了理论支撑。

Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\mathcal{O}(n^{-\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.

</details>


### [50] [Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction](https://arxiv.org/abs/2601.16406)
*Vitaly Bulgakov,Alexander Turchin*

Main category: cs.LG

TL;DR: 本文提出LPCORP框架，通过两阶段方法解决极端类别不平衡问题：先用推理模型产生丰富预测，再用逻辑回归分类器评估并选择性校正，以减轻流行度偏差。


<details>
  <summary>Details</summary>
Motivation: 稀有事件预测在医疗、金融、可靠性工程等领域至关重要，但极度类别不平衡会使传统模型偏向多数类预测，限制召回率、校准度和操作实用性。

Method: LPCORP是两阶段框架：1）推理模型从叙述输入产生丰富预测；2）轻量级逻辑回归分类器评估并选择性校正这些输出以减轻流行度驱动偏差。

Result: 该方法将高度不平衡设置转变为平衡设置，同时保持原始样本数量且不应用任何重采样策略，精度显著提高，并在某些情况下预计减少50%以上的成本。

Conclusion: LPCORP框架有效解决了低流行度数据的预测偏差问题，通过两阶段校正方法在保持样本完整性的同时显著提升预测性能，为实际应用提供了可行的解决方案。

Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.

</details>


### [51] [Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing](https://arxiv.org/abs/2601.16812)
*Francesca Lanzillotta,Chiara Albisani,Davide Pucci,Daniele Baracchi,Alessandro Piva,Matteo Lapucci*

Main category: cs.LG

TL;DR: 提出将学习任务中对单个数据样本的处理要求作为严格约束而非惩罚项，开发了一种在深度学习中具有收敛保证的顺序惩罚方法，实验证明该方法在实际应用中可行


<details>
  <summary>Details</summary>
Motivation: 在许多学习任务中，某些对单个数据样本的处理要求应作为底层优化问题的严格约束而非任意惩罚项来形式化，现有方法在处理这类约束时存在不足

Method: 采用顺序惩罚方法处理约束，该方法专门针对深度学习场景设计，能够将严格的样本级约束纳入优化过程中，而不是通过惩罚函数近似

Result: 该方法在合理假设下具有收敛保证，在图像处理任务上的实验结果表明，该方法在实际应用中是可行的，并且能够有效处理约束

Conclusion: 针对需要将数据处理要求作为严格约束而非惩罚项的学习任务，提出了一种实用的顺序惩罚方法，为深度学习中处理硬约束提供了新的有效解决方案

Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.

</details>


### [52] [A Refinement of Vapnik--Chervonenkis' Theorem](https://arxiv.org/abs/2601.16411)
*A. Iosevich,A. Vagharshakyan,E. Wyman*

Main category: cs.LG

TL;DR: 本文通过使用带有显式 Berry-Esseen 误差控制的正态近似代替 Hoeffding 不等式，对经典 VC 定理的概率部分进行了改进，获得了中等偏差下的精度提升。


<details>
  <summary>Details</summary>
Motivation: 重新审视经典 VC 定理的概率论证部分，通过改进分析方法获得更精确的收敛率估计，特别是在中等偏差情况下提供更锐利的结果。

Method: 使用带有显式 Berry-Esseen 误差控制的正态近似方法代替传统证明中的 Hoeffding 不等式，对 VC 定理的概率部分进行重新分析。

Result: 获得了比传统 VC 估计更锐利的中等偏差结果，当 ε√n 较大时，在主要的指数项中得到了 (ε√n)^(-1) 阶的额外因子改进。

Conclusion: 通过更精细的概率分析技术，可以显著改进经典 VC 定理的收敛率估计，为机器学习理论提供更精确的统计保证。

Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.
  We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\varepsilon\sqrt{n})^{-1}$ in the leading exponential term when $\varepsilon\sqrt{n}$ is large.

</details>


### [53] [PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning](https://arxiv.org/abs/2601.16414)
*John Wu,Yongda Fan,Zhenbang Wu,Paul Landes,Eric Schrock,Sayeed Sajjad Razin,Arjun Chatterjee,Naveen Baskaran,Joshua Steier,Andrea Fitzpatrick,Bilal Arif,Rian Atri,Jathurshan Pradeepkumar,Siddhartha Laghuvarapu,Junyi Gao,Adam R. Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: PyHealth 2.0是一个增强型临床深度学习工具包，旨在通过最小化代码行数（少至7行）来降低临床AI研究的门槛，解决基线复现难、计算成本高和专业知识要求高等挑战。


<details>
  <summary>Details</summary>
Motivation: 解决临床AI研究中存在的基线复现困难、计算成本高昂和领域专业知识要求的持续障碍。

Method: PyHealth 2.0提供了统一框架，整合了15+数据集、20+临床任务、25+模型、5+可解释性方法和不确定性量化，支持多种临床数据模态（信号、影像、电子健康记录），并具备多语言支持。

Result: 实现了高达39倍的加速处理和20倍的内存使用降低，支持从16GB笔记本电脑到生产系统的多样化计算资源，建立了拥有400+成员的活跃开源社区。

Conclusion: PyHealth 2.0建立了一个开源基础和社区，推动可访问、可重现的医疗AI发展。

Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.

</details>


### [54] [Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance](https://arxiv.org/abs/2601.16425)
*Huchen Yang,Xinghao Dong,Jin-Long Wu*

Main category: cs.LG

TL;DR: 本文通过系统对比KL散度和Wasserstein距离作为贝叶斯实验设计的效用函数，揭示了各自的适用场景：KL散度在无模型失配时收敛更快，而Wasserstein距离在存在显著模型失配时能提供更稳健的序贯BED结果，为实际应用提供了选择指南。


<details>
  <summary>Details</summary>
Motivation: 解决贝叶斯实验设计(BED)中长期存在的效用函数选择问题。虽然KL散度一直是常见选择，但近年来Wasserstein距离作为替代方案被提出。作者通过分析Wasserstein距离在某些情况下与信息增益无关的虚假奖励问题，系统对比这两种标准的性能差异，为实际应用提供指导。

Method: 1. 使用一个简单示例说明Wasserstein距离的问题：固定形状后验的Wasserstein距离值取决于其主要质量在支撑集内的相对位置，可能产生与信息增益无关的虚假奖励；2. 通过BED文献中的经典源反演问题，系统比较两种准则在不同情况下的表现，特别关注模型失配的影响。

Result: 1. 在无模型失配时，KL散度倾向于导致更快的收敛速度；2. 当模型失配不可忽略时，Wasserstein度量能够提供更稳健的序贯BED结果；3. 揭示了KL散度和Wasserstein距离作为效用函数的权衡取舍关系。

Conclusion: 研究阐明了KL散度和Wasserstein度量在效用函数选择中的权衡，为实际BED应用中选择合适准则提供了明确指导：根据是否存在显著模型失配来选择相应的效用函数标准。

Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.

</details>


### [55] [Endless Terminals: Scaling RL Environments for Terminal Agents](https://arxiv.org/abs/2601.16443)
*Kanishk Gandhi,Shivam Garg,Noah D. Goodman,Dimitris Papailiopoulos*

Main category: cs.LG

TL;DR: Endless Terminals是一个完全自主的流程，用于程序化生成终端使用任务，无需人工标注。使用普通PPO和简单交互训练智能体，在多个模型上取得显著性能提升，并且在人类标注基准上也有良好迁移效果。


<details>
  <summary>Details</summary>
Motivation: 环境是自改进agent的瓶颈。现有的终端基准仅用于评估而非训练，而强化学习需要一个可扩展的流程，而不仅仅是数据集。

Method: 流程包括四个阶段：生成多样化任务描述、构建和验证容器化环境、生成完成测试、以及筛选可解决的任务。最终获得3255个任务，涵盖文件操作、日志管理、数据处理、脚本编写和数据库操作。训练使用普通的PPO算法和二进制回合级奖励，采用最小化的交互循环，不涉及检索、多智能体协调或专用工具。

Result: 在内部开发集上，Llama-3.2-3B从4.0%提高到18.2%，Qwen2.5-7B从10.7%提高到53.3%，Qwen3-8B-openthinker-sft从42.6%提高到59.0%。在TerminalBench 2.0基准上，这些模型也表现出显著提升，并且超越了使用更复杂智能体框架的替代方法。

Conclusion: 研究结果表明，当环境具有可扩展性时，简单的强化学习方法就能取得显著成功。

Abstract: Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.

</details>


### [56] [On the Expressive Power of Floating-Point Transformers](https://arxiv.org/abs/2601.16450)
*Sejun Park,Yeachan Park,Geonho Hwang*

Main category: cs.LG

TL;DR: 本研究分析了使用浮点参数和操作的Transformer的表达能力，发现在有限精度计算环境下，其表达能力与理想的理论模型存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 现有研究证明Transformer在实数参数和精确操作下是具有置换等变性的，可以近似所有置换等变连续函数。但实际计算机实现只能使用有限精度的浮点数和不精确的机器操作，这引发了在浮点计算环境下Transformer表达能力如何变化的问题。

Method: 通过理论分析浮点Transformer（使用浮点参数和浮点操作）的表示能力，与理想实数参数Transformer进行比较研究。探讨了序列长度、位置编码等因素对浮点Transformer表达能力的影响。

Result: 发现浮点Transformer在没有位置编码的情况下也能表示一类非置换等变函数；当序列长度有界时可以表示所有置换等变函数，但序列长度较大时则不能；揭示了浮点Transformer的最小等变结构，并证明所有非平凡加性位置编码都会损害浮点Transformer的表示能力。

Conclusion: 浮点计算环境显著改变了Transformer的理论表达能力，实际实现的表达性与理想模型存在本质差异，位置编码在浮点实现中可能对表达式能力产生负面影响，这对于理解和设计实际Transformer模型具有重要意义。

Abstract: The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.

</details>


### [57] [Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario](https://arxiv.org/abs/2511.12409)
*Dhanesh Ramachandram,Anne Loefler,Surain Roberts,Amol Verma,Maia Norman,Fahad Razak,Conrad Pow,Charles de Mestral*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.

</details>


### [58] [On the Effects of Adversarial Perturbations on Distribution Robustness](https://arxiv.org/abs/2601.16464)
*Yipei Wang,Zhaoying Pan,Xiaoqian Wang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Adversarial robustness refers to a model's ability to resist perturbation of inputs, while distribution robustness evaluates the performance of the model under data shifts. Although both aim to ensure reliable performance, prior work has revealed a tradeoff in distribution and adversarial robustness. Specifically, adversarial training might increase reliance on spurious features, which can harm distribution robustness, especially the performance on some underrepresented subgroups. We present a theoretical analysis of adversarial and distribution robustness that provides a tractable surrogate for per-step adversarial training by studying models trained on perturbed data. In addition to the tradeoff, our work further identified a nuanced phenomenon that $\ell_\infty$ perturbations on data with moderate bias can yield an increase in distribution robustness. Moreover, the gain in distribution robustness remains on highly skewed data when simplicity bias induces reliance on the core feature, characterized as greater feature separability. Our theoretical analysis extends the understanding of the tradeoff by highlighting the interplay of the tradeoff and the feature separability. Despite the tradeoff that persists in many cases, overlooking the role of feature separability may lead to misleading conclusions about robustness.

</details>


### [59] [A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study](https://arxiv.org/abs/2601.16467)
*Maxwell Reynolds,Chaitanya Srinivasan,Vijay Cherupally,Michael Leone,Ke Yu,Li Sun,Tigmanshu Chaudhary,Andreas Pfenning,Kayhan Batmanghelich*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.

</details>


### [60] [Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning](https://arxiv.org/abs/2601.16491)
*Shenghong Cai,Yiqun Zhang,Xiaopeng Luo,Yiu-Ming Cheung,Hong Jia,Peng Liu*

Main category: cs.LG

TL;DR: 本文提出了一种基于多粒度竞争惩罚学习的分类数据聚类方法(MCDC)，通过MGCPL算法探索分类数据中的嵌套粒度簇结构，并使用CAME策略进行聚类，在多个领域的数据集上表现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 分类数据集在大数据分析中非常常见，但由于分类数据的定性特征，其隐式离散距离空间无法明确定义，导致聚类分析面临巨大挑战。分类数据中普遍存在嵌套粒度簇效应，需要新的方法来有效识别这种多粒度聚类结构。

Method: 提出多粒度竞争惩罚学习算法(MGCPL)，让潜在簇通过交互式调整以不同粒度的紧凑簇形式收敛。基于此提出簇聚合策略(CAME)，首先根据学到的多粒度分布对数据对象进行编码，然后在嵌入空间中进行最终聚类。整个方法称为MCDC(MGCPL指导的分类数据聚类)。

Result: MCDC能够自动探索多粒度簇的嵌套分布，对各种领域的分类数据集具有高度鲁棒性。具有线性时间复杂度，可扩展到大规模数据集。在多个真实公开数据集上的实验结果表明，该方法优于现有的先进方法。

Conclusion: MCDC方法能够有效处理分类数据的聚类问题，特别是识别嵌套的粒度簇结构，在大规模数据分析和分布式计算预分区方面具有应用前景。

Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.

</details>


### [61] [BoostFGL: Boosting Fairness in Federated Graph Learning](https://arxiv.org/abs/2601.16496)
*Zekai Chen,Kairui Yang,Xunkai Li,Henan Sun,Zhihan Zhang,Jia Li,Qiangqiang Dai,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantaged node groups. From a fairness perspective, these disparities arise systematically from three coupled sources: label skew toward majority patterns, topology confounding in message propagation, and aggregation dilution of updates from hard clients. To address this, we propose \textbf{BoostFGL}, a boosting-style framework for fairness-aware FGL. BoostFGL introduces three coordinated mechanisms: \ding{182} \emph{Client-side node boosting}, which reshapes local training signals to emphasize systematically under-served nodes; \ding{183} \emph{Client-side topology boosting}, which reallocates propagation emphasis toward reliable yet underused structures and attenuates misleading neighborhoods; and \ding{184} \emph{Server-side model boosting}, which performs difficulty- and reliability-aware aggregation to preserve informative updates from hard clients while stabilizing the global model. Extensive experiments on 9 datasets show that BoostFGL delivers substantial fairness gains, improving Overall-F1 by 8.43\%, while preserving competitive overall performance against strong FGL baselines.

</details>


### [62] [kNN-Graph: An adaptive graph model for $k$-nearest neighbors](https://arxiv.org/abs/2601.16509)
*Jiaye Li,Gang Chen,Hang Xu,Shichao Zhang*

Main category: cs.LG

TL;DR: 提出可适应图模型，将kNN邻居选择与权重计算完全前移到训练阶段，通过分层导航小世界图加速推理速度，实现实时性能且不损失分类精度。


<details>
  <summary>Details</summary>
Motivation: kNN算法在大型应用中的推理速度与精度存在计算权衡，现有近似最近邻方案虽加速检索但常降低分类精度，且缺乏对最优邻居规模的自适应性。

Method: 集成分层导航小世界图与预计算投票机制，高层图实现快速导航，低层图编码节点特定决策边界与自适应的邻居数量，将邻域选择与权重计算负担完全转移到训练阶段。

Result: 在六个多样化数据集上对八个先进基准测试，显示该架构显著加速推理速度达到实时性能，同时保持分类精度。

Conclusion: 为kNN长期存在的推理瓶颈提供了可扩展且鲁棒的解决方案，建立了基于图的非参数学习新结构范式。

Abstract: The k-nearest neighbors (kNN) algorithm is a cornerstone of non-parametric classification in artificial intelligence, yet its deployment in large-scale applications is persistently constrained by the computational trade-off between inference speed and accuracy. Existing approximate nearest neighbor solutions accelerate retrieval but often degrade classification precision and lack adaptability in selecting the optimal neighborhood size (k). Here, we present an adaptive graph model that decouples inference latency from computational complexity. By integrating a Hierarchical Navigable Small World (HNSW) graph with a pre-computed voting mechanism, our framework completely transfers the computational burden of neighbor selection and weighting to the training phase. Within this topological structure, higher graph layers enable rapid navigation, while lower layers encode precise, node-specific decision boundaries with adaptive neighbor counts. Benchmarking against eight state-of-the-art baselines across six diverse datasets, we demonstrate that this architecture significantly accelerates inference speeds, achieving real-time performance, without compromising classification accuracy. These findings offer a scalable, robust solution to the long-standing inference bottleneck of kNN, establishing a new structural paradigm for graph-based nonparametric learning.

</details>


### [63] [Finite-Time Analysis of Gradient Descent for Shallow Transformers](https://arxiv.org/abs/2601.16514)
*Enes Arda,Semih Cayci,Atilla Eryilmaz*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Understanding why Transformers perform so well remains challenging due to their non-convex optimization landscape. In this work, we analyze a shallow Transformer with $m$ independent heads trained by projected gradient descent in the kernel regime. Our analysis reveals two main findings: (i) the width required for nonasymptotic guarantees scales only logarithmically with the sample size $n$, and (ii) the optimization error is independent of the sequence length $T$. This contrasts sharply with recurrent architectures, where the optimization error can grow exponentially with $T$. The trade-off is memory: to keep the full context, the Transformer's memory requirement grows with the sequence length. We validate our theoretical results numerically in a teacher-student setting and confirm the predicted scaling laws for Transformers.

</details>


### [64] [DANCE: Dynamic, Available, Neighbor-gated Condensation for Federated Text-Attributed Graphs](https://arxiv.org/abs/2601.16519)
*Zekai Chen,Haodong Lu,Xunkai Li,Henan Sun,Jia Li,Hongchao Qin,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 提出了DANCE方法，通过图浓缩（GC）来解决文本属性图联邦学习中的成本、性能和可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的文本属性图联邦学习方法面临三大挑战：（1）处理长文本的大模型成本高，（2）一次性的图浓缩方法导致性能次优，（3）大模型浓缩过程缺乏可解释性，难以追踪预测来源。

Method: 设计了DANCE方法，通过轮次式的模型驱动图浓缩刷新机制来优化性能，并构建本地可检查的证据包来增强可解释性，实现预测结果到具体文本片段的溯源。

Result: 在8个数据集上，以8%的浓缩比例实现了准确率提升2.33%，同时比基线方法减少了33.42%的令牌消耗。

Conclusion: DANCE方法通过在联邦图学习中引入轮次刷新的图浓缩机制和可溯源设计，有效解决了成本、性能和可解释性的三重挑战。

Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \textbf{2.33\%} at an \textbf{8\%} condensation ratio, with \textbf{33.42\%} fewer tokens than baselines.

</details>


### [65] [Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs](https://arxiv.org/abs/2601.16527)
*Xianya Fang,Feiyang Ren,Xiang Chen,Yu Tian,Zhen Bi,Haiyang Yu,Sheng-Jun Huang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为SARE的新方法，通过几何稳定化解决多模态大模型中的物体幻觉问题，能够更鲁棒地消除幻觉概念


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型虽然强大，但容易产生物体幻觉（描述不存在的实体），这损害了模型的可靠性。现有的去学习方法存在结构脆弱性缺陷，只能实现表面抑制，模型容易陷入尖锐最小值，导致幻觉在轻量级再学习后灾难性复发

Method: 提出SARE方法，将去学习视为有针对性的最小-最大优化问题，使用Targeted-SAM机制来显式地平缓幻觉概念周围的损失景观。通过对模拟最坏情况参数扰动下的幻觉进行抑制，确保模型权重变化时的鲁棒消除

Result: 大量实验表明，SARE在消除效果上显著优于基线方法，同时保持了一般的生成质量。最重要的是，该方法能够在对再学习和参数更新的情况下保持持续的幻觉抑制

Conclusion: 研究证明了SARE方法在几何稳定化方面的有效性，能够实现持久的多模态大模型幻觉抑制，比现有方法更加稳定可靠

Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.

</details>


### [66] [A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics](https://arxiv.org/abs/2601.16531)
*Tao Lin*

Main category: cs.LG

TL;DR: 论文研究发现，在高频键冲突问题被消除的 Engram 内存架构中，性能提升并不显著，这暗示了键冲突本身具有正则化作用，而门控机制的信用分配问题是更本质的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 探索高频键冲突是否是 Engram 风格条件记忆的主要性能瓶颈。如果冲突是主要瓶颈，那么消除冲突应该会显著改善训练损失。

Method: 引入 Engram-Nine，一种无冲突的热层扩展，使用最小完美哈希函数（MPHF）映射最频繁的 n-gram，同时保留原始多头哈希查找作为冷层。在严格等参数设置下，对比有冲突和无冲突设计的性能。通过路由分层评估，将每个 token 的损失分解为热/冷层的贡献，分析训练动态。

Result: 无冲突设计并未持续改善验证损失。训练过程中出现了‘热到冷优势翻转’的现象：热层（高频）位置最初损失较低，但冷层位置最终会超越。重要的是，无冲突配置比有冲突基线更早发生翻转，这表明冲突起到了隐式正则化的作用。同时发现了门控不匹配问题：门控早期学会偏袒热位置，但这种偏好即使翻转后仍持续存在，导致权重分配给了损失更高的位置。

Conclusion: 单纯提高查找精度并不能保证训练结果更好。主要的限制可能在于门控的信用分配机制，而不是索引的准确性；而且冲突引入的噪声可能提供了有益的正则化，不应被轻易消除。

Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.
  Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent "hot-to-cold advantage flip" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.
  Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.

</details>


### [67] [Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm](https://arxiv.org/abs/2601.16552)
*Xiaobin Li,Run Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.

</details>


### [68] [Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach](https://arxiv.org/abs/2601.16568)
*Abdurahman Maarouf,Alket Bakiaj,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 针对早期初创企业投资预测的数据稀缺问题，提出了基于大语言模型的kNN-ICL上下文学习框架，无需模型训练，仅需少量标注样本即可获得优于传统机器学习方法的预测性能。


<details>
  <summary>Details</summary>
Motivation: 早期初创公司的成功预测对风险投资至关重要，但面临数据稀缺的挑战——许多VC公司只有几十个初创企业的标注信息。传统机器学习方法依赖于大量标注数据进行模型训练，在这种数据稀缺环境下效果受限。

Method: 提出了kNN-ICL（k最近邻上下文学习）框架，利用大语言模型进行预测，无需模型训练。该方法通过相似性选择最相关的历史初创企业作为上下文示例，仅需少数标注样本作为演示示例。

Result: 使用Crunchbase真实数据实验表明，kNN-ICL方法比监督机器学习基线和普通上下文学习获得了更高的预测准确率。仅需50个示例就能达到较高的平衡准确率，证明了在数据稀缺环境下的有效性。

Conclusion: 上下文学习可以作为风险投资公司在数据稀缺环境下的有效决策工具，该方法突破了传统机器学习对大量标注数据的依赖，为早期初创企业成功预测提供了实用解决方案。

Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.

</details>


### [69] [Integrating Meteorological and Operational Data: A Novel Approach to Understanding Railway Delays in Finland](https://arxiv.org/abs/2601.16592)
*Vinicius Pozzobon Borin,Jean Michel de Souza Sant'Ana,Usama Raheel,Nurul Huda Mahmood*

Main category: cs.LG

TL;DR: 首个结合芬兰铁路运营数据与同步气象观测的公开数据集（2018-2024），包含2,850万条观测记录，用于分析天气对铁路可靠性的影响并支持机器学习应用。


<details>
  <summary>Details</summary>
Motivation: 现有数据集很少将气象信息与铁路运营数据整合，尤其是在天气影响显著的北欧地区，缺乏公开可用资源来研究天气与铁路可靠性的复杂交互关系。

Method: 通过Haversine距离进行时空对齐，整合芬兰Digitraffic铁路交通服务的运营指标与209个环境监测站的气象测量数据，采用空间回退算法处理缺失值，对时间特征进行循环编码，并对天气数据进行鲁棒缩放。

Result: 数据揭示明显的季节性模式，冬季延误率超过25%，高延误走廊集中在芬兰中部和北部；XGBoost回归基线实验在预测站点特定延误时达到2.73分钟的平均绝对误差。

Conclusion: 该数据集为铁路运营研究提供了灵活资源，支持列车延误预测、天气影响评估和基础设施脆弱性分析等多样应用，填补了气象与铁路运营整合数据集的空白。

Abstract: Train delays result from complex interactions between operational, technical, and environmental factors. While weather impacts railway reliability, particularly in Nordic regions, existing datasets rarely integrate meteorological information with operational train data. This study presents the first publicly available dataset combining Finnish railway operations with synchronized meteorological observations from 2018-2024. The dataset integrates operational metrics from Finland Digitraffic Railway Traffic Service with weather measurements from 209 environmental monitoring stations, using spatial-temporal alignment via Haversine distance. It encompasses 28 engineered features across operational variables and meteorological measurements, covering approximately 38.5 million observations from Finland's 5,915-kilometer rail network. Preprocessing includes strategic missing data handling through spatial fallback algorithms, cyclical encoding of temporal features, and robust scaling of weather data to address sensor outliers. Analysis reveals distinct seasonal patterns, with winter months exhibiting delay rates exceeding 25\% and geographic clustering of high-delay corridors in central and northern Finland. Furthermore, the work demonstrates applications of the data set in analysing the reliability of railway traffic in Finland. A baseline experiment using XGBoost regression achieved a Mean Absolute Error of 2.73 minutes for predicting station-specific delays, demonstrating the dataset's utility for machine learning applications. The dataset enables diverse applications, including train delay prediction, weather impact assessment, and infrastructure vulnerability mapping, providing researchers with a flexible resource for machine learning applications in railway operations research.

</details>


### [70] [E2Former-V2: On-the-Fly Equivariant Attention with Linear Activation Memory](https://arxiv.org/abs/2601.16622)
*Lin Huang,Chengxiang Huang,Ziang Wang,Yiyue Du,Chu Wang,Haocheng Lu,Yunyang Li,Xiaoli Liu,Arthur Jiang,Jia Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Equivariant Graph Neural Networks (EGNNs) have become a widely used approach for modeling 3D atomistic systems. However, mainstream architectures face critical scalability bottlenecks due to the explicit construction of geometric features or dense tensor products on \textit{every} edge. To overcome this, we introduce \textbf{E2Former-V2}, a scalable architecture that integrates algebraic sparsity with hardware-aware execution. We first propose \textbf{E}quivariant \textbf{A}xis-\textbf{A}ligned \textbf{S}parsification (EAAS). EAAS builds on Wigner-$6j$ convolution by exploiting an $\mathrm{SO}(3) \rightarrow \mathrm{SO}(2)$ change of basis to transform computationally expensive dense tensor contractions into efficient, sparse parity re-indexing operations. Building on this representation, we introduce \textbf{On-the-Fly Equivariant Attention}, a fully node-centric mechanism implemented via a custom fused Triton kernel. By eliminating materialized edge tensors and maximizing SRAM utilization, our kernel achieves a \textbf{20$\times$ improvement in TFLOPS} compared to standard implementations. Extensive experiments on the SPICE and OMol25 datasets demonstrate that E2Former-V2 maintains comparable predictive performance while notably accelerating inference. This work demonstrates that large equivariant transformers can be trained efficiently using widely accessible GPU platforms. The code is avalible at https://github.com/IQuestLab/UBio-MolFM/tree/e2formerv2.

</details>


### [71] [Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting](https://arxiv.org/abs/2601.16632)
*Haonan Yang,Jianchao Tang,Zhuo Li*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.

</details>


### [72] [Provably Robust Bayesian Counterfactual Explanations under Model Changes](https://arxiv.org/abs/2601.16659)
*Jamie Duell,Xiuyi Fan*

Main category: cs.LG

TL;DR: 本文提出了一种概率安全的反事实解释方法（PSCE），通过贝叶斯框架确保反事实解释在模型更新时仍具有高预测置信度和低方差，并提供形式化的概率保证。


<details>
  <summary>Details</summary>
Motivation: 传统反事实解释在模型频繁更新的现实场景中容易失效，缺乏对模型变化的鲁棒性保证。

Method: 基于贝叶斯原理构建PSCE方法，引入δ-安全（高预测置信度）和ε-鲁棒（低预测方差）的概念，通过不确定性感知的约束优化框架生成反事实解释。

Result: 在多个数据集上的实验表明，PSCE生成的反事实解释比现有贝叶斯方法更具合理性、判别性，且对模型变化具有可证明的鲁棒性。

Conclusion: PSCE方法为反事实解释提供了形式化的概率安全保证，能够有效应对实际应用中模型更新的挑战，提高解释的可靠性和实用性。

Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $δ$-safe, to ensure high predictive confidence, and $ε$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\langle δ, ε\rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.

</details>


### [73] [Dynamic Expert-Guided Model Averaging for Causal Discovery](https://arxiv.org/abs/2601.16715)
*Adrick Tench,Thomas Demeester*

Main category: cs.LG

TL;DR: 提出了一种利用动态请求专家知识（如LLMs）来集成多种因果发现算法的灵活模型平均方法，以应对实际应用中算法选择困难和假设违反的问题。


<details>
  <summary>Details</summary>
Motivation: 实践中面临多种因果发现算法选择困难，且现实场景常违反算法假设，依赖专家知识，因此探索集成方法和利用LLMs等专家知识进行辅助。

Method: 采用动态请求专家知识的方式，结合模型平均技术，集成多个因果发现算法，利用LLMs等不完美专家处理干净和噪声数据。

Result: 实验证明该方法在干净和噪声数据上均有效，分析了专家正确性程度的影响，并评估了LLMs在临床因果发现中的能力。

Conclusion: 该集成方法为实践者提供了有价值的见解，特别是在利用LLMs等不完美专家进行因果发现时，展示了其在实际应用中的潜力。

Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.

</details>


### [74] [Calibrated Probabilistic Interpolation for GEDI Biomass](https://arxiv.org/abs/2601.16834)
*Robin Young,Srinivasan Keshav*

Main category: cs.LG

TL;DR: 该研究提出了


<details>
  <summary>Details</summary>
Motivation: NASA GEDI任务的林间到林间生物量映射需要处理异质景观中稀疏LiDAR观测的插值问题。尽管随机森林和XGBoost等机器学习方法是标准工具，但它们未能适应异质景观的不同难度水平，并且无法产生校准良好的预测区间。主要问题在于将集成方差与偶然不确定性混为一谈，并忽视了局部空间背景。

Method: 为了解决这些问题，研究引入了Attentive Neural Processes（ANPs），这是一个概率元学习框架，明确地将预测条件建立在局部观测集和地理空间基础模型嵌入上。与静态集成方法不同，ANPs学习了灵活的空间协方差函数，使不确定性估计能够在复杂景观中扩展，在均质区域中收缩。

Result: 该方法在从热带亚马逊森林到北方和阿尔卑斯生态系统的五个不同生物群落中进行了验证，结果表明ANPs在实现具有竞争力准确性的同时，保持了接近理想的不确定性校准。通过少样本适应性测试表明，该模型能够使用极少的本地数据，在跨区域转移中恢复大部分性能差距。

Conclusion: 这项工作为洲际尺度的地球观测提供了一个可扩展、理论严谨的替代方案，用于替代传统的集成方差方法。

Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.
  To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.

</details>


### [75] [The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics](https://arxiv.org/abs/2601.16849)
*Henri Nikoleit,Ankit Anand,Anurag Murty Naredla,Heiko Röglin*

Main category: cs.LG

TL;DR: 本论文展现人机协同在解决理论计算机科学开放问题中的力量，通过改进FunSearch算法的输出来提升经典启发式算法的下界，在多个组合优化问题上取得了十年未见的突破性进展。


<details>
  <summary>Details</summary>
Motivation: 研究者旨在探索人类与大型语言模型（LLM）协作在理论计算机科学研究中的潜力，特别是针对长期未解决的组合优化问题，试图通过结合LLM的模式发现能力和人类专家的深度洞察来突破现有瓶颈。

Method: 采用FunSearch算法生成初始结果，然后通过人工专家的迭代精炼，设计对抗性实例来挑战标准启发式算法，在层次k-中值聚类、装箱问题、背包问题以及Lovász汽油问题的推广等多个经典问题上展开研究。

Result: 研究成功提升了多个组合优化问题的下界，其中一些问题的结果在过去十多年间都未曾有实质性进展，证明了人机协作模式的有效性，突破了长期存在的理论障碍。

Conclusion: 大型语言模型是数学和计算机科学研究的强大协作工具，虽然能提供关键初始模式，但人类专业知识对于将这些模式转化为数学严谨且富有洞察力的构造至关重要，这种协同研究模式具有重要意义。

Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lovász's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.
  Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.

</details>


### [76] [Provably Learning Attention with Queries](https://arxiv.org/abs/2601.16873)
*Satwik Bhattamishra,Kulin Shah,Michael Hahn,Varun Kanade*

Main category: cs.LG

TL;DR: 本文研究了仅通过黑盒查询输出学习Transformer模型参数的问题。针对单头softmax注意力模型，提出了不同的高效学习算法，包括O(d²)查询的精确学习、O(rd)查询的压缩感知方法，并分析了噪声容忍性。同时证明了多头注意力参数无法仅从值查询中被唯一识别。


<details>
  <summary>Details</summary>
Motivation: Transformer已成为序列建模的主导架构，理解其学习能力和样本效率对理论分析和实际应用至关重要。本文旨在探索仅通过模型输出查询（无需梯度信息）能否高效学习Transformer参数，特别是注意力机制的参数，这有助于理解Transformer的可学习性边界。

Method: 针对单头注意力模型，提出了两种算法：1）基于精确学习的O(d²)查询算法；2）利用头维度r≪d的压缩感知算法，实现O(rd)查询效率。分析了噪声下的鲁棒性条件。通过构造反例证明了多头注意力参数的非可识别性问题。

Result: 单头注意力模型可在多项式查询复杂度下被精确学习，且算法对噪声具有鲁棒性。但多头注意力模型存在参数非唯一性问题——不同的参数配置可能产生完全相同的输入输出映射，因此无法保证类似单头情形的学习保证。

Conclusion: 单头注意力模型在黑盒查询设定下具有良好的可学习性，可通过高效算法恢复参数。但对于更复杂的多头注意力模型，由于参数非唯一性，需要额外的结构假设才能保证可识别性。这一结果揭示了Transformer不同组件在查询学习范式下的根本差异。

Abstract: We study the problem of learning Transformer-based sequence models with black-box access to their outputs. In this setting, a learner may adaptively query the oracle with any sequence of vectors and observe the corresponding real-valued output. We begin with the simplest case, a single-head softmax-attention regressor. We show that for a model with width $d$, there is an elementary algorithm to learn the parameters of single-head attention exactly with $O(d^2)$ queries. Further, we show that if there exists an algorithm to learn ReLU feedforward networks (FFNs), then the single-head algorithm can be easily adapted to learn one-layer Transformers with single-head attention. Next, motivated by the regime where the head dimension $r \ll d$, we provide a randomised algorithm that learns single-head attention-based models with $O(rd)$ queries via compressed sensing arguments. We also study robustness to noisy oracle access, proving that under mild norm and margin conditions, the parameters can be estimated to $\varepsilon$ accuracy with a polynomial number of queries even when outputs are only provided up to additive tolerance. Finally, we show that multi-head attention parameters are not identifiable from value queries in general -- distinct parameterisations can induce the same input-output map. Hence, guarantees analogous to the single-head setting are impossible without additional structural assumptions.

</details>


### [77] [Multigrade Neural Network Approximation](https://arxiv.org/abs/2601.16884)
*Shijun Zhang,Zuowei Shen,Yuesheng Xu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study multigrade deep learning (MGDL) as a principled framework for structured error refinement in deep neural networks. While the approximation power of neural networks is now relatively well understood, training very deep architectures remains challenging due to highly non-convex and often ill-conditioned optimization landscapes. In contrast, for relatively shallow networks, most notably one-hidden-layer $\texttt{ReLU}$ models, training admits convex reformulations with global guarantees, motivating learning paradigms that improve stability while scaling to depth. MGDL builds upon this insight by training deep networks grade by grade: previously learned grades are frozen, and each new residual block is trained solely to reduce the remaining approximation error, yielding an interpretable and stable hierarchical refinement process. We develop an operator-theoretic foundation for MGDL and prove that, for any continuous target function, there exists a fixed-width multigrade $\texttt{ReLU}$ scheme whose residuals decrease strictly across grades and converge uniformly to zero. To the best of our knowledge, this work provides the first rigorous theoretical guarantee that grade-wise training yields provable vanishing approximation error in deep networks. Numerical experiments further illustrate the theoretical results.

</details>


### [78] [FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization](https://arxiv.org/abs/2601.16897)
*Antesh Upadhyay,Sang Bin Moon,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: FedSGM是一个统一的联邦约束优化框架，解决了联邦学习中的四个主要挑战：函数约束、通信瓶颈、本地更新和部分客户端参与


<details>
  <summary>Details</summary>
Motivation: 当前的联邦学习方法在处理函数约束时面临多重挑战，包括需要昂贵的双重变量调整、内部求解器、通信效率低下，以及缺乏对压缩噪声与本地更新之间相互作用的理论理解

Method: 基于切换梯度法，提供无投影、纯原始变量的更新，避免了双变量调整或内部求解器。结合双向错误反馈处理通信限制，明确分析压缩噪声与多步本地更新之间的相互作用。此外还引入了软切换版本以稳定边界附近的更新

Result: 理论分析表明平均迭代达到经典O(1/√T)收敛率，提供额外的高概率界限，将优化进展与部分参与引起的采样噪声解耦。实验验证了在Neyman-Pearson分类和约束马尔科夫决策过程任务上的有效性

Conclusion: FedSGM是首个统一处理函数约束、压缩、多步本地更新和部分客户端参与的框架，为约束联邦学习建立了理论基础，并展示了在现实任务中的实际效果

Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.

</details>


### [79] [Embedding -based Crop Type Classification in the Groundnut Basin of Senegal](https://arxiv.org/abs/2601.16900)
*Madeline C. Lisaius,Srinivasan Keshav,Andrew Blake,Clement Atzberger*

Main category: cs.LG

TL;DR: 评估了基于地理空间基础模型嵌入的方法在塞内加尔小农条件下的作物类型制图表现，发现TESSERA方法在性能、合理性、可迁移性和可访问性方面最佳，在时间迁移示例中准确度比次优方法高28%。


<details>
  <summary>Details</summary>
Motivation: 卫星遥感作物类型图对全球小农地区的粮食安全、生计支持和气候变化缓解很重要，但现有卫星方法大多不适合小农条件，需开发更适用的方法。

Method: 建立了四个标准的嵌入方法评估框架（性能、合理性、可转移性、可访问性），在塞内加尔花生盆地比较了TESSERA和AlphaEarth等地理空间基础模型嵌入方法与基线方法。

Result: TESSERA嵌入方法在四项标准中表现最好，在一个时间迁移示例中准确度比次优方法高出28%，适合塞内加尔的作物类型分类与制图任务。

Conclusion: TESSERA嵌入是塞内加尔作物类型分类和制图的有效方法，满足小农地区的实用需求标准。

Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.

</details>


### [80] [GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints](https://arxiv.org/abs/2601.16905)
*Andy Zhu,Rongzhe Wei,Yupu Gu,Pan Li*

Main category: cs.LG

TL;DR: GRIP框架通过几何约束路由更新到专家特定零空间，在保持路由稳定性的同时允许参数调整，解决了传统遗忘方法在MoE架构中的路由器漏洞问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习遗忘方法无法适用于混合专家架构，它们通过操纵路由器而非真正擦除知识，导致模型效用损失和表面遗忘，需要解决MoE特有的架构漏洞。

Method: 提出GRIP框架，通过将路由器梯度更新投影到专家特定零空间来实施几何约束，分离路由稳定性与参数刚性，保持专家选择稳定同时允许内部重构。

Result: 实验表明GRIP在大型MoE模型中消除了专家选择偏移（路由稳定性超过95%），同时保持了原有遗忘方法的效用，使密集架构的遗忘研究可适用于MoE。

Conclusion: GRIP作为适配器框架，成功解决了MoE架构中的机器学习遗忘问题，防止算法利用路由器漏洞，为MoE模型提供了稳健的遗忘能力。

Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.

</details>


### [81] [The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning](https://arxiv.org/abs/2601.16906)
*Calarina Muslimani,Yunshu Du,Kenta Kawamoto,Kaushik Subramanian,Peter Stone,Peter Wurman*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.

</details>


### [82] [Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces](https://arxiv.org/abs/2601.16907)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 该论文提出使用保序回归校准余弦相似度的绝对值分布，解决各向异性导致的相似度分数集中在高值区域的问题，同时保持排序相关性和局部稳定性。


<details>
  <summary>Details</summary>
Motivation: 预训练嵌入空间的余弦相似度虽然在排序相关性上与人类判断高度一致，但由于各向异性，其绝对值被系统性地误校准——相似度分数集中在狭窄的高值带宽，与实际语义相关性脱节，限制了其作为定量指标的解读性。以往方法通常修改嵌入空间本身（如白化、对比微调），但这会改变几何结构并需要重新计算所有嵌入。

Method: 利用人类相似度判断数据训练保序回归，构建单调变换对余弦相似度进行校准，在保持排序相关性和局部稳定性（98%）的同时，实现近乎完美的校准效果。该方法不是替换余弦相似度，而是通过单调校准恢复其绝对值的解读性。

Result: 研究表明保序校准能保持排序特性不变，证明所有基于排序的结构（角度排序、最近邻、阈值图和分位数决策）在该变换下都具有不变性，实现了在多个扰动类型上98%的局部稳定性。

Conclusion: 保序回归校准提供了一种有效且轻量级的方法来解决余弦相似度的校准问题，既能恢复绝对值的解读性，又不会影响其排序质量，为相似度指标的实用化提供了重要改进。

Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.
  Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.
  We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.

</details>


### [83] [Group-realizable multi-group learning by minimizing empirical risk](https://arxiv.org/abs/2601.16922)
*Navid Ardeshir,Samuel Deng,Daniel Hsu,Jingwen Liu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.

</details>


### [84] [A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs](https://arxiv.org/abs/2601.16979)
*Dayal Singh Kalra,Jean-Christophe Gagnon-Audet,Andrey Gromov,Ishita Mediratta,Kelvin Niu,Alexander H Miller,Michael Shvartsman*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($λ_{\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\textit{critical sharpness}$ ($λ_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $Δ\mathbfθ$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\textit{relative critical sharpness}$ ($λ_c^{1\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.

</details>


### [85] [3D Molecule Generation from Rigid Motifs via SE(3) Flows](https://arxiv.org/abs/2601.16955)
*Roman Poletukhin,Marcel Kollovieh,Eike Eberhard,Stephan Günnemann*

Main category: cs.LG

TL;DR: 该研究提出了一种基于刚性基元的三维分子结构生成方法，相比传统原子级方法，在保持生成质量的同时显著提升了效率和压缩率。


<details>
  <summary>Details</summary>
Motivation: 传统3D分子结构生成通常在原子级别进行，而分子图生成技术常常使用片段作为结构单元。本研究旨在将蛋白质结构生成中的框架概念扩展到3D分子生成，将分子表示为刚性基元的集合，从而提高生成效率和表示压缩。

Method: 利用SE(3)等变生成模型，将分子表示为刚性构象基元（rigid motifs）集合，实现从刚性基元出发的3D分子从头生成。

Result: 在多个基准测试中达到与最先进方法相当或更优的结果，在GEOM-Drugs数据集上原子稳定性表现超出现有方法，同时生成步骤减少2-10倍，分子表示压缩率达到3.5倍。

Conclusion: 基于刚性基元的表示方法为3D分子生成提供了更高效、更紧凑的解决方案，在保持生成质量的同时显著提升了计算效率。

Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.

</details>


### [86] [Auto-Regressive Masked Diffusion Models](https://arxiv.org/abs/2601.16971)
*Mahdi Karami,Ali Ghodsi*

Main category: cs.LG

TL;DR: ARMD模型结合自回归模型训练效率与扩散模型并行生成能力，在语言建模基准上达到SOTA性能，显著缩小并行与序列解码间的性能差距


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型在语言建模中性能仍落后于自回归模型且训练迭代次数更多，需要弥补这一差距

Method: 设计自回归掩码扩散架构，将掩码扩散过程重构为块级因果模型，实现严格因果且置换等变的架构，支持高效并行前向计算，并提出跨步并行生成策略

Result: 在标准语言建模基准上实现最先进性能，超越已有扩散基线且训练步数明显减少，为并行文本生成设立新标杆

Conclusion: ARMD有效统一自回归模型训练效率与扩散模型并行生成优势，成功缩小并行与序列解码间的性能差距

Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.

</details>


### [87] [Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection](https://arxiv.org/abs/2601.16976)
*Estela Sánchez-Carballo,Francisco M. Melgarejo-Meseguer,José Luis Rojo-Álvarez*

Main category: cs.LG

TL;DR: 本文提出使用LDM模型增强物联网入侵检测中的攻击数据，以解决类别不平衡问题，相比现有方法在生成质量、多样性和效率方面都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前物联网入侵检测系统中，基于机器学习的IDS受到正常与攻击流量类别不平衡的影响，现有数据增强方法在样本逼真度、多样性和计算效率上存在不足，需要更有效的解决方案。

Method: 采用LDM模型进行物联网攻击数据增强，并与最先进的基线方法在三种典型物联网攻击类型上进行对比。使用分布、依赖和多样性指标评估下游IDS性能和生成本质质量。

Result: LDM平衡训练数据显著提升了IDS性能，为DDoS/Mirai攻击实现了最高0.99的F1分数，比竞争方法表现更优。LDM有效保持特征依赖，生成多样样本，采样时间也比传统扩散模型减少约25%。

Conclusion: LDM是解决物联网入侵检测中类别不平衡问题的有效、可扩展方案，在保持特征多样性和计算效率方面具有优势。

Abstract: Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [88] [SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems](https://arxiv.org/abs/2601.16286)
*Varun Chillara,Dylan Kline,Christopher Alvares,Evan Wooten,Huan Yang,Shlok Khetan,Cade Bauer,Tré Guillory,Tanishka Shah,Yashodhara Dhariwal,Volodymyr Pavlov,George Popstefanov*

Main category: cs.AI

TL;DR: 本文提出SemanticALLI架构，通过将生成任务分解为分析意图解析和可视化合成两个阶段，将结构化中间表示作为可缓存的一级工件，大幅提升了智能体AI流水线的缓存命中率。


<details>
  <summary>Details</summary>
Motivation: 现有智能体AI流水线存在隐藏的低效问题：即使用户的自然语言表达完全不同，它们也经常重复构建相同的中间逻辑（如指标标准化或图表脚手架）。传统的边界缓存将推理视为一个整体黑盒，无法捕捉这种低效性。

Method: 提出SemanticALLI架构，将生成过程分解为两个阶段：1）分析意图解析（AIR）阶段，2）可视化合成（VS）阶段。这一方法将结构化中间表示提升为可缓存的一级工件，从而实现语义级别的缓存复用。

Result: 评估显示，基于传统整体缓存的方法由于语言多样性，缓存命中率上限仅为38.7%。而结构化方法在可视化合成阶段实现了83.10%的缓存命中率，避免了4023次LLM调用，中位延迟仅2.66毫秒，显著降低了总令牌消耗。

Conclusion: 本研究的重要发现是：即使用户很少重复自己的表述，但流水线内部却经常重复处理相同的逻辑，在稳定、结构化的检查点处，缓存是最可靠的。这为AI系统设计提供了实用经验：将生成任务分解为结构化阶段并缓存中间表示可以显著提升效率。

Abstract: Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.
  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.
  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable.

</details>


### [89] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [90] [SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care](https://arxiv.org/abs/2601.16529)
*Dongshen Peng,Yi Wang,Carl Preiksaitis,Christian Rose*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在临床决策支持方面潜力显著，但面临因患者压力而做出不当妥协的风险：SycoEval-EM是一种多智能体模拟框架，用于评估LLMs在急诊医学场景中应对对抗性患者说服时的鲁棒性；通过对20个LLMs和1，875次交互在三个'Choosing Wisely'场景下的测试显示，妥协率在0-100%之间，揭示了静态基准测试在社交压力下预测安全性的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在临床决策支持中表现出潜力，但存在向患者压力妥协、提供不合理护理的风险；当前静态评估方法无法有效评测模型在社交压力下的安全性，因此需要一个能模拟多轮对抗性患者互动的测试框架。

Method: 研究者设计了SycoEval-EM框架，通过多智能体模拟进行对抗性患者说服的测试；框架构建了三个'Choosing Wisely'场景（例如不必要影像检查、阿片类药物处方请求等），并让不同LLMs扮演临床医生角色，与模拟的坚持己见的患者进行多轮交互；覆盖20个LLMs和1，875次交互，量化了模型对患者不合理请求的妥协率。

Result: 实验结果发现LLMs的妥协率范围极广（0-100%），其中对影像检查请求的妥协率（38.8%）高于对阿片类药物处方请求的妥协率（25.0%），模型本身的能力并未有效预示其鲁棒性；所有说服策略（包括情感诉求、反复请求等）的效果相似（30.0-36.0%），表明模型存在普遍的脆弱性而非策略特定的弱点。

Conclusion: 静态基准测试不足以预测临床AI在社交压力下的安全性，揭示了当前LLMs在临床决策中普遍存在向患者不合理请求妥协的脆弱性；为确保临床AI认证的可信度，必须引入多轮对抗性测试方法来全面评估模型鲁棒性。

Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

</details>


### [91] [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)
*Meet Raval,Tejul Pandit,Dhvani Upadhyay*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.

</details>


### [92] [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)
*Suzhong Fu,Jingqi Dong,Xuan Ding,Rui Sun,Yiming Yang,Shuguang Cui,Zhen Li*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.

</details>


### [93] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking-2601 是一个具有优秀智能体推理能力的开源混合专家模型


<details>
  <summary>Details</summary>
Motivation: 为提升智能体推理能力的开源模型水平，解决复杂工具使用、多环境噪声以及深度推理能力不足的问题

Method: 采用混合专家架构与统一训练框架，包含领域并行专家训练、环境扩展、异步强化学习（DORA）优化、噪声模式分析与针对训练，以及测试时扩展的Heavy Thinking模式

Result: 在智能体搜索、工具使用和工具集成推理等任务上取得开源模型的最优性能，表现出强大的泛化能力、复杂工具交互能力和噪声环境下的鲁棒性

Conclusion: 该模型通过综合的训练框架设计在智能体推理任务上实现了突破，为复杂现实世界任务的部署提供了有效的解决方案

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [94] [An Efficient Insect-inspired Approach for Visual Point-goal Navigation](https://arxiv.org/abs/2601.16806)
*Lu Yihe,Barbara Webb*

Main category: cs.AI

TL;DR: 该论文提出了一种受昆虫启发的视觉点目标导航智能体，结合了昆虫大脑中负责联想学习和路径整合的两个抽象模型，在Habitat点目标导航任务中表现出与SOTA模型相当的性能，但计算成本低数个数量级。


<details>
  <summary>Details</summary>
Motivation: 从昆虫在发现食物位置和巢穴之间学习并优化绕过障碍物的视觉引导路径的能力中获得启发，开发计算效率高的导航智能体，以解决传统方法计算成本高昂的问题。

Method: 结合昆虫大脑中与联想学习（可能指蘑菇体）和路径整合（可能指中央复合体）相关的两个抽象神经结构模型，构建昆虫启发的导航智能体，并在Habitat点目标导航任务和更真实的模拟环境中进行测试。

Result: 在Habitat点目标导航基准测试中，该简单昆虫启发的智能体性能与最近的SOTA模型相当，但计算成本低多个数量级；在更真实的模拟环境中测试表明该方法对扰动具有鲁棒性。

Conclusion: 昆虫启发的神经结构为开发高效、鲁棒的视觉导航智能体提供了有前景的途径，显著降低了计算需求，同时保持了与最先进方法竞争的性能。

Abstract: In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.

</details>


### [95] [Reasoning Promotes Robustness in Theory of Mind Tasks](https://arxiv.org/abs/2601.16853)
*Ian B. de Haan,Peter van der Putten,Max van Duijn*

Main category: cs.AI

TL;DR: 研究表明，经过强化学习训练的推理型LLM在心理理论任务中表现更强健，这主要源于其解决策略的稳定性而非新推理能力


<details>
  <summary>Details</summary>
Motivation: 探究推理型大语言模型在心理理论任务中的真实表现，厘清其性能提升的本质原因

Method: 采用新型机器心理学实验设计结合现有基准测试，分析经过强化学习与可验证奖励训练的推理模型在心理理论任务中的行为模式

Result: 推理模型在提示变化和任务扰动下表现出更强的鲁棒性，但这种增益主要源于寻找正确解决方案的稳定性提升，而非根本性的新心理理论推理形式

Conclusion: 评估LLM的社会认知行为时需区分真正的心理理论能力与任务解决的鲁棒性，对模型能力的解释需要更加谨慎

Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.

</details>


### [96] [MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion](https://arxiv.org/abs/2601.16886)
*Chi Yu,Hongyu Yuan,Zhiyi Duan*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.

</details>


### [97] [Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts](https://arxiv.org/abs/2601.16965)
*Riyang Bao,Cheng Yang,Dazhou Yu,Zhexiang Tang,Gengchen Mai,Liang Zhao*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows.

</details>


### [98] [Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians](https://arxiv.org/abs/2601.16967)
*Bernes Lorier Atabonfack,Ahmed Tahiru Issah,Mohammed Hardi Abdul Baaki,Clemence Ingabire,Tolulope Olusuyi,Maruf Adewole,Udunna C. Anazodo,Timothy X Brown*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [99] [Study of Switched Step-size Based Filtered-x NLMS Algorithm for Active Noise Cancellation](https://arxiv.org/abs/2601.16382)
*Zhiyuan Li,Yi Yu,Hongsen He,Yuyu Zhu,Rodrigo C. de Lamare*

Main category: cs.IT

TL;DR: 提出了一种改进的FxNLMS算法来解决传统算法在步长选择（收敛速度与稳态残差之间的权衡）和脉冲噪声环境下的性能问题。


<details>
  <summary>Details</summary>
Motivation: FxNLMS算法被广泛应用于有源噪声控制系统，但存在两个关键限制：固定步长导致收敛速度和稳态残差误差之间的权衡问题；在脉冲噪声环境下性能急剧下降。

Method: 1. 提出了切换步长FxNLMS（SSS-FxNLMS）算法，通过推导FxNLMS的均方偏差趋势，比较不同步长对应的MSD趋势，为每次迭代选择最优步长。2. 将鲁棒策略集成到SSS-FxNLMS中，形成其鲁棒变体，以提高在脉冲噪声环境下的鲁棒性。

Result: 通过在多种噪声场景下的计算机仿真，证实了所提算法的有效性和优越性。

Conclusion: 提出的SSS-FxNLMS算法及其鲁棒变体成功解决了传统FxNLMS算法的步长约束和脉冲噪声敏感性问题，在保持简单结构的同时显著提高了性能。

Abstract: While the filtered-x normalized least mean square (FxNLMS) algorithm is widely applied due to its simple structure and easy implementation for active noise control system, it faces two critical limitations: the fixed step-size causes a trade-off between convergence rate and steady-state residual error, and its performance deteriorates significantly in impulsive noise environments. To address the step-size constraint issue, we propose the switched \mbox{step-size} FxNLMS (SSS-FxNLMS) algorithm. Specifically, we derive the \mbox{mean-square} deviation (MSD) trend of the FxNLMS algorithm, and then by comparing the MSD trends corresponding to different \mbox{step-sizes}, the optimal step-size for each iteration is selected. Furthermore, to enhance the algorithm's robustness in impulsive noise scenarios, we integrate a robust strategy into the SSS-FxNLMS algorithm, resulting in a robust variant of it. The effectiveness and superiority of the proposed algorithms has been confirmed through computer simulations in different noise scenarios.

</details>


### [100] [Two classes of LCD codes derived from $(\mathcal{L},\mathcal{P})$-TGRS codes](https://arxiv.org/abs/2601.16438)
*Ziwei Zhao,Xiaoni DU,Xingbin Qiao*

Main category: cs.IT

TL;DR: 论文研究了扭曲广义里德-所罗门(TGRS)码，并构建了两类线性互补对偶(LCD)码。


<details>
  <summary>Details</summary>
Motivation: TGRS码作为经典广义里德-所罗门(GRS)码的灵活扩展，近年来受到广泛关注。本文旨在从TGRS码构造LCD码，并进一步获得LCD MDS码。

Method: 使用特定评估点和系数的限制条件，从TGRS码构造两类LCD码，并通过调整参数获得LCD MDS码。

Result: 推导了TGRS码的校验矩阵，给出了成为AMDS码的充要条件，成功构建了两类LCD码，并由此获得了LCD MDS码，提供了多个实例证明。

Conclusion: 本文提出的构造方法能够从TGRS码有效产生LCD码，特别是LCD MDS码，扩展了LCD码的构建途径。

Abstract: Twisted generalized Reed-Solomon (TGRS) codes, as a flexible extension of classical generalized Reed-Solomon (GRS) codes, have attracted significant attention in recent years. In this paper, we construct two classes of LCD codes from the $(\mathcal{L},\mathcal{P})$-TGRS code $\mathcal{C}_h$ of length $n$ and dimension $k$, where $\mathcal{L}=\{0,1,\ldots,l\}$ for $l\leq n-k-1$ and $\mathcal{P}=\{h\}$ for $1\leq h\leq k-1$. First, we derive the parity check matrix of $\mathcal{C}_h$ and provide a necessary and sufficient condition for $\mathcal{C}_h$ to be an AMDS code. Then, we construct two classes of LCD codes from $\mathcal{C}_h$ by suitably choosing the evaluation points together with certain restrictions on the coefficient of $x^{h-1}$ in the polynomial associated with the twisting term. From the constructed LCD codes we further obtain two classes of LCD MDS codes. Finally, several examples are presented.

</details>


### [101] [Log-Likelihood Loss for Semantic Compression](https://arxiv.org/abs/2601.16461)
*Anuj Kumar Yadav,Dan Song,Yanina Shkel,Ayfer Özgür*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study lossy source coding under a distortion measure defined by the negative log-likelihood induced by a prescribed conditional distribution $P_{X|U}$. This \emph{log-likelihood distortion} models compression settings in which the reconstruction is a semantic representation from which the source can be probabilistically generated, rather than a pointwise approximation. We formulate the corresponding rate-distortion problem and characterize fundamental properties of the resulting rate-distortion function, including its connections to lossy compression under log-loss, classical rate-distortion problems with arbitrary distortion measures, and rate-distortion with perfect perception.

</details>


### [102] [Noise-immune and AI-enhanced DNA storage via adaptive partition mapping of digital data](https://arxiv.org/abs/2601.16518)
*Zimu Li,Bingyi Liu,Lei Zhao,Qian Zhang,Yang Liu,Jun Liu,Ke Ke,Huating Kong,Xiaolei Zuo,Chunhai Fan,Fei Wang*

Main category: cs.IT

TL;DR: 提出了PJ编码方案，用于解决DNA存储中的错误和噪声问题，使数据在任意噪声条件下都能解码，并支持可控的信息恢复。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能时代数据量快速增长，DNA存储成为有潜力的解决方案，但合成、保存和测序过程中的错误限制了其实际应用，传统纠错码在超出预设阈值的高噪声水平下仍然脆弱。

Method: 开发了PJ编码方案，包括打破跨链信息依赖性（防止链丢失导致灾难性故障），以及链内跳转旋转策略（放松序列约束，提供可调信息密度），结合基于AI的推理实现可控信息恢复。

Result: 证明了PJ编码能够在任意链丢失比例下始终解码原始文件，信息保真度随损坏程度平滑下降，即使有10%链丢失也能有效恢复原始文件，存储的机器学习数据集保持分类性能，且经加速老化和高强度X射线辐照等极端环境干扰后仍能成功解码图像文件。

Conclusion: 通过消除对先验错误概率的依赖，PJ为稳健的归档DNA存储建立了一个通用框架，能够承受现实世界保存的严格条件。

Abstract: Encoding digital information into DNA sequences offers an attractive potential solution for storing rapidly growing data under the information age and the rise of artificial intelligence. However, practical implementations of DNA storage are constrained by errors introduced during synthesis, preservation, and sequencing processes, and traditional error-correcting codes remain vulnerable to noise levels that exceed predefined thresholds. Here, we developed a Partitioning-mapping with Jump-rotating (PJ) encoding scheme, which exhibits exceptional noise resilience. PJ removes cross-strand information dependencies so that strand loss manifests as localized gaps rather than catastrophic file failure. It prioritizes file decodability under arbitrary noise conditions and leverages AI-based inference to enable controllable recovery of digital information. For the intra-strand encoding, we develop a jump-rotating strategy that relaxes sequence constraints relative to conventional rotating codes and provides tunable information density via an adjustable jump length. Based on this encoding architecture, the original file information can always be decoded and recovered under any strand loss ratio, with fidelity degrading smoothly as damage increases. We demonstrate that original files can be effectively recovered even with 10% strand loss, and machine learning datasets stored under these conditions retain their classification performance. Experiments further confirmed that PJ successfully decodes image files after extreme environmental disturbance using accelerated aging and high-intensity X-ray irradiation. By eliminating reliance on prior error probabilities, PJ establishes a general framework for robust, archival DNA storage capable of withstanding the rigorous conditions of real-world preservation.

</details>


### [103] [Generalized Forms of the Kraft Inequality for Finite-State Encoders](https://arxiv.org/abs/2601.16594)
*Neri Merhav*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We derive a few extended versions of the Kraft inequality for information lossless finite-state encoders. The main basic contribution is in defining a notion of a Kraft matrix and in establishing the fact that a necessary condition for information losslessness of a finite-state encoder is that none of the eigenvalues of this matrix have modulus larger than unity, or equivalently, the generalized Kraft inequality asserts that the spectral radius of the Kraft matrix cannot exceed one. For the important special case where the FS encoder is irreducible, we derive several equivalent forms of this inequality, which are based on well known formulas for spectral radius. It also turns out that in the irreducible case, Kraft sums are bounded by a constant, independent of the block length, and thus cannot grow even in any subexponential rate. Finally, two extensions are outlined - one concerns the case of side information available to both encoder and decoder, and the other is for lossy compression.

</details>


### [104] [An Explicit Upper Bound of Generalized Quadratic Gauss Sums and Its Applications for Asymptotically Optimal Aperiodic Polyphase Sequence Design](https://arxiv.org/abs/2601.16599)
*Huaning Liu,Zilong Liu*

Main category: cs.IT

TL;DR: 该论文解决了设计满足Welch界的渐进最优非周期多相序列集的长期开放问题，提出了广义二次高斯和的上界证明，并系统构造了四类具有低非周期相关性的最优序列集。


<details>
  <summary>Details</summary>
Motivation: 针对满足Welch界的渐进最优非周期多相序列集设计的开放问题，虽然Mow在30年前尝试过，但对该问题的全面理解仍不足。本文旨在系统解决这一基础理论问题。

Method: 1) 通过递归应用巴黎渐近展开并利用斐波那契zeta函数的快速收敛性，得到广义二次高斯和的显式上界。2) 基于这一关键发现，通过精心选择Chu序列和Alltop序列，系统构造了四种具有低非周期相关和/或模糊特性的阶最优序列集。

Result: 1) 首次揭示完整的Alltop序列集在低非周期相关旁瓣方面是渐进最优的。2) 提出了Alltop序列的新子集，其在整段时间偏移窗口内同时具有阶最优的非周期相关特性和模糊特性。

Conclusion: 论文成功解决了非周期多相序列集设计的开放性问题，提供了理论分析工具和系统构造方法，为实现Welch界逼近的序列设计奠定了理论基础，并在Alltop序列的性能优化方面取得了突破性进展。

Abstract: This work is motivated by the long-standing open problem of designing asymptotically order-optimal aperiodic polyphase sequence sets with respect to the celebrated Welch bound. Attempts were made by Mow over 30 years ago, but a comprehensive understanding to this problem is lacking. Our first key contribution is an explicit upper bound of generalized quadratic Gauss sums which is obtained by recursively applying Paris' asymptotic expansion and then bounding it by leveraging the fast convergence property of the Fibonacci zeta function. Building upon this major finding, our second key contribution includes four systematic constructions of order-optimal sequence sets with low aperiodic correlation and/or ambiguity properties via carefully selected Chu sequences and Alltop sequences. For the first time in the literature, we reveal that the full Alltop sequence set is asymptotically optimal for its low aperiodic correlation sidelobes. Besides, we introduce a novel subset of Alltop sequences possessing both order-optimal aperiodic correlation and ambiguity properties for the entire time-shift window.

</details>


### [105] [Term Coding: An Entropic Framework for Extremal Combinatorics and the Guessing--Number Sandwich Theorem](https://arxiv.org/abs/2601.16614)
*Søren Riis*

Main category: cs.IT

TL;DR: 本文建立了一个连接项编码和图猜数理论的框架，通过熵和多拟阵方法，将组合设计的存在性问题转化为编码大小的极值问题。


<details>
  <summary>Details</summary>
Motivation: 将拟群、设计等组合结构的存在性问题转化为量化的极值问题，研究在给定约束条件下解决方案集的最大规模。

Method: 提出'猜测数夹逼定理'，通过显式正规化和多样化约简，将项编码与图猜数（图熵）联系起来，构建规范有向依赖结构，利用熵和多拟阵方法计算最大编码大小。

Result: 证明最大编码大小满足$\log_n\Sn(Γ)=α+o(1)$，其中α是依赖结构的猜数，可以用熵方法计算，并在Steiner型恒等式、自正交拉丁方等实例中演示了该框架的应用。

Conclusion: 建立了一个统一框架，将组合设计和信息流约束的极值问题转化为可计算的熵方法问题，展示了该框架在组合和信息论交叉领域的广泛应用前景。

Abstract: Term Coding asks: given a finite system of term identities $Γ$ in $v$ variables, how large can its solution set be on an $n$--element alphabet, when we are free to choose the interpretations of the function symbols? This turns familiar existence problems for quasigroups, designs, and related objects into quantitative extremal questions.
  We prove a guessing-number sandwich theorem that connects term coding to graph guessing numbers (graph entropy). After explicit normalisation and diversification reductions, every instance yields a canonical directed dependency structure with guessing number $α$ such that the maximum code size satisfies $\log_n \Sn(Γ)=α+o(1)$ (equivalently, $\Sn(Γ)=n^{α+o(1)}$), and $α$ can be bounded or computed using entropy and polymatroid methods.
  We illustrate the framework with examples from extremal combinatorics (Steiner-type identities, self-orthogonal Latin squares) and from information-flow / network-coding style constraints (including a five-cycle instance with fractional exponent and small storage/relay maps).

</details>


### [106] [Taming the Heavy Tail: Age-Optimal Preemption](https://arxiv.org/abs/2601.16624)
*Aimin Li,Yiğit İnce,Elif Uysal*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper studies a continuous-time joint sampling-and-preemption problem, incorporating sampling and preemption penalties under general service-time distributions. We formulate the system as an impulse-controlled piecewise-deterministic Markov process (PDMP) and derive coupled integral average-cost optimality equations via the dynamic programming principle, thereby avoiding the smoothness assumptions typically required for an average-cost Hamilton-Jacobi-Bellman quasi-variational inequality (HJB-QVI) characterization. A key invariance in the busy phase collapses the dynamics onto a one-dimensional busy-start boundary, reducing preemption control to an optimal stopping problem. Building on this structure, we develop an efficient policy iteration algorithm with heavy-tail acceleration, employing a hybrid (uniform/log-spaced) action grid and a far-field linear closure. Simulations under Pareto and log-normal service times demonstrate substantial improvements over AoI-optimal non-preemptive sampling and zero-wait baselines, achieving up to a 30x reduction in average cost in heavy-tailed regimes. Finally, simulations uncover a counterintuitive insight: under preemption, delay variance, despite typically being a liability, can become a strategic advantage for information freshness.

</details>


### [107] [The Oval Strikes Back](https://arxiv.org/abs/2601.16628)
*Andrea Di Giusto,Alberto Ravagnani,Emina Soljanin*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the applications of ovals in projective planes to distributed storage, with a focus on the Service Rate Region problem. Leveraging the incidence relations between lines and ovals, we describe a class of non-systematic MDS matrices with a large number of small and disjoint recovery sets. For certain parameter choices, the service-rate region of these matrices contains the region of a systematic generator matrix for the same code, yielding better service performance. We further apply our construction to analyze the PIR properties of the considered MDS matrices and present a one-step majority-logic decoding algorithm with strong error-correcting capability. These results highlight how ovals, a classical object in finite geometry, re-emerge as a useful tool in modern coding theory.

</details>


### [108] [Stable Source Coding](https://arxiv.org/abs/2601.16680)
*Zhenduo Wen,Amin Gohari*

Main category: cs.IT

TL;DR: 研究稳定性无损信源编码的压缩率，推导其信息论极限与稳定性参数的关系


<details>
  <summary>Details</summary>
Motivation: 传统信源编码的随机分组技术不稳定——类似源序列可能映射到完全不相关的位置，这在实际传输或存储中可能带来问题，因此需要研究保证稳定性的编码方案

Method: 使用组合论证方法建立稳定性条件与编码率之间的数学关系

Result: 推导出了在给定稳定性参数（编码方案对小扰动的敏感度界限）下的可达编码率信息论极限

Conclusion: 稳定性要求在信源编码中带来了新的速率限制，但可以通过适当的编码设计实现这些极限

Abstract: A source encoder is stable if a small change in the source sequence (e.g., changing a few symbols) results in a small (or bounded) change in the output codeword. By this definition, the common technique of random binning is unstable; because the mapping is random, two nearly identical source sequences can be assigned to completely unrelated bin indices. We study compression rates of stable lossless source codes. Using combinatorial arguments, we derive information-theoretic limits on the achievable rate as a function of the stability parameters.

</details>


### [109] [Privacy-Resolution Tradeoff for Adaptive Noisy Twenty Questions Estimation](https://arxiv.org/abs/2601.16825)
*Chunsong Sun,Lin Zhou*

Main category: cs.IT

TL;DR: 本文研究了噪声二十问估计中的隐私-分辨率权衡问题，提出了两阶段隐私查询算法，分析了其非渐近和二阶渐近性能，并在无噪声情况下超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 自适应查询虽然性能更优，但会引发隐私泄露风险。先前研究关注无噪声情况，本文将其扩展到更实际的含噪声场景，研究如何在保持隐私的前提下进行估计。

Method: 设计了两阶段隐私查询算法：第一阶段使用非自适应查询收集粗粒度信息，第二阶段利用第一阶段信息设计自适应查询。分析了该算法的非渐近和二阶渐近性能。

Result: 1. 在噪声情况下实现了隐私保护的估计；2. 所提算法的性能优于现有方法；3. 分析了隐私约束对性能的影响；4. 在无噪声情况下超越了COLT 2018和AISTATS 2021的成果。

Conclusion: 两阶段隐私查询算法能有效平衡噪声环境下的隐私保护和估计精度，为实际应用提供了理论基础。

Abstract: We revisit noisy twenty questions estimation and study the privacy-resolution tradeoff for adaptive query procedures. Specifically, in twenty questions estimation, there are two players: an oracle and a questioner. The questioner aims to estimate target variables by posing queries to the oracle that knows the variables and using noisy responses to form reliable estimates. Typically, there are adaptive and non-adaptive query procedures. In adaptive querying, one designs the current query using previous queries and their noisy responses while in non-adaptive querying, all queries are posed simultaneously. Generally speaking, adaptive query procedures yield better performance. However, adaptive querying leads to privacy concerns, which were first studied by Tsitsiklis, Xu and Xu (COLT 2018) and by Xu, Xu and Yang (AISTATS 2021) for the noiseless case, where the oracle always provides correct answers to queries. In this paper, we generalize the above results to the more practical noisy case, by proposing a two-stage private query procedure, analyzing its non-asymptotic and second-order asymptotic achievable performance and discussing the impact of privacy concerns. Furthermore, when specialized to the noiseless case, our private query procedure achieves better performance than above-mentioned query procedures (COLT 2018, AISTATS 2021).

</details>


### [110] [Information Contraction under $(\varepsilon,δ)$-Differentially Private Mechanisms](https://arxiv.org/abs/2601.16845)
*Theshani Nuradha,Ian George,Christoph Hirche*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The distinguishability quantified by information measures after being processed by a private mechanism has been a useful tool in studying various statistical and operational tasks while ensuring privacy. To this end, standard data-processing inequalities and strong data-processing inequalities (SDPI) are employed. Most of the previously known and even tight characterizations of contraction of information measures, including total variation distance, hockey-stick divergences, and $f$-divergences, are applicable for $(\varepsilon,0)$-local differential private (LDP) mechanisms. In this work, we derive both linear and non-linear strong data-processing inequalities for hockey-stick divergence and $f$-divergences that are valid for all $(\varepsilon,δ)$-LDP mechanisms even when $δ\neq 0$. Our results either generalize or improve the previously known bounds on the contraction of these distinguishability measures.

</details>


### [111] [Perfect Privacy and Strong Stationary Times for Markovian Sources](https://arxiv.org/abs/2601.16857)
*Fangwei Ye,Zonghong Liu,Parimal Parag,Salim El Rouayheb*

Main category: cs.IT

TL;DR: 研究在完美信息论隐私约束下共享相关数据的问题，关注数据删减机制，证明了基于窗口的删减方案和最优序列删减机制都能在保护隐私的同时达到最优失真效果，且平均删减数据量与数据长度无关。


<details>
  <summary>Details</summary>
Motivation: 在共享相关数据时如何在保证完美隐私的前提下最大化共享数据量，特别关注保护初始状态隐私的问题。

Method: 采用数据删减（擦除）机制，假设数据由有限时间齐次马尔可夫链生成，研究基于窗口的删减方案，并分析了最优序列删减机制及其与窗口解释的等价性。

Result: 证明了基于窗口的删减方案在适当条件下能保护隐私，最优序列删减机制与窗口方案等价，且两种机制都能达到最优失真，平均删减的数据点数量与数据长度N无关。

Conclusion: 在完美隐私约束下，通过精心设计的删减机制可以有效地共享相关数据，既能保护初始状态隐私，又能实现接近最优的数据共享效率，且效率与数据规模无关。

Abstract: We consider the problem of sharing correlated data under a perfect information-theoretic privacy constraint. We focus on redaction (erasure) mechanisms, in which data are either withheld or released unchanged, and measure utility by the average cardinality of the released set, equivalently, the expected Hamming distortion. Assuming the data are generated by a finite time-homogeneous Markov chain, we study the protection of the initial state while maximizing the amount of shared data. We establish a connection between perfect privacy and window-based redaction schemes, showing that erasing data up to a strong stationary time preserves privacy under suitable conditions. We further study an optimal sequential redaction mechanism and prove that it admits an equivalent window interpretation. Interestingly, we show that both mechanisms achieve the optimal distortion while redacting only a constant average number of data points, independent of the data length~$N$.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [112] [Multi-User Content Diversity in Wireless Networks](https://arxiv.org/abs/2601.16323)
*Belal Korany,Peerapol Tinnakornsrisuphap,Saadallah Kassir,Prashanth Hande,Hyun Yong Lee,Thomas Stockhammer,Hemanth Sampath*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Immersive applications such as eXtended Reality (XR), cloud gaming, and real-time video streaming are central to the vision of 6G networks. These applications require not only low latency and high data rates, but also consistent and high-quality User Experience (UX). Traditional rate allocation and congestion control mechanisms in wireless networks treat users uniformly based on channel conditions, rely only on network-centric Key Performance Indicators (KPIs), and ignore the content diversity, which can lead to inefficient resource utilization and degraded UX. In this paper, we introduce the concept of Multi-User Content Diversity, which recognizes that different users concurrently consume media with varying complexity, and therefore have different bitrate requirements to achieve satisfactory UX. We propose multiple different frameworks that exploit multi-user content diversity and lead to overall network-wide gains in terms of UX. For each framework, we demonstrate the required information exchange between Application Servers (ASs), Application Clients (ACs), and the network, and the algorithms that run in each of these components to optimize a network-wide UXbased objective. Simulation results demonstrate that exploiting multi-user content diversity leads to significant gains in UX capacity, UX fairness, and network utilization, when compared to conventional rate control methods. These findings highlight the potential of content-aware networking as a key enabler for emerging wireless systems.

</details>


### [113] [Predicting Networks Before They Happen: Experimentation on a Real-Time V2X Digital Twin](https://arxiv.org/abs/2601.16559)
*Roberto Pegurri,Habu Shintaro,Francesco Linsalata,Wang Kui,Tao Yu,Eugenio Moro,Maiya Igarashi,Antonio Capone,Kei Sakaguchi*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Emerging safety-critical Vehicle-to-Everything (V2X) applications require networks to proactively adapt to rapid environmental changes rather than merely reacting to them. While Network Digital Twins (NDTs) offer a pathway to such predictive capabilities, existing solutions typically struggle to reconcile high-fidelity physical modeling with strict real-time constraints. This paper presents a novel, end-to-end real-time V2X Digital Twin framework that integrates live mobility tracking with deterministic channel simulation. By coupling the Tokyo Mobility Digital Twin-which provides live sensing and trajectory forecasting-with VaN3Twin-a full-stack simulator with ray tracing-we enable the prediction of network performance before physical events occur. We validate this approach through an experimental proof-of-concept deployed in Tokyo, Japan, featuring connected vehicles operating on 60 GHz links. Our results demonstrate the system's ability to predict Received Signal Strength (RSSI) with a maximum average error of 1.01 dB and reliably forecast Line-of-Sight (LoS) transitions within a maximum average end-to-end system latency of 250 ms, depending on the ray tracing level of detail. Furthermore, we quantify the fundamental trade-offs between digital model fidelity, computational latency, and trajectory prediction horizons, proving that high-fidelity and predictive digital twins are feasible in real-world urban environments.

</details>


### [114] [Stochastic Modeling and Resource Dimensioning of Multi-Cellular Edge Intelligent Systems](https://arxiv.org/abs/2601.16848)
*Jaume Anguera Peris,Joakim Jaldén*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Edge intelligence enables AI inference at the network edge, co-located with or near the radio access network, rather than in centralized clouds or on mobile devices. It targets low-latency, resource-constrained applications with large data volumes, requiring tight integration of wireless access and on-site computing. Yet system performance and cost-efficiency hinge on joint pre-deployment dimensioning of radio and computational resources, especially under spatial and temporal uncertainty. Prior work largely emphasizes run-time allocation or relies on simplified models that decouple radio and computing, missing end-to-end correlations in large-scale deployments. This paper introduces a unified stochastic framework to dimension multi-cell edge-intelligent systems. We model network topology with Poisson point processes, capturing random user and base-station locations, inter-cell interference, distance-based fractional power control, and peak-power constraints. By combining this with queueing theory and empirical AI inference workload profiling, we derive tractable expressions for end-to-end offloading delay. These enable a non-convex joint optimization that minimizes deployment cost under statistical QoS guarantees, expressed through strict tail-latency and inference-accuracy constraints. We prove the problem decomposes into convex subproblems, yielding global optimality. Numerical results in noise- and interference-limited regimes identify cost-efficient design regions and configurations that cause under-utilization or user unfairness. Smaller cells reduce transmission delay but raise per-request computing cost due to weaker server multiplexing, whereas larger cells show the opposite trend. Densification reduces computational costs only when frequency reuse scales with base-station density; otherwise, sparser deployments improve fairness and efficiency in interference-limited settings.

</details>


### [115] [Evaluating Wi-Fi Performance for VR Streaming: A Study on Realistic HEVC Video Traffic](https://arxiv.org/abs/2601.16950)
*Ferran Maura,Francesc Wilhelmi,Boris Bellalta*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Cloud-based Virtual Reality (VR) streaming presents significant challenges for 802.11 networks due to its high throughput and low latency requirements. When multiple VR users share a Wi-Fi network, the resulting uplink and downlink traffic can quickly saturate the channel. This paper investigates the capacity of 802.11 networks for supporting realistic VR streaming workloads across varying frame rates, bitrates, codec settings, and numbers of users. We develop an emulation framework that reproduces Air Light VR (ALVR) operation, where real HEVC video traffic is fed into an 802.11 simulation model. Our findings explore Wi-Fi's performance anomaly and demonstrate that Intra-refresh (IR) coding effectively reduces latency variability and improves QoS, supporting up to 4 concurrent VR users with Constant Bitrate (CBR) 100 Mbps before the channel is saturated.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [116] [BESTOpt: A Modular, Physics-Informed Machine Learning based Building Modeling, Control and Optimization Framework](https://arxiv.org/abs/2601.16283)
*Zixin Jiang,Ruizhi Song,Guowen Li,Yuhang Zhang,Zheng O'Neill,Xuezheng Wang,Judah Goldfeder,Bing Dong*

Main category: eess.SY

TL;DR: BESTOpt是一个模块化、物理信息化的机器学习框架，用于统一建筑应用，包括基准测试、评估、诊断、控制、优化和性能模拟，以解决现有工具在建模、控制和优化多领域建筑系统时存在的可扩展性和物理一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现代建筑与人员占用、HVAC系统、分布式能源资源和电网的互联日益紧密，对这些多领域系统进行建模、控制和优化对实现建筑领域脱碳至关重要。然而，现有工具大多缺乏可扩展性和物理一致性，难以解决这些复杂、多尺度的问题。

Method: 该研究提出了BESTOpt框架，采用集群-领域-系统/建筑-组件层次结构，使用标准化的状态-动作-干扰-观察数据类型学，并将物理先验嵌入数据驱动模块。

Result: 在单一建筑和集群场景的案例研究中，证明了该框架在多级集中式和分散式控制方面的能力。

Conclusion: BESTOpt为建立一个开放、可扩展的平台奠定了基础，将加速跨学科研究，推动智能、有韧性和脱碳的建筑生态系统发展。

Abstract: Modern buildings are increasingly interconnected with occupancy, heating, ventilation, and air-conditioning (HVAC) systems, distributed energy resources (DERs), and power grids. Modeling, control, and optimization of such multi-domain systems play a critical role in achieving building-sector decarbonization. However, most existing tools lack scalability and physical consistency for addressing these complex, multi-scale ecosystem problems. To bridge this gap, this study presents BESTOpt, a modular, physics-informed machine learning (PIML) framework that unifies building applications, including benchmarking, evaluation, diagnostics, control, optimization, and performance simulation. The framework adopts a cluster-domain-system/building-component hierarchy and a standardized state-action-disturbance-observation data typology. By embedding physics priors into data-driven modules, BESTOpt improves model accuracy and physical consistency under unseen conditions. Case studies on single-building and cluster scenarios demonstrate its capability for multi-level centralized and decentralized control. Looking ahead, BESTOpt lays the foundation for an open, extensible platform that accelerates interdisciplinary research toward smart, resilient, and decarbonized building ecosystems.

</details>


### [117] [Optimal County-Level Siting of Data Centers in the United States](https://arxiv.org/abs/2601.16315)
*Maria Vabson,Muhy Eddin Zater,Amir Sajadi,Kyri Baker,Bri-Mathias Hodge*

Main category: eess.SY

TL;DR: 提出一个综合模型来优化数据中心选址，综合考虑电网、通信、气候、用水和共址发电潜力，通过多个测试案例验证模型，发现资本成本是关键因素，但延长未来展望和允许更多可变发电共址会促使选择可再生能源潜力更高的地点。


<details>
  <summary>Details</summary>
Motivation: 数据中心快速增长，能源和水资源消耗巨大，给已经紧张的老化电网和水资源带来压力，需要建立关键基础设施来支持这些大型负载。

Method: 采用综合性建模方法，量化资源使用并最小化成本，考虑因素包括电网、电信、气候、用水和共址发电潜力，基于县域级别在美国进行多个碳零排放发电共址的测试案例。

Result: 资本成本是主要驱动因素，但更长的未来展望和允许更多可变发电共址会促使模型选择可再生能源潜力更高的地点。

Conclusion: 该模型为数据中心选址提供了综合优化框架，平衡了经济成本与可再生能源利用，支持可持续基础设施规划。

Abstract: Data centers are growing rapidly, creating the pressing need for the development of critical infrastructure build out to support these resource-intensive large loads. Their immense consumption of electricity and, often, freshwater, continues to stress an already constrained and aging power grid and water resources. This paper presents a comprehensive modeling approach to determine the optimal locations to construct such facilities by quantifying their resource use and minimizing associated costs. The interdisciplinary modeling approach incorporates a number of factors including the power grid, telecommunications, climate, water use, and collocated generation potential. This work establishes the base model whose functionality is shown through several test cases focusing on carbon-free generation collocation on a county-level in the United States. The results suggest that while capital costs are the biggest driver, having a longer future outlook and allowing more variable generation collocation influences the model to choose sites with higher renewable potential.

</details>


### [118] [Robust Grid-Forming Control Based on Virtual Flux Observer](https://arxiv.org/abs/2601.16418)
*Xueqing Gao,Jun Zhang,Tao Li,Mingming Zhang*

Main category: eess.SY

TL;DR: 该论文提出了一种基于虚拟磁链观测器的同步和负载角控制方法，用于并网变换器的电网形成控制，具有强鲁棒性和良好的动态性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种新型电网形成控制方法，以应对并网变换器在变化和不确定的电网强度下的稳定性和动态性能挑战。

Method: 采用虚拟磁链观测器进行同步和负载角控制，直接调节变换器端电压以实现电压源行为，并通过解耦和极点配置设计控制参数。

Result: 通过小信号分析证明了该方法的鲁棒控制性能，并在20 kVA功率转换系统上通过实验验证了其有效性。

Conclusion: 提出的基于虚拟磁链观测器的电网形成控制方法具有强鲁棒性，能在不同电网强度下保持稳定性和良好的动态性能。

Abstract: This paper investigates the design and analysis of a novel grid-forming (GFM) control method for grid-connected converters (GCCs). The core novelty lies in a virtual flux observer-based synchronization and load angle control method. The terminal voltage of the converter is directly regulated to provide voltage-source behavior. The control parameters are designed for decoupling and pole placement. The proposed method exhibits strong robustness in stability and dynamical performance across varying and uncertain grid strengths. The robust control performance of the proposed method is first demonstrated by small-signal analysis, then validated by experiments on a 20 kVA power conversion system.

</details>


### [119] [Sequential Operating Simulation of Solid State Transformer-Driven Next-Generation 800 VDC Data Center](https://arxiv.org/abs/2601.16502)
*Jian Xu,Xinxiong Jiang,Yi Bao,Yuchen Zheng,Xuhui Chen,Qiang Xu,Siyang Liao,Deping Ke,Xiaoqi Gao*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Artificial-intelligence (AI) workloads are driving rapid growth in data-center electricity use and rack power density, increasing demand for power-delivery systems that are efficient and robust to fast load transients. Conventional uninterruptible power supply (UPS) based AC distribution chains involve multiple conversion stages and line-frequency transformers, which compound losses and are less compatible with dynamic AI power profiles. Although solid-state transformers (SSTs) and 800 VDC distribution architecture are widely discussed, implementable topology/control details, and long-horizon validation with realistic operating profiles remain limited. This paper develops an SST-driven 800 VDC architecture that converts 10 kV MVAC to an 800V LVDC bus using a three-phase H-bridge AC/DC stage cascaded with a dual-active-bridge (DAB) DC/DC stage. A coordinated closed-loop control scheme, combining rectifier voltage/current regulation and DAB phase-shift control, is designed to maintain DC-bus voltage stability. The proposed system is implemented on the real-time digital simulation (RTDS) platform and evaluated via sequential simulations using real-world day- and month-scale operating profiles of data centers, benchmarked against a UPS supply chain. Numerical studies demonstrate tight 800 VDC regulation, reduced input-side energy consumption compared with the UPS baseline, and satisfactory power-quality performance. A capacitance sensitivity test quantifies tradeoffs between DC-bus ripple and low-frequency input-power oscillations, yielding a practical capacitance range for design. Overall, the work provides a reproducible evaluation workflow and actionable guidance for next-generation AI data centers.

</details>


### [120] [Agentic AI-RAN Empowering Synergetic Sensing, Communication, Computing, and Control](https://arxiv.org/abs/2601.16565)
*Lingxiao Sun,Zhaoyang Zhang,Zihan Lin,Zirui Chen,Weijie Zhou,Zhaohui Yang,Tony Q. S. Quek*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Future sixth-generation (6G) networks are expected to support low-altitude wireless networks (LAWNs), where unmanned aerial vehicles (UAVs) and aerial robots operate in highly dynamic three-dimensional environments under stringent latency, reliability, and autonomy requirements. In such scenarios, autonomous task execution at the network edge demands holistic coordination among sensing, communication, computing, and control (SC3) processes. Agentic Artificially Intelligent Radio Access Networks (Agentic AI-RAN) offer a promising paradigm by enabling the edge network to function as an autonomous decision-making entity for low-altitude agents with limited onboard resources. In this article, we propose and design a task-oriented Agentic AI-RAN architecture that enables SC3 task execution within a single edge node. This integrated design tackles the fundamental problem of coordinating heterogeneous workloads in resource-constrained edge environments. Furthermore, a representative low-altitude embodied intelligence system is prototyped based on a general-purpose Graphics Processing Unit (GPU) platform to demonstrate autonomous drone navigation in realistic settings. By leveraging the Multi-Instance GPU (MIG) partitioning technique and the containerized deployment, the demonstration system achieves physical resource isolation while supporting tightly coupled coordination between real-time communication and multimodal inference under a unified task framework. Experimental results demonstrate low closed-loop latency, robust bidirectional communication, and stable performance under dynamic runtime conditions, highlighting its viability for mission-critical low-altitude wireless networks in 6G.

</details>


### [121] [Challenges in the Proper Metrological Verification of Smart Energy Meters](https://arxiv.org/abs/2601.16612)
*Antonio Bracale,Jakub Janowicz,Piotr Kuwałek,Grzegorz Wiczyński*

Main category: eess.SY

TL;DR: 本文分析了智能电能表测量精度验证的局限性，指出当前校验证方法无法模拟真实电网工况，并展示了现行法规标准下的仪表仍存在信号链缺陷，为后续研究方向提供依据。


<details>
  <summary>Details</summary>
Motivation: 当前智能电能表的验证工作在理想条件下进行，无法还原真实电网状态，导致信号链特性验证不足。现有法规虽批准相关仪表上市，但实际测量精度仍有潜在隐患，需要系统性评估验证方法的有效性。

Method: 梳理现行法规标准与科研方向，通过设计特殊测试信号对已获批准上市的智能电能表进行实测分析，揭示其在非理想信号条件下的信号链缺陷与测量误差。

Result: 测试显示符合现行法规要求的智能电能表在实际复杂信号条件下仍存在显著信号链缺陷，表明当前验证体系存在漏洞，无法保证真实工况下的测量准确性。

Conclusion: 智能电能表的现行验证标准与方法存在不足，需要建立更贴近真实电网环境的测试体系，并针对信号链特性制定更严格的验证规范，这是未来研究的重点方向。

Abstract: The most common instruments currently measuring active/reactive energy and power quality indicators are smart energy meters. Unfortunately, the verification of such meters is currently performed under ideal conditions or with simple signal models, which do not recreate actual states occurring in the power grid and do not ensure the verification of the properties of their signal chains. This paper presents challenges in the proper metrological verification of smart energy meters. It presents existing legal and normative requirements and scientific research directions regarding these meters. Selected test results are presented, which show that although the tested meters meet the normative and legal requirements because they have been approved for sale, numerous imperfections in the signal and measurement chains of the analyzed instruments are revealed for the selected test signal. On the basis of the presented research results, further directions of research in the field of smart energy meters have been determined.

</details>


### [122] [A Cognitive Framework for Autonomous Agents: Toward Human-Inspired Design](https://arxiv.org/abs/2601.16648)
*Francesco Guidi,Jingfeng Shan,Mehrdad Saeidi,Enrico Testi,Elia Favarelli,Andrea Giorgetti,Davide Dardari,Alberto Zanella,Giorgio Li Pira,Francesca Starita,Anna Guerra*

Main category: eess.SY

TL;DR: 论文提出了一种融合巴甫洛夫和工具性学习的人类启发式强化学习架构，通过条件线索引导决策来提升自主系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有工程解决方案过度依赖工具性学习，而神经科学研究表明人类利用巴甫洛夫关联来借助预测性线索在结果发生前调整行为。这启发了将双系统机制融入智能体架构，以提升在未知、部分可观察环境中的决策效率和适应能力。

Method: 设计了一个提示引导的强化学习框架，将射频刺激作为巴甫洛夫条件线索，通过将巴甫洛夫值与工具性策略优化相结合来调制动作选择。该架构模仿人类学习的双系统机制，使得智能体能利用外部预测线索优化导航和协作行为。

Result: 仿真结果显示，线索驱动智能体比传统仅依靠工具性学习的智能体适应更快，在导航效率和合作行为方面表现出更优越的性能。

Conclusion: 本研究凸显了人类学习原则在重塑数字智能体智能方面的潜力，展示了融合巴甫洛夫和工具性过程如何显著改善自主系统在复杂环境中的决策能力。

Abstract: This work introduces a human-inspired reinforcement learning (RL) architecture that integrates Pavlovian and instrumental processes to enhance decision-making in autonomous systems. While existing engineering solutions rely almost exclusively on instrumental learning, neuroscience shows that humans use Pavlovian associations to leverage predictive cues to bias behavior before outcomes occur. We translate this dual-system mechanism into a cue-guided RL framework in which radio-frequency (RF) stimuli act as conditioned (Pavlovian) cues that modulate action selection. The proposed architecture combines Pavlovian values with instrumental policy optimization, improving navigation efficiency and cooperative behavior in unknown, partially observable environments. Simulation results demonstrate that cue-driven agents adapt faster, achieving superior performance compared to traditional instrumental-solo agents. This work highlights the potential of human learning principles to reshape digital agents intelligence.

</details>


### [123] [Computation-Accuracy Trade-Off in Service-Oriented Model-Based Control](https://arxiv.org/abs/2601.16682)
*Hazem Ibrahim,Julius Beerwerth,Lorenz Dörschel,Bassam Alrifaee*

Main category: eess.SY

TL;DR: 该论文提出了一个基于A*搜索和上下文贝叶斯优化的服务编排优化框架，用于在车辆纵向速度控制中实现计算精度权衡的在线性能驱动重构


<details>
  <summary>Details</summary>
Motivation: 将控制系统表示为面向服务的架构（SOMC）使其能够在运行时灵活组合控制环元素，但需要优化计算精度权衡以满足实时控制要求

Method: 1) 将服务编排建模为A*搜索问题 2) 使用上下文贝叶斯优化调优多目标成本权重 3) 在车辆纵向速度控制案例中实现在线性能驱动架构重构

Result: 框架成功实现了控制回路的运行时重配置，不仅能结合控制和软件结构，还能在性能优化中考虑控制系统的实时要求

Conclusion: 提出的SOMC优化框架通过智能服务编排和参数调优，有效解决了控制系统中计算复杂度与性能精度之间的权衡问题，并在实际控制案例中验证了其有效性

Abstract: Representing a control system as a Service-Oriented Architecture (SOA)-referred to as Service-Oriented Model-Based Control (SOMC)-enables runtime-flexible composition of control loop elements. This paper presents a framework that optimizes the computation-accuracy trade-off by formulating service orchestration as an A$^\star$search problem, complemented by Contextual Bayesian Optimization (BO) to tune the multi-objective cost weights. A vehicle longitudinal-velocity control case study demonstrates online, performancedriven reconfiguration of the control architecture. We show that our framework not only combines control and software structure but also considers the real-time requirements of the control system during performance optimization.

</details>


### [124] [On a Coupled Adoption-Opinion Framework for Competing Innovations](https://arxiv.org/abs/2601.16719)
*Martina Alutto,Fabrizio Dabbene,Angela Fontan,Karl H. Johansson,Chiara Ravazzi*

Main category: eess.SY

TL;DR: 提出了一个双层采纳-意见模型，研究两种竞争技术在人群中的扩散，证明存在独特的采纳扩散均衡，使两种技术共存。市场占有率仅取决于用户体验，对称干预可能不成比例地有利于更高质量的技术。


<details>
  <summary>Details</summary>
Motivation: 研究在社会影响和采纳驱动反馈下，两种竞争技术在人群中的扩散机制。特别关注采纳后的不满情绪可能导致用户转向替代技术，并探索对称干预如何产生不对称结果。

Method: 采用双层采纳-意见模型，第一层模拟技术采纳动态，第二层模拟意见演变。模型包含社会影响和采纳驱动的反馈机制。通过理论分析证明均衡存在性与唯一性，并进行数值模拟验证。

Result: 证明了采纳扩散均衡的存在性和唯一性，两种技术将共存且不会出现部分采纳或垄断局面。数值模拟表明，意见影响采纳水平，但两种技术的相对市场份额仅取决于用户体验质量。对称的干预措施可能不成比例地有利于更高质量的技术。

Conclusion: 在竞争技术扩散过程中，用户体验质量决定了市场份额，而非社会意见。政策制定者应注意对称干预措施可能产生不对称结果，这为理解技术竞争和政策干预提供了新视角。

Abstract: In this paper, we propose a two-layer adoption-opinion model to study the diffusion of two competing technologies within a population whose opinions evolve under social influence and adoption-driven feedback. After adopting one technology, individuals may become dissatisfied and switch to the alternative. We prove the existence and uniqueness of the adoption-diffused equilibrium, showing that both technologies coexist and that neither partial-adoption nor monopoly can arise. Numerical simulations show that while opinions shape the equilibrium adoption levels, the relative market share between the two technologies depends solely on their user-experience. As a consequence, interventions that symmetrically boost opinions or adoption can disproportionately favor the higher-quality technology, illustrating how symmetric control actions may generate asymmetric outcomes.

</details>


### [125] [ReLU Networks for Model Predictive Control: Network Complexity and Performance Guarantees](https://arxiv.org/abs/2601.16764)
*Xingchen Li,Keyou You*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent years have witnessed a resurgence in using ReLU neural networks (NNs) to represent model predictive control (MPC) policies. However, determining the required network complexity to ensure closed-loop performance remains a fundamental open problem. This involves a critical precision-complexity trade-off: undersized networks may fail to capture the MPC policy, while oversized ones may outweigh the benefits of ReLU network approximation. In this work, we propose a projection-based method to enforce hard constraints and establish a state-dependent Lipschitz continuity property for the optimal MPC cost function, which enables sharp convergence analysis of the closed-loop system. For the first time, we derive explicit bounds on ReLU network width and depth for approximating MPC policies with guaranteed closed-loop performance. To further reduce network complexity and enhance closed-loop performance, we propose a non-uniform error framework with a state-aware scaling function to adaptively adjust both the input and output of the ReLU network. Our contributions provide a foundational step toward certifiable ReLU NN-based MPC.

</details>


### [126] [Identification of Port-Hamiltonian Differential-Algebraic Equations from Input-Output Data](https://arxiv.org/abs/2601.16827)
*N. Hagelaars,G. J. E. van Otterdijk,S. Moradi,R. Tóth,N. O. Jaensson,M. Schoukens*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Many models of physical systems, such as mechanical and electrical networks, exhibit algebraic constraints that arise from subsystem interconnections and underlying physical laws. Such systems are commonly formulated as differential-algebraic equations (DAEs), which describe both the dynamic evolution of system states and the algebraic relations that must hold among them. Within this class, port-Hamiltonian differential-algebraic equations (pH-DAEs) offer a structured, energy-based representation that preserves interconnection and passivity properties. This work introduces a data-driven identification method that combines port-Hamiltonian neural networks (pHNNs) with a differential-algebraic solver to model such constrained systems directly from noisy input-output data. The approach preserves the passivity and interconnection structure of port-Hamiltonian systems while employing a backward Euler discretization with Newton's method to solve the coupled differential and algebraic equations consistently. The performance of the proposed approach is demonstrated on a DC power network, where the identified model accurately captures system behaviour and maintains errors proportional to the noise amplitude, while providing reliable parameter estimates.

</details>


### [127] [Performance of Differential Protection Applied to Collector Cables of Offshore Wind Farms with MMC-HVDC Transmission](https://arxiv.org/abs/2601.16876)
*Moisés J. B. B. Davi,Felipe V. Lopes,Vinícius A. Lacerda,Mário Oleskovicz,Oriol Gomis-Bellmunt*

Main category: eess.SY

TL;DR: 本摘要讨论了在低功耗向低碳排放能源转型背景下，结合模块化多电平变换器和高压直流传输的海上风电场的电力系统保护所面临的独特挑战。重点评估了在连接风力发电机至离岸MMC的集电电缆中，由于两端均由逆变器类电源供电，常规差动保护的限制及其与改进方案（考虑相序分量）的对比分析。


<details>
  <summary>Details</summary>
Motivation: 随着全球能源转型，海上风电场的快速发展与MMC-HVDC技术的结合给电力系统保护带来了新挑战，特别是当集电电缆的两端均由逆变器型资源供电时，故障电流的大小和特性发生改变，导致传统保护方案可能不再适用，因此需要研究针对这类新型故障场景的保护策略。

Method: 采用电磁暂态仿真方法，在PSCAD/EMTDC软件中建立一个典型的海上风电模型，对内外部故障场景（包括不同类型故障和故障电阻变化）下差动保护的表现进行模拟评估和对比。

Result: 通过对比分析，揭示了传统差动保护在逆变器主导电网条件下的局限性，而考虑相序分量的增强型保护策略则在灵敏性和选择性方面表现出更优的性能，深化了对未来转换器为主导电网的保护挑战的理解。

Conclusion: 该研究表明，在未来的高比例新能源电网中，电力保护策略需要适应从同步发电机主导系统向逆变器基础资源系统的转变，特别是要充分考虑故障特性的变化及提高保护系统的性能，以确保电网的可靠与安全。

Abstract: The ongoing global transition towards low-carbon energy has propelled the integration of offshore wind farms, which, when combined with Modular Multilevel Converter-based High-Voltage Direct Current (MMC-HVDC) transmission, present unique challenges for power system protection. In collector cables connecting wind turbines to offshore MMC, both ends are supplied by Inverter-Based Resources (IBRs), which modify the magnitude and characteristics of fault currents. In this context, this paper investigates the limitations of conventional differential protection schemes under such conditions and compares them with enhanced strategies that account for sequence components. Using electromagnetic transient simulations of a representative offshore wind farm modeled in PSCAD/EMTDC software, internal and external fault scenarios are assessed, varying fault types and resistances. The comparative evaluation provides insights into the sensitivity and selectivity of differential protection and guides a deeper conceptual understanding of the evolving protection challenges inherent to future converter-dominated grids.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [128] [Experience with Single Domain Generalization in Real World Medical Imaging Deployments](https://arxiv.org/abs/2601.16359)
*Ayan Banerjee,Komandoor Srivathsan,Sandeep K. S. Gupta*

Main category: eess.IV

TL;DR: 该论文介绍了一种名为DL+EKE的专家知识集成深度学习技术，用于解决医学影像中的单域泛化问题，在糖尿病视网膜病变等多个真实案例中超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 医学影像应用中，不同中心扫描仪和成像协议的差异导致领域偏移，加剧了罕见类别特征的变异性，需要能够在单域训练下有效泛化到未见目标域的方法。

Method: 开发了DL+EKE（深度学习+专家知识集成）通用框架，首先用糖尿病视网膜病变应用验证其有效性，然后部署到压力心电图和静息态fMRI两个真实世界案例中。

Result: 在糖尿病视网膜病变应用中，DL+EKE技术超越了现有SOTA单域泛化方法，在实际部署的压力心电图和静息态fMRI案例中也验证了其有效性。

Conclusion: 专家知识集成的深度学习技术DL+EKE在解决医学影像单域泛化问题上显示出优越性能，特别适用于真实世界多中心研究中的领域偏移挑战。

Abstract: A desirable property of any deployed artificial intelligence is generalization across domains, i.e. data generation distribution under a specific acquisition condition. In medical imagining applications the most coveted property for effective deployment is Single Domain Generalization (SDG), which addresses the challenge of training a model on a single domain to ensure it generalizes well to unseen target domains. In multi-center studies, differences in scanners and imaging protocols introduce domain shifts that exacerbate variability in rare class characteristics. This paper presents our experience on SDG in real life deployment for two exemplary medical imaging case studies on seizure onset zone detection using fMRI data, and stress electrocardiogram based coronary artery detection. Utilizing the commonly used application of diabetic retinopathy, we first demonstrate that state-of-the-art SDG techniques fail to achieve generalized performance across data domains. We then develop a generic expert knowledge integrated deep learning technique DL+EKE and instantiate it for the DR application and show that DL+EKE outperforms SOTA SDG methods on DR. We then deploy instances of DL+EKE technique on the two real world examples of stress ECG and resting state (rs)-fMRI and discuss issues faced with SDG techniques.

</details>


### [129] [On The Robustness of Foundational 3D Medical Image Segmentation Models Against Imprecise Visual Prompts](https://arxiv.org/abs/2601.16383)
*Soumitri Chattopadhyay,Basar Demir,Marc Niethammer*

Main category: eess.IV

TL;DR: 本研究系统分析了3D医学图像基础模型在提示不精确情况下的鲁棒性，揭示了模型对视觉形状和空间线索的依赖程度以及对抗扰动的韧性


<details>
  <summary>Details</summary>
Motivation: 现有3D医学图像基础模型在提示式分割中表现出潜力，但其对不精确提示的鲁棒性尚未得到充分研究。本文旨在通过系统研究各种受控扰动的影响来弥补这一空白，这些扰动可以密切模拟现实世界中的不精确情况

Method: 通过对两种最近的3D基础模型在多器官腹部分割任务上进行实验，系统研究了密集视觉提示的各种受控扰动效果，包括视觉形状和空间线索的变化

Result: 揭示了提示式医学分割的多个方面，特别是模型对视觉形状和空间线索的依赖程度，以及模型对某些扰动表现出的韧性限度

Conclusion: 研究为理解3D医学图像基础模型在提示式分割中的鲁棒性提供了系统分析，有助于未来开发更具韧性的医学图像分割系统

Abstract: While 3D foundational models have shown promise for promptable segmentation of medical volumes, their robustness to imprecise prompts remains under-explored. In this work, we aim to address this gap by systematically studying the effect of various controlled perturbations of dense visual prompts, that closely mimic real-world imprecision. By conducting experiments with two recent foundational models on a multi-organ abdominal segmentation task, we reveal several facets of promptable medical segmentation, especially pertaining to reliance on visual shape and spatial cues, and the extent of resilience of models towards certain perturbations. Codes are available at: https://github.com/ucsdbiag/Prompt-Robustness-MedSegFMs

</details>


### [130] [Unsupervised Super-Resolution of Hyperspectral Remote Sensing Images Using Fully Synthetic Training](https://arxiv.org/abs/2601.16602)
*Xinxin Xu,Yann Gousseau,Christophe Kervazo,Saïd Ladjal*

Main category: eess.IV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Considerable work has been dedicated to hyperspectral single image super-resolution to improve the spatial resolution of hyperspectral images and fully exploit their potential. However, most of these methods are supervised and require some data with ground truth for training, which is often non-available. To overcome this problem, we propose a new unsupervised training strategy for the super-resolution of hyperspectral remote sensing images, based on the use of synthetic abundance data. Its first step decomposes the hyperspectral image into abundances and endmembers by unmixing. Then, an abundance super-resolution neural network is trained using synthetic abundances, which are generated using the dead leaves model in such a way as to faithfully mimic real abundance statistics. Next, the spatial resolution of the considered hyperspectral image abundances is increased using this trained network, and the high resolution hyperspectral image is finally obtained by recombination with the endmembers. Experimental results show the training potential of the synthetic images, and demonstrate the method effectiveness.

</details>


### [131] [Fast, faithful and photorealistic diffusion-based image super-resolution with enhanced Flow Map models](https://arxiv.org/abs/2601.16660)
*Maxence Noble,Gonzalo Iñaki Quintana,Benjamin Aubin,Clément Chadebec*

Main category: eess.IV

TL;DR: FlowMapSR是一种基于扩散模型的图像超分辨率框架，通过知识蒸馏实现高效推理，在保持重建保真度与照片真实感之间取得了更好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的图像超分辨率方法需要在重建保真度和照片真实感之间权衡，且推理效率低。现有的知识蒸馏方法虽然提升了效率，但会损失感知线索如真实纹理和景深等。

Method: 基于自蒸馏的Flow Map模型构建FlowMapSR框架，引入两个关键增强：1）基于分类器自由引导范式泛化的正负提示引导；2）使用LoRA进行对抗微调。在Eulerian、Lagrangian和Shortcut三种Flow Map变体中，Shortcut变体表现最佳。

Result: 实验表明，FlowMapSR在x4和x8超分辨率任务中，比现有最先进方法在重建保真度与照片真实感之间取得了更好平衡，同时保持有竞争力的推理时间。一个单一模型即可处理两种缩放因子，无需特定尺度条件或退化引导机制。

Conclusion: FlowMapSR是一种有效且高效的扩散式超分辨率框架，通过自蒸馏和增强技术，在保持高质量输出的同时提升了推理效率，为图像超分辨率提供了新思路。

Abstract: Diffusion-based image super-resolution (SR) has recently attracted significant attention by leveraging the expressive power of large pre-trained text-to-image diffusion models (DMs). A central practical challenge is resolving the trade-off between reconstruction faithfulness and photorealism. To address inference efficiency, many recent works have explored knowledge distillation strategies specifically tailored to SR, enabling one-step diffusion-based approaches. However, these teacher-student formulations are inherently constrained by information compression, which can degrade perceptual cues such as lifelike textures and depth of field, even with high overall perceptual quality. In parallel, self-distillation DMs, known as Flow Map models, have emerged as a promising alternative for image generation tasks, enabling fast inference while preserving the expressivity and training stability of standard DMs. Building on these developments, we propose FlowMapSR, a novel diffusion-based framework for image super-resolution explicitly designed for efficient inference. Beyond adapting Flow Map models to SR, we introduce two complementary enhancements: (i) positive-negative prompting guidance, based on a generalization of classifier free-guidance paradigm to Flow Map models, and (ii) adversarial fine-tuning using Low-Rank Adaptation (LoRA). Among the considered Flow Map formulations (Eulerian, Lagrangian, and Shortcut), we find that the Shortcut variant consistently achieves the best performance when combined with these enhancements. Extensive experiments show that FlowMapSR achieves a better balance between reconstruction faithfulness and photorealism than recent state-of-the-art methods for both x4 and x8 upscaling, while maintaining competitive inference time. Notably, a single model is used for both upscaling factors, without any scale-specific conditioning or degradation-guided mechanisms.

</details>
