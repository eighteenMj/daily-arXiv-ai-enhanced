<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 91]
- [cs.IT](#cs.IT) [Total: 8]
- [eess.IV](#eess.IV) [Total: 6]
- [eess.SY](#eess.SY) [Total: 10]
- [cs.LG](#cs.LG) [Total: 95]
- [cs.AI](#cs.AI) [Total: 57]
- [cs.NI](#cs.NI) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [WorldVQA: Measuring Atomic World Knowledge in Multimodal Large Language Models](https://arxiv.org/abs/2602.02537)
*Runjie Zhou,Youbo Shao,Haoyu Lu,Bowei Xing,Tongtong Bai,Yujie Chen,Jie Zhao,Lin Sui,Haotian Yao,Zijia Zhao,Hao Yang,Haoning Wu,Zaida Zhou,Jinguo Zhu,Zhiqi Huang,Yiping Bao,Yangyang Liu,Y. Charles,Xinyu Zhou*

Main category: cs.CV

TL;DR: WorldVQA：一个评估MLLMs原子视觉世界知识的基准，专注于剥离推理能力、严格测量模型记忆的视觉实体知识


<details>
  <summary>Details</summary>
Motivation: 现有评估方法将视觉知识检索与推理能力混淆，难以准确衡量模型真正记忆的视觉世界知识。需要建立一个专门评估模型原子视觉实体命名与识别能力的基准，为视觉事实性提供严格测试标准。

Method: 设计分层分类法的评估框架，涵盖从常见头部类别对象到长尾稀有实体的视觉实体，使能评估模型在不同颗粒度上的原子视觉知识。

Result: 创建了WorldVQA基准，能够解耦视觉知识检索与推理能力，专门评估MLLMs的视觉实体识别和命名能力，测量记忆的视觉事实知识。

Conclusion: WorldVQA可作为评估当前及下一代前沿模型百科全书广度和幻觉率的标准化基准，为MLLMs视觉事实性提供严格测试框架。

Abstract: We introduce WorldVQA, a benchmark designed to evaluate the atomic visual world knowledge of Multimodal Large Language Models (MLLMs). Unlike current evaluations, which often conflate visual knowledge retrieval with reasoning, WorldVQA decouples these capabilities to strictly measure "what the model memorizes." The benchmark assesses the atomic capability of grounding and naming visual entities across a stratified taxonomy, spanning from common head-class objects to long-tail rarities. We expect WorldVQA to serve as a rigorous test for visual factuality, thereby establishing a standard for assessing the encyclopedic breadth and hallucination rates of current and next-generation frontier models.

</details>


### [2] [AdaptMMBench: Benchmarking Adaptive Multimodal Reasoning for Mode Selection and Reasoning Process](https://arxiv.org/abs/2602.02676)
*Xintong Zhang,Xiaowen Zhang,Jongrong Wu,Zhi Gao,Shilin Yan,Zhenxin Diao,Kunpeng Gao,Xuanyan Chen,Yuwei Wu,Yunde Jia,Qing Li*

Main category: cs.CV

TL;DR: 提出AdaptMMBench基准，通过动态任务难度识别和MCC指标评估自适应多模态推理模式选择的合理性，发现模式选择与模型能力相关但最终准确率无关，关键步骤覆盖率与性能一致而工具有效性不一致。


<details>
  <summary>Details</summary>
Motivation: 现有自适应多模态推理评估依赖静态难度标签和简单指标，无法反映动态难度变化且忽略了细粒度过程分析，需要新的评估框架来解决这些局限性。

Method: 建立AdaptMMBench基准，涵盖现实世界、OCR、GUI、知识和数学五个领域，结合直接感知和复杂推理任务，通过MCC评估不同推理模式选择合理性，并支持多维度过程评估。

Result: 自适应模式选择随模型能力提高而增强但与最终准确率无关，关键步骤覆盖率与性能一致，工具有效性在不同模型架构间高度不一致。

Conclusion: AdaptMMBench为自适应多模态推理提供了更全面的评估框架，揭示了模式选择能力与最终性能的分离，强调了过程评估的重要性，并为未来模型开发提供了指导。

Abstract: Adaptive multimodal reasoning has emerged as a promising frontier in Vision-Language Models (VLMs), aiming to dynamically modulate between tool-augmented visual reasoning and text reasoning to enhance both effectiveness and efficiency. However, existing evaluations rely on static difficulty labels and simplistic metrics, which fail to capture the dynamic nature of difficulty relative to varying model capacities. Consequently, they obscure the distinction between adaptive mode selection and general performance while neglecting fine-grained process analyses. In this paper, we propose AdaptMMBench, a comprehensive benchmark for adaptive multimodal reasoning across five domains: real-world, OCR, GUI, knowledge, and math, encompassing both direct perception and complex reasoning tasks. AdaptMMBench utilizes a Matthews Correlation Coefficient (MCC) metric to evaluate the selection rationality of different reasoning modes, isolating this meta-cognition ability by dynamically identifying task difficulties based on models' capability boundaries. Moreover, AdaptMMBench facilitates multi-dimensional process evaluation across key step coverage, tool effectiveness, and computational efficiency. Our evaluation reveals that while adaptive mode selection scales with model capacity, it notably decouples from final accuracy. Conversely, key step coverage aligns with performance, though tool effectiveness remains highly inconsistent across model architectures.

</details>


### [3] [End-to-end reconstruction of OCT optical properties and speckle-reduced structural intensity via physics-based learning](https://arxiv.org/abs/2602.02721)
*Jinglun Yu,Yaning Wang,Wenhan Guo,Yuan Gao,Yu Sun,Jin U. Kang*

Main category: cs.CV

TL;DR: 提出一个用于光学相干断层扫描的端到端深度学习框架，通过结合物理前向模型联合重建光学参数图和去散斑的结构图像。


<details>
  <summary>Details</summary>
Motivation: OCT中的逆散射问题需要同时恢复结构图像和内在组织光学特性，但传统方法因衰减、散斑噪声和参数强耦合而面临挑战。

Method: 使用正则化端到端深度学习框架，结合基于物理的OCT前向模型，通过蒙特卡洛模拟生成训练数据，联合估计光学参数并生成去散斑结构图像。

Result: 在合成角膜OCT数据集上验证，方法在噪声下稳健地恢复光学参数图，提高了分辨率和结构保真度。

Conclusion: 该方法实现了定量多参数组织表征，展示了物理建模与深度学习结合在计算OCT中的优势。

Abstract: Inverse scattering in optical coherence tomography (OCT) seeks to recover both structural images and intrinsic tissue optical properties, including refractive index, scattering coefficient, and anisotropy. This inverse problem is challenging due to attenuation, speckle noise, and strong coupling among parameters. We propose a regularized end-to-end deep learning framework that jointly reconstructs optical parameter maps and speckle-reduced OCT structural intensity for layer visualization. Trained with Monte Carlo-simulated ground truth, our network incorporates a physics-based OCT forward model that generates predicted signals from the estimated parameters, providing physics-consistent supervision for parameter recovery and artifact suppression. Experiments on the synthetic corneal OCT dataset demonstrate robust optical map recovery under noise, improved resolution, and enhanced structural fidelity. This approach enables quantitative multi-parameter tissue characterization and highlights the benefit of combining physics-informed modeling with deep learning for computational OCT.

</details>


### [4] [SVD-ViT: Does SVD Make Vision Transformers Attend More to the Foreground?](https://arxiv.org/abs/2602.02765)
*Haruhiko Murata,Kazuhiro Hotta*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Vision Transformers (ViT) have been established as large-scale foundation models. However, because self-attention operates globally, they lack an explicit mechanism to distinguish foreground from background. As a result, ViT may learn unnecessary background features and artifacts, leading to degraded classification performance. To address this issue, we propose SVD-ViT, which leverages singular value decomposition (SVD) to prioritize the learning of foreground features. SVD-ViT consists of three components-\textbf{SPC module}, \textbf{SSVA}, and \textbf{ID-RSVD}-and suppresses task-irrelevant factors such as background noise and artifacts by extracting and aggregating singular vectors that capture object foreground information. Experimental results demonstrate that our method improves classification accuracy and effectively learns informative foreground representations while reducing the impact of background noise.

</details>


### [5] [LmPT: Conditional Point Transformer for Anatomical Landmark Detection on 3D Point Clouds](https://arxiv.org/abs/2602.02808)
*Matteo Bastico,Pierre Onghena,David Ryckelynck,Beatriz Marcotegui,Santiago Velasco-Forero,Laurent Corté,Caroline Robine--Decourcelle,Etienne Decencière*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate identification of anatomical landmarks is crucial for various medical applications. Traditional manual landmarking is time-consuming and prone to inter-observer variability, while rule-based methods are often tailored to specific geometries or limited sets of landmarks. In recent years, anatomical surfaces have been effectively represented as point clouds, which are lightweight structures composed of spatial coordinates. Following this strategy and to overcome the limitations of existing landmarking techniques, we propose Landmark Point Transformer (LmPT), a method for automatic anatomical landmark detection on point clouds that can leverage homologous bones from different species for translational research. The LmPT model incorporates a conditioning mechanism that enables adaptability to different input types to conduct cross-species learning. We focus the evaluation of our approach on femoral landmarking using both human and newly annotated dog femurs, demonstrating its generalization and effectiveness across species. The code and dog femur dataset will be publicly available at: https://github.com/Pierreoo/LandmarkPointTransformer.

</details>


### [6] [Self-Supervised Uncalibrated Multi-View Video Anonymization in the Operating Room](https://arxiv.org/abs/2602.02850)
*Keqi Chen,Vinkle Srivastav,Armine Vardazaryan,Cindy Rolland,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Privacy preservation is a prerequisite for using video data in Operating Room (OR) research. Effective anonymization relies on the exhaustive localization of every individual; even a single missed detection necessitates extensive manual correction. However, existing approaches face two critical scalability bottlenecks: (1) they usually require manual annotations of each new clinical site for high accuracy; (2) while multi-camera setups have been widely adopted to address single-view ambiguity, camera calibration is typically required whenever cameras are repositioned. To address these problems, we propose a novel self-supervised multi-view video anonymization framework consisting of whole-body person detection and whole-body pose estimation, without annotation or camera calibration. Our core strategy is to enhance the single-view detector by "retrieving" false negatives using temporal and multi-view context, and conducting self-supervised domain adaptation. We first run an off-the-shelf whole-body person detector in each view with a low-score threshold to gather candidate detections. Then, we retrieve the low-score false negatives that exhibit consistency with the high-score detections via tracking and self-supervised uncalibrated multi-view association. These recovered detections serve as pseudo labels to iteratively fine-tune the whole-body detector. Finally, we apply whole-body pose estimation on each detected person, and fine-tune the pose model using its own high-score predictions. Experiments on the 4D-OR dataset of simulated surgeries and our dataset of real surgeries show the effectiveness of our approach achieving over 97% recall. Moreover, we train a real-time whole-body detector using our pseudo labels, achieving comparable performance and highlighting our method's practical applicability. Code is available at https://github.com/CAMMA-public/OR_anonymization.

</details>


### [7] [ViThinker: Active Vision-Language Reasoning via Dynamic Perceptual Querying](https://arxiv.org/abs/2602.02873)
*Weihang You,Qingchan Zhu,David Liu,Yi Pan,Geng Yuan,Hanqi Jiang*

Main category: cs.CV

TL;DR: ViThinker是一个主动感知的视觉-语言推理框架，通过生成查询令牌按需合成专家对齐的视觉特征，改善传统CoT在视觉分析中因过早转换而丢失空间信息的问题。


<details>
  <summary>Details</summary>
Motivation: 传统CoT推理在视觉-语言模型中存在局限：过早将视觉信息转换为文本会丢失几何、空间布局等连续信息；现有方法多为被动处理预计算输入，缺乏主动获取任务相关细节的能力。

Method: 1) 训练时内化视觉专家能力：首先通过蒸馏将冻结专家的知识融入模型参数；2) 学习任务驱动的主动查询：通过稀疏性惩罚使模型为每个推理步骤生成最小充分的感知查询；3) 推理时进行生成性心智模拟，无需调用外部工具。

Result: 在多个视觉中心基准测试中表现出一致的改进，验证了主动查询生成在感知基础和推理准确性方面均优于被动方法。

Conclusion: ViThinker通过模拟人类主动感知机制，实现了视觉-语言模型的自主动态信息获取，解决了传统CoT在视觉推理中的局限性，为多模态推理提供了新范式。

Abstract: Chain-of-Thought (CoT) reasoning excels in language models but struggles in vision-language models due to premature visual-to-text conversion that discards continuous information such as geometry and spatial layout. While recent methods enhance CoT through static enumeration or attention-based selection, they remain passive, i.e., processing pre-computed inputs rather than actively seeking task-relevant details. Inspired by human active perception, we introduce ViThinker, a framework that enables vision-language models to autonomously generate decision (query) tokens triggering the synthesis of expert-aligned visual features on demand. ViThinker internalizes vision-expert capabilities during training, performing generative mental simulation during inference without external tool calls. Through a two-stage curriculum: first distilling frozen experts into model parameters, then learning task-driven querying via sparsity penalties, i.e., ViThinker discovers minimal sufficient perception for each reasoning step. Evaluations across vision-centric benchmarks demonstrate consistent improvements, validating that active query generation outperforms passive approaches in both perceptual grounding and reasoning accuracy.

</details>


### [8] [DoubleTake: Contrastive Reasoning for Faithful Decision-Making in Medical Imaging](https://arxiv.org/abs/2602.02894)
*Daivik Patel,Shrenik Patel*

Main category: cs.CV

TL;DR: 本文提出对比文档感知的参考选择框架和反事实对比推理方法，提升医学影像鉴别诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像决策方法多数依赖最近邻检索，这种方法返回冗余证据并强化单一假设，但医疗决策需要基于细微视觉差异进行鉴别。ROCO数据库虽提供大规模图像-文本对，但未指定如何进行对比推理的参考选择。

Method: 1) 构建对比文档感知参考选择框架，平衡视觉相关性、嵌入多样性和来源追踪，使用ROCO嵌入和元数据；2) 提出反事实对比推理框架，执行结构化成对视觉比较，使用基于边界的决策规则和可信度弃权聚合证据。

Result: 在MediConfusion基准测试中，该方法的集合级准确率比先前方法提高近15%，并减少混淆、提升个体准确率。

Conclusion: 研究证明对比参考选择和结构化反事实推理能显著改善医学影像鉴别诊断性能，为可信医疗决策系统提供有效解决方案。

Abstract: Accurate decision making in medical imaging requires reasoning over subtle visual differences between confusable conditions, yet most existing approaches rely on nearest neighbor retrieval that returns redundant evidence and reinforces a single hypothesis. We introduce a contrastive, document-aware reference selection framework that constructs compact evidence sets optimized for discrimination rather than similarity by explicitly balancing visual relevance, embedding diversity, and source-level provenance using ROCO embeddings and metadata. While ROCO provides large-scale image-caption pairs, it does not specify how references should be selected for contrastive reasoning, and naive retrieval frequently yields near-duplicate figures from the same document. To address this gap, we release a reproducible reference selection protocol and curated reference bank that enable a systematic study of contrastive retrieval in medical image reasoning. Building on these contrastive evidence sets, we propose Counterfactual-Contrastive Inference, a confidence-aware reasoning framework that performs structured pairwise visual comparisons and aggregates evidence using margin-based decision rules with faithful abstention. On the MediConfusion benchmark, our approach achieves state-of-the-art performance, improving set-level accuracy by nearly 15% relative to prior methods while reducing confusion and improving individual accuracy.

</details>


### [9] [HypCBC: Domain-Invariant Hyperbolic Cross-Branch Consistency for Generalizable Medical Image Analysis](https://arxiv.org/abs/2602.03264)
*Francesco Di Salvo,Sebastian Doerrich,Jonas Alle,Christian Ledig*

Main category: cs.CV

TL;DR: 该论文提出了利用双曲流形处理医学图像分析中的领域泛化问题，通过双曲交叉分支一致性约束显著提高了模型在分布外数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析中数据稀缺且存在硬件、成像协议和患者群体的协变量偏移，传统欧几里得方法难以捕捉复杂的层次结构特征，导致领域泛化表现不佳，阻碍了临床应用的可靠性。

Method: 采用双曲流形建模复杂数据特征，提出无监督的领域不变双曲交叉分支一致性约束方法，用于提取领域不变特征并在双曲空间中进行特征对齐。

Result: 在11个分布内数据集和3种ViT模型上获得统计显著提升；在3个领域泛化基准测试（Fitzpatrick17k、Camelyon17-WILDS、视网膜影像跨数据集）上平均AUC提升2.1%，超越了现有欧几里得方法的性能。

Conclusion: 双曲表示学习能有效捕捉医学图像中的层次结构特征，提出的双曲交叉分支一致性约束显著提升了模型在协变量偏移下的泛化能力，验证了双曲方法在医学图像分析中的优势。

Abstract: Robust generalization beyond training distributions remains a critical challenge for deep neural networks. This is especially pronounced in medical image analysis, where data is often scarce and covariate shifts arise from different hardware devices, imaging protocols, and heterogeneous patient populations. These factors collectively hinder reliable performance and slow down clinical adoption. Despite recent progress, existing learning paradigms primarily rely on the Euclidean manifold, whose flat geometry fails to capture the complex, hierarchical structures present in clinical data. In this work, we exploit the advantages of hyperbolic manifolds to model complex data characteristics. We present the first comprehensive validation of hyperbolic representation learning for medical image analysis and demonstrate statistically significant gains across eleven in-distribution datasets and three ViT models. We further propose an unsupervised, domain-invariant hyperbolic cross-branch consistency constraint. Extensive experiments confirm that our proposed method promotes domain-invariant features and outperforms state-of-the-art Euclidean methods by an average of $+2.1\%$ AUC on three domain generalization benchmarks: Fitzpatrick17k, Camelyon17-WILDS, and a cross-dataset setup for retinal imaging. These datasets span different imaging modalities, data sizes, and label granularities, confirming generalization capabilities across substantially different conditions. The code is available at https://github.com/francescodisalvo05/hyperbolic-cross-branch-consistency .

</details>


### [10] [FaceLinkGen: Rethinking Identity Leakage in Privacy-Preserving Face Recognition with Identity Extraction](https://arxiv.org/abs/2602.02914)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Transformation-based privacy-preserving face recognition (PPFR) aims to verify identities while hiding facial data from attackers and malicious service providers. Existing evaluations mostly treat privacy as resistance to pixel-level reconstruction, measured by PSNR and SSIM. We show that this reconstruction-centric view fails. We present FaceLinkGen, an identity extraction attack that performs linkage/matching and face regeneration directly from protected templates without recovering original pixels. On three recent PPFR systems, FaceLinkGen reaches over 98.5\% matching accuracy and above 96\% regeneration success, and still exceeds 92\% matching and 94\% regeneration in a near zero knowledge setting. These results expose a structural gap between pixel distortion metrics, which are widely used in PPFR evaluation, and real privacy. We show that visual obfuscation leaves identity information broadly exposed to both external intruders and untrusted service providers.

</details>


### [11] [LEVIO: Lightweight Embedded Visual Inertial Odometry for Resource-Constrained Devices](https://arxiv.org/abs/2602.03294)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate, infrastructure-less sensor systems for motion tracking are essential for mobile robotics and augmented reality (AR) applications. The most popular state-of-the-art visual-inertial odometry (VIO) systems, however, are too computationally demanding for resource-constrained hardware, such as micro-drones and smart glasses. This work presents LEVIO, a fully featured VIO pipeline optimized for ultra-low-power compute platforms, allowing six-degrees-of-freedom (DoF) real-time sensing. LEVIO incorporates established VIO components such as Oriented FAST and Rotated BRIEF (ORB) feature tracking and bundle adjustment, while emphasizing a computationally efficient architecture with parallelization and low memory usage to suit embedded microcontrollers and low-power systems-on-chip (SoCs). The paper proposes and details the algorithmic design choices and the hardware-software co-optimization approach, and presents real-time performance on resource-constrained hardware. LEVIO is validated on a parallel-processing ultra-low-power RISC-V SoC, achieving 20 FPS while consuming less than 100 mW, and benchmarked against public VIO datasets, offering a compelling balance between efficiency and accuracy. To facilitate reproducibility and adoption, the complete implementation is released as open-source.

</details>


### [12] [A Multi-scale Linear-time Encoder for Whole-Slide Image Analysis](https://arxiv.org/abs/2602.02918)
*Jagan Mohan Reddy Dwarampudi,Joshua Wong,Hien Van Nguyen,Tania Banerjee*

Main category: cs.CV

TL;DR: MARBLE：第一个基于Mamba的纯多头多状态多尺度实例学习框架，用于全切片图像分析，通过并行处理多放大级别和coarse-to-fine推理，在线性时间内捕捉跨尺度依赖，在5个公开数据集上AUC提升高达6.9%，准确率提升20.3%，C-index提升2.3%


<details>
  <summary>Details</summary>
Motivation: 全切片图像分析面临千兆像素分辨率和层次化放大倍率的挑战，现有MIL方法通常只在单一尺度操作，而基于transformer的方法存在二次注意力计算成本问题，需要更高效的多尺度处理方法

Method: 提出MARBLE框架，采用纯Mamba-based的多状态多尺度实例学习架构，并行处理多个放大级别，在状态空间模型中集成coarse-to-fine推理，实现线性时间序列建模，以最小参数开销捕捉跨尺度依赖

Result: 在五个公开数据集上的实验表明，MARBLE在AUC上提升高达6.9%，准确率提升20.3%，C-index提升2.3%，相比现有方法表现更优

Conclusion: MARBLE为多尺度WSI分析提供了一个可扩展、模块化的替代注意力架构的框架，通过并行多尺度处理和线性时间序列建模，实现了高效且泛化性强的全切片图像分析

Abstract: We introduce Multi-scale Adaptive Recurrent Biomedical Linear-time Encoder (MARBLE), the first \textit{purely Mamba-based} multi-state multiple instance learning (MIL) framework for whole-slide image (WSI) analysis. MARBLE processes multiple magnification levels in parallel and integrates coarse-to-fine reasoning within a linear-time state-space model, efficiently capturing cross-scale dependencies with minimal parameter overhead. WSI analysis remains challenging due to gigapixel resolutions and hierarchical magnifications, while existing MIL methods typically operate at a single scale and transformer-based approaches suffer from quadratic attention costs. By coupling parallel multi-scale processing with linear-time sequence modeling, MARBLE provides a scalable and modular alternative to attention-based architectures. Experiments on five public datasets show improvements of up to \textbf{6.9\%} in AUC, \textbf{20.3\%} in accuracy, and \textbf{2.3\%} in C-index, establishing MARBLE as an efficient and generalizable framework for multi-scale WSI analysis.

</details>


### [13] [SRA-Seg: Synthetic to Real Alignment for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2602.02944)
*OFM Riaz Rahman Aranya,Kevin Desai*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Synthetic data, an appealing alternative to extensive expert-annotated data for medical image segmentation, consistently fails to improve segmentation performance despite its visual realism. The reason being that synthetic and real medical images exist in different semantic feature spaces, creating a domain gap that current semi-supervised learning methods cannot bridge. We propose SRA-Seg, a framework explicitly designed to align synthetic and real feature distributions for medical image segmentation. SRA-Seg introduces a similarity-alignment (SA) loss using frozen DINOv2 embeddings to pull synthetic representations toward their nearest real counterparts in semantic space. We employ soft edge blending to create smooth anatomical transitions and continuous labels, eliminating the hard boundaries from traditional copy-paste augmentation. The framework generates pseudo-labels for synthetic images via an EMA teacher model and applies soft-segmentation losses that respect uncertainty in mixed regions. Our experiments demonstrate strong results: using only 10% labeled real data and 90% synthetic unlabeled data, SRA-Seg achieves 89.34% Dice on ACDC and 84.42% on FIVES, significantly outperforming existing semi-supervised methods and matching the performance of methods using real unlabeled data.

</details>


### [14] [Nüwa: Mending the Spatial Integrity Torn by VLM Token Pruning](https://arxiv.org/abs/2602.02951)
*Yihong Huang,Fei Ma,Yihua Shao,Jingcai Guo,Zitong Yu,Laizhong Cui,Qi Tian*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Vision token pruning has proven to be an effective acceleration technique for the efficient Vision Language Model (VLM). However, existing pruning methods demonstrate excellent performance preservation in visual question answering (VQA) and suffer substantial degradation on visual grounding (VG) tasks. Our analysis of the VLM's processing pipeline reveals that strategies utilizing global semantic similarity and attention scores lose the global spatial reference frame, which is derived from the interactions of tokens' positional information. Motivated by these findings, we propose $\text{Nüwa}$, a two-stage token pruning framework that enables efficient feature aggregation while maintaining spatial integrity. In the first stage, after the vision encoder, we apply three operations, namely separation, alignment, and aggregation, which are inspired by swarm intelligence algorithms to retain information-rich global spatial anchors. In the second stage, within the LLM, we perform text-guided pruning to retain task-relevant visual tokens. Extensive experiments demonstrate that $\text{Nüwa}$ achieves SOTA performance on multiple VQA benchmarks (from 94% to 95%) and yields substantial improvements on visual grounding tasks (from 7% to 47%).

</details>


### [15] [TRACE: Temporal Radiology with Anatomical Change Explanation for Grounded X-ray Report Generation](https://arxiv.org/abs/2602.02963)
*OFM Riaz Rahman Aranya,Kevin Desai*

Main category: cs.CV

TL;DR: TRACE是首个结合时序比较和空间定位的胸部X光时序分析方法，能够检测疾病变化并进行自然语言描述。


<details>
  <summary>Details</summary>
Motivation: 现有方法只支持单张图像的报告生成或视觉定位，缺乏结合时序变化检测的能力。临床需要同时处理时序对比、变化分类和空间定位的任务。

Method: 提出TRACE模型，同时处理两张时序胸部X光图像，生成自然语言的变化描述（恶化、改善、稳定），并为每个发现提供边界框坐标。通过联合学习时序比较和空间定位来实现变化检测。

Result: TRACE在空间定位方面达到超过90%的准确率，消融研究发现只有当联合学习时序比较和空间定位时，才能实现有意义的时序变化检测。

Conclusion: 时序放射学变化检测需要联合学习时序比较和空间定位，空间定位为时序推理提供了重要的注意力机制，TRACE为这个新挑战任务奠定了基础。

Abstract: Temporal comparison of chest X-rays is fundamental to clinical radiology, enabling detection of disease progression, treatment response, and new findings. While vision-language models have advanced single-image report generation and visual grounding, no existing method combines these capabilities for temporal change detection. We introduce Temporal Radiology with Anatomical Change Explanation (TRACE), the first model that jointly performs temporal comparison, change classification, and spatial localization. Given a prior and current chest X-ray, TRACE generates natural language descriptions of interval changes (worsened, improved, stable) while grounding each finding with bounding box coordinates. TRACE demonstrates effective spatial localization with over 90% grounding accuracy, establishing a foundation for this challenging new task. Our ablation study uncovers an emergent capability: change detection arises only when temporal comparison and spatial grounding are jointly learned, as neither alone enables meaningful change detection. This finding suggests that grounding provides a spatial attention mechanism essential for temporal reasoning.

</details>


### [16] [Fisheye Stereo Vision: Depth and Range Error](https://arxiv.org/abs/2602.02973)
*Leaf Jiang,Matthew Holzel,Bernhard Kaplan,Hsiou-Yuan Liu,Sabyasachi Paul,Karen Rankin,Piotr Swierczynski*

Main category: cs.CV

TL;DR: 该研究推导了鱼眼立体视觉系统深度和范围误差随物体距离变化的解析表达式，专门考虑了在大角度情况下的精度。


<details>
  <summary>Details</summary>
Motivation: 鱼眼立体视觉系统在机器人、AR/VR、自动驾驶等领域广泛应用，但在大视角情况下存在精度下降问题。研究人员希望建立更精确的误差建模框架，特别是针对大角度条件下的深度和范围误差，以提高远距离和小角度条件下的测量精度。

Method: 通过数学建模和理论分析，推导出鱼眼立体视觉系统深度和范围误差的解析表达式。考虑了大角度条件下的几何特性和光学畸变参数，将误差表示为物体距离、焦距、基线长度、角度等参数的函数。

Result: 获得了可用于量化鱼眼立体视觉系统性能的误差表达式，能够准确预测不同条件下的深度测量精度，特别是揭示了大角度情况下误差的变化规律。

Conclusion: 推导出的解析表达式为鱼眼立体视觉系统的精度评估和优化提供了理论工具，有助于在实际应用中改进系统设计参数选择，特别是在需要大视角覆盖和远距离测量的应用场景中。

Abstract: This study derives analytical expressions for the depth and range error of fisheye stereo vision systems as a function of object distance, specifically accounting for accuracy at large angles.

</details>


### [17] [SceneLinker: Compositional 3D Scene Generation via Semantic Scene Graph from RGB Sequences](https://arxiv.org/abs/2602.02974)
*Seok-Young Kim,Dooyoung Kim,Woojin Cho,Hail Song,Suji Kang,Woontack Woo*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce SceneLinker, a novel framework that generates compositional 3D scenes via semantic scene graph from RGB sequences. To adaptively experience Mixed Reality (MR) content based on each user's space, it is essential to generate a 3D scene that reflects the real-world layout by compactly capturing the semantic cues of the surroundings. Prior works struggled to fully capture the contextual relationship between objects or mainly focused on synthesizing diverse shapes, making it challenging to generate 3D scenes aligned with object arrangements. We address these challenges by designing a graph network with cross-check feature attention for scene graph prediction and constructing a graph-variational autoencoder (graph-VAE), which consists of a joint shape and layout block for 3D scene generation. Experiments on the 3RScan/3DSSG and SG-FRONT datasets demonstrate that our approach outperforms state-of-the-art methods in both quantitative and qualitative evaluations, even in complex indoor environments and under challenging scene graph constraints. Our work enables users to generate consistent 3D spaces from their physical environments via scene graphs, allowing them to create spatial MR content. Project page is https://scenelinker2026.github.io.

</details>


### [18] [Aligning Forest and Trees in Images and Long Captions for Visually Grounded Understanding](https://arxiv.org/abs/2602.02977)
*Byeongju Woo,Zilin Wang,Byeonghyun Pak,Sangwoo Mo,Stella X. Yu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large vision-language models such as CLIP struggle with long captions because they align images and texts as undifferentiated wholes. Fine-grained vision-language understanding requires hierarchical semantics capturing both global context and localized details across visual and textual domains. Yet linguistic hierarchies from syntax or semantics rarely match visual organization, and purely visual hierarchies tend to fragment scenes into appearance-driven parts without semantic focus. We propose CAFT (Cross-domain Alignment of Forests and Trees), a hierarchical image-text representation learning framework that aligns global and local semantics across images and long captions without pixel-level supervision. Coupling a fine-to-coarse visual encoder with a hierarchical text transformer, it uses a hierarchical alignment loss that matches whole images with whole captions while biasing region-sentence correspondences, so that coarse semantics are built from fine-grained evidence rather than from aggregation untethered to part-level grounding. Trained on 30M image-text pairs, CAFT achieves state-of-the-art performance on six long-text retrieval benchmarks and exhibits strong scaling behavior. Experiments show that hierarchical cross-domain alignment enables fine-grained, visually grounded image-text representations to emerge without explicit region-level supervision.

</details>


### [19] [SharpTimeGS: Sharp and Stable Dynamic Gaussian Splatting via Lifespan Modulation](https://arxiv.org/abs/2602.02989)
*Zhanfeng Liao,Jiajun Zhang,Hanzhang Tu,Zhixi Wang,Yunqi Gao,Hongwen Zhang,Yebin Liu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Novel view synthesis of dynamic scenes is fundamental to achieving photorealistic 4D reconstruction and immersive visual experiences. Recent progress in Gaussian-based representations has significantly improved real-time rendering quality, yet existing methods still struggle to maintain a balance between long-term static and short-term dynamic regions in both representation and optimization. To address this, we present SharpTimeGS, a lifespan-aware 4D Gaussian framework that achieves temporally adaptive modeling of both static and dynamic regions under a unified representation. Specifically, we introduce a learnable lifespan parameter that reformulates temporal visibility from a Gaussian-shaped decay into a flat-top profile, allowing primitives to remain consistently active over their intended duration and avoiding redundant densification. In addition, the learned lifespan modulates each primitives' motion, reducing drift in long-lived static points while retaining unrestricted motion for short-lived dynamic ones. This effectively decouples motion magnitude from temporal duration, improving long-term stability without compromising dynamic fidelity. Moreover, we design a lifespan-velocity-aware densification strategy that mitigates optimization imbalance between static and dynamic regions by allocating more capacity to regions with pronounced motion while keeping static areas compact and stable. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art performance while supporting real-time rendering up to 4K resolution at 100 FPS on one RTX 4090.

</details>


### [20] [Video-OPD: Efficient Post-Training of Multimodal Large Language Models for Temporal Video Grounding via On-Policy Distillation](https://arxiv.org/abs/2602.02994)
*Jiaze Li,Hao Yin,Haoran Xu,Boshen Xu,Wenhui Tan,Zewen He,Jianzhong Ju,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reinforcement learning has emerged as a principled post-training paradigm for Temporal Video Grounding (TVG) due to its on-policy optimization, yet existing GRPO-based methods remain fundamentally constrained by sparse reward signals and substantial computational overhead. We propose Video-OPD, an efficient post-training framework for TVG inspired by recent advances in on-policy distillation. Video-OPD optimizes trajectories sampled directly from the current policy, thereby preserving alignment between training and inference distributions, while a frontier teacher supplies dense, token-level supervision via a reverse KL divergence objective. This formulation preserves the on-policy property critical for mitigating distributional shift, while converting sparse, episode-level feedback into fine-grained, step-wise learning signals. Building on Video-OPD, we introduce Teacher-Validated Disagreement Focusing (TVDF), a lightweight training curriculum that iteratively prioritizes trajectories that are both teacher-reliable and maximally informative for the student, thereby improving training efficiency. Empirical results demonstrate that Video-OPD consistently outperforms GRPO while achieving substantially faster convergence and lower computational cost, establishing on-policy distillation as an effective alternative to conventional reinforcement learning for TVG.

</details>


### [21] [VOILA: Value-of-Information Guided Fidelity Selection for Cost-Aware Multimodal Question Answering](https://arxiv.org/abs/2602.03007)
*Rahul Atul Bhope,K. R. Jayaram,Vinod Muthusamy,Ritesh Kumar,Vatche Isahagian,Nalini Venkatasubramanian*

Main category: cs.CV

TL;DR: VOILA 是一个基于信息价值驱动的自适应保真度选择框架，通过预测准确率与检索成本的权衡，在视觉问答中动态选择最小成本的视觉输入保真度以实现显著的成本节省。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态视觉-语言系统在固定保真度下运行，忽略了高保真度视觉输入的获取和处理成本较高的问题，需要一种能够在模型执行前优化信息检索的适应性方法来平衡成本和精度。

Method: VOILA采用两阶段流水线：1) 基于问题特征的梯度提升回归器估计每个保真度的正确率可能性；2) 等渗校准器细化概率以实现可靠决策，系统选择最大化预期效用且成本最低的保真度。

Result: 在3种部署场景、5个数据集和6个视觉语言模型的评估中，VOILA实现了50-60%的成本降低，同时保持了90-95%的全分辨率准确率。

Conclusion: 在资源受限的多模态推理中，基于信息价值驱动的自适应保真度选择是优化性能和成本的关键策略，VOILA展示了显著的实用性。

Abstract: Despite significant costs from retrieving and processing high-fidelity visual inputs, most multimodal vision-language systems operate at fixed fidelity levels. We introduce VOILA, a framework for Value-Of-Information-driven adaptive fidelity selection in Visual Question Answering (VQA) that optimizes what information to retrieve before model execution. Given a query, VOILA uses a two-stage pipeline: a gradient-boosted regressor estimates correctness likelihood at each fidelity from question features alone, then an isotonic calibrator refines these probabilities for reliable decision-making. The system selects the minimum-cost fidelity maximizing expected utility given predicted accuracy and retrieval costs. We evaluate VOILA across three deployment scenarios using five datasets (VQA-v2, GQA, TextVQA, LoCoMo, FloodNet) and six Vision-Language Models (VLMs) with 7B-235B parameters. VOILA consistently achieves 50-60% cost reductions while retaining 90-95% of full-resolution accuracy across diverse query types and model architectures, demonstrating that pre-retrieval fidelity selection is vital to optimize multimodal inference under resource constraints.

</details>


### [22] [Thinking inside the Convolution for Image Inpainting: Reconstructing Texture via Structure under Global and Local Side](https://arxiv.org/abs/2602.03013)
*Haipeng Liu,Yang Wang,Biao Qian,Yong Rui,Meng Wang*

Main category: cs.CV

TL;DR: 该论文针对图像修复中卷积下采样导致的纹理和结构信息丢失问题，提出了一种统计归一化和反归一化策略，通过相互增强结构特征和纹理特征的表达来提升修复效果


<details>
  <summary>Details</summary>
Motivation: 现有图像修复方法采用编码器-解码器架构，通过卷积下采样从已知区域学习来修复掩码区域，但下采样过程会导致结构特征和纹理特征信息丢失，影响最终上采样修复效果。需要解决如何让结构和纹理特征在下采样过程中相互帮助以缓解信息流失

Method: 提出采用统计归一化和反归一化策略，在卷积下采样过程中利用结构和纹理特征图的统计特征进行重建指导，通过特征间的相互增强来改善特征表达

Result: 在256x256和512x512分辨率图像上的实验结果表明，该方法优于现有技术，特别是在将所有编码器替换为该方法时效果显著

Conclusion: 通过统计归一化和反归一化策略，能够有效缓解卷积下采样过程中的信息损失，实现结构和纹理特征的相互增强，从而提升图像修复质量

Abstract: Image inpainting has earned substantial progress, owing to the encoder-and-decoder pipeline, which is benefited from the Convolutional Neural Networks (CNNs) with convolutional downsampling to inpaint the masked regions semantically from the known regions within the encoder, coupled with an upsampling process from the decoder for final inpainting output. Recent studies intuitively identify the high-frequency structure and low-frequency texture to be extracted by CNNs from the encoder, and subsequently for a desirable upsampling recovery. However, the existing arts inevitably overlook the information loss for both structure and texture feature maps during the convolutional downsampling process, hence suffer from a non-ideal upsampling output. In this paper, we systematically answer whether and how the structure and texture feature map can mutually help to alleviate the information loss during the convolutional downsampling. Given the structure and texture feature maps, we adopt the statistical normalization and denormalization strategy for the reconstruction guidance during the convolutional downsampling process. The extensive experimental results validate its advantages to the state-of-the-arts over the images from low-to-high resolutions including 256*256 and 512*512, especially holds by substituting all the encoders by ours. Our code is available at https://github.com/htyjers/ConvInpaint-TSGL

</details>


### [23] [A Vision-Based Analysis of Congestion Pricing in New York City](https://arxiv.org/abs/2602.03015)
*Mehmet Kerem Turkcan,Jhonatan Tavori,Javad Ghaderi,Gil Zussman,Zoran Kostic,Andrew Smyth*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We examine the impact of New York City's congestion pricing program through automated analysis of traffic camera data. Our computer vision pipeline processes footage from over 900 cameras distributed throughout Manhattan and New York, comparing traffic patterns from November 2024 through the program's implementation in January 2025 until January 2026. We establish baseline traffic patterns and identify systematic changes in vehicle density across the monitored region.

</details>


### [24] [MUSE: A Multi-agent Framework for Unconstrained Story Envisioning via Closed-Loop Cognitive Orchestration](https://arxiv.org/abs/2602.03028)
*Wenzhang Sun,Zhenyu Wang,Zhangchi Hu,Chunfeng Wang,Hao Li,Wei Chen*

Main category: cs.CV

TL;DR: 本文提出了MUSE框架，通过多智能体闭环约束执行方法解决长篇幅视听故事生成中的语义漂移和身份一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法（前馈流水线或基于提示的细化）在生成长篇幅故事时存在语义漂移和身份不一致问题，导致用户叙事意图难以在长时间跨度的多模态生成中保持连贯性。

Method: 将叙事过程形式化为闭环约束执行问题，提出MUSE多智能体框架，通过迭代式的“计划-执行-验证-修正”循环来协调生成。该方法将叙事意图转换为机器可执行的标识、空间构图、时间连续性等控制信号，并应用针对性的多模态反馈来修正生成过程中的违规现象。

Result: 在MUSEBench评价协议（基于人类判断的无参考评估）中，MUSE相比代表性基线方法显著提升了长篇幅叙事连贯性、跨模态身份一致性和电影制作质量。

Conclusion: MUSE框架通过闭环约束执行和多智能体协作有效解决了长篇幅视听故事生成中的意图-执行鸿沟问题，为开放叙事生成提供了更可靠的解决方案。

Abstract: Generating long-form audio-visual stories from a short user prompt remains challenging due to an intent-execution gap, where high-level narrative intent must be preserved across coherent, shot-level multimodal generation over long horizons. Existing approaches typically rely on feed-forward pipelines or prompt-only refinement, which often leads to semantic drift and identity inconsistency as sequences grow longer. We address this challenge by formulating storytelling as a closed-loop constraint enforcement problem and propose MUSE, a multi-agent framework that coordinates generation through an iterative plan-execute-verify-revise loop. MUSE translates narrative intent into explicit, machine-executable controls over identity, spatial composition, and temporal continuity, and applies targeted multimodal feedback to correct violations during generation. To evaluate open-ended storytelling without ground-truth references, we introduce MUSEBench, a reference-free evaluation protocol validated by human judgments. Experiments demonstrate that MUSE substantially improves long-horizon narrative coherence, cross-modal identity consistency, and cinematic quality compared with representative baselines.

</details>


### [25] [Bongards at the Boundary of Perception and Reasoning: Programs or Language?](https://arxiv.org/abs/2602.03038)
*Cassidy Langenfeld,Claas Beger,Gloria Geng,Wasu Top Piriyakulkij,Keya Hu,Yewen Pu,Kevin Ellis*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Vision-Language Models (VLMs) have made great strides in everyday visual tasks, such as captioning a natural image, or answering commonsense questions about such images. But humans possess the puzzling ability to deploy their visual reasoning abilities in radically new situations, a skill rigorously tested by the classic set of visual reasoning challenges known as the Bongard problems. We present a neurosymbolic approach to solving these problems: given a hypothesized solution rule for a Bongard problem, we leverage LLMs to generate parameterized programmatic representations for the rule and perform parameter fitting using Bayesian optimization. We evaluate our method on classifying Bongard problem images given the ground truth rule, as well as on solving the problems from scratch.

</details>


### [26] [IVC-Prune: Revealing the Implicit Visual Coordinates in LVLMs for Vision Token Pruning](https://arxiv.org/abs/2602.03060)
*Zhichao Sun,Yidong Ma,Gang Liu,Yibo Chen,Xu Tang,Yao Hu,Yongchao Xu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Vision-Language Models (LVLMs) achieve impressive performance across multiple tasks. A significant challenge, however, is their prohibitive inference cost when processing high-resolution visual inputs. While visual token pruning has emerged as a promising solution, existing methods that primarily focus on semantic relevance often discard tokens that are crucial for spatial reasoning. We address this gap through a novel insight into \emph{how LVLMs process spatial reasoning}. Specifically, we reveal that LVLMs implicitly establish visual coordinate systems through Rotary Position Embeddings (RoPE), where specific token positions serve as \textbf{implicit visual coordinates} (IVC tokens) that are essential for spatial reasoning. Based on this insight, we propose \textbf{IVC-Prune}, a training-free, prompt-aware pruning strategy that retains both IVC tokens and semantically relevant foreground tokens. IVC tokens are identified by theoretically analyzing the mathematical properties of RoPE, targeting positions at which its rotation matrices approximate identity matrix or the $90^\circ$ rotation matrix. Foreground tokens are identified through a robust two-stage process: semantic seed discovery followed by contextual refinement via value-vector similarity. Extensive evaluations across four representative LVLMs and twenty diverse benchmarks show that IVC-Prune reduces visual tokens by approximately 50\% while maintaining $\geq$ 99\% of the original performance and even achieving improvements on several benchmarks. Source codes are available at https://github.com/FireRedTeam/IVC-Prune.

</details>


### [27] [Finding Optimal Video Moment without Training: Gaussian Boundary Optimization for Weakly Supervised Video Grounding](https://arxiv.org/abs/2602.03071)
*Sunoh Kim,Kimin Yun,Daeho Um*

Main category: cs.CV

TL;DR: GBO是一种新颖的推理框架，通过优化问题预测视频片段边界，提升弱监督时序视频定位性能


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯分布的时间提案方法依赖于启发式映射从高斯参数到片段边界，导致定位性能次优。作者提出GBO来解决这一缺陷。

Method: 提出高斯边界优化（GBO）框架，通过解决平衡提案覆盖度和片段紧凑性的优化问题来预测片段边界；推导出封闭解，并分析了不同惩罚机制下的最优性条件；训练免费，兼容单高斯和混合高斯提案架构。

Result: 实验表明GBO显著提升定位性能，在标准基准测试中达到最先进水平；广泛实验证明了GBO在不同提案方案中的高效性和泛化能力。

Conclusion: GBO通过理论严谨的优化框架解决弱监督时序视频定位中的边界预测问题，在实践中表现出色且具有良好泛化性。

Abstract: Weakly supervised temporal video grounding aims to localize query-relevant segments in untrimmed videos using only video-sentence pairs, without requiring ground-truth segment annotations that specify exact temporal boundaries. Recent approaches tackle this task by utilizing Gaussian-based temporal proposals to represent query-relevant segments. However, their inference strategies rely on heuristic mappings from Gaussian parameters to segment boundaries, resulting in suboptimal localization performance. To address this issue, we propose Gaussian Boundary Optimization (GBO), a novel inference framework that predicts segment boundaries by solving a principled optimization problem that balances proposal coverage and segment compactness. We derive a closed-form solution for this problem and rigorously analyze the optimality conditions under varying penalty regimes. Beyond its theoretical foundations, GBO offers several practical advantages: it is training-free and compatible with both single-Gaussian and mixture-based proposal architectures. Our experiments show that GBO significantly improves localization, achieving state-of-the-art results across standard benchmarks. Extensive experiments demonstrate the efficiency and generalizability of GBO across various proposal schemes. The code is available at \href{https://github.com/sunoh-kim/gbo}{https://github.com/sunoh-kim/gbo}.

</details>


### [28] [A generalizable large-scale foundation model for musculoskeletal radiographs](https://arxiv.org/abs/2602.03076)
*Shinn Kim,Soobin Lee,Kyoungseob Shin,Han-Soo Kim,Yongsung Kim,Minsu Kim,Juhong Nam,Somang Ko,Daeheon Kwon,Wook Huh,Ilkyu Han,Sunghoon Kwon*

Main category: cs.CV

TL;DR: 提出了SKELEX，一个基于自监督学习训练的大规模骨科X光片基础模型，在12个下游诊断任务中表现优于基线，并展示了零样本异常定位能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型大多是任务特定、依赖标注、并且在不同疾病和解剖区域的泛化能力有限，临床需要一个在大规模多样化骨科X光片上训练的可泛化基础模型。

Method: 采用自监督学习方法，在120万张多样化、条件丰富的图像上训练SKELEX基础模型，并开发了可解释的区域引导模型用于骨肿瘤预测。

Result: 模型在骨折检测、骨关节炎分级和骨肿瘤分类任务中普遍优于基线，能够进行零样本异常定位，并在独立外部数据集上保持稳健性能。

Conclusion: SKELEX为骨科影像提供了一个可扩展、标签高效且可泛化的AI框架，为临床转化和骨科放射学的数据高效研究奠定了基础。

Abstract: Artificial intelligence (AI) has shown promise in detecting and characterizing musculoskeletal diseases from radiographs. However, most existing models remain task-specific, annotation-dependent, and limited in generalizability across diseases and anatomical regions. Although a generalizable foundation model trained on large-scale musculoskeletal radiographs is clinically needed, publicly available datasets remain limited in size and lack sufficient diversity to enable training across a wide range of musculoskeletal conditions and anatomical sites. Here, we present SKELEX, a large-scale foundation model for musculoskeletal radiographs, trained using self-supervised learning on 1.2 million diverse, condition-rich images. The model was evaluated on 12 downstream diagnostic tasks and generally outperformed baselines in fracture detection, osteoarthritis grading, and bone tumor classification. Furthermore, SKELEX demonstrated zero-shot abnormality localization, producing error maps that identified pathologic regions without task-specific training. Building on this capability, we developed an interpretable, region-guided model for predicting bone tumors, which maintained robust performance on independent external datasets and was deployed as a publicly accessible web application. Overall, SKELEX provides a scalable, label-efficient, and generalizable AI framework for musculoskeletal imaging, establishing a foundation for both clinical translation and data-efficient research in musculoskeletal radiology.

</details>


### [29] [Gromov Wasserstein Optimal Transport for Semantic Correspondences](https://arxiv.org/abs/2602.03105)
*Francis Snelgar,Stephen Gould,Ming Xu,Liang Zheng,Akshay Asthana*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Establishing correspondences between image pairs is a long studied problem in computer vision. With recent large-scale foundation models showing strong zero-shot performance on downstream tasks including classification and segmentation, there has been interest in using the internal feature maps of these models for the semantic correspondence task. Recent works observe that features from DINOv2 and Stable Diffusion (SD) are complementary, the former producing accurate but sparse correspondences, while the latter produces spatially consistent correspondences. As a result, current state-of-the-art methods for semantic correspondence involve combining features from both models in an ensemble. While the performance of these methods is impressive, they are computationally expensive, requiring evaluating feature maps from large-scale foundation models. In this work we take a different approach, instead replacing SD features with a superior matching algorithm which is imbued with the desirable spatial consistency property. Specifically, we replace the standard nearest neighbours matching with an optimal transport algorithm that includes a Gromov Wasserstein spatial smoothness prior. We show that we can significantly boost the performance of the DINOv2 baseline, and be competitive and sometimes surpassing state-of-the-art methods using Stable Diffusion features, while being 5--10x more efficient. We make code available at https://github.com/fsnelgar/semantic_matching_gwot .

</details>


### [30] [Beyond Cropping and Rotation: Automated Evolution of Powerful Task-Specific Augmentations with Generative Models](https://arxiv.org/abs/2602.03123)
*Judah Goldfeder,Shreyes Kaliyur,Vaibhav Sourirajan,Patrick Minwan Puma,Philippe Martin Wyder,Yuhang Hu,Jiong Lin,Hod Lipson*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Data augmentation has long been a cornerstone for reducing overfitting in vision models, with methods like AutoAugment automating the design of task-specific augmentations. Recent advances in generative models, such as conditional diffusion and few-shot NeRFs, offer a new paradigm for data augmentation by synthesizing data with significantly greater diversity and realism. However, unlike traditional augmentations like cropping or rotation, these methods introduce substantial changes that enhance robustness but also risk degrading performance if the augmentations are poorly matched to the task. In this work, we present EvoAug, an automated augmentation learning pipeline, which leverages these generative models alongside an efficient evolutionary algorithm to learn optimal task-specific augmentations. Our pipeline introduces a novel approach to image augmentation that learns stochastic augmentation trees that hierarchically compose augmentations, enabling more structured and adaptive transformations. We demonstrate strong performance across fine-grained classification and few-shot learning tasks. Notably, our pipeline discovers augmentations that align with domain knowledge, even in low-data settings. These results highlight the potential of learned generative augmentations, unlocking new possibilities for robust model training.

</details>


### [31] [Flexible Geometric Guidance for Probabilistic Human Pose Estimation with Diffusion Models](https://arxiv.org/abs/2602.03126)
*Francis Snelgar,Ming Xu,Stephen Gould,Liang Zheng,Akshay Asthana*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: 3D human pose estimation from 2D images is a challenging problem due to depth ambiguity and occlusion. Because of these challenges the task is underdetermined, where there exists multiple -- possibly infinite -- poses that are plausible given the image. Despite this, many prior works assume the existence of a deterministic mapping and estimate a single pose given an image. Furthermore, methods based on machine learning require a large amount of paired 2D-3D data to train and suffer from generalization issues to unseen scenarios. To address both of these issues, we propose a framework for pose estimation using diffusion models, which enables sampling from a probability distribution over plausible poses which are consistent with a 2D image. Our approach falls under the guidance framework for conditional generation, and guides samples from an unconditional diffusion model, trained only on 3D data, using the gradients of the heatmaps from a 2D keypoint detector. We evaluate our method on the Human 3.6M dataset under best-of-$m$ multiple hypothesis evaluation, showing state-of-the-art performance among methods which do not require paired 2D-3D data for training. We additionally evaluate the generalization ability using the MPI-INF-3DHP and 3DPW datasets and demonstrate competitive performance. Finally, we demonstrate the flexibility of our framework by using it for novel tasks including pose generation and pose completion, without the need to train bespoke conditional models. We make code available at https://github.com/fsnelgar/diffusion_pose .

</details>


### [32] [FinMTM: A Multi-Turn Multimodal Benchmark for Financial Reasoning and Agent Evaluation](https://arxiv.org/abs/2602.03130)
*Chenxi Zhang,Ziliang Gan,Liyun Zhu,Youwei Pang,Qing Zhang,Rongjunchen Zhang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The financial domain poses substantial challenges for vision-language models (VLMs) due to specialized chart formats and knowledge-intensive reasoning requirements. However, existing financial benchmarks are largely single-turn and rely on a narrow set of question formats, limiting comprehensive evaluation in realistic application scenarios. To address this gap, we propose FinMTM, a multi-turn multimodal benchmark that expands diversity along both data and task dimensions. On the data side, we curate and annotate 11{,}133 bilingual (Chinese and English) financial QA pairs grounded in financial visuals, including candlestick charts, statistical plots, and report figures. On the task side, FinMTM covers single- and multiple-choice questions, multi-turn open-ended dialogues, and agent-based tasks. We further design task-specific evaluation protocols, including a set-overlap scoring rule for multiple-choice questions, a weighted combination of turn-level and session-level scores for multi-turn dialogues, and a composite metric that integrates planning quality with final outcomes for agent tasks. Extensive experimental evaluation of 22 VLMs reveal their limitations in fine-grained visual perception, long-context reasoning, and complex agent workflows.

</details>


### [33] [SwiftVLM: Efficient Vision-Language Model Inference via Cross-Layer Token Bypass](https://arxiv.org/abs/2602.03134)
*Chen Qian,Xinran Yu,Danyang Li,Guoxuan Chi,Zheng Yang,Qiang Ma,Xin Miao*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Visual token pruning is a promising approach for reducing the computational cost of vision-language models (VLMs), and existing methods often rely on early pruning decisions to improve efficiency. While effective on coarse-grained reasoning tasks, they suffer from significant performance degradation on tasks requiring fine-grained visual details. Through layer-wise analysis, we reveal substantial discrepancies in visual token importance across layers, showing that tokens deemed unimportant at shallow layers can later become highly relevant for text-conditioned reasoning. To avoid irreversible critical information loss caused by premature pruning, we introduce a new pruning paradigm, termed bypass, which preserves unselected visual tokens and forwards them to subsequent pruning stages for re-evaluation. Building on this paradigm, we propose SwiftVLM, a simple and training-free method that performs pruning at model-specific layers with strong visual token selection capability, while enabling independent pruning decisions across layers. Experiments across multiple VLMs and benchmarks demonstrate that SwiftVLM consistently outperforms existing pruning strategies, achieving superior accuracy-efficiency trade-offs and more faithful visual token selection behavior.

</details>


### [34] [FSOD-VFM: Few-Shot Object Detection with Vision Foundation Models and Graph Diffusion](https://arxiv.org/abs/2602.03137)
*Chen-Bin Feng,Youyang Sha,Longfei Liu,Yongjun Yu,Chi Man Vong,Xuanlong Yu,Xi Shen*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we present FSOD-VFM: Few-Shot Object Detectors with Vision Foundation Models, a framework that leverages vision foundation models to tackle the challenge of few-shot object detection. FSOD-VFM integrates three key components: a universal proposal network (UPN) for category-agnostic bounding box generation, SAM2 for accurate mask extraction, and DINOv2 features for efficient adaptation to new object categories. Despite the strong generalization capabilities of foundation models, the bounding boxes generated by UPN often suffer from overfragmentation, covering only partial object regions and leading to numerous small, false-positive proposals rather than accurate, complete object detections. To address this issue, we introduce a novel graph-based confidence reweighting method. In our approach, predicted bounding boxes are modeled as nodes in a directed graph, with graph diffusion operations applied to propagate confidence scores across the network. This reweighting process refines the scores of proposals, assigning higher confidence to whole objects and lower confidence to local, fragmented parts. This strategy improves detection granularity and effectively reduces the occurrence of false-positive bounding box proposals. Through extensive experiments on Pascal-5$^i$, COCO-20$^i$, and CD-FSOD datasets, we demonstrate that our method substantially outperforms existing approaches, achieving superior performance without requiring additional training. Notably, on the challenging CD-FSOD dataset, which spans multiple datasets and domains, our FSOD-VFM achieves 31.6 AP in the 10-shot setting, substantially outperforming previous training-free methods that reach only 21.4 AP. Code is available at: https://intellindust-ai-lab.github.io/projects/FSOD-VFM.

</details>


### [35] [Diversity-Preserved Distribution Matching Distillation for Fast Visual Synthesis](https://arxiv.org/abs/2602.03139)
*Tianhe Wu,Ruibin Li,Lei Zhang,Kede Ma*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Distribution matching distillation (DMD) aligns a multi-step generator with its few-step counterpart to enable high-quality generation under low inference cost. However, DMD tends to suffer from mode collapse, as its reverse-KL formulation inherently encourages mode-seeking behavior, for which existing remedies typically rely on perceptual or adversarial regularization, thereby incurring substantial computational overhead and training instability. In this work, we propose a role-separated distillation framework that explicitly disentangles the roles of distilled steps: the first step is dedicated to preserving sample diversity via a target-prediction (e.g., v-prediction) objective, while subsequent steps focus on quality refinement under the standard DMD loss, with gradients from the DMD objective blocked at the first step. We term this approach Diversity-Preserved DMD (DP-DMD), which, despite its simplicity -- no perceptual backbone, no discriminator, no auxiliary networks, and no additional ground-truth images -- preserves sample diversity while maintaining visual quality on par with state-of-the-art methods in extensive text-to-image experiments.

</details>


### [36] [Fully Kolmogorov-Arnold Deep Model in Medical Image Segmentation](https://arxiv.org/abs/2602.03156)
*Xingyu Qiu,Xinghua Ma,Dong Liang,Gongning Luo,Wei Wang,Kuanquan Wang,Shuo Li*

Main category: cs.CV

TL;DR: 该研究提出了首个完全基于Kolmogorov-Arnold（KA）的深度学习模型，通过Share-activation KAN和Grad-Free Spline等技术突破深度KAN堆叠的难题，显著降低了参数数量和内存消耗，在医学图像分割任务中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度堆叠KAN存在训练困难、内存需求大等问题，导致只能使用少数KAN层，限制了KAN架构的深入探索。本研究旨在克服这些限制，实现完全基于KA层的深度模型。

Method: 1) 提出Share-activation KAN（SaKAN），基于Sprecher变体的Kolmogorov-Arnold表示定理，简化参数化并增加训练样本密度；2) 发现样条梯度对训练贡献微小但消耗大量GPU内存，提出Grad-Free Spline减少内存和计算开销；3) 基于这些创新构建ALL U-KAN模型，用KA和KAonv层完全替代传统FC和Conv层。

Result: 在三个医学图像分割任务上，完全KA架构相比部分KA架构和传统架构都取得了更高的分割精度。相比直接深度堆叠KAN，ALL U-KAN参数数量减少10倍，内存消耗降低20倍以上。

Conclusion: 研究成功突破了深度KAN的实际应用障碍，证明了KA层能够完全替代传统深度学习架构，展示了深度KAN模型在医学图像分割等任务中的优越学习能力和应用潜力。

Abstract: Deeply stacked KANs are practically impossible due to high training difficulties and substantial memory requirements. Consequently, existing studies can only incorporate few KAN layers, hindering the comprehensive exploration of KANs. This study overcomes these limitations and introduces the first fully KA-based deep model, demonstrating that KA-based layers can entirely replace traditional architectures in deep learning and achieve superior learning capacity. Specifically, (1) the proposed Share-activation KAN (SaKAN) reformulates Sprecher's variant of Kolmogorov-Arnold representation theorem, which achieves better optimization due to its simplified parameterization and denser training samples, to ease training difficulty, (2) this paper indicates that spline gradients contribute negligibly to training while consuming huge GPU memory, thus proposes the Grad-Free Spline to significantly reduce memory usage and computational overhead. (3) Building on these two innovations, our ALL U-KAN is the first representative implementation of fully KA-based deep model, where the proposed KA and KAonv layers completely replace FC and Conv layers. Extensive evaluations on three medical image segmentation tasks confirm the superiority of the full KA-based architecture compared to partial KA-based and traditional architectures, achieving all higher segmentation accuracy. Compared to directly deeply stacked KAN, ALL U-KAN achieves 10 times reduction in parameter count and reduces memory consumption by more than 20 times, unlocking the new explorations into deep KAN architectures.

</details>


### [37] [Human-in-the-loop Adaptation in Group Activity Feature Learning for Team Sports Video Retrieval](https://arxiv.org/abs/2602.03157)
*Chihiro Nakatani,Hiroaki Kawashima,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出无需群体活动标注的人类参与循环适配方法，用于改进群体活动视频检索框架的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的群体活动学习方法需要预定义的群体活动类别和监督学习，限制了其适用性。本文旨在通过自监督学习和人类参与循环来减少对标注的依赖，同时提升视频检索的准确性。

Method: 1. 基于群体活动相似性以自监督方式预训练群体活动特征空间；2. 通过人类参与循环进行交互式微调，包括数据高效视频选择过程，让用户手动标注正负样本；3. 使用对比学习更新特征空间，使正样本靠近查询视频，负样本远离。

Result: 在两个团队运动数据集上的实验结果表明，该方法显著提升了检索性能。消融研究证实了人类参与循环适配中多个组件的有效性。

Conclusion: 本文提出的无标注人类参与循环适配方法能有效改进群体活动视频检索性能，通过自监督预训练和交互式微调实现了对群体活动特征的更好学习。

Abstract: This paper proposes human-in-the-loop adaptation for Group Activity Feature Learning (GAFL) without group activity annotations. This human-in-the-loop adaptation is employed in a group-activity video retrieval framework to improve its retrieval performance. Our method initially pre-trains the GAF space based on the similarity of group activities in a self-supervised manner, unlike prior work that classifies videos into pre-defined group activity classes in a supervised learning manner. Our interactive fine-tuning process updates the GAF space to allow a user to better retrieve videos similar to query videos given by the user. In this fine-tuning, our proposed data-efficient video selection process provides several videos, which are selected from a video database, to the user in order to manually label these videos as positive or negative. These labeled videos are used to update (i.e., fine-tune) the GAF space, so that the positive and negative videos move closer to and farther away from the query videos through contrastive learning. Our comprehensive experimental results on two team sports datasets validate that our method significantly improves the retrieval performance. Ablation studies also demonstrate that several components in our human-in-the-loop adaptation contribute to the improvement of the retrieval performance. Code: https://github.com/chihina/GAFL-FINE-CVIU.

</details>


### [38] [BinaryDemoire: Moiré-Aware Binarization for Image Demoiréing](https://arxiv.org/abs/2602.03176)
*Zheng Chen,Zhi Yang,Xiaoyang Liu,Weihang Zhang,Mengfan Wang,Yifan Fu,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Image demoiréing aims to remove structured moiré artifacts in recaptured imagery, where degradations are highly frequency-dependent and vary across scales and directions. While recent deep networks achieve high-quality restoration, their full-precision designs remain costly for deployment. Binarization offers an extreme compression regime by quantizing both activations and weights to 1-bit. Yet, it has been rarely studied for demoiréing and performs poorly when naively applied. In this work, we propose BinaryDemoire, a binarized demoiréing framework that explicitly accommodates the frequency structure of moiré degradations. First, we introduce a moiré-aware binary gate (MABG) that extracts lightweight frequency descriptors together with activation statistics. It predicts channel-wise gating coefficients to condition the aggregation of binary convolution responses. Second, we design a shuffle-grouped residual adapter (SGRA) that performs structured sparse shortcut alignment. It further integrates interleaved mixing to promote information exchange across different channel partitions. Extensive experiments on four benchmarks demonstrate that the proposed BinaryDemoire surpasses current binarization methods. Code: https://github.com/zhengchen1999/BinaryDemoire.

</details>


### [39] [LSGQuant: Layer-Sensitivity Guided Quantization for One-Step Diffusion Real-World Video Super-Resolution](https://arxiv.org/abs/2602.03182)
*Tianxing Wu,Zheng Chen,Cirou Xu,Bowen Chai,Yong Guo,Yutong Liu,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: One-Step Diffusion Models have demonstrated promising capability and fast inference in video super-resolution (VSR) for real-world. Nevertheless, the substantial model size and high computational cost of Diffusion Transformers (DiTs) limit downstream applications. While low-bit quantization is a common approach for model compression, the effectiveness of quantized models is challenged by the high dynamic range of input latent and diverse layer behaviors. To deal with these challenges, we introduce LSGQuant, a layer-sensitivity guided quantizing approach for one-step diffusion-based real-world VSR. Our method incorporates a Dynamic Range Adaptive Quantizer (DRAQ) to fit video token activations. Furthermore, we estimate layer sensitivity and implement a Variance-Oriented Layer Training Strategy (VOLTS) by analyzing layer-wise statistics in calibration. We also introduce Quantization-Aware Optimization (QAO) to jointly refine the quantized branch and a retained high-precision branch. Extensive experiments demonstrate that our method has nearly performance to origin model with full-precision and significantly exceeds existing quantization techniques. Code is available at: https://github.com/zhengchen1999/LSGQuant.

</details>


### [40] [From Single Scan to Sequential Consistency: A New Paradigm for LIDAR Relocalization](https://arxiv.org/abs/2602.03198)
*Minghang Zhu,Zhijing Wang,Yuxin Guo,Wen Li,Sheng Ao,Cheng Wang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: LiDAR relocalization aims to estimate the global 6-DoF pose of a sensor in the environment. However, existing regression-based approaches are prone to dynamic or ambiguous scenarios, as they either solely rely on single-frame inference or neglect the spatio-temporal consistency across scans. In this paper, we propose TempLoc, a new LiDAR relocalization framework that enhances the robustness of localization by effectively modeling sequential consistency. Specifically, a Global Coordinate Estimation module is first introduced to predict point-wise global coordinates and associated uncertainties for each LiDAR scan. A Prior Coordinate Generation module is then presented to estimate inter-frame point correspondences by the attention mechanism. Lastly, an Uncertainty-Guided Coordinate Fusion module is deployed to integrate both predictions of point correspondence in an end-to-end fashion, yielding a more temporally consistent and accurate global 6-DoF pose. Experimental results on the NCLT and Oxford Robot-Car benchmarks show that our TempLoc outperforms stateof-the-art methods by a large margin, demonstrating the effectiveness of temporal-aware correspondence modeling in LiDAR relocalization. Our code will be released soon.

</details>


### [41] [Hand3R: Online 4D Hand-Scene Reconstruction in the Wild](https://arxiv.org/abs/2602.03200)
*Wendi Hu,Haonan Zhou,Wenhao Hu,Gaoang Wang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: For Embodied AI, jointly reconstructing dynamic hands and the dense scene context is crucial for understanding physical interaction. However, most existing methods recover isolated hands in local coordinates, overlooking the surrounding 3D environment. To address this, we present Hand3R, the first online framework for joint 4D hand-scene reconstruction from monocular video. Hand3R synergizes a pre-trained hand expert with a 4D scene foundation model via a scene-aware visual prompting mechanism. By injecting high-fidelity hand priors into a persistent scene memory, our approach enables simultaneous reconstruction of accurate hand meshes and dense metric-scale scene geometry in a single forward pass. Experiments demonstrate that Hand3R bypasses the reliance on offline optimization and delivers competitive performance in both local hand reconstruction and global positioning.

</details>


### [42] [VIRAL: Visual In-Context Reasoning via Analogy in Diffusion Transformers](https://arxiv.org/abs/2602.03210)
*Zhiwen Li,Zhongjie Duan,Jinyan Ye,Cen Chen,Daoyuan Chen,Yaliang Li,Yingda Chen*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Replicating In-Context Learning (ICL) in computer vision remains challenging due to task heterogeneity. We propose \textbf{VIRAL}, a framework that elicits visual reasoning from a pre-trained image editing model by formulating ICL as conditional generation via visual analogy ($x_s : x_t :: x_q : y_q$). We adapt a frozen Diffusion Transformer (DiT) using role-aware multi-image conditioning and introduce a Mixture-of-Experts LoRA to mitigate gradient interference across diverse tasks. Additionally, to bridge the gaps in current visual context datasets, we curate a large-scale dataset spanning perception, restoration, and editing. Experiments demonstrate that VIRAL outperforms existing methods, validating that a unified V-ICL paradigm can handle the majority of visual tasks, including open-domain editing. Our code is available at https://anonymous.4open.science/r/VIRAL-744A

</details>


### [43] [ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask](https://arxiv.org/abs/2602.03213)
*Zhuoran Yang,Yanyong Zhang*

Main category: cs.CV

TL;DR: 提出ConsisDrive模型来解决自动驾驶世界模型中身份漂移问题，提升驾驶视频生成质量


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶世界模型虽然在生成驾驶数据上具有成本效益，但存在身份漂移问题——同一对象在不同帧中会改变外观或类别，主要原因是没有实例级的时间一致性约束

Method: 1. 实例掩码注意力机制：将实例身份掩码和轨迹掩码应用于注意力模块，确保视觉tokens只与对应的实例特征在空间和时间维度上交互；2. 实例掩码损失函数：通过概率性实例掩码自适应地强调前景区域，减少背景噪声的同时保持场景保真度

Result: 在nuScenes数据集上，ConsisDrive实现了最先进的驾驶视频生成质量，并在下游自动驾驶任务中展现出显著改进

Conclusion: ConsisDrive通过实例级时态一致性约束有效解决了身份漂移问题，为自动驾驶模型提供了高质量、时间一致的驾驶视频生成方案

Abstract: Autonomous driving relies on robust models trained on large-scale, high-quality multi-view driving videos. Although world models provide a cost-effective solution for generating realistic driving data, they often suffer from identity drift, where the same object changes its appearance or category across frames due to the absence of instance-level temporal constraints. We introduce ConsisDrive, an identity-preserving driving world model designed to enforce temporal consistency at the instance level. Our framework incorporates two key components: (1) Instance-Masked Attention, which applies instance identity masks and trajectory masks within attention blocks to ensure that visual tokens interact only with their corresponding instance features across spatial and temporal dimensions, thereby preserving object identity consistency; and (2) Instance-Masked Loss, which adaptively emphasizes foreground regions with probabilistic instance masking, reducing background noise while maintaining overall scene fidelity. By integrating these mechanisms, ConsisDrive achieves state-of-the-art driving video generation quality and demonstrates significant improvements in downstream autonomous driving tasks on the nuScenes dataset. Our project page is https://shanpoyang654.github.io/ConsisDrive/page.html.

</details>


### [44] [FARTrack: Fast Autoregressive Visual Tracking with High Performance](https://arxiv.org/abs/2602.03214)
*Guijie Wang,Tong Lin,Yifan Bai,Anjia Cao,Shiyi Liang,Wangbo Zhao,Xing Wei*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Inference speed and tracking performance are two critical evaluation metrics in the field of visual tracking. However, high-performance trackers often suffer from slow processing speeds, making them impractical for deployment on resource-constrained devices. To alleviate this issue, we propose FARTrack, a Fast Auto-Regressive Tracking framework. Since autoregression emphasizes the temporal nature of the trajectory sequence, it can maintain high performance while achieving efficient execution across various devices. FARTrack introduces Task-Specific Self-Distillation and Inter-frame Autoregressive Sparsification, designed from the perspectives of shallow-yet-accurate distillation and redundant-to-essential token optimization, respectively. Task-Specific Self-Distillation achieves model compression by distilling task-specific tokens layer by layer, enhancing the model's inference speed while avoiding suboptimal manual teacher-student layer pairs assignments. Meanwhile, Inter-frame Autoregressive Sparsification sequentially condenses multiple templates, avoiding additional runtime overhead while learning a temporally-global optimal sparsification strategy. FARTrack demonstrates outstanding speed and competitive performance. It delivers an AO of 70.6% on GOT-10k in real-time. Beyond, our fastest model achieves a speed of 343 FPS on the GPU and 121 FPS on the CPU.

</details>


### [45] [PokeFusion Attention: Enhancing Reference-Free Style-Conditioned Generation](https://arxiv.org/abs/2602.03220)
*Jingbang Tang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper studies reference-free style-conditioned character generation in text-to-image diffusion models, where high-quality synthesis requires both stable character structure and consistent, fine-grained style expression across diverse prompts. Existing approaches primarily rely on text-only prompting, which is often under-specified for visual style and tends to produce noticeable style drift and geometric inconsistency, or introduce reference-based adapters that depend on external images at inference time, increasing architectural complexity and limiting deployment flexibility.We propose PokeFusion Attention, a lightweight decoder-level cross-attention mechanism that fuses textual semantics with learned style embeddings directly inside the diffusion decoder. By decoupling text and style conditioning at the attention level, our method enables effective reference-free stylized generation while keeping the pretrained diffusion backbone fully frozen.PokeFusion Attention trains only decoder cross-attention layers together with a compact style projection module, resulting in a parameter-efficient and plug-and-play control component that can be easily integrated into existing diffusion pipelines and transferred across different backbones.Experiments on a stylized character generation benchmark (Pokemon-style) demonstrate that our method consistently improves style fidelity, semantic alignment, and character shape consistency compared with representative adapter-based baselines, while maintaining low parameter overhead and inference-time simplicity.

</details>


### [46] [Spiral RoPE: Rotate Your Rotary Positional Embeddings in the 2D Plane](https://arxiv.org/abs/2602.03227)
*Haoyu Liu,Sucheng Ren,Tingyu Zhu,Peng Wang,Cihang Xie,Alan Yuille,Zeyu Zheng,Feng Wang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Rotary Position Embedding (RoPE) is the de facto positional encoding in large language models due to its ability to encode relative positions and support length extrapolation. When adapted to vision transformers, the standard axial formulation decomposes two-dimensional spatial positions into horizontal and vertical components, implicitly restricting positional encoding to axis-aligned directions. We identify this directional constraint as a fundamental limitation of the standard axial 2D RoPE, which hinders the modeling of oblique spatial relationships that naturally exist in natural images. To overcome this limitation, we propose Spiral RoPE, a simple yet effective extension that enables multi-directional positional encoding by partitioning embedding channels into multiple groups associated with uniformly distributed directions. Each group is rotated according to the projection of the patch position onto its corresponding direction, allowing spatial relationships to be encoded beyond the horizontal and vertical axes. Across a wide range of vision tasks including classification, segmentation, and generation, Spiral RoPE consistently improves performance. Qualitative analysis of attention maps further show that Spiral RoPE exhibits more concentrated activations on semantically relevant objects and better respects local object boundaries, highlighting the importance of multi-directional positional encoding in vision transformers.

</details>


### [47] [EventFlash: Towards Efficient MLLMs for Event-Based Vision](https://arxiv.org/abs/2602.03230)
*Shaoyu Liu,Jianing Li,Guanghui Zhao,Yunjian Zhang,Wen Jiang,Ming Li,Xiangyang Ji*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Event-based multimodal large language models (MLLMs) enable robust perception in high-speed and low-light scenarios, addressing key limitations of frame-based MLLMs. However, current event-based MLLMs often rely on dense image-like processing paradigms, overlooking the spatiotemporal sparsity of event streams and resulting in high computational cost. In this paper, we propose EventFlash, a novel and efficient MLLM to explore spatiotemporal token sparsification for reducing data redundancy and accelerating inference. Technically, we build EventMind, a large-scale and scene-diverse dataset with over 500k instruction sets, providing both short and long event stream sequences to support our curriculum training strategy. We then present an adaptive temporal window aggregation module for efficient temporal sampling, which adaptively compresses temporal tokens while retaining key temporal cues. Finally, a sparse density-guided attention module is designed to improve spatial token efficiency by selecting informative regions and suppressing empty or sparse areas. Experimental results show that EventFlash achieves a $12.4\times$ throughput improvement over the baseline (EventFlash-Zero) while maintaining comparable performance. It supports long-range event stream processing with up to 1,000 bins, significantly outperforming the 5-bin limit of EventGPT. We believe EventFlash serves as an efficient foundation model for event-based vision.

</details>


### [48] [InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation](https://arxiv.org/abs/2602.03242)
*Zhuoran Yang,Xi Guo,Chenjing Ding,Chiyu Wang,Wei Wu,Yanyong Zhang*

Main category: cs.CV

TL;DR: 本文提出了InstaDrive框架，通过实例流引导和空间几何对齐机制改进驾驶视频生成，提升时序一致性和空间几何保真度，并在nuScenes数据集上达到SOTA性能，同时利用CARLA模拟器进行安全评估。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶模型依赖大规模多视角驾驶视频数据，但现有世界模型在生成视频时难以保持实例级的时序一致性和空间几何保真度，这影响了生成的驾驶视频的真实性和下游任务性能。

Method: 提出InstaDrive框架，包含两个核心模块：(1) 实例流引导器 - 提取和传播实例特征以增强时序一致性；(2) 空间几何对齐器 - 改进空间推理，确保实例精确定位并建模遮挡层次结构。此外，利用CARLA自动驾驶系统程序化和随机生成罕见但安全关键的驾驶场景进行安全评估。

Result: 在nuScenes数据集上，InstaDrive在视频生成质量方面达到SOTA性能，并有效提升了下游自动驾驶任务的性能。通过CARLA模拟器能够系统性地评估自动驾驶系统的安全性。

Conclusion: InstaDrive通过显式建模实例级时序一致性和空间几何关系，显著提升了驾驶视频生成的真实性，为自动驾驶模型训练提供了更高质量的数据，并通过程序化场景生成支持了安全评估框架的发展。

Abstract: Autonomous driving relies on robust models trained on high-quality, large-scale multi-view driving videos. While world models offer a cost-effective solution for generating realistic driving videos, they struggle to maintain instance-level temporal consistency and spatial geometric fidelity. To address these challenges, we propose InstaDrive, a novel framework that enhances driving video realism through two key advancements: (1) Instance Flow Guider, which extracts and propagates instance features across frames to enforce temporal consistency, preserving instance identity over time. (2) Spatial Geometric Aligner, which improves spatial reasoning, ensures precise instance positioning, and explicitly models occlusion hierarchies. By incorporating these instance-aware mechanisms, InstaDrive achieves state-of-the-art video generation quality and enhances downstream autonomous driving tasks on the nuScenes dataset. Additionally, we utilize CARLA's autopilot to procedurally and stochastically simulate rare but safety-critical driving scenarios across diverse maps and regions, enabling rigorous safety evaluation for autonomous systems. Our project page is https://shanpoyang654.github.io/InstaDrive/page.html.

</details>


### [49] [LaVPR: Benchmarking Language and Vision for Place Recognition](https://arxiv.org/abs/2602.03253)
*Ofer Idan,Dan Badur,Yosi Keller,Yoli Shavit*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Visual Place Recognition (VPR) often fails under extreme environmental changes and perceptual aliasing. Furthermore, standard systems cannot perform "blind" localization from verbal descriptions alone, a capability needed for applications such as emergency response. To address these challenges, we introduce LaVPR, a large-scale benchmark that extends existing VPR datasets with over 650,000 rich natural-language descriptions. Using LaVPR, we investigate two paradigms: Multi-Modal Fusion for enhanced robustness and Cross-Modal Retrieval for language-based localization. Our results show that language descriptions yield consistent gains in visually degraded conditions, with the most significant impact on smaller backbones. Notably, adding language allows compact models to rival the performance of much larger vision-only architectures. For cross-modal retrieval, we establish a baseline using Low-Rank Adaptation (LoRA) and Multi-Similarity loss, which substantially outperforms standard contrastive methods across vision-language models. Ultimately, LaVPR enables a new class of localization systems that are both resilient to real-world stochasticity and practical for resource-constrained deployment. Our dataset and code are available at https://github.com/oferidan1/LaVPR.

</details>


### [50] [Global Geometry Is Not Enough for Vision Representations](https://arxiv.org/abs/2602.03282)
*Jiwan Chung,Seon Joo Kim*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A common assumption in representation learning is that globally well-distributed embeddings support robust and generalizable representations. This focus has shaped both training objectives and evaluation protocols, implicitly treating global geometry as a proxy for representational competence. While global geometry effectively encodes which elements are present, it is often insensitive to how they are composed. We investigate this limitation by testing the ability of geometric metrics to predict compositional binding across 21 vision encoders. We find that standard geometry-based statistics exhibit near-zero correlation with compositional binding. In contrast, functional sensitivity, as measured by the input-output Jacobian, reliably tracks this capability. We further provide an analytic account showing that this disparity arises from objective design, as existing losses explicitly constrain embedding geometry but leave the local input-output mapping unconstrained. These results suggest that global embedding geometry captures only a partial view of representational competence and establish functional sensitivity as a critical complementary axis for modeling composite structure.

</details>


### [51] [A3-TTA: Adaptive Anchor Alignment Test-Time Adaptation for Image Segmentation](https://arxiv.org/abs/2602.03292)
*Jianghao Wu,Xiangde Luo,Yubo Zhou,Lianming Wu,Guotai Wang,Shaoting Zhang*

Main category: cs.CV

TL;DR: A3-TTA是一种用于医学图像分割的无源数据测试时自适应框架，通过锚点引导的伪标签生成克服现有方法中的分布不确定性和训练不稳定问题，在心脏和前列腺分割等任务上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 当前的测试时自适应方法，特别是基于伪标签的方法，通常依赖扰动集成启发式策略，这些方法缺乏分布理论基础，产生不稳定的训练信号，可能导致错误累积和灾难性遗忘

Method: 提出A3-TTA框架，使用类别紧凑密度度量识别源域分布相近的置信度高的目标域图像作为锚点，以锚点作为稳定参考进行伪标签生成，同时引入语义一致性和边界感知熵最小化正则化，以及自适应指数移动平均策略来减少标签噪声

Result: 在多域医学图像和自然图像分割任务上，A3-TTA将平均Dice分数提升了10.40-17.68个百分点，优于多种SOTA方法，在连续TTA场景下也表现出色，具有强大的抗遗忘能力

Conclusion: A3-TTA通过锚点引导监督构建可靠的伪标签，有效解决了测试时自适应中的训练信号不稳定问题，在多个分割任务和模型架构上取得了显著的性能提升，同时具备良好的抗遗忘能力

Abstract: Test-Time Adaptation (TTA) offers a practical solution for deploying image segmentation models under domain shift without accessing source data or retraining. Among existing TTA strategies, pseudo-label-based methods have shown promising performance. However, they often rely on perturbation-ensemble heuristics (e.g., dropout sampling, test-time augmentation, Gaussian noise), which lack distributional grounding and yield unstable training signals. This can trigger error accumulation and catastrophic forgetting during adaptation. To address this, we propose \textbf{A3-TTA}, a TTA framework that constructs reliable pseudo-labels through anchor-guided supervision. Specifically, we identify well-predicted target domain images using a class compact density metric, under the assumption that confident predictions imply distributional proximity to the source domain. These anchors serve as stable references to guide pseudo-label generation, which is further regularized via semantic consistency and boundary-aware entropy minimization. Additionally, we introduce a self-adaptive exponential moving average strategy to mitigate label noise and stabilize model update during adaptation. Evaluated on both multi-domain medical images (heart structure and prostate segmentation) and natural images, A3-TTA significantly improves average Dice scores by 10.40 to 17.68 percentage points compared to the source model, outperforming several state-of-the-art TTA methods under different segmentation model architectures. A3-TTA also excels in continual TTA, maintaining high performance across sequential target domains with strong anti-forgetting ability. The code will be made publicly available at https://github.com/HiLab-git/A3-TTA.

</details>


### [52] [Full end-to-end diagnostic workflow automation of 3D OCT via foundation model-driven AI for retinal diseases](https://arxiv.org/abs/2602.03302)
*Jinze Zhang,Jian Zhong,Li Lin,Jiaxiong Li,Ke Ma,Naiyang Li,Meng Li,Yuan Pan,Zeyu Meng,Mengyun Zhou,Shang Huang,Shilong Yu,Zhengyu Duan,Sutong Li,Honghui Xia,Juping Liu,Dan Liang,Yantao Wei,Xiaoying Tang,Jin Yuan,Peng Xiao*

Main category: cs.CV

TL;DR: FOCUS是一个基于基础模型的端到端3D OCT视网膜疾病诊断系统，通过统一的适应性聚合方法实现了从图像质量评估到多疾病分类的自动化诊断流程。


<details>
  <summary>Details</summary>
Motivation: 虽然OCT在视网膜疾病诊断中具有高分辨率3D成像优势，但其在临床实践中的全自动诊断仍受限于多阶段工作流程和传统的单切片单任务AI模型，需要开发更高效的端到端解决方案。

Method: FOCUS采用EfficientNetV2-S进行图像质量评估，然后使用微调的视觉基础模型进行异常检测和多疾病分类，创新性地采用统一自适应聚合方法将2D切片级预测智能整合成全面的3D患者级诊断。

Result: 在3,300名患者数据集上训练测试，并在四个不同层级医疗中心的1,345名患者外部验证中，FOCUS在质量评估、异常检测和患者级诊断方面分别获得99.01%、97.46%和94.39%的F1分数，实际验证表现稳定，在异常检测和多疾病诊断方面与专家表现相当且效率更高。

Conclusion: FOCUS实现了从图像到诊断的管道自动化，代表了无人值守眼科的重要进展，为增强人群规模视网膜护理可及性和效率的自筛查提供了验证蓝图。

Abstract: Optical coherence tomography (OCT) has revolutionized retinal disease diagnosis with its high-resolution and three-dimensional imaging nature, yet its full diagnostic automation in clinical practices remains constrained by multi-stage workflows and conventional single-slice single-task AI models. We present Full-process OCT-based Clinical Utility System (FOCUS), a foundation model-driven framework enabling end-to-end automation of 3D OCT retinal disease diagnosis. FOCUS sequentially performs image quality assessment with EfficientNetV2-S, followed by abnormality detection and multi-disease classification using a fine-tuned Vision Foundation Model. Crucially, FOCUS leverages a unified adaptive aggregation method to intelligently integrate 2D slices-level predictions into comprehensive 3D patient-level diagnosis. Trained and tested on 3,300 patients (40,672 slices), and externally validated on 1,345 patients (18,498 slices) across four different-tier centers and diverse OCT devices, FOCUS achieved high F1 scores for quality assessment (99.01%), abnormally detection (97.46%), and patient-level diagnosis (94.39%). Real-world validation across centers also showed stable performance (F1: 90.22%-95.24%). In human-machine comparisons, FOCUS matched expert performance in abnormality detection (F1: 95.47% vs 90.91%) and multi-disease diagnosis (F1: 93.49% vs 91.35%), while demonstrating better efficiency. FOCUS automates the image-to-diagnosis pipeline, representing a critical advance towards unmanned ophthalmology with a validated blueprint for autonomous screening to enhance population scale retinal care accessibility and efficiency.

</details>


### [53] [Invisible Clean-Label Backdoor Attacks for Generative Data Augmentation](https://arxiv.org/abs/2602.03316)
*Ting Xiang,Jinhui Zhao,Changjian Chen,Zhuo Tang*

Main category: cs.CV

TL;DR: 提出一种基于潜在特征扰动的不可见干净标签后门攻击方法InvLBA，针对生成式数据增强场景，相比现有像素级攻击方法大幅提升成功率。


<details>
  <summary>Details</summary>
Motivation: 现有像素级干净标签后门攻击方法（如COMBAT）直接应用于生成图像时攻击成功率低，需要超越像素级触发器的潜在特征层面攻击方法。

Method: 设计InvLBA方法，在潜在特征层面对生成图像进行扰动，实现不可见的干净标签后门攻击，并通过理论分析保证其通用性。

Result: 在多个数据集上实验，攻击成功率平均提升46.43%，清洁准确率几乎没有下降，对SOTA防御方法具有高鲁棒性。

Conclusion: 潜在特征层面的后门攻击比像素级攻击更有效，InvLBA方法为生成式数据增强场景提供了强大的后门攻击能力。

Abstract: With the rapid advancement of image generative models, generative data augmentation has become an effective way to enrich training images, especially when only small-scale datasets are available. At the same time, in practical applications, generative data augmentation can be vulnerable to clean-label backdoor attacks, which aim to bypass human inspection. However, based on theoretical analysis and preliminary experiments, we observe that directly applying existing pixel-level clean-label backdoor attack methods (e.g., COMBAT) to generated images results in low attack success rates. This motivates us to move beyond pixel-level triggers and focus instead on the latent feature level. To this end, we propose InvLBA, an invisible clean-label backdoor attack method for generative data augmentation by latent perturbation. We theoretically prove that the generalization of the clean accuracy and attack success rates of InvLBA can be guaranteed. Experiments on multiple datasets show that our method improves the attack success rate by 46.43% on average, with almost no reduction in clean accuracy and high robustness against SOTA defense methods.

</details>


### [54] [MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning](https://arxiv.org/abs/2602.03320)
*Shengyuan Liu,Liuxin Bao,Qi Yang,Wanting Geng,Boyun Zheng,Chenxin Li,Wenting Chen,Houwen Peng,Yixuan Yuan*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Medical image segmentation is evolving from task-specific models toward generalizable frameworks. Recent research leverages Multi-modal Large Language Models (MLLMs) as autonomous agents, employing reinforcement learning with verifiable reward (RLVR) to orchestrate specialized tools like the Segment Anything Model (SAM). However, these approaches often rely on single-turn, rigid interaction strategies and lack process-level supervision during training, which hinders their ability to fully exploit the dynamic potential of interactive tools and leads to redundant actions. To bridge this gap, we propose MedSAM-Agent, a framework that reformulates interactive segmentation as a multi-step autonomous decision-making process. First, we introduce a hybrid prompting strategy for expert-curated trajectory generation, enabling the model to internalize human-like decision heuristics and adaptive refinement strategies. Furthermore, we develop a two-stage training pipeline that integrates multi-turn, end-to-end outcome verification with a clinical-fidelity process reward design to promote interaction parsimony and decision efficiency. Extensive experiments across 6 medical modalities and 21 datasets demonstrate that MedSAM-Agent achieves state-of-the-art performance, effectively unifying autonomous medical reasoning with robust, iterative optimization. Code is available \href{https://github.com/CUHK-AIM-Group/MedSAM-Agent}{here}.

</details>


### [55] [PWAVEP: Purifying Imperceptible Adversarial Perturbations in 3D Point Clouds via Spectral Graph Wavelets](https://arxiv.org/abs/2602.03333)
*Haoran Li,Renyang Liu,Hongjia Liu,Chen Wang,Long Yin,Jian Xu*

Main category: cs.CV

TL;DR: 针对3D点云对抗攻击的防御方法，提出了无需侵入模型修改的非侵入式频谱域净化框架PWAVEP


<details>
  <summary>Details</summary>
Motivation: 目前3D点云对抗攻击在空间不可感知性和高攻击性能方面进展显著，而现有防御方法大多需要侵入式模型修改、昂贵训练过程或辅助数据访问，防御效果有限

Method: 基于对抗扰动与高频频谱分量关系的理论分析，提出PWAVEP净化框架：1)计算频谱图小波域显著性和局部稀疏性得分；2)采用分层策略消除最显著点（难恢复的对抗离群点）；3)对中等显著性点应用频谱过滤，通过图小波变换衰减目标点的高频系数以抑制对抗噪声

Result: 大量评估表明PWAVEP在准确性和鲁棒性方面优于现有方法，推进了3D点云净化的最新水平

Conclusion: PWAVEP是一种即插即用、非侵入式的频谱域防御机制，无需模型修改或额外训练，能有效防御空间不可感知的3D点云对抗攻击

Abstract: Recent progress in adversarial attacks on 3D point clouds, particularly in achieving spatial imperceptibility and high attack performance, presents significant challenges for defenders. Current defensive approaches remain cumbersome, often requiring invasive model modifications, expensive training procedures or auxiliary data access. To address these threats, in this paper, we propose a plug-and-play and non-invasive defense mechanism in the spectral domain, grounded in a theoretical and empirical analysis of the relationship between imperceptible perturbations and high-frequency spectral components. Building upon these insights, we introduce a novel purification framework, termed PWAVEP, which begins by computing a spectral graph wavelet domain saliency score and local sparsity score for each point. Guided by these values, PWAVEP adopts a hierarchical strategy, it eliminates the most salient points, which are identified as hardly recoverable adversarial outliers. Simultaneously, it applies a spectral filtering process to a broader set of moderately salient points. This process leverages a graph wavelet transform to attenuate high-frequency coefficients associated with the targeted points, thereby effectively suppressing adversarial noise. Extensive evaluations demonstrate that the proposed PWAVEP achieves superior accuracy and robustness compared to existing approaches, advancing the state-of-the-art in 3D point cloud purification. Code and datasets are available at https://github.com/a772316182/pwavep

</details>


### [56] [Composable Visual Tokenizers with Generator-Free Diagnostics of Learnability](https://arxiv.org/abs/2602.03339)
*Bingchen Zhao,Qiushan Guo,Ye Wang,Yixuan Huang,Zhonghua Zhai,Yu Tian*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce CompTok, a training framework for learning visual tokenizers whose tokens are enhanced for compositionality. CompTok uses a token-conditioned diffusion decoder. By employing an InfoGAN-style objective, where we train a recognition model to predict the tokens used to condition the diffusion decoder using the decoded images, we enforce the decoder to not ignore any of the tokens. To promote compositional control, besides the original images, CompTok also trains on tokens formed by swapping token subsets between images, enabling more compositional control of the token over the decoder. As the swapped tokens between images do not have ground truth image targets, we apply a manifold constraint via an adversarial flow regularizer to keep unpaired swap generations on the natural-image distribution. The resulting tokenizer not only achieves state-of-the-art performance on image class-conditioned generation, but also demonstrates properties such as swapping tokens between images to achieve high level semantic editing of an image. Additionally, we propose two metrics that measures the landscape of the token space that can be useful to describe not only the compositionality of the tokens, but also how easy to learn the landscape is for a generator to be trained on this space. We show in experiments that CompTok can improve on both of the metrics as well as supporting state-of-the-art generators for class conditioned generation.

</details>


### [57] [Tiled Prompts: Overcoming Prompt Underspecification in Image and Video Super-Resolution](https://arxiv.org/abs/2602.03342)
*Bryan Sangwoo Kim,Jonghyun Park,Jong Chul Ye*

Main category: cs.CV

TL;DR: 为解决扩散模型在图像和视频超分辨率中全局提示词描述不足的问题，本文提出了分块提示词框架，为每个潜在分块生成特定提示词，从而提供局部化高信息量引导。


<details>
  <summary>Details</summary>
Motivation: 现代超分辨率流程依赖潜在分块技术来处理高分辨率内容，但使用单一全局提示词会导致提示词描述不足。具体表现为全局提示词会忽略局部细节（提示词稀疏性）并提供无关的局部引导（提示词误导），而分类器-自由引导机制会放大这种误导。

Method: 提出Tiled Prompts统一框架，为每个潜在分块生成特定提示词，在局部文本条件下进行超分辨率处理，以最小开销提供高信息量引导，解决提示词描述不足问题。

Result: 在高分辨率真实世界图像和视频实验中，该方法在感知质量和文本对齐方面均取得一致提升，同时减少了幻觉和分块伪影。

Conclusion: Tiled Prompts框架通过局部化的文本条件处理，有效解决了超分辨率中全局提示词的描述不足问题，提升了生成质量。

Abstract: Text-conditioned diffusion models have advanced image and video super-resolution by using prompts as semantic priors, but modern super-resolution pipelines typically rely on latent tiling to scale to high resolutions, where a single global caption causes prompt underspecification. A coarse global prompt often misses localized details (prompt sparsity) and provides locally irrelevant guidance (prompt misguidance) that can be amplified by classifier-free guidance. We propose Tiled Prompts, a unified framework for image and video super-resolution that generates a tile-specific prompt for each latent tile and performs super-resolution under locally text-conditioned posteriors, providing high-information guidance that resolves prompt underspecification with minimal overhead. Experiments on high resolution real-world images and videos show consistent gains in perceptual quality and text alignment, while reducing hallucinations and tile-level artifacts relative to global-prompt baselines.

</details>


### [58] [Z3D: Zero-Shot 3D Visual Grounding from Images](https://arxiv.org/abs/2602.03361)
*Nikita Drozdov,Andrey Lemeshko,Nikita Gavrilov,Anton Konushin,Danila Rukhovich,Maksim Kolodiazhnyi*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: 3D visual grounding (3DVG) aims to localize objects in a 3D scene based on natural language queries. In this work, we explore zero-shot 3DVG from multi-view images alone, without requiring any geometric supervision or object priors. We introduce Z3D, a universal grounding pipeline that flexibly operates on multi-view images while optionally incorporating camera poses and depth maps. We identify key bottlenecks in prior zero-shot methods causing significant performance degradation and address them with (i) a state-of-the-art zero-shot 3D instance segmentation method to generate high-quality 3D bounding box proposals and (ii) advanced reasoning via prompt-based segmentation, which utilizes full capabilities of modern VLMs. Extensive experiments on the ScanRefer and Nr3D benchmarks demonstrate that our approach achieves state-of-the-art performance among zero-shot methods. Code is available at https://github.com/col14m/z3d .

</details>


### [59] [Symbol-Aware Reasoning with Masked Discrete Diffusion for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2602.03370)
*Takaya Kawakatsu,Ryo Ishiyama*

Main category: cs.CV

TL;DR: 使用离散扩散框架解决手写数学表达式识别中的曝光偏差和语法不一致问题，将HMER重新定义为迭代符号细化过程，通过多步重掩码优化符号和结构关系，在多个基准测试上超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于自回归模型的手写数学表达式识别方法面临曝光偏差和语法结构不一致的挑战，需要一个能够更好推理符号和2D布局结构的替代框架。

Method: 提出离散扩散框架，采用迭代符号细化代替序列生成，通过多步重掩码技术逐步优化符号和结构关系，结合符号感知分词和随机掩码互学习机制增强语法对齐和对手写多样性的鲁棒性。

Result: 在MathWriting基准测试上达到5.56%字符错误率和60.42%完全匹配率，优于Transformer和商业基线，在CROHME 2014-2023数据集上同样表现出色。

Conclusion: 离散扩散框架为结构感知的视觉识别提供了超越生成建模的新范式，能够有效消除因果依赖关系并改善结构一致性。

Abstract: Handwritten Mathematical Expression Recognition (HMER) requires reasoning over diverse symbols and 2D structural layouts, yet autoregressive models struggle with exposure bias and syntactic inconsistency. We present a discrete diffusion framework that reformulates HMER as iterative symbolic refinement instead of sequential generation. Through multi-step remasking, the proposal progressively refines both symbols and structural relations, removing causal dependencies and improving structural consistency. A symbol-aware tokenization and Random-Masking Mutual Learning further enhance syntactic alignment and robustness to handwriting diversity. On the MathWriting benchmark, the proposal achieves 5.56\% CER and 60.42\% EM, outperforming strong Transformer and commercial baselines. Consistent gains on CROHME 2014--2023 demonstrate that discrete diffusion provides a new paradigm for structure-aware visual recognition beyond generative modeling.

</details>


### [60] [Multi-Resolution Alignment for Voxel Sparsity in Camera-Based 3D Semantic Scene Completion](https://arxiv.org/abs/2602.03371)
*Zhiwen Yang,Yuxin Peng*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Camera-based 3D semantic scene completion (SSC) offers a cost-effective solution for assessing the geometric occupancy and semantic labels of each voxel in the surrounding 3D scene with image inputs, providing a voxel-level scene perception foundation for the perception-prediction-planning autonomous driving systems. Although significant progress has been made in existing methods, their optimization rely solely on the supervision from voxel labels and face the challenge of voxel sparsity as a large portion of voxels in autonomous driving scenarios are empty, which limits both optimization efficiency and model performance. To address this issue, we propose a \textit{Multi-Resolution Alignment (MRA)} approach to mitigate voxel sparsity in camera-based 3D semantic scene completion, which exploits the scene and instance level alignment across multi-resolution 3D features as auxiliary supervision. Specifically, we first propose the Multi-resolution View Transformer module, which projects 2D image features into multi-resolution 3D features and aligns them at the scene level through fusing discriminative seed features. Furthermore, we design the Cubic Semantic Anisotropy module to identify the instance-level semantic significance of each voxel, accounting for the semantic differences of a specific voxel against its neighboring voxels within a cubic area. Finally, we devise a Critical Distribution Alignment module, which selects critical voxels as instance-level anchors with the guidance of cubic semantic anisotropy, and applies a circulated loss for auxiliary supervision on the critical feature distribution consistency across different resolutions. The code is available at https://github.com/PKU-ICST-MIPL/MRA_TIP.

</details>


### [61] [SLIM-Diff: Shared Latent Image-Mask Diffusion with Lp loss for Data-Scarce Epilepsy FLAIR MRI](https://arxiv.org/abs/2602.03372)
*Mario Pascual-González,Ariadna Jiménez-Partinen,R. M. Luque-Baena,Fátima Nagib-Raya,Ezequiel López-Rubio*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Focal cortical dysplasia (FCD) lesions in epilepsy FLAIR MRI are subtle and scarce, making joint image--mask generative modeling prone to instability and memorization. We propose SLIM-Diff, a compact joint diffusion model whose main contributions are (i) a single shared-bottleneck U-Net that enforces tight coupling between anatomy and lesion geometry from a 2-channel image+mask representation, and (ii) loss-geometry tuning via a tunable $L_p$ objective. As an internal baseline, we include the canonical DDPM-style objective ($ε$-prediction with $L_2$ loss) and isolate the effect of prediction parameterization and $L_p$ geometry under a matched setup. Experiments show that $x_0$-prediction is consistently the strongest choice for joint synthesis, and that fractional sub-quadratic penalties ($L_{1.5}$) improve image fidelity while $L_2$ better preserves lesion mask morphology. Our code and model weights are available in https://github.com/MarioPasc/slim-diff

</details>


### [62] [Unifying Watermarking via Dimension-Aware Mapping](https://arxiv.org/abs/2602.03373)
*Jiale Meng,Runyi Hu,Jie Zhang,Zheming Lu,Ivor Tsang,Tianwei Zhang*

Main category: cs.CV

TL;DR: DiM是一个多维水印框架，将水印建模为维度感知映射问题，统一了现有水印方法。通过改变嵌入和提取的维度配置，可以实现不同的水印行为，包括时空篡改定位、局部嵌入控制和帧顺序恢复。


<details>
  <summary>Details</summary>
Motivation: 现有深度水印方法虽然有相似的编码器-解码器架构，但在功能行为上差异很大。需要建立一个统一框架来理解不同水印方法的本质，并探索维度配置如何影响水印功能。

Method: 提出了DiM框架，将水印信息建模为不同维度的有效载荷（1D二进制消息、2D空间掩码、3D时空结构），通过维度感知映射统一现有方法。在视频域实例化DiM，展示时空表示支持更广泛的维度映射。

Result: 实验表明，仅改变嵌入和提取的维度（不改变架构）就能产生不同的水印能力：时空篡改定位、局部嵌入控制以及帧顺序恢复等。

Conclusion: DiM框架从功能层面统一了现有水印方法，揭示了维度配置决定水印行为的关键作用，为设计具有特定功能的水印系统提供了新的理论基础。

Abstract: Deep watermarking methods often share similar encoder-decoder architectures, yet differ substantially in their functional behaviors. We propose DiM, a new multi-dimensional watermarking framework that formulates watermarking as a dimension-aware mapping problem, thereby unifying existing watermarking methods at the functional level. Under DiM, watermark information is modeled as payloads of different dimensionalities, including one-dimensional binary messages, two-dimensional spatial masks, and three-dimensional spatiotemporal structures. We find that the dimensional configuration of embedding and extraction largely determines the resulting watermarking behavior. Same-dimensional mappings preserve payload structure and support fine-grained control, while cross-dimensional mappings enable spatial or spatiotemporal localization. We instantiate DiM in the video domain, where spatiotemporal representations enable a broader set of dimension mappings. Experiments demonstrate that varying only the embedding and extraction dimensions, without architectural changes, leads to different watermarking capabilities, including spatiotemporal tamper localization, local embedding control, and recovery of temporal order under frame disruptions.

</details>


### [63] [From Vicious to Virtuous Cycles: Synergistic Representation Learning for Unsupervised Video Object-Centric Learning](https://arxiv.org/abs/2602.03390)
*Hyun Seok Seong,WonJun Moon,Jae-Pil Heo*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Unsupervised object-centric learning models, particularly slot-based architectures, have shown great promise in decomposing complex scenes. However, their reliance on reconstruction-based training creates a fundamental conflict between the sharp, high-frequency attention maps of the encoder and the spatially consistent but blurry reconstruction maps of the decoder. We identify that this discrepancy gives rise to a vicious cycle: the noisy feature map from the encoder forces the decoder to average over possibilities and produce even blurrier outputs, while the gradient computed from blurry reconstruction maps lacks high-frequency details necessary to supervise encoder features. To break this cycle, we introduce Synergistic Representation Learning (SRL) that establishes a virtuous cycle where the encoder and decoder mutually refine one another. SRL leverages the encoder's sharpness to deblur the semantic boundary within the decoder output, while exploiting the decoder's spatial consistency to denoise the encoder's features. This mutual refinement process is stabilized by a warm-up phase with a slot regularization objective that initially allocates distinct entities per slot. By bridging the representational gap between the encoder and decoder, SRL achieves state-of-the-art results on video object-centric learning benchmarks. Codes are available at https://github.com/hynnsk/SRL.

</details>


### [64] [Socratic-Geo: Synthetic Data Generation and Geometric Reasoning via Multi-Agent Interaction](https://arxiv.org/abs/2602.03414)
*Zhengbo Jiao,Shaobo Wang,Zifan Zhang,Wei Wang,Bing Zhao,Hu Wei,Linfeng Zhang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multimodal Large Language Models (MLLMs) have significantly advanced vision-language understanding. However, even state-of-the-art models struggle with geometric reasoning, revealing a critical bottleneck: the extreme scarcity of high-quality image-text pairs. Human annotation is prohibitively expensive, while automated methods fail to ensure fidelity and training effectiveness. Existing approaches either passively adapt to available images or employ inefficient random exploration with filtering, decoupling generation from learning needs. We propose Socratic-Geo, a fully autonomous framework that dynamically couples data synthesis with model learning through multi-agent interaction. The Teacher agent generates parameterized Python scripts with reflective feedback (Reflect for solvability, RePI for visual validity), ensuring image-text pair purity. The Solver agent optimizes reasoning through preference learning, with failure paths guiding Teacher's targeted augmentation. Independently, the Generator learns image generation capabilities on accumulated "image-code-instruction" triplets, distilling programmatic drawing intelligence into visual generation. Starting from only 108 seed problems, Socratic-Solver achieves 49.11 on six benchmarks using one-quarter of baseline data, surpassing strong baselines by 2.43 points. Socratic-Generator achieves 42.4% on GenExam, establishing new state-of-the-art for open-source models, surpassing Seedream-4.0 (39.8%) and approaching Gemini-2.5-Flash-Image (43.1%).

</details>


### [65] [ConsistentRFT: Reducing Visual Hallucinations in Flow-based Reinforcement Fine-Tuning](https://arxiv.org/abs/2602.03425)
*Xiaofeng Tan,Jun Liu,Yuanting Fan,Bin-Bin Gao,Xi Jiang,Xiaochen Chen,Jinlong Peng,Chengjie Wang,Hongsong Wang,Feng Zheng*

Main category: cs.CV

TL;DR: 针对基于流的强化微调模型中的视觉幻觉问题，提出了名为ConsistentRFT的通用框架，通过动态粒度rollout和一致性策略梯度优化来平衡全局语义与局部细节，显著减少了低层和高层的视觉幻觉。


<details>
  <summary>Details</summary>
Motivation: 基于流的模型的强化微调常导致视觉幻觉，如过度优化的细节和语义错位。本研究旨在探究视觉幻觉产生的原因并提出减少这些幻觉的方法，以提升模型的整体视觉一致性。

Method: 提出了ConsistentRFT框架，主要包括两个部分：1) 动态粒度rollout（DGR），通过动态调度不同噪声源来平衡全局语义与局部细节之间的探索；2) 一致性策略梯度优化（CPGO），通过将当前策略与更稳定的先验对齐，保持模型的跨步一致性，避免由轨迹模仿过程引起的向量场扭曲。

Result: 实验证明ConsistentRFT显著减少了视觉幻觉，在低层和高层知觉幻觉上平均分别减少了49%和38%。在使用领域外度量时，ConsistentRFT比FLUX1.dev提高了5.1%，而基线方法下降了-0.4%。

Conclusion: ConsistentRFT框架从探索与开发的统一视角出发，有效解决了基于流模型的强化微调中的视觉幻觉问题，在视觉质量和一致性方面表现优越，为后续基于流的偏好对齐方法提供了通用框架和理论基础。

Abstract: Reinforcement Fine-Tuning (RFT) on flow-based models is crucial for preference alignment. However, they often introduce visual hallucinations like over-optimized details and semantic misalignment. This work preliminarily explores why visual hallucinations arise and how to reduce them. We first investigate RFT methods from a unified perspective, and reveal the core problems stemming from two aspects, exploration and exploitation: (1) limited exploration during stochastic differential equation (SDE) rollouts, leading to an over-emphasis on local details at the expense of global semantics, and (2) trajectory imitation process inherent in policy gradient methods, distorting the model's foundational vector field and its cross-step consistency. Building on this, we propose ConsistentRFT, a general framework to mitigate these hallucinations. Specifically, we design a Dynamic Granularity Rollout (DGR) mechanism to balance exploration between global semantics and local details by dynamically scheduling different noise sources. We then introduce a Consistent Policy Gradient Optimization (CPGO) that preserves the model's consistency by aligning the current policy with a more stable prior. Extensive experiments demonstrate that ConsistentRFT significantly mitigates visual hallucinations, achieving average reductions of 49\% for low-level and 38\% for high-level perceptual hallucinations. Furthermore, ConsistentRFT outperforms other RFT methods on out-of-domain metrics, showing an improvement of 5.1\% (v.s. the baseline's decrease of -0.4\%) over FLUX1.dev. This is \href{https://xiaofeng-tan.github.io/projects/ConsistentRFT}{Project Page}.

</details>


### [66] [Hierarchical Concept-to-Appearance Guidance for Multi-Subject Image Generation](https://arxiv.org/abs/2602.03448)
*Yijia Xu,Zihao Wang,Jinshi Cui*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multi-subject image generation aims to synthesize images that faithfully preserve the identities of multiple reference subjects while following textual instructions. However, existing methods often suffer from identity inconsistency and limited compositional control, as they rely on diffusion models to implicitly associate text prompts with reference images. In this work, we propose Hierarchical Concept-to-Appearance Guidance (CAG), a framework that provides explicit, structured supervision from high-level concepts to fine-grained appearances. At the conceptual level, we introduce a VAE dropout training strategy that randomly omits reference VAE features, encouraging the model to rely more on robust semantic signals from a Visual Language Model (VLM) and thereby promoting consistent concept-level generation in the absence of complete appearance cues. At the appearance level, we integrate the VLM-derived correspondences into a correspondence-aware masked attention module within the Diffusion Transformer (DiT). This module restricts each text token to attend only to its matched reference regions, ensuring precise attribute binding and reliable multi-subject composition. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the multi-subject image generation, substantially improving prompt following and subject consistency.

</details>


### [67] [Contextualized Visual Personalization in Vision-Language Models](https://arxiv.org/abs/2602.03454)
*Yeongtak Oh,Sangwon Yu,Junsung Park,Han Cheol Moon,Jisoo Mok,Sungroh Yoon*

Main category: cs.CV

TL;DR: CoViP框架通过强化学习训练解决视觉-语言模型在基于用户历史视觉-文本上下文的个性化响应生成问题，提升个性化图像描述能力并改善下游任务表现


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型难以基于用户特定经历生成个性化响应，因为它们缺乏将视觉输入与用户累积的视觉-文本上下文关联的能力

Method: 提出CoViP统一框架，将个性化图像描述作为核心任务，通过强化学习后训练和描述增强生成技术来提升上下文视觉个性化能力

Result: 实验表明现有开源和专有VLM存在明显局限，而CoViP不仅改进了个性化图像描述，还在下游个性化任务中带来全面提升

Conclusion: CoViP是实现稳健且可泛化的上下文视觉个性化的重要阶段

Abstract: Despite recent progress in vision-language models (VLMs), existing approaches often fail to generate personalized responses based on the user's specific experiences, as they lack the ability to associate visual inputs with a user's accumulated visual-textual context. We newly formalize this challenge as contextualized visual personalization, which requires the visual recognition and textual retrieval of personalized visual experiences by VLMs when interpreting new images. To address this issue, we propose CoViP, a unified framework that treats personalized image captioning as a core task for contextualized visual personalization and improves this capability through reinforcement-learning-based post-training and caption-augmented generation. We further introduce diagnostic evaluations that explicitly rule out textual shortcut solutions and verify whether VLMs truly leverage visual context. Extensive experiments demonstrate that existing open-source and proprietary VLMs exhibit substantial limitations, while CoViP not only improves personalized image captioning but also yields holistic gains across downstream personalization tasks. These results highlight CoViP as a crucial stage for enabling robust and generalizable contextualized visual personalization.

</details>


### [68] [Inlier-Centric Post-Training Quantization for Object Detection Models](https://arxiv.org/abs/2602.03472)
*Minsu Kim,Dongyeun Lee,Jaemyung Yu,Jiwan Hur,Giseop Kim,Junmo Kim*

Main category: cs.CV

TL;DR: InlierQ：一种基于内点的后训练量化方法，通过梯度感知的体积显著性分数分离异常值，在仅需64个校准样本的情况下，显著降低二维/三维目标检测的量化误差。


<details>
  <summary>Details</summary>
Motivation: 目标检测的计算需求巨大导致部署缓慢且耗电，而量化是解决方案。但任务无关的形态（如背景杂波、传感器噪声）会引发冗余激活并扭曲激活分布，使得比特分配复杂化并削弱信息特征的保留。

Method: 提出InlierQ后训练量化方法：1）计算梯度感知的体积显著性分数；2）将每个体积分类为内点或异常值；3）使用EM算法拟合这些分数的后验分布，抑制异常值同时保留信息特征。该方法无需标签、即插即用，仅需64个校准样本。

Result: 在COCO和nuScenes基准测试中，InlierQ在基于摄像头（2D和3D）和LiDAR（3D）的目标检测任务上均实现了量化误差的一致降低。

Conclusion: InlierQ通过内点中心化的量化策略有效分离和抑制异常激活，在最小化校准需求的同时提升了目标检测模型的量化精度。

Abstract: Object detection is pivotal in computer vision, yet its immense computational demands make deployment slow and power-hungry, motivating quantization. However, task-irrelevant morphologies such as background clutter and sensor noise induce redundant activations (or anomalies). These anomalies expand activation ranges and skew activation distributions toward task-irrelevant responses, complicating bit allocation and weakening the preservation of informative features. Without a clear criterion to distinguish anomalies, suppressing them can inadvertently discard useful information. To address this, we present InlierQ, an inlier-centric post-training quantization approach that separates anomalies from informative inliers. InlierQ computes gradient-aware volume saliency scores, classifies each volume as an inlier or anomaly, and fits a posterior distribution over these scores using the Expectation-Maximization (EM) algorithm. This design suppresses anomalies while preserving informative features. InlierQ is label-free, drop-in, and requires only 64 calibration samples. Experiments on the COCO and nuScenes benchmarks show consistent reductions in quantization error for camera-based (2D and 3D) and LiDAR-based (3D) object detection.

</details>


### [69] [Decoupling Skeleton and Flesh: Efficient Multimodal Table Reasoning with Disentangled Alignment and Structure-aware Guidance](https://arxiv.org/abs/2602.03491)
*Yingjie Zhu,Xuefeng Bai,Kehai Chen,Yang Xiang,Youcheng Pan,Xiaoqiang Zhou,Min Zhang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reasoning over table images remains challenging for Large Vision-Language Models (LVLMs) due to complex layouts and tightly coupled structure-content information. Existing solutions often depend on expensive supervised training, reinforcement learning, or external tools, limiting efficiency and scalability. This work addresses a key question: how to adapt LVLMs to table reasoning with minimal annotation and no external tools? Specifically, we first introduce DiSCo, a Disentangled Structure-Content alignment framework that explicitly separates structural abstraction from semantic grounding during multimodal alignment, efficiently adapting LVLMs to tables structures. Building on DiSCo, we further present Table-GLS, a Global-to-Local Structure-guided reasoning framework that performs table reasoning via structured exploration and evidence-grounded inference. Extensive experiments across diverse benchmarks demonstrate that our framework efficiently enhances LVLM's table understanding and reasoning capabilities, particularly generalizing to unseen table structures.

</details>


### [70] [Semantic Routing: Exploring Multi-Layer LLM Feature Weighting for Diffusion Transformers](https://arxiv.org/abs/2602.03510)
*Bozhou Li,Yushuo Guan,Haolin Li,Bohan Zeng,Yiyan Ji,Yue Ding,Pengfei Wan,Kun Gai,Yuanxing Zhang,Wentao Zhang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent DiT-based text-to-image models increasingly adopt LLMs as text encoders, yet text conditioning remains largely static and often utilizes only a single LLM layer, despite pronounced semantic hierarchy across LLM layers and non-stationary denoising dynamics over both diffusion time and network depth. To better match the dynamic process of DiT generation and thereby enhance the diffusion model's generative capability, we introduce a unified normalized convex fusion framework equipped with lightweight gates to systematically organize multi-layer LLM hidden states via time-wise, depth-wise, and joint fusion. Experiments establish Depth-wise Semantic Routing as the superior conditioning strategy, consistently improving text-image alignment and compositional generation (e.g., +9.97 on the GenAI-Bench Counting task). Conversely, we find that purely time-wise fusion can paradoxically degrade visual generation fidelity. We attribute this to a train-inference trajectory mismatch: under classifier-free guidance, nominal timesteps fail to track the effective SNR, causing semantically mistimed feature injection during inference. Overall, our results position depth-wise routing as a strong and effective baseline and highlight the critical need for trajectory-aware signals to enable robust time-dependent conditioning.

</details>


### [71] [Interpretable Logical Anomaly Classification via Constraint Decomposition and Instruction Fine-Tuning](https://arxiv.org/abs/2602.03530)
*Xufei Zhang,Xinjiao Zhou,Ziling Deng,Dongdong Geng,Jianxiong Wang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Logical anomalies are violations of predefined constraints on object quantity, spatial layout, and compositional relationships in industrial images. While prior work largely treats anomaly detection as a binary decision, such formulations cannot indicate which logical rule is broken and therefore offer limited value for quality assurance. We introduce Logical Anomaly Classification (LAC), a task that unifies anomaly detection and fine-grained violation classification in a single inference step. To tackle LAC, we propose LogiCls, a vision-language framework that decomposes complex logical constraints into a sequence of verifiable subqueries. We further present a data-centric instruction synthesis pipeline that generates chain-of-thought (CoT) supervision for these subqueries, coupling precise grounding annotations with diverse image-text augmentations to adapt vision language models (VLMs) to logic-sensitive reasoning. Training is stabilized by a difficulty-aware resampling strategy that emphasizes challenging subqueries and long tail constraint types. Extensive experiments demonstrate that LogiCls delivers robust, interpretable, and accurate industrial logical anomaly classification, providing both the predicted violation categories and their evidence trails.

</details>


### [72] [PnP-U3D: Plug-and-Play 3D Framework Bridging Autoregression and Diffusion for Unified Understanding and Generation](https://arxiv.org/abs/2602.03533)
*Yongwei Chen,Tianyi Wei,Yushi Lan,Zhaoyang Lyu,Shangchen Zhou,Xudong Xu,Xingang Pan*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid progress of large multimodal models has inspired efforts toward unified frameworks that couple understanding and generation. While such paradigms have shown remarkable success in 2D, extending them to 3D remains largely underexplored. Existing attempts to unify 3D tasks under a single autoregressive (AR) paradigm lead to significant performance degradation due to forced signal quantization and prohibitive training cost. Our key insight is that the essential challenge lies not in enforcing a unified autoregressive paradigm, but in enabling effective information interaction between generation and understanding while minimally compromising their inherent capabilities and leveraging pretrained models to reduce training cost. Guided by this perspective, we present the first unified framework for 3D understanding and generation that combines autoregression with diffusion. Specifically, we adopt an autoregressive next-token prediction paradigm for 3D understanding, and a continuous diffusion paradigm for 3D generation. A lightweight transformer bridges the feature space of large language models and the conditional space of 3D diffusion models, enabling effective cross-modal information exchange while preserving the priors learned by standalone models. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across diverse 3D understanding and generation benchmarks, while also excelling in 3D editing tasks. These results highlight the potential of unified AR+diffusion models as a promising direction for building more general-purpose 3D intelligence.

</details>


### [73] [Constrained Dynamic Gaussian Splatting](https://arxiv.org/abs/2602.03538)
*Zihan Zheng,Zhenglong Wu,Xuanxuan Wang,Houqiang Zhong,Xiaoyun Zhang,Qiang Hu,Guangtao Zhai,Wenjun Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为CDGS的新框架，将动态场景重构定义为预算约束优化问题，通过在训练中强制执行用户定义的高斯数量预算，解决了动态高斯喷洒在边缘设备上的内存限制问题。


<details>
  <summary>Details</summary>
Motivation: 动态高斯喷洒虽然能实现高保真4D重建，但面临一个根本性困境：无约束的密化会导致内存消耗过大不兼容边缘设备，而启发式剪枝在预设高斯预算下无法实现最优渲染质量。

Method: 引入可微分预算控制器作为核心优化驱动，基于多模态统一重要性评分；解耦静态和动态元素的优化，采用自适应分配机制；实施三阶段训练策略来整合约束；配合双模式混合压缩方案。

Result: CDGS能够严格遵循硬件约束（误差<2%），并在速率失真性能上推进了帕累托前沿，在不同容量限制下实现最优渲染质量，相比最先进方法实现超过3倍的压缩率。

Conclusion: CDGS框架成功解决了动态高斯喷洒在边缘设备部署中的内存效率问题，通过在训练中严格强制执行高斯预算约束，同时不牺牲渲染质量，为资源受限环境下的4D重建提供了实用解决方案。

Abstract: While Dynamic Gaussian Splatting enables high-fidelity 4D reconstruction, its deployment is severely hindered by a fundamental dilemma: unconstrained densification leads to excessive memory consumption incompatible with edge devices, whereas heuristic pruning fails to achieve optimal rendering quality under preset Gaussian budgets. In this work, we propose Constrained Dynamic Gaussian Splatting (CDGS), a novel framework that formulates dynamic scene reconstruction as a budget-constrained optimization problem to enforce a strict, user-defined Gaussian budget during training. Our key insight is to introduce a differentiable budget controller as the core optimization driver. Guided by a multi-modal unified importance score, this controller fuses geometric, motion, and perceptual cues for precise capacity regulation. To maximize the utility of this fixed budget, we further decouple the optimization of static and dynamic elements, employing an adaptive allocation mechanism that dynamically distributes capacity based on motion complexity. Furthermore, we implement a three-phase training strategy to seamlessly integrate these constraints, ensuring precise adherence to the target count. Coupled with a dual-mode hybrid compression scheme, CDGS not only strictly adheres to hardware constraints (error < 2%}) but also pushes the Pareto frontier of rate-distortion performance. Extensive experiments demonstrate that CDGS delivers optimal rendering quality under varying capacity limits, achieving over 3x compression compared to state-of-the-art methods.

</details>


### [74] [Cut to the Mix: Simple Data Augmentation Outperforms Elaborate Ones in Limited Organ Segmentation Datasets](https://arxiv.org/abs/2602.03555)
*Chang Liu,Fuxin Fan,Annette Schwarz,Andreas Maier*

Main category: cs.CV

TL;DR: 研究探索了四种跨图像数据增强策略对医学图像多器官分割性能的影响，发现CutMix、CarveMix和AnatoMix能显著提升分割准确率


<details>
  <summary>Details</summary>
Motivation: 多器官分割是临床常规任务，深度学习模型需要大量标注数据，但临床数据稀缺问题突出。传统数据增强局限于单图像操作，跨图像的对象级数据增强策略在多器官分割任务中尚未充分探索

Method: 在两种器官分割数据集上研究了四种跨图像数据增强策略：CutMix、CarveMix、ObjectAug和AnatoMix，并与nnUNet基线模型进行比较

Result: CutMix、CarveMix和AnatoMix相比不使用数据增强的nnUNet，分别将平均Dice分数提高了4.9、2.0和1.9。与传统数据增强结合后性能进一步提升

Conclusion: CutMix是一种鲁棒且简单的数据增强策略，即使生成看似'错误'的图像，也能有效提高多器官分割性能

Abstract: Multi-organ segmentation is a widely applied clinical routine and automated organ segmentation tools dramatically improve the pipeline of the radiologists. Recently, deep learning (DL) based segmentation models have shown the capacity to accomplish such a task. However, the training of the segmentation networks requires large amount of data with manual annotations, which is a major concern due to the data scarcity from clinic. Working with limited data is still common for researches on novel imaging modalities. To enhance the effectiveness of DL models trained with limited data, data augmentation (DA) is a crucial regularization technique. Traditional DA (TDA) strategies focus on basic intra-image operations, i.e. generating images with different orientations and intensity distributions. In contrast, the interimage and object-level DA operations are able to create new images from separate individuals. However, such DA strategies are not well explored on the task of multi-organ segmentation. In this paper, we investigated four possible inter-image DA strategies: CutMix, CarveMix, ObjectAug and AnatoMix, on two organ segmentation datasets. The result shows that CutMix, CarveMix and AnatoMix can improve the average dice score by 4.9, 2.0 and 1.9, compared with the state-of-the-art nnUNet without DA strategies. These results can be further improved by adding TDA strategies. It is revealed in our experiments that Cut-Mix is a robust but simple DA strategy to drive up the segmentation performance for multi-organ segmentation, even when CutMix produces intuitively 'wrong' images. Our implementation is publicly available for future benchmarks.

</details>


### [75] [ELIQ: A Label-Free Framework for Quality Assessment of Evolving AI-Generated Images](https://arxiv.org/abs/2602.03558)
*Xinyue Li,Zhiming Xu,Zhichao Zhang,Zhaolin Cai,Sijing Wu,Xiongkuo Min,Yitong Chen,Guangtao Zhai*

Main category: cs.CV

TL;DR: ELIQ是一个无需人工标注的框架，用于评估不断进化的AI生成图像的质量，重点关注视觉质量和提示-图像对齐，通过自动构建正负样本对实现可迁移监督，实验表明其性能优于现有无标注方法。


<details>
  <summary>Details</summary>
Motivation: 生成式文本到图像模型快速发展，之前收集的图像质量标签对新一代模型已不可靠，需要建立不需要人工标注的质量评估方法。

Method: 自动构建正负样本对覆盖传统失真和AIGC特定失真模式，通过指令调优将预训练多模态模型适配为质量感知评判器，使用轻量级门控融合和质量查询转换器预测二维质量。

Result: 在多个基准测试中，ELIQ始终优于现有的无标注方法，无需修改即可从AIGC泛化到UGC场景。

Conclusion: ELIQ为持续进化的生成模型下可扩展的无标注质量评估铺平了道路，代码将在发表后开源。

Abstract: Generative text-to-image models are advancing at an unprecedented pace, continuously shifting the perceptual quality ceiling and rendering previously collected labels unreliable for newer generations. To address this, we present ELIQ, a Label-free Framework for Quality Assessment of Evolving AI-generated Images. Specifically, ELIQ focuses on visual quality and prompt-image alignment, automatically constructs positive and aspect-specific negative pairs to cover both conventional distortions and AIGC-specific distortion modes, enabling transferable supervision without human annotations. Building on these pairs, ELIQ adapts a pre-trained multimodal model into a quality-aware critic via instruction tuning and predicts two-dimensional quality using lightweight gated fusion and a Quality Query Transformer. Experiments across multiple benchmarks demonstrate that ELIQ consistently outperforms existing label-free methods, generalizes from AI-generated content (AIGC) to user-generated content (UGC) scenarios without modification, and paves the way for scalable and label-free quality assessment under continuously evolving generative models. The code will be released upon publication.

</details>


### [76] [SlowFocus: Enhancing Fine-grained Temporal Understanding in Video LLM](https://arxiv.org/abs/2602.03589)
*Ming Nie,Dan Ding,Chunwei Wang,Yuanfan Guo,Jianhua Han,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: 本文提出SlowFocus机制解决视频大语言模型在保持高质量帧级语义信息和全面视频级时序信息之间的平衡问题，通过问题引导的时序定位和密集采样来提升细粒度视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型难以同时保持高质量的帧级语义信息（充足的每帧标记数）和全面的视频级时序信息（足够的每视频采样帧数），这阻碍了细粒度视频理解的发展。

Method: 1) 提出SlowFocus机制：基于问题识别相关时序片段，在该片段进行密集采样提取局部高频特征；2) 多频率混合注意力模块：聚合局部高频细节与全局低频上下文；3) 设计训练策略加强时序定位和详细时序推理能力；4) 建立FineAction-CGR基准测试细粒度时序理解。

Result: 综合实验表明，SlowFocus机制在现有公共视频理解基准和提出的FineAction-CGR基准上均表现出优越性能。

Conclusion: SlowFocus机制能有效提升视频大语言模型的细粒度视频理解能力，在同时保持高质量帧级语义和充分时序信息方面具有显著优势。

Abstract: Large language models (LLMs) have demonstrated exceptional capabilities in text understanding, which has paved the way for their expansion into video LLMs (Vid-LLMs) to analyze video data. However, current Vid-LLMs struggle to simultaneously retain high-quality frame-level semantic information (i.e., a sufficient number of tokens per frame) and comprehensive video-level temporal information (i.e., an adequate number of sampled frames per video). This limitation hinders the advancement of Vid-LLMs towards fine-grained video understanding. To address this issue, we introduce the SlowFocus mechanism, which significantly enhances the equivalent sampling frequency without compromising the quality of frame-level visual tokens. SlowFocus begins by identifying the query-related temporal segment based on the posed question, then performs dense sampling on this segment to extract local high-frequency features. A multi-frequency mixing attention module is further leveraged to aggregate these local high-frequency details with global low-frequency contexts for enhanced temporal comprehension. Additionally, to tailor Vid-LLMs to this innovative mechanism, we introduce a set of training strategies aimed at bolstering both temporal grounding and detailed temporal reasoning capabilities. Furthermore, we establish FineAction-CGR, a benchmark specifically devised to assess the ability of Vid-LLMs to process fine-grained temporal understanding tasks. Comprehensive experiments demonstrate the superiority of our mechanism across both existing public video understanding benchmarks and our proposed FineAction-CGR.

</details>


### [77] [High-Resolution Underwater Camouflaged Object Detection: GBU-UCOD Dataset and Topology-Aware and Frequency-Decoupled Networks](https://arxiv.org/abs/2602.03591)
*Wenji Wu,Shuo Ye,Yiyu Liu,Jiguang He,Zhuo Wang,Zitong Yu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Underwater Camouflaged Object Detection (UCOD) is a challenging task due to the extreme visual similarity between targets and backgrounds across varying marine depths. Existing methods often struggle with topological fragmentation of slender creatures in the deep sea and the subtle feature extraction of transparent organisms. In this paper, we propose DeepTopo-Net, a novel framework that integrates topology-aware modeling with frequency-decoupled perception. To address physical degradation, we design the Water-Conditioned Adaptive Perceptor (WCAP), which employs Riemannian metric tensors to dynamically deform convolutional sampling fields. Furthermore, the Abyssal-Topology Refinement Module (ATRM) is developed to maintain the structural connectivity of spindly targets through skeletal priors. Specifically, we first introduce GBU-UCOD, the first high-resolution (2K) benchmark tailored for marine vertical zonation, filling the data gap for hadal and abyssal zones. Extensive experiments on MAS3K, RMAS, and our proposed GBU-UCOD datasets demonstrate that DeepTopo-Net achieves state-of-the-art performance, particularly in preserving the morphological integrity of complex underwater patterns. The datasets and codes will be released at https://github.com/Wuwenji18/GBU-UCOD.

</details>


### [78] [Refer-Agent: A Collaborative Multi-Agent System with Reasoning and Reflection for Referring Video Object Segmentation](https://arxiv.org/abs/2602.03595)
*Haichao Jiang,Tianming Liang,Wei-Shi Zheng,Jian-Fang Hu*

Main category: cs.CV

TL;DR: 提出了一个用于指代视频对象分割（RVOS）的协作多智能体系统Refer-Agent，它通过交替推理-反射机制分解任务，使用粗到细的帧选择策略和动态焦点布局，并通过Chain-of-Reflection机制验证中间结果。该方法在多个基准测试中超越了现有方法，且无需额外微调即可灵活集成新MLLM。


<details>
  <summary>Details</summary>
Motivation: 现有的RVOS方法主要依赖于多模态大语言模型的大规模监督微调，存在数据依赖性强、扩展性受限的问题。零样本方法虽然灵活但性能明显落后。需要一种既能保持高性能又具备灵活性的新方法。

Method: 设计了协作多智能体系统Refer-Agent，包含交替推理-反射机制：1）通过Coarse-to-Fine帧选择确保帧多样性和文本相关性；2）Dynamic Focus Layout自适应调整视觉焦点；3）Chain-of-Reflection机制使用Questioner-Responder对生成自我反思链，验证中间结果并为下一轮推理提供反馈。

Result: 在五个具有挑战性的基准测试上进行广泛实验，Refer-Agent显著优于当前最先进的方法，包括基于监督微调的方法和零样本方法。

Conclusion: Refer-Agent为RVOS提供了一种高效灵活的解决方案，无需额外微调成本即可快速集成新的MLLM，在性能和可扩展性方面都表现出色。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment objects in videos based on textual queries. Current methods mainly rely on large-scale supervised fine-tuning (SFT) of Multi-modal Large Language Models (MLLMs). However, this paradigm suffers from heavy data dependence and limited scalability against the rapid evolution of MLLMs. Although recent zero-shot approaches offer a flexible alternative, their performance remains significantly behind SFT-based methods, due to the straightforward workflow designs. To address these limitations, we propose \textbf{Refer-Agent}, a collaborative multi-agent system with alternating reasoning-reflection mechanisms. This system decomposes RVOS into step-by-step reasoning process. During reasoning, we introduce a Coarse-to-Fine frame selection strategy to ensure the frame diversity and textual relevance, along with a Dynamic Focus Layout that adaptively adjusts the agent's visual focus. Furthermore, we propose a Chain-of-Reflection mechanism, which employs a Questioner-Responder pair to generate a self-reflection chain, enabling the system to verify intermediate results and generates feedback for next-round reasoning refinement. Extensive experiments on five challenging benchmarks demonstrate that Refer-Agent significantly outperforms state-of-the-art methods, including both SFT-based models and zero-shot approaches. Moreover, Refer-Agent is flexible and enables fast integration of new MLLMs without any additional fine-tuning costs. Code will be released.

</details>


### [79] [A Lightweight Library for Energy-Based Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2602.03604)
*Basile Terver,Randall Balestriero,Megi Dervishi,David Fan,Quentin Garrido,Tushar Nagarajan,Koustuv Sinha,Wancong Zhang,Mike Rabbat,Yann LeCun,Amir Bar*

Main category: cs.CV

TL;DR: EB-JEPA 是一个用于学习表征和世界模型的开源库，基于联合嵌入预测架构，支持图像到视频再到动作条件世界模型的扩展应用。


<details>
  <summary>Details</summary>
Motivation: 现有生成式模型存在缺陷，且缺乏适用于视频和动作条件世界模型的模块化实现方案。

Method: 采用基于能量的 JEPA 架构，在表征空间进行预测而非像素空间，通过正则化组件防止表征崩溃，并实现从图像到视频再到动作条件模型的逐步扩展。

Result: 在 CIFAR-10 上获得 91% 的探测准确率；在 Moving MNIST 上实现多步预测；在 Two Rooms 导航任务中达到 97% 的规划成功率。

Conclusion: EB-JEPA 有效支持不同领域的表征学习，其正则化组件对防止表征崩溃至关重要，为研究和教育提供了便捷工具。

Abstract: We present EB-JEPA, an open-source library for learning representations and world models using Joint-Embedding Predictive Architectures (JEPAs). JEPAs learn to predict in representation space rather than pixel space, avoiding the pitfalls of generative modeling while capturing semantically meaningful features suitable for downstream tasks. Our library provides modular, self-contained implementations that illustrate how representation learning techniques developed for image-level self-supervised learning can transfer to video, where temporal dynamics add complexity, and ultimately to action-conditioned world models, where the model must additionally learn to predict the effects of control inputs. Each example is designed for single-GPU training within a few hours, making energy-based self-supervised learning accessible for research and education. We provide ablations of JEA components on CIFAR-10. Probing these representations yields 91% accuracy, indicating that the model learns useful features. Extending to video, we include a multi-step prediction example on Moving MNIST that demonstrates how the same principles scale to temporal modeling. Finally, we show how these representations can drive action-conditioned world models, achieving a 97% planning success rate on the Two Rooms navigation task. Comprehensive ablations reveal the critical importance of each regularization component for preventing representation collapse. Code is available at https://github.com/facebookresearch/eb_jepa.

</details>


### [80] [KTV: Keyframes and Key Tokens Selection for Efficient Training-Free Video LLMs](https://arxiv.org/abs/2602.03615)
*Baiyang Song,Jun Peng,Yuxin Zhang,Guangyao Chen,Feidiao Yang,Jianyuan Guo*

Main category: cs.CV

TL;DR: KTV提出了一种两阶段的无需训练视频理解框架，通过聚类选择关键帧并剪枝冗余视觉token，显著减少计算开销同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无需训练视频理解方法面临视觉冗余和高计算开销问题，特别是基于CLIP相似度的关键帧选择策略容易产生偏差并忽略关键帧，导致视频理解性能不佳。

Method: KTV采用两阶段框架：第一阶段通过聚类帧级视觉特征进行问题无关的关键帧选择，获得紧凑、多样且具有代表性的帧子集；第二阶段基于token重要性和冗余性，对每个关键帧进行关键视觉token选择，剪枝冗余或不重要的token。

Result: 在多项选择视频问答任务上的实验表明，KTV在使用显著更少视觉token的情况下（如60分钟视频仅用504个token），超越了最先进的无需训练基线方法，在MLVU-Test基准上达到44.8%的准确率，甚至在某些基准上超过了部分需要训练的方法。

Conclusion: KTV通过创新的两阶段框架有效解决了训练免费视频理解中的冗余和效率问题，为长视频理解提供了一种高效且有效的方法，展示了无需训练方法在处理长视频内容方面的潜力。

Abstract: Training-free video understanding leverages the strong image comprehension capabilities of pre-trained vision language models (VLMs) by treating a video as a sequence of static frames, thus obviating the need for costly video-specific training. However, this paradigm often suffers from severe visual redundancy and high computational overhead, especially when processing long videos. Crucially, existing keyframe selection strategies, especially those based on CLIP similarity, are prone to biases and may inadvertently overlook critical frames, resulting in suboptimal video comprehension. To address these significant challenges, we propose \textbf{KTV}, a novel two-stage framework for efficient and effective training-free video understanding. In the first stage, KTV performs question-agnostic keyframe selection by clustering frame-level visual features, yielding a compact, diverse, and representative subset of frames that mitigates temporal redundancy. In the second stage, KTV applies key visual token selection, pruning redundant or less informative tokens from each selected keyframe based on token importance and redundancy, which significantly reduces the number of tokens fed into the LLM. Extensive experiments on the Multiple-Choice VideoQA task demonstrate that KTV outperforms state-of-the-art training-free baselines while using significantly fewer visual tokens, \emph{e.g.}, only 504 visual tokens for a 60-min video with 10800 frames, achieving $44.8\%$ accuracy on the MLVU-Test benchmark. In particular, KTV also exceeds several training-based approaches on certain benchmarks.

</details>


### [81] [Quasi-multimodal-based pathophysiological feature learning for retinal disease diagnosis](https://arxiv.org/abs/2602.03622)
*Lu Zhang,Huizhen Yu,Zuowei Wang,Fu Gui,Yatu Guo,Wei Zhang,Mengyu Jia*

Main category: cs.CV

TL;DR: 提出基于多模态数据合成与融合的统一框架，用于视网膜疾病分类与分级，在多标签分类和糖尿病视网膜病变分级任务上表现优越。


<details>
  <summary>Details</summary>
Motivation: 眼科临床中多模态诊断面临数据异质性、潜在侵入性、配准复杂性等挑战，需要能够整合多模态数据合成与融合的统一框架。

Method: 1) 合成包含FFA、MSI和显著性图的多模态数据；2) 并行模型学习模态特定表征；3) 跨模态自适应校准特征以进行信息剪枝和灵活整合；4) 通过图像和特征空间可视化全面解释学习系统。

Result: 在两个公共数据集上的实验显示，该方法在多标签分类（F1分数: 0.683，AUC: 0.953）和糖尿病视网膜病变分级（准确率: 0.842，Kappa: 0.861）任务上优于最先进的方法。

Conclusion: 该工作不仅提高了视网膜疾病筛查的准确性和效率，还为各种医学成像模态的数据增强提供了可扩展的框架。

Abstract: Retinal diseases spanning a broad spectrum can be effectively identified and diagnosed using complementary signals from multimodal data. However, multimodal diagnosis in ophthalmic practice is typically challenged in terms of data heterogeneity, potential invasiveness, registration complexity, and so on. As such, a unified framework that integrates multimodal data synthesis and fusion is proposed for retinal disease classification and grading. Specifically, the synthesized multimodal data incorporates fundus fluorescein angiography (FFA), multispectral imaging (MSI), and saliency maps that emphasize latent lesions as well as optic disc/cup regions. Parallel models are independently trained to learn modality-specific representations that capture cross-pathophysiological signatures. These features are then adaptively calibrated within and across modalities to perform information pruning and flexible integration according to downstream tasks. The proposed learning system is thoroughly interpreted through visualizations in both image and feature spaces. Extensive experiments on two public datasets demonstrated the superiority of our approach over state-of-the-art ones in the tasks of multi-label classification (F1-score: 0.683, AUC: 0.953) and diabetic retinopathy grading (Accuracy:0.842, Kappa: 0.861). This work not only enhances the accuracy and efficiency of retinal disease screening but also offers a scalable framework for data augmentation across various medical imaging modalities.

</details>


### [82] [SPWOOD: Sparse Partial Weakly-Supervised Oriented Object Detection](https://arxiv.org/abs/2602.03634)
*Wei Zhang,Xiang Liu,Ningjing Liu,Mingxin Liu,Wei Liao,Chunyan Xu,Xue Yang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A consistent trend throughout the research of oriented object detection has been the pursuit of maintaining comparable performance with fewer and weaker annotations. This is particularly crucial in the remote sensing domain, where the dense object distribution and a wide variety of categories contribute to prohibitively high costs. Based on the supervision level, existing oriented object detection algorithms can be broadly grouped into fully supervised, semi-supervised, and weakly supervised methods. Within the scope of this work, we further categorize them to include sparsely supervised and partially weakly-supervised methods. To address the challenges of large-scale labeling, we introduce the first Sparse Partial Weakly-Supervised Oriented Object Detection framework, designed to efficiently leverage only a few sparse weakly-labeled data and plenty of unlabeled data. Our framework incorporates three key innovations: (1) We design a Sparse-annotation-Orientation-and-Scale-aware Student (SOS-Student) model to separate unlabeled objects from the background in a sparsely-labeled setting, and learn orientation and scale information from orientation-agnostic or scale-agnostic weak annotations. (2) We construct a novel Multi-level Pseudo-label Filtering strategy that leverages the distribution of model predictions, which is informed by the model's multi-layer predictions. (3) We propose a unique sparse partitioning approach, ensuring equal treatment for each category. Extensive experiments on the DOTA and DIOR datasets show that our framework achieves a significant performance gain over traditional oriented object detection methods mentioned above, offering a highly cost-effective solution. Our code is publicly available at https://github.com/VisionXLab/SPWOOD.

</details>


### [83] [MM-SCALE: Grounded Multimodal Moral Reasoning via Scalar Judgment and Listwise Alignment](https://arxiv.org/abs/2602.03665)
*Eunkyu Park,Wesley Hanwen Deng,Cheyon Jin,Matheus Kunzler Maldaner,Jordan Wheeler,Jason I. Hong,Hong Shen,Adam Perer,Ken Holstein,Motahhare Eslami,Gunhee Kim*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Vision-Language Models (VLMs) continue to struggle to make morally salient judgments in multimodal and socially ambiguous contexts. Prior works typically rely on binary or pairwise supervision, which often fail to capture the continuous and pluralistic nature of human moral reasoning. We present MM-SCALE (Multimodal Moral Scale), a large-scale dataset for aligning VLMs with human moral preferences through 5-point scalar ratings and explicit modality grounding. Each image-scenario pair is annotated with moral acceptability scores and grounded reasoning labels by humans using an interface we tailored for data collection, enabling listwise preference optimization over ranked scenario sets. By moving from discrete to scalar supervision, our framework provides richer alignment signals and finer calibration of multimodal moral reasoning. Experiments show that VLMs fine-tuned on MM-SCALE achieve higher ranking fidelity and more stable safety calibration than those trained with binary signals.

</details>


### [84] [Referring Industrial Anomaly Segmentation](https://arxiv.org/abs/2602.03673)
*Pengfei Yue,Xiaokang Jiang,Yilin Lu,Jianghang Lin,Shengchuan Zhang,Liujuan Cao*

Main category: cs.CV

TL;DR: 提出RIAS范式，通过语言引导工业异常检测，实现无需人工阈值的精确掩码生成和单模型检测多样化异常。


<details>
  <summary>Details</summary>
Motivation: 传统工业异常检测方法存在局限：无监督方法需要手动阈值，监督方法因数据稀缺、不平衡而过拟合，且两者都受限于'一种异常对应一个模型'。需要更通用、准确的检测方法。

Method: 提出RIAS(Referring Industrial Anomaly Segmentation)范式，利用文本描述引导检测。设计了MVTec-Ref数据集，包含多样化指代表达，重点关注异常模式（95%为小异常）。提出DQFormer基准模型，采用Dual Query Token和Mask Group Transformer机制，结合Language-Gated Multi-Level Aggregation增强多尺度分割。

Result: 实验证明RIAS在工业异常检测的有效性，推动IAD向开放集能力发展。

Conclusion: RIAS范式通过语言引导显著提升工业异常检测的性能，解决了传统方法的局限性，为更通用、准确的异常检测提供了新方向。

Abstract: Industrial Anomaly Detection (IAD) is vital for manufacturing, yet traditional methods face significant challenges: unsupervised approaches yield rough localizations requiring manual thresholds, while supervised methods overfit due to scarce, imbalanced data. Both suffer from the "One Anomaly Class, One Model" limitation. To address this, we propose Referring Industrial Anomaly Segmentation (RIAS), a paradigm leveraging language to guide detection. RIAS generates precise masks from text descriptions without manual thresholds and uses universal prompts to detect diverse anomalies with a single model. We introduce the MVTec-Ref dataset to support this, designed with diverse referring expressions and focusing on anomaly patterns, notably with 95% small anomalies. We also propose the Dual Query Token with Mask Group Transformer (DQFormer) benchmark, enhanced by Language-Gated Multi-Level Aggregation (LMA) to improve multi-scale segmentation. Unlike traditional methods using redundant queries, DQFormer employs only "Anomaly" and "Background" tokens for efficient visual-textual integration. Experiments demonstrate RIAS's effectiveness in advancing IAD toward open-set capabilities. Code: https://github.com/swagger-coder/RIAS-MVTec-Ref.

</details>


### [85] [RegionReasoner: Region-Grounded Multi-Round Visual Reasoning](https://arxiv.org/abs/2602.03733)
*Wenfang Sun,Hao Chen,Yingjun Du,Yefeng Zheng,Cees G. M. Snoek*

Main category: cs.CV

TL;DR: RegionReasoner-7B框架实现多轮视觉推理，通过强化学习和区域引用机制提升视觉语言模型在检测与分割任务中的准确性和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型大多依赖单步或纯文本推理，缺乏在多个视觉场景中迭代细化的能力，需建立系统性多轮视觉推理基准与学习框架。

Method: 提出RegionReasoner强化学习框架：要求推理过程明确引用对应边界框，并通过全局-局部一致性奖励保持语义连贯性；构建RegionDial-Bench多轮视觉推理基准。

Result: 在检测与分割任务中，RegionReasoner-7B显著提升多轮推理准确率、空间定位精度及全局-局部一致性，为新兴研究方向建立强基线。

Conclusion: 研究验证了迭代式区域引用机制与语义一致性奖励在多轮视觉推理中的有效性，为复杂视觉理解任务提供了新基准与方法框架。

Abstract: Large vision-language models have achieved remarkable progress in visual reasoning, yet most existing systems rely on single-step or text-only reasoning, limiting their ability to iteratively refine understanding across multiple visual contexts. To address this limitation, we introduce a new multi-round visual reasoning benchmark with training and test sets spanning both detection and segmentation tasks, enabling systematic evaluation under iterative reasoning scenarios. We further propose RegionReasoner, a reinforcement learning framework that enforces grounded reasoning by requiring each reasoning trace to explicitly cite the corresponding reference bounding boxes, while maintaining semantic coherence via a global-local consistency reward. This reward extracts key objects and nouns from both global scene captions and region-level captions, aligning them with the reasoning trace to ensure consistency across reasoning steps. RegionReasoner is optimized with structured rewards combining grounding fidelity and global-local semantic alignment. Experiments on detection and segmentation tasks show that RegionReasoner-7B, together with our newly introduced benchmark RegionDial-Bench, considerably improves multi-round reasoning accuracy, spatial grounding precision, and global-local consistency, establishing a strong baseline for this emerging research direction.

</details>


### [86] [Edge-Optimized Vision-Language Models for Underground Infrastructure Assessment](https://arxiv.org/abs/2602.03742)
*Johny J. Lopez,Md Meftahul Ferdaus,Mahdi Abdelguerfi*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Autonomous inspection of underground infrastructure, such as sewer and culvert systems, is critical to public safety and urban sustainability. Although robotic platforms equipped with visual sensors can efficiently detect structural deficiencies, the automated generation of human-readable summaries from these detections remains a significant challenge, especially on resource-constrained edge devices. This paper presents a novel two-stage pipeline for end-to-end summarization of underground deficiencies, combining our lightweight RAPID-SCAN segmentation model with a fine-tuned Vision-Language Model (VLM) deployed on an edge computing platform. The first stage employs RAPID-SCAN (Resource-Aware Pipeline Inspection and Defect Segmentation using Compact Adaptive Network), achieving 0.834 F1-score with only 0.64M parameters for efficient defect segmentation. The second stage utilizes a fine-tuned Phi-3.5 VLM that generates concise, domain-specific summaries in natural language from the segmentation outputs. We introduce a curated dataset of inspection images with manually verified descriptions for VLM fine-tuning and evaluation. To enable real-time performance, we employ post-training quantization with hardware-specific optimization, achieving significant reductions in model size and inference latency without compromising summarization quality. We deploy and evaluate our complete pipeline on a mobile robotic platform, demonstrating its effectiveness in real-world inspection scenarios. Our results show the potential of edge-deployable integrated AI systems to bridge the gap between automated defect detection and actionable insights for infrastructure maintenance, paving the way for more scalable and autonomous inspection solutions.

</details>


### [87] [LIVE: Long-horizon Interactive Video World Modeling](https://arxiv.org/abs/2602.03747)
*Junchao Huang,Ziyang Ye,Xinting Hu,Tianyu He,Guiyu Zhang,Shaoshuai Shi,Jiang Bian,Li Jiang*

Main category: cs.CV

TL;DR: 提出了一种通过循环一致性目标来确保有界误差积累的长时交互视频世界模型LIVE，不需要教师蒸馏机制


<details>
  <summary>Details</summary>
Motivation: 现有的自回归视频世界模型在短时预测效果良好，但在长时预测中会面临预测误差累积的问题。先前的方法使用预训练教师模型和序列级分布匹配会带来额外计算成本，且无法防止超出训练范围后的误差传播

Method: 提出LIVE模型，使用循环一致性目标：1）从真实帧进行前向传播；2）应用反向生成过程重建初始状态；3）在重构的终端状态上计算扩散损失，为长时误差传播提供显式约束，同时提出了统一框架和渐进训练课程来稳定训练

Result: 在长时基准测试中取得了最先进的性能，能够生成稳定、高质量的远超出训练传播长度的视频

Conclusion: LIVE通过循环一致性目标有效解决了长时预测中的误差累积问题，相比传统方法更具计算效率，为长时交互视频世界建模提供了新的有效方案

Abstract: Autoregressive video world models predict future visual observations conditioned on actions. While effective over short horizons, these models often struggle with long-horizon generation, as small prediction errors accumulate over time. Prior methods alleviate this by introducing pre-trained teacher models and sequence-level distribution matching, which incur additional computational cost and fail to prevent error propagation beyond the training horizon. In this work, we propose LIVE, a Long-horizon Interactive Video world modEl that enforces bounded error accumulation via a novel cycle-consistency objective, thereby eliminating the need for teacher-based distillation. Specifically, LIVE first performs a forward rollout from ground-truth frames and then applies a reverse generation process to reconstruct the initial state. The diffusion loss is subsequently computed on the reconstructed terminal state, providing an explicit constraint on long-horizon error propagation. Moreover, we provide an unified view that encompasses different approaches and introduce progressive training curriculum to stabilize training. Experiments demonstrate that LIVE achieves state-of-the-art performance on long-horizon benchmarks, generating stable, high-quality videos far beyond training rollout lengths.

</details>


### [88] [See-through: Single-image Layer Decomposition for Anime Characters](https://arxiv.org/abs/2602.03749)
*Jian Lin,Chengze Li,Haoyun Qin,Kwun Wang Chan,Yanghua Jin,Hanyuan Liu,Stephen Chun Wang Choy,Xueting Liu*

Main category: cs.CV

TL;DR: 论文提出了一种自动化框架，能将静态动漫插图转换为可操控的2.5D模型，解决了传统方法需要繁琐手动分割和艺术想象的问题。


<details>
  <summary>Details</summary>
Motivation: 当前专业工作流程需要对动漫角色进行繁琐的手动分割，并且需要艺术家“想象”被遮挡的区域来生成动画，这个过程耗时且需要专业知识。本文旨在通过自动化方法克服这些限制。

Method: 1. 从单张图像分解出完全修复的、语义分层的图层结构；2. 开发可扩展的训练引擎，从商业Live2D模型获取高质量的监督数据；3. 结合扩散式身体部位一致性模块（确保全局几何一致性）和像素级伪深度推理机制；4. 解决复杂分层问题（如交错的头发丝），实现动态图层重建。

Result: 该方法能够生成高保真、可操控的2.5D模型，适用于专业的实时动画应用，效果展示达到了预期的专业水准。

Conclusion: 本框架成功实现了静态动漫插图的自动化2.5D转换，通过创新的数据生成方法和模型架构，有效解决了动漫角色分层复杂的问题，为动漫动画制作提供了高效的解决方案。

Abstract: We introduce a framework that automates the transformation of static anime illustrations into manipulatable 2.5D models. Current professional workflows require tedious manual segmentation and the artistic ``hallucination'' of occluded regions to enable motion. Our approach overcomes this by decomposing a single image into fully inpainted, semantically distinct layers with inferred drawing orders. To address the scarcity of training data, we introduce a scalable engine that bootstraps high-quality supervision from commercial Live2D models, capturing pixel-perfect semantics and hidden geometry. Our methodology couples a diffusion-based Body Part Consistency Module, which enforces global geometric coherence, with a pixel-level pseudo-depth inference mechanism. This combination resolves the intricate stratification of anime characters, e.g., interleaving hair strands, allowing for dynamic layer reconstruction. We demonstrate that our approach yields high-fidelity, manipulatable models suitable for professional, real-time animation applications.

</details>


### [89] [Test-Time Conditioning with Representation-Aligned Visual Features](https://arxiv.org/abs/2602.03753)
*Nicolas Sereyjol-Garros,Ellington Kirby,Victor Letzelter,Victor Besnier,Nermin Samet*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While representation alignment with self-supervised models has been shown to improve diffusion model training, its potential for enhancing inference-time conditioning remains largely unexplored. We introduce Representation-Aligned Guidance (REPA-G), a framework that leverages these aligned representations, with rich semantic properties, to enable test-time conditioning from features in generation. By optimizing a similarity objective (the potential) at inference, we steer the denoising process toward a conditioned representation extracted from a pre-trained feature extractor. Our method provides versatile control at multiple scales, ranging from fine-grained texture matching via single patches to broad semantic guidance using global image feature tokens. We further extend this to multi-concept composition, allowing for the faithful combination of distinct concepts. REPA-G operates entirely at inference time, offering a flexible and precise alternative to often ambiguous text prompts or coarse class labels. We theoretically justify how this guidance enables sampling from the potential-induced tilted distribution. Quantitative results on ImageNet and COCO demonstrate that our approach achieves high-quality, diverse generations. Code is available at https://github.com/valeoai/REPA-G.

</details>


### [90] [RAWDet-7: A Multi-Scenario Benchmark for Object Detection and Description on Quantized RAW Images](https://arxiv.org/abs/2602.03760)
*Mishal Fatima,Shashank Agnihotri,Kanchana Vaishnavi Gandikota,Michael Moeller,Margret Keuper*

Main category: cs.CV

TL;DR: RAWDet-7数据集包含约2.5万训练和7.6万测试RAW图像，用于研究RAW图像在物体检测和描述任务中的优势，支持4/6/8位量化评估。


<details>
  <summary>Details</summary>
Motivation: 传统RGB图像经过ISP处理后可能丢失传感器层面的有用信息，RAW图像保留了更多原始数据，有助于提升模型在物体检测和描述任务中的性能。

Method: 构建大规模RAW图像数据集RAWDet-7，包含多样化相机、光照和环境下的图像，按照MS-COCO和LVIS标准标注七个物体类别，并提供物体级描述和高分辨率sRGB参考图像。

Result: 数据集支持模拟4/6/8位量化来反映真实传感器限制，为RAW图像处理中的检测性能、描述质量和泛化能力提供了基准测试平台。

Conclusion: RAWDet-7数据集填补了该领域研究空白，有助于探索RAW图像在机器视觉任务中的潜力，促进低比特量化RAW图像处理技术发展。

Abstract: Most vision models are trained on RGB images processed through ISP pipelines optimized for human perception, which can discard sensor-level information useful for machine reasoning. RAW images preserve unprocessed scene data, enabling models to leverage richer cues for both object detection and object description, capturing fine-grained details, spatial relationships, and contextual information often lost in processed images. To support research in this domain, we introduce RAWDet-7, a large-scale dataset of ~25k training and 7.6k test RAW images collected across diverse cameras, lighting conditions, and environments, densely annotated for seven object categories following MS-COCO and LVIS conventions. In addition, we provide object-level descriptions derived from the corresponding high-resolution sRGB images, facilitating the study of object-level information preservation under RAW image processing and low-bit quantization. The dataset allows evaluation under simulated 4-bit, 6-bit, and 8-bit quantization, reflecting realistic sensor constraints, and provides a benchmark for studying detection performance, description quality & detail, and generalization in low-bit RAW image processing. Dataset & code upon acceptance.

</details>


### [91] [QVLA: Not All Channels Are Equal in Vision-Language-Action Model's Quantization](https://arxiv.org/abs/2602.03782)
*Yuhao Xu,Yantai Yang,Zhenyang Fan,Yufan Liu,Yuming Li,Bing Li,Zhipeng Zhang*

Main category: cs.CV

TL;DR: 提出了QVLA——首个面向机器人控制的动作中心量化框架，通过细粒度的通道级比特分配策略量化VLA模型，在保持原始性能98.9%的同时将VRAM降至29.2%。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作（VLA）模型计算需求大，阻碍其在资源受限机器人平台上的部署。现有从LLM继承的统一比特量化方法优先考虑数据保真度而忽略动作偏差累积导致任务失败的问题，缺乏对VLA模型量化的系统性分析。

Method: QVLA框架采用通道级比特分配策略，核心机制是通过量化每个通道到不同比特宽度时直接测量最终动作空间敏感性，得到精确的每通道重要性指标，指导将量化和剪枝（0比特）统一在单一框架中的全局优化。

Result: 在LIBERO上，使用QVLA量化的OpenVLA-OFT仅需原始模型29.2%的VRAM，保持98.9%原始性能，实现1.49倍加速，相对LLM衍生方法SmoothQuant性能提升22.6%。

Conclusion: 为机器人领域VLA模型压缩建立了新的原则性基础，推动大规模模型在现实硬件上的部署。

Abstract: The advent of Vision-Language-Action (VLA) models represents a significant leap for embodied intelligence, yet their immense computational demands critically hinder deployment on resource-constrained robotic platforms. Intuitively, low-bit quantization is a prevalent and preferred technique for large-scale model compression. However, we find that a systematic analysis of VLA model's quantization is fundamentally lacking. We argue that naively applying uniform-bit quantization from Large Language Models (LLMs) to robotics is flawed, as these methods prioritize passive data fidelity while ignoring how minor action deviations compound into catastrophic task failures. To bridge this gap, we introduce QVLA, the first action-centric quantization framework specifically designed for embodied control. In a sharp departure from the rigid, uniform-bit quantization of LLM-based methods, QVLA introduces a highly granular, channel-wise bit allocation strategy. Its core mechanism is to directly measure the final action-space sensitivity when quantizing each individual channel to various bit-widths. This process yields a precise, per-channel importance metric that guides a global optimization, which elegantly unifies quantization and pruning (0-bit) into a single, cohesive framework. Extensive evaluations on different baselines demonstrate the superiority of our approach. In the LIBERO, the quantization version of OpenVLA-OFT with our method requires only 29.2% of the original model's VRAM while maintaining 98.9% of its original performance and achieving a 1.49x speedup. This translates to a 22.6% performance improvement over the LLM-derived method SmoothQuant. Our work establishes a new, principled foundation for compressing VLA models in robotics, paving the way for deploying powerful, large-scale models on real-world hardware. Code will be released.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [92] [Precoding-Oriented CSI Feedback Design with Mutual Information Regularized VQ-VAE](https://arxiv.org/abs/2602.02508)
*Xi Chen,Homa Esfahanizadeh,Foad Sohrabi*

Main category: cs.IT

TL;DR: 提出一种基于向量量化变分自编码器的预编码导向CSI反馈框架，通过信息论正则化提升有限反馈带宽下的系统性能。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统中，需要在CSI反馈开销与下行速率之间取得平衡，最大化有限反馈的效用以维持高性能。

Method: 使用向量量化变分自编码器框架，引入可微分互信息下界估计器作为训练正则项，促进在固定反馈预算下有效利用学习到的码本。

Result: 该方法在固定长度反馈下达到与变长神经压缩方案相当的数据率，学到的码字使用更均匀且能捕获与信道状态信息强相关的可解释结构。

Conclusion: 所提框架能有效平衡CSI反馈压缩与系统性能，在有限反馈资源下实现高效的信道状态信息压缩。

Abstract: Efficient channel state information (CSI) compression at the user equipment plays a key role in enabling accurate channel reconstruction and precoder design in massive multiple-input multiple-output systems. A key challenge lies in balancing the CSI feedback overhead with the achievable downlink rate, i.e., maximizing the utility of limited feedback to maintain high system performance. In this work, we propose a precoding-oriented CSI feedback framework based on a vector quantized variational autoencoder, augmented with an information-theoretic regularization. To achieve this, we introduce a differentiable mutual information lower-bound estimator as a training regularizer to promote effective utilization of the learned codebook under a fixed feedback budget. Numerical results demonstrate that the proposed method achieves rates comparable to variable-length neural compression schemes, while operating with fixed-length feedback. Furthermore, the learned codewords exhibit significantly more uniform usage and capture interpretable structures that are strongly correlated with the underlying channel state information.

</details>


### [93] [Rate-Distortion Analysis of Optically Passive Vision Compression](https://arxiv.org/abs/2602.02768)
*Ronald Ogden,David Fridovich-Keil,Takashi Tanaka*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The use of remote vision sensors for autonomous decision-making poses the challenge of transmitting high-volume visual data over resource-constrained channels in real-time. In robotics and control applications, many systems can quickly destabilize, which can exacerbate the issue by necessitating higher sampling frequencies. This work proposes a novel sensing paradigm in which an event camera observes the optically generated cosine transform of a visual scene, enabling high-speed, computation-free video compression inspired by modern video codecs. In this study, we simulate this optically passive vision compression (OPVC) scheme and compare its rate-distortion performance to that of a standalone event camera (SAEC). We find that the rate-distortion performance of the OPVC scheme surpasses that of the SAEC and that this performance gap increases as the spatial resolution of the event camera increases.

</details>


### [94] [Straggler-Aware Coded Polynomial Aggregation](https://arxiv.org/abs/2602.03074)
*Xi Zhong,Jörg Kliewer,Mingyue Ji*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Coded polynomial aggregation (CPA) in distributed computing systems enables the master to directly recover a weighted aggregation of polynomial computations without individually decoding each term, thereby reducing the number of required worker responses. However, existing CPA schemes are restricted to an idealized setting in which the system cannot tolerate stragglers. In this paper, we extend CPA to straggler-aware distributed computing systems with a pre-specified non-straggler pattern, where exact recovery is required for a given collection of admissible non-straggler sets. Our main results show that exact recovery of the desired aggregation is achievable with fewer worker responses than that required by polynomial codes based on individual decoding, and that feasibility is characterized by the intersection structure of the non-straggler patterns. In particular, we establish necessary and sufficient conditions for exact recovery in straggler-aware CPA. We identify an intersection-size threshold that is sufficient to guarantee exact recovery. When the number of admissible non-straggler sets is sufficiently large, we further show that this threshold is necessary in a generic sense. We also provide an explicit construction of feasible CPA schemes whenever the intersection size exceeds the derived threshold. Finally, simulations verify our theoretical results by demonstrating a sharp feasibility transition at the predicted intersection threshold.

</details>


### [95] [Entropy Functions on Two-Dimensional Faces of Polymatroid Region with One Extreme Ray Containing Rank-One Matroid](https://arxiv.org/abs/2602.03363)
*Kaizhe He,Qi Chen*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Characterization of entropy functions is of fundamental importance in information theory. By imposing constraints on their Shannon outer bound, i.e., the polymatroidal region, one obtains the faces of the region and entropy functions on them with special structures. In this paper, we characterize entropy functions on 2-dimensional faces of polymatroid region of degree n with one extreme ray containing rank-1 matroid. We classify all such 2-dimensional faces with another extreme ray containing a matroid into four types.

</details>


### [96] [Universal Costas Matrices: Towards a General Framework for Costas Array Construction](https://arxiv.org/abs/2602.03407)
*Fatih Gulec,Vahid Abolghasemi*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Costas arrays are a special type of permutation matrices with ideal autocorrelation and low cross-correlation properties, making them valuable for radar, wireless communication, and integrated sensing and communication applications. This paper presents a novel unified framework for analyzing and discovering new Costas arrays. We introduce Universal Costas Matrices (UCMs) and Universal Costas Frequency Matrices (UCFMs) and investigate their structural characteristics. A framework integrating UCMs and UCFMs is proposed to pave the way for future artificial intelligence-assisted Costas array discovery. Leveraging the structural properties of UCMs and UCFMs, a reconstruction-based search method is developed to generate UCMs from UCFMs. Numerical results demonstrate that the proposed approach significantly accelerates the search process and enhances structural insight into Costas array generation.

</details>


### [97] [On (Im)possibility of Network Oblivious Transfer via Noisy Channels and Non-Signaling Correlations](https://arxiv.org/abs/2602.03421)
*Hadi Aghaee,Christian Deppe,Holger Boche*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work investigates the fundamental limits of implementing network oblivious transfer via noisy multiple access channels and broadcast channels between honest-but-curious parties when the parties have access to general tripartite non-signaling correlations. By modeling the shared resource as an arbitrary tripartite non-signaling box, we obtain a unified perspective on both the channel behavior and the resulting correlations. Our main result demonstrates that perfect oblivious transfer is impossible. In the asymptotic regime, we further show that even negligible leakage cannot be achieved, as repeated use of the resource amplifies the receiver(s)'s ability to distinguish messages that were not intended for him/them. In contrast, the receiver(s)'s own privacy is not subject to a universal impossibility limitation.

</details>


### [98] [Generative Decompression: Optimal Lossy Decoding Against Distribution Mismatch](https://arxiv.org/abs/2602.03505)
*Saeed R. Khosravirad,Ahmed Alkhateeb,Ingrid van de Voorde*

Main category: cs.IT

TL;DR: 该论文针对损失y压缩中编解码器分布不匹配时的最优解码策略进行研究，提出生成式解压缩方法，通过贝叶斯校正提升解码性能，并扩展到噪声信道和任务导向解码场景。


<details>
  <summary>Details</summary>
Motivation: 在标准通信系统中，编码器采用固定设计分布，而解码器可能获得源真实分布的额外先验信息。这种分布不匹配导致传统解码规则性能下降，需要研究适应真实分布的最优解码策略。

Method: 论文将不匹配量化问题形式化，提出生成式解压缩作为最优重建规则——在量化索引条件下基于真实分布计算条件期望。该方法将经典贝叶斯估计应用于固定编码器约束，并扩展到噪声信道（推导鲁棒软解码规则）和任务导向解码（转为MAP检测）。

Result: 在高斯源和基于深度学习的语义分类实验上，生成式解压缩方法显著缩小了与理想联合优化基准的性能差距，在多数情况下恢复了大部分性能损失，实现了无需修改编码器的高质量自适应重建。

Conclusion: 生成式解压缩为编解码器分布不匹配问题提供了理论框架和实用解决方案，通过解码端的贝叶斯校正实现接近理想性能的自适应重建，突破了传统模块化源信道分离架构在分布不匹配下的效率限制。

Abstract: This paper addresses optimal decoding strategies in lossy compression where the assumed distribution for compressor design mismatches the actual (true) distribution of the source. This problem has immediate relevance in standardized communication systems where the decoder acquires side information or priors about the true distribution that are unavailable to the fixed encoder. We formally define the mismatched quantization problem, demonstrating that the optimal reconstruction rule, termed generative decompression, aligns with classical Bayesian estimation by taking the conditional expectation under the true distribution given the quantization indices and adapting it to fixed-encoder constraints. This strategy effectively performs a generative Bayesian correction on the decoder side, strictly outperforming the conventional centroid rule. We extend this framework to transmission over noisy channels, deriving a robust soft-decoding rule that quantifies the inefficiency of standard modular source--channel separation architectures under mismatch. Furthermore, we generalize the approach to task-oriented decoding, showing that the optimal strategy shifts from conditional mean estimation to maximum a posteriori (MAP) detection. Experimental results on Gaussian sources and deep-learning-based semantic classification demonstrate that generative decompression closes a vast majority of the performance gap to the ideal joint-optimization benchmark, enabling adaptive, high-fidelity reconstruction without modifying the encoder.

</details>


### [99] [Secure Decentralized Pliable Index Coding for Target Data Size](https://arxiv.org/abs/2602.03579)
*Anjali Padmanabhan,Danya Arun Bindhu,Nujoom Sageer Karat,Shanuja Sasi*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Decentralized Pliable Index Coding (DPIC) problem addresses efficient information exchange in distributed systems where clients communicate among themselves without a central server. An important consideration in DPIC is the heterogeneity of side-information and demand sizes. Although many prior works assume homogeneous settings with identical side-information cardinality and single message demands, these assumptions limit real-world applicability where clients typically possess unequal amounts of prior information. In this paper, we study DPIC problem under heterogeneous side-information cardinalities. We propose a transmission scheme that coordinates client broadcasts to maximize coding efficiency while ensuring that each client achieves a common target level $T$. In addition, we impose a strict security constraint that no client acquires more than the target $T$ number of messages, guaranteeing that each client ends up with exactly $T$ messages. We analyze the communication cost incurred by the proposed scheme under this security constraint.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [100] [Super-résolution non supervisée d'images hyperspectrales de télédétection utilisant un entraînement entièrement synthétique](https://arxiv.org/abs/2602.02552)
*Xinxin Xu,Yann Gousseau,Christophe Kervazo,Saïd Ladjal*

Main category: eess.IV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Hyperspectral single image super-resolution (SISR) aims to enhance spatial resolution while preserving the rich spectral information of hyperspectral images. Most existing methods rely on supervised learning with high-resolution ground truth data, which is often unavailable in practice. To overcome this limitation, we propose an unsupervised learning approach based on synthetic abundance data. The hyperspectral image is first decomposed into endmembers and abundance maps through hyperspectral unmixing. A neural network is then trained to super-resolve these maps using data generated with the dead leaves model, which replicates the statistical properties of real abundances. The final super-resolution hyperspectral image is reconstructed by recombining the super-resolved abundance maps with the endmembers. Experimental results demonstrate the effectiveness of our method and the relevance of synthetic data for training.

</details>


### [101] [EchoJEPA: A Latent Predictive Foundation Model for Echocardiography](https://arxiv.org/abs/2602.02603)
*Alif Munim,Adibvafa Fallahpour,Teodora Szasz,Ahmadreza Attarpour,River Jiang,Brana Sooriyakanthan,Maala Sooriyakanthan,Heather Whitney,Jeremy Slivnick,Barry Rubin,Wendy Tsang,Bo Wang*

Main category: eess.IV

TL;DR: EchoJEPA是一种基于超声心动图的Foundation Model，通过JEPA方法在300K患者1800万超声心动图上预训练，显著提升心功能评估准确性，尤其在数据稀缺情况下表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有超声心动图基础模型未能有效分离解剖信号与超声图像中的噪声伪影，需要新的预训练方法提升模型鲁棒性和泛化能力。

Method: 采用潜在预测（JEPA）范式，构建多视图探测框架标准化评估，在300K患者的1800万超声心动图上进行预训练。

Result: 相比先前方法：左心室射血分数估计误差降低19%；仅用1%标注数据达到78.6%准确率（baseline需100%数据仅42.1%）；噪声环境下仅下降2.3%（baseline下降16.8%）；零样本迁移到儿科患者误差降低15%。

Conclusion: 潜在预测是超声基础模型的优越范式，EchoJEPA在减少标注需求、提升模型鲁棒性和跨人群泛化方面表现突出。

Abstract: Foundation models for echocardiography promise to reduce annotation burden and improve diagnostic consistency by learning generalizable representations from large unlabeled video archives. However, current approaches fail to disentangle anatomical signal from the stochastic speckle and acquisition artifacts that dominate ultrasound imagery. We present EchoJEPA, a foundation model for echocardiography trained on 18 million echocardiograms across 300K patients, the largest pretraining corpus for this modality to date. We also introduce a novel multi-view probing framework with factorized stream embeddings that standardizes evaluation under frozen backbones. Compared to prior methods, EchoJEPA reduces left ventricular ejection fraction estimation error by 19% and achieves 87.4% view classification accuracy. EchoJEPA exhibits strong sample efficiency, reaching 78.6% accuracy with only 1% of labeled data versus 42.1% for the best baseline trained on 100%. Under acoustic perturbations, EchoJEPA degrades by only 2.3% compared to 16.8% for the next best model, and transfers zero-shot to pediatric patients with 15% lower error than the next best model, outperforming all fine-tuned baselines. These results establish latent prediction as a superior paradigm for ultrasound foundation models.

</details>


### [102] [Physics-based generation of multilayer corneal OCT data via Gaussian modeling and MCML for AI-driven diagnostic and surgical guidance applications](https://arxiv.org/abs/2602.02755)
*Jinglun Yu,Yaning Wang,Rosalinda Xiong,Ziyi Huang,Kristina Irsch,Jin U. Kang*

Main category: eess.IV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Training deep learning models for corneal optical coherence tomography (OCT) imaging is limited by the availability of large, well-annotated datasets. We present a configurable Monte Carlo simulation framework that generates synthetic corneal B-scan optical OCT images with pixel-level five-layer segmentation labels derived directly from the simulation geometry. A five-layer corneal model with Gaussian surfaces captures curvature and thickness variability in healthy and keratoconic eyes. Each layer is assigned optical properties from the literature and light transport is simulated using Monte Carlo modeling of light transport in multi-layered tissues (MCML), while incorporating system features such as the confocal PSF and sensitivity roll-off. This approach produces over 10,000 high-resolution (1024x1024) image-label pairs and supports customization of geometry, photon count, noise, and system parameters. The resulting dataset enables systematic training, validation, and benchmarking of AI models under controlled, ground-truth conditions, providing a reproducible and scalable resource to support the development of diagnostic and surgical guidance applications in image-guided ophthalmology.

</details>


### [103] [Wide-field high-resolution microscopy via high-speed galvo scanning and real-time mosaicking](https://arxiv.org/abs/2602.02758)
*Ziyi Huang,Rosalinda Xiong,Yaning Wang,Jinglun Yu,Jin U. Kang*

Main category: eess.IV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Wide-field high-resolution microscopy requires fast scanning and accurate image mosaicking to cover large fields of view without compromising image quality. However, conventional galvanometric scanning, particularly under sinusoidal driving, can introduce nonuniform spatial sampling, leading to geometric inconsistencies and brightness variations across the scanned field. To address these challenges, we present an image mosaicking framework for wide-field microscopic imaging that is applicable to both linear and sinusoidal galvanometric scanning strategies. The proposed approach combines a translation-based geometric mosaicking model with region-of-interest (ROI) based brightness correction and seam-aware feathering to improve radiometric consistency across large fields of view. The method relies on calibrated scan parameters and synchronized scan--camera control, without requiring image-content-based registration. Using the proposed framework, wide-field mosaicked images were successfully reconstructed under both linear and sinusoidal scanning strategies, achieving a field of view of up to $2.5 \times 2.5~\mathrm{cm}^2$ with a total acquisition time of approximately $6~\mathrm{s}$ per dataset. Quantitative evaluation shows that both scanning strategies demonstrate improved image quality, including enhanced brightness uniformity, increased contrast-to-noise ratio (CNR), and reduced seam-related artifacts after image processing, while preserving a lateral resolution of $7.81~μ\mathrm{m}$. Overall, the presented framework provides a practical and efficient solution for scan-based wide-field microscopic mosaicking.

</details>


### [104] [Super-Resolution and Denoising of Corneal B-Scan OCT Imaging Using Diffusion Model Plug-and-Play Priors](https://arxiv.org/abs/2602.02795)
*Yaning Wang,Jinglun Yu,Wenhan Guo,Ziyi Huang,Rosalinda Xiong,Yu Sun,Jin U. Kang*

Main category: eess.IV

TL;DR: 提出基于扩散模型即插即用先验的先进超分辨率框架，实现OCT B扫描图像的4倍空间分辨率提升和有效去噪，在真实鱼眼角膜数据上验证了其卓越性能。


<details>
  <summary>Details</summary>
Motivation: 光学相干断层扫描(OCT)在角膜成像中至关重要，但高速采集会降低空间分辨率并增加散斑噪声，影响准确解读。需要开发能够同时提升分辨率和抑制噪声的方法来支持更可靠的临床评估。

Method: 将重建问题构建为贝叶斯逆问题，结合马尔可夫链蒙特卡洛采样和预训练生成先验以加强解剖学一致性。采用扩散模型即插即用先验实现超分辨率和去噪。

Result: 在鱼眼角膜数据集上验证，与双三次插值、监督U-Net基准和替代扩散先验相比，该方法能生成更精确的解剖结构、改善角膜层界划定和更好的噪声抑制。定量结果显示在PSNR、SSIM和感知指标上达到最先进性能。

Conclusion: 这项工作凸显了扩散驱动的即插即用重建在提供高保真、高分辨率OCT成像方面的潜力，支持更可靠的临床评估并实现先进的图像引导干预。该方法可扩展到其他需要稳健超分辨率和去噪的生物医学成像模式。

Abstract: Optical coherence tomography (OCT) is pivotal in corneal imaging for both surgical planning and diagnosis. However, high-speed acquisitions often degrade spatial resolution and increase speckle noise, posing challenges for accurate interpretation. We propose an advanced super-resolution framework leveraging diffusion model plug-and-play (PnP) priors to achieve 4x spatial resolution enhancement alongside effective denoising of OCT Bscan images. Our approach formulates reconstruction as a principled Bayesian inverse problem, combining Markov chain Monte Carlo sampling with pretrained generative priors to enforce anatomical consistency. We comprehensively validate the framework using \emph{in vivo} fisheye corneal datasets, to assess robustness and scalability under diverse clinical settings. Comparative experiments against bicubic interpolation, conventional supervised U-Net baselines, and alternative diffusion priors demonstrate that our method consistently yields more precise anatomical structures, improved delineation of corneal layers, and superior noise suppression. Quantitative results show state-of-the-art performance in peak signal-to-noise ratio, structural similarity index, and perceptual metrics. This work highlights the potential of diffusion-driven plug-and-play reconstruction to deliver high-fidelity, high-resolution OCT imaging, supporting more reliable clinical assessments and enabling advanced image-guided interventions. Our findings suggest the approach can be extended to other biomedical imaging modalities requiring robust super-resolution and denoising.

</details>


### [105] [Real-time topology-aware M-mode OCT segmentation for robotic deep anterior lamellar keratoplasty (DALK) guidance](https://arxiv.org/abs/2602.02798)
*Rosalinda Xiong,Jinglun Yu,Yaning Wang,Ziyi Huang,Jin U. Kang*

Main category: eess.IV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Robotic deep anterior lamellar keratoplasty (DALK) requires accurate real time depth feedback to approach Descemet's membrane (DM) without perforation. M-mode intraoperative optical coherence tomography (OCT) provides high temporal resolution depth traces, but speckle noise, attenuation, and instrument induced shadowing often result in discontinuous or ambiguous layer interfaces that challenge anatomically consistent segmentation at deployment frame rates. We present a lightweight, topology aware M-mode segmentation pipeline based on UNeXt that incorporates anatomical topology regularization to stabilize boundary continuity and layer ordering under low signal to noise ratio conditions. The proposed system achieves end to end throughput exceeding 80 Hz measured over the complete preprocessing inference overlay pipeline on a single GPU, demonstrating practical real time guidance beyond model only timing. This operating margin provides temporal headroom to reject low quality or dropout frames while maintaining a stable effective depth update rate. Evaluation on a standard rabbit eye M-mode dataset using an established baseline protocol shows improved qualitative boundary stability compared with topology agnostic controls, while preserving deployable real time performance.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [106] [Estimation of Cell-to-Cell Variation and State of Health for Battery Modules with Parallel-Connected Cells](https://arxiv.org/abs/2602.02866)
*Qinan Zhou,Jing Sun*

Main category: eess.SY

TL;DR: 该论文提出了一个统一框架，仅使用从模块级增量容量分析和微分电压分析提取的信息，就能准确估计并联电池模块的电池间差异和健康状态。该框架将这两个参数的估计解耦为独立任务，具有高精度、低计算复杂度和强适应性。


<details>
  <summary>Details</summary>
Motivation: 在并联电池模块中，当只能测量模块级信号且无法观察单个电池行为时，准确估计电池间差异和健康状态具有挑战性。现有研究在健康状态估计方面虽有进展，但电池间差异的估计问题仍未解决。

Method: 提出一个统一框架，利用模块级增量容量分析和微分电压分析提取的特征，将电池间差异和健康状态估计解耦为两个独立任务。框架支持不同的电池间差异度量标准，并通过专用算法分别处理，避免相互干扰。

Result: 在三个并联电池组成的模块上进行实验验证，结果表明该框架能系统性选择最优模块级特征，以高置信度和低计算复杂度提供准确的电池间差异和健康状态估计，在不同倍率下保持有效，适合车载实施。

Conclusion: 该论文提出的统一框架成功解决了并联电池模块中电池间差异和健康状态的联合估计问题，仅使用模块级信息即可实现准确、高效且适应性强的评估，为电池管理系统提供了实用的解决方案。

Abstract: Estimating cell-to-cell variation (CtCV) and state of health (SoH) for battery modules with parallel-connected cells is challenging when only module-level signals are measurable and individual cell behaviors remain unobserved. Although progress has been made in SoH estimation, CtCV estimation remains unresolved in the literature. This paper proposes a unified framework that accurately estimates both CtCV and SoH for modules using only module-level information extracted from incremental capacity analysis (ICA) and differential voltage analysis (DVA). With the proposed framework, CtCV and SoH estimations can be decoupled into two separate tasks, allowing each to be solved with dedicated algorithms without mutual interference and providing greater design flexibility. The framework also exhibits strong versatility in accommodating different CtCV metrics, highlighting its general-purpose nature. Experimental validation on modules with three parallel-connected cells demonstrates that the proposed framework can systematically select optimal module-level features for CtCV and SoH estimations, deliver accurate CtCV and SoH estimates with high confidence and low computational complexity, remain effective across different C-rates, and be suitable for onboard implementation.

</details>


### [107] [Hybrid-Field Channel Estimation for XL-MIMO Systems: Dictionary-based Sparse Signal Recovery](https://arxiv.org/abs/2602.02942)
*David William Marques Guerra,Taufik Abrao*

Main category: eess.SY

TL;DR: 论文提出了一种用于XL-MIMO系统的混合场信道估计方法，无需预先知道信道稀疏度、近场/远场比例等参数，通过自适应确定路径数量和参数细化的稀疏恢复框架实现高效信道重构。


<details>
  <summary>Details</summary>
Motivation: XL-MIMO系统的大阵列孔径导致混合场传播问题，传统信道估计方法需要先验参数信息且无法有效处理FF/NF共存的场景，因此需要开发能够自适应的统一模型。

Method: 该方法采用统一的FF+NF叠加模型，通过稀疏恢复框架进行信道估计，利用组合字典初始化支持集，并通过残差停止规则自适应确定路径数量，同时采用连续参数细化来减少网格失配问题。

Result: 仿真结果表明该估计器能够在LoS和NLoS条件下实现准确的混合场信道重建，为XL-MIMO提供了一种实用且计算高效的解决方案。

Conclusion: 该方法为XL-MIMO系统中的混合场场景提供了有效的信道估计方案，能够自适应处理信道的稀疏特性，消除对先验参数的依赖，并在多种条件下表现出优异的性能。

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems are a key technology for future wireless networks, but the large array aperture naturally creates a hybrid-field (HF) propagation regime in which far-field (FF) planar-wave and near-field (NF) spherical-wave components coexist. This work considers the problem of HF channel estimation (CE) and introduces a unified model that superimposes FF and NF contributions according to the Rayleigh distance boundary. By exploiting the inherent sparsity of the channel in the angular and polar domains, we formulate the estimation task as a sparse recovery problem. Unlike conventional approaches that require prior knowledge of the channel sparsity level, the proposed method operates without requiring knowledge of the sparsity level L and the NF/FF ratio γ, which are used only for synthetic channel generation in simulations. The channel estimator determines the number of paths adaptively through a residual-based stopping rule. A combined FF/NF dictionary is employed to initialize the support, and each selected atom undergoes continuous parameter refinement to mitigate grid mismatch. Simulation results demonstrate that the proposed estimator achieves accurate HF channel reconstruction under both line-of-sight (LoS) and non-line-of-sight (NLoS) conditions, offering a practical and computationally efficient solution for XL-MIMO systems.
  Extremely Large-Scale MIMO (XL-MIMO); Channel State Information (CSI); Channel estimation (CE); hybrid-field (HF) wave propagation; near-field (NF) spherical wave model; far-field (FF) planar wave model

</details>


### [108] [Fast Diffusion with Physics-Correction for ACOPF](https://arxiv.org/abs/2602.03020)
*Shashank Shekhar,Abhinav Karn,Kris Keshav,Shivam Bansal,Parikshit Pareek*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Generating large-scale, physically consistent AC Optimal Power Flow (ACOPF) datasets is essential for modern data-driven power system applications. The central challenge lies in balancing solution accuracy with computational efficiency. Recent diffusion-based generative models produce high-quality samples; however, their slow sampling procedures limit practical scalability. In this work, we argue that exact physical feasibility is ultimately enforced by power flow solvers or projection steps, and therefore the generative model only needs to produce good initializations rather than perfectly feasible solutions. Based on this insight, we propose a fast diffusion framework using Denoising Diffusion Implicit Models (DDIM) combined with physics-guided corrections during sampling. The proposed method replaces slow stochastic refinement with a small number of deterministic steps and explicit constraint guidance. Experiments on IEEE 6-, 24-, and 118-bus systems show that our approach achieves up to 20 times faster sampling than standard diffusion models while maintaining comparable statistical accuracy and physical consistency. This makes the method well suited for scalable OPF dataset generation and practical power system learning tasks. We release the implementation code at https://github.com/PSquare-Lab/DDIM_OPF.

</details>


### [109] [ProOPF: Benchmarking and Improving LLMs for Professional-Grade Power Systems Optimization Modeling](https://arxiv.org/abs/2602.03070)
*Chao Shen,Zihan Guo,Xu Wan,Zhenghao Yang,Yifan Zhang,Wengi Huang,Jie Song,Zongyan Zhang,Mingyang Sun*

Main category: eess.SY

TL;DR: 该研究针对电力系统中可再生能源渗透增加带来的运行不确定性挑战，提出了基于大语言模型的自动化最优潮流建模数据集和基准测试。


<details>
  <summary>Details</summary>
Motivation: 可再生能源渗透率的提高给电力系统运行带来了巨大的不确定性，需要频繁调整调度目标和约束条件，这对专家密集的近实时建模工作流提出了挑战。大语言模型通过语义推理和代码合成，能够将自然语言操作需求转化为可执行的优化模型，为自动化这一过程提供了有前景的途径。

Method: 研究引入了ProOPF-D数据集和ProOPF-B基准测试：ProOPF-D包含12K个实例，将自然语言请求与参数调整和结构扩展配对到典型的最优潮流模型中，并提供可执行实现；ProOPF-B提供121个专家标注的测试用例和真实代码，支持在具体和抽象两种最优潮流建模机制下进行端到端评估。

Result: 开发了专业级的最优潮流建模数据集和基准测试框架，填补了当前大语言模型在电力系统优化建模领域缺乏严谨评估工具的空白。

Conclusion: ProOPF-D和ProOPF-B为大语言模型在电力系统最优潮流建模中的应用提供了系统化的评估标准和数据支持，有助于推动自动化建模技术的发展，应对可再生能源并网带来的运行挑战。

Abstract: Growing renewable penetration introduces substantial uncertainty into power system operations, necessitating frequent adaptation of dispatch objectives and constraints and challenging expertise-intensive, near-real-time modeling workflows. Large Language Models (LLMs) provide a promising avenue for automating this process by translating natural-language (NL) operational requirements into executable optimization models via semantic reasoning and code synthesis. Yet existing LLM datasets and benchmarks for optimization modeling primarily target coarse-grained cross-domain generalization, offering limited, rigorous evaluation in power-system settings, particularly for Optimal Power Flow (OPF). We therefore introduce \textbf{ProOPF-D} and \textbf{ProOPF-B}, a dataset and benchmark for professional-grade OPF modeling: ProOPF-D contains 12K instances pairing NL requests with parameter adjustments and structural extensions to a canonical OPF, together with executable implementations; ProOPF-B provides 121 expert-annotated test cases with ground-truth code, enabling end-to-end evaluation under both concrete and abstract OPF modeling regimes.

</details>


### [110] [Power Reserve Procurement Considering Dependent Random Variables with PCE](https://arxiv.org/abs/2602.03272)
*Nicola Ramseyer,Matthieu Jacobs,Mario Paolone*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents an approach for the modelling of dependent random variables using generalised polynomial chaos. This allows to write chance-constrained optimization problems with respect to a joint distribution modelling dependencies between different stochastic inputs. Arbitrary dependencies are modelled by using Gaussian copulas to construct the joint distribution. The paper exploits the problem structure and develops suitable transformations to ensure tractability. The proposed method is applied to a probabilistic power reserve procurement problem. The effectiveness of the method to capture dependencies is shown by comparing the approach with a standard approach considering independent random variables.

</details>


### [111] [Dynamics of Implicit Time-Invariant Max-Min-Plus-Scaling Discrete-Event Systems](https://arxiv.org/abs/2602.03346)
*Sreeshma Markkassery,Ton van den Boom,Bart De Schutter*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Max-min-plus-scaling (MMPS) systems generalize max-plus, min-plus and max-min-plus models with more flexibility in modelling discrete-event dynamics. Especially, implicit MMPS models capture a wide range of real world discrete-event applications. This article analyzes the dynamics of an autonomous, time-invariant implicit MMPS system in a discrete-event framework. First, we provide sufficient conditions under which an implicit MMPS system admits at least one solution to its state-space representation. Then, we analyze its global behavior by determining the key parameters; the growth rates and fixed points. For a solvable MMPS system, we assess the local behavior of the system around its set of fixed points via a normalization procedure. Further, we present the notion of stability for the normalized system. A case study of the urban railway network substantiates the theoretical results.

</details>


### [112] [When control meets large language models: From words to dynamics](https://arxiv.org/abs/2602.03433)
*Komeil Nosrati,Aleksei Tepljakov,Juri Belikov,Eduard Petlenkov*

Main category: eess.SY

TL;DR: 将大语言模型与控制理论的双向关系构建为一个连续统一体，研究两者如何相互促进


<details>
  <summary>Details</summary>
Motivation: 大语言模型正在转变为需要调控的复杂动态系统，同时也能增强控制系统设计和工程工作流程。需要建立双向理论框架来理解这种互惠关系。

Method: 通过四个层次构建分析框架：1）研究LLMs如何直接辅助控制器设计、间接增强研究流程；2）应用控制理论优化LLM输出和内部表示；3）将LLMs建模为状态空间动态系统；4）识别关键技术挑战和未来方向

Result: 建立了一个全面的双向连续统一体框架，展示了LLMs与控制理论的多层次整合潜力，为可控、可解释LLMs的发展提供理论基础

Conclusion: 需要系统研究LLM与控制理论的双向关系，最终目标是开发出与机电系统同样可信赖和鲁棒的LLM系统，确保其安全服务社会

Abstract: While large language models (LLMs) are transforming engineering and technology through enhanced control capabilities and decision support, they are simultaneously evolving into complex dynamical systems whose behavior must be regulated. This duality highlights a reciprocal connection in which prompts support control system design while control theory helps shape prompts to achieve specific goals efficiently. In this study, we frame this emerging interconnection of LLM and control as a bidirectional continuum, from prompt design to system dynamics. First, we investigate how LLMs can advance the field of control in two distinct capacities: directly, by assisting in the design and synthesis of controllers, and indirectly, by augmenting research workflows. Second, we examine how control concepts help LLMs steer their trajectories away from undesired meanings, improving reachability and alignment via input optimization, parameter editing, and activation-level interventions. Third, we look into deeper integrations by treating LLMs as dynamic systems within a state-space framework, where their internal representations are closely linked to external control loops. Finally, we identify key challenges and outline future research directions to understand LLM behavior and develop interpretable and controllable LLMs that are as trustworthy and robust as their electromechanical counterparts, thereby ensuring they continue to support and safeguard society.

</details>


### [113] [A Comparison of Set-Based Observers for Nonlinear Systems](https://arxiv.org/abs/2602.03646)
*Nico Holzinger,Matthias Althoff*

Main category: eess.SY

TL;DR: 论文对非线性离散时间系统的集合状态估计器进行了统一评估，在CORA框架下实现并比较了代表性方法，重点考察计算量、可扩展性和结果保守性。


<details>
  <summary>Details</summary>
Motivation: 现有集合状态估计方法众多但缺乏统一评估，为安全关键应用提供可靠的系统状态边界分析需要全面的比较研究。

Method: 在CORA框架中选择了代表性集合状态估计器实现，通过标准测试平台进行客观对比，分析计算复杂度、扩展能力和边界保守性。

Result: 研究揭示了不同观测器类型和集合表示之间的特征权衡关系，并提供了公开的实现代码支持复现性。

Conclusion: 这是首个广泛、工具支持的非线性离散时间系统保证状态估计器比较研究，为未来方法选择和开发提供了实践指导。

Abstract: Set-based state estimation computes sets of states consistent with a system model given bounded sets of disturbances and noise. Bounding the set of states is crucial for safety-critical applications so that one can ensure that all specifications are met. While numerous approaches have been proposed for nonlinear discrete-time systems, a unified evaluation under comparable conditions is lacking. This paper reviews and implements a representative selection of set-based observers within the CORA framework. To provide an objective comparison, the methods are evaluated on common benchmarks, and we examine computational effort, scalability, and the conservatism of the resulting state bounds. This study highlights characteristic trade-offs between observer categories and set representations, as well as practical considerations arising in their implementation. All implementations are made publicly available to support reproducibility and future development. This paper thereby offers the first broad, tool-supported comparison of guaranteed state estimators for nonlinear discrete-time systems.

</details>


### [114] [Input-to-State Safe Backstepping: Robust Safety-Critical Control with Unmatched Uncertainties](https://arxiv.org/abs/2602.03691)
*Max H. Cohen,Pio Ong,Aaron D. Ames*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Guaranteeing safety in the presence of unmatched disturbances -- uncertainties that cannot be directly canceled by the control input -- remains a key challenge in nonlinear control. This paper presents a constructive approach to safety-critical control of nonlinear systems with unmatched disturbances. We first present a generalization of the input-to-state safety (ISSf) framework for systems with these uncertainties using the recently developed notion of an Optimal Decay CBF, which provides more flexibility for satisfying the associated Lyapunov-like conditions for safety. From there, we outline a procedure for constructing ISSf-CBFs for two relevant classes of systems with unmatched uncertainties: i) strict-feedback systems; ii) dual-relative-degree systems, which are similar to differentially flat systems. Our theoretical results are illustrated via numerical simulations of an inverted pendulum and planar quadrotor.

</details>


### [115] [Mitigating Timing-Based Attacks in Real-Time Cyber-Physical Systems](https://arxiv.org/abs/2602.03757)
*Arkaprava Sain,Sunandan Adhikary,Soumyajit Dey*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Real-time cyber-physical systems depend on deterministic task execution to guarantee safety and correctness. Unfortunately, this determinism can unintentionally expose timing information that enables adversaries to infer task execution patterns and carry out timing-based attacks targeting safety-critical control tasks. While prior defenses aim to obscure schedules through randomization or isolation, they typically neglect the implications of such modifications on closed-loop control behavior and real-time feasibility. This work studies the problem of securing real-time control workloads against timing inference attacks while explicitly accounting for both schedulability constraints and control performance requirements. We present a scheduling-based mitigation approach that introduces bounded timing perturbations to control task executions in a structured manner, reducing adversarial opportunities without violating real-time guarantees. The framework jointly considers worst-case execution behavior and the impact of execution delays on control performance, enabling the system to operate within predefined safety and performance limits. Through experimental evaluation on representative task sets and control scenarios, the proposed approach demonstrates that exposure to timing-based attacks can be significantly reduced while preserving predictable execution and acceptable control quality.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [116] [UNSO: Unified Newton Schulz Orthogonalization](https://arxiv.org/abs/2602.02500)
*Chen Hu,Qianxi Zhao,Yuming Li,Mingyu Zhou,Xiyin Li*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Newton-Schulz (NS) iteration has gained increasing interest for its role in the Muon optimizer and the Stiefel manifold. However, the conventional NS iteration suffers from inefficiency and instability. Although various improvements have been introduced to NS iteration, they fail to deviate from the conventional iterative paradigm, which could increase computation burden largely due to the matrix products along the long dimension repeatedly. To address this, we consolidate the iterative structure into a unified framework, named Unified Newton-Schulz Orthogonalization (UNSO). To do so, we could avoid a polynomial expansion. Instead, we evaluate the role of each matrix power, remove the insignificant terms, and provide a recommended polynomial with learnable coefficients. These learnable coefficients are then optimized, and achieve an outstanding performance with stable convergence. The code of our method is available: https://github.com/greekinRoma/Unified_Newton_Schulz_Orthogonalization.

</details>


### [117] [Sparse Adapter Fusion for Continual Learning in NLP](https://arxiv.org/abs/2602.02502)
*Min Zeng,Xi Chen,Haiqin Yang,Yike Guo*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Continual learning in natural language processing plays a crucial role in adapting to evolving data and preventing catastrophic forgetting. Despite significant progress, existing methods still face challenges, such as inefficient parameter reuse across tasks, risking catastrophic forgetting when tasks are dissimilar, and the unnecessary introduction of new parameters for each task, which hampers knowledge sharing among similar tasks. To tackle these issues, we propose a Sparse Adapter Fusion Method (SAFM), which dynamically fuses old and new adapters to address these challenges. SAFM operates in two stages: the decision stage and the tuning stage. In the decision stage, SAFM determines whether to incorporate a new adapter, reuse an existing one, or add an empty adapter. The architecture search procedure, designed to prioritize reusing or adding empty adapters, minimizes parameter consumption and maximizes reuse. In the tuning stage, SAFM especially facilitates a layer-wise loss to encourage differentiation between adapters, effectively capturing knowledge within the same task. Experimental results consistently show that SAFM outperforms state-of-the-art (SOTA) methods, achieving comparable performance while utilizing less than 60% of the parameters.

</details>


### [118] [Learning ORDER-Aware Multimodal Representations for Composite Materials Design](https://arxiv.org/abs/2602.02513)
*Xinyao Li,Hangwei Qian,Jingjing Li,Ivor Tsang*

Main category: cs.LG

TL;DR: 提出了ORDER多模态预训练框架，通过序数性对齐解决复合材料设计中连续非线性空间和数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 复合材料设计空间连续非线性，缺乏明确图结构，现有基于对齐的多模态方法无法在极端数据稀缺下处理连续设计空间

Method: 引入ORDinal-aware imagE-tabulaR alignment (ORDER)框架，以序数性为核心原则建立复合材料表示，确保相似性能材料在潜在空间中占据邻近区域

Result: 在公开纳米纤维复合材料和内部碳纤维T700数据集上，ORDER在性能预测、跨模态检索和微结构生成任务上均优于现有多模态基线方法

Conclusion: ORDER通过序数性对齐原则有效捕捉复合材料连续性质，实现了在数据稀缺条件下的可靠复合材料表示学习

Abstract: Artificial intelligence (AI) has shown remarkable success in materials discovery and property prediction, particularly for crystalline and polymer systems where material properties and structures are dominated by discrete graph representations. Such graph-central paradigm breaks down on composite materials, which possess continuous and nonlinear design spaces that lack well-defined graph structures. General composite descriptors, e.g., fiber volume and misalignment angle, cannot fully capture the fiber distributions that fundamentally determine microstructural characteristics, necessitating the integration of heterogeneous data sources through multimodal learning. Existing alignment-oriented multimodal frameworks have proven effective on abundant crystal or polymer data under discrete, unique graph-property mapping assumptions, but fail to address the highly continuous composite design space under extreme data scarcity. In this work, we introduce ORDinal-aware imagE-tabulaR alignment (ORDER), a multimodal pretraining framework that establishes ordinality as a core principle for composite material representations. ORDER ensures that materials with similar target properties occupy nearby regions in the latent space, which effectively preserves the continuous nature of composite properties and enables meaningful interpolation between sparsely observed designs. We evaluate ORDER on a public Nanofiber-enforced composite dataset and an internally curated dataset that simulates the construction of carbon fiber T700 with diverse fiber distributions. ORDER achieves consistent improvements over state-of-the-art multimodal baselines across property prediction, cross-modal retrieval, and microstructure generation tasks.

</details>


### [119] [GraphDancer: Training LLMs to Explore and Reason over Graphs via Curriculum Reinforcement Learning](https://arxiv.org/abs/2602.02518)
*Yuyang Bai,Zhuofeng Li,Ping Nie,Jianwen Xie,Yu Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) increasingly rely on external knowledge to improve factuality, yet many real-world knowledge sources are organized as heterogeneous graphs rather than plain text. Reasoning over such graph-structured knowledge poses two key challenges: (1) navigating structured, schema-defined relations requires precise function calls rather than similarity-based retrieval, and (2) answering complex questions often demands multi-hop evidence aggregation through iterative information seeking. We propose GraphDancer, a reinforcement learning (RL) framework that teaches LLMs to navigate graphs by interleaving reasoning and function execution. To make RL effective for moderate-sized LLMs, we introduce a graph-aware curriculum that schedules training by the structural complexity of information-seeking trajectories using an easy-to-hard biased sampler. We evaluate GraphDancer on a multi-domain benchmark by training on one domain only and testing on unseen domains and out-of-distribution question types. Despite using only a 3B backbone, GraphDancer outperforms baselines equipped with either a 14B backbone or GPT-4o-mini, demonstrating robust cross-domain generalization of graph exploration and reasoning skills. Our code and models can be found at https://yuyangbai.com/graphdancer/ .

</details>


### [120] [Scaled Dot-Product Attention implements projection of inputs onto a common surface](https://arxiv.org/abs/2602.02521)
*Terence D Sanger*

Main category: cs.LG

TL;DR: 重新解读SDPA为输入向量在由自身确定的公共曲面上的投影，揭示其非线性依赖发现能力


<details>
  <summary>Details</summary>
Motivation: 传统基于'查询、键、值'概念的SDPA解释难以与数学信号处理方法相协调，需要更合理的数学解释来理解其工作原理和优势

Method: 将SDPA改写为数学等价的投影形式，将输入向量投影到由输入自身确定的公共曲面上

Result: 发现SDPA能够揭示输入中时间相关和上下文相关的非线性依赖关系，提高前馈和学习算法的速度，并启发潜在的扩展

Conclusion: SDPA实际上是发现由输入向量所在曲面确定的时变上下文含义，为SDPA在具有时变局部非线性依赖的时间序列数据中的应用提供了有力理论依据

Abstract: Scaled dot-product attention (SDPA) is a fundamental component responsible for the success of large-language models and other nonlinear signal processing applications. The rationale for SDPA has been based upon "query, key, value" concepts borrowed from database theory, but these concepts are difficult to reconcile with standard methods in mathematical signal processing. We show that SDPA can be rewritten in a different but mathematically equivalent form as a projection of the input vectors onto a common surface determined by the inputs themselves. Therefore SDPA discovers nonlinear dependencies in the input that are time-dependent and context-dependent. The rewritten form of SDPA permits increased speed of both feedforward and learning algorithms, but more importantly suggests potential extensions. In the context of language, we re-interpret the role of SDPA as finding a time-dependent contextual meaning determined by the surface on which the set of input vectors lies. Input token embeddings are then modified by the local context surface. This interpretation differs substantially from the concept of "self-attention", and provides a strong justification for the use of SDPA for time-series data with time-varying local nonlinear dependencies.

</details>


### [121] [IceBench-S2S: A Benchmark of Deep Learning for Challenging Subseasonal-to-Seasonal Daily Arctic Sea Ice Forecasting in Deep Latent Space](https://arxiv.org/abs/2602.02567)
*Jingyi Xu,Shengnan Wang,Weidong Yang,Siwei Tu,Lei Bai,Ben Fei*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Arctic sea ice plays a critical role in regulating Earth's climate system, significantly influencing polar ecological stability and human activities in coastal regions. Recent advances in artificial intelligence have facilitated the development of skillful pan-Arctic sea ice forecasting systems, where data-driven approaches showcase tremendous potential to outperform conventional physics-based numerical models in terms of accuracy, computational efficiency and forecasting lead times. Despite the latest progress made by deep learning (DL) forecasting models, most of their skillful forecasting lead times are confined to daily subseasonal scale and monthly averaged values for up to six months, which drastically hinders their deployment for real-world applications, e.g., maritime routine planning for Arctic transportation and scientific investigation. Extending daily forecasts from subseasonal to seasonal (S2S) scale is scientifically crucial for operational applications. To bridge the gap between the forecasting lead time of current DL models and the significant daily S2S scale, we introduce IceBench-S2S, the first comprehensive benchmark for evaluating DL approaches in mitigating the challenge of forecasting Arctic sea ice concentration in successive 180-day periods. It proposes a generalized framework that first compresses spatial features of daily sea ice data into a deep latent space. The temporally concatenated deep features are subsequently modeled by DL-based forecasting backbones to predict the sea ice variation at S2S scale. IceBench-S2S provides a unified training and evaluation pipeline for different backbones, along with practical guidance for model selection in polar environmental monitoring tasks.

</details>


### [122] [IMU-1: Sample-Efficient Pre-training of Small Language Models](https://arxiv.org/abs/2602.02522)
*George Grigorev*

Main category: cs.LG

TL;DR: 介绍了IMU-1，一个430M参数的语言模型，在72B token上训练后，性能接近那些用56倍更多数据训练的模型的基准表现。描述了包含架构、优化和多阶段训练在内的完整训练方案。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过优化的训练方案和模型设计，以相对较少的数据（72B token）达到与用大量数据（56倍更多）训练的模型相当的性能，提升训练效率和资源利用率。

Method: 结合了QK-norm注意力、per-head门控、残差值、LayerNorm缩放等架构改进，以及NorMuon优化器（带谨慎权重衰减）、muP参数化、三阶段训练计划和事后检查点EMA等技术。

Result: IMU-1模型在430M参数规模下，仅用72B token训练，就能接近基准模型用56倍更多数据训练的表现，验证了所提训练方案的有效性。

Conclusion: 通过精心设计的训练方案，可以在显著减少训练数据量的情况下达到与大规模数据训练相当的性能，这为高效训练高性能语言模型提供了可行的路径。

Abstract: We present IMU-1, a 430M-parameter language model trained on 72B tokens that approaches the benchmark performance of models trained on 56x more data. We describe a validated training recipe combining recent architectural interventions (QK-norm attention, per-head gating, value residuals, LayerNorm scaling) with optimization advances (NorMuon with cautious weight decay, muP parametrization) and a three-stage training schedule with post-hoc checkpoint EMA. We provide ablations for each component and release code, weights and data to enable reproduction: https://huggingface.co/thepowerfuldeez/imu1_base

</details>


### [123] [Information-Theoretic Multi-Model Fusion for Target-Oriented Adaptive Sampling in Materials Design](https://arxiv.org/abs/2602.03319)
*Yixuan Zhang,Zhiyuan Li,Weijia He,Mian Dai,Chen Shen,Teng Long,Hongbin Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Target-oriented discovery under limited evaluation budgets requires making reliable progress in high-dimensional, heterogeneous design spaces where each new measurement is costly, whether experimental or high-fidelity simulation. We present an information-theoretic framework for target-oriented adaptive sampling that reframes optimization as trajectory discovery: instead of approximating the full response surface, the method maintains and refines a low-entropy information state that concentrates search on target-relevant directions. The approach couples data, model beliefs, and physics/structure priors through dimension-aware information budgeting, adaptive bootstrapped distillation over a heterogeneous surrogate reservoir, and structure-aware candidate manifold analysis with Kalman-inspired multi-model fusion to balance consensus-driven exploitation and disagreement-driven exploration. Evaluated under a single unified protocol without dataset-specific tuning, the framework improves sample efficiency and reliability across 14 single- and multi-objective materials design tasks spanning candidate pools from $600$ to $4 \times 10^6$ and feature dimensions from $10$ to $10^3$, typically reaching top-performing regions within 100 evaluations. Complementary 20-dimensional synthetic benchmarks (Ackley, Rastrigin, Schwefel) further demonstrate robustness to rugged and multimodal landscapes.

</details>


### [124] [The "Robert Boulton" Singularity: Semantic Tunneling and Manifold Unfolding in Recursive AI](https://arxiv.org/abs/2602.02526)
*Pengyue Hou*

Main category: cs.LG

TL;DR: 本文揭示了生成式AI在递归合成数据训练中，Perplexity指标在上下文稳定时的欺骗性，发现了一种称为“语义隧道”的失效模式，并提出了MNCIS框架通过ASNC操作实现“流形展开”以对抗语义多样性崩溃。


<details>
  <summary>Details</summary>
Motivation: 常规的Perplexity指标在上下文稳定的训练过程中具有误导性，无法检测到生成模型语义多样性的灾难性丧失。本文旨在揭示这种隐藏的失败模式，并提出有效的解决方案来维持模型的语义多样性。

Method: 使用严格的滑动窗口协议（N=1500）分析递归合成数据训练的稳定性。针对发现的“语义隧道”问题，应用多尺度负耦合信息系统（MNCIS）框架，特别是自适应谱负耦合（ASNC）作为拓扑操作符，实现“流形展开”。

Result: 基准模型虽然保持了高语法流畅性（PPL约83.9），但在七代内语义多样性就灾难性丧失，收敛到单一低熵叙事吸引子（Robert Boulton奇点）。MNCIS框架能有效将有效秩从各向异性的3.62扩展到超多样性的5.35，构建抵抗语义吸引子引力并保留训练数据长尾分布的“人工流形”。

Conclusion: Perplexity在上下文稳定训练中是一个欺骗性指标，无法检测语义多样性崩溃。MNCIS框架中的ASNC操作能够有效对抗“语义隧道”现象，通过流形展开维持生成模型的语义多样性，为生成式AI的稳定训练提供了新范式。

Abstract: The stability of generative artificial intelligence trained on recursive synthetic data is conventionally monitored via Perplexity (PPL). We demonstrate that PPL is a deceptive metric in context-stabilized regimes (L=128). Using a rigorous sliding-window protocol (N=1500), we identify a novel failure mode termed "Semantic Tunneling." While the Baseline model maintains high grammatical fluency (PPL approx. 83.9), it suffers a catastrophic loss of semantic diversity, converging within seven generations to a single, low-entropy narrative attractor: the "Robert Boulton" Singularity. This phenomenon represents a total collapse of the latent manifold (Global Effective Rank 3.62 -> 2.22), where the model discards diverse world knowledge to optimize for statistically safe syntactic templates. To address this, we apply the Multi-Scale Negative Coupled Information Systems (MNCIS) framework recently established in Hou (2026) [arXiv:2601.11594]. We demonstrate that Adaptive Spectral Negative Coupling (ASNC) acts as a topological operator that actively induces "Manifold Unfolding." MNCIS forces the model to expand its effective rank from the anisotropic baseline of 3.62 to a hyper-diverse state of 5.35, effectively constructing an "Artificial Manifold" that resists the gravitational pull of semantic attractors and preserves the long-tail distribution of the training data.

</details>


### [125] [Incident-Guided Spatiotemporal Traffic Forecasting](https://arxiv.org/abs/2602.02528)
*Lixiang Fan,Bohao Li,Tao Zou,Bowen Du,Junchen Ye*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent years have witnessed the rapid development of deep-learning-based, graph-neural-network-based forecasting methods for modern intelligent transportation systems. However, most existing work focuses exclusively on capturing spatio-temporal dependencies from historical traffic data, while overlooking the fact that suddenly occurring transportation incidents, such as traffic accidents and adverse weather, serve as external disturbances that can substantially alter temporal patterns. We argue that this issue has become a major obstacle to modeling the dynamics of traffic systems and improving prediction accuracy, but the unpredictability of incidents makes it difficult to observe patterns from historical sequences. To address these challenges, this paper proposes a novel framework named the Incident-Guided Spatiotemporal Graph Neural Network (IGSTGNN). IGSTGNN explicitly models the incident's impact through two core components: an Incident-Context Spatial Fusion (ICSF) module to capture the initial heterogeneous spatial influence, and a Temporal Incident Impact Decay (TIID) module to model the subsequent dynamic dissipation. To facilitate research on the spatio-temporal impact of incidents on traffic flow, a large-scale dataset is constructed and released, featuring incident records that are time-aligned with traffic time series. On this new benchmark, the proposed IGSTGNN framework is demonstrated to achieve state-of-the-art performance. Furthermore, the generalizability of the ICSF and TIID modules is validated by integrating them into various existing models.

</details>


### [126] [Formulating Reinforcement Learning for Human-Robot Collaboration through Off-Policy Evaluation](https://arxiv.org/abs/2602.02530)
*Saurav Singh,Rodney Sanchez,Alexander Ororbia,Jamison Heard*

Main category: cs.LG

TL;DR: 提出了一种基于离线策略评估的新RL框架，利用历史交互数据自动选择状态空间和奖励函数，减少对实时环境交互和人工反馈的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在现实世界中部署时需要大量人工参与和实时环境交互，成本高且不实用，特别是在复杂和安全关键的应用中。

Method: 使用离线策略评估（OPE）对多个候选状态表示和奖励函数进行系统评估，训练离线RL智能体并应用OPE估计策略性能，基于OPE指标选择能产生高性能策略的状态空间和奖励函数。

Result: 在OpenAI Gym的Lunar Lander环境和NASA-MATB-II人类受试者研究环境中验证了方法的有效性，后者特别评估了该方法在人机协作场景中的实际适用性。

Conclusion: 该工作通过数据驱动的基于OPE的评估自动化关键的RL设计决策，增强了离线RL在现实世界环境中的可行性和可扩展性，为复杂的人机交互场景提供了更可靠、有效和可持续的RL方案。

Abstract: Reinforcement learning (RL) has the potential to transform real-world decision-making systems by enabling autonomous agents to learn from experience. Deploying RL in real-world settings, especially in the context of human-robot interaction, requires defining state representations and reward functions, which are critical for learning efficiency and policy performance. Traditional RL approaches often rely on domain expertise and trial-and-error, necessitating extensive human involvement as well as direct interaction with the environment, which can be costly and impractical, especially in complex and safety-critical applications. This work proposes a novel RL framework that leverages off-policy evaluation (OPE) for state space and reward function selection, using only logged interaction data. This approach eliminates the need for real-time access to the environment or human-in-the-loop feedback, greatly reducing the dependency on costly real-time interactions. The proposed approach systematically evaluates multiple candidate state representations and reward functions by training offline RL agents and applying OPE to estimate policy performance. The optimal state space and reward function are selected based on their ability to produce high-performing policies under OPE metrics. Our method is validated on two environments: the Lunar Lander environment by OpenAI Gym, which provides a controlled setting for assessing state space and reward function selection, and a NASA-MATB-II human subjects study environment, which evaluates the approach's real-world applicability to human-robot teaming scenarios. This work enhances the feasibility and scalability of offline RL for real-world environments by automating critical RL design decisions through a data-driven OPE-based evaluation, enabling more reliable, effective, and sustainable RL formulation for complex human-robot interaction settings.

</details>


### [127] [Hypersonic Flow Control: Generalized Deep Reinforcement Learning for Hypersonic Intake Unstart Control under Uncertainty](https://arxiv.org/abs/2602.02531)
*Trishit Mondal,Ameya D. Jagtap*

Main category: cs.LG

TL;DR: 本文使用深度强化学习实现了高超声速进气道不起动现象的主动流动控制，在Mach 5条件下成功稳定了进气道工作，并展示了良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 高超声速（Mach 5及以上）条件下的进气道不起动现象是吸气式推进系统面临的主要挑战，强激波-边界层相互作用和快速压力波动会破坏进气道稳定运行，需要有效的实时控制策略。

Method: 采用基于深度强化学习的主动流动控制策略，结合自适应网格细化的高保真CFD求解器，精确捕捉激波运动、边界层动力学和流动分离等关键流动特征，学习物理一致的实时控制策略。

Result: DRL控制器在广泛代表燃烧室条件变化的背压范围内都稳定了进气道，对未见过的背压水平、雷诺数和传感器配置表现出零样本泛化能力，同时在传感器噪声下保持鲁棒性，最优传感器集合实现了可比的性能。

Conclusion: 这项研究为实际运行不确定性下的实时高超声速流动控制建立了数据驱动方法，展示了DRL在复杂流体控制问题中的应用潜力。

Abstract: The hypersonic unstart phenomenon poses a major challenge to reliable air-breathing propulsion at Mach 5 and above, where strong shock-boundary-layer interactions and rapid pressure fluctuations can destabilize inlet operation. Here, we demonstrate a deep reinforcement learning (DRL)- based active flow control strategy to control unstart in a canonical two-dimensional hypersonic inlet at Mach 5 and Reynolds number $5\times 10^6$. The in-house CFD solver enables high-fidelity simulations with adaptive mesh refinement, resolving key flow features, including shock motion, boundary-layer dynamics, and flow separation, that are essential for learning physically consistent control policies suitable for real-time deployment. The DRL controller robustly stabilizes the inlet over a wide range of back pressures representative of varying combustion chamber conditions. It further generalizes to previously unseen scenarios, including different back-pressure levels, Reynolds numbers, and sensor configurations, while operating with noisy measurements, thereby demonstrating strong zero-shot generalization. Control remains robust in the presence of noisy sensor measurements, and a minimal, optimally selected sensor set achieves comparable performance, enabling practical implementation. These results establish a data-driven approach for real-time hypersonic flow control under realistic operational uncertainties.

</details>


### [128] [CADENT: Gated Hybrid Distillation for Sample-Efficient Transfer in Reinforcement Learning](https://arxiv.org/abs/2602.02532)
*Mahyar Alinejad,Yue Wang,George Atia*

Main category: cs.LG

TL;DR: CADENT框架结合了策略蒸馏的战术指导和自动化战略知识，通过经验门控信任机制动态调整教师指导权重，在强化学习中实现自适应知识迁移。


<details>
  <summary>Details</summary>
Motivation: 现有迁移学习方法在强化学习中面临领域偏移问题：策略蒸馏缺乏长期战略知识传递，自动化方法则缺失细粒度动作指导。需要统一战略和战术知识以提高样本效率。

Method: CADENT框架将基于自动机的战略知识与策略级战术知识统一为连贯的指导信号，创新性地采用经验门控信任机制，在状态-动作级别动态权衡教师指导与学生自身经验。

Result: 在稀疏奖励网格世界和连续控制任务等挑战性环境中，CADENT比基线方法实现了40-60%的样本效率提升，同时保持了优越的渐近性能。

Conclusion: CADENT为强化学习中的自适应知识迁移提供了一个鲁棒的方法框架，有效解决了战略与战术知识融合的问题，显著提高了迁移学习的效率。

Abstract: Transfer learning promises to reduce the high sample complexity of deep reinforcement learning (RL), yet existing methods struggle with domain shift between source and target environments. Policy distillation provides powerful tactical guidance but fails to transfer long-term strategic knowledge, while automaton-based methods capture task structure but lack fine-grained action guidance. This paper introduces Context-Aware Distillation with Experience-gated Transfer (CADENT), a framework that unifies strategic automaton-based knowledge with tactical policy-level knowledge into a coherent guidance signal. CADENT's key innovation is an experience-gated trust mechanism that dynamically weighs teacher guidance against the student's own experience at the state-action level, enabling graceful adaptation to target domain specifics. Across challenging environments, from sparse-reward grid worlds to continuous control tasks, CADENT achieves 40-60\% better sample efficiency than baselines while maintaining superior asymptotic performance, establishing a robust approach for adaptive knowledge transfer in RL.

</details>


### [129] [How Does the Lagrangian Guide Safe Reinforcement Learning through Diffusion Models?](https://arxiv.org/abs/2602.02924)
*Xiaoyuan Cheng,Wenxuan Yuan,Boyang Li,Yuanchao Xu,Yiming Yang,Hao Liang,Bei Peng,Robert Loftin,Zhuo Sun,Yukun Hu*

Main category: cs.LG

TL;DR: 本文提出了一种用于离策略安全强化学习的增强拉格朗日引导扩散算法（ALGD），通过引入增强拉格朗日函数来稳定扩散策略，解决了传统方法在安全强化学习中的训练不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的强化学习方法主要关注离线设置下的奖励最大化，对在线设置的安全性考虑有限，且传统方法在非凸拉格朗日景观中容易产生不稳定问题。

Method: ALGD算法通过优化理论重新审视能量基模型，引入增强拉格朗日函数局部凸化能量景观，从而稳定策略生成和训练过程，同时不改变最优策略的分布。

Result: 理论分析和大量实验表明ALGD具有理论基础和实证效果，在多样化环境中实现了强大且稳定的性能表现。

Conclusion: ALGD为安全强化学习提供了一种稳定有效的扩散策略解决方案，在保证策略多样性的同时解决了训练稳定性问题。

Abstract: Diffusion policy sampling enables reinforcement learning (RL) to represent multimodal action distributions beyond suboptimal unimodal Gaussian policies. However, existing diffusion-based RL methods primarily focus on offline settings for reward maximization, with limited consideration of safety in online settings. To address this gap, we propose Augmented Lagrangian-Guided Diffusion (ALGD), a novel algorithm for off-policy safe RL. By revisiting optimization theory and energy-based model, we show that the instability of primal-dual methods arises from the non-convex Lagrangian landscape. In diffusion-based safe RL, the Lagrangian can be interpreted as an energy function guiding the denoising dynamics. Counterintuitively, direct usage destabilizes both policy generation and training. ALGD resolves this issue by introducing an augmented Lagrangian that locally convexifies the energy landscape, yielding a stabilized policy generation and training process without altering the distribution of the optimal policy. Theoretical analysis and extensive experiments demonstrate that ALGD is both theoretically grounded and empirically effective, achieving strong and stable performance across diverse environments.

</details>


### [130] [Human-Centric Traffic Signal Control for Equity: A Multi-Agent Action Branching Deep Reinforcement Learning Approach](https://arxiv.org/abs/2602.02959)
*Xiaocai Zhang,Neema Nassir,Lok Sang Chan,Milad Haghani*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Coordinating traffic signals along multimodal corridors is challenging because many multi-agent deep reinforcement learning (DRL) approaches remain vehicle-centric and struggle with high-dimensional discrete action spaces. We propose MA2B-DDQN, a human-centric multi-agent action-branching double Deep Q-Network (DQN) framework that explicitly optimizes traveler-level equity. Our key contribution is an action-branching discrete control formulation that decomposes corridor control into (i) local, per-intersection actions that allocate green time between the next two phases and (ii) a single global action that selects the total duration of those phases. This decomposition enables scalable coordination under discrete control while reducing the effective complexity of joint decision-making. We also design a human-centric reward that penalizes the number of delayed individuals in the corridor, accounting for pedestrians, vehicle occupants, and transit passengers. Extensive evaluations across seven realistic traffic scenarios in Melbourne, Australia, demonstrate that our approach significantly reduces the number of impacted travelers, outperforming existing DRL and baseline methods. Experiments confirm the robustness of our model, showing minimal variance across diverse settings. This framework not only advocates for a fairer traffic signal system but also provides a scalable solution adaptable to varied urban traffic conditions.

</details>


### [131] [From Sparse Decisions to Dense Reasoning: A Multi-attribute Trajectory Paradigm for Multimodal Moderation](https://arxiv.org/abs/2602.02536)
*Tianle Gu,Kexin Huang,Lingyu Li,Ruilin Luo,Shiyang Huang,Zongqi Wang,Yujiu Yang,Yan Teng,Yingchun Wang*

Main category: cs.LG

TL;DR: 本文提出了UniMod，一种新的多模态安全内容审核学习范式，通过密集推理轨迹而非稀疏二进制标签来解决数据与监督双稀疏问题，防止捷径学习，并在较少训练数据下实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 传统多模态安全内容审核主要依赖二进制标签，导致模型学习捷径、难以捕捉内在分类边界，且面临数据和监督稀疏的双重挑战。需要从稀疏决策转向密集推理轨迹来提升审核效果。

Method: 1. 提出UniMod学习范式，构建包含证据定位、模态评估、风险映射、政策决策和响应生成的结构化推理轨迹；2. 开发多头标量奖励模型UniRM，为响应生成阶段提供多维度属性级监督；3. 引入专门优化策略，解耦任务特定参数并重新平衡训练动态，解决多任务学习中的目标干扰问题。

Result: UniMod在文本审核方面取得竞争性性能，并在多模态审核中设立新基准，仅使用领先基线不到40%的训练数据。消融研究进一步验证了多属性轨迹推理的有效性。

Conclusion: UniMod通过结构化的密集推理轨迹和多维度监督，有效解决了多模态内容审核中的数据和监督稀疏问题，防止捷径学习，为多模态审核提供了高效且有效的框架。

Abstract: Safety moderation is pivotal for identifying harmful content. Despite the success of textual safety moderation, its multimodal counterparts remain hindered by a dual sparsity of data and supervision. Conventional reliance on binary labels lead to shortcut learning, which obscures the intrinsic classification boundaries necessary for effective multimodal discrimination. Hence, we propose a novel learning paradigm (UniMod) that transitions from sparse decision-making to dense reasoning traces. By constructing structured trajectories encompassing evidence grounding, modality assessment, risk mapping, policy decision, and response generation, we reformulate monolithic decision tasks into a multi-dimensional boundary learning process. This approach forces the model to ground its decision in explicit safety semantics, preventing the model from converging on superficial shortcuts. To facilitate this paradigm, we develop a multi-head scalar reward model (UniRM). UniRM provides multi-dimensional supervision by assigning attribute-level scores to the response generation stage. Furthermore, we introduce specialized optimization strategies to decouple task-specific parameters and rebalance training dynamics, effectively resolving interference between diverse objectives in multi-task learning. Empirical results show UniMod achieves competitive textual moderation performance and sets a new multimodal benchmark using less than 40\% of the training data used by leading baselines. Ablations further validate our multi-attribute trajectory reasoning, offering an effective and efficient framework for multimodal moderation. Supplementary materials are available at \href{https://trustworthylab.github.io/UniMod/}{project website}.

</details>


### [132] [Enhancing Post-Training Quantization via Future Activation Awareness](https://arxiv.org/abs/2602.02538)
*Zheqi Lv,Zhenxuan Fan,Qi Tian,Wenqiao Zhang,Yueting Zhuang*

Main category: cs.LG

TL;DR: 本文提出了Future-Aware Quantization (FAQ)方法，利用未来层激活指导大语言模型的后训练量化，解决传统方法因校准数据偏差导致的量化偏差和误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 后训练量化(PTQ)是压缩大语言模型的高效方法，但传统基于当前层激活的方法存在量化偏差和误差累积问题，尤其是在校准数据存在偏差时会导致量化效果不稳定。

Method: 提出FAQ方法：1）利用未来层激活指导量化，更好地识别和保护重要权重；2）引入窗口式预览机制，软聚合多个未来层激活，避免过度依赖单层；3）使用预搜索配置避免昂贵贪婪搜索，最小化开销。

Result: 实验表明FAQ方法持续优于先前方法，额外成本可忽略，且不需要反向传播、数据重建或调参，适合边缘部署。

Conclusion: FAQ通过考虑未来层信息有效解决了PTQ中的量化偏差和误差累积问题，提供了一种高效稳定的量化方案。

Abstract: Post-training quantization (PTQ) is a widely used method to compress large language models (LLMs) without fine-tuning. It typically sets quantization hyperparameters (e.g., scaling factors) based on current-layer activations. Although this method is efficient, it suffers from quantization bias and error accumulation, resulting in suboptimal and unstable quantization, especially when the calibration data is biased. To overcome these issues, we propose Future-Aware Quantization (FAQ), which leverages future-layer activations to guide quantization. This allows better identification and preservation of important weights, while reducing sensitivity to calibration noise. We further introduce a window-wise preview mechanism to softly aggregate multiple future-layer activations, mitigating over-reliance on any single layer. To avoid expensive greedy search, we use a pre-searched configuration to minimize overhead. Experiments show that FAQ consistently outperforms prior methods with negligible extra cost, requiring no backward passes, data reconstruction, or tuning, making it well-suited for edge deployment.

</details>


### [133] [How Much Information Can a Vision Token Hold? A Scaling Law for Recognition Limits in VLMs](https://arxiv.org/abs/2602.02539)
*Shuxin Zhuang,Zi Liang,Runsheng Yu,Hongzong Li,Rong Feng,Shiqin Tang,Youzhi Zhang*

Main category: cs.LG

TL;DR: 本文探讨视觉token的信息上限，通过压力实验发现视觉编码存在稳定相、不稳定相和崩溃相的三相变现象，并建立了统一的概率缩放定律。


<details>
  <summary>Details</summary>
Motivation: 视觉中心方法在长上下文建模中取得进展，但将视觉编码器视为有限容量的有损通道引发了根本问题：视觉token的信息上限是什么？

Method: 通过逐步增加图像中的字符数量（信息量）进行受控压力测试，分析三相变现象的机制，并将平均视觉token负载和视觉密度统一为潜在难度指标。

Result: 实验观察到明显的相变现象：稳定相（接近完美）、不稳定相（误差方差增加）和崩溃相。建立的缩放定律在不同视觉语言模型中具有普遍性。

Conclusion: 该研究为视觉上下文压缩的效率-精度权衡优化提供了关键经验指导，揭示了视觉token的信息容量限制和相变规律。

Abstract: Recent vision-centric approaches have made significant strides in long-context modeling. Represented by DeepSeek-OCR, these models encode rendered text into continuous vision tokens, achieving high compression rates without sacrificing recognition precision. However, viewing the vision encoder as a lossy channel with finite representational capacity raises a fundamental question: what is the information upper bound of visual tokens? To investigate this limit, we conduct controlled stress tests by progressively increasing the information quantity (character count) within an image. We observe a distinct phase-transition phenomenon characterized by three regimes: a near-perfect Stable Phase, an Instability Phase marked by increased error variance, and a total Collapse Phase. We analyze the mechanical origins of these transitions and identify key factors. Furthermore, we formulate a probabilistic scaling law that unifies average vision token load and visual density into a latent difficulty metric. Extensive experiments across various Vision-Language Models demonstrate the universality of this scaling law, providing critical empirical guidance for optimizing the efficiency-accuracy trade-off in visual context compression.

</details>


### [134] [Toward Ultra-Long-Horizon Sequential Model Editing](https://arxiv.org/abs/2602.02543)
*Mingda Liu,Zhenghan Zhu,Ze'an Miao,Katsuki Fujisawa*

Main category: cs.LG

TL;DR: 论文提出了Norm-Anchor Scaling (NAS)方法，通过控制权重范数来解决Locate-and-Edit模型编辑中的灾难性崩溃问题


<details>
  <summary>Details</summary>
Motivation: 现有Locate-and-Edit范式在连续编辑时会出现模型崩溃，研究发现这与MLP权重范数爆炸性增长有强相关性

Method: 提出NAS方法，作为即插即用的范数约束策略，在编辑过程中保持权重范数稳定

Result: NAS将崩溃点延迟4倍以上，编辑性能提升72.2%，仅需一行额外代码且计算开销可忽略

Conclusion: NAS通过简单有效的范数控制机制，显著提升了Locate-and-Edit方法的稳定性和编辑能力

Abstract: Model editing has emerged as a practical approach for mitigating factual errors and outdated knowledge in large language models (LLMs). Among existing methods, the Locate-and-Edit (L&E) paradigm is the dominant framework: it locates MLP parameters implicated in expressing a target fact, and then performs a localized update to rewrite that fact. However, long sequences of edits often trigger abrupt model collapse in L&E beyond a critical point. We empirically identify a strong correlation between collapse and explosive growth of edited MLP weight norms, and formally prove that commonly used L&E update rules can induce exponential norm growth across sequential edits in the absence of explicit norm control. To address this issue, we propose Norm-Anchor Scaling NAS, a plug-and-play norm-constrained strategy. Across extensive experiments, NAS delays the collapse point of representative L&E algorithms by more than 4 times and yields a 72.2% average relative gain in editing performance, requiring only a single additional line of code and incurring negligible computational overhead.

</details>


### [135] [SPA-Cache: Singular Proxies for Adaptive Caching in Diffusion Language Models](https://arxiv.org/abs/2602.02544)
*Wenhao Sun,Rong-Cheng Tu,Yifu Ding,Zhao Jin,Jingyi Liao,Yongcheng Jing,Dacheng Tao*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While Diffusion Language Models (DLMs) offer a flexible, arbitrary-order alternative to the autoregressive paradigm, their non-causal nature precludes standard KV caching, forcing costly hidden state recomputation at every decoding step. Existing DLM caching approaches reduce this cost by selective hidden state updates; however, they are still limited by (i) costly token-wise update identification heuristics and (ii) rigid, uniform budget allocation that fails to account for heterogeneous hidden state dynamics. To address these challenges, we present SPA-Cache that jointly optimizes update identification and budget allocation in DLM cache. First, we derive a low-dimensional singular proxy that enables the identification of update-critical tokens in a low-dimensional subspace, substantially reducing the overhead of update identification. Second, we introduce an adaptive strategy that allocates fewer updates to stable layers without degrading generation quality. Together, these contributions significantly improve the efficiency of DLMs, yielding up to an $8\times$ throughput improvement over vanilla decoding and a $2$--$4\times$ speedup over existing caching baselines.

</details>


### [136] [Beyond Alignment: Expanding Reasoning Capacity via Manifold-Reshaping Policy Optimization](https://arxiv.org/abs/2602.02545)
*Dayu Wang,Jiaye Yang,Weikang Li,Jiahui Liang,Yang Li*

Main category: cs.LG

TL;DR: 论文提出的MRPO方法通过几何干预拓展LLM推理空间，挑战了RLVR仅微调预训练能力的观点


<details>
  <summary>Details</summary>
Motivation: 现有研究质疑强化学习是否真的拓展了大语言模型的推理能力，还是仅仅对齐了已有的潜在能力，认为探索被限制在预训练模型的低秩偏见流形内。本研究旨在挑战这种可访问性边界假说

Method: 提出了流形重塑策略优化(MRPO)框架，包含两个阶段：1. 使用谱正交探索将策略初始化弹射到偏见流形的零空间；2. 在策略优化目标中集成有效秩正则化项，激励发现和维护高维推理轨迹

Result: 4B参数的方法在数学任务上取得了最先进性能，显著优于更大的模型(如Qwen3-32B)，并超越了标准GRPO的能力边界

Conclusion: 通过有针对性的几何干预，可以根本性拓展LLM的潜在推理空间，证明了推理能力的实质性扩展而非简单对齐

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated remarkable success in enhancing the reasoning capabilities of Large Language Models (LLMs). However, recent studies question whether RL genuinely expands reasoning capacity or merely aligns existing latent capabilities, arguing that exploration remains confined within the pre-trained model's low-rank bias manifold. In this work, we challenge this accessibility boundary hypothesis by demonstrating that the latent reasoning space can be fundamentally expanded through targeted geometric interventions. We propose Manifold-Reshaping Policy Optimization (MRPO), a geometric framework designed to fundamentally restructure the inference space of LLMs. MRPO operates in two stages: first, we employ Spectral Orthogonal Exploration (SOE) to eject the policy initialization into the null space of the bias manifold; second, we integrate an Effective Rank regularization term into the policy optimization objective. This approach incentivizes the discovery and maintenance of high-dimensional reasoning trajectories against the entropy-reducing tendency of standard RL. Empirically, our 4B-parameter method achieves state-of-the-art performance on mathematical tasks, significantly outperforming larger models (e.g., Qwen3-32B) and expanding the capability boundary beyond standard GRPO. Our code is available at https://anonymous.4open.science/r/MRPO-D57B/

</details>


### [137] [D$^2$Quant: Accurate Low-bit Post-Training Weight Quantization for LLMs](https://arxiv.org/abs/2602.02546)
*Xianglong Yan,ChengZhu Bao,Zhiteng Li,Tianao Zhang,Shaoqiu Zhang,Ruobing Xie,Samm Sun,Yulun Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) deliver strong performance, but their high compute and memory costs make deployment difficult in resource-constrained scenarios. Weight-only post-training quantization (PTQ) is appealing, as it reduces memory usage and enables practical speedup without low-bit operators or specialized hardware. However, accuracy often degrades significantly in weight-only PTQ at sub-4-bit precision, and our analysis identifies two main causes: (1) down-projection matrices are a well-known quantization bottleneck, but maintaining their fidelity often requires extra bit-width; (2) weight quantization induces activation deviations, but effective correction strategies remain underexplored. To address these issues, we propose D$^2$Quant, a novel weight-only PTQ framework that improves quantization from both the weight and activation perspectives. On the weight side, we design a Dual-Scale Quantizer (DSQ) tailored to down-projection matrices, with an absorbable scaling factor that significantly improves accuracy without increasing the bit budget. On the activation side, we propose Deviation-Aware Correction (DAC), which incorporates a mean-shift correction within LayerNorm to mitigate quantization-induced activation distribution shifts. Extensive experiments across multiple LLM families and evaluation metrics show that D$^2$Quant delivers superior performance for weight-only PTQ at sub-4-bit precision. The code and models will be available at https://github.com/XIANGLONGYAN/D2Quant.

</details>


### [138] [naPINN: Noise-Adaptive Physics-Informed Neural Networks for Recovering Physics from Corrupted Measurement](https://arxiv.org/abs/2602.02547)
*Hankyeol Kim,Pilsung Kang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Physics-Informed Neural Networks (PINNs) are effective methods for solving inverse problems and discovering governing equations from observational data. However, their performance degrades significantly under complex measurement noise and gross outliers. To address this issue, we propose the Noise-Adaptive Physics-Informed Neural Network (naPINN), which robustly recovers physical solutions from corrupted measurements without prior knowledge of the noise distribution. naPINN embeds an energy-based model into the training loop to learn the latent distribution of prediction residuals. Leveraging the learned energy landscape, a trainable reliability gate adaptively filters data points exhibiting high energy, while a rejection cost regularization prevents trivial solutions where valid data are discarded. We demonstrate the efficacy of naPINN on various benchmark partial differential equations corrupted by non-Gaussian noise and varying rates of outliers. The results show that naPINN significantly outperforms existing robust PINN baselines, successfully isolating outliers and accurately reconstructing the dynamics under severe data corruption.

</details>


### [139] [HyPAC: Cost-Efficient LLMs-Human Hybrid Annotation with PAC Error Guarantees](https://arxiv.org/abs/2602.02550)
*Hao Zeng,Huipeng Huang,Xinhao Qu,Jianguo Huang,Bingyi Jing,Hongxin Wei*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Data annotation often involves multiple sources with different cost-quality trade-offs, such as fast large language models (LLMs), slow reasoning models, and human experts. In this work, we study the problem of routing inputs to the most cost-efficient annotation source while controlling the labeling error on test instances. We propose \textbf{HyPAC}, a method that adaptively labels inputs to the most cost-efficient annotation source while providing distribution-free guarantees on annotation error. HyPAC calibrates two decision thresholds using importance sampling and upper confidence bounds, partitioning inputs into three regions based on uncertainty and routing each to the appropriate annotation source. We prove that HyPAC achieves the minimum expected cost with a probably approximately correct (PAC) guarantee on the annotation error, free of data distribution and pre-trained models. Experiments on common benchmarks demonstrate the effectiveness of our method, reducing the annotation cost by 78.51\% while tightly controlling the annotation error.

</details>


### [140] [EEO-TFV: Escape-Explore Optimizer for Web-Scale Time-Series Forecasting and Vision Analysis](https://arxiv.org/abs/2602.02551)
*Hua Wang,Jinghao Lu,Fan Zhang*

Main category: cs.LG

TL;DR: 本文针对Transformer基础模型在多元长序列预测和图像分割任务中的误差累积及分布外样本脆弱性问题，提出轻量级Transformer架构结合新颖的Escape-Explore Optimizer（EEO），在Web数据场景下实现与SOTAs相当的性能。


<details>
  <summary>Details</summary>
Motivation: Transformer基础模型虽然在时间序列预测和图像分割等任务上取得显著进展，但在多元长序列预测中常出现误差累积，在图像相关任务中对分布外样本敏感。这些挑战在涉及复杂时序模式和多模态特征的大规模Web数据分析任务中尤为突出，导致模型容易在高维参数空间中陷入鞍点陷阱。

Method: 提出轻量级Transformer架构结合新颖的Escape-Explore Optimizer（EEO）。该优化器同时增强探索能力和泛化能力，有效避免尖锐最小值和鞍点陷阱。模型在11个时间序列基准数据集和Synapse医学图像分割任务上进行评估。

Result: 实验结果表明，在代表性Web数据场景中，该方法在11个时间序列基准数据集和Synapse医学图像分割任务上达到与最先进模型相当的性能。同时表现出更优的泛化能力和稳定性。

Conclusion: 该方法验证了其作为跨任务基础模型在大规模Web数据挖掘和分析中的潜力，为解决Transformer模型在复杂Web数据分析中的优化难题提供了有效方案。

Abstract: Transformer-based foundation models have achieved remarkable progress in tasks such as time-series forecasting and image segmentation. However, they frequently suffer from error accumulation in multivariate long-sequence prediction and exhibit vulnerability to out-of-distribution samples in image-related tasks. Furthermore, these challenges become particularly pronounced in large-scale Web data analysis tasks, which typically involve complex temporal patterns and multimodal features. This complexity substantially increases optimization difficulty, rendering models prone to stagnation at saddle points within high-dimensional parameter spaces. To address these issues, we propose a lightweight Transformer architecture in conjunction with a novel Escape-Explore Optimizer (EEO). The optimizer enhances both exploration and generalization while effectively avoiding sharp minima and saddle-point traps. Experimental results show that, in representative Web data scenarios, our method achieves performance on par with state-of-the-art models across 11 time-series benchmark datasets and the Synapse medical image segmentation task. Moreover, it demonstrates superior generalization and stability, thereby validating its potential as a versatile cross-task foundation model for Web-scale data mining and analysis.

</details>


### [141] [BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation](https://arxiv.org/abs/2602.02554)
*Jingwen Xu,Yiyang Lu,Zisu Huang,Changze Lv,Xiaohua Wang,Shizheng Li,Zhibo Xu,Zhengkang Guo,Zhengyuan Wang,Muzhao Tian,Xuanjing Huang,Xiaoqing Zheng*

Main category: cs.LG

TL;DR: BatCoder是一种自监督强化学习框架，通过反向翻译策略联合优化代码生成和文档生成，仅需代码数据即可训练，在代码生成任务上表现优异


<details>
  <summary>Details</summary>
Motivation: 为代码相关任务训练大语言模型通常依赖高质量代码-文档对，但这类数据获取成本高且在特定编程语言中稀缺，需要一种仅使用代码数据就能进行有效训练的方法

Method: 采用反向翻译策略：从代码生成文档，再用生成的文档重建原始代码；原始代码与重建代码的语义相似度作为隐式奖励，通过强化学习同时提升代码生成和文档生成能力

Result: 在HumanEval和MBPP基准测试上，7B模型分别达到83.5%和81.0%的pass@1分数，超越了开源基线模型；框架在训练数据规模和模型容量方面都显示出良好的扩展性

Conclusion: BatCoder通过自监督强化学习框架有效解决了代码-文档对数据稀缺问题，仅使用代码数据就能训练出高性能的代码生成模型，为资源受限环境下的代码相关任务训练提供了可行方案

Abstract: Training LLMs for code-related tasks typically depends on high-quality code-documentation pairs, which are costly to curate and often scarce for niche programming languages. We introduce BatCoder, a self-supervised reinforcement learning framework designed to jointly optimize code generation and documentation production. BatCoder employs a back-translation strategy: a documentation is first generated from code, and then the generated documentation is used to reconstruct the original code. The semantic similarity between the original and reconstructed code serves as an implicit reward, enabling reinforcement learning to improve the model's performance both in generating code from documentation and vice versa. This approach allows models to be trained using only code, substantially increasing the available training examples. Evaluated on HumanEval and MBPP with a 7B model, BatCoder achieved 83.5% and 81.0% pass@1, outperforming strong open-source baselines. Moreover, the framework demonstrates consistent scaling with respect to both training corpus size and model capacity.

</details>


### [142] [Learning to Explore with Parameter-Space Noise: A Deep Dive into Parameter-Space Noise for Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2602.02555)
*Bizhe Bai,Xinyue Wang,Peng Ye,Tao Chen*

Main category: cs.LG

TL;DR: PSN-RLVR通过在策略参数层面添加扰动来增强探索能力，结合截断重要性采样解决采样更新失配问题，并使用轻量级自适应噪声调度器，在大型采样预算下显著提升了推理任务的性能表现。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习中可验证奖励方法（RLVR）存在探索瓶颈：主要依赖对现有解决方案轨迹的重新加权，而非发现新的解决策略，这限制了在大采样预算下的性能提升。

Method: 提出了PSN-RLVR方法：在生成rollout前扰动策略参数以实现时间一致的轨迹级探索；使用截断重要性采样解决采样更新失配；设计了一个基于语义多样性和归一化自确定性的轻量级自适应噪声调度器，避免昂贵的KL自适应噪声控制。

Result: 基于GRPO实现的PSN-GRPO在多个数学推理基准测试和模型家族中一致扩展了有效推理能力的边界，在大采样预算下获得了更高的pass-at-k性能，超越了之前的探索导向RLVR方法，并且保持了正交性可实现进一步增益。

Conclusion: PSN-RLVR方法通过参数级扰动和自适应噪声调度，有效突破了RLVR的探索瓶颈，为大规模采样预算下的推理任务提供了更有效的训练策略。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) improves LLM reasoning, yet growing evidence indicates an exploration ceiling: it often reweights existing solution traces rather than discovering new strategies, limiting gains under large sampling budgets (e.g., pass-at-256). We address this limitation with PSN-RLVR, which perturbs policy parameters before rollout generation to induce temporally consistent, trajectory-level exploration that better preserves long-horizon chain-of-thought coherence than action-space noise. To mitigate the resulting sampling-update mismatch, we incorporate truncated importance sampling (TIS). To avoid expensive KL-based adaptive noise control, we propose a computationally efficient real-time adaptive noise scheduler driven by a lightweight surrogate that combines semantic diversity with normalized self-certainty. Instantiated on GRPO, a widely used RLVR method, PSN-GRPO consistently expands the effective reasoning capability boundary across multiple mathematical reasoning benchmarks and model families, yielding higher pass-at-k under large sampling budgets and outperforming prior exploration-oriented RLVR methods (e.g., Pass-at-k-style training) while remaining orthogonal and thus composable for additional gains.

</details>


### [143] [Beyond Experience Retrieval: Learning to Generate Utility-Optimized Structured Experience for Frozen LLMs](https://arxiv.org/abs/2602.02556)
*Xuancheng Li,Haitao Li,Yujia Zhou,Yiqun Liu,Qingyao Ai*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) are largely static and often redo reasoning or repeat mistakes. Prior experience reuse typically relies on external retrieval, which is similarity-based, can introduce noise, and adds latency. We introduce SEAM (Structured Experience Adapter Module), a lightweight, executor-specific plug-in that stores experience in its parameters and generates a structured, instance-tailored experience entry in a single forward pass to guide a frozen LLM executor. SEAM is trained for utility via executor rollouts and GRPO while keeping the executor frozen, and it can be further improved after deployment with supervised fine-tuning on logged successful trajectories. Experiments on mathematical reasoning benchmarks show consistent accuracy gains across executors with low overhead. Extensive ablations and analyses further elucidate the mechanisms underlying SEAM's effectiveness and robustness.

</details>


### [144] [The Alignment Curse: Cross-Modality Jailbreak Transfer in Omni-Models](https://arxiv.org/abs/2602.02557)
*Yupeng Chen,Junchi Yu,Aoxi Liu,Philip Torr,Adel Bibi*

Main category: cs.LG

TL;DR: 本文研究了从文本越狱攻击跨模态转移到音频的攻击有效性，发现文本转移的音频越狱攻击表现得与现有音频攻击相当甚至更好，揭示了模型对齐的副作用。


<details>
  <summary>Details</summary>
Motivation: 现有的越狱攻击研究主要集中在文本和音频模态，但模态间的攻击转移未被充分探索。本文基于文本与音频的语义相似度，以及文本越狱方法的成熟性，探讨文本到音频的越狱攻击转移。

Method: 作者首先分析了模态对齐与跨模态越狱转移之间的关系，揭示出强对齐会无意中传播文本脆弱性到音频模态。然后实证评估了文本越狱、文本转移的音频越狱和现有音频越狱攻击在最新全模态模型上的表现。

Result: 实验结果表明文本转移的音频越狱攻击与现有音频攻击效果相当甚至更好，确立了其作为未来音频红队测试的简单有效基线。此外，研究还展现了该攻击的强跨模型可转移性，并且即使在纯音频访问的威胁模型下依然有效。

Conclusion: 文本到音频的越狱攻击转移是有效的，文本转移的音频越狱攻击可以作为未来音频红队测试的强大基线。研究同时揭示了模型强对齐可能带来的安全隐患，即所谓的“对齐诅咒”。

Abstract: Recent advances in end-to-end trained omni-models have significantly improved multimodal understanding. At the same time, safety red-teaming has expanded beyond text to encompass audio-based jailbreak attacks. However, an important bridge between textual and audio jailbreaks remains underexplored. In this work, we study the cross-modality transfer of jailbreak attacks from text to audio, motivated by the semantic similarity between the two modalities and the maturity of textual jailbreak methods. We first analyze the connection between modality alignment and cross-modality jailbreak transfer, showing that strong alignment can inadvertently propagate textual vulnerabilities to the audio modality, which we term the alignment curse. Guided by this analysis, we conduct an empirical evaluation of textual jailbreaks, text-transferred audio jailbreaks, and existing audio-based jailbreaks on recent omni-models. Our results show that text-transferred audio jailbreaks perform comparably to, and often better than, audio-based jailbreaks, establishing them as simple yet powerful baselines for future audio red-teaming. We further demonstrate strong cross-model transferability and show that text-transferred audio attacks remain effective even under a stricter audio-only access threat model.

</details>


### [145] [PA-MIL: Phenotype-Aware Multiple Instance Learning Guided by Language Prompting and Genotype-to-Phenotype Relationships](https://arxiv.org/abs/2602.02558)
*Zekang Yang,Hong Liu,Xiangdong Wang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep learning has been extensively researched in the analysis of pathology whole-slide images (WSIs). However, most existing methods are limited to providing prediction interpretability by locating the model's salient areas in a post-hoc manner, failing to offer more reliable and accountable explanations. In this work, we propose Phenotype-Aware Multiple Instance Learning (PA-MIL), a novel ante-hoc interpretable framework that identifies cancer-related phenotypes from WSIs and utilizes them for cancer subtyping. To facilitate PA-MIL in learning phenotype-aware features, we 1) construct a phenotype knowledge base containing cancer-related phenotypes and their associated genotypes. 2) utilize the morphological descriptions of phenotypes as language prompting to aggregate phenotype-related features. 3) devise the Genotype-to-Phenotype Neural Network (GP-NN) grounded in genotype-to-phenotype relationships, which provides multi-level guidance for PA-MIL. Experimental results on multiple datasets demonstrate that PA-MIL achieves competitive performance compared to existing MIL methods while offering improved interpretability. PA-MIL leverages phenotype saliency as evidence and, using a linear classifier, achieves competitive results compared to state-of-the-art methods. Additionally, we thoroughly analyze the genotype-phenotype relationships, as well as cohort-level and case-level interpretability, demonstrating the reliability and accountability of PA-MIL.

</details>


### [146] [Auditing Sybil: Explaining Deep Lung Cancer Risk Prediction Through Generative Interventional Attributions](https://arxiv.org/abs/2602.02560)
*Bartlomiej Sobieski,Jakub Grzywaczewski,Karol Dobiczek,Mateusz Wójcik,Tomasz Bartczak,Patryk Szatkowski,Przemysław Bombiński,Matthew Tivnan,Przemyslaw Biecek*

Main category: cs.LG

TL;DR: 提出了S(H)NAP模型审计框架，对Sybil肺癌筛查模型进行因果验证，揭示了该模型存在对临床不合理伪影的敏感性和径向偏差等关键失效模式。


<details>
  <summary>Details</summary>
Motivation: 当前基于观测指标的评估忽视了深度学习模型的实际推理机制，需要进行因果验证以确保临床部署前的稳健决策。

Method: 提出了S(H)NAP模型无关审计框架，利用3D扩散桥建模系统性修改解剖特征，构建生成干预归因，并通过放射科专家验证。

Result: 首次对Sybil进行干预性审计，发现虽然该模型常表现出类似放射科专家的行为，但存在危险失效模式：对临床不合理伪影异常敏感，存在明显的径向偏差。

Conclusion: 模型审计在临床部署前至关重要，S(H)NAP框架能够揭示深度学习风险预测模型的因果推理缺陷，为医疗AI系统提供更严格的验证手段。

Abstract: Lung cancer remains the leading cause of cancer mortality, driving the development of automated screening tools to alleviate radiologist workload. Standing at the frontier of this effort is Sybil, a deep learning model capable of predicting future risk solely from computed tomography (CT) with high precision. However, despite extensive clinical validation, current assessments rely purely on observational metrics. This correlation-based approach overlooks the model's actual reasoning mechanism, necessitating a shift to causal verification to ensure robust decision-making before clinical deployment. We propose S(H)NAP, a model-agnostic auditing framework that constructs generative interventional attributions validated by expert radiologists. By leveraging realistic 3D diffusion bridge modeling to systematically modify anatomical features, our approach isolates object-specific causal contributions to the risk score. Providing the first interventional audit of Sybil, we demonstrate that while the model often exhibits behavior akin to an expert radiologist, differentiating malignant pulmonary nodules from benign ones, it suffers from critical failure modes, including dangerous sensitivity to clinically unjustified artifacts and a distinct radial bias.

</details>


### [147] [A General ReLearner: Empowering Spatiotemporal Prediction by Re-learning Input-label Residual](https://arxiv.org/abs/2602.02563)
*Jiaming Ma,Binwu Wang,Pengkun Wang,Xu Wang,Zhengyang Zhou,Yang Wang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Prevailing spatiotemporal prediction models typically operate under a forward (unidirectional) learning paradigm, in which models extract spatiotemporal features from historical observation input and map them to target spatiotemporal space for future forecasting (label). However, these models frequently exhibit suboptimal performance when spatiotemporal discrepancies exist between inputs and labels, for instance, when nodes with similar time-series inputs manifest distinct future labels, or vice versa. To address this limitation, we propose explicitly incorporating label features during the training phase. Specifically, we introduce the Spatiotemporal Residual Theorem, which generalizes the conventional unidirectional spatiotemporal prediction paradigm into a bidirectional learning framework. Building upon this theoretical foundation, we design an universal module, termed ReLearner, which seamlessly augments Spatiotemporal Neural Networks (STNNs) with a bidirectional learning capability via an auxiliary inverse learning process. In this process, the model relearns the spatiotemporal feature residuals between input data and future data. The proposed ReLearner comprises two critical components: (1) a Residual Learning Module, designed to effectively disentangle spatiotemporal feature discrepancies between input and label representations; and (2) a Residual Smoothing Module, employed to smooth residual terms and facilitate stable convergence. Extensive experiments conducted on 11 real-world datasets across 14 backbone models demonstrate that ReLearner significantly enhances the predictive performance of existing STNNs.Our code is available on GitHub.

</details>


### [148] [Label Curation Using Agentic AI](https://arxiv.org/abs/2602.02564)
*Subhodeep Ghosh,Bayan Divaaniaazar,Md Ishat-E-Rabban,Spencer Clarke,Senjuti Basu Roy*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Data annotation is essential for supervised learning, yet producing accurate, unbiased, and scalable labels remains challenging as datasets grow in size and modality. Traditional human-centric pipelines are costly, slow, and prone to annotator variability, motivating reliability-aware automated annotation. We present AURA (Agentic AI for Unified Reliability Modeling and Annotation Aggregation), an agentic AI framework for large-scale, multi-modal data annotation. AURA coordinates multiple AI agents to generate and validate labels without requiring ground truth. At its core, AURA adapts a classical probabilistic model that jointly infers latent true labels and annotator reliability via confusion matrices, using Expectation-Maximization to reconcile conflicting annotations and aggregate noisy predictions. Across the four benchmark datasets evaluated, AURA achieves accuracy improvements of up to 5.8% over baseline. In more challenging settings with poor quality annotators, the improvement is up to 50% over baseline. AURA also accurately estimates the reliability of annotators, allowing assessment of annotator quality even without any pre-validation steps.

</details>


### [149] [A Comparative Simulation Study of the Fairness and Accuracy of Predictive Policing Systems in Baltimore City](https://arxiv.org/abs/2602.02566)
*Samin Semsar,Kiran Laxmikant Prabhu,Gabriella Waters,James Foulds*

Main category: cs.LG

TL;DR: 本研究通过模拟比较巴尔的摩市的预测性警务与热点警务，发现预测性警务的偏见问题比预想的更复杂：短期内比热点警务更公平、准确，但长期可能放大偏见，且某些情况下偏见方向与以往研究相反。


<details>
  <summary>Details</summary>
Motivation: 针对预测性警务系统（如洛杉矶和巴尔的摩部署的系统）存在种族偏见等不公平性的讨论，现有研究较少且不够全面，需要进行更全面的比较研究。

Method: 采用综合性模拟比较研究，评估巴尔的摩市预测性警务技术的公平性和准确性，并与传统热点警务进行对比。

Result: 预测性警务存在反馈循环导致的偏见（与之前研究一致），但热点警务也有类似问题；预测性警务在短期内比热点警务更公平准确，但偏见放大速度更快，可能导致更差的长期表现；在巴尔的摩，某些情况下系统偏向于对白人社区过度监管（与以往研究相反）。

Conclusion: 本研究展示了城市特定评估和预测性警务系统行为倾向比较的方法论，此类模拟能揭示不公平性和长期趋势，表明预测性警务的偏见问题比先前假设的更复杂。

Abstract: There are ongoing discussions about predictive policing systems, such as those deployed in Los Angeles, California and Baltimore, Maryland, being unfair, for example, by exhibiting racial bias. Studies found that unfairness may be due to feedback loops and being trained on historically biased recorded data. However, comparative studies on predictive policing systems are few and are not sufficiently comprehensive. In this work, we perform a comprehensive comparative simulation study on the fairness and accuracy of predictive policing technologies in Baltimore. Our results suggest that the situation around bias in predictive policing is more complex than was previously assumed. While predictive policing exhibited bias due to feedback loops as was previously reported, we found that the traditional alternative, hot spots policing, had similar issues. Predictive policing was found to be more fair and accurate than hot spots policing in the short term, although it amplified bias faster, suggesting the potential for worse long-run behavior. In Baltimore, in some cases the bias in these systems tended toward over-policing in White neighborhoods, unlike in previous studies. Overall, this work demonstrates a methodology for city-specific evaluation and behavioral-tendency comparison of predictive policing systems, showing how such simulations can reveal inequities and long-term tendencies.

</details>


### [150] [Mitigating Task-Order Sensitivity and Forgetting via Hierarchical Second-Order Consolidation](https://arxiv.org/abs/2602.02568)
*Protik Nag,Krishnan Raghavan,Vignesh Narayanan*

Main category: cs.LG

TL;DR: HTCL框架通过将快速局部适应与保守的二阶全局整合相结合来解决持续学习中的任务顺序方差问题。


<details>
  <summary>Details</summary>
Motivation: 传统持续学习方法因随机任务顺序引入的高方差而性能不稳定，HTCL旨在解决任务顺序效应对学习性能的影响。

Method: 通过寻找最佳组内任务序列，并利用Hessian正则化的泰勒展开整合局部更新，形成具有理论保证的整合步骤；支持多级层次结构实现多尺度知识集成。

Result: 在多个数据集及基线方法上，HTCL作为模型无关的整合层持续提升性能，平均准确率提高7%-25%，最终准确率标准差降低最高达68%。

Conclusion: HTCL框架能有效减少任务顺序方差并提升持续学习性能，其模型无关特性和多级层次结构扩展了传统单级持续学习系统的能力。

Abstract: We introduce $\textbf{Hierarchical Taylor Series-based Continual Learning (HTCL)}$, a framework that couples fast local adaptation with conservative, second-order global consolidation to address the high variance introduced by random task ordering. To address task-order effects, HTCL identifies the best intra-group task sequence and integrates the resulting local updates through a Hessian-regularized Taylor expansion, yielding a consolidation step with theoretical guarantees. The approach naturally extends to an $L$-level hierarchy, enabling multiscale knowledge integration in a manner not supported by conventional single-level CL systems. Across a wide range of datasets and replay and regularization baselines, HTCL acts as a model-agnostic consolidation layer that consistently enhances performance, yielding mean accuracy gains of $7\%$ to $25\%$ while reducing the standard deviation of final accuracy by up to $68\%$ across random task permutations.

</details>


### [151] [Trajectory Consistency for One-Step Generation on Euler Mean Flows](https://arxiv.org/abs/2602.02571)
*Zhiqi Li,Yuchen Sun,Duowen Chen,Jinjin He,Bo Zhu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose \emph{Euler Mean Flows (EMF)}, a flow-based generative framework for one-step and few-step generation that enforces long-range trajectory consistency with minimal sampling cost. The key idea of EMF is to replace the trajectory consistency constraint, which is difficult to supervise and optimize over long time scales, with a principled linear surrogate that enables direct data supervision for long-horizon flow-map compositions. We derive this approximation from the semigroup formulation of flow-based models and show that, under mild regularity assumptions, it faithfully approximates the original consistency objective while being substantially easier to optimize. This formulation leads to a unified, JVP-free training framework that supports both $u$-prediction and $x_1$-prediction variants, avoiding explicit Jacobian computations and significantly reducing memory and computational overhead. Experiments on image synthesis, particle-based geometry generation, and functional generation demonstrate improved optimization stability and sample quality under fixed sampling budgets, together with approximately $50\%$ reductions in training time and memory consumption compared to existing one-step methods for image generation.

</details>


### [152] [Reward Shaping for Inference-Time Alignment: A Stackelberg Game Perspective](https://arxiv.org/abs/2602.02572)
*Haichuan Wang,Tao Lin,Lingkai Kong,Ce Li,Hezi Jiang,Milind Tambe*

Main category: cs.LG

TL;DR: 该论文提出通过优化奖励模型设计来缓解K正则化导致的基模型偏差与用户偏好冲突的问题，采用Stackelberg博弈框架，证明简单奖励整形方法可近似最优解，在多种现有对齐方法中有效提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法直接使用从用户偏好数据学习的奖励模型来优化LLM策略，并结合基策略的KL正则化。这种做法的缺陷在于KL正则化可能使LLM继承基策略中与用户偏好冲突的偏差。虽然放大偏好输出的奖励可以缓解此偏差，但会增加奖励攻击风险，需要寻求KL正则化下的最优奖励设计。

Method: 将奖励模型优化问题形式化为Stackelberg博弈，理论分析表明简单的奖励整形方案可以有效地近似最优奖励模型，该方法可无缝集成到现有对齐方法中，仅增加最小开销。

Result: 在推理时对齐设置中，该方法持续改善平均奖励，所有基线对比中胜率超过66%（平均跨评估设置），提升效果显著。

Conclusion: 通过优化奖励模型设计而非直接使用原始奖励，可以解决KL正则化导致的基模型偏差问题，提出的奖励整形方法实现近似最优，并能无缝增强现有对齐方法，显著提升对齐效果。

Abstract: Existing alignment methods directly use the reward model learned from user preference data to optimize an LLM policy, subject to KL regularization with respect to the base policy. This practice is suboptimal for maximizing user's utility because the KL regularization may cause the LLM to inherit the bias in the base policy that conflicts with user preferences. While amplifying rewards for preferred outputs can mitigate this bias, it also increases the risk of reward hacking. This tradeoff motivates the problem of optimally designing reward models under KL regularization. We formalize this reward model optimization problem as a Stackelberg game, and show that a simple reward shaping scheme can effectively approximate the optimal reward model. We empirically evaluate our method in inference-time alignment settings and demonstrate that it integrates seamlessly into existing alignment methods with minimal overhead. Our method consistently improves average reward and achieves win-tie rates exceeding 66% against all baselines, averaged across evaluation settings.

</details>


### [153] [QuantLRM: Quantization of Large Reasoning Models via Fine-Tuning Signals](https://arxiv.org/abs/2602.02581)
*Nan Zhang,Eugene Kwek,Yusen Zhang,Muyu Pan,Suhang Wang,Prasenjit Mitra,Rui Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Weight-only quantization is important for compressing Large Language Models (LLMs). Inspired by the spirit of classical magnitude pruning, we study whether the magnitude of weight updates during reasoning-incentivized fine-tuning can provide valuable signals for quantizing Large Reasoning Models (LRMs). We hypothesize that the smallest and largest weight updates during fine-tuning are more important than those of intermediate magnitude, a phenomenon we term "protecting both ends". Upon hypothesis validation, we introduce QuantLRM, which stands for weight quantization of LRMs via fine-tuning signals. We fit simple restricted quadratic functions on weight updates to protect both ends. By multiplying the average quadratic values with the count of zero weight updates of channels, we compute channel importance that is more effective than using activation or second-order information. We run QuantLRM to quantize various fine-tuned models (including supervised, direct preference optimization, and reinforcement learning fine-tuning) over four reasoning benchmarks (AIME-120, FOLIO, temporal sequences, and GPQA-Diamond) and empirically find that QuantLRM delivers a consistent improvement for LRMs quantization, with an average improvement of 6.55% on a reinforcement learning fine-tuned model. Also supporting non-fine-tuned LRMs, QuantLRM gathers effective signals via pseudo-fine-tuning, which greatly enhances its applicability.

</details>


### [154] [Copula-Based Aggregation and Context-Aware Conformal Prediction for Reliable Renewable Energy Forecasting](https://arxiv.org/abs/2602.02583)
*Alireza Moradi,Mathieu Tanneau,Reza Zandehshahvar,Pascal Van Hentenryck*

Main category: cs.LG

TL;DR: 提出校准概率聚合框架，将站点级太阳能发电概率预测转换为可靠的机群级预测，解决跨站点依赖和聚合校准问题


<details>
  <summary>Details</summary>
Motivation: 可再生能源渗透快速增长需要可靠的机群级概率预测，但系统运营商通常只能获得异构第三方提供的站点级预测，难以从这些输入构建校准良好的机群级概率预测

Method: 开发校准概率聚合框架，结合基于copula的依赖建模捕获跨站点相关性，使用上下文感知符合预测(CACP)纠正聚合级别的校准误差

Result: 在MISO、ERCOT和SPP的大型太阳能发电数据集上验证，Copula+CACP方法始终实现接近标称的覆盖范围，比未经校准的聚合基线有更锐利的预测区间

Conclusion: 该框架为无法训练或维护系统级模型的场景提供有效解决方案，实现了依赖感知的聚合，提供有效覆盖率和锐利的预测区间

Abstract: The rapid growth of renewable energy penetration has intensified the need for reliable probabilistic forecasts to support grid operations at aggregated (fleet or system) levels. In practice, however, system operators often lack access to fleet-level probabilistic models and instead rely on site-level forecasts produced by heterogeneous third-party providers. Constructing coherent and calibrated fleet-level probabilistic forecasts from such inputs remains challenging due to complex cross-site dependencies and aggregation-induced miscalibration. This paper proposes a calibrated probabilistic aggregation framework that directly converts site-level probabilistic forecasts into reliable fleet-level forecasts in settings where system-level models cannot be trained or maintained. The framework integrates copula-based dependence modeling to capture cross-site correlations with Context-Aware Conformal Prediction (CACP) to correct miscalibration at the aggregated level. This combination enables dependence-aware aggregation while providing valid coverage and maintaining sharp prediction intervals. Experiments on large-scale solar generation datasets from MISO, ERCOT, and SPP demonstrate that the proposed Copula+CACP approach consistently achieves near-nominal coverage with significantly sharper intervals than uncalibrated aggregation baselines.

</details>


### [155] [Effective Frontiers: A Unification of Neural Scaling Laws](https://arxiv.org/abs/2602.02593)
*Jiaxuan Zou,Zixuan Gong,Ye Su,Huayi Tang,Yong Liu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Neural scaling laws govern the prediction power-law improvement of test loss with respect to model capacity ($N$), datasize ($D$), and compute ($C$). However, existing theoretical explanations often rely on specific architectures or complex kernel methods, lacking intuitive universality. In this paper, we propose a unified framework that abstracts general learning tasks as the progressive coverage of patterns from a long-tail (Zipfian) distribution. We introduce the Effective Frontier ($k_\star$), a threshold in the pattern rank space that separates learned knowledge from the unlearned tail. We prove that reducible loss is asymptotically determined by the probability mass of the tail a resource-dependent frontier truncation. Based on our framework, we derive the precise scaling laws for $N$, $D$, and $C$, attributing them to capacity, coverage, and optimization bottlenecks, respectively. Furthermore, we unify these mechanisms via a Max-Bottleneck principle, demonstrating that the Kaplan and Chinchilla scaling laws are not contradictory, but equilibrium solutions to the same constrained optimization problem under different active bottlenecks.

</details>


### [156] [Fubini Study geometry of representation drift in high dimensional data](https://arxiv.org/abs/2602.02596)
*Arturo Tozzi*

Main category: cs.LG

TL;DR: 本文提出了一个基于射影几何和弗比尼-斯图迪度量的高维表示漂移度量框架，用于区分数据的内在变化与参数化引入的规范变换，相比传统欧氏/余弦距离更能反映本质演化。


<details>
  <summary>Details</summary>
Motivation: 传统用于量化高维表示漂移的欧氏距离和余弦距离假设固定坐标系，在比较跨时间、训练或预处理阶段的表示时将数据的内在变化与由任意参数化引起的变化纠缠在一起，存在系统性的高估问题。

Method: 引入基于弗比尼-斯图迪度量的射影几何视角来识别表示，这些表示仅因全局缩放、符号翻转等规范变换而不同；在实证高维数据集上显式构建表示轨迹，通过累积几何漂移跟踪其演化；比较欧氏距离、余弦距离和弗比尼-斯图迪距离沿这些轨迹的差异。

Result: 弗比尼-斯图迪度量在受规范诱导的波动下保持不变，能分离出内在演化；余弦距离与弗比尼-斯图迪漂移之间的差值定义了一个可计算的单调量，直接捕捉由规范自由度引起的表示搅动；这种分离为区分有意义的结构演化与参数化伪影提供了诊断工具，无需引入模型特定假设。

Conclusion: 为高维系统中的表示稳定性评估建立了几何准则，阐明了角度距离的局限性；将表示动态嵌入射影空间将数据分析与已有的几何程序连接起来，并产生了可在经验工作流中直接测试的可观测量。

Abstract: High dimensional representation drift is commonly quantified using Euclidean or cosine distances, which presuppose fixed coordinates when comparing representations across time, training or preprocessing stages. While effective in many settings, these measures entangle intrinsic changes in the data with variations induced by arbitrary parametrizations. We introduce a projective geometric view of representation drift grounded in the Fubini Study metric, which identifies representations that differ only by gauge transformations such as global rescalings or sign flips. Applying this framework to empirical high dimensional datasets, we explicitly construct representation trajectories and track their evolution through cumulative geometric drift. Comparing Euclidean, cosine and Fubini Study distances along these trajectories reveals that conventional metrics systematically overestimate change whenever representations carry genuine projective ambiguity. By contrast, the Fubini Study metric isolates intrinsic evolution by remaining invariant under gauge-induced fluctuations. We further show that the difference between cosine and Fubini Study drift defines a computable, monotone quantity that directly captures representation churn attributable to gauge freedom. This separation provides a diagnostic for distinguishing meaningful structural evolution from parametrization artifacts, without introducing model-specific assumptions. Overall, we establish a geometric criterion for assessing representation stability in high-dimensional systems and clarify the limits of angular distances. Embedding representation dynamics in projective space connects data analysis with established geometric programs and yields observables that are directly testable in empirical workflows.

</details>


### [157] [ContextEvolve: Multi-Agent Context Compression for Systems Code Optimization](https://arxiv.org/abs/2602.02597)
*Hongyuan Su,Yu Zheng,Yong Li*

Main category: cs.LG

TL;DR: ContextEvolve 是一个多智能体框架，能够在参数盲约束下实现强化学习级别的搜索效率，用于优化 LLM 生成的性能关键算法代码。通过将优化上下文分解为三个正交维度，显著提升搜索效率和减少 token 消耗。


<details>
  <summary>Details</summary>
Motivation: LLM 能够生成看似合理的代码，但要满足系统对正确性和性能的严格要求，需要迭代优化。现有的测试时强化学习方法需要参数更新，这在仅 API 访问下不可行；而免训练的进化方法存在上下文利用低效和搜索无方向的问题。

Method: ContextEvolve 引入了三个正交智能体：Summarizer Agent 通过代码到语言的抽象来浓缩语义状态；Navigator Agent 通过轨迹分析提炼优化方向；Sampler Agent 通过优先级示例检索来管理经验分布。这种编排形成了与强化学习的函数同构，可在文本潜在空间中实现原则性优化。

Result: 在 ADRS 基准测试中，ContextEvolve 性能优于最先进的基线方法 33.3%，同时 token 消耗减少 29.0%。

Conclusion: ContextEvolve 能够在严格的参数盲约束下实现强化学习级别的搜索效率，通过智能体协同工作分解优化上下文，显著提升 LLM 生成代码的性能优化效果，同时减少计算资源消耗。

Abstract: Large language models are transforming systems research by automating the discovery of performance-critical algorithms for computer systems. Despite plausible codes generated by LLMs, producing solutions that meet the stringent correctness and performance requirements of systems demands iterative optimization. Test-time reinforcement learning offers high search efficiency but requires parameter updates infeasible under API-only access, while existing training-free evolutionary methods suffer from inefficient context utilization and undirected search. We introduce ContextEvolve, a multi-agent framework that achieves RL-level search efficiency under strict parameter-blind constraints by decomposing optimization context into three orthogonal dimensions: a Summarizer Agent condenses semantic state via code-to-language abstraction, a Navigator Agent distills optimization direction from trajectory analysis, and a Sampler Agent curates experience distribution through prioritized exemplar retrieval. This orchestration forms a functional isomorphism with RL-mapping to state representation, policy gradient, and experience replay-enabling principled optimization in a textual latent space. On the ADRS benchmark, ContextEvolve outperforms state-of-the-art baselines by 33.3% while reducing token consumption by 29.0%. Codes for our work are released at https://anonymous.4open.science/r/ContextEvolve-ACC

</details>


### [158] [RAP: KV-Cache Compression via RoPE-Aligned Pruning](https://arxiv.org/abs/2602.02599)
*Jihao Xin,Tian Lvu,Hatem Ltaief,David Keyes,Marco Canini*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Long-context inference in large language models is increasingly bottlenecked by the memory and compute cost of the KV-Cache. Low-rank factorization compresses KV projections by writing $W \approx A * B$, where A produces latent KV states and B can be absorbed into downstream weights. In modern RoPE-based LLMs, this absorption fails: RoPE forces latent KV states to be reconstructed to full dimension, reintroducing substantial memory and compute overhead. We propose RoPE-Aligned Pruning (RAP), which prunes entire RoPE-aligned column pairs to preserve RoPE's 2x2 rotation structure, restore B absorption, and eliminate reconstruction. Our evaluation on LLaMA-3-8B and Mistral-7B shows that RAP enables joint reduction of KV-Cache, attention parameters, and FLOPs by 20-30%, all at once, while maintaining strong accuracy. Notably, RAP reduces attention latency to 83% (prefill) and 77% (decode) of baseline.

</details>


### [159] [Step-Wise Refusal Dynamics in Autoregressive and Diffusion Language Models](https://arxiv.org/abs/2602.02600)
*Eliron Rahimi,Elad Hirshel,Rom Himelstein,Amit LeVi,Avi Mendelson,Chaim Baskin*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Diffusion language models (DLMs) have recently emerged as a promising alternative to autoregressive (AR) models, offering parallel decoding and controllable sampling dynamics while achieving competitive generation quality at scale. Despite this progress, the role of sampling mechanisms in shaping refusal behavior and jailbreak robustness remains poorly understood. In this work, we present a fundamental analytical framework for step-wise refusal dynamics, enabling comparison between AR and diffusion sampling. Our analysis reveals that the sampling strategy itself plays a central role in safety behavior, as a factor distinct from the underlying learned representations. Motivated by this analysis, we introduce the Step-Wise Refusal Internal Dynamics (SRI) signal, which supports interpretability and improved safety for both AR and DLMs. We demonstrate that the geometric structure of SRI captures internal recovery dynamics, and identifies anomalous behavior in harmful generations as cases of \emph{incomplete internal recovery} that are not observable at the text level. This structure enables lightweight inference-time detectors that generalize to unseen attacks while matching or outperforming existing defenses with over $100\times$ lower inference overhead.

</details>


### [160] [Discovering Data Manifold Geometry via Non-Contracting Flows](https://arxiv.org/abs/2602.02611)
*David Vigouroux,Lucas Drumetz,Ronan Fablet,François Rousseau*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce an unsupervised approach for constructing a global reference system by learning, in the ambient space, vector fields that span the tangent spaces of an unknown data manifold. In contrast to isometric objectives, which implicitly assume manifold flatness, our method learns tangent vector fields whose flows transport all samples to a common, learnable reference point. The resulting arc-lengths along these flows define interpretable intrinsic coordinates tied to a shared global frame. To prevent degenerate collapse, we enforce a non-shrinking constraint and derive a scalable, integration-free objective inspired by flow matching. Within our theoretical framework, we prove that minimizing the proposed objective recovers a global coordinate chart when one exists. Empirically, we obtain correct tangent alignment and coherent global coordinate structure on synthetic manifolds. We also demonstrate the scalability of our method on CIFAR-10, where the learned coordinates achieve competitive downstream classification performance.

</details>


### [161] [A Semi-Supervised Pipeline for Generalized Behavior Discovery from Animal-Borne Motion Time Series](https://arxiv.org/abs/2602.02618)
*Fatemeh Karimi Nejadasl,Judy Shamoun-Baranes,Eldar Rakhimberdiev*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Learning behavioral taxonomies from animal-borne sensors is challenging because labels are scarce, classes are highly imbalanced, and behaviors may be absent from the annotated set. We study generalized behavior discovery in short multivariate motion snippets from gulls, where each sample is a sequence with 3-axis IMU acceleration (20 Hz) and GPS speed, spanning nine expert-annotated behavior categories. We propose a semi-supervised discovery pipeline that (i) learns an embedding function from the labeled subset, (ii) performs label-guided clustering over embeddings of both labeled and unlabeled samples to form candidate behavior groups, and (iii) decides whether a discovered group is truly novel using a containment score. Our key contribution is a KDE + HDR (highest-density region) containment score that measures how much a discovered cluster distribution is contained within, or contains, each known-class distribution; the best-match containment score serves as an interpretable novelty statistic. In experiments where an entire behavior is withheld from supervision and appears only in the unlabeled pool, the method recovers a distinct cluster and the containment score flags novelty via low overlap, while a negative-control setting with no novel behavior yields consistently higher overlaps. These results suggest that HDR-based containment provides a practical, quantitative test for generalized class discovery in ecological motion time series under limited annotation and severe class imbalance.

</details>


### [162] [daVinci-Agency: Unlocking Long-Horizon Agency Data-Efficiently](https://arxiv.org/abs/2602.02619)
*Mohan Jiang,Dayuan Fu,Junhao Shi,Ji Zeng,Weiye Si,Keyu Li,Xuefeng Li,Yang Xiao,Wenjie Li,Dequan Wang,Pengfei Liu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While Large Language Models (LLMs) excel at short-term tasks, scaling them to long-horizon agentic workflows remains challenging. The core bottleneck lies in the scarcity of training data that captures authentic long-dependency structures and cross-stage evolutionary dynamics--existing synthesis methods either confine to single-feature scenarios constrained by model distribution, or incur prohibitive human annotation costs, failing to provide scalable, high-quality supervision. We address this by reconceptualizing data synthesis through the lens of real-world software evolution. Our key insight: Pull Request (PR) sequences naturally embody the supervision signals for long-horizon learning. They decompose complex objectives into verifiable submission units, maintain functional coherence across iterations, and encode authentic refinement patterns through bug-fix histories. Building on this, we propose daVinci-Agency, which systematically mines structured supervision from chain-of-PRs through three interlocking mechanisms: (1) progressive task decomposition via continuous commits, (2) long-term consistency enforcement through unified functional objectives, and (3) verifiable refinement from authentic bug-fix trajectories. Unlike synthetic trajectories that treat each step independently, daVinci-Agency's PR-grounded structure inherently preserves the causal dependencies and iterative refinements essential for teaching persistent goal-directed behavior and enables natural alignment with project-level, full-cycle task modeling. The resulting trajectories are substantial--averaging 85k tokens and 116 tool calls--yet remarkably data-efficient: fine-tuning GLM-4.6 on 239 daVinci-Agency samples yields broad improvements across benchmarks, notably achieving a 47% relative gain on Toolathlon. Beyond benchmark performance, our analysis confirms...

</details>


### [163] [Learning Better Certified Models from Empirically-Robust Teachers](https://arxiv.org/abs/2602.02626)
*Alessandro De Palma*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Adversarial training attains strong empirical robustness to specific adversarial attacks by training on concrete adversarial perturbations, but it produces neural networks that are not amenable to strong robustness certificates through neural network verification. On the other hand, earlier certified training schemes directly train on bounds from network relaxations to obtain models that are certifiably robust, but display sub-par standard performance. Recent work has shown that state-of-the-art trade-offs between certified robustness and standard performance can be obtained through a family of losses combining adversarial outputs and neural network bounds. Nevertheless, differently from empirical robustness, verifiability still comes at a significant cost in standard performance. In this work, we propose to leverage empirically-robust teachers to improve the performance of certifiably-robust models through knowledge distillation. Using a versatile feature-space distillation objective, we show that distillation from adversarially-trained teachers consistently improves on the state-of-the-art in certified training for ReLU networks across a series of robust computer vision benchmarks.

</details>


### [164] [Performance of Small Language Model Pretraining on FABRIC: An Empirical Study](https://arxiv.org/abs/2602.02632)
*Praveen Rao*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) require enormous computing power to pretrain on massive datasets. When limited datasets are available, smaller-sized LLMs are better choice to pretrain (on user-specified datasets) by following the scaling laws of LLMs. Using pretrained models, vector embeddings can be generated for raw data and stored using vector databases to support modern AI applications and semantic search. In this work, we investigate the performance of pretraining techniques for smaller-sized LLMs on an experimental testbed (with commodity GPUs) available to academic users at no charge. We consider data parallelism, intra-operator parallelism, and inter-operator/pipeline parallelism, and their combinations for pretraining. We set up different GPU clusters with homogeneous and heterogeneous GPU hardware. Furthermore, we investigate the impact of network latency on pretraining performance especially when GPUs are geographically distributed. We used GPT-2 medium and large models and pretrained them using open-source packages, namely, Alpa and Ray. We observed that Alpa's execution plans that collectively optimized intra-operator and inter-operator/pipeline parallelism consistently performed the best when GPUs were geographically distributed. This was especially true when the network latencies were in 10's of milliseconds. Based on the insights gained from the experiments, we propose a systematic approach for selecting the appropriate pretraining technique to achieve high training performance/lower execution time as well as to reduce the number of GPUs used.

</details>


### [165] [A Reduction from Delayed to Immediate Feedback for Online Convex Optimization with Improved Guarantees](https://arxiv.org/abs/2602.02634)
*Alexander Ryabchenko,Idan Attias,Daniel M. Roy*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We develop a reduction-based framework for online learning with delayed feedback that recovers and improves upon existing results for both first-order and bandit convex optimization. Our approach introduces a continuous-time model under which regret decomposes into a delay-independent learning term and a delay-induced drift term, yielding a delay-adaptive reduction that converts any algorithm for online linear optimization into one that handles round-dependent delays. For bandit convex optimization, we significantly improve existing regret bounds, with delay-dependent terms matching state-of-the-art first-order rates. For first-order feedback, we recover state-of-the-art regret bounds via a simpler, unified analysis. Quantitatively, for bandit convex optimization we obtain $O(\sqrt{d_{\text{tot}}} + T^{\frac{3}{4}}\sqrt{k})$ regret, improving the delay-dependent term from $O(\min\{\sqrt{T d_{\text{max}}},(Td_{\text{tot}})^{\frac{1}{3}}\})$ in previous work to $O(\sqrt{d_{\text{tot}}})$. Here, $k$, $T$, $d_{\text{max}}$, and $d_{\text{tot}}$ denote the dimension, time horizon, maximum delay, and total delay, respectively. Under strong convexity, we achieve $O(\min\{σ_{\text{max}} \ln T, \sqrt{d_{\text{tot}}}\} + (T^2\ln T)^{\frac{1}{3}} {k}^{\frac{2}{3}})$, improving the delay-dependent term from $O(d_{\text{max}} \ln T)$ in previous work to $O(\min\{σ_{\text{max}} \ln T, \sqrt{d_{\text{tot}}}\})$, where $σ_{\text{max}}$ denotes the maximum number of outstanding observations and may be considerably smaller than $d_{\text{max}}$.

</details>


### [166] [hSNMF: Hybrid Spatially Regularized NMF for Image-Derived Spatial Transcriptomics](https://arxiv.org/abs/2602.02638)
*Md Ishtyaq Mahmud,Veena Kochat,Suresh Satpati,Jagan Mohan Reddy Dwarampudi,Humaira Anzum,Kunal Rai,Tania Banerjee*

Main category: cs.LG

TL;DR: 该研究针对高分辨率空间转录组数据（如Xenium平台）的高维特性，提出了两种空间正则化的非负矩阵分解方法：SNMF和hSNMF，以改善细胞聚类和空间结构分析。


<details>
  <summary>Details</summary>
Motivation: 高分辨率空间转录组平台（如Xenium）生成的单细胞图像具有极高的维度，这给表示学习和聚类带来了重大挑战。本研究旨在解决如何有效整合空间邻近性和转录组相似性，以提升细胞聚类的空间一致性和生物学意义。

Method: 提出了两种空间正则化的非负矩阵分解（NMF）变体：1) Spatial NMF（SNMF），通过扩散每个细胞的NMF因子向量到其空间邻域，强制局部空间平滑性；2) Hybrid Spatial NMF（hSNMF），执行空间正则化的NMF后，在混合邻接矩阵上进行Leiden聚类，该矩阵通过可调参数alpha整合空间邻近性（通过接触半径图）和转录组相似性。

Result: 在胆管癌数据集上的评估显示，SNMF和hSNMF相比其他空间基线方法，显著提升了空间紧凑性（CHAOS < 0.004，Moran's I > 0.96）、聚类分离性（Silhouette > 0.12，DBI < 1.8）以及生物学一致性（CMC和富集分析）。

Conclusion: 本研究提出的SNMF和hSNMF方法，通过有效整合空间和转录组信息，为高分辨率空间转录组数据的分析提供了强大的工具，能够实现更准确、更具生物学意义的细胞聚类和空间结构解析。

Abstract: High-resolution spatial transcriptomics platforms, such as Xenium, generate single-cell images that capture both molecular and spatial context, but their extremely high dimensionality poses major challenges for representation learning and clustering. In this study, we analyze data from the Xenium platform, which captures high-resolution images of tumor microarray (TMA) tissues and converts them into cell-by-gene matrices suitable for computational analysis. We benchmark and extend nonnegative matrix factorization (NMF) for spatial transcriptomics by introducing two spatially regularized variants. First, we propose Spatial NMF (SNMF), a lightweight baseline that enforces local spatial smoothness by diffusing each cell's NMF factor vector over its spatial neighborhood. Second, we introduce Hybrid Spatial NMF (hSNMF), which performs spatially regularized NMF followed by Leiden clustering on a hybrid adjacency that integrates spatial proximity (via a contact-radius graph) and transcriptomic similarity through a tunable mixing parameter alpha. Evaluated on a cholangiocarcinoma dataset, SNMF and hSNMF achieve markedly improved spatial compactness (CHAOS < 0.004, Moran's I > 0.96), greater cluster separability (Silhouette > 0.12, DBI < 1.8), and higher biological coherence (CMC and enrichment) compared to other spatial baselines. Availability and implementation: https://github.com/ishtyaqmahmud/hSNMF

</details>


### [167] [MARA: Continuous SE(3)-Equivariant Attention for Molecular Force Fields](https://arxiv.org/abs/2602.02671)
*Francesco Leonardi,Boris Bonev,Kaspar Riesen*

Main category: cs.LG

TL;DR: 这篇文章提出了一种名为MARA的模块化角度-径向注意力机制，通过扩展球形注意力到分子领域，为SE(3)等变机器学习力场提供了更灵活的几何交互加权方法。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习力场大多依赖固定的角度展开，限制了局部几何交互的灵活加权。作者希望通过发展更灵活的注意力机制来提升原子模型的表达能力。

Method: 作者引入了模块化角度-径向注意力模块，直接在相邻原子的角度和径向坐标上操作，允许对局部环境进行灵活、几何感知的加权。该模块可以即插即用地集成到MACE等现有模型中。

Result: 在分子基准测试中，MARA改善了能量和力的预测精度，减少了高误差事件，并增强了模型的鲁棒性。

Conclusion: 连续球形注意力是一种有效且可推广的几何操作符，能够提高原子模型的表达能力、稳定性和可靠性。

Abstract: Machine learning force fields (MLFFs) have become essential for accurate and efficient atomistic modeling. Despite their high accuracy, most existing approaches rely on fixed angular expansions, limiting flexibility in weighting local geometric interactions. We introduce Modular Angular-Radial Attention (MARA), a module that extends spherical attention -- originally developed for SO(3) tasks -- to the molecular domain and SE(3), providing an efficient approximation of equivariant interactions. MARA operates directly on the angular and radial coordinates of neighboring atoms, enabling flexible, geometrically informed, and modular weighting of local environments. Unlike existing attention mechanisms in SE(3)-equivariant architectures, MARA can be integrated in a plug-and-play manner into models such as MACE without architectural modifications. Across molecular benchmarks, MARA improves energy and force predictions, reduces high-error events, and enhances robustness. These results demonstrate that continuous spherical attention is an effective and generalizable geometric operator that increases the expressiveness, stability, and reliability of atomistic models.

</details>


### [168] [FlexRank: Nested Low-Rank Knowledge Decomposition for Adaptive Model Deployment](https://arxiv.org/abs/2602.02680)
*Riccardo Zaccone,Stefanos Laskaridis,Marco Ciccone,Samuel Horváth*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The growing scale of deep neural networks, encompassing large language models (LLMs) and vision transformers (ViTs), has made training from scratch prohibitively expensive and deployment increasingly costly. These models are often used as computational monoliths with fixed cost, a rigidity that does not leverage overparametrized architectures and largely hinders adaptive deployment across different cost budgets. We argue that importance-ordered nested components can be extracted from pretrained models, and selectively activated on the available computational budget. To this end, our proposed FlexRank method leverages low-rank weight decomposition with nested, importance-based consolidation to extract submodels of increasing capabilities. Our approach enables a "train-once, deploy-everywhere" paradigm that offers a graceful trade-off between cost and performance without training from scratch for each budget - advancing practical deployment of large models.

</details>


### [169] [Expert-Data Alignment Governs Generation Quality in Decentralized Diffusion Models](https://arxiv.org/abs/2602.02685)
*Marcos Villagra,Bidhan Roy,Raihan Seraj,Zhiying Jiang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Decentralized Diffusion Models (DDMs) route denoising through experts trained independently on disjoint data clusters, which can strongly disagree in their predictions. What governs the quality of generations in such systems? We present the first ever systematic investigation of this question. A priori, the expectation is that minimizing denoising trajectory sensitivity -- minimizing how perturbations amplify during sampling -- should govern generation quality. We demonstrate this hypothesis is incorrect: a stability-quality dissociation. Full ensemble routing, which combines all expert predictions at each step, achieves the most stable sampling dynamics and best numerical convergence while producing the worst generation quality (FID 47.9 vs. 22.6 for sparse Top-2 routing). Instead, we identify expert-data alignment as the governing principle: generation quality depends on routing inputs to experts whose training distribution covers the current denoising state. Across two distinct DDM systems, we validate expert-data alignment using (i) data-cluster distance analysis, confirming sparse routing selects experts with data clusters closest to the current denoising state, and (ii) per-expert analysis, showing selected experts produce more accurate predictions than non-selected ones, and (iii) expert disagreement analysis, showing quality degrades when experts disagree. For DDM deployment, our findings establish that routing should prioritize expert-data alignment over numerical stability metrics.

</details>


### [170] [Sparsely Supervised Diffusion](https://arxiv.org/abs/2602.02699)
*Wenshuai Zhao,Zhiyuan Li,Yi Zhao,Mohammad Hassan Vali,Martin Trapp,Joni Pajarinen,Juho Kannala,Arno Solin*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Diffusion models have shown remarkable success across a wide range of generative tasks. However, they often suffer from spatially inconsistent generation, arguably due to the inherent locality of their denoising mechanisms. This can yield samples that are locally plausible but globally inconsistent. To mitigate this issue, we propose sparsely supervised learning for diffusion models, a simple yet effective masking strategy that can be implemented with only a few lines of code. Interestingly, the experiments show that it is safe to mask up to 98\% of pixels during diffusion model training. Our method delivers competitive FID scores across experiments and, most importantly, avoids training instability on small datasets. Moreover, the masking strategy reduces memorization and promotes the use of essential contextual information during generation.

</details>


### [171] [Every Bit Counts: A Theoretical Study of Precision-Expressivity Tradeoffs in Quantized Transformers](https://arxiv.org/abs/2602.02707)
*Sayak Chakrabarti,Toniann Pitassi,Josh Alman*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantization reduces the numerical precision of Transformer computations and is widely used to accelerate inference, yet its effect on expressivity remains poorly characterized. We demonstrate a fine-grained theoretical tradeoff between expressivity and precision: For every p we exhibit a function Γ, inspired by the equality function, and prove that a one-layer softmax Transformer can compute Γ, with p bits of precision, but not with p-1 bits of precision.
  This result concretely explains the widely observed phenomenon of empirical loss of expressivity when quantization is used. Practically, it suggests that tasks requiring equality-like comparisons (exact match, membership, etc.) are especially sensitive to quantization. Dropping even one bit can cross a threshold where the model cannot represent the needed comparison reliably. Thus, it paves the way for developing heuristics that will help practitioners choose how much quantization is possible: the precision should be chosen as a function of the length of equality to be checked for the specific task.
  Our proofs combine explicit finite-precision Transformer constructions with communication-complexity lower bounds, yielding a tight "one-bit" threshold.

</details>


### [172] [BinaryPPO: Efficient Policy Optimization for Binary Classification](https://arxiv.org/abs/2602.02708)
*Punya Syon Pandey,Zhijing Jin*

Main category: cs.LG

TL;DR: BinaryPPO：一个用于二元分类的离线强化学习框架，将分类问题重构为奖励最大化问题，使用PPO变体和置信度加权奖励函数，在噪声和类别不平衡等现实场景下显著优于有监督微调。


<details>
  <summary>Details</summary>
Motivation: 有监督微调(SFT)在存在标签噪声、类别不平衡或稀疏监督的现实场景中表现不佳，需要更鲁棒的二元分类方法。

Method: 提出BinaryPPO框架，将二元分类重构为奖励最大化问题，使用PPO变体和置信度加权奖励函数（惩罚不确定或错误的预测），可以从静态数据集中学习稳健的决策策略，无需在线交互。

Result: 在八个领域特定基准和多个不同架构的模型上，BinaryPPO将准确率提高了40-60个百分点，最高可达99%，显著优于有监督基线。

Conclusion: 基于置信度的奖励设计为二元分类提供了比有监督微调更鲁棒的替代方案，离线强化学习方法在现实噪声场景中表现优异。

Abstract: Supervised fine-tuning (SFT) is the standard approach for binary classification tasks such as toxicity detection, factuality verification, and causal inference. However, SFT often performs poorly in real-world settings with label noise, class imbalance, or sparse supervision. We introduce BinaryPPO, an offline reinforcement learning large language model (LLM) framework that reformulates binary classification as a reward maximization problem. Our method leverages a variant of Proximal Policy Optimization (PPO) with a confidence-weighted reward function that penalizes uncertain or incorrect predictions, enabling the model to learn robust decision policies from static datasets without online interaction. Across eight domain-specific benchmarks and multiple models with differing architectures, BinaryPPO improves accuracy by 40-60 percentage points, reaching up to 99%, substantially outperforming supervised baselines. We provide an in-depth analysis of the role of reward shaping, advantage scaling, and policy stability in enabling this improvement. Overall, we demonstrate that confidence-based reward design provides a robust alternative to SFT for binary classification. Our code is available at https://github.com/psyonp/BinaryPPO.

</details>


### [173] [Maximum Likelihood Reinforcement Learning](https://arxiv.org/abs/2602.02710)
*Fahim Tajwar,Guanning Zeng,Yueer Zhou,Yuda Song,Daman Arora,Yiding Jiang,Jeff Schneider,Ruslan Salakhutdinov,Haiwen Feng,Andrea Zanette*

Main category: cs.LG

TL;DR: 本文提出Maximum Likelihood Reinforcement Learning (MaxRL)框架，使用强化学习技术近似最大似然估计，旨在解决采样不可微情况下的优化问题，并在正确性评估任务中展现优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习在二元结果反馈任务中仅优化低阶近似，并未最大化正确演算的似然估计。作者观察到这一局限性，旨在开发一种能更好利用采样计算资源的方法。 

Method: MaxRL定义了基于计算索引的采样目标族，随着计算资源增加，这些目标在标准强化学习和精确最大似然估计之间插值。该方法提供简单、无偏的策略梯度估计器，在无限计算极限下收敛到最大似然优化。

Result: 在实践中，MaxRL在所有测试的模型和任务上都帕累托优于现有方法，相比GRPO训练对方法实现了高达20倍的测试时缩放效率提升，并且在数据和计算资源增加时表现出更好的扩展性。

Conclusion: MaxRL是正确性评估场景中扩展强化学习训练的有效框架，显示出在采样不可微设置下实现最大似然估计的潜力。

Abstract: Reinforcement learning is the method of choice to train models in sampling-based setups with binary outcome feedback, such as navigation, code generation, and mathematical problem solving. In such settings, models implicitly induce a likelihood over correct rollouts. However, we observe that reinforcement learning does not maximize this likelihood, and instead optimizes only a lower-order approximation. Inspired by this observation, we introduce Maximum Likelihood Reinforcement Learning (MaxRL), a sampling-based framework to approximate maximum likelihood using reinforcement learning techniques. MaxRL addresses the challenges of non-differentiable sampling by defining a compute-indexed family of sample-based objectives that interpolate between standard reinforcement learning and exact maximum likelihood as additional sampling compute is allocated. The resulting objectives admit a simple, unbiased policy-gradient estimator and converge to maximum likelihood optimization in the infinite-compute limit. Empirically, we show that MaxRL Pareto-dominates existing methods in all models and tasks we tested, achieving up to 20x test-time scaling efficiency gains compared to its GRPO-trained counterpart. We also observe MaxRL to scale better with additional data and compute. Our results suggest MaxRL is a promising framework for scaling RL training in correctness based settings.

</details>


### [174] [Towards Understanding Steering Strength](https://arxiv.org/abs/2602.02712)
*Magamed Taimeskhanov,Samuel Vaiter,Damien Garreau*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A popular approach to post-training control of large language models (LLMs) is the steering of intermediate latent representations. Namely, identify a well-chosen direction depending on the task at hand and perturbs representations along this direction at inference time. While many propositions exist to pick this direction, considerably less is understood about how to choose the magnitude of the move, whereas its importance is clear: too little and the intended behavior does not emerge, too much and the model's performance degrades beyond repair. In this work, we propose the first theoretical analysis of steering strength. We characterize its effect on next token probability, presence of a concept, and cross-entropy, deriving precise qualitative laws governing these quantities. Our analysis reveals surprising behaviors, including non-monotonic effects of steering strength. We validate our theoretical predictions empirically on eleven language models, ranging from a small GPT architecture to modern models.

</details>


### [175] [Neural Probabilistic Amplitude Shaping for Nonlinear Fiber Channels](https://arxiv.org/abs/2602.02716)
*Mohammad Taha Askari,Lutz Lampe,Amirhossein Ghazisaeidi*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce neural probabilistic amplitude shaping, a joint-distribution learning framework for coherent fiber systems. The proposed scheme provides a 0.5 dB signal-to-noise ratio gain over sequence selection for dual-polarized 64-QAM transmission across a single-span 205 km link.

</details>


### [176] [Hierarchical Entity-centric Reinforcement Learning with Factored Subgoal Diffusion](https://arxiv.org/abs/2602.02722)
*Dan Haramati,Carl Qi,Tal Daniel,Amy Zhang,Aviv Tamar,George Konidaris*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a hierarchical entity-centric framework for offline Goal-Conditioned Reinforcement Learning (GCRL) that combines subgoal decomposition with factored structure to solve long-horizon tasks in domains with multiple entities. Achieving long-horizon goals in complex environments remains a core challenge in Reinforcement Learning (RL). Domains with multiple entities are particularly difficult due to their combinatorial complexity. GCRL facilitates generalization across goals and the use of subgoal structure, but struggles with high-dimensional observations and combinatorial state-spaces, especially under sparse reward. We employ a two-level hierarchy composed of a value-based GCRL agent and a factored subgoal-generating conditional diffusion model. The RL agent and subgoal generator are trained independently and composed post hoc through selective subgoal generation based on the value function, making the approach modular and compatible with existing GCRL algorithms. We introduce new variations to benchmark tasks that highlight the challenges of multi-entity domains, and show that our method consistently boosts performance of the underlying RL agent on image-based long-horizon tasks with sparse rewards, achieving over 150% higher success rates on the hardest task in our suite and generalizing to increasing horizons and numbers of entities. Rollout videos are provided at: https://sites.google.com/view/hecrl

</details>


### [177] [Automated Dysphagia Screening Using Noninvasive Neck Acoustic Sensing](https://arxiv.org/abs/2602.02725)
*Jade Chng,Rong Xing,Yunfei Luo,Kristen Linnemeyer-Risser,Tauhidur Rahman,Andrew Yousef,Philip A Weissbrod*

Main category: cs.LG

TL;DR: 本文提出了一种通过便携式非侵入性声学传感结合机器学习来自动检测吞咽困难的框架，旨在通过捕捉吞咽过程中的颈部声音信号来实现早期异常检测。


<details>
  <summary>Details</summary>
Motivation: 咽部健康对呼吸、吞咽和发声等基本功能至关重要。目前诊断吞咽困难的方法主要依赖放射成像或有创检查，需要一种更实用、可扩展的非侵入性监测工具。

Method: 采用便携式非侵入性声学传感设备，在吞咽任务中捕捉颈部区域的细微声学信号，然后运用机器学习方法分析这些信号，识别与异常生理状态相关的模式。

Result: 在5次独立的训练-测试分割中，该方法的异常检测性能表现优异，AUC-ROC达到0.904，显示出良好的检测能力。

Conclusion: 这项工作证明了非侵入性声学传感作为咽部健康监测工具的可行性和实用性，为早期发现吞咽异常提供了一种可扩展的新途径。

Abstract: Pharyngeal health plays a vital role in essential human functions such as breathing, swallowing, and vocalization. Early detection of swallowing abnormalities, also known as dysphagia, is crucial for timely intervention. However, current diagnostic methods often rely on radiographic imaging or invasive procedures. In this study, we propose an automated framework for detecting dysphagia using portable and noninvasive acoustic sensing coupled with applied machine learning. By capturing subtle acoustic signals from the neck during swallowing tasks, we aim to identify patterns associated with abnormal physiological conditions. Our approach achieves promising test-time abnormality detection performance, with an AUC-ROC of 0.904 under 5 independent train-test splits. This work demonstrates the feasibility of using noninvasive acoustic sensing as a practical and scalable tool for pharyngeal health monitoring.

</details>


### [178] [RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System](https://arxiv.org/abs/2602.02488)
*Yinjie Wang,Tianbao Xie,Ke Shen,Mengdi Wang,Ling Yang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL

</details>


### [179] [Vector Quantized Latent Concepts: A Scalable Alternative to Clustering-Based Concept Discovery](https://arxiv.org/abs/2602.02726)
*Xuemin Yu,Ankur Garg,Samira Ebrahimi Kahou,Hassan Sajjad*

Main category: cs.LG

TL;DR: VQLC（向量量化潜在概念）是一种基于VQ-VAE架构的框架，用于将深度学习的隐藏表征映射到离散的概念向量，提升可解释性方法的可扩展性并保持解释质量。


<details>
  <summary>Details</summary>
Motivation: 深度学习的隐藏表征包含丰富的语义信息，但现有基于聚类的概念解释方法（如层次聚类和K-Means）在大规模数据集上存在计算不可行或聚类质量浅薄/频率主导的问题。

Method: 基于VQ-VAE（向量量化变分自编码器）架构，学习一个离散的码本，将连续的隐藏表征映射到概念向量，实现高效的概念提取。

Result: VQLC在可扩展性方面显著提升，同时保持了与人类可理解解释相当的质量。通过全面评估验证了其有效性。

Conclusion: VQLC通过向量量化方法解决了现有概念解释方法的可扩展性问题，在大规模深度学习模型的可解释性应用中具有实用价值。

Abstract: Deep Learning models encode rich semantic information in their hidden representations. However, it remains challenging to understand which parts of this information models actually rely on when making predictions. A promising line of post-hoc concept-based explanation methods relies on clustering token representations. However, commonly used approaches such as hierarchical clustering are computationally infeasible for large-scale datasets, and K-Means often yields shallow or frequency-dominated clusters. We propose the vector quantized latent concept (VQLC) method, a framework built upon the vector quantized-variational autoencoder (VQ-VAE) architecture that learns a discrete codebook mapping continuous representations to concept vectors. We perform thorough evaluations and show that VQLC improves scalability while maintaining comparable quality of human-understandable explanations.

</details>


### [180] [Search-Augmented Masked Diffusion Models for Constrained Generation](https://arxiv.org/abs/2602.02727)
*Huu Binh Ta,Michael Cardei,Alvaro Velasquez,Ferdinando Fioretto*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Discrete diffusion models generate sequences by iteratively denoising samples corrupted by categorical noise, offering an appealing alternative to autoregressive decoding for structured and symbolic generation. However, standard training targets a likelihood-based objective that primarily matches the data distribution and provides no native mechanism for enforcing hard constraints or optimizing non-differentiable properties at inference time. This work addresses this limitation and introduces Search-Augmented Masked Diffusion (SearchDiff), a training-free neurosymbolic inference framework that integrates informed search directly into the reverse denoising process. At each denoising step, the model predictions define a proposal set that is optimized under a user-specified property satisfaction, yielding a modified reverse transition that steers sampling toward probable and feasible solutions. Experiments in biological design and symbolic reasoning illustrate that SearchDiff substantially improves constraint satisfaction and property adherence, while consistently outperforming discrete diffusion and autoregressive baselines.

</details>


### [181] [CAPS: Unifying Attention, Recurrence, and Alignment in Transformer-based Time Series Forecasting](https://arxiv.org/abs/2602.02729)
*Viresh Pati,Yubin Kim,Vinh Pham,Jevon Twitty,Shihao Yang,Jiecheng Lu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents $\textbf{CAPS}$ (Clock-weighted Aggregation with Prefix-products and Softmax), a structured attention mechanism for time series forecasting that decouples three distinct temporal structures: global trends, local shocks, and seasonal patterns. Standard softmax attention entangles these through global normalization, while recent recurrent models sacrifice long-term, order-independent selection for order-dependent causal structure. CAPS combines SO(2) rotations for phase alignment with three additive gating paths -- Riemann softmax, prefix-product gates, and a Clock baseline -- within a single attention layer. We introduce the Clock mechanism, a learned temporal weighting that modulates these paths through a shared notion of temporal importance. Experiments on long- and short-term forecasting benchmarks surpass vanilla softmax and linear attention mechanisms and demonstrate competitive performance against seven strong baselines with linear complexity. Our code implementation is available at https://github.com/vireshpati/CAPS-Attention.

</details>


### [182] [TabPFN for Zero-shot Parametric Engineering Design Generation](https://arxiv.org/abs/2602.02735)
*Ke Wang,Yifan Tang,Nguyen Gia Hien Vu,Faez Ahmed,G. Gary Wang*

Main category: cs.LG

TL;DR: 提出基于TabPFN的零样本参数化工设计框架，仅需少量参考样本即可实现条件生成，无需任务特定训练


<details>
  <summary>Details</summary>
Motivation: 传统生成模型在工程设计中面临计算成本高、需大量训练数据、需求变更时需重新训练等问题，限制其在实时工程流程中的应用

Method: 采用TabPFN模型，基于目标性能指标顺序生成设计参数，无需任务特定训练或微调，仅需有限参考样本

Result: 在三个工程数据集上验证效果：船体设计、BlendedNet飞机、UIUC翼型；生成多样性强，对采样、分辨率、参数维度变化稳健，性能误差低（如船体设计性能误差低于2%），相比扩散模型显著降低计算开销和数据需求

Conclusion: 零样本高效生成框架能够为工程设计提供实用高效工具，支持快速部署、灵活适应新设计场景，易于集成到真实工程工作流

Abstract: Deep generative models for engineering design often require substantial computational cost, large training datasets, and extensive retraining when design requirements or datasets change, limiting their applicability in real-world engineering design workflow. In this work, we propose a zero-shot generation framework for parametric engineering design based on TabPFN, enabling conditional design generation using only a limited number of reference samples and without any task-specific model training or fine-tuning. The proposed method generates design parameters sequentially conditioned on target performance indicators, providing a flexible alternative to conventional generative models. The effectiveness of the proposed approach is evaluated on three engineering design datasets, i.e., ship hull design, BlendedNet aircraft, and UIUC airfoil. Experimental results demonstrate that the proposed method achieves competitive diversity across highly structured parametric design spaces, remains robust to variations in sampling, resolution and parameter dimensionality of geometry generation, and achieves a low performance error (e.g., less than 2% in generated ship hull designs' performance). Compared with diffusion-based generative models, the proposed framework significantly reduces computational overhead and data requirements while preserving reliable generation performance. These results highlight the potential of zero-shot, data-efficient generation as a practical and efficient tool for engineering design, enabling rapid deployment, flexible adaptation to new design settings, and ease of integration into real-world engineering workflows.

</details>


### [183] [Entropy-Guided Dynamic Tokens for Graph-LLM Alignment in Molecular Understanding](https://arxiv.org/abs/2602.02742)
*Zihao Jing,Qiuhao Zeng,Ruiyi Fang,Yan Sun,Boyu Wang,Pingzhao Hu*

Main category: cs.LG

TL;DR: EDT-Former是一种熵引导的动态令牌转换器，通过生成与信息丰富的分子片段对齐的令牌来提升大语言模型对分子图的理解能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）难以有效理解分子图结构。现有的图-LLM连接方法通常采用为视觉任务设计的固定长度静态令牌方案，忽略了立体化学和子结构语境，且通常需要成本高昂的LLM主干微调，限制了效率和泛化能力。

Method: 提出EDT-Former（熵引导的动态令牌转换器），该模型生成与信息丰富的分子片段对齐的令牌，从而保留局部和全局结构特征。该模型实现了冻结图编码器与LLMs之间的对齐，无需微调LLM主干（嵌入层除外），实现了计算高效的微调。

Result: 在MoleculeQA、分子导向的Mol-Instructions以及性质预测基准（TDC、MoleculeNet）上取得了最先进的结果，证明了其在可扩展和可泛化的多模态分子理解方面的有效性。

Conclusion: EDT-Former通过创新的动态令牌生成方案，成功解决了现有方法在分子图理解中的局限性，为高效的分子多模态理解提供了有效的解决方案。

Abstract: Molecular understanding is central to advancing areas such as scientific discovery, yet Large Language Models (LLMs) struggle to understand molecular graphs effectively. Existing graph-LLM bridges often adapt the Q-Former-style connector with fixed-length static tokens, which is originally designed for vision tasks. These designs overlook stereochemistry and substructural context and typically require costly LLM-backbone fine-tuning, limiting efficiency and generalization. We introduce EDT-Former, an Entropy-guided Dynamic Token Transformer that generates tokens aligned with informative molecular patches, thereby preserving both local and global structural features for molecular graph understanding. Beyond prior approaches, EDT-Former enables alignment between frozen graph encoders and LLMs without tuning the LLM backbone (excluding the embedding layer), resulting in computationally efficient finetuning, and achieves stateof-the-art results on MoleculeQA, Molecule-oriented Mol-Instructions, and property prediction benchmarks (TDC, MoleculeNet), underscoring its effectiveness for scalable and generalizable multimodal molecular understanding

</details>


### [184] [On the Sample Efficiency of Inverse Dynamics Models for Semi-Supervised Imitation Learning](https://arxiv.org/abs/2602.02762)
*Sacha Morin,Moonsub Byeon,Alexia Jolicoeur-Martineau,Sébastien Lachapelle*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Semi-supervised imitation learning (SSIL) consists in learning a policy from a small dataset of action-labeled trajectories and a much larger dataset of action-free trajectories. Some SSIL methods learn an inverse dynamics model (IDM) to predict the action from the current state and the next state. An IDM can act as a policy when paired with a video model (VM-IDM) or as a label generator to perform behavior cloning on action-free data (IDM labeling). In this work, we first show that VM-IDM and IDM labeling learn the same policy in a limit case, which we call the IDM-based policy. We then argue that the previously observed advantage of IDM-based policies over behavior cloning is due to the superior sample efficiency of IDM learning, which we attribute to two causes: (i) the ground-truth IDM tends to be contained in a lower complexity hypothesis class relative to the expert policy, and (ii) the ground-truth IDM is often less stochastic than the expert policy. We argue these claims based on insights from statistical learning theory and novel experiments, including a study of IDM-based policies using recent architectures for unified video-action prediction (UVA). Motivated by these insights, we finally propose an improved version of the existing LAPO algorithm for latent action policy learning.

</details>


### [185] [Privately Fine-Tuned LLMs Preserve Temporal Dynamics in Tabular Data](https://arxiv.org/abs/2602.02766)
*Lucas Rosenblatt,Peihan Liu,Ryan McKenna,Natalia Ponomareva*

Main category: cs.LG

TL;DR: 提出了PATH框架，首次将大型语言模型的自回归能力应用于纵向数据集的差分隐私合成生成，解决了传统方法无法保持时间连贯性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私合成表格数据研究主要关注独立同分布行数据，忽略了电子健康记录等纵向数据集的时序复杂性，其中每个用户贡献的是整个时间序列事件子表。实践中将用户历史展平为高维向量的做法会破坏时间一致性。

Method: 开发PATH框架：1）将整个表格作为合成单元处理；2）利用差分隐私微调的大型语言模型的自回归能力；3）以生成完整时间序列的方式合成数据，而非独立边际分布。

Result: 评估显示PATH能有效捕捉传统方法遗漏的长程依赖关系：1）将真实轨迹分布距离降低60%以上；2）将状态转移错误减少近50%；3）同时保持与领先边际机制相当的边际保真度。

Conclusion: PATH框架证明在处理纵向数据集时，基于边际分布的方法存在根本性限制；通过自回归语言模型维护时间连贯性是生成高质量差分隐私合成数据的关键；该方法为时序敏感数据合成开辟了新方向。

Abstract: Research on differentially private synthetic tabular data has largely focused on independent and identically distributed rows where each record corresponds to a unique individual. This perspective neglects the temporal complexity in longitudinal datasets, such as electronic health records, where a user contributes an entire (sub) table of sequential events. While practitioners might attempt to model such data by flattening user histories into high-dimensional vectors for use with standard marginal-based mechanisms, we demonstrate that this strategy is insufficient. Flattening fails to preserve temporal coherence even when it maintains valid marginal distributions. We introduce PATH, a novel generative framework that treats the full table as the unit of synthesis and leverages the autoregressive capabilities of privately fine-tuned large language models. Extensive evaluations show that PATH effectively captures long-range dependencies that traditional methods miss. Empirically, our method reduces the distributional distance to real trajectories by over 60% and reduces state transition errors by nearly 50% compared to leading marginal mechanisms while achieving similar marginal fidelity.

</details>


### [186] [Provable Effects of Data Replay in Continual Learning: A Feature Learning Perspective](https://arxiv.org/abs/2602.02767)
*Meng Ding,Jinhui Xu,Kaiyi Ji*

Main category: cs.LG

TL;DR: 该论文从特征学习角度建立了全数据回放持续学习的理论分析框架，识别出信噪比（SNR）是影响遗忘的关键因素，发现即使全数据回放下遗忘仍可能发生，但充分信号积累可以恢复早期任务，并揭示了优先训练高信号任务的新排序策略。


<details>
  <summary>Details</summary>
Motivation: 持续学习（CL）中灾难性遗忘是核心挑战，数据回放方法被认为是简单有效的解决方案，但全数据回放的理论有效性尚未充分探索。本文旨在从理论角度分析全数据回放在持续学习中的效果和局限性。

Method: 采用多视图数据模型，从特征学习视角建立全数据回放的理论分析框架。重点关注M个任务的增量二元分类，通过信号噪声比（SNR）分析遗忘机制，并研究任务排序对学习效果的影响。

Result: 理论分析验证：1）即使在全数据回放下，当后续任务的累积噪声主导早期任务的信号时仍会发生遗忘；2）充分信号积累可使数据回放进早期任务，即使其初始学习效果不佳；3）优先训练高信号任务有助于学习低信号任务并防止灾难性遗忘。通过合成和真实实验验证了理论发现。

Conclusion: 全数据回放并非持续学习的万能解决方案，信噪比在决定遗忘程度中起关键作用。合理的任务排序策略（优先高信号任务）可以改善学习效果和减轻遗忘。该研究为设计更有效的持续学习算法提供了理论基础。

Abstract: Continual learning (CL) aims to train models on a sequence of tasks while retaining performance on previously learned ones. A core challenge in this setting is catastrophic forgetting, where new learning interferes with past knowledge. Among various mitigation strategies, data-replay methods, where past samples are periodically revisited, are considered simple yet effective, especially when memory constraints are relaxed. However, the theoretical effectiveness of full data replay, where all past data is accessible during training, remains largely unexplored. In this paper, we present a comprehensive theoretical framework for analyzing full data-replay training in continual learning from a feature learning perspective. Adopting a multi-view data model, we identify the signal-to-noise ratio (SNR) as a critical factor affecting forgetting. Focusing on task-incremental binary classification across $M$ tasks, our analysis verifies two key conclusions: (1) forgetting can still occur under full replay when the cumulative noise from later tasks dominates the signal from earlier ones; and (2) with sufficient signal accumulation, data replay can recover earlier tasks-even if their initial learning was poor. Notably, we uncover a novel insight into task ordering: prioritizing higher-signal tasks not only facilitates learning of lower-signal tasks but also helps prevent catastrophic forgetting. We validate our theoretical findings through synthetic and real-world experiments that visualize the interplay between signal learning and noise memorization across varying SNRs and task correlation regimes.

</details>


### [187] [Cross-Temporal Attention Fusion (CTAF) for Multimodal Physiological Signals in Self-Supervised Learning](https://arxiv.org/abs/2602.02784)
*Arian Khorasani,Théophile Demazure*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study multimodal affect modeling when EEG and peripheral physiology are asynchronous, which most fusion methods ignore or handle with costly warping. We propose Cross-Temporal Attention Fusion (CTAF), a self-supervised module that learns soft bidirectional alignments between modalities and builds a robust clip embedding using time-aware cross attention, a lightweight fusion gate, and alignment-regularized contrastive objectives with optional weak supervision. On the K-EmoCon dataset, under leave-one-out cross-validation evaluation, CTAF yields higher cosine margins for matched pairs and better cross-modal token retrieval within one second, and it is competitive with the baseline on three-bin accuracy and macro-F1 while using few labels. Our contributions are a time-aware fusion mechanism that directly models correspondence, an alignment-driven self-supervised objective tailored to EEG and physiology, and an evaluation protocol that measures alignment quality itself. Our approach accounts for the coupling between the central and autonomic nervous systems in psychophysiological time series. These results indicate that CTAF is a strong step toward label-efficient, generalizable EEG-peripheral fusion under temporal asynchrony.

</details>


### [188] [LEMON: Local Explanations via Modality-aware OptimizatioN](https://arxiv.org/abs/2602.02786)
*Yu Qin,Phillip Sloan,Raul Santos-Rodriguez,Majid Mirmehdi,Telmo de Menezes e Silva Filho*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multimodal models are ubiquitous, yet existing explainability methods are often single-modal, architecture-dependent, or too computationally expensive to run at scale. We introduce LEMON (Local Explanations via Modality-aware OptimizatioN), a model-agnostic framework for local explanations of multimodal predictions. LEMON fits a single modality-aware surrogate with group-structured sparsity to produce unified explanations that disentangle modality-level contributions and feature-level attributions. The approach treats the predictor as a black box and is computationally efficient, requiring relatively few forward passes while remaining faithful under repeated perturbations. We evaluate LEMON on vision-language question answering and a clinical prediction task with image, text, and tabular inputs, comparing against representative multimodal baselines. Across backbones, LEMON achieves competitive deletion-based faithfulness while reducing black-box evaluations by 35-67 times and runtime by 2-8 times compared to strong multimodal baselines.

</details>


### [189] [Structure-Preserving Learning Improves Geometry Generalization in Neural PDEs](https://arxiv.org/abs/2602.02788)
*Benjamin D. Shaffer,Shawn Koohy,Brooks Kinch,M. Ani Hsieh,Nathaniel Trask*

Main category: cs.LG

TL;DR: Geo-NeW是一种数据驱动的有限元方法，针对偏微分方程（PDEs）开发，能够实现实时求解并保持结构精度，适应未见的几何形状。


<details>
  <summary>Details</summary>
Motivation: 旨在开发科学和工程中的物理基础模型，为偏微分方程提供实时解，在适应未见几何形状时保持物理守恒定律和数值精度。

Method: 提出一种称为‘Geo-NeW’的数据驱动有限元方法，其通过联合学习微分算子和基于底层几何的兼容降维有限元空间，利用有限元外微积分（FEEC）保持物理守恒定律，并借助基于Transformer的编码在离散网格中嵌入几何信息以增强归纳偏置。

Result: 在多个稳态偏微分方程基准测试中达到最先进的性能，在几何分布外（OOD）的情形下显著优于传统基线模型。

Conclusion: Geo-NeW通过将几何嵌入有限元空间构建，提供了一种强大的归纳偏置，显著提升了神经PDE学习在未见几何上的泛化能力，同时确保解的物理守恒和存在唯一性。

Abstract: We aim to develop physics foundation models for science and engineering that provide real-time solutions to Partial Differential Equations (PDEs) which preserve structure and accuracy under adaptation to unseen geometries. To this end, we introduce General-Geometry Neural Whitney Forms (Geo-NeW): a data-driven finite element method. We jointly learn a differential operator and compatible reduced finite element spaces defined on the underlying geometry. The resulting model is solved to generate predictions, while exactly preserving physical conservation laws through Finite Element Exterior Calculus. Geometry enters the model as a discretized mesh both through a transformer-based encoding and as the basis for the learned finite element spaces. This explicitly connects the underlying geometry and imposed boundary conditions to the solution, providing a powerful inductive bias for learning neural PDEs, which we demonstrate improves generalization to unseen domains. We provide a novel parameterization of the constitutive model ensuring the existence and uniqueness of the solution. Our approach demonstrates state-of-the-art performance on several steady-state PDE benchmarks, and provides a significant improvement over conventional baselines on out-of-distribution geometries.

</details>


### [190] [Causality--Δ: Jacobian-Based Dependency Analysis in Flow Matching Models](https://arxiv.org/abs/2602.02793)
*Reza Rezvan,Gustav Gille,Moritz Schauer,Richard Torkar*

Main category: cs.LG

TL;DR: 通过研究流匹配模型中的雅可比向量积，揭示生成特征的局部线性结构，并开发了一种属性级依赖分析工具


<details>
  <summary>Details</summary>
Motivation: 动机是理解流匹配模型中潜在空间微小扰动如何影响生成特征，探索生成特征的依赖结构，超越传统的相关性分析

Method: 在流匹配框架中分析雅可比向量积，推导高斯和混合高斯分布下的最优漂移及其雅可比的闭式表达式，将流模型与属性分类器结合来估计属性级雅可比向量积

Result: 在低维合成基准中数值雅可比向量积成功恢复解析雅可比矩阵；在图像领域中，该方法在MNIST和CelebA数据集上恢复了经验相关性；通过条件化小分类器-雅可比范数可以按照假设的共同因果结构减少相关性

Conclusion: 即使全局非线性流也表现出局部仿射结构，雅可比向量积为分析生成特征依赖性提供了实际可行的视角，但强调条件化处理并非正式干预操作

Abstract: Flow matching learns a velocity field that transports a base distribution to data. We study how small latent perturbations propagate through these flows and show that Jacobian-vector products (JVPs) provide a practical lens on dependency structure in the generated features. We derive closed-form expressions for the optimal drift and its Jacobian in Gaussian and mixture-of-Gaussian settings, revealing that even globally nonlinear flows admit local affine structure. In low-dimensional synthetic benchmarks, numerical JVPs recover the analytical Jacobians. In image domains, composing the flow with an attribute classifier yields an attribute-level JVP estimator that recovers empirical correlations on MNIST and CelebA. Conditioning on small classifier-Jacobian norms reduces correlations in a way consistent with a hypothesized common-cause structure, while we emphasize that this conditioning is not a formal do intervention.

</details>


### [191] [Joint Learning of Hierarchical Neural Options and Abstract World Model](https://arxiv.org/abs/2602.02799)
*Wasu Top Piriyakulkij,Wolfgang Lehrach,Kevin Ellis,Kevin Murphy*

Main category: cs.LG

TL;DR: AgentOWL是一种联合学习抽象世界模型和分层神经选项的高效采样方法，在Object-Centric Atari游戏中用更少数据学习更多技能。


<details>
  <summary>Details</summary>
Motivation: 实现通过组合现有技能来执行新技能的智能体是AI研究的长期目标，但现有的无模型分层强化学习算法需要大量数据。

Method: 联合学习跨越状态和时间的抽象世界模型以及一组分层神经选项，实现高效采样学习。

Result: 在Object-Centric Atari游戏子集上，该方法比基线方法用更少数据学习到更多技能。

Conclusion: AgentOWL为高效构建可组合技能的智能体提供了一种有前景的方法，实现了更高的样本效率。

Abstract: Building agents that can perform new skills by composing existing skills is a long-standing goal of AI agent research. Towards this end, we investigate how to efficiently acquire a sequence of skills, formalized as hierarchical neural options. However, existing model-free hierarchical reinforcement algorithms need a lot of data. We propose a novel method, which we call AgentOWL (Option and World model Learning Agent), that jointly learns -- in a sample efficient way -- an abstract world model (abstracting across both states and time) and a set of hierarchical neural options. We show, on a subset of Object-Centric Atari games, that our method can learn more skills using much less data than baseline methods.

</details>


### [192] [Membership Inference Attacks from Causal Principles](https://arxiv.org/abs/2602.02819)
*Mathieu Even,Clément Berenfeld,Linus Bleistein,Tudor Cebere,Julie Josse,Aurélien Bellet*

Main category: cs.LG

TL;DR: 本文提出将成员推理攻击评估视为因果推断问题，量化训练数据记忆化的因果效应，为单次训练和零次训练方法提供统计有效性和一致性保证。


<details>
  <summary>Details</summary>
Motivation: 解决传统成员推理攻击评估需要重复训练导致的高计算成本，以及现有单次训练和零次训练方法统计有效性不明确的问题。

Method: 将成员推理攻击评估构建为因果推断问题，定义记忆化为数据点对训练集的因果效应，推导标准因果MIA指标，并为多轮、单次和零次训练场景设计理论保证的实用评估器。

Result: 在真实数据上的实验表明，该方法在无法重复训练和分布偏移情况下仍能提供可靠的记忆化度量，为现代AI系统隐私评估奠定理论基础。

Conclusion: 基于因果推断的成员推理攻击评估框架为隐私风险量化提供了原则性基础，能在限制计算成本时提供统计有效的评估方法。

Abstract: Membership Inference Attacks (MIAs) are widely used to quantify training data memorization and assess privacy risks. Standard evaluation requires repeated retraining, which is computationally costly for large models. One-run methods (single training with randomized data inclusion) and zero-run methods (post hoc evaluation) are often used instead, though their statistical validity remains unclear. To address this gap, we frame MIA evaluation as a causal inference problem, defining memorization as the causal effect of including a data point in the training set. This novel formulation reveals and formalizes key sources of bias in existing protocols: one-run methods suffer from interference between jointly included points, while zero-run evaluations popular for LLMs are confounded by non-random membership assignment. We derive causal analogues of standard MIA metrics and propose practical estimators for multi-run, one-run, and zero-run regimes with non-asymptotic consistency guarantees. Experiments on real-world data show that our approach enables reliable memorization measurement even when retraining is impractical and under distribution shift, providing a principled foundation for privacy evaluation in modern AI systems.

</details>


### [193] [From Tokens to Numbers: Continuous Number Modeling for SVG Generation](https://arxiv.org/abs/2602.02820)
*Michael Ogezi,Martin Bell,Freda Shi,Ethan Smith*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: For certain image generation tasks, vector graphics such as Scalable Vector Graphics (SVGs) offer clear benefits such as increased flexibility, size efficiency, and editing ease, but remain less explored than raster-based approaches. A core challenge is that the numerical, geometric parameters, which make up a large proportion of SVGs, are inefficiently encoded as long sequences of tokens. This slows training, reduces accuracy, and hurts generalization. To address these problems, we propose Continuous Number Modeling (CNM), an approach that directly models numbers as first-class, continuous values rather than discrete tokens. This formulation restores the mathematical elegance of the representation by aligning the model's inputs with the data's continuous nature, removing discretization artifacts introduced by token-based encoding. We then train a multimodal transformer on 2 million raster-to-SVG samples, followed by fine-tuning via reinforcement learning using perceptual feedback to further improve visual quality. Our approach improves training speed by over 30% while maintaining higher perceptual fidelity compared to alternative approaches. This work establishes CNM as a practical and efficient approach for high-quality vector generation, with potential for broader applications. We make our code available http://github.com/mikeogezi/CNM.

</details>


### [194] [A Single Revision Step Improves Token-Efficient LLM Reasoning](https://arxiv.org/abs/2602.02828)
*Yingchuan Zhang,Terry Ma,Wenxuan Zhong,Ping Ma*

Main category: cs.LG

TL;DR: 通过让推理路径互相评审来改进大语言模型的推理精度


<details>
  <summary>Details</summary>
Motivation: 现有多数投票或基于置信度的聚合方法存在根本性'盲点'：它们孤立评估每个推理路径。随着问题难度增加，模型经常生成具有误导性高置信度的幻觉路径，导致真实解决方案被微小差距压制。需要解决这些'接近但未命中'的错误。

Method: 提出PACER（Packet-Conditioned Revision）框架，无需训练，仅推理阶段使用。首先筛选生成的推理路径，构建包含（i）独特候选答案、（ii）聚合置信度分数、（iii）每个答案代表性推理摘要的共识包。然后各个推理路径基于此包进行有针对性的自我审查，识别与广泛共识分叉的逻辑节点并在发现原推理有缺陷时调整。最终通过置信度加权投票获得预测。

Result: 在AIME和BRUMO等具有挑战性的数学竞赛基准上，PACER达到或超过256样本多数投票的精度，显著优于原始集成基线。

Conclusion: PACER通过将简单共识转化为协作逻辑精炼过程，有效提升了LLM在困难推理任务上的表现。

Abstract: Large language models (LLMs) achieve higher accuracy on challenging reasoning tasks by scaling test-time compute through multiple trajectory sampling. However, standard aggregation methods like majority voting or individual confidence-based filtering face a fundamental "blind spot": they evaluate each trace in isolation. As problems scale in difficulty, models often generate hallucinated paths that exhibit misleadingly high confidence, causing the true solution to be suppressed by a narrow margin in traditional voting. We ask: can we enable traces to "peer-review" each other to resolve these near-miss errors?
  We introduce Packet-Conditioned Revision (PACER), a training-free, inference-only framework that enables reasoning traces to revise their conclusions through a structured coordination step. After a preliminary screening of generated traces, PACER constructs a compact consensus packet containing (i) unique candidate answers, (ii) their aggregated confidence scores, and (iii) representative reasoning summaries for each candidate answer. Individual traces then perform a targeted self-review conditioned on this packet, allowing them to identify specific logical junctions where they diverged from the broader consensus and pivot if their original reasoning is found to be flawed. Final predictions are obtained via confidence-weighted voting over these revised trajectories. On challenging competitive math benchmarks such as AIME and BRUMO, PACER matches or exceeds the accuracy of 256-sample majority voting, significantly outperforming raw ensemble baselines by transforming simple consensus into a collaborative logical refinement process.

</details>


### [195] [SC3D: Dynamic and Differentiable Causal Discovery for Temporal and Instantaneous Graphs](https://arxiv.org/abs/2602.02830)
*Sourajit Das,Dibyajyoti Chakraborthy,Romit Maulik*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Discovering causal structures from multivariate time series is a key problem because interactions span across multiple lags and possibly involve instantaneous dependencies. Additionally, the search space of the dynamic graphs is combinatorial in nature. In this study, we propose \textit{Stable Causal Dynamic Differentiable Discovery (SC3D)}, a two-stage differentiable framework that jointly learns lag-specific adjacency matrices and, if present, an instantaneous directed acyclic graph (DAG). In Stage 1, SC3D performs edge preselection through node-wise prediction to obtain masks for lagged and instantaneous edges, whereas Stage 2 refines these masks by optimizing a likelihood with sparsity along with enforcing acyclicity on the instantaneous block. Numerical results across synthetic and benchmark dynamical systems demonstrate that SC3D achieves improved stability and more accurate recovery of both lagged and instantaneous causal structures compared to existing temporal baselines.

</details>


### [196] [Koopman Autoencoders with Continuous-Time Latent Dynamics for Fluid Dynamics Forecasting](https://arxiv.org/abs/2602.02832)
*Rares Grozavescu,Pengyu Zhang,Etienne Meunier,Mark Girolami*

Main category: cs.LG

TL;DR: 本文提出了一种连续时间Koopman框架，通过数值积分方案建模隐空间中的演化过程，能够在推理阶段灵活处理可变时间步长，并显示出对时间分辨率的鲁棒性以及对训练范围外的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统基于自回归的替代模型方法在湍流模拟中往往需要在短期精度和长期稳定性之间做出权衡，而现有的Koopman自编码器大多工作在离散时间设置下，限制了时间灵活性。

Method: 引入连续时间Koopman框架，在隐空间中通过数值积分方案建模演化过程，所学习到的动力学能够近似解析矩阵指数解，实现了高效的长时程预测。

Result: 在经典CFD基准测试中，该方法展示了高精度、良好稳定性以及优异的泛化能力，特别是在处理可变时间步长和超越训练范围的情况下表现出色。

Conclusion: 连续时间Koopman框架为加速湍流模拟提供了一种有效的替代模型方法，克服了传统自回归模型在精度与稳定性之间的权衡问题，并且具有更好的时间灵活性和泛化能力。

Abstract: Data-driven surrogate models have emerged as powerful tools for accelerating the simulation of turbulent flows. However, classical approaches which perform autoregressive rollouts often trade off between strong short-term accuracy and long-horizon stability. Koopman autoencoders, inspired by Koopman operator theory, provide a physics-based alternative by mapping nonlinear dynamics into a latent space where linear evolution is conducted. In practice, most existing formulations operate in a discrete-time setting, limiting temporal flexibility. In this work, we introduce a continuous-time Koopman framework that models latent evolution through numerical integration schemes. By allowing variable timesteps at inference, the method demonstrates robustness to temporal resolution and generalizes beyond training regimes. In addition, the learned dynamics closely adhere to the analytical matrix exponential solution, enabling efficient long-horizon forecasting. We evaluate the approach on classical CFD benchmarks and report accuracy, stability, and extrapolation properties.

</details>


### [197] [Tabula RASA: Exposing and Breaking the Relational Bottleneck in Transformers](https://arxiv.org/abs/2602.02834)
*Jonas Petersen,Camilla Mazzoleni,Riccardo Maggioni*

Main category: cs.LG

TL;DR: 本文介绍了RASA（Relation-Aware Sparse Attention），一种改进Transformer进行多跳关系和抽象推理的方法。通过边缘类型嵌入和稀疏掩码，RASA显著提升了结构化数据的多跳推理能力。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer在多跳关系推理任务上表现有限，尤其是在需要处理结构化数据时。为了解决这一限制，研究团队从电路复杂度角度分析，提出了RASA方法来改进Transformer的推理能力。

Method: RASA通过两种最小化修改增强标准Transformer：1) 边缘类型嵌入：将关系结构注入注意力分数；2) 稀疏掩码：限制注意力仅关注图相邻位置，显著减少注意力搜索空间。

Result: 在MetaQA（1/2/3跳）和WebQuestionsSP基准测试中，RASA优于标准Transformer，能以更低的成本达到GPT-4水平，推理深度增加时优势更明显（在3跳推理上提升7.1分）。尽管没有正式的可学习性保证，但实证验证了结构改进的有效性。

Conclusion: 最小化结构修改能显著提升Transformer在多跳关系推理任务上的表现。RASA通过引入关系感知的稀疏注意力机制，为解决Transformer在结构化数据推理方面的局限性提供了有效途径。

Abstract: Transformers achieve remarkable performance across many domains, yet struggle with tasks requiring multi-hop relational reasoning over structured data. We analyze this limitation through circuit complexity: standard transformers are $\mathsf{TC}^0$-complete and require $Ω(k)$ layers for $k$-hop reasoning. We introduce RASA (Relation-Aware Sparse Attention), a minimal modification adding: (1) edge-type embeddings that inject relational structure into attention scores, and (2) sparse masking that restricts attention to graph-adjacent positions. While RASA has the same asymptotic depth requirements, sparse masking reduces the attention search space from $O(2^{n^2})$ to $O(2^m)$ patterns, and edge biases provide explicit relation routing. Empirically, on MetaQA (1/2/3-hop) and WebQuestionsSP, RASA outperforms standard transformers and matches GPT-4 at lower cost, with advantages growing with reasoning depth (+7.1 points on 3-hop). We do not claim formal learnability guarantees; the contribution is empirical validation that minimal structural modifications substantially improve multi-hop reasoning.

</details>


### [198] [Semantics-Aware Generative Latent Data Augmentation for Learning in Low-Resource Domains](https://arxiv.org/abs/2602.02841)
*Jae-Sung Bae,Minje Kim*

Main category: cs.LG

TL;DR: GeLDA：一种利用条件扩散模型在基础模型潜在空间中进行语义感知生成数据增强的框架，有效解决数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 深度学习方法在数据丰富时表现优异，但在实际应用中常见的少样本场景下表现不佳。虽然基于海量数据训练的基础模型通过提取通用特征表现出较强的泛化能力，但在下游微调时仍受限于有限的标注数据。

Method: GeLDA框架利用条件扩散模型在基础模型诱导的潜在空间中合成样本。该潜在空间相比输入空间维度更低且集中了任务相关信息，使高效高质量的数据生成成为可能。GeLDA通过捕捉类别或子域间语义关系的辅助特征向量来调节生成过程，从而在资源有限的领域进行数据增强。

Result: GeLDA在两大识别任务中验证：在零样本语言特定的语音情感识别中，将Whisper-large基线的未加权平均召回率提高了6.13%；在长尾图像分类中，在ImageNet-LT上达到了74.7%的尾部类别准确率，创造了新的最先进结果。

Conclusion: GeLDA通过语义感知的生成式潜在数据增强框架，在基础模型的低维潜在空间中实现了高效高质量的数据生成，显著提升了数据稀缺场景下深度学习模型的性能，在多个任务中取得了显著的改进效果。

Abstract: Despite strong performance in data-rich regimes, deep learning often underperforms in the data-scarce settings common in practice. While foundation models (FMs) trained on massive datasets demonstrate strong generalization by extracting general-purpose features, they can still suffer from scarce labeled data during downstream fine-tuning. To address this, we propose GeLDA, a semantics-aware generative latent data augmentation framework that leverages conditional diffusion models to synthesize samples in an FM-induced latent space. Because this space is low-dimensional and concentrates task-relevant information compared to the input space, GeLDA enables efficient, high-quality data generation. GeLDA conditions generation on auxiliary feature vectors that capture semantic relationships among classes or subdomains, facilitating data augmentation in low-resource domains. We validate GeLDA in two large-scale recognition tasks: (a) in zero-shot language-specific speech emotion recognition, GeLDA improves the Whisper-large baseline's unweighted average recall by 6.13%; and (b) in long-tailed image classification, it achieves 74.7% tail-class accuracy on ImageNet-LT, setting a new state-of-the-art result.

</details>


### [199] [Causal Flow Q-Learning for Robust Offline Reinforcement Learning](https://arxiv.org/abs/2602.02847)
*Mingxuan Li,Junzhe Zhang,Elias Bareinboim*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Expressive policies based on flow-matching have been successfully applied in reinforcement learning (RL) more recently due to their ability to model complex action distributions from offline data. These algorithms build on standard policy gradients, which assume that there is no unmeasured confounding in the data. However, this condition does not necessarily hold for pixel-based demonstrations when a mismatch exists between the demonstrator's and the learner's sensory capabilities, leading to implicit confounding biases in offline data. We address the challenge by investigating the problem of confounded observations in offline RL from a causal perspective. We develop a novel causal offline RL objective that optimizes policies' worst-case performance that may arise due to confounding biases. Based on this new objective, we introduce a practical implementation that learns expressive flow-matching policies from confounded demonstrations, employing a deep discriminator to assess the discrepancy between the target policy and the nominal behavioral policy. Experiments across 25 pixel-based tasks demonstrate that our proposed confounding-robust augmentation procedure achieves a success rate 120\% that of confounding-unaware, state-of-the-art offline RL methods.

</details>


### [200] [Zero Sum SVD: Balancing Loss Sensitivity for Low Rank LLM Compression](https://arxiv.org/abs/2602.02848)
*Ali Abbasi,Chayne Thrash,Haoran Qin,Shansita Sharma,Sepehr Seifi,Soheil Kolouri*

Main category: cs.LG

TL;DR: ZS-SVD是一种基于SVD的后训练压缩方法，通过全局奇异成分选择和零和规则自动分配异构秩，无需迭代优化，同时在截断后应用单次梯度更新进一步提高性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的内存和计算成本限制了部署。现有的SVD压缩方法要么对相似大小的矩阵采用均匀秩分配（忽略了损失敏感性的差异），要么依赖昂贵的迭代预截断优化来确定各矩阵的秩，需要更高效、自动化的压缩方案。

Method: 提出ZS-SVD方法：1) 通过激活白化和一阶校准损失估计在白化坐标中进行全局奇异成分选择；2) 使用零和规则在整个模型中修剪成分，保持累积预测损失变化接近零，自动产生异构秩；3) 可选的轻量校正步骤：在截断后应用单次投影梯度更新，然后重新截断。

Result: 在多种LLM架构上进行的大量实验表明，该方法在不同基准测试和压缩比率下都能获得一致的性能提升。

Conclusion: ZS-SVD提供了一种高效的后训练压缩方法，能够自动确定异构秩分配，无需复杂优化，在保持性能的同时减少模型存储和加速推理。

Abstract: Advances in large language models have driven strong performance across many tasks, but their memory and compute costs still hinder deployment. SVD-based compression reduces storage and can speed up inference via low-rank factors, yet performance depends on how rank is allocated under a global compression ratio. Prior methods often use homogeneous ranks for similarly sized matrices, despite large differences in loss sensitivity, or rely on expensive iterative pre-truncation optimization to determine per matrix ranks. We propose \textbf{Zero Sum SVD} (\textbf{ZS-SVD}), a post-training method that performs \emph{global} singular component selection using activation whitening and first-order calibration loss estimates in whitened coordinates. \textbf{ZS-SVD} prunes components across the whole model with a \textbf{zero sum} rule that keeps the cumulative predicted loss change near zero, automatically yielding heterogeneous ranks without solving a rank allocation optimization. Motivated by evidence that gradients near pretrained solutions exhibit low rank structure, we also introduce an optional lightweight correction that applies a \textbf{single} projected gradient update after truncation, followed by re-truncation. Extensive experiments across multiple LLM architectures show consistent gains across diverse benchmarks and compression ratios. Code is available at https://github.com/mint-vu/Zero-Sum-SVD

</details>


### [201] [Recurrent Equivariant Constraint Modulation: Learning Per-Layer Symmetry Relaxation from Data](https://arxiv.org/abs/2602.02853)
*Stefanos Pertigkiozoglou,Mircea Petrache,Shubhendu Trivedi,Kostas Daniilidis*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Equivariant neural networks exploit underlying task symmetries to improve generalization, but strict equivariance constraints can induce more complex optimization dynamics that can hinder learning. Prior work addresses these limitations by relaxing strict equivariance during training, but typically relies on prespecified, explicit, or implicit target levels of relaxation for each network layer, which are task-dependent and costly to tune. We propose Recurrent Equivariant Constraint Modulation (RECM), a layer-wise constraint modulation mechanism that learns appropriate relaxation levels solely from the training signal and the symmetry properties of each layer's input-target distribution, without requiring any prior knowledge about the task-dependent target relaxation level. We demonstrate that under the proposed RECM update, the relaxation level of each layer provably converges to a value upper-bounded by its symmetry gap, namely the degree to which its input-target distribution deviates from exact symmetry. Consequently, layers processing symmetric distributions recover full equivariance, while those with approximate symmetries retain sufficient flexibility to learn non-symmetric solutions when warranted by the data. Empirically, RECM outperforms prior methods across diverse exact and approximate equivariant tasks, including the challenging molecular conformer generation on the GEOM-Drugs dataset.

</details>


### [202] [When pre-training hurts LoRA fine-tuning: a dynamical analysis via single-index models](https://arxiv.org/abs/2602.02855)
*Gibbs Nwemadji,Bruno Loureiro,Jean Barbier*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Pre-training on a source task is usually expected to facilitate fine-tuning on similar downstream problems. In this work, we mathematically show that this naive intuition is not always true: excessive pre-training can computationally slow down fine-tuning optimization. We study this phenomenon for low-rank adaptation (LoRA) fine-tuning on single-index models trained under one-pass SGD. Leveraging a summary statistics description of the fine-tuning dynamics, we precisely characterize how the convergence rate depends on the initial fine-tuning alignment and the degree of non-linearity of the target task. The key take away is that even when the pre-training and down- stream tasks are well aligned, strong pre-training can induce a prolonged search phase and hinder convergence. Our theory thus provides a unified picture of how pre-training strength and task difficulty jointly shape the dynamics and limitations of LoRA fine-tuning in a nontrivial tractable model.

</details>


### [203] [Late-Stage Generalization Collapse in Grokking: Detecting anti-grokking with Weightwatcher](https://arxiv.org/abs/2602.02859)
*Hari K Prakash,Charles H Martin*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: \emph{Memorization} in neural networks lacks a precise operational definition and is often inferred from the grokking regime, where training accuracy saturates while test accuracy remains very low. We identify a previously unreported third phase of grokking in this training regime: \emph{anti-grokking}, a late-stage collapse of generalization.
  We revisit two canonical grokking setups: a 3-layer MLP trained on a subset of MNIST and a transformer trained on modular addition, but extended training far beyond standard. In both cases, after models transition from pre-grokking to successful generalization, test accuracy collapses back to chance while training accuracy remains perfect, indicating a distinct post-generalization failure mode.
  To diagnose anti-grokking, we use the open-source \texttt{WeightWatcher} tool based on HTSR/SETOL theory. The primary signal is the emergence of \emph{Correlation Traps}: anomalously large eigenvalues beyond the Marchenko--Pastur bulk in the empirical spectral density of shuffled weight matrices, which are predicted to impair generalization. As a secondary signal, anti-grokking corresponds to the average HTSR layer quality metric $α$ deviating from $2.0$. Neither metric requires access to the test or training data.
  We compare these signals to alternative grokking diagnostic, including $\ell_2$ norms, Activation Sparsity, Absolute Weight Entropy, and Local Circuit Complexity. These track pre-grokking and grokking but fail to identify anti-grokking. Finally, we show that Correlation Traps can induce catastrophic forgetting and/or prototype memorization, and observe similar pathologies in large-scale LLMs, like OSS GPT 20/120B.

</details>


### [204] [A Geometry-Aware Efficient Algorithm for Compositional Entropic Risk Minimization](https://arxiv.org/abs/2602.02877)
*Xiyuan Wei,Linli Zhou,Bokun Wang,Chih-Jen Lin,Tianbao Yang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper studies optimization for a family of problems termed $\textbf{compositional entropic risk minimization}$, in which each data's loss is formulated as a Log-Expectation-Exponential (Log-E-Exp) function. The Log-E-Exp formulation serves as an abstraction of the Log-Sum-Exponential (LogSumExp) function when the explicit summation inside the logarithm is taken over a gigantic number of items and is therefore expensive to evaluate. While entropic risk objectives of this form arise in many machine learning problems, existing optimization algorithms suffer from several fundamental limitations including non-convergence, numerical instability, and slow convergence rates. To address these limitations, we propose a geometry-aware stochastic algorithm, termed $\textbf{SCENT}$, for the dual formulation of entropic risk minimization cast as a min--min optimization problem. The key to our design is a $\textbf{stochastic proximal mirror descent (SPMD)}$ update for the dual variable, equipped with a Bregman divergence induced by a negative exponential function that faithfully captures the geometry of the objective. Our main contributions are threefold: (i) we establish an $O(1/\sqrt{T})$ convergence rate of the proposed SCENT algorithm for convex problems; (ii) we theoretically characterize the advantages of SPMD over standard SGD update for optimizing the dual variable; and (iii) we demonstrate the empirical effectiveness of SCENT on extreme classification, partial AUC maximization, contrastive learning and distributionally robust optimization, where it consistently outperforms existing baselines.

</details>


### [205] [Mixture of Concept Bottleneck Experts](https://arxiv.org/abs/2602.02886)
*Francesco De Santis,Gabriele Ciravegna,Giovanni De Felice,Arianna Casanova,Francesco Giannini,Michelangelo Diligenti,Mateo Espinosa Zarlenga,Pietro Barbiero,Johannes Schneider,Danilo Giordano*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Concept Bottleneck Models (CBMs) promote interpretability by grounding predictions in human-understandable concepts. However, existing CBMs typically fix their task predictor to a single linear or Boolean expression, limiting both predictive accuracy and adaptability to diverse user needs. We propose Mixture of Concept Bottleneck Experts (M-CBEs), a framework that generalizes existing CBMs along two dimensions: the number of experts and the functional form of each expert, exposing an underexplored region of the design space. We investigate this region by instantiating two novel models: Linear M-CBE, which learns a finite set of linear expressions, and Symbolic M-CBE, which leverages symbolic regression to discover expert functions from data under user-specified operator vocabularies. Empirical evaluation demonstrates that varying the mixture size and functional form provides a robust framework for navigating the accuracy-interpretability trade-off, adapting to different user and task needs.

</details>


### [206] [Self-Soupervision: Cooking Model Soups without Labels](https://arxiv.org/abs/2602.02890)
*Anthony Fuller,James R. Green,Evan Shelhamer*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Model soups are strange and strangely effective combinations of parameters. They take a model (the stock), fine-tune it into multiple models (the ingredients), and then mix their parameters back into one model (the soup) to improve predictions. While all known soups require supervised learning, and optimize the same loss on labeled data, our recipes for Self-\emph{Soup}ervision generalize soups to self-supervised learning (SSL). Our Self-Souping lets us flavor ingredients on new data sources, e.g. from unlabeled data from a task for transfer or from a shift for robustness. We show that Self-Souping on corrupted test data, then fine-tuning back on uncorrupted train data, boosts robustness by +3.5\% (ImageNet-C) and +7\% (LAION-C). Self-\emph{Soup}ervision also unlocks countless SSL algorithms to cook the diverse ingredients needed for more robust soups. We show for the first time that ingredients can differ in their SSL hyperparameters -- and more surprisingly, in their SSL algorithms. We cook soups of MAE, MoCoV3, and MMCR ingredients that are more accurate than any one single SSL ingredient.

</details>


### [207] [Controlled disagreement improves generalization in decentralized training](https://arxiv.org/abs/2602.02899)
*Zesen Wang,Mikael Johansson*

Main category: cs.LG

TL;DR: 该研究挑战了去中心化训练因共识误差而性能较差的传统观点，提出DSGD-AC算法通过故意保留非零共识误差来提升泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为去中心化训练的共识误差会损害收敛和泛化性能，即使数据分布均匀。本研究旨在挑战这一观点，探索共识误差作为隐式正则化的潜力。

Method: 提出了去中心化SGD与自适应共识（DSGD-AC）算法，通过时间相关的缩放机制故意保留非消失的共识误差。

Result: 在图像分类和机器翻译基准测试中，DSGD-AC持续超越标准DSGD和集中式SGD，在测试准确性和解平坦性方面表现更优。实验证明共识误差不是随机噪声，而是与主导Hessian子空间对齐的结构化扰动，引导优化趋向更平坦的极小值。

Conclusion: 共识错误是一种有用的隐式正则化机制，为去中心化学习算法的设计开辟了新的视角。

Abstract: Decentralized training is often regarded as inferior to centralized training because the consensus errors between workers are thought to undermine convergence and generalization, even with homogeneous data distributions. This work challenges this view by introducing decentralized SGD with Adaptive Consensus (DSGD-AC), which intentionally preserves non-vanishing consensus errors through a time-dependent scaling mechanism. We prove that these errors are not random noise but systematically align with the dominant Hessian subspace, acting as structured perturbations that guide optimization toward flatter minima. Across image classification and machine translation benchmarks, DSGD-AC consistently surpasses both standard DSGD and centralized SGD in test accuracy and solution flatness. Together, these results establish consensus errors as a useful implicit regularizer and open a new perspective on the design of decentralized learning algorithms.

</details>


### [208] [Manifold-Constrained Energy-Based Transition Models for Offline Reinforcement Learning](https://arxiv.org/abs/2602.02900)
*Zeyu Fang,Zuyuan Zhang,Mahdi Imani,Tian Lan*

Main category: cs.LG

TL;DR: 提出MC-ETM，一种基于流形约束能量函数的转移模型，通过在潜在空间中进行投影扩散采样来提升离线强化学习中的模型准确性和策略鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基于模型的离线强化学习在分布偏移下很脆弱，策略改进会将rollouts推向数据集支持较弱的区域，模型误差累积导致严重的价值高估问题。

Method: 1. 训练条件能量转移模型（MC-ETM），使用流形投影-扩散负采样器；
2. 学习潜在状态流形，通过扰动潜在代码并在潜在空间中运行Langevin动力学生成近流形硬负样本；
3. 在策略优化中，使用学习到的能量作为可靠性信号：当采样下一个状态的最小能量超过阈值时截断rollouts；
4. 通过基于Q值分散的悲观惩罚稳定Bellman备份；
5. 通过混合悲观MDP公式化MC-ETM。

Result: MC-ETM提高了多步动态保真度，在标准离线控制基准测试中获得了更高的归一化回报，特别是在不规则动态和稀疏数据覆盖情况下表现更好。

Conclusion: MC-ETM通过流形约束和能量建模有效处理了离线强化学习中的分布偏移问题，提高了模型准确性和策略性能，为处理稀疏数据和不规则环境下的决策问题提供了有效解决方案。

Abstract: Model-based offline reinforcement learning is brittle under distribution shift: policy improvement drives rollouts into state--action regions weakly supported by the dataset, where compounding model error yields severe value overestimation. We propose Manifold-Constrained Energy-based Transition Models (MC-ETM), which train conditional energy-based transition models using a manifold projection--diffusion negative sampler. MC-ETM learns a latent manifold of next states and generates near-manifold hard negatives by perturbing latent codes and running Langevin dynamics in latent space with the learned conditional energy, sharpening the energy landscape around the dataset support and improving sensitivity to subtle out-of-distribution deviations. For policy optimization, the learned energy provides a single reliability signal: rollouts are truncated when the minimum energy over sampled next states exceeds a threshold, and Bellman backups are stabilized via pessimistic penalties based on Q-value-level dispersion across energy-guided samples. We formalize MC-ETM through a hybrid pessimistic MDP formulation and derive a conservative performance bound separating in-support evaluation error from truncation risk. Empirically, MC-ETM improves multi-step dynamics fidelity and yields higher normalized returns on standard offline control benchmarks, particularly under irregular dynamics and sparse data coverage.

</details>


### [209] [Weighted Temporal Decay Loss for Learning Wearable PPG Data with Sparse Clinical Labels](https://arxiv.org/abs/2602.02917)
*Yunsung Chung,Keum San Chun,Migyeong Gwak,Han Feng,Yingshuo Liu,Chanho Lim,Viswam Nathan,Nassir Marrouche,Sharanya Arcot Desai*

Main category: cs.LG

TL;DR: 本文提出了一种基于时间权重衰减的PPG生物信号训练策略，以解决临床标签稀疏导致的监督信号随时间可靠性下降的问题。


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备和AI技术的发展推动了基于PPG的健康监测应用，但临床标签的稀疏性使得远离实验室采血时间点的生物信号监督可靠性降低。

Method: 引入简单训练策略，学习基于生物标志物特异性的样本权重衰减函数（随时间间隔衰减），在损失函数中使用加权并添加正则化防止平凡解。比较了四种衰减函数族。

Result: 在450名参与者的10种生物标志物PPG数据上，该方法平均AUPRC达到0.715，优于自监督基线（0.674）和基于特征的随机森林（0.626）。线性衰减函数表现最稳健。衰减率可解释为不同生物标志物的PPG证据时效性。

Conclusion: 提出的时间加权策略能有效提升稀疏标签下PPG生物标志物预测性能，且学习的衰减率提供了生物标志物时敏性的可解释性视角。

Abstract: Advances in wearable computing and AI have increased interest in leveraging PPG for health monitoring over the past decade. One of the biggest challenges in developing health algorithms based on such biosignals is the sparsity of clinical labels, which makes biosignals temporally distant from lab draws less reliable for supervision. To address this problem, we introduce a simple training strategy that learns a biomarker-specific decay of sample weight over the time gap between a segment and its ground truth label and uses this weight in the loss with a regularizer to prevent trivial solutions. On smartwatch PPG from 450 participants across 10 biomarkers, the approach improves over baselines. In the subject-wise setting, the proposed approach averages 0.715 AUPRC, compared to 0.674 for a fine-tuned self-supervised baseline and 0.626 for a feature-based Random Forest. A comparison of four decay families shows that a simple linear decay function is most robust on average. Beyond accuracy, the learned decay rates summarize how quickly each biomarker's PPG evidence becomes stale, providing an interpretable view of temporal sensitivity.

</details>


### [210] [Rare Event Early Detection: A Dataset of Sepsis Onset for Critically Ill Trauma Patients](https://arxiv.org/abs/2602.02930)
*Yin Jin,Tucker R. Stewart,Deyi Zhou,Chhavi Gupta,Arjita Nema,Scott C. Brakenridge,Grant E. O'Keefe,Juhua Hu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Sepsis is a major public health concern due to its high morbidity, mortality, and cost. Its clinical outcome can be substantially improved through early detection and timely intervention. By leveraging publicly available datasets, machine learning (ML) has driven advances in both research and clinical practice. However, existing public datasets consider ICU patients (Intensive Care Unit) as a uniform group and neglect the potential challenges presented by critically ill trauma patients in whom injury-related inflammation and organ dysfunction can overlap with the clinical features of sepsis. We propose that a targeted identification of post-traumatic sepsis is necessary in order to develop methods for early detection. Therefore, we introduce a publicly available standardized post-trauma sepsis onset dataset extracted, relabeled using standardized post-trauma clinical facts, and validated from MIMIC-III. Furthermore, we frame early detection of post-trauma sepsis onset according to clinical workflow in ICUs in a daily basis resulting in a new rare event detection problem. We then establish a general benchmark through comprehensive experiments, which shows the necessity of further advancements using this new dataset. The data code is available at https://github.com/ML4UWHealth/SepsisOnset_TraumaCohort.git.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [211] [Experience-Driven Multi-Agent Systems Are Training-free Context-aware Earth Observers](https://arxiv.org/abs/2602.02559)
*Pengyu Dai,Weihao Xuan,Junjue Wang,Hongruixuan Chen,Jian Song,Yafei Ou,Naoto Yokoya*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances have enabled large language model (LLM) agents to solve complex tasks by orchestrating external tools. However, these agents often struggle in specialized, tool-intensive domains that demand long-horizon execution, tight coordination across modalities, and strict adherence to implicit tool constraints. Earth Observation (EO) tasks exemplify this challenge due to the multi-modal and multi-temporal data inputs, as well as the requirements of geo-knowledge constraints (spectrum library, spatial reasoning, etc): many high-level plans can be derailed by subtle execution errors that propagate through a pipeline and invalidate final results. A core difficulty is that existing agents lack a mechanism to learn fine-grained, tool-level expertise from interaction. Without such expertise, they cannot reliably configure tool parameters or recover from mid-execution failures, limiting their effectiveness in complex EO workflows. To address this, we introduce \textbf{GeoEvolver}, a self-evolving multi-agent system~(MAS) that enables LLM agents to acquire EO expertise through structured interaction without any parameter updates. GeoEvolver decomposes each query into independent sub-goals via a retrieval-augmented multi-agent orchestrator, then explores diverse tool-parameter configurations at the sub-goal level. Successful patterns and root-cause attribution from failures are then distilled in an evolving memory bank that provides in-context demonstrations for future queries. Experiments on three tool-integrated EO benchmarks show that GeoEvolver consistently improves end-to-end task success, with an average gain of 12\% across multiple LLM backbones, demonstrating that EO expertise can emerge progressively from efficient, fine-grained interactions with the environment.

</details>


### [212] [Uncertainty and Fairness Awareness in LLM-Based Recommendation Systems](https://arxiv.org/abs/2602.02582)
*Chandan Kumar Sah,Xiaoli Lian,Li Zhang,Tony Xu,Syed Shazaib Shah*

Main category: cs.AI

TL;DR: 评估LLM推荐中的不确定性、公平性和偏差，提出新的评估方法和基准以提升推荐LLM的可信度和公平性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的零-shot推荐能利用广泛的上下文知识，但预测不确定性和内嵌偏差威胁其可靠性和公平性，需要系统评估这些因素对推荐准确性、一致性和可信度的影响。

Method: 提出了一种结合预测不确定性（通过熵量化）和公平性评估的评估框架；引入了包含8个人口统计属性（31个分类值）的基准数据集，覆盖电影和音乐两个领域；通过案例研究（包括提示扰动如拼写错误和多语言输入）分析系统偏差；并将人格感知公平性整合到RecLLM评估流程中。

Result: Google DeepMind Gemini 1.5 Flash在特定敏感属性上表现出系统性不公平（SNSR为0.1363，SNSV为0.0507）；这些不公平情况在提示扰动下仍然存在；揭示了人格特征与偏差模式的关联以及个性化与群体公平性之间的权衡。

Conclusion: 提出了新的不确定性感知评估方法用于RecLLM，建立了人格档案知情公平性基准，提高了LLM推荐的可解释性和公平性；这些成果为更安全、更可解释的RecLLM奠定了基础，并激励未来关于多模型基准和自适应校准的研究以实现可信部署。

Abstract: Large language models (LLMs) enable powerful zero-shot recommendations by leveraging broad contextual knowledge, yet predictive uncertainty and embedded biases threaten reliability and fairness. This paper studies how uncertainty and fairness evaluations affect the accuracy, consistency, and trustworthiness of LLM-generated recommendations. We introduce a benchmark of curated metrics and a dataset annotated for eight demographic attributes (31 categorical values) across two domains: movies and music. Through in-depth case studies, we quantify predictive uncertainty (via entropy) and demonstrate that Google DeepMind's Gemini 1.5 Flash exhibits systematic unfairness for certain sensitive attributes; measured similarity-based gaps are SNSR at 0.1363 and SNSV at 0.0507. These disparities persist under prompt perturbations such as typographical errors and multilingual inputs. We further integrate personality-aware fairness into the RecLLM evaluation pipeline to reveal personality-linked bias patterns and expose trade-offs between personalization and group fairness. We propose a novel uncertainty-aware evaluation methodology for RecLLMs, present empirical insights from deep uncertainty case studies, and introduce a personality profile-informed fairness benchmark that advances explainability and equity in LLM recommendations. Together, these contributions establish a foundation for safer, more interpretable RecLLMs and motivate future work on multi-model benchmarks and adaptive calibration for trustworthy deployment.

</details>


### [213] [A Positive Case for Faithfulness: LLM Self-Explanations Help Predict Model Behavior](https://arxiv.org/abs/2602.02639)
*Harry Mayne,Justin Singh Kang,Dewi Gould,Kannan Ramchandran,Adam Mahdi,Noah Y. Siegel*

Main category: cs.AI

TL;DR: 论文介绍了归一化模拟增益(NSG)作为评估LLM自我解释忠实度的新指标，发现自我解释相比外部模型解释能更好预测模型行为，但仍有5-15%的自我解释存在严重误导性


<details>
  <summary>Details</summary>
Motivation: 现有LLM自我解释的忠实度评估方法存在局限，通常依赖对抗性提示或检测推理错误，忽视了解释的预测价值。需要一种通用的、可扩展的指标来评估自我解释是否能反映模型真实的推理过程

Method: 提出归一化模拟增益(NSG)指标，基于一个核心思想：如果解释是忠实的，观察者应该能够学习到模型的决策标准，从而更好地预测其在相关输入上的行为。评估了18个前沿专有和开源模型在7,000个来自健康、商业、伦理等领域数据集的对抗样本上的表现

Result: 自我解释显著改善了模型行为预测能力(NSG提升11-37%)；自我解释比外部模型生成的解释提供更多预测信息，即使外部模型更强；同时发现，所有模型中5-15%的自我解释存在严重误导性

Conclusion: 虽然LLM自我解释存在不完美之处(如部分解释具有误导性)，但它们确实编码了有助于预测模型行为的信息，且自我知识带来的优势是外部解释方法无法复制的，这为自我解释的应用提供了积极支持

Abstract: LLM self-explanations are often presented as a promising tool for AI oversight, yet their faithfulness to the model's true reasoning process is poorly understood. Existing faithfulness metrics have critical limitations, typically relying on identifying unfaithfulness via adversarial prompting or detecting reasoning errors. These methods overlook the predictive value of explanations. We introduce Normalized Simulatability Gain (NSG), a general and scalable metric based on the idea that a faithful explanation should allow an observer to learn a model's decision-making criteria, and thus better predict its behavior on related inputs. We evaluate 18 frontier proprietary and open-weight models, e.g., Gemini 3, GPT-5.2, and Claude 4.5, on 7,000 counterfactuals from popular datasets covering health, business, and ethics. We find self-explanations substantially improve prediction of model behavior (11-37% NSG). Self-explanations also provide more predictive information than explanations generated by external models, even when those models are stronger. This implies an advantage from self-knowledge that external explanation methods cannot replicate. Our approach also reveals that, across models, 5-15% of self-explanations are egregiously misleading. Despite their imperfections, we show a positive case for self-explanations: they encode information that helps predict model behavior.

</details>


### [214] [ATLAS : Adaptive Self-Evolutionary Research Agent with Task-Distributed Multi-LLM Supporters](https://arxiv.org/abs/2602.02709)
*Ujin Jeon,Jiyong Kwon,Madison Ann Sullivan,Caleb Eunho Lee,Guang Lin*

Main category: cs.AI

TL;DR: 提出ATLAS框架，通过任务分发和EvoDPO算法解决多智能体系统中长期任务的适应性问题，在非平稳环境中表现优于静态基线。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统在提示优化和问题解决方面表现良好，但在长期任务中面临固定求解器或静态偏好优化带来的可扩展性问题，需要适应非平稳环境的动态优化机制。

Method: 设计ATLAS任务分发框架：1）迭代开发轻量级研究智能体 2）将探索、超参数调优、参考策略管理等角色分配给专业支持智能体 3）核心EvoDPO算法自适应更新阶段索引的参考策略 4）基于概念漂移的偏好上下文赌博机理论分析。

Result: 在非平稳线性上下文赌博机和科学机器学习（SciML）的1D Burgers方程损失重加权实验中，ATLAS相比静态单智能体基线提高了稳定性和性能。

Conclusion: ATLAS通过任务分发和自适应参考策略更新，有效解决了长期任务中的非平稳优化问题，为多智能体系统在动态环境中的应用提供了新思路。

Abstract: Recent multi-LLM agent systems perform well in prompt optimization and automated problem-solving, but many either keep the solver frozen after fine-tuning or rely on a static preference-optimization loop, which becomes intractable for long-horizon tasks. We propose ATLAS (Adaptive Task-distributed Learning for Agentic Self-evolution), a task-distributed framework that iteratively develops a lightweight research agent while delegating complementary roles to specialized supporter agents for exploration, hyperparameter tuning, and reference policy management. Our core algorithm, Evolving Direct Preference Optimization (EvoDPO), adaptively updates the phase-indexed reference policy. We provide a theoretical regret analysis for a preference-based contextual bandit under concept drift. In addition, experiments were conducted on non-stationary linear contextual bandits and scientific machine learning (SciML) loss reweighting for the 1D Burgers' equation. Both results show that ATLAS improves stability and performance over a static single-agent baseline.

</details>


### [215] [Dynamic Mix Precision Routing for Efficient Multi-step LLM Interaction](https://arxiv.org/abs/2602.02711)
*Yuanzhe Li,Jianing Deng,Jingtong Hu,Tianlong Chen,Song Wang,Huanrui Yang*

Main category: cs.AI

TL;DR: 本文提出一种动态混合精度路由框架，通过识别步骤敏感度自适应选择高精度或低精度LLM，在降低推理成本的同时保持长时程决策性能。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型在长时程决策任务中表现优异，但与大型模型进行多步交互会产生高昂推理成本。现有方法普遍认为更高任务成功率需要使用更大更强的LLM，这导致了性能与成本之间的权衡问题。

Method: 基于观察到交互步骤间存在不同精度敏感度，提出动态混合精度路由框架，在每一步决策中自适应选择高精度或低精度LLM。路由器通过两阶段流程训练：1）基于KL散度的监督学习识别精度敏感步骤；2）使用组相对策略优化（GRPO）进一步提升任务成功率。

Result: 在ALFWorld环境上的实验表明，该方法在准确率-成本权衡方面显著优于单精度基线方法和启发式路由方法。

Conclusion: 动态混合精度路由框架能够有效平衡长时程决策任务中的性能与成本，为实际部署中优化LLM推理效率提供了可行方案。

Abstract: Large language models (LLM) achieve strong performance in long-horizon decision-making tasks through multi-step interaction and reasoning at test time. While practitioners commonly believe a higher task success rate necessitates the use of a larger and stronger LLM model, multi-step interaction with a large LLM incurs prohibitive inference cost. To address this problem, we explore the use of low-precision quantized LLM in the long-horizon decision-making process. Based on the observation of diverse sensitivities among interaction steps, we propose a dynamic mix-precision routing framework that adaptively selects between high-precision and low-precision LLMs at each decision step. The router is trained via a two-stage pipeline, consisting of KL-divergence-based supervised learning that identifies precision-sensitive steps, followed by Group-Relative Policy Optimization (GRPO) to further improve task success rates. Experiments on ALFWorld demonstrate that our approach achieves a great improvement on accuracy-cost trade-off over single-precision baselines and heuristic routing methods.

</details>


### [216] [Scaling-Aware Adapter for Structure-Grounded LLM Reasoning](https://arxiv.org/abs/2602.02780)
*Zihao Jing,Qiuhao Zeng,Ruiyi Fang,Yan Yi Li,Yan Sun,Boyu Wang,Pingzhao Hu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) are enabling reasoning over biomolecular structures, yet existing methods remain modality-specific and typically compress structural inputs through sequence-based tokenization or fixed-length query connectors. Such architectures either omit the geometric groundings requisite for mitigating structural hallucinations or impose inflexible modality fusion bottlenecks that concurrently over-compress and suboptimally allocate structural tokens, thereby impeding the realization of generalized all-atom reasoning. We introduce Cuttlefish, a unified all-atom LLM that grounds language reasoning in geometric cues while scaling modality tokens with structural complexity. First, Scaling-Aware Patching leverages an instruction-conditioned gating mechanism to generate variable-size patches over structural graphs, adaptively scaling the query token budget with structural complexity to mitigate fixed-length connector bottlenecks. Second, Geometry Grounding Adapter refines these adaptive tokens via cross-attention to modality embeddings and injects the resulting modality tokens into the LLM, exposing explicit geometric cues to reduce structural hallucination. Experiments across diverse all-atom benchmarks demonstrate that Cuttlefish achieves superior performance in heterogeneous structure-grounded reasoning. Code is available at the project repository.

</details>


### [217] [AutoSizer: Automatic Sizing of Analog and Mixed-Signal Circuits via Large Language Model (LLM) Agents](https://arxiv.org/abs/2602.02849)
*Xi Yu,Dmitrii Torbunov,Soumyajit Mandal,Yihui Ren*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The design of Analog and Mixed-Signal (AMS) integrated circuits remains heavily reliant on expert knowledge, with transistor sizing a major bottleneck due to nonlinear behavior, high-dimensional design spaces, and strict performance constraints. Existing Electronic Design Automation (EDA) methods typically frame sizing as static black-box optimization, resulting in inefficient and less robust solutions. Although Large Language Models (LLMs) exhibit strong reasoning abilities, they are not suited for precise numerical optimization in AMS sizing. To address this gap, we propose AutoSizer, a reflective LLM-driven meta-optimization framework that unifies circuit understanding, adaptive search-space construction, and optimization orchestration in a closed loop. It employs a two-loop optimization framework, with an inner loop for circuit sizing and an outer loop that analyzes optimization dynamics and constraints to iteratively refine the search space from simulation feedback. We further introduce AMS-SizingBench, an open benchmark comprising 24 diverse AMS circuits in SKY130 CMOS technology, designed to evaluate adaptive optimization policies under realistic simulator-based constraints. AutoSizer experimentally achieves higher solution quality, faster convergence, and higher success rate across varying circuit difficulties, outperforming both traditional optimization methods and existing LLM-based agents.

</details>


### [218] [STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search](https://arxiv.org/abs/2602.02862)
*Eric Yang,Jong Ha Lee,Jonathan Amar,Elissa Ye,Yugang Jia*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) trained for average correctness often exhibit mode collapse, producing narrow decision behaviors on tasks where multiple responses may be reasonable. This limitation is particularly problematic in ordinal decision settings such as clinical triage, where standard alignment removes the ability to trade off specificity and sensitivity (the ROC operating point) based on contextual constraints. We propose STEER (Steerable Tuning via Evolutionary Ensemble Refinement), a training-free framework that reintroduces this tunable control. STEER constructs a population of natural-language personas through an offline, constrained quality-diversity search that promotes behavioral coverage while enforcing minimum safety, reasoning, and stability thresholds. At inference time, STEER exposes a single, interpretable control parameter that maps a user-specified risk percentile to a selected persona, yielding a monotonic adjustment of decision conservativeness. On two clinical triage benchmarks, STEER achieves broader behavioral coverage compared to temperature-based sampling and static persona ensembles. Compared to a representative post-training method, STEER maintains substantially higher accuracy on unambiguous urgent cases while providing comparable control over ambiguous decisions. These results demonstrate STEER as a safety-preserving paradigm for risk control, capable of steering behavior without compromising domain competence.

</details>


### [219] [Aligning Language Model Benchmarks with Pairwise Preferences](https://arxiv.org/abs/2602.02898)
*Marco Gutierrez,Xinyi Leng,Hannah Cyberey,Jonathan Richard Schwarz,Ahmed Alaa,Thomas Hartvigsen*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Language model benchmarks are pervasive and computationally-efficient proxies for real-world performance. However, many recent works find that benchmarks often fail to predict real utility. Towards bridging this gap, we introduce benchmark alignment, where we use limited amounts of information about model performance to automatically update offline benchmarks, aiming to produce new static benchmarks that predict model pairwise preferences in given test settings. We then propose BenchAlign, the first solution to this problem, which learns preference-aligned weight- ings for benchmark questions using the question-level performance of language models alongside ranked pairs of models that could be collected during deployment, producing new benchmarks that rank previously unseen models according to these preferences. Our experiments show that our aligned benchmarks can accurately rank unseen models according to models of human preferences, even across different sizes, while remaining interpretable. Overall, our work provides insights into the limits of aligning benchmarks with practical human preferences, which stands to accelerate model development towards real utility.

</details>


### [220] [Minimal Computational Preconditions for Subjective Perspective in Artificial Agents](https://arxiv.org/abs/2602.02902)
*Hongju Pae*

Main category: cs.AI

TL;DR: 本研究通过一个缓慢演化的全局潜在状态来实现人工智能中的主观视角，该状态调节快速策略动态但不直接优化行为结果。在具有状态切换的无奖励环境中，这种结构表现出方向依赖的迟滞现象。


<details>
  <summary>Details</summary>
Motivation: 在人工智能系统中建立一种类似主观视角的内部结构，从现象学角度为机器主体性提供可操作化的理论基础。

Method: 采用缓慢演化的全局潜在状态来模拟主观视角，该状态调制快速策略动态但不直接优化行为。在具有状态切换的无奖励环境中测试这种结构。

Result: 潜在状态结构表现出方向依赖的迟滞现象，而策略级行为保持相对反应性，这种迟滞被视为机器系统中类似主观视角的可测量特征。

Conclusion: 方向依赖的迟滞现象为机器系统中主观视角的存在提供了可量化证据，为实现具有主体性的人工智能提供了理论基础。

Abstract: This study operationalizes subjective perspective in artificial agents by grounding it in a minimal, phenomenologically motivated internal structure. The perspective is implemented as a slowly evolving global latent state that modulates fast policy dynamics without being directly optimized for behavioral consequences. In a reward-free environment with regime shifts, this latent structure exhibits direction-dependent hysteresis, while policy-level behavior remains comparatively reactive. I argue that such hysteresis constitutes a measurable signature of perspective-like subjectivity in machine systems.

</details>


### [221] [FIRE-Bench: Evaluating Agents on the Rediscovery of Scientific Insights](https://arxiv.org/abs/2602.02905)
*Zhen Wang,Fan Bai,Zhongyan Luo,Jinyan Su,Kaiser Sun,Xinle Yu,Jieyuan Liu,Kun Zhou,Claire Cardie,Mark Dredze,Eric P. Xing,Zhiting Hu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Autonomous agents powered by large language models (LLMs) promise to accelerate scientific discovery end-to-end, but rigorously evaluating their capacity for verifiable discovery remains a central challenge. Existing benchmarks face a trade-off: they either heavily rely on LLM-as-judge evaluations of automatically generated research outputs or optimize convenient yet isolated performance metrics that provide coarse proxies for scientific insight. To address this gap, we introduce FIRE-Bench (Full-cycle Insight Rediscovery Evaluation), a benchmark that evaluates agents through the rediscovery of established findings from recent, high-impact machine learning research. Agents are given only a high-level research question extracted from a published, verified study and must autonomously explore ideas, design experiments, implement code, execute their plans, and derive conclusions supported by empirical evidence. We evaluate a range of state-of-the-art agents with frontier LLMs backbones like gpt-5 on FIRE-Bench. Our results show that full-cycle scientific research remains challenging for current agent systems: even the strongest agents achieve limited rediscovery success (<50 F1), exhibit high variance across runs, and display recurring failure modes in experimental design, execution, and evidence-based reasoning. FIRE-Bench provides a rigorous and diagnostic framework for measuring progress toward reliable agent-driven scientific discovery.

</details>


### [222] [Reasoning about Reasoning: BAPO Bounds on Chain-of-Thought Token Complexity in LLMs](https://arxiv.org/abs/2602.02909)
*Kiran Tomlinson,Tobias Schnabel,Adith Swaminathan,Jennifer Neville*

Main category: cs.AI

TL;DR: 研究了推理时思维链所需的令牌数量随输入规模增长的理论下界，证明了三个经典任务需要Ω(n)推理令牌，并通过实验验证了理论结果


<details>
  <summary>Details</summary>
Motivation: 思维链推理虽然能提升大语言模型性能，但带来了显著的延迟和计算成本。为了理解推理令牌数量与问题规模的关系，提出了一个理论分析框架

Method: 扩展了有限注意力前缀预测器模型，用于量化解决问题所需的信息流。针对三个规范任务（二元多数、三元组匹配、图可达性）证明了推理令牌数量的下界，并提供了相匹配或接近的上界构造

Result: 理论上证明了这三个任务都需要Ω(n)推理令牌。实验结果显示前沿推理模型在这些任务上呈现近似线性的推理令牌规模增长，受到限制时会出现失败

Conclusion: 研究揭示了通过思维链进行推理时计算的根本瓶颈，为分析最优推理长度提供了一个原则性工具，有助于优化推理效率和计算成本

Abstract: Inference-time scaling via chain-of-thought (CoT) reasoning is a major driver of state-of-the-art LLM performance, but it comes with substantial latency and compute costs. We address a fundamental theoretical question: how many reasoning tokens are required to solve a problem as input size grows? By extending the bounded attention prefix oracle (BAPO) model--an abstraction of LLMs that quantifies the information flow required to solve a task--we prove lower bounds on the CoT tokens required for three canonical BAPO-hard tasks: binary majority, triplet matching, and graph reachability. We show that each requires $Ω(n)$ reasoning tokens when the input size is $n$. We complement these results with matching or near-matching upper bounds via explicit constructions. Finally, our experiments with frontier reasoning models show approximately linear reasoning token scaling on these tasks and failures when constrained to smaller reasoning budgets, consistent with our theoretical lower bounds. Together, our results identify fundamental bottlenecks in inference-time compute through CoT and offer a principled tool for analyzing optimal reasoning length.

</details>


### [223] [UAT-LITE: Inference-Time Uncertainty-Aware Attention for Pretrained Transformers](https://arxiv.org/abs/2602.02952)
*Elias Hossain,Shubhashis Roy Dipta,Subash Neupane,Rajib Rana,Ravid Shwartz-Ziv,Ivan Garibay,Niloofar Yousefi*

Main category: cs.AI

TL;DR: 论文提出了UAT-LITE，一个无需重新训练即可使预训练Transformer分类器的自注意力具备感知不确定性能力的推理时框架，通过蒙特卡洛Dropout近似贝叶斯推理来估计标记级认知不确定性，以此调制注意力机制，从而改善模型校准和不确定性评估。


<details>
  <summary>Details</summary>
Motivation: 当前神经NLP模型存在校准不佳的问题，常对错误预测赋予高置信度，这影响了选择性预测和关键部署。现有校准方法要么只调整输出概率而不改变内部计算，要么代价高昂。

Method: 提出UAT-LITE框架：在推理时使用蒙特卡洛Dropout进行近似贝叶斯推理，从随机前向传播中估计标记级认知不确定性，并用其调制自注意力机制。同时引入分层方差分解诊断Transformer深度中预测不确定性的累积过程。

Result: 在SQuAD 2.0 answerability、MNLI和SST-2三个任务上，UAT-LITE相比微调的BERT-base基线平均减少约20%的期望校准误差，同时保持任务准确性，并改善了分布偏移下的选择性预测和鲁棒性。

Conclusion: UAT-LITE通过在推理时使自注意力具备不确定性感知能力，有效改善了预训练Transformer分类器的校准和不确定性评估，且无需修改预训练权重或训练目标，具有良好的实用性。

Abstract: Neural NLP models are often miscalibrated, assigning high confidence to incorrect predictions, which undermines selective prediction and high-stakes deployment. Post-hoc calibration methods adjust output probabilities but leave internal computation unchanged, while ensemble and Bayesian approaches improve uncertainty at substantial training or storage cost. We propose UAT-LITE, an inference-time framework that makes self-attention uncertainty-aware using approximate Bayesian inference via Monte Carlo dropout in pretrained transformer classifiers. Token-level epistemic uncertainty is estimated from stochastic forward passes and used to modulate self-attention during contextualization, without modifying pretrained weights or training objectives. We additionally introduce a layerwise variance decomposition to diagnose how predictive uncertainty accumulates across transformer depth. Across the SQuAD 2.0 answerability, MNLI, and SST-2, UAT-LITE reduces Expected Calibration Error by approximately 20% on average relative to a fine-tuned BERT-base baseline while preserving task accuracy, and improves selective prediction and robustness under distribution shift.

</details>


### [224] [Generative Engine Optimization: A VLM and Agent Framework for Pinterest Acquisition Growth](https://arxiv.org/abs/2602.02961)
*Faye Zhang,Qianyu Cheng,Jasmine Wan,Vishwakarma Singh,Jinfeng Rao,Kofi Boakye*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models are fundamentally reshaping content discovery through AI-native search systems such as ChatGPT, Gemini, and Claude. Unlike traditional search engines that match keywords to documents, these systems infer user intent, synthesize multimodal evidence, and generate contextual answers directly on the search page, introducing a paradigm shift from Search Engine Optimization (SEO) to Generative Engine Optimization (GEO). For visual content platforms hosting billions of assets, this poses an acute challenge: individual images lack the semantic depth and authority signals that generative search prioritizes, risking disintermediation as user needs are satisfied in-place without site visits.
  We present Pinterest GEO, a production-scale framework that pioneers reverse search design: rather than generating generic image captions describing what content is, we fine-tune Vision-Language Models (VLMs) to predict what users would actually search for, augmented this with AI agents that mine real-time internet trends to capture emerging search demand. These VLM-generated queries then drive construction of semantically coherent Collection Pages via multimodal embeddings, creating indexable aggregations optimized for generative retrieval. Finally, we employ hybrid VLM and two-tower ANN architectures to build authority-aware interlinking structures that propagate signals across billions of visual assets. Deployed at scale across billions of images and tens of millions of collections, GEO delivers 20\% organic traffic growth contributing to multi-million monthly active user (MAU) growth, demonstrating a principled pathway for visual platforms to thrive in the generative search era.

</details>


### [225] [Structuring Value Representations via Geometric Coherence in Markov Decision Processes](https://arxiv.org/abs/2602.02978)
*Zuyuan Zhang,Zeyu Fang,Tian Lan*

Main category: cs.AI

TL;DR: 这篇论文通过序理论视角重新审视强化学习，提出了几何一致性正则化强化学习（GCR-RL），通过学习逐步精细化的偏序集（poset）来保证价值函数估计的几何一致性，从而提高了样本效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的几何方法虽然能提升强化学习效果，但缺乏系统的理论框架。为了更深入地利用几何特性来稳定和加速强化学习过程，需要从序理论的视角重新构建价值函数的学习问题。

Method: 提出GCR-RL方法，通过学习一个期望的偏序集序列来实现几何一致性。通过逐步细化先前步骤中的偏序集，并从时间差分信号中学习额外的序关系，确保支撑学习价值函数的偏序集序列具有几何一致性。同时设计了基于Q学习和演员-评论家架构的两种高效算法来实现这一超偏序集细化过程。

Result: 理论分析证明了这些算法的理论性质与收敛速率。在多种任务上的实验评估表明，GCR-RL相较于强基线方法在样本效率和稳定性能方面均有显著提升。

Conclusion: 通过序理论框架重新构思强化学习，GCR-RL能够系统性地保证价值函数学习的几何一致性。这为强化学习提供了一种新的几何正则化方法，在实际应用中取得了显著的性能改进。

Abstract: Geometric properties can be leveraged to stabilize and speed reinforcement learning. Existing examples include encoding symmetry structure, geometry-aware data augmentation, and enforcing structural restrictions. In this paper, we take a novel view of RL through the lens of order theory and recast value function estimates into learning a desired poset (partially ordered set). We propose \emph{GCR-RL} (Geometric Coherence Regularized Reinforcement Learning) that computes a sequence of super-poset refinements -- by refining posets in previous steps and learning additional order relationships from temporal difference signals -- thus ensuring geometric coherence across the sequence of posets underpinning the learned value functions. Two novel algorithms by Q-learning and by actor--critic are developed to efficiently realize these super-poset refinements. Their theoretical properties and convergence rates are analyzed. We empirically evaluate GCR-RL in a range of tasks and demonstrate significant improvements in sample efficiency and stable performance over strong baselines.

</details>


### [226] [Are LLMs Biased Like Humans? Causal Reasoning as a Function of Prior Knowledge, Irrelevant Information, and Reasoning Budget](https://arxiv.org/abs/2602.02983)
*Hanna M. Dettki,Charley M. Wu,Bob Rehder*

Main category: cs.AI

TL;DR: 本研究对20多个大型语言模型在11个因果判断任务上进行基准测试，发现LLMs展现出比人类更加规则化的推理策略，但没有表现出人类特有的碰撞偏差。思维链提示能提升模型对语义抽象和提示过载的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在需要因果推理的领域应用日益增多，需要明确它们的因果判断是基于规范计算、人类式捷径还是脆弱的模式匹配，以便评估其部署的安全性和有效性。

Method: 研究人员将20多个LLMs与匹配的人类基准在11个基于碰撞结构（C₁→E←C₂）的因果判断任务上进行对比，使用可解释的小模型压缩LLMs的因果判断，并测试模型在语义抽象和提示过载两种情况下的鲁棒性。

Result: 大多数LLMs展现出比人类更加规则化的推理策略，未表现出人类的弱解释排他和马尔可夫违背等碰撞偏差。思维链提示提高了许多LLMs对语义抽象和提示过载的鲁棒性。

Conclusion: LLMs在已知的人类偏见不可取时可作为人类的补充工具，但其规则化的推理在面对本质不确定性时可能失效，这凸显了深入理解LLM推理策略对于安全有效部署的重要性。

Abstract: Large language models (LLMs) are increasingly used in domains where causal reasoning matters, yet it remains unclear whether their judgments reflect normative causal computation, human-like shortcuts, or brittle pattern matching. We benchmark 20+ LLMs against a matched human baseline on 11 causal judgment tasks formalized by a collider structure ($C_1 \!\rightarrow\! E\! \leftarrow \!C_2$). We find that a small interpretable model compresses LLMs' causal judgments well and that most LLMs exhibit more rule-like reasoning strategies than humans who seem to account for unmentioned latent factors in their probability judgments. Furthermore, most LLMs do not mirror the characteristic human collider biases of weak explaining away and Markov violations. We probe LLMs' causal judgment robustness under (i) semantic abstraction and (ii) prompt overloading (injecting irrelevant text), and find that chain-of-thought (CoT) increases robustness for many LLMs. Together, this divergence suggests LLMs can complement humans when known biases are undesirable, but their rule-like reasoning may break down when uncertainty is intrinsic -- highlighting the need to characterize LLM reasoning strategies for safe, effective deployment.

</details>


### [227] [Large Language Models Can Take False First Steps at Inference-time Planning](https://arxiv.org/abs/2602.02991)
*Haijiang Yan,Jian-Qiao Zhu,Adam Sanborn*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) have been shown to acquire sequence-level planning abilities during training, yet their planning behavior exhibited at inference time often appears short-sighted and inconsistent with these capabilities. We propose a Bayesian account for this gap by grounding planning behavior in the evolving generative context: given the subtle differences between natural language and the language internalized by LLMs, accumulated self-generated context drives a planning-shift during inference and thereby creates the appearance of compromised planning behavior. We further validate the proposed model through two controlled experiments: a random-generation task demonstrating constrained planning under human prompts and increasing planning strength as self-generated context accumulates, and a Gaussian-sampling task showing reduced initial bias when conditioning on self-generated sequences. These findings provide a theoretical explanation along with empirical evidence for characterizing how LLMs plan ahead during inference.

</details>


### [228] [Agent Alpha: Tree Search Unifying Generation, Exploration and Evaluation for Computer-Use Agents](https://arxiv.org/abs/2602.02995)
*Sizhe Tang,Rongqian Chen,Tian Lan*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While scaling test-time compute through trajectory-level sampling has significantly improved Graphical User Interface (GUI) agents, the lack of regressive ability prevents the reuse of partial successes and the recovery from early missteps. In this paper, we introduce Agent Alpha, a unified framework that synergizes generation, exploration, and evaluation through step-level Monte Carlo Tree Search (MCTS). It enables active modeling or exploiting structures of the planning space. By integrating alpha-UCT guided search into the interaction loop, Agent Alpha enables deliberate planning, facilitating early pruning of suboptimal branches and efficient prefix reuse. We also employ comparison-driven evaluation to mitigate absolute scoring biases and diversity-constrained expansion to maintain a compact, informative search space. Regret bound of alpha-UCT is analyzed. On the OSWorld benchmark, Agent Alpha achieves a state-of-the-art success rate of $\sim 77\%$, significantly outperforming trajectory-level baselines under equivalent compute.

</details>


### [229] [Methods and Open Problems in Differentiable Social Choice: Learning Mechanisms, Decisions, and Alignment](https://arxiv.org/abs/2602.03003)
*Zhiyu An,Wan Du*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Social choice is no longer a peripheral concern of political theory or economics-it has become a foundational component of modern machine learning systems. From auctions and resource allocation to federated learning, participatory governance, and the alignment of large language models, machine learning pipelines increasingly aggregate heterogeneous preferences, incentives, and judgments into collective decisions. In effect, many contemporary machine learning systems already implement social choice mechanisms, often implicitly and without explicit normative scrutiny.
  This Review surveys differentiable social choice: an emerging paradigm that formulates voting rules, mechanisms, and aggregation procedures as learnable, differentiable models optimized from data. We synthesize work across auctions, voting, budgeting, liquid democracy, decentralized aggregation, and inverse mechanism learning, showing how classical axioms and impossibility results reappear as objectives, constraints, and optimization trade-offs. We conclude by identifying 36 open problems defining a new research agenda at the intersection of machine learning, economics, and democratic theory.

</details>


### [230] [Distilling LLM Reasoning into Graph of Concept Predictors](https://arxiv.org/abs/2602.03006)
*Ziyang Yu,Liang Zhao*

Main category: cs.AI

TL;DR: 提出Graph of Concept Predictors (GCP)框架，通过将LLM的推理过程显式化为有向无环图，并用模块化概念预测器来训练紧凑学生模型，从而提高active distillation的样本效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型(LLMs)用于判别性工作时，推理延迟、计算成本和API成本成为主要限制。传统的active distillation方法只蒸馏最终标签而丢弃中间推理信号，缺乏对错误来源的诊断，并且训练动态难以分析。

Method: 1. 将教师LLM的决策过程外部化为有向无环图形式的推理结构；2. 在学生模型中使用模块化概念预测器来模拟该推理图；3. 采用图感知采集策略，针对关键推理节点的不确定性和分歧进行采样；4. 通过针对性子模块重训练，将下游损失归因于特定概念预测器，并只更新最有影响力的模块。

Result: 在八个NLP分类基准上的实验表明，GCP在有限标注预算下提高了性能，同时产生了更具可解释性和可控性的训练动态。

Conclusion: GCP框架通过显式建模推理图和模块化设计，有效提升了active distillation的样本效率、训练稳定性和可解释性，为在资源受限场景下部署紧凑判别模型提供了新思路。

Abstract: Deploying Large Language Models (LLMs) for discriminative workloads is often limited by inference latency, compute, and API costs at scale. Active distillation reduces these costs by querying an LLM oracle to train compact discriminative students, but most pipelines distill only final labels, discarding intermediate reasoning signals and offering limited diagnostics of what reasoning is missing and where errors arise. We propose Graph of Concept Predictors (GCP), a reasoning-aware active distillation framework that externalizes the teacher's decision process as a directed acyclic graph and mirrors it with modular concept predictors in the student. GCP enhances sample efficiency through a graph-aware acquisition strategy that targets uncertainty and disagreement at critical reasoning nodes. Additionally, it improves training stability and efficiency by performing targeted sub-module retraining, which attributes downstream loss to specific concept predictors and updates only the most influential modules. Experiments on eight NLP classification benchmarks demonstrate that GCP enhances performance under limited annotation budgets while yielding more interpretable and controllable training dynamics. Code is available at: https://github.com/Ziyang-Yu/GCP.

</details>


### [231] [STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models](https://arxiv.org/abs/2602.03022)
*Jiliang Ni,Jiachen Pu,Zhongyi Yang,Jingfeng Luo,Conggang Hu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The proliferation of Large Language Models (LLMs) in function calling is pivotal for creating advanced AI agents, yet their large scale hinders widespread adoption, necessitating transferring their capabilities into smaller ones. However, existing paradigms are often plagued by overfitting, training instability, ineffective binary rewards for multi-solution tasks, and the difficulty of synergizing techniques. We introduce STAR: Similarity-guided Teacher-Assisted Refinement, a novel holistic framework that effectively transfers LLMs' capabilities to super-tiny models. STAR consists of two core technical innovations: (1) Constrained Knowledge Distillation (CKD), a training objective that augments top-k forward KL divergence to suppress confidently incorrect predictions, ensuring training stability while preserving exploration capacity for downstream RL. STAR holistically synergizes these strategies within a cohesive training curriculum, enabling super-tiny models to achieve exceptional performance on complex function calling tasks; (2) Similarity-guided RL (Sim-RL), a RL mechanism that introduces a fine-grained, similarity-based reward. This provides a robust, continuous, and rich signal for better policy optimization by evaluating the similarity between generated outputs and the ground truth. Extensive experiments on challenging and renowned benchmarks demonstrate the effectiveness of our method. Our STAR models establish SOTA in their size classes, significantly outperforming baselines. Remarkably, our 0.6B STAR model achieves the best performance among all open models under 1B, surpassing even several well-known open models at a larger scale. STAR demonstrates a training framework that distills capabilities of LLMs into super-tiny models, paving the way for powerful, accessible, and efficient AI agents.

</details>


### [232] [RC-GRPO: Reward-Conditioned Group Relative Policy Optimization for Multi-Turn Tool Calling Agents](https://arxiv.org/abs/2602.03025)
*Haitian Zhong,Jixiu Zhai,Lei Song,Jiang Bian,Qiang Liu,Tieniu Tan*

Main category: cs.AI

TL;DR: 论文提出RC-GRPO方法解决多轮工具调用中群体内奖励差异低导致学习停滞的问题，通过奖励令牌控制探索多样性，在BFCLv4基准上超越基线并达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 传统SFT+GRPO方法在多轮工具调用任务中，当群体内奖励变化较低时（如多数rollout获得全0或全1奖励），组归一化优势函数变得不具信息性，导致更新消失，学习过程停滞

Method: 提出RC-GRPO (Reward-Conditioned Group Relative Policy Optimization)：
1. 首先微调奖励条件轨迹策略(RCTP)，在混合质量轨迹中注入奖励目标特殊令牌（如<|high_reward|>, <|low_reward|>），让模型学习按需生成不同质量的轨迹
2. 在RL阶段，在每个GRPO组内采样多样化的奖励令牌，基于采样令牌生成rollout以提升组内多样性，改善优势增益

Result: 在Berkeley Function Calling Leaderboard v4 (BFCLv4)多轮基准测试上，该方法相比基线获得一致性能提升，Qwen-2.5-7B-Instruct模型甚至超越所有闭源API模型

Conclusion: RC-GRPO通过将探索视为可控的引导问题，使用离散奖励令牌提升组内轨迹多样性，有效解决了GRPO中奖励信号稀疏和组内变化低导致的优化停滞问题，为LLM多轮工具调用训练提供了新思路

Abstract: Multi-turn tool calling is challenging for Large Language Models (LLMs) because rewards are sparse and exploration is expensive. A common recipe, SFT followed by GRPO, can stall when within-group reward variation is low (e.g., more rollouts in a group receive the all 0 or all 1 reward), making the group-normalized advantage uninformative and yielding vanishing updates. To address this problem, we propose RC-GRPO (Reward-Conditioned Group Relative Policy Optimization), which treats exploration as a controllable steering problem via discrete reward tokens. We first fine-tune a Reward-Conditioned Trajectory Policy (RCTP) on mixed-quality trajectories with reward goal special tokens (e.g., <|high_reward|>, <|low_reward|>) injected into the prompts, enabling the model to learn how to generate distinct quality trajectories on demand. Then during RL, we sample diverse reward tokens within each GRPO group and condition rollouts on the sampled token to improve within-group diversity, improving advantage gains. On the Berkeley Function Calling Leaderboard v4 (BFCLv4) multi-turn benchmark, our method yields consistently improved performance than baselines, and the performance on Qwen-2.5-7B-Instruct even surpasses all closed-source API models.

</details>


### [233] [Visual Reasoning over Time Series via Multi-Agent System](https://arxiv.org/abs/2602.03026)
*Weilin Ruan,Yuxuan Liang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Time series analysis underpins many real-world applications, yet existing time-series-specific methods and pretrained large-model-based approaches remain limited in integrating intuitive visual reasoning and generalizing across tasks with adaptive tool usage. To address these limitations, we propose MAS4TS, a tool-driven multi-agent system for general time series tasks, built upon an Analyzer-Reasoner-Executor paradigm that integrates agent communication, visual reasoning, and latent reconstruction within a unified framework. MAS4TS first performs visual reasoning over time series plots with structured priors using a Vision-Language Model to extract temporal structures, and subsequently reconstructs predictive trajectories in latent space. Three specialized agents coordinate via shared memory and gated communication, while a router selects task-specific tool chains for execution. Extensive experiments on multiple benchmarks demonstrate that MAS4TS achieves state-of-the-art performance across a wide range of time series tasks, while exhibiting strong generalization and efficient inference.

</details>


### [234] [KANFIS A Neuro-Symbolic Framework for Interpretable and Uncertainty-Aware Learning](https://arxiv.org/abs/2602.03034)
*Binbin Yong,Haoran Pei,Jun Shen,Haoran Li,Qingguo Zhou,Zhao Su*

Main category: cs.AI

TL;DR: 本文提出KANFIS（Kolmogorov-Arnold神经模糊推理系统），通过加法聚合机制解决传统ANFIS在高维空间中规则指数爆炸的问题，实现线性复杂度，并支持T1和IT2模糊逻辑系统。


<details>
  <summary>Details</summary>
Motivation: 传统ANFIS架构因基于乘积的推理机制在高维空间中存在规则指数爆炸的结构复杂性缺陷，因此需要一种更紧凑的神经符号架构来保持模糊推理优势同时降低复杂度。

Method: 使用加法聚合机制替代传统乘积推理，结合Kolmogorov-Arnold函数分解理论，利用稀疏掩码机制生成结构化规则集，同时支持Type-1和Interval Type-2模糊逻辑系统。

Result: 实验结果表明KANFIS在保持模糊推理透明度的同时，与代表性神经和神经模糊基线相比达到竞争性性能，且参数和规则复杂度随输入维度线性增长。

Conclusion: KANFIS通过统一的加法分解框架解决了传统神经模糊系统的高维规则爆炸问题，实现了紧凑性、可解释性和不确定性的有效建模，在实际应用中具有重要价值。

Abstract: Adaptive Neuro-Fuzzy Inference System (ANFIS) was designed to combine the learning capabilities of neural network with the reasoning transparency of fuzzy logic. However, conventional ANFIS architectures suffer from structural complexity, where the product-based inference mechanism causes an exponential explosion of rules in high-dimensional spaces. We herein propose the Kolmogorov-Arnold Neuro-Fuzzy Inference System (KANFIS), a compact neuro-symbolic architecture that unifies fuzzy reasoning with additive function decomposition. KANFIS employs an additive aggregation mechanism, under which both model parameters and rule complexity scale linearly with input dimensionality rather than exponentially. Furthermore, KANFIS is compatible with both Type-1 (T1) and Interval Type-2 (IT2) fuzzy logic systems, enabling explicit modeling of uncertainty and ambiguity in fuzzy representations. By using sparse masking mechanisms, KANFIS generates compact and structured rule sets, resulting in an intrinsically interpretable model with clear rule semantics and transparent inference processes. Empirical results demonstrate that KANFIS achieves competitive performance against representative neural and neuro-fuzzy baselines.

</details>


### [235] [MAS-ProVe: Understanding the Process Verification of Multi-Agent Systems](https://arxiv.org/abs/2602.03053)
*Vishal Venkataramani,Haizhou Shi,Zixuan Ke,Austin Xu,Xiaoxiao He,Yingbo Zhou,Semih Yavuz,Hao Wang,Shafiq Joty*

Main category: cs.AI

TL;DR: 该研究对多智能体系统中的流程验证进行了系统性实证分析，发现当前验证方法在高方差和不稳定性，LLM-as-a-Judge方法表现相对较好但仍有局限。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统常表现出高方差的推理轨迹，流程验证在通用推理中显示潜力，但其在多智能体系统中的实际效果尚不明确，需要系统性研究。

Method: 提出MAS-ProVe框架，评估三种验证范式（LLM-as-a-Judge、奖励模型、过程奖励模型）、两个验证粒度（智能体级和迭代级），覆盖五个验证器、四个上下文管理策略，在六个多智能体框架和多个推理基准上进行实验。

Result: 流程层面验证并不总能提升性能，常表现出高方差；LLM-as-a-Judge方法优于基于奖励的方法；训练过的法官优于通用LLM；LLM作为法官和作为单智能体之间存在性能差距；存在上下文长度与性能的权衡。

Conclusion: 有效且稳健的多智能体系统流程验证仍然是一个开放挑战，需要超越当前范式的进一步发展。

Abstract: Multi-Agent Systems (MAS) built on Large Language Models (LLMs) often exhibit high variance in their reasoning trajectories. Process verification, which evaluates intermediate steps in trajectories, has shown promise in general reasoning settings, and has been suggested as a potential tool for guiding coordination of MAS; however, its actual effectiveness in MAS remains unclear. To fill this gap, we present MAS-ProVe, a systematic empirical study of process verification for multi-agent systems (MAS). Our study spans three verification paradigms (LLM-as-a-Judge, reward models, and process reward models), evaluated across two levels of verification granularity (agent-level and iteration-level). We further examine five representative verifiers and four context management strategies, and conduct experiments over six diverse MAS frameworks on multiple reasoning benchmarks. We find that process-level verification does not consistently improve performance and frequently exhibits high variance, highlighting the difficulty of reliably evaluating partial multi-agent trajectories. Among the methods studied, LLM-as-a-Judge generally outperforms reward-based approaches, with trained judges surpassing general-purpose LLMs. We further observe a small performance gap between LLMs acting as judges and as single agents, and identify a context-length-performance trade-off in verification. Overall, our results suggest that effective and robust process verification for MAS remains an open challenge, requiring further advances beyond current paradigms. Code is available at https://github.com/Wang-ML-Lab/MAS-ProVe.

</details>


### [236] [De-conflating Preference and Qualification: Constrained Dual-Perspective Reasoning for Job Recommendation with Large Language Models](https://arxiv.org/abs/2602.03097)
*Bryce Kan,Wei Yang,Emily Nguyen,Ganghui Yi,Bowen Yi,Chenxiao Yu,Yan Liu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Professional job recommendation involves a complex bipartite matching process that must reconcile a candidate's subjective preference with an employer's objective qualification. While Large Language Models (LLMs) are well-suited for modeling the rich semantics of resumes and job descriptions, existing paradigms often collapse these two decision dimensions into a single interaction signal, yielding confounded supervision under recruitment-funnel censoring and limiting policy controllability. To address these challenges, We propose JobRec, a generative job recommendation framework for de-conflating preference and qualification via constrained dual-perspective reasoning. JobRec introduces a Unified Semantic Alignment Schema that aligns candidate and job attributes into structured semantic layers, and a Two-Stage Cooperative Training Strategy that learns decoupled experts to separately infer preference and qualification. Building on these experts, a Lagrangian-based Policy Alignment module optimizes recommendations under explicit eligibility requirements, enabling controllable trade-offs. To mitigate data scarcity, we construct a synthetic dataset refined by experts. Experiments show that JobRec consistently outperforms strong baselines and provides improved controllability for strategy-aware professional matching.

</details>


### [237] [Risky-Bench: Probing Agentic Safety Risks under Real-World Deployment](https://arxiv.org/abs/2602.03100)
*Jingnan Zheng,Yanzhen Luo,Jingjun Xu,Bingnan Liu,Yuxin Chen,Chenhang Cui,Gelei Deng,Chaochao Lu,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) are increasingly deployed as agents that operate in real-world environments, introducing safety risks beyond linguistic harm. Existing agent safety evaluations rely on risk-oriented tasks tailored to specific agent settings, resulting in limited coverage of safety risk space and failing to assess agent safety behavior during long-horizon, interactive task execution in complex real-world deployments. Moreover, their specialization to particular agent settings limits adaptability across diverse agent configurations. To address these limitations, we propose Risky-Bench, a framework that enables systematic agent safety evaluation grounded in real-world deployment. Risky-Bench organizes evaluation around domain-agnostic safety principles to derive context-aware safety rubrics that delineate safety space, and systematically evaluates safety risks across this space through realistic task execution under varying threat assumptions. When applied to life-assist agent settings, Risky-Bench uncovers substantial safety risks in state-of-the-art agents under realistic execution conditions. Moreover, as a well-structured evaluation pipeline, Risky-Bench is not confined to life-assist scenarios and can be adapted to other deployment settings to construct environment-specific safety evaluations, providing an extensible methodology for agent safety assessment.

</details>


### [238] [Understanding Multi-Agent LLM Frameworks: A Unified Benchmark and Experimental Analysis](https://arxiv.org/abs/2602.03128)
*Abdelghny Orogat,Ana Rostam,Essam Mansour*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multi-agent LLM frameworks are widely used to accelerate the development of agent systems powered by large language models (LLMs). These frameworks impose distinct architectural structures that govern how agents interact, store information, and coordinate tasks. However, their impact on system performance remains poorly understood. This gap is critical, as architectural choices alone can induce order-of-magnitude differences in latency and throughput, as well as substantial variation in accuracy and scalability. Addressing this challenge requires (i) jointly evaluating multiple capabilities, such as orchestration overhead, memory behavior, planning, specialization, and coordination, and (ii) conducting these evaluations under controlled, framework-level conditions to isolate architectural effects. Existing benchmarks focus on individual capabilities and lack standardized framework-level evaluation. We address these limitations by (i) introducing an architectural taxonomy for systematically comparing multi-agent LLM frameworks along fundamental dimensions, and (ii) developing MAFBench, a unified evaluation suite that integrates existing benchmarks under a standardized execution pipeline. Using MAFBench, we conduct a controlled empirical study across several widely used frameworks. Our results show that framework-level design choices alone can increase latency by over 100x, reduce planning accuracy by up to 30%, and lower coordination success from above 90% to below 30%. Finally, we translate our findings into concrete architectural design principles and framework selection guidance, and outline promising future research directions.

</details>


### [239] [General Agents Contain World Models, even under Partial Observability and Stochasticity](https://arxiv.org/abs/2602.03146)
*Santiago Cifuentes*

Main category: cs.AI

TL;DR: 将先前关于智能体必然包含环境模型的理论扩展到随机智能体和部分可观测环境。


<details>
  <summary>Details</summary>
Motivation: 先前研究仅在确定性和完全可观测环境下证明智能体必然包含环境模型，需要扩展到更实际的随机和部分可观测设置，以更全面地理解智能体的能力与限制。

Method: 扩展之前的数学框架，允许智能体具有随机性且环境部分可观测，同时减弱智能体通用性的要求。

Result: 证明了随机智能体在部分可观测环境中也必然学习到环境模型，且对智能体通用性的要求更弱。

Conclusion: 随机性无法帮助智能体避免学习环境模型，即使通用性较弱的智能体也包含其操作环境的内在表示。

Abstract: Deciding whether an agent possesses a model of its surrounding world is a fundamental step toward understanding its capabilities and limitations. In [10], it was shown that, within a particular framework, every almost optimal and general agent necessarily contains sufficient knowledge of its environment to allow an approximate reconstruction of it by querying the agent as a black box. This result relied on the assumptions that the agent is deterministic and that the environment is fully observable.
  In this work, we remove both assumptions by extending the theorem to stochastic agents operating in partially observable environments. Fundamentally, this shows that stochastic agents cannot avoid learning their environment through the usage of randomization. We also strengthen the result by weakening the notion of generality, proving that less powerful agents already contain a model of the world in which they operate.

</details>


### [240] [Enhancing Foundation VLM Robustness to Missing Modality: Scalable Diffusion for Bi-directional Feature Restoration](https://arxiv.org/abs/2602.03151)
*Wei Dai,Haoyu Wang,Honghao Chang,Lijun He,Fan Li,Jian Sun,Haixia Bi*

Main category: cs.AI

TL;DR: 针对视觉语言模型(VLMs)在多模态输入缺失时性能下降的问题，提出了一种通用的缺失模态恢复策略，通过增强型扩散模型和两个创新机制来恢复语义一致的特征。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型假设推理时具备完整模态输入，但在某些模态缺失或不全时效果急剧下降。现有方法存在两个主要困境：基于提示的方法难以恢复缺失的关键特征并损害VLM的泛化能力；基于插补的方法缺乏有效指导，容易生成语义无关的噪声。如何在恢复精确语义的同时保持VLM的泛化能力仍然具有挑战性。

Method: 提出通用的缺失模态恢复策略，引入增强型扩散模型作为可插拔的中间阶段训练模块。包含两个关键创新：(1)动态模态门控，自适应利用条件特征引导生成语义一致的特征；(2)跨模态互学习机制，桥接双编码器的语义空间实现双向对齐。

Result: 在基准数据集上的零样本评估表明，该方法优于现有基线方法。大量实验和消融研究证实，该模型在缺失模态场景下是VLM的鲁棒且可扩展的扩展，确保在不同缺失率和环境下保持可靠性。

Conclusion: 本文提出的缺失模态恢复策略能有效解决VLM在多模态输入不全时的性能问题，通过动态门控和跨模态互学习机制实现语义一致的缺失特征恢复，具有出色的泛化能力和实用性。

Abstract: Vision Language Models (VLMs) typically assume complete modality input during inference. However, their effectiveness drops sharply when certain modalities are unavailable or incomplete. Current research primarily faces two dilemmas: Prompt-based methods struggle to restore missing yet indispensable features and impair generalization of VLMs. Imputation-based approaches, lacking effective guidance, are prone to generating semantically irrelevant noise. Restoring precise semantics while sustaining VLM generalization remains challenging. Therefore, we propose a general missing modality restoration strategy in this paper. We introduce an enhanced diffusion model as a pluggable mid-stage training module to effectively restore missing features. Our strategy introduces two key innovations: (I) Dynamic Modality Gating, which adaptively leverages conditional features to steer the generation of semantically consistent features; (II) Cross-Modal Mutual Learning mechanism, which bridges the semantic spaces of dual encoders to achieve bidirectional alignment. Zero-shot evaluations across benchmark datasets demonstrate that our approach outperforms existing baseline methods. Extensive experiments and ablation studies confirm our model as a robust and scalable extension for VLMs in missing modality scenarios, ensuring reliability across diverse missing rates and environments. Our code and models will be publicly available.

</details>


### [241] [VALUEFLOW: Toward Pluralistic and Steerable Value-based Alignment in Large Language Models](https://arxiv.org/abs/2602.03160)
*Woojin Kim,Sieun Hyeon,Jusang Oh,Jaeyoung Do*

Main category: cs.AI

TL;DR: VALUEFLOW是一个统一的框架，用于大语言模型（LLM）的价值提取、评估和校准强度控制，包含层次化价值嵌入空间、大规模价值强度数据库和基于锚定的评估器。


<details>
  <summary>Details</summary>
Motivation: 当前基于偏好的对齐方法难以捕捉人类多样价值观的深层动机原则，基于价值的方法虽然更具原则性，但在层次结构提取、强度评估和可控强度下的可操控性方面存在三大空白。

Method: 提出VALUEFLOW框架，包含三个组件：HIVES（层次化价值嵌入空间）捕捉理论内和理论间的价值结构；VIDB（价值强度数据库）通过排序聚合生成大规模价值标注文本的强度估计；基于锚定的评估器通过将模型输出与VIDB面板排名来生成一致的强度评分。

Result: 通过VALUEFLOW，在十个模型和四种价值理论上进行大规模研究，发现可操控性的非对称性以及多价值控制的组合规律。

Conclusion: 该论文建立了评估和控制价值强度的可扩展基础设施，推动了LLM的多元对齐。

Abstract: Aligning Large Language Models (LLMs) with the diverse spectrum of human values remains a central challenge: preference-based methods often fail to capture deeper motivational principles. Value-based approaches offer a more principled path, yet three gaps persist: extraction often ignores hierarchical structure, evaluation detects presence but not calibrated intensity, and the steerability of LLMs at controlled intensities remains insufficiently understood. To address these limitations, we introduce VALUEFLOW, the first unified framework that spans extraction, evaluation, and steering with calibrated intensity control. The framework integrates three components: (i) HIVES, a hierarchical value embedding space that captures intra- and cross-theory value structure; (ii) the Value Intensity DataBase (VIDB), a large-scale resource of value-labeled texts with intensity estimates derived from ranking-based aggregation; and (iii) an anchor-based evaluator that produces consistent intensity scores for model outputs by ranking them against VIDB panels. Using VALUEFLOW, we conduct a comprehensive large-scale study across ten models and four value theories, identifying asymmetries in steerability and composition laws for multi-value control. This paper establishes a scalable infrastructure for evaluating and controlling value intensity, advancing pluralistic alignment of LLMs.

</details>


### [242] [The Necessity of a Unified Framework for LLM-Based Agent Evaluation](https://arxiv.org/abs/2602.03238)
*Pengyu Zhu,Li Sun,Philip S. Yu,Sen Su*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements. However, evaluating these agents presents unique challenges that distinguish them from static QA benchmarks. We observe that current agent benchmarks are heavily confounded by extraneous factors, including system prompts, toolset configurations, and environmental dynamics. Existing evaluations often rely on fragmented, researcher-specific frameworks where the prompt engineering for reasoning and tool usage varies significantly, making it difficult to attribute performance gains to the model itself. Additionally, the lack of standardized environmental data leads to untraceable errors and non-reproducible results. This lack of standardization introduces substantial unfairness and opacity into the field. We propose that a unified evaluation framework is essential for the rigorous advancement of agent evaluation. To this end, we introduce a proposal aimed at standardizing agent evaluation.

</details>


### [243] [Accordion-Thinking: Self-Regulated Step Summaries for Efficient and Readable LLM Reasoning](https://arxiv.org/abs/2602.03249)
*Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Wenlei Shi,Yiwei Wang,Xiaodan Liang,Jing Tang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Scaling test-time compute via long Chain-ofThought unlocks remarkable gains in reasoning capabilities, yet it faces practical limits due to the linear growth of KV cache and quadratic attention complexity. In this paper, we introduce Accordion-Thinking, an end-to-end framework where LLMs learn to self-regulate the granularity of the reasoning steps through dynamic summarization. This mechanism enables a Fold inference mode, where the model periodically summarizes its thought process and discards former thoughts to reduce dependency on historical tokens. We apply reinforcement learning to incentivize this capability further, uncovering a critical insight: the accuracy gap between the highly efficient Fold mode and the exhaustive Unfold mode progressively narrows and eventually vanishes over the course of training. This phenomenon demonstrates that the model learns to encode essential reasoning information into compact summaries, achieving effective compression of the reasoning context. Our Accordion-Thinker demonstrates that with learned self-compression, LLMs can tackle complex reasoning tasks with minimal dependency token overhead without compromising solution quality, and it achieves a 3x throughput while maintaining accuracy on a 48GB GPU memory configuration, while the structured step summaries provide a human-readable account of the reasoning process.

</details>


### [244] [LPS-Bench: Benchmarking Safety Awareness of Computer-Use Agents in Long-Horizon Planning under Benign and Adversarial Scenarios](https://arxiv.org/abs/2602.03255)
*Tianyu Chen,Chujia Hu,Ge Gao,Dongrui Liu,Xia Hu,Wenjie Wang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Computer-use agents (CUAs) that interact with real computer systems can perform automated tasks but face critical safety risks. Ambiguous instructions may trigger harmful actions, and adversarial users can manipulate tool execution to achieve malicious goals. Existing benchmarks mostly focus on short-horizon or GUI-based tasks, evaluating on execution-time errors but overlooking the ability to anticipate planning-time risks. To fill this gap, we present LPS-Bench, a benchmark that evaluates the planning-time safety awareness of MCP-based CUAs under long-horizon tasks, covering both benign and adversarial interactions across 65 scenarios of 7 task domains and 9 risk types. We introduce a multi-agent automated pipeline for scalable data generation and adopt an LLM-as-a-judge evaluation protocol to assess safety awareness through the planning trajectory. Experiments reveal substantial deficiencies in existing CUAs' ability to maintain safe behavior. We further analyze the risks and propose mitigation strategies to improve long-horizon planning safety in MCP-based CUA systems. We open-source our code at https://github.com/tychenn/LPS-Bench.

</details>


### [245] [CSR-Bench: A Benchmark for Evaluating the Cross-modal Safety and Reliability of MLLMs](https://arxiv.org/abs/2602.03263)
*Yuxuan Liu,Yuntian Shi,Kun Wang,Haoting Shen,Kun Yang*

Main category: cs.AI

TL;DR: CSR-Bench是一个评估多模态大语言模型跨模态可靠性的基准测试，包含四大压力测试模式（安全性、过度拒绝、偏见、幻觉），涵盖61种细粒度类型，通过配对纯文本对照来诊断模态引发的行为偏移。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在文本和图像交互中的安全行为可能受到单模态捷径驱动，而非真正的联合意图理解，因此需要系统评估其跨模态可靠性。

Method: 构建CSR-Bench基准测试，包含四种压力测试交互模式（安全性、过度拒绝、偏见、幻觉），每个实例都需要整合的图像-文本解释，并提供配对的纯文本对照来诊断模态引发的行为变化。评估了16个最先进的MLLMs。

Result: 观察到系统性的跨模态对齐差距：模型表现出弱安全意识、干扰下的强语言主导性，以及从纯文本对照到多模态输入的性能一致下降。还发现降低过度拒绝与保持安全非歧视行为之间存在明显权衡。

Conclusion: 一些看似安全性的提升可能来自拒绝导向的启发式方法，而非稳健的意图理解。多模态可靠性评估对于理解MLLMs的真实安全能力至关重要。

Abstract: Multimodal large language models (MLLMs) enable interaction over both text and images, but their safety behavior can be driven by unimodal shortcuts instead of true joint intent understanding. We introduce CSR-Bench, a benchmark for evaluating cross-modal reliability through four stress-testing interaction patterns spanning Safety, Over-rejection, Bias, and Hallucination, covering 61 fine-grained types. Each instance is constructed to require integrated image-text interpretation, and we additionally provide paired text-only controls to diagnose modality-induced behavior shifts. We evaluate 16 state-of-the-art MLLMs and observe systematic cross-modal alignment gaps. Models show weak safety awareness, strong language dominance under interference, and consistent performance degradation from text-only controls to multimodal inputs. We also observe a clear trade-off between reducing over-rejection and maintaining safe, non-discriminatory behavior, suggesting that some apparent safety gains may come from refusal-oriented heuristics rather than robust intent understanding. WARNING: This paper contains unsafe contents.

</details>


### [246] [Agentic Proposing: Enhancing Large Language Model Reasoning via Compositional Skill Synthesis](https://arxiv.org/abs/2602.03279)
*Zhengbo Jiao,Shaobo Wang,Zifan Zhang,Xuan Ren,Wei Wang,Bing Zhao,Hu Wei,Linfeng Zhang*

Main category: cs.AI

TL;DR: Agentic Proposing框架使用基于技能的智能体合成高质量、可验证的复杂推理训练数据，大幅提升下游模型性能。


<details>
  <summary>Details</summary>
Motivation: 人工标注高质量复杂推理数据集成本高且难以扩展，现有合成方法面临结构有效性与问题复杂度之间的权衡困境，需要突破性的数据合成方法。

Method: 将问题合成建模为目标驱动的序列决策过程，使用专门化的智能体动态选择和组合模块化推理技能，通过内部反思和工具使用的迭代工作流，配合多粒度策略优化(MGPO)训练Agentic-Proposer-4B模型。

Result: 使用智能体合成的数据训练的下游求解器显著超越领先基准，表现出强大的跨领域泛化能力。仅使用11,000条合成轨迹训练的30B模型在AIME25上达到91.6%的SOTA准确率，媲美GPT-5等前沿专有模型。

Conclusion: 少量高质量合成信号可以有效替代大规模人工标注数据集，为提升大语言模型的复杂推理能力提供了可扩展的高效数据合成解决方案。

Abstract: Advancing complex reasoning in large language models relies on high-quality, verifiable datasets, yet human annotation remains cost-prohibitive and difficult to scale. Current synthesis paradigms often face a recurring trade-off: maintaining structural validity typically restricts problem complexity, while relaxing constraints to increase difficulty frequently leads to inconsistent or unsolvable instances. To address this, we propose Agentic Proposing, a framework that models problem synthesis as a goal-driven sequential decision process where a specialized agent dynamically selects and composes modular reasoning skills. Through an iterative workflow of internal reflection and tool-use, we develop the Agentic-Proposer-4B using Multi-Granularity Policy Optimization (MGPO) to generate high-precision, verifiable training trajectories across mathematics, coding, and science. Empirical results demonstrate that downstream solvers trained on agent-synthesized data significantly outperform leading baselines and exhibit robust cross-domain generalization. Notably, a 30B solver trained on only 11,000 synthesized trajectories achieves a state-of-the-art 91.6% accuracy on AIME25, rivaling frontier-scale proprietary models such as GPT-5 and proving that a small volume of high-quality synthetic signals can effectively substitute for massive human-curated datasets.

</details>


### [247] [MeetBench-XL: Calibrated Multi-Dimensional Evaluation and Learned Dual-Policy Agents for Real-Time Meetings](https://arxiv.org/abs/2602.03285)
*Yuelin Hu,Jun Xu,Bingcong Lu,Zhengxue Cheng,Hongwei Hu,Ronghua Wu,Li Song*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Enterprise meeting environments require AI assistants that handle diverse operational tasks, from rapid fact checking during live discussions to cross meeting analysis for strategic planning, under strict latency, cost, and privacy constraints. Existing meeting benchmarks mainly focus on simplified question answering and fail to reflect real world enterprise workflows, where queries arise organically from multi stakeholder collaboration, span long temporal contexts, and require tool augmented reasoning.
  We address this gap through a grounded dataset and a learned agent framework. First, we introduce MeetAll, a bilingual and multimodal corpus derived from 231 enterprise meetings totaling 140 hours. Questions are injected using an enterprise informed protocol validated by domain expert review and human discriminability studies. Unlike purely synthetic benchmarks, this protocol is grounded in four enterprise critical dimensions: cognitive load, temporal context span, domain expertise, and actionable task execution, calibrated through interviews with stakeholders across finance, healthcare, and technology sectors.
  Second, we propose MeetBench XL, a multi dimensional evaluation protocol aligned with human judgment that measures factual fidelity, intent alignment, response efficiency, structural clarity, and completeness. Third, we present MeetMaster XL, a learned dual policy agent that jointly optimizes query routing between fast and slow reasoning paths and tool invocation, including retrieval, cross meeting aggregation, and web search. A lightweight classifier enables accurate routing with minimal overhead, achieving a superior quality latency tradeoff over single model baselines. Experiments against commercial systems show consistent gains, supported by ablations, robustness tests, and a real world deployment case study.Resources: https://github.com/huyuelin/MeetBench.

</details>


### [248] [Rejecting Arguments Based on Doubt in Structured Bipolar Argumentation](https://arxiv.org/abs/2602.03286)
*Michael A. Müller,Srdjan Vesic,Bruno Yun*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper develops a new approach to computational argumentation that is informed by philosophical and linguistic views. Namely, it takes into account two ideas that have received little attention in the literature on computational argumentation: First, an agent may rationally reject an argument based on mere doubt, thus not all arguments they could defend must be accepted; and, second, that it is sometimes more natural to think in terms of which individual sentences or claims an agent accepts in a debate, rather than which arguments. In order to incorporate these two ideas into a computational approach, we first define the notion of structured bipolar argumentation frameworks (SBAFs), where arguments consist of sentences and we have both an attack and a support relation between them. Then, we provide semantics for SBAFs with two features: (1) Unlike with completeness-based semantics, our semantics do not force agents to accept all defended arguments. (2) In addition to argument extensions, which give acceptable sets of arguments, we also provide semantics for language extensions that specify acceptable sets of sentences. These semantics represent reasonable positions an agent might have in a debate. Our semantics lie between the admissible and complete semantics of abstract argumentation. Further, our approach can be used to provide a new perspective on existing approaches. For instance, we can specify the conditions under which an agent can ignore support between arguments (i.e. under which the use of abstract argumentation is warranted) and we show that deductive support semantics is a special case of our approach.

</details>


### [249] [Memora: A Harmonic Memory Representation Balancing Abstraction and Specificity](https://arxiv.org/abs/2602.03315)
*Menglin Xia,Xuchao Zhang,Shantanu Dixit,Paramaguru Harimurugan,Rujia Wang,Victor Ruhle,Robert Sim,Chetan Bansal,Saravan Rajmohan*

Main category: cs.AI

TL;DR: Memora是一种新型记忆表示方法，通过平衡抽象性和特异性解决传统记忆系统中信息扩展与细粒度细节获取的矛盾，在记忆扩展时提升检索相关性和推理效果


<details>
  <summary>Details</summary>
Motivation: 解决agent记忆系统中信息持续增长带来的扩展性问题，传统抽象方法会牺牲特异性，导致推理所需细粒度细节缺失，需要一种平衡抽象与具体细节的记忆表示

Method: 提出Memora记忆表示结构：1）主要抽象索引具体记忆值；2）统一相关更新到记忆条目；3）提示锚点扩展检索路径；4）利用记忆连接的主动检索策略；5）理论证明RAG和KG记忆系统是其特例

Result: Memora在LoCoMo和LongMemEval基准上达到新的SOTA，展示出更好的检索相关性和推理效果（随记忆扩展而提升）

Conclusion: Memora通过谐波记忆表示平衡抽象与特异性，有效解决了agent记忆系统的扩展性问题，在多个基准上超越了现有技术，为大规模agent记忆管理提供了新框架

Abstract: Agent memory systems must accommodate continuously growing information while supporting efficient, context-aware retrieval for downstream tasks. Abstraction is essential for scaling agent memory, yet it often comes at the cost of specificity, obscuring the fine-grained details required for effective reasoning. We introduce Memora, a harmonic memory representation that structurally balances abstraction and specificity. Memora organizes information via its primary abstractions that index concrete memory values and consolidate related updates into unified memory entries, while cue anchors expand retrieval access across diverse aspects of the memory and connect related memories. Building on this structure, we employ a retrieval policy that actively exploits these memory connections to retrieve relevant information beyond direct semantic similarity. Theoretically, we show that standard Retrieval-Augmented Generation (RAG) and Knowledge Graph (KG)-based memory systems emerge as special cases of our framework. Empirically, Memora establishes a new state-of-the-art on the LoCoMo and LongMemEval benchmarks, demonstrating better retrieval relevance and reasoning effectiveness as memory scales.

</details>


### [250] [MentalSeek-Dx: Towards Progressive Hypothetico-Deductive Reasoning for Real-world Psychiatric Diagnosis](https://arxiv.org/abs/2602.03340)
*Xiao Sun,Yuming Yang,Junnan Zhu,Jiang Zhong,Xinyu Zhou,Kaiwen Wei*

Main category: cs.AI

TL;DR: MentalDx Bench是首个用于真实临床环境下疾病级别精神病诊断的基准，包含712份经认证精神病医生标注的电子健康记录，覆盖16个诊断类别下的76种疾病。评估发现LLMs在粗粒度分类表现良好，但在疾病级别诊断上系统性地失败。为此提出的MentalSeek-Dx模型通过监督轨迹构建和课程强化学习实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在精神健康评估方面缺乏生态效度强的基准和细粒度的诊断监督，限制了其临床实际应用价值。

Method: 1. 构建MentalDx Bench基准数据集；2. 提出MentalSeek-Dx模型，采用监督轨迹构建和课程基础强化学习训练，让模型内化临床推理过程。

Result: 评估18个LLM发现范式错配：粗粒度分类表现良好，疾病级别诊断系统性失败。MentalSeek-Dx仅用14B参数就达到了最先进的诊断性能。

Conclusion: 研究填补了LLMs在临床精神病诊断中的基准空白，提出的MentalSeek-Dx为可靠的临床精神病诊断建立了基础框架。

Abstract: Mental health disorders represent a burgeoning global public health challenge. While Large Language Models (LLMs) have demonstrated potential in psychiatric assessment, their clinical utility is severely constrained by benchmarks that lack ecological validity and fine-grained diagnostic supervision. To bridge this gap, we introduce \textbf{MentalDx Bench}, the first benchmark dedicated to disorder-level psychiatric diagnosis within real-world clinical settings. Comprising 712 de-identified electronic health records annotated by board-certified psychiatrists under ICD-11 guidelines, the benchmark covers 76 disorders across 16 diagnostic categories. Evaluation of 18 LLMs reveals a critical \textit{paradigm misalignment}: strong performance at coarse diagnostic categorization contrasts with systematic failure at disorder-level diagnosis, underscoring a gap between pattern-based modeling and clinical hypothetico-deductive reasoning. In response, we propose \textbf{MentalSeek-Dx}, a medical-specialized LLM trained to internalize this clinical reasoning process through supervised trajectory construction and curriculum-based reinforcement learning. Experiments on MentalDx Bench demonstrate that MentalSeek-Dx achieves state-of-the-art (SOTA) performance with only 14B parameters, establishing a clinically grounded framework for reliable psychiatric diagnosis.

</details>


### [251] [Risk Awareness Injection: Calibrating Vision-Language Models for Safety without Compromising Utility](https://arxiv.org/abs/2602.03402)
*Mengxuan Wang,Yuxin Chen,Gang Xu,Tao He,Hongjie Jiang,Ming Li*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Vision language models (VLMs) extend the reasoning capabilities of large language models (LLMs) to cross-modal settings, yet remain highly vulnerable to multimodal jailbreak attacks. Existing defenses predominantly rely on safety fine-tuning or aggressive token manipulations, incurring substantial training costs or significantly degrading utility. Recent research shows that LLMs inherently recognize unsafe content in text, and the incorporation of visual inputs in VLMs frequently dilutes risk-related signals. Motivated by this, we propose Risk Awareness Injection (RAI), a lightweight and training-free framework for safety calibration that restores LLM-like risk recognition by amplifying unsafe signals in VLMs. Specifically, RAI constructs an Unsafe Prototype Subspace from language embeddings and performs targeted modulation on selected high-risk visual tokens, explicitly activating safety-critical signals within the cross-modal feature space. This modulation restores the model's LLM-like ability to detect unsafe content from visual inputs, while preserving the semantic integrity of original tokens for cross-modal reasoning. Extensive experiments across multiple jailbreak and utility benchmarks demonstrate that RAI substantially reduces attack success rate without compromising task performance.

</details>


### [252] [Feasible strategies for conflict resolution within intuitionistic fuzzy preference-based conflict situations](https://arxiv.org/abs/2602.03403)
*Guangming Lang,Mingchuan Shang,Mengjun Hu,Jie Zhou,Feng Xu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In three-way conflict analysis, preference-based conflict situations characterize agents' attitudes towards issues by formally modeling their preferences over pairs of issues. However, existing preference-based conflict models rely exclusively on three qualitative relations, namely, preference, converse, and indifference, to describe agents' attitudes towards issue pairs, which significantly limits their capacity in capturing the essence of conflict. To overcome this limitation, we introduce the concept of an intuitionistic fuzzy preference-based conflict situation that captures agents' attitudes towards issue pairs with finer granularity than that afforded by classical preference-based models. Afterwards, we develop intuitionistic fuzzy preference-based conflict measures within this framework, and construct three-way conflict analysis models for trisecting the set of agent pairs, the agent set, and the issue set. Additionally, relative loss functions built on the proposed conflict functions are employed to calculate thresholds for three-way conflict analysis. Finally, we present adjustment mechanism-based feasible strategies that simultaneously account for both adjustment magnitudes and conflict degrees, together with an algorithm for constructing such feasible strategies, and provide an illustrative example to demonstrate the validity and effectiveness of the proposed model.

</details>


### [253] [DiscoverLLM: From Executing Intents to Discovering Them](https://arxiv.org/abs/2602.03429)
*Tae Soo Kim,Yoonjoo Lee,Jaesang Yu,John Joon Young Chung,Juho Kim*

Main category: cs.AI

TL;DR: 引入DiscoverLLM框架，通过训练LLM帮助用户探索和明确意图，利用层级认知模型和强化学习优化对话


<details>
  <summary>Details</summary>
Motivation: 现有LLM在处理模糊请求时存在局限——当用户自己尚未形成明确意图时，简单的澄清询问无效，需要帮助用户通过探索结果来发现真正的需求

Method: 1. 新颖的用户模拟器：用层级意图结构建模认知状态，随模型呈现相关选项而逐步具体化。2. 具体化程度作为奖励信号训练模型。3. 模型学习自适应策略：意图模糊时发散探索选项，意图明确时收敛细化实现

Result: 1. 在创意写作、技术写作和SVG绘图等交互基准测试中：任务性能提升超过10%，对话长度减少达40%。2. 75人用户研究中：与基线相比，显著提高了对话满意度和效率

Conclusion: DiscoverLLM是一个通用框架，通过建模用户认知过程并优化意图具体化过程，显著改善了LLM在开放式任务中的协作能力

Abstract: To handle ambiguous and open-ended requests, Large Language Models (LLMs) are increasingly trained to interact with users to surface intents they have not yet expressed (e.g., ask clarification questions). However, users are often ambiguous because they have not yet formed their intents: they must observe and explore outcomes to discover what they want. Simply asking "what kind of tone do you want?" fails when users themselves do not know. We introduce DiscoverLLM, a novel and generalizable framework that trains LLMs to help users form and discover their intents. Central to our approach is a novel user simulator that models cognitive state with a hierarchy of intents that progressively concretize as the model surfaces relevant options -- where the degree of concretization serves as a reward signal that models can be trained to optimize. Resulting models learn to collaborate with users by adaptively diverging (i.e., explore options) when intents are unclear, and converging (i.e., refine and implement) when intents concretize. Across proposed interactive benchmarks in creative writing, technical writing, and SVG drawing, DiscoverLLM achieves over 10% higher task performance while reducing conversation length by up to 40%. In a user study with 75 human participants, DiscoverLLM improved conversation satisfaction and efficiency compared to baselines.

</details>


### [254] [Ontology-to-tools compilation for executable semantic constraint enforcement in LLM agents](https://arxiv.org/abs/2602.03439)
*Xiaochi Zhou,Patrick Bulter,Changxuan Yang,Simon D. Rihm,Thitikarn Angkanaporn,Jethro Akroyd,Sebastian Mosbach,Markus Kraft*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce ontology-to-tools compilation as a proof-of-principle mechanism for coupling large language models (LLMs) with formal domain knowledge. Within The World Avatar (TWA), ontological specifications are compiled into executable tool interfaces that LLM-based agents must use to create and modify knowledge graph instances, enforcing semantic constraints during generation rather than through post-hoc validation. Extending TWA's semantic agent composition framework, the Model Context Protocol (MCP) and associated agents are integral components of the knowledge graph ecosystem, enabling structured interaction between generative models, symbolic constraints, and external resources. An agent-based workflow translates ontologies into ontology-aware tools and iteratively applies them to extract, validate, and repair structured knowledge from unstructured scientific text. Using metal-organic polyhedra synthesis literature as an illustrative case, we show how executable ontological semantics can guide LLM behaviour and reduce manual schema and prompt engineering, establishing a general paradigm for embedding formal knowledge into generative systems.

</details>


### [255] [CRL-VLA: Continual Vision-Language-Action Learning](https://arxiv.org/abs/2602.03445)
*Qixin Zeng,Shuo Zhang,Hongyin Zhang,Renjie Wang,Han Zhao,Libang Zhao,Runze Li,Donglin Wang,Chao Huang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Lifelong learning is critical for embodied agents in open-world environments, where reinforcement learning fine-tuning has emerged as an important paradigm to enable Vision-Language-Action (VLA) models to master dexterous manipulation through environmental interaction. Thus, Continual Reinforcement Learning (CRL) is a promising pathway for deploying VLA models in lifelong robotic scenarios, yet balancing stability (retaining old skills) and plasticity (learning new ones) remains a formidable challenge for existing methods. We introduce CRL-VLA, a framework for continual post-training of VLA models with rigorous theoretical bounds. We derive a unified performance bound linking the stability-plasticity trade-off to goal-conditioned advantage magnitude, scaled by policy divergence. CRL-VLA resolves this dilemma via asymmetric regulation: constraining advantage magnitudes on prior tasks while enabling controlled growth on new tasks. This is realized through a simple but effective dual-critic architecture with novel Goal-Conditioned Value Formulation (GCVF), where a frozen critic anchors semantic consistency and a trainable estimator drives adaptation. Experiments on the LIBERO benchmark demonstrate that CRL-VLA effectively harmonizes these conflicting objectives, outperforming baselines in both anti-forgetting and forward adaptation.

</details>


### [256] [The Dual Role of Abstracting over the Irrelevant in Symbolic Explanations: Cognitive Effort vs. Understanding](https://arxiv.org/abs/2602.03467)
*Zeynep G. Saribatur,Johannes Langer,Ute Schmid*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Explanations are central to human cognition, yet AI systems often produce outputs that are difficult to understand. While symbolic AI offers a transparent foundation for interpretability, raw logical traces often impose a high extraneous cognitive load. We investigate how formal abstractions, specifically removal and clustering, impact human reasoning performance and cognitive effort. Utilizing Answer Set Programming (ASP) as a formal framework, we define a notion of irrelevant details to be abstracted over to obtain simplified explanations. Our cognitive experiments, in which participants classified stimuli across domains with explanations derived from an answer set program, show that clustering details significantly improve participants' understanding, while removal of details significantly reduce cognitive effort, supporting the hypothesis that abstraction enhances human-centered symbolic explanations.

</details>


### [257] [When Routing Collapses: On the Degenerate Convergence of LLM Routers](https://arxiv.org/abs/2602.03478)
*Guannan Lai,Han-Jia Ye*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: LLM routing aims to achieve a favorable quality--cost trade-off by dynamically assigning easy queries to smaller models and harder queries to stronger ones. However, across both unimodal and multimodal settings, we uncover a pervasive yet underexplored failure mode in existing routers: as the user's cost budget increases, routers systematically default to the most capable and most expensive model even when cheaper models already suffice. As a result, current routers under-utilize small models, wasting computation and monetary cost and undermining the core promise of routing; we term this phenomenon routing collapse. We attribute routing collapse to an objective--decision mismatch: many routers are trained to predict scalar performance scores, whereas routing decisions ultimately depend on discrete comparisons among candidate models. Consequently, small prediction errors can flip relative orderings and trigger suboptimal selections. To bridge this gap, we propose EquiRouter, a decision-aware router that directly learns model rankings, restoring the role of smaller models and mitigating routing collapse. On RouterBench, EquiRouter reduces cost by about 17\% at GPT-4-level performance compared to the strongest prior router. Our code is available at https://github.com/AIGNLAI/EquiRouter.

</details>


### [258] [Group Selection as a Safeguard Against AI Substitution](https://arxiv.org/abs/2602.03541)
*Qiankun Zhong,Thomas F. Eisenmann,Julian Garcia,Iyad Rahwan*

Main category: cs.AI

TL;DR: 本文通过基于主体的模型和演化博弈论，探讨了生成式AI对人类文化演化的长期影响，特别是AI使用方式（互补与替代）如何影响文化多样性和创新。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的普及可能降低文化多样性和创新，导致'文化崩溃'风险。本文旨在研究不同AI使用方式对人类文化演化的长期影响及其演化动态。

Method: 1. 建立基于主体的演化模型；2. 通过演化博弈论分析两种AI使用策略：互补型（用户主导，AI辅助）和替代型（AI主导）；3. 研究两种策略在演化动态中的竞争与传播。

Result: 1. 替代型用户在个体层面选择中占优势，但会导致文化多样性更强降低；2. 互补型用户在群体选择中更有利，能维持创新所需的多样性，特别是在群体边界较强时；3. 互补型使用策略有助于避免'文化崩溃'。

Conclusion: 不同AI使用策略对文化演化有显著影响：替代型策略短期个体效益好但损害文化多样性；互补型策略更能促进群体创新和长期文化演化。这些发现为制定降低AI风险的策略提供了科学依据。

Abstract: Reliance on generative AI can reduce cultural variance and diversity, especially in creative work. This reduction in variance has already led to problems in model performance, including model collapse and hallucination. In this paper, we examine the long-term consequences of AI use for human cultural evolution and the conditions under which widespread AI use may lead to "cultural collapse", a process in which reliance on AI-generated content reduces human variation and innovation and slows cumulative cultural evolution. Using an agent-based model and evolutionary game theory, we compare two types of AI use: complement and substitute. AI-complement users seek suggestions and guidance while remaining the main producers of the final output, whereas AI-substitute users provide minimal input, and rely on AI to produce most of the output. We then study how these use strategies compete and spread under evolutionary dynamics. We find that AI-substitute users prevail under individual-level selection despite the stronger reduction in cultural variance. By contrast, AI-complement users can benefit their groups by maintaining the variance needed for exploration, and can therefore be favored under cultural group selection when group boundaries are strong. Overall, our findings shed light on the long-term, population-level effects of AI adoption and inform policy and organizational strategies to mitigate these risks.

</details>


### [259] [EHRWorld: A Patient-Centric Medical World Model for Long-Horizon Clinical Trajectories](https://arxiv.org/abs/2602.03569)
*Linjie Mu,Zhongzhen Huang,Yannian Gu,Shengqian Qin,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: 提出EHRWorld患者中心医疗世界模型，解决LLM在长程医疗模拟中状态不一致问题


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在医疗领域虽能完成静态推理任务，但在动态疾病演变和治疗结果的时间序列模拟中，难以维持患者状态一致性，导致长程模拟错误累积

Method: 开发EHRWorld患者中心医疗世界模型，采用因果序列范式训练，并结合真实世界电子健康记录创建EHRWorld-110K大规模纵向临床数据集

Result: EHRWorld显著优于基于LLM的基线方法，实现了更稳定的长程模拟、更好的临床敏感事件建模以及更优的推理效率

Conclusion: 可靠的医疗世界模型需要基于因果基础和时序演化的临床数据进行训练，而非仅依靠静态医疗知识的大语言模型

Abstract: World models offer a principled framework for simulating future states under interventions, but realizing such models in complex, high-stakes domains like medicine remains challenging. Recent large language models (LLMs) have achieved strong performance on static medical reasoning tasks, raising the question of whether they can function as dynamic medical world models capable of simulating disease progression and treatment outcomes over time. In this work, we show that LLMs only incorporating medical knowledge struggle to maintain consistent patient states under sequential interventions, leading to error accumulation in long-horizon clinical simulation. To address this limitation, we introduce EHRWorld, a patient-centric medical world model trained under a causal sequential paradigm, together with EHRWorld-110K, a large-scale longitudinal clinical dataset derived from real-world electronic health records. Extensive evaluations demonstrate that EHRWorld significantly outperforms naive LLM-based baselines, achieving more stable long-horizon simulation, improved modeling of clinically sensitive events, and favorable reasoning efficiency, highlighting the necessity of training on causally grounded, temporally evolving clinical data for reliable and robust medical world modeling.

</details>


### [260] [Can LLMs Do Rocket Science? Exploring the Limits of Complex Reasoning with GTOC 12](https://arxiv.org/abs/2602.03630)
*Iñaki del Campo,Pablo Cuervo,Victor Rodriguez-Fernandez,Roberto Armellin,Jack Yarndley*

Main category: cs.AI

TL;DR: 该研究评估大语言模型在复杂航天任务多阶段规划中的能力，发现模型战略理解显著提升但存在执行瓶颈。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在代码生成和一般推理方面表现出色，但其在物理约束的高维环境中进行自主多阶段规划的能力尚不明确，需要在实际复杂任务中进行评估。

Method: 研究利用MLE-Bench框架适配轨道力学领域，部署AIDE智能体架构自主生成和优化任务方案，并采用专家制定的标准通过LLM-as-a-Judge方法在五个结构类别中评估战略可行性。

Result: 对比分析显示，过去两年平均战略可行性得分几乎翻倍（从9.3上升到17.2/26），但发现战略与执行之间存在关键能力缺口。先进模型能正确理解目标函数和任务架构，但在实施中存在物理单位不一致、边界条件错误和调试效率低下等问题。

Conclusion: 当前大语言模型虽然具备足够的知识和智能来应对空间科学任务，但受限于实施障碍，主要作为强大的领域协助者而非完全自主的工程师。

Abstract: Large Language Models (LLMs) have demonstrated remarkable proficiency in code generation and general reasoning, yet their capacity for autonomous multi-stage planning in high-dimensional, physically constrained environments remains an open research question. This study investigates the limits of current AI agents by evaluating them against the 12th Global Trajectory Optimization Competition (GTOC 12), a complex astrodynamics challenge requiring the design of a large-scale asteroid mining campaign. We adapt the MLE-Bench framework to the domain of orbital mechanics and deploy an AIDE-based agent architecture to autonomously generate and refine mission solutions. To assess performance beyond binary validity, we employ an "LLM-as-a-Judge" methodology, utilizing a rubric developed by domain experts to evaluate strategic viability across five structural categories. A comparative analysis of models, ranging from GPT-4-Turbo to reasoning-enhanced architectures like Gemini 2.5 Pro, and o3, reveals a significant trend: the average strategic viability score has nearly doubled in the last two years (rising from 9.3 to 17.2 out of 26). However, we identify a critical capability gap between strategy and execution. While advanced models demonstrate sophisticated conceptual understanding, correctly framing objective functions and mission architectures, they consistently fail at implementation due to physical unit inconsistencies, boundary condition errors, and inefficient debugging loops. We conclude that, while current LLMs often demonstrate sufficient knowledge and intelligence to tackle space science tasks, they remain limited by an implementation barrier, functioning as powerful domain facilitators rather than fully autonomous engineers.

</details>


### [261] [Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration](https://arxiv.org/abs/2602.03647)
*Bowei He,Minda Hu,Zenan Xu,Hongru Wang,Licheng Zong,Yankai Chen,Chen Ma,Xue Liu,Pluto Zhou,Irwin King*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Search-integrated reasoning enables language agents to transcend static parametric knowledge by actively querying external sources. However, training these agents via reinforcement learning is hindered by the multi-scale credit assignment problem: existing methods typically rely on sparse, trajectory-level rewards that fail to distinguish between high-quality reasoning and fortuitous guesses, leading to redundant or misleading search behaviors. To address this, we propose Search-R2, a novel Actor-Refiner collaboration framework that enhances reasoning through targeted intervention, with both components jointly optimized during training. Our approach decomposes the generation process into an Actor, which produces initial reasoning trajectories, and a Meta-Refiner, which selectively diagnoses and repairs flawed steps via a 'cut-and-regenerate' mechanism. To provide fine-grained supervision, we introduce a hybrid reward design that couples outcome correctness with a dense process reward quantifying the information density of retrieved evidence. Theoretically, we formalize the Actor-Refiner interaction as a smoothed mixture policy, proving that selective correction yields strict performance gains over strong baselines. Extensive experiments across various general and multi-hop QA datasets demonstrate that Search-R2 consistently outperforms strong RAG and RL-based baselines across model scales, achieving superior reasoning accuracy with minimal overhead.

</details>


### [262] [Mitigating Conversational Inertia in Multi-Turn Agents](https://arxiv.org/abs/2602.03664)
*Yang Wan,Zheng Cao,Zhenhao Zhang,Zhengwen Zeng,Shuheng Shen,Changhua Meng,Linchao Zhu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models excel as few-shot learners when provided with appropriate demonstrations, yet this strength becomes problematic in multiturn agent scenarios, where LLMs erroneously mimic their own previous responses as few-shot examples. Through attention analysis, we identify conversational inertia, a phenomenon where models exhibit strong diagonal attention to previous responses, which is associated with imitation bias that constrains exploration. This reveals a tension when transforming few-shot LLMs into agents: longer context enriches environmental feedback for exploitation, yet also amplifies conversational inertia that undermines exploration. Our key insight is that for identical states, actions generated with longer contexts exhibit stronger inertia than those with shorter contexts, enabling construction of preference pairs without environment rewards. Based on this, we propose Context Preference Learning to calibrate model preferences to favor low-inertia responses over highinertia ones. We further provide context management strategies at inference time to balance exploration and exploitation. Experimental results across eight agentic environments and one deep research scenario validate that our framework reduces conversational inertia and achieves performance improvements.

</details>


### [263] [TodyComm: Task-Oriented Dynamic Communication for Multi-Round LLM-based Multi-Agent System](https://arxiv.org/abs/2602.03688)
*Wenzhe Fan,Tommaso Tognoli,Henry Peng Zou,Chunyu Miao,Yibo Wang,Xinhua Zhang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multi-round LLM-based multi-agent systems rely on effective communication structures to support collaboration across rounds. However, most existing methods employ a fixed communication topology during inference, which falls short in many realistic applications where the agents' roles may change \textit{across rounds} due to dynamic adversary, task progression, or time-varying constraints such as communication bandwidth. In this paper, we propose addressing this issue through TodyComm, a \textbf{t}ask-\textbf{o}riented \textbf{dy}namic \textbf{comm}unication algorithm. It produces behavior-driven collaboration topologies that adapt to the dynamics at each round, optimizing the utility for the task through policy gradient. Experiments on five benchmarks demonstrate that under both dynamic adversary and communications budgets, TodyComm delivers superior task effectiveness while retaining token efficiency and scalability.

</details>


### [264] [AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration](https://arxiv.org/abs/2602.03786)
*Jianhao Ruan,Zhihao Xu,Yiran Peng,Fashen Ren,Zhaoyang Yu,Xinbing Liang,Jinyu Xiang,Bang Liu,Chenglin Wu,Yuyu Luo,Jiayi Zhang*

Main category: cs.AI

TL;DR: 该论文提出了一个统一的、框架无关的智能体抽象模型，通过Instruction-Context-Tools-Model元组表示智能体，并在此基础上构建了AOrchestra智能体系统，能动态创建专用执行者以适应不同任务。


<details>
  <summary>Details</summary>
Motivation: 现有智能体系统缺乏动态抽象视图，导致适应性不足。研究者希望设计一个能灵活组合能力、减少人工工程投入的框架无关方案，实现可控的性能-成本权衡。

Method: 提出统一的智能体抽象（Instruction, Context, Tools, Model元组），AOrchestra系统作为中央协调器，能在每个步骤动态具体化该元组：筛选任务相关上下文、选择工具和模型、通过即时自动创建智能体来委托执行。

Result: 在三个具有挑战性的基准测试（GAIA、SWE-Bench、Terminal-Bench）中，AOrchestra与Gemini-3-Flash配合使用时，相对于最强基线取得了16.28%的相对性能提升。

Conclusion: 该研究提供的统一抽象和AOrchestra系统能够动态创建专用智能体执行者，减少人工工程负担，实现框架无关的即插即用支持，同时允许可控的性能-成本权衡以达到帕累托效率。

Abstract: Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra

</details>


### [265] [Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity](https://arxiv.org/abs/2602.03794)
*Yingxuan Yang,Chengrui Qu,Muning Wen,Laixi Shi,Ying Wen,Weinan Zhang,Adam Wierman,Shangding Gu*

Main category: cs.AI

TL;DR: 多智能体系统中智能体数量增加带来的性能提升存在边际效应递减，而异质性（不同模型、提示或工具）则能持续带来显著提升，原因在于性能受限于任务本身的不确定性而非智能体数量，异质性智能体提供了互补证据


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的多智能体系统常通过增加智能体数量来提升性能，但这存在明显的边际收益递减问题，而异质性配置却表现出持续改进。需要从理论上解释为何单纯的规模扩展受限制，以及多样性为何有效

Method: 提出了一个信息论框架，证明MAS性能受限于内在任务不确定性，推导出架构无关的边界条件，显示改进取决于系统访问的有效通道数量。引入了有效通道计数K*来量化无需真实标签的有效通道。经验上对比了同质与异质配置的性能差异

Result: 异质配置始终优于同质扩展：2个异质智能体的性能可以匹配或超过16个同质智能体。同质智能体因其输出强相关而早期饱和，而异质智能体提供互补证据，有效通道更多

Conclusion: 基于多样性的设计能构建更高效、鲁棒的多智能体系统，提供了基于信息论原理的指导原则，强调智能体多样性而非单纯增加数量

Abstract: LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling.

</details>


### [266] [Conformal Thinking: Risk Control for Reasoning on a Compute Budget](https://arxiv.org/abs/2602.03814)
*Xi Wang,Anushri Suresh,Alvin Zhang,Rishi More,William Jurayj,Benjamin Van Durme,Mehrdad Farajtabar,Daniel Khashabi,Eric Nalisnick*

Main category: cs.AI

TL;DR: 本文提出一个风险控制框架，用于自适应调整大型语言模型的推理计算资源：通过设定上下界阈值来平衡准确率与效率，在验证集上利用分布无关风险控制优化停止机制，以减少不必要的计算开销。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型推理时存在计算预算设置的实用挑战，需要在风险与准确率之间权衡。自适应推理虽然能在需要时增加计算，但要避免在额外计算无帮助时浪费资源。本文旨在将预算设置问题重新定义为风险控制问题，限制作错误率的同时尽量减少计算。

Method: 提出风险控制框架，引入上阈值用于模型置信时停止推理，以及新颖的参数化下阈值用于提前终止无解实例。给定目标风险和验证集，使用分布无关风险控制优化这些停止机制；对于多个预算控制标准，结合效率损失选择计算效率最高的退出机制。

Result: 在多种推理任务和模型上的实证结果表明，该风险控制方法能有效降低计算开销，同时满足用户指定的风险目标，下阈值和集成停止机制均展现出计算效率提升。

Conclusion: 所提出的风险控制框架能有效管理自适应推理的计算开销，在确保错误率可控的前提下优化计算效率，为大型语言模型推理中的预算设置提供了可行的解决方案。

Abstract: Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting the token budget, as well as the threshold for adaptive reasoning, is a practical challenge that entails a fundamental risk-accuracy trade-off. We re-frame the budget setting problem as risk control, limiting the error rate while minimizing compute. Our framework introduces an upper threshold that stops reasoning when the model is confident (risking incorrect output) and a novel parametric lower threshold that preemptively stops unsolvable instances (risking premature stoppage). Given a target risk and a validation set, we use distribution-free risk control to optimally specify these stopping mechanisms. For scenarios with multiple budget controlling criteria, we incorporate an efficiency loss to select the most computationally efficient exiting mechanism. Empirical results across diverse reasoning tasks and models demonstrate the effectiveness of our risk control approach, demonstrating computational efficiency gains from the lower threshold and ensemble stopping mechanisms while adhering to the user-specified risk target.

</details>


### [267] [AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations](https://arxiv.org/abs/2602.03828)
*Minjun Zhu,Zhen Lin,Yixuan Weng,Panzhong Lu,Qiujie Xie,Yifan Wei,Sifan Liu,Qiyao Sun,Yue Zhang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers, surveys, blogs, and textbooks. Moreover, we propose AutoFigure, the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text. Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal. Leveraging the high-quality data from FigureBench, we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations. The code, dataset and huggingface space are released in https://github.com/ResearAI/AutoFigure.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [268] [Real-World Applications of AI in LTE and 5G-NR Network Infrastructure](https://arxiv.org/abs/2602.02787)
*Simran Saxena,Arpad Kovesdy*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Telecommunications networks generate extensive performance and environmental telemetry, yet most LTE and 5G-NR deployments still rely on static, manually engineered configurations. This limits adaptability in rural, nomadic, and bandwidth-constrained environments where traffic distributions, propagation characteristics, and user behavior fluctuate rapidly. Artificial Intelligence (AI), more specifically Machine Learning (ML) models, provide new opportunities to transition Radio Access Networks (RANs) from rigid, rule-based systems toward adaptive, self-optimizing infrastructures that can respond autonomously to these dynamics. This paper proposes a practical architecture incorporating AI-assisted planning, reinforcement-learning-based RAN optimization, real-time telemetry analytics, and digital-twin-based validation. In parallel, the paper addresses the challenge of delivering embodied-AI healthcare services, educational tools, and large language model (LLM) applications to communities with insufficient backhaul for cloud computing. We introduce an edge-hosted execution model in which applications run directly on LTE/5G-NR base stations using containers, reducing latency and bandwidth consumption while improving resilience. Together, these contributions demonstrate how AI can enhance network performance, reduce operational overhead, and expand access to advanced digital services, aligning with broader goals of sustainable and inclusive network development.

</details>


### [269] [Towards Context-Aware Edge-Cloud Continuum Orchestration for Multi-user XR Services](https://arxiv.org/abs/2602.03262)
*Inhar Yeregui,Ángel Martín,Mikel Zorrilla,Roberto Viola,Jasone Astorga,Eduardo Jacob*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid growth of multi-user eXtended Reality (XR) applications, spanning fields such as entertainment, education, and telemedicine, demands seamless, immersive experiences for users interacting within shared, distributed environments. Delivering such latency-sensitive experiences involves considerable challenges in orchestrating network, computing, and service resources, where existing limitations highlight the need for a structured approach to analyse and optimise these complex systems. This challenge is amplified by the need for high-performance, low-latency connectivity, where 5G and 6G networks provide essential infrastructure to meet the requirements of XR services at scale. This article addresses these challenges by developing a model that parametrises multi-user XR services across four critical layers of the standard virtualisation architecture. We formalise this model mathematically, proposing a context-aware framework that defines key parameters at each level and integrates them into a comprehensive Edge-Cloud Continuum orchestration strategy. Our contributions include a detailed analysis of the current limitations and needs in existing Edge-Cloud Continuum orchestration approaches, the formulation of a layered mathematical model, and a validation framework that demonstrates the utility and feasibility of the proposed solution.

</details>
