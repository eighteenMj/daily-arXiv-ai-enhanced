<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals](https://arxiv.org/abs/2511.10615)
*Shruti Singh Baghel,Yash Pratap Singh Rathore,Sushovan Jena,Anurag Pradhan,Amit Shukla,Arnav Bhavsar,Pawan Goyal*

Main category: cs.CV

TL;DR: 评估不同规模视觉语言模型在盲人和低视力用户应用中的性能，引入两个专门评估框架并测试模型在移动设备的部署效果。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型虽然能生成有效的视频描述，但内存和计算需求大，限制了其在盲人和低视力用户中的实际使用。

Method: 评估500M和2.2B参数的SmolVLM2变体在AVCaps和Charades数据集上的表现，引入面向盲人和低视力用户的多上下文评估框架和导航辅助框架，测试四种提示策略和移动设备上的FP32、INT8精度变体。

Result: 该内容未通过合规测试，已隐藏。

Conclusion: 该项研究开发了专门针对盲人和低视力用户需求的评估方法，并测试了不同规模模型在移动设备上的可行性。

Abstract: Large Vision-Language Models (VLMs) excel at understanding and generating video descriptions but their high memory, computation, and deployment demands hinder practical use particularly for blind and low-vision (BLV) users who depend on detailed, context-aware descriptions. To study the effect of model size on accessibility-focused description quality, we evaluate SmolVLM2 variants with 500M and 2.2B parameters across two diverse datasets: AVCaps (outdoor), and Charades (indoor). In this work, we introduce two novel evaluation frameworks specifically designed for BLV accessibility assessment: the Multi-Context BLV Framework evaluating spatial orientation, social interaction, action events, and ambience contexts; and the Navigational Assistance Framework focusing on mobility-critical information. Additionally, we conduct a systematic evaluation of four different prompt design strategies and deploy both models on a smartphone, evaluating FP32 and INT8 precision variants to assess real-world performance constraints on resource-limited mobile devices.

</details>


### [2] [One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter for Your Diffusion Models](https://arxiv.org/abs/2511.10629)
*Aleksandr Razin,Danil Kazantsev,Ilya Makarov*

Main category: cs.CV

TL;DR: LUA (Latent Upscaler Adapter) 是一个在潜在空间中直接进行超分辨率处理的轻量级模块，避免了扩散模型直接高分辨率采样的成本高昂问题以及后处理超分辨率带来的伪影和延迟。


<details>
  <summary>Details</summary>
Motivation: 扩散模型难以扩展到超出训练分辨率，直接高分辨率采样既慢又昂贵，而后处理的图像超分辨率(ISR)会在解码后引入伪影和额外延迟。

Method: LUA是一个轻量级模块，在最终VAE解码步骤之前直接在生成器的潜在代码上执行超分辨率。它作为即插即用组件集成，不改变基础模型或增加额外的扩散阶段，通过潜在空间的单次前向传递实现高分辨率合成。使用共享的Swin风格骨干和特定尺度的像素重排头部支持2倍和4倍缩放，与图像空间SR基线保持兼容。

Result: LUA在感知质量上可与基准方法相媲美，解码和上采样时间降低了近3倍（从512px生成1024px仅增加+0.42秒，而相同SwinIR架构的像素空间SR需要1.87秒）。LUA在不同VAE的潜在空间中都表现出强大的泛化能力。

Conclusion: LUA在保持原生高分辨率生成保真度的同时，为现代扩散管道提供了实用且高效的可扩展高保真图像合成路径。

Abstract: Diffusion models struggle to scale beyond their training resolutions, as direct high-resolution sampling is slow and costly, while post-hoc image super-resolution (ISR) introduces artifacts and additional latency by operating after decoding. We present the Latent Upscaler Adapter (LUA), a lightweight module that performs super-resolution directly on the generator's latent code before the final VAE decoding step. LUA integrates as a drop-in component, requiring no modifications to the base model or additional diffusion stages, and enables high-resolution synthesis through a single feed-forward pass in latent space. A shared Swin-style backbone with scale-specific pixel-shuffle heads supports 2x and 4x factors and remains compatible with image-space SR baselines, achieving comparable perceptual quality with nearly 3x lower decoding and upscaling time (adding only +0.42 s for 1024 px generation from 512 px, compared to 1.87 s for pixel-space SR using the same SwinIR architecture). Furthermore, LUA shows strong generalization across the latent spaces of different VAEs, making it easy to deploy without retraining from scratch for each new decoder. Extensive experiments demonstrate that LUA closely matches the fidelity of native high-resolution generation while offering a practical and efficient path to scalable, high-fidelity image synthesis in modern diffusion pipelines.

</details>


### [3] [Enhancing the Outcome Reward-based RL Training of MLLMs with Self-Consistency Sampling](https://arxiv.org/abs/2511.10648)
*Jiahao Wang,Weiye Xu,Aijun Yang,Wengang Zhou,Lewei Lu,Houqiang Li,Xiaohua Wang,Jinguo Zhu*

Main category: cs.CV

TL;DR: 提出自洽采样（SCS）方法，解决多模态大语言模型在结果奖励强化学习中轨迹不忠实的问题，通过在视觉扰动和轨迹重采样中达成一致，提升推理可靠性。


<details>
  <summary>Details</summary>
Motivation: 多模态推理基准中，结果奖励强化学习面临轨迹不忠实的障碍——错误推理链却能猜对选项，这无法忽视。

Method: 自洽采样（SCS）对每个问题引入视觉扰动，并对初始轨迹进行重复截断和重采样，基于轨迹间一致性生成可微一致性分数，在策略更新中降低不可靠轨迹的权重。

Result: 基于Qwen2.5-VL-7B-Instruct，SCS在RLOO、GRPO和REINFORCE++系列上使六个多模态基准的准确率提升达7.7个百分点，额外计算极少。

Conclusion: SCS为多模态大语言模型的结果奖励强化学习提供了一个简单通用的补救方案。

Abstract: Outcome-reward reinforcement learning (RL) is a common and increasingly significant way to refine the step-by-step reasoning of multimodal large language models (MLLMs). In the multiple-choice setting - a dominant format for multimodal reasoning benchmarks - the paradigm faces a significant yet often overlooked obstacle: unfaithful trajectories that guess the correct option after a faulty chain of thought receive the same reward as genuine reasoning, which is a flaw that cannot be ignored. We propose Self-Consistency Sampling (SCS) to correct this issue. For each question, SCS (i) introduces small visual perturbations and (ii) performs repeated truncation and resampling of an initial trajectory; agreement among the resulting trajectories yields a differentiable consistency score that down-weights unreliable traces during policy updates. Based on Qwen2.5-VL-7B-Instruct, plugging SCS into RLOO, GRPO, and REINFORCE++ series improves accuracy by up to 7.7 percentage points on six multimodal benchmarks with negligible extra computation. SCS also yields notable gains on both Qwen2.5-VL-3B-Instruct and InternVL3-8B, offering a simple, general remedy for outcome-reward RL in MLLMs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Algorithm Design and Stronger Guarantees for the Improving Multi-Armed Bandits Problem](https://arxiv.org/abs/2511.10619)
*Avrim Blum,Marten Garicano,Kavya Ravichandran,Dravyansh Sharma*

Main category: cs.LG

TL;DR: 该论文提出了两个参数化多臂老虎机算法家族，用于解决奖励随投入单调递增但收益递减的改进型老虎机问题。第一个家族包含了现有最优随机算法，第二个家族能在假设成立时识别最优臂，在假设不成立时保持最优最坏情况保证。论文还研究了如何利用离线数据学习两个家族中的近似最优算法。


<details>
  <summary>Details</summary>
Motivation: 改进型多臂老虎机问题为在不确定性下分配努力提供了形式化模型，应用于技术研究投资、临床试验和超参数选择等场景。现有算法在最坏情况下存在Ω(k)和Ω(√k)的近似比下界，论文旨在设计能在满足特定假设时提供更强保证的算法。

Method: 定义了两个参数化算法家族：第一个家族包含现有最优随机算法，能在奖励曲线满足额外凹性性质时获得更强的k依赖性保证；第二个家族能在良好实例上保证最优臂识别，在糟糕实例上回退到最坏情况保证。采用统计学习视角，利用离线数据学习近似最优算法。

Result: 提出的算法家族能够在满足强度凹性等额外性质时获得比现有算法更强的保证，实现了最优的k依赖性。同时能够在不验证假设是否成立的情况下获得数据依赖的强保证。

Conclusion: 通过参数化算法家族的设计和离线数据学习，论文克服了改进型老虎机问题中的悲观下界，在满足特定结构假设时提供了更强的性能保证，并实现了在假设验证和稳健性之间的平衡。

Abstract: The improving multi-armed bandits problem is a formal model for allocating effort under uncertainty, motivated by scenarios such as investing research effort into new technologies, performing clinical trials, and hyperparameter selection from learning curves. Each pull of an arm provides reward that increases monotonically with diminishing returns. A growing line of work has designed algorithms for improving bandits, albeit with somewhat pessimistic worst-case guarantees. Indeed, strong lower bounds of $Ω(k)$ and $Ω(\sqrt{k})$ multiplicative approximation factors are known for both deterministic and randomized algorithms (respectively) relative to the optimal arm, where $k$ is the number of bandit arms. In this work, we propose two new parameterized families of bandit algorithms and bound the sample complexity of learning the near-optimal algorithm from each family using offline data. The first family we define includes the optimal randomized algorithm from prior work. We show that an appropriately chosen algorithm from this family can achieve stronger guarantees, with optimal dependence on $k$, when the arm reward curves satisfy additional properties related to the strength of concavity. Our second family contains algorithms that both guarantee best-arm identification on well-behaved instances and revert to worst case guarantees on poorly-behaved instances. Taking a statistical learning perspective on the bandit rewards optimization problem, we achieve stronger data-dependent guarantees without the need for actually verifying whether the assumptions are satisfied.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [Querying Labeled Time Series Data with Scenario Programs](https://arxiv.org/abs/2511.10627)
*Edward Kim,Devan Shanker,Varun Bharadwaj,Hongbeen Park,Jinkyu Kim,Hazem Torfah,Daniel J Fremont,Sanjit A Seshia*

Main category: cs.AI

TL;DR: 论文提出了一种验证模拟仿真中发现的自驾失败场景在真实世界中可复现性的方法，通过形式化定义传感器数据与抽象场景的匹配，并开发了高效的查询算法在真实数据集中定位相似场景。


<details>
  <summary>Details</summary>
Motivation: 解决仿真测试与真实世界之间的差距问题，确保在仿真环境中发现的自动驾驶失效场景能够在现实系统中真实复现，而非仿真数据的人为产物。

Method: 提出了形式化定义标记时间序列传感器数据与Scenic概率编程语言表示的抽象场景匹配的方法，并开发了相应的查询算法在真实数据集中识别符合指定场景的数据子集。

Result: 实验显示该算法比最先进的商业视觉大语言模型更准确，查询速度快了几个数量级，且能够随查询时间序列数据的持续时长进行扩展。

Conclusion: 该方法有效验证了仿真失效场景在真实世界中的可复现性，为自动驾驶系统的安全性验证提供了实用工具。

Abstract: Simulation-based testing has become a crucial complement to road testing for ensuring the safety of cyber physical systems (CPS). As a result, significant research efforts have been directed toward identifying failure scenarios within simulation environments. However, a critical question remains. Are the AV failure scenarios discovered in simulation reproducible on actual systems in the real world? The sim-to-real gap caused by differences between simulated and real sensor data means that failure scenarios identified in simulation might either be artifacts of synthetic sensor data or actual issues that also occur with real sensor data. To address this, an effective approach to validating simulated failure scenarios is to locate occurrences of these scenarios within real-world datasets and verify whether the failure persists on the datasets. To this end, we introduce a formal definition of how labeled time series sensor data can match an abstract scenario, represented as a scenario program using the Scenic probabilistic programming language. We present a querying algorithm that, given a scenario program and a labeled dataset, identifies the subset of data that matches the specified scenario. Our experiment shows that our algorithm is more accurate and orders of magnitude faster in querying scenarios than the state-of-the-art commercial vision large language models, and can scale with the duration of queried time series data.

</details>
