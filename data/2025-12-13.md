<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 8]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.LG](#cs.LG) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MMSI-Video-Bench: A Holistic Benchmark for Video-Based Spatial Intelligence](https://arxiv.org/abs/2512.10863)
*Jingli Lin,Runsen Xu,Shaohao Zhu,Sihan Yang,Peizhou Cao,Yunlong Ran,Miao Hu,Chenming Zhu,Yiman Xie,Yilin Long,Wenbo Hu,Dahua Lin,Tai Wang,Jiangmiao Pang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Spatial understanding over continuous visual input is crucial for MLLMs to evolve into general-purpose assistants in physical environments. Yet there is still no comprehensive benchmark that holistically assesses the progress toward this goal. In this work, we introduce MMSI-Video-Bench, a fully human-annotated benchmark for video-based spatial intelligence in MLLMs. It operationalizes a four-level framework, Perception, Planning, Prediction, and Cross-Video Reasoning, through 1,106 questions grounded in 1,278 clips from 25 datasets and in-house videos. Each item is carefully designed and reviewed by 3DV experts with explanatory rationales to ensure precise, unambiguous grounding. Leveraging its diverse data sources and holistic task coverage, MMSI-Video-Bench also supports three domain-oriented sub-benchmarks (Indoor Scene Perception Bench, Robot Bench and Grounding Bench) for targeted capability assessment. We evaluate 25 strong open-source and proprietary MLLMs, revealing a striking human--AI gap: many models perform near chance, and the best reasoning model lags humans by nearly 60%. We further find that spatially fine-tuned models still fail to generalize effectively on our benchmark. Fine-grained error analysis exposes systematic failures in geometric reasoning, motion grounding, long-horizon prediction, and cross-video correspondence. We also show that typical frame-sampling strategies transfer poorly to our reasoning-intensive benchmark, and that neither 3D spatial cues nor chain-of-thought prompting yields meaningful gains. We expect our benchmark to establish a solid testbed for advancing video-based spatial intelligence.

</details>


### [2] [BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models](https://arxiv.org/abs/2512.10932)
*Shengao Wang,Wenqi Wang,Zecheng Wang,Max Whitton,Michael Wakeham,Arjun Chandra,Joey Huang,Pengyue Zhu,Helen Chen,David Li,Jeffrey Li,Shawn Li,Andrew Zagula,Amy Zhao,Andrew Zhu,Sayaka Nakamura,Yuki Yamamoto,Jerry Jun Yokono,Aaron Mueller,Bryan A. Plummer,Kate Saenko,Venkatesh Saligrama,Boqing Gong*

Main category: cs.CV

TL;DR: BabyVLM-V2是一个基于儿童发展轨迹的视觉语言模型框架，通过纵向多模态数据预训练和DevCV认知评估工具箱，在小规模模型上达到与GPT-4o相当的性能。


<details>
  <summary>Details</summary>
Motivation: 早期儿童发育轨迹为视觉基础模型的高效预训练提供了自然目标，需要开发更符合儿童认知发展的视觉语言建模方法。

Method: 1.使用纵向、多维度的婴儿中心视听语料库预训练数据集；2.开发多功能模型；3.推出DevCV工具箱，将NIH Baby Toolbox的视觉相关测量转化为10项多模态任务基准。

Result: 从零开始预训练的紧凑模型在DevCV工具箱上表现优异，在某些任务上超越了GPT-4o的性能。

Conclusion: BabyVLM-V2框架有望加速视觉基础模型在发展合理性预训练方面的研究进程。

Abstract: Early children's developmental trajectories set up a natural goal for sample-efficient pretraining of vision foundation models. We introduce BabyVLM-V2, a developmentally grounded framework for infant-inspired vision-language modeling that extensively improves upon BabyVLM-V1 through a longitudinal, multifaceted pretraining set, a versatile model, and, most importantly, DevCV Toolbox for cognitive evaluation. The pretraining set maximizes coverage while minimizing curation of a longitudinal, infant-centric audiovisual corpus, yielding video-utterance, image-utterance, and multi-turn conversational data that mirror infant experiences. DevCV Toolbox adapts all vision-related measures of the recently released NIH Baby Toolbox into a benchmark suite of ten multimodal tasks, covering spatial reasoning, memory, and vocabulary understanding aligned with early children's capabilities. Experimental results show that a compact model pretrained from scratch can achieve competitive performance on DevCV Toolbox, outperforming GPT-4o on some tasks. We hope the principled, unified BabyVLM-V2 framework will accelerate research in developmentally plausible pretraining of vision foundation models.

</details>


### [3] [Any4D: Unified Feed-Forward Metric 4D Reconstruction](https://arxiv.org/abs/2512.10935)
*Jay Karhade,Nikhil Keetha,Yuchen Zhang,Tanisha Gupta,Akash Sharma,Sebastian Scherer,Deva Ramanan*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking. Moreover, unlike other recent methods for 4D reconstruction from monocular RGB videos, Any4D can process additional modalities and sensors such as RGB-D frames, IMU-based egomotion, and Radar Doppler measurements, when available. One of the key innovations that allows for such a flexible framework is a modular representation of a 4D scene; specifically, per-view 4D predictions are encoded using a variety of egocentric factors (depthmaps and camera intrinsics) represented in local camera coordinates, and allocentric factors (camera extrinsics and scene flow) represented in global world coordinates. We achieve superior performance across diverse setups - both in terms of accuracy (2-3X lower error) and compute efficiency (15X faster), opening avenues for multiple downstream applications.

</details>


### [4] [OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis](https://arxiv.org/abs/2512.10940)
*Xiang Fan,Sharath Girish,Vivek Ramanujan,Chaoyang Wang,Ashkan Mirzaei,Petr Sushko,Aliaksandr Siarohin,Sergey Tulyakov,Ranjay Krishna*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Prior approaches injecting camera control into diffusion models have focused on specific subsets of 4D consistency tasks: novel view synthesis, text-to-video with camera control, image-to-video, amongst others. Therefore, these fragmented approaches are trained on disjoint slices of available 3D/4D data. We introduce OmniView, a unified framework that generalizes across a wide range of 4D consistency tasks. Our method separately represents space, time, and view conditions, enabling flexible combinations of these inputs. For example, OmniView can synthesize novel views from static, dynamic, and multiview inputs, extrapolate trajectories forward and backward in time, and create videos from text or image prompts with full camera control. OmniView is competitive with task-specific models across diverse benchmarks and metrics, improving image quality scores among camera-conditioned diffusion models by up to 33\% in multiview NVS LLFF dataset, 60\% in dynamic NVS Neural 3D Video benchmark, 20\% in static camera control on RE-10K, and reducing camera trajectory errors by 4x in text-conditioned video generation. With strong generalizability in one model, OmniView demonstrates the feasibility of a generalist 4D video model. Project page is available at https://snap-research.github.io/OmniView/

</details>


### [5] [Mull-Tokens: Modality-Agnostic Latent Thinking](https://arxiv.org/abs/2512.10941)
*Arijit Ray,Ahmed Abdelkader,Chengzhi Mao,Bryan A. Plummer,Kate Saenko,Ranjay Krishna,Leonidas Guibas,Wen-Sheng Chu*

Main category: cs.CV

TL;DR: 该论文提出Mull-Tokens方法，通过模态无关的潜在令牌让模型在图像和文本模态间进行自由推理，解决了现有多模态模型在空间、时间等真实世界推理中的不足。


<details>
  <summary>Details</summary>
Motivation: 现实世界的推理需要涉及空间、时间、功能等多维度信息，而纯语言模型无法充分表达这些内容。现有利用图像进行推理的多模态模型存在脆弱性、缺乏扩展性，依赖专业工具、昂贵的图像生成或手工制作的推理数据。

Method: 提出Mull-Tokens方法，即模态无关的潜在令牌，通过监督性的交错文本-图像轨迹进行预训练，然后在仅有最终答案的情况下进行无监督微调。该方法受潜在推理框架启发，让模型能够在图像或文本模态中自由思考。

Result: 在四个具有挑战性的空间推理基准测试中（包括解决拼图和不同视角转换等任务），Mull-Tokens相比仅文本推理或交错图像-文本推理的基线方法表现更优，平均提升3%，在推理密集的拼图解决任务上最多提升16%。

Conclusion: Mull-Tokens为多模态抽象推理提供了一个简单有效的解决方案，为处理文本和视觉推理中的难题提供了新思路。

Abstract: Reasoning goes beyond language; the real world requires reasoning about space, time, affordances, and much more that words alone cannot convey. Existing multimodal models exploring the potential of reasoning with images are brittle and do not scale. They rely on calling specialist tools, costly generation of images, or handcrafted reasoning data to switch between text and image thoughts. Instead, we offer a simpler alternative -- Mull-Tokens -- modality-agnostic latent tokens pre-trained to hold intermediate information in either image or text modalities to let the model think free-form towards the correct answer. We investigate best practices to train Mull-Tokens inspired by latent reasoning frameworks. We first train Mull-Tokens using supervision from interleaved text-image traces, and then fine-tune without any supervision by only using the final answers. Across four challenging spatial reasoning benchmarks involving tasks such as solving puzzles and taking different perspectives, we demonstrate that Mull-Tokens improve upon several baselines utilizing text-only reasoning or interleaved image-text reasoning, achieving a +3% average improvement and up to +16% on a puzzle solving reasoning-heavy split compared to our strongest baseline. Adding to conversations around challenges in grounding textual and visual reasoning, Mull-Tokens offers a simple solution to abstractly think in multiple modalities.

</details>


### [6] [AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation](https://arxiv.org/abs/2512.10943)
*Sharath Girish,Viacheslav Ivanov,Tsai-Shien Chen,Hao Chen,Aliaksandr Siarohin,Sergey Tulyakov*

Main category: cs.CV

TL;DR: AlcheMinT：一种通过时序编码实现多主体精确时间控制的视频生成框架


<details>
  <summary>Details</summary>
Motivation: 现有主题驱动视频生成方法缺乏对主体出现和消失的细粒度时间控制，这在合成视频、故事板和可控动画等应用中至关重要

Method: 提出统一框架，引入创新的位置编码机制来编码与时序间隔（与主体身份关联），整合预训练视频生成模型位置嵌入；加入主体描述文本标记以增强视觉身份与视频描述的绑定；通过标记级拼接避免额外交叉注意力模块

Result: 在多项主体身份保持、视频保真度和时序一致性评估基准中表现优异，视觉质量达到SOTA视频个性化方法水平，首次实现视频内多主体生成的精确时间控制

Conclusion: AlcheMinT在保持高质量视觉输出的同时，实现了对多主体视频生成的时间维度精确控制，为视频合成、故事板和动画等应用提供了新能力

Abstract: Recent advances in subject-driven video generation with large diffusion models have enabled personalized content synthesis conditioned on user-provided subjects. However, existing methods lack fine-grained temporal control over subject appearance and disappearance, which are essential for applications such as compositional video synthesis, storyboarding, and controllable animation. We propose AlcheMinT, a unified framework that introduces explicit timestamps conditioning for subject-driven video generation. Our approach introduces a novel positional encoding mechanism that unlocks the encoding of temporal intervals, associated in our case with subject identities, while seamlessly integrating with the pretrained video generation model positional embeddings. Additionally, we incorporate subject-descriptive text tokens to strengthen binding between visual identity and video captions, mitigating ambiguity during generation. Through token-wise concatenation, AlcheMinT avoids any additional cross-attention modules and incurs negligible parameter overhead. We establish a benchmark evaluating multiple subject identity preservation, video fidelity, and temporal adherence. Experimental results demonstrate that AlcheMinT achieves visual quality matching state-of-the-art video personalization methods, while, for the first time, enabling precise temporal control over multi-subject generation within videos. Project page is at https://snap-research.github.io/Video-AlcheMinT

</details>


### [7] [Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation](https://arxiv.org/abs/2512.10949)
*Yiwen Tang,Zoey Guo,Kaixin Zhu,Ray Zhang,Qizhi Chen,Dongzhi Jiang,Junli Liu,Bohan Zeng,Haoming Song,Delin Qu,Tianyi Bai,Dan Xu,Wentao Zhang,Bin Zhao*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.

</details>


### [8] [SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model](https://arxiv.org/abs/2512.10957)
*Yukai Shi,Weiyu Li,Zihao Wang,Hongyang Li,Xingyu Chen,Ping Tan,Lei Zhang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [LLMs Can Assist with Proposal Selection at Large User Facilities](https://arxiv.org/abs/2512.10895)
*Lijie Ding,Janell Thomson,Jon Taylor,Changwoo Do*

Main category: cs.AI

TL;DR: 该研究探索使用大语言模型（LLM）改进大型用户设施的提案评选过程，相比传统人工评审，LLM方法更可扩展、一致且成本效益更高。提案选择关键在于评估提案间的相对强度，传统人工评分存在相关性弱、易受偏见和不一致影响的问题。基于成对偏好的方法理论上更严谨、内部一致性更好，但对人工评审来说工作量巨大。利用橡树岭国家实验室散裂中子源三个束线的精心整理提案和发表记录，研究表明LLM排名与人工排名高度相关（相关系数0.2-0.8，移除10%离群值后可达≥0.5）。LLM在识别高发表潜力提案方面不逊于人工评审，而成本降低两个数量级以上。此外，LLM还能进行嵌入模型量化评估提案相似性等人类难以实现的先进分析。


<details>
  <summary>Details</summary>
Motivation: 传统人工评审提案评分存在三大问题：1）不同提案间的相关性较弱；2）易受评审人偏见影响；3）一致性不足。虽然基于成对偏好的排序方法在理论上更严谨、内部一致性更好，但由于工作量按提案数量呈二次方增长，对人工评审完全不现实。因此需要寻找一种既能保持成对比较优势，又能大规模应用的替代方案。

Method: 采用大语言模型进行提案评审，特别强调基于成对偏好的排名方法。该方法逻辑上优于传统评分，通过LLM自动进行成对比较。研究数据来自橡树岭国家实验室散裂中子源三个束线的精心整理提案和相应发表记录，具有高质量的标注基础。除了基本排名功能外，还利用嵌入模型进行提案相似性量化分析等高级能力。

Result: 1. LLM排名与人工评审排名呈强正相关（Spearman ρ ≈ 0.2-0.8）；2. 移除10%离群值后相关性显著提升，达到ρ ≥ 0.5；3. 在识别高发表潜力提案方面，LLM表现不亚于人类评审者；4. 成本效益显著：LLM成本比人工评审低两个数量级以上；5. 实现了人工难以进行的先进分析，如通过嵌入模型量化评估提案相似性，为评审委员会提供关键信息。

Conclusion: LLM为大型用户设施的提案选择流程提供了可行、高效且成本效益显著的替代方案。它在保持与传统人工评审相当甚至更优表现的同时，消除了人工评审的主观不一致性和高成本问题。特别是LLM能够实现的成对偏好排名和提案相似性量化分析等高级功能，为评审过程带来了传统方法无法提供的新维度，有潜力彻底改变大规模科研提案的评审范式。

Abstract: We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $ρ\simeq 0.2-0.8$, improving to $\geq 0.5$ after 10\% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.

</details>


### [10] [On Decision-Making Agents and Higher-Order Causal Processes](https://arxiv.org/abs/2512.10937)
*Matt Wilson*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent's policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [UrbanAI 2025 Challenge: Linear vs Transformer Models for Long-Horizon Exogenous Temperature Forecasting](https://arxiv.org/abs/2512.10866)
*Ruslan Gokhman*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study long-horizon exogenous-only temperature forecasting - a challenging univariate setting where only the past values of the indoor temperature are used for prediction - using linear and Transformer-family models. We evaluate Linear, NLinear, DLinear, Transformer, Informer, and Autoformer under standardized train, validation, and test splits. Results show that linear baselines (Linear, NLinear, DLinear) consistently outperform more complex Transformer-family architectures, with DLinear achieving the best overall accuracy across all splits. These findings highlight that carefully designed linear models remain strong baselines for time series forecasting in challenging exogenous-only settings.

</details>


### [12] [Guided Transfer Learning for Discrete Diffusion Models](https://arxiv.org/abs/2512.10877)
*Julian Kleutgens,Claudio Battiloro,Lingkai Kong,Benjamin Grewe,Francesca Dominici,Mauricio Tec*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Discrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domains. Transfer learning is the natural way to adapt pretrained discrete diffusion models, but current methods require fine-tuning large diffusion models, which is computationally expensive and often impractical. Building on ratio-based transfer learning for continuous diffusion, we provide Guided Transfer Learning for discrete diffusion models (GTL). This enables sampling from a target distribution without modifying the pretrained denoiser. The same guidance formulation applies to both discrete-time diffusion and continuous-time score-based discrete diffusion, yielding a unified treatment. Guided discrete diffusion often requires many forward passes of the guidance network, which becomes impractical for large vocabularies and long sequences. To address this, we further present an efficient guided sampler that concentrates evaluations on planner-selected positions and top candidate tokens, thus lowering sampling time and computation. This makes guided language modeling practical at scale for large vocabularies and long sequences. We evaluate GTL on sequential data, including synthetic Markov chains and language modeling, and provide empirical analyses of its behavior.

</details>


### [13] [Physics-Informed Learning of Flow Distribution and Receiver Heat Losses in Parabolic Trough Solar Fields](https://arxiv.org/abs/2512.10886)
*Stefan Matthes,Markus Schramm*

Main category: cs.LG

TL;DR: 本文提出了一种物理信息学习框架，利用夜间均化期运行数据，从抛物槽式CSP电站的常规运行数据中推断回路级质量流量比和接收器时变传热系数。


<details>
  <summary>Details</summary>
Motivation: 抛物槽式CSP电站的回路系统中存在光学性能、热损失和压降的空间异质性，但流量和接收器热损参数无法直接观测，导致难以诊断水力不平衡或接收器退化问题。

Method: 利用夜间热油在未辐照场中循环的均化期来分离水力和热损效应，将可微分共轭传热模型离散化并嵌入端到端学习流程，使用Andasol 3电站历史数据进行优化。

Result: 模型准确重构了回路温度（RMSE <2°C），获得了物理意义上合理的回路不平衡和接收器热损估计，与无人机红外热成像结果高度吻合，成功识别了所有高损耗接收器区域。

Conclusion: 嘈杂的真实世界CSP运行数据结合适当的建模和可微分优化，包含足够信息来恢复潜在物理参数，为解决CSP电站的监控难题提供了有效方法。

Abstract: Parabolic trough Concentrating Solar Power (CSP) plants operate large hydraulic networks of collector loops that must deliver a uniform outlet temperature despite spatially heterogeneous optical performance, heat losses, and pressure drops. While loop temperatures are measured, loop-level mass flows and receiver heat-loss parameters are unobserved, making it impossible to diagnose hydraulic imbalances or receiver degradation using standard monitoring tools.
  We present a physics-informed learning framework that infers (i) loop-level mass-flow ratios and (ii) time-varying receiver heat-transfer coefficients directly from routine operational data. The method exploits nocturnal homogenization periods -- when hot oil is circulated through a non-irradiated field -- to isolate hydraulic and thermal-loss effects. A differentiable conjugate heat-transfer model is discretized and embedded into an end-to-end learning pipeline optimized using historical plant data from the 50 MW Andasol 3 solar field.
  The model accurately reconstructs loop temperatures (RMSE $<2^\circ$C) and produces physically meaningful estimates of loop imbalances and receiver heat losses. Comparison against drone-based infrared thermography (QScan) shows strong correspondence, correctly identifying all areas with high-loss receivers. This demonstrates that noisy real-world CSP operational data contain enough information to recover latent physical parameters when combined with appropriate modeling and differentiable optimization.

</details>


### [14] [SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale](https://arxiv.org/abs/2512.10922)
*Max Zimmer,Christophe Roux,Moritz Wagner,Deborah Hendrych,Sebastian Pokutta*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The resource requirements of Neural Networks can be significantly reduced through pruning -- the removal of seemingly less important parameters. However, with the rise of Large Language Models (LLMs), full retraining to recover pruning-induced performance degradation is often prohibitive and classical approaches such as global magnitude pruning are suboptimal on Transformer architectures. State-of-the-art methods hence solve a layer-wise mask selection problem, the problem of finding a pruning mask which minimizes the per-layer pruning error on a small set of calibration data. Exactly solving this problem to optimality using Integer Programming (IP) solvers is computationally infeasible due to its combinatorial nature and the size of the search space, and existing approaches therefore rely on approximations or heuristics. In this work, we demonstrate that the mask selection problem can be made drastically more tractable at LLM scale. To that end, we decouple the rows by enforcing equal sparsity levels per row. This allows us to derive optimal 1-swaps (exchanging one kept and one pruned weight) that can be computed efficiently using the Gram matrix of the calibration data. Using these observations, we propose a tractable and simple 1-swap algorithm that warm starts from any pruning mask, runs efficiently on GPUs at LLM scale, and is essentially hyperparameter-free. We demonstrate that our approach reduces per-layer pruning error by up to 60% over Wanda (Sun et al., 2023) and consistently improves perplexity and zero-shot accuracy across state-of-the-art GPT architectures.

</details>


### [15] [Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation](https://arxiv.org/abs/2512.10925)
*Zamirddine Mari,Mohamad Motasem Nawaf,Pierre Drap*

Main category: cs.LG

TL;DR: 提出基于PPO算法的深度强化学习方法用于BlueROV2水下自主导航，通过结合多个传感器信息，在仿真和真实环境中验证，性能优于动态窗口方法


<details>
  <summary>Details</summary>
Motivation: 水下环境缺乏GPS、能见度差且存在障碍物，自主导航面临严峻挑战，需要开发适应复杂水下环境的有效导航方法

Method: 使用PPO算法训练导航策略，观测空间融合目标导向导航信息、虚拟占用网格和操作区域边界射线投射。通过与动态窗口方法对比，在仿真和真实BlueROV2上进行验证

Result: 在高度杂乱环境中，PPO策略始终优于DWA方法，表现出更好的局部适应性和更少的碰撞。实验验证了从仿真到真实世界的可转移性

Conclusion: 深度强化学习对于水下机器人自主导航具有实际应用价值，能够有效适应复杂环境并减少碰撞风险

Abstract: Autonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We propose a deep reinforcement learning approach based on the Proximal Policy Optimization (PPO) algorithm, using an observation space that combines target-oriented navigation information, a virtual occupancy grid, and ray-casting along the boundaries of the operational area. The learned policy is compared against a reference deterministic kinematic planner, the Dynamic Window Approach (DWA), commonly employed as a robust baseline for obstacle avoidance. The evaluation is conducted in a realistic simulation environment and complemented by validation on a physical BlueROV2 supervised by a 3D digital twin of the test site, helping to reduce risks associated with real-world experimentation. The results show that the PPO policy consistently outperforms DWA in highly cluttered environments, notably thanks to better local adaptation and reduced collisions. Finally, the experiments demonstrate the transferability of the learned behavior from simulation to the real world, confirming the relevance of deep RL for autonomous navigation in underwater robotics.

</details>


### [16] [Decoupled Q-Chunking](https://arxiv.org/abs/2512.10926)
*Qiyang Li,Seohong Park,Sergey Levine*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Temporal-difference (TD) methods learn state and action values efficiently by bootstrapping from their own future value predictions, but such a self-bootstrapping mechanism is prone to bootstrapping bias, where the errors in the value targets accumulate across steps and result in biased value estimates. Recent work has proposed to use chunked critics, which estimate the value of short action sequences ("chunks") rather than individual actions, speeding up value backup. However, extracting policies from chunked critics is challenging: policies must output the entire action chunk open-loop, which can be sub-optimal for environments that require policy reactivity and also challenging to model especially when the chunk length grows. Our key insight is to decouple the chunk length of the critic from that of the policy, allowing the policy to operate over shorter action chunks. We propose a novel algorithm that achieves this by optimizing the policy against a distilled critic for partial action chunks, constructed by optimistically backing up from the original chunked critic to approximate the maximum value achievable when a partial action chunk is extended to a complete one. This design retains the benefits of multi-step value propagation while sidestepping both the open-loop sub-optimality and the difficulty of learning action chunking policies for long action chunks. We evaluate our method on challenging, long-horizon offline goal-conditioned tasks and show that it reliably outperforms prior methods. Code: github.com/ColinQiyangLi/dqc.

</details>


### [17] [Asynchronous Reasoning: Training-Free Interactive Thinking LLMs](https://arxiv.org/abs/2512.10931)
*George Yakushev,Nataliia Babina,Masoud Vahid Dastgerdi,Vyacheslav Zhdanovskiy,Alina Shutova,Denis Kuznedelev*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while formulating the answer. In this work, we augment LLMs capable of reasoning to operate in a similar way without additional training. Our method uses the properties of rotary embeddings to enable LLMs built for sequential interactions to simultaneously think, listen, and generate outputs. We evaluate our approach on math, commonsense, and safety reasoning and find that it can generate accurate thinking-augmented answers in real time, reducing time to first non-thinking token from minutes to <= 5s. and the overall real-time delays by 6-11x.

</details>


### [18] [Stronger Normalization-Free Transformers](https://arxiv.org/abs/2512.10938)
*Mingzhi Chen,Taiming Lu,Jiachen Zhu,Mingjie Sun,Zhuang Liu*

Main category: cs.LG

TL;DR: 论文研究了标准化层的替代方案，提出了Derf函数（基于误差函数的点对点函数），在多个领域超越了现有标准化方法。


<details>
  <summary>Details</summary>
Motivation: 虽然标准化层长期以来被视为深度学习架构的必要组成部分，但近期Dynamic Tanh（DyT）的引入表明存在替代方案。本研究旨在探索能超越DyT性能的函数设计。

Method: 首先研究点对点函数的内在属性如何影响训练和性能，然后进行大规模搜索以寻找更有效的函数设计，最终提出了基于缩放高斯累积分布函数的Derf函数。

Result: Derf在视觉、语音表示、DNA序列建模等多个领域超越了LayerNorm、RMSNorm和DyT，性能增益主要源于改进的泛化能力而非更强的拟合能力。

Conclusion: Derf的简单性和更强性能使其成为无标准化Transformer架构的实用选择。

Abstract: Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Through this exploration, we introduce $\mathrm{Derf}(x) = \mathrm{erf}(αx + s)$, where $\mathrm{erf}(x)$ is the rescaled Gaussian cumulative distribution function, and identify it as the most performant design. Derf outperforms LayerNorm, RMSNorm, and DyT across a wide range of domains, including vision (image recognition and generation), speech representation, and DNA sequence modeling. Our findings suggest that the performance gains of Derf largely stem from its improved generalization rather than stronger fitting capacity. Its simplicity and stronger performance make Derf a practical choice for normalization-free Transformer architectures.

</details>


### [19] [Hierarchical Dataset Selection for High-Quality Data Sharing](https://arxiv.org/abs/2512.10952)
*Xiaona Zhou,Yingyan Zeng,Ran Jin,Ismini Lourentzou*

Main category: cs.LG

TL;DR: DaSH方法通过分层次建模数据集和分组效用，在大规模异构数据集池中进行有效选择，提升下游模型性能


<details>
  <summary>Details</summary>
Motivation: 现实场景中数据按数据集组织，质量和相关性各异。现有方法大多忽略数据集差异，仅选择单个样本，需要能选择整个数据集的有效方法

Method: 提出DaSH方法，在数据集和分组（如收藏机构、组织）两个层次建模效用，实现从有限观测中高效泛化

Result: 在Digit-Five和DomainNet基准测试中，DaSH比最先进的数据选择基线准确率提升达26.2%，且需要更少的探索步骤。在低资源和无相关数据集情况下仍保持稳健

Conclusion: DaSH适用于实际多源学习工作流中可扩展和自适应的数据集选择

Abstract: The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.

</details>


### [20] [Bidirectional Normalizing Flow: From Data to Noise and Back](https://arxiv.org/abs/2512.10953)
*Yiyang Lu,Qiao Sun,Xianbang Wang,Zhicheng Jiang,Hanhong Zhao,Kaiming He*

Main category: cs.LG

TL;DR: BiFlow通过用近似逆模型取代精确解析逆，解决了因果解码瓶颈，在保持生成质量的同时大幅加速采样。


<details>
  <summary>Details</summary>
Motivation: 传统标准化流（NFs）要求前向变换具有显式可逆性以确保精确解析逆，但TARFlow等变体暴露了因果解码的速度瓶颈。BiFlow旨在去除对精确解析逆的依赖，实现更灵活架构和更高效率。

Method: 提出双向标准化流（BiFlow）框架，学习一个近似噪声到数据逆映射的逆向模型，替代传统NF的精确解析逆。这允许使用更灵活的损失函数和架构设计，突破因果解码限制。

Result: 在ImageNet上的实验表明，相比因果解码方法，BiFlow提升了生成质量，同时采样加速了1-2个数量级。在基于NF的方法中达到SOTA，并在单步评估（1-NFE）方法中具有竞争力。

Conclusion: BiFlow通过引入近似逆映射机制，显著改善了NFs的效率和性能，为这一经典范式的新发展提供了方向。

Abstract: Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ($\textbf{BiFlow}$), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation ("1-NFE") methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.

</details>
