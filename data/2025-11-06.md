<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 34]
- [cs.LG](#cs.LG) [Total: 43]
- [eess.SY](#eess.SY) [Total: 13]
- [cs.IT](#cs.IT) [Total: 5]
- [cs.AI](#cs.AI) [Total: 11]
- [eess.IV](#eess.IV) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Cropland Mapping using Geospatial Embeddings](https://arxiv.org/abs/2511.02923)
*Ivan Zvonkov,Gabriel Tseng,Inbal Becker-Reshef,Hannah Kerner*

Main category: cs.CV

TL;DR: This研究使用Presto和AlphaEarth的地理空间嵌入来制作对土地利用变化及其气候影响进行更好评估的农田地图，证明了地理空间嵌入在制作农场地图方面的高效性和可访问性，简化了工作流程，并实现了高精度的农田分类。


<details>
  <summary>Details</summary>
Motivation: 准确及时的土地覆盖图是理解土地利用变化的关键，而土地利用变化是气候变化的主要驱动力。地理空间嵌入提供了一种更有效和可访问的方法来绘制景观特征。然而，它们在现实世界的制图应用中的使用仍然被忽视。这项工作的动机是评估地理空间嵌入在多哥农田制图中的效用。

Method: 研究使用Presto和AlphaEarth的地理空间嵌入生成农田地图，以证明地理空间嵌入在实际应用中的优越性。

Result: 研究发现，地理空间嵌入可以简化工作流程，实现高精度的农田分类，并最终支持更好的土地利用变化和气候影响评估。这表明地理空间嵌入在现实世界的制图应用中有巨大的潜力。

Conclusion: 地理空间嵌入可以为制作高精度的农田地图提供一种更高效、可访问的方法，简化了工作流程，并提高了土地利用变化的评估效率与精度，适用于评估气候影响。

Abstract: Accurate and up-to-date land cover maps are essential for understanding land
use change, a key driver of climate change. Geospatial embeddings offer a more
efficient and accessible way to map landscape features, yet their use in
real-world mapping applications remains underexplored. In this work, we
evaluated the utility of geospatial embeddings for cropland mapping in Togo. We
produced cropland maps using embeddings from Presto and AlphaEarth. Our
findings show that geospatial embeddings can simplify workflows, achieve
high-accuracy cropland classification and ultimately support better assessments
of land use change and its climate impacts.

</details>


### [2] [Generative Hints](https://arxiv.org/abs/2511.02933)
*Andy Dimnaku,Abdullah Yusuf Kavranoğlu,Yaser Abu-Mostafa*

Main category: cs.CV

TL;DR: 提出了一种名为'生成提示'的训练方法，该方法利用生成模型生成虚拟示例，以直接强制执行整个输入空间中的已知不变性。这种方法在半监督学习设置中优于标准的数据增强方法，在多个数据集、架构和损失函数上表现出一致的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的数据增强方法通过变换训练数据来引入变化和减少过拟合，但它并不能完全捕捉到这些不变性。因此，提出了生成提示的方法，直接强制执行整个输入空间中的已知不变性，以改进模型的泛化能力。

Method: 利用生成模型学习训练集的输入分布并生成未标记的虚拟图像（虚拟示例），在模型训练过程中同时考虑分类和提示目标，通过虚拟示例来引导模型学习期望的提示。

Result: 在多个数据集、架构和损失函数上，生成提示方法的表现优于标准数据增强方法，特别是在细粒度视觉分类基准上，性能提升了高达1.78％（平均0.63％），在CheXpert X光数据集上平均性能提升1.286％。

Conclusion: 生成提示是一种新的训练方法，能够更好地捕捉模型不变性，从而提高模型在不同数据集和任务上的泛化能力。

Abstract: Data augmentation is widely used in vision to introduce variation and
mitigate overfitting, through enabling models to learn invariant properties,
such as spatial invariance. However, these properties are not fully captured by
data augmentation alone, since it attempts to learn the property on
transformations of the training data only. We propose generative hints, a
training methodology that directly enforces known invariances in the entire
input space. Our approach leverages a generative model trained on the training
set to approximate the input distribution and generate unlabeled images, which
we refer to as virtual examples. These virtual examples are used to enforce
functional properties known as hints. In generative hints, although the
training dataset is fully labeled, the model is trained in a semi-supervised
manner on both the classification and hint objectives, using the unlabeled
virtual examples to guide the model in learning the desired hint. Across
datasets, architectures, and loss functions, generative hints consistently
outperform standard data augmentation when learning the same property. On
popular fine-grained visual classification benchmarks, we achieved up to 1.78%
top-1 accuracy improvement (0.63% on average) over fine-tuned models with data
augmentation and an average performance boost of 1.286% on the CheXpert X-ray
dataset.

</details>


### [3] [ProM3E: Probabilistic Masked MultiModal Embedding Model for Ecology](https://arxiv.org/abs/2511.02946)
*Srikumar Sastry,Subash Khanal,Aayush Dhakal,Jiayu Lin,Dan Cher,Phoenix Jarosz,Nathan Jacobs*

Main category: cs.CV

TL;DR: ProM3E 是一个概率性掩码多模态嵌入模型，用于生态学中任意模态到任意模态的生成。该模型基于嵌入空间中的掩码模态重构，学习在给定一些上下文模态的情况下推断缺失的模态。通过这些特性，该研究提出了一种新的跨模态检索方法，结合了跨模态和同模态相似性，显著提升了检索任务的性能。此外，还利用模型的隐藏表示进行线性探测任务，展示了模型的优越表示学习能力。所有代码、数据集和模型将在指定网址上公开。


<details>
  <summary>Details</summary>
Motivation: 在生态学领域，研究者面临从多种模态数据中生成高质量表示的挑战，特别是在给定有限模态信息时。为了克服这一问题，本研究提出了一个名为 ProM3E 的概率性掩码多模态嵌入模型，旨在有效结合和转换不同模态的信息，以适应各种下游任务的需求。覆盖多模态信息的同时，还保持了模型对于任务相关的模态融合的灵活性和高效性。此外，通过混合跨模态和同模态相似性，能显著提升跨模态检索任务的表现。最后，通过线性探测任务，展示模型强大的表示学习能力。因此该方法可用于生态学中多种模态数据的复杂任务处理，有效解决现有技术中性能不足的问题。

Method: 模型通过学习给定条件下的模态信息来推测缺失的模态信息。重要的是，模型允许模态在嵌入空间中反转，这使得它能够结合各种给定下游任务所需的模态。此外，还提出了一种新的跨模态检索方法，通过结合不同模态间和同模态的相似性来提升检索性能。最后，对模型的潜在表示进行线性探测任务，追踪学习结果。

Result: 该模型在跨模态检索任务中表现出色，在所有实验中都优于现有方法。而且，模型能够根据任务要求灵活调整模态融合策略，增强了表示学习的效果。开放的资源如代码、数据集和模型将极大促进生态学领域和其他研究的学术交流和实际应用。

Conclusion: 通过引入一个概率性掩码多模态嵌入模型 ProM3E，实现了高效的模态信息处理和融合，并展示了在跨模态检索任务中的强大性能优势。实现了高效的学习和灵活的模态融合策略，既适用于复杂生态学场景中的多模态任务，也为其他多模态研究提供了新的视角和方法。

Abstract: We introduce ProM3E, a probabilistic masked multimodal embedding model for
any-to-any generation of multimodal representations for ecology. ProM3E is
based on masked modality reconstruction in the embedding space, learning to
infer missing modalities given a few context modalities. By design, our model
supports modality inversion in the embedding space. The probabilistic nature of
our model allows us to analyse the feasibility of fusing various modalities for
given downstream tasks, essentially learning what to fuse. Using these features
of our model, we propose a novel cross-modal retrieval approach that mixes
inter-modal and intra-modal similarities to achieve superior performance across
all retrieval tasks. We further leverage the hidden representation from our
model to perform linear probing tasks and demonstrate the superior
representation learning capability of our model. All our code, datasets and
model will be released at https://vishu26.github.io/prom3e.

</details>


### [4] [EvtSlowTV - A Large and Diverse Dataset for Event-Based Depth Estimation](https://arxiv.org/abs/2511.02953)
*Sadiq Layi Macaulay,Nimet Kaygusuz,Simon Hadfield*

Main category: cs.CV

TL;DR: 引入了EvtSlowTV，一个大规模的事件相机数据集，用于深度估计，具有高动态范围和低延迟，适用于复杂场景和运动。该数据集来自YouTube视频，包含超过13B事件，比现有数据集大一个数量级。使用EvtSlowTV训练增强模型的泛化能力，无需帧级注释，保持异步性质数据特点。


<details>
  <summary>Details</summary>
Motivation: 当前事件基于深度估计方法受限于小规模注释数据集，导致泛化能力有限。本文动机是通过引入大规模、自然环境的事件数据集提高算法在真实世界中的泛化能力。

Method: 创建大规模事件数据集EvtSlowTV，使用来自YouTube不同环境和运动的视频获取事件流，用于训练无监督深度估计模型以利用事件流的高动态范围属性。

Result: 使用的EvtSlowTV数据集训练模型可以更好地适应复杂场景和运动，展示了数据集对深度估计任务的优越性和无监督学习的优势。

Conclusion: 通过引入大规模、高质量的事件数据集EvtSlowTV，不仅扩大了训练样本的多样性，还展示了在复杂条件下进行深度估计的有效性，突破了传统注释方法的限制，提供了新的研究路径。

Abstract: Event cameras, with their high dynamic range (HDR) and low latency, offer a
promising alternative for robust depth estimation in challenging environments.
However, many event-based depth estimation approaches are constrained by
small-scale annotated datasets, limiting their generalizability to real-world
scenarios. To bridge this gap, we introduce EvtSlowTV, a large-scale event
camera dataset curated from publicly available YouTube footage, which contains
more than 13B events across various environmental conditions and motions,
including seasonal hiking, flying, scenic driving, and underwater exploration.
EvtSlowTV is an order of magnitude larger than existing event datasets,
providing an unconstrained, naturalistic setting for event-based depth
learning. This work shows the suitability of EvtSlowTV for a self-supervised
learning framework to capitalise on the HDR potential of raw event streams. We
further demonstrate that training with EvtSlowTV enhances the model's ability
to generalise to complex scenes and motions. Our approach removes the need for
frame-based annotations and preserves the asynchronous nature of event data.

</details>


### [5] [Hybrid Convolution and Vision Transformer NAS Search Space for TinyML Image Classification](https://arxiv.org/abs/2511.02992)
*Mikhael Djajapermana,Moritz Reiber,Daniel Mueller-Gritschneder,Ulf Schlichtmann*

Main category: cs.CV

TL;DR: 本文介绍了一种新的Neural Architecture Search (NAS)的CNN-ViT混合架构搜索空间，以在图像分类任务中找到高效的混合架构。实验结果表明，在模型尺寸限制下，该搜索空间可以生成比ResNet-based tinyML模型具有更优准确率和推断速度的CNN-ViT混合架构。


<details>
  <summary>Details</summary>
Motivation: 现有的CNN和ViT混合架构虽然在性能上优于纯CNN或ViT架构，但由于参数量大，计算成本高，难以用于tinyML部署。因此，本文提出了一个新的NAS搜索空间，以找到适用于tinyML部署的高效混合架构。

Method: 本文提出的NAS搜索空间包括混合CNN和ViT模块以学习局部和全局信息，以及一种可搜索的Pooling层，用于高效的特征图减少。通过实验验证了该搜索空间的有效性。

Result: 实验结果表明，在CIFAR10数据集上，本文方法可以生成准确率和推断速度优于ResNet-based tinyML模型的CNN-ViT混合架构。

Conclusion: 本文提出了一个用于高效图像分类任务的新的CNN-ViT混合架构搜索空间，结果表明该方法在模型尺寸限制下仍能生成性能优异的模型。

Abstract: Hybrids of Convolutional Neural Network (CNN) and Vision Transformer (ViT)
have outperformed pure CNN or ViT architecture. However, since these
architectures require large parameters and incur large computational costs,
they are unsuitable for tinyML deployment. This paper introduces a new hybrid
CNN-ViT search space for Neural Architecture Search (NAS) to find efficient
hybrid architectures for image classification. The search space covers hybrid
CNN and ViT blocks to learn local and global information, as well as the novel
Pooling block of searchable pooling layers for efficient feature map reduction.
Experimental results on the CIFAR10 dataset show that our proposed search space
can produce hybrid CNN-ViT architectures with superior accuracy and inference
speed to ResNet-based tinyML models under tight model size constraints.

</details>


### [6] [ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly](https://arxiv.org/abs/2511.03098)
*Miftahur Rahman,Samuel Adebayo,Dorian A. Acevedo-Mejia,David Hester,Daniel McPolin,Karen Rafferty,Debra F. Laefer*

Main category: cs.CV

TL;DR: ISC-Perception是一个专门为ISC组件检测设计的混合数据集，结合了CAD图像、游戏引擎的真实场景和少量实际照片。该数据集通过模拟引擎和场景设置、资产准备、后期处理脚本和质量检查等步骤生成。实验表明，与合成数据或真实数据训练的模型相比，使用ISC-Perception训练的检测器性能明显更好。


<details>
  <summary>Details</summary>
Motivation: 目前钢架组装过程中，需要依靠手动组装，但这种方法效率低且存在安全隐患。因此，需要一种能够加速组装过程的同时保障工人安全的技术，这里引入了ISC系统。但是对于机器人执行ISC任务，可靠的感知是最初的步骤，而这缺乏专门的图像库，因为从实际建筑工地收集照片在操作上困难且存在安全和隐私的问题。所以需要一个专门的ISC组件检测的数据集来改进这个问题。

Method: 通过使用CAD图像，游戏引擎的逼真场景和少量的真实照片，创建了一个混合数据集，称为ISC-Perception。这个数据集的生成考虑了人为的努力，包括模拟引擎和场景设置，资产准备，后期处理脚本和质量检查。数据集的总人为时间是30.5小时，与手工标记的166.7小时相比减少了81.7%。模型在ISC-Perception上的训练表现出色，mAP@0.50/mAP@[0.50:0.95]的指标分别为0.943/0.823。

Result: 实验结果显示，使用ISC-Perception训练的检测器在mAP@0.50上的平均准确率达到了0.756，这远远超过了仅通过合成数据或仅通过真实数据训练的模型。而在1200帧基准测试中，记录的mAP@0.50/mAP@[0.50:0.95]的指标分别为0.943/0.823。

Conclusion: ISC-Perception填补了建筑机器人感知的数据空白，促进定制对象检测器的快速开发，并且该数据集可免费用于研究成果和工业应用。

Abstract: The Intermeshed Steel Connection (ISC) system, when paired with robotic
manipulators, can accelerate steel-frame assembly and improve worker safety by
eliminating manual assembly. Dependable perception is one of the initial stages
for ISC-aware robots. However, this is hampered by the absence of a dedicated
image corpus, as collecting photographs on active construction sites is
logistically difficult and raises safety and privacy concerns. In response, we
introduce ISC-Perception, the first hybrid dataset expressly designed for ISC
component detection. It blends procedurally rendered CAD images, game-engine
photorealistic scenes, and a limited, curated set of real photographs, enabling
fully automatic labelling of the synthetic portion. We explicitly account for
all human effort to produce the dataset, including simulation engine and scene
setup, asset preparation, post-processing scripts and quality checks; our total
human time to generate a 10,000-image dataset was 30.5,h versus 166.7,h for
manual labelling at 60,s per image (-81.7%). A manual pilot on a representative
image with five instances of ISC members took 60,s (maximum 80,s), anchoring
the manual baseline. Detectors trained on ISC-Perception achieved a mean
Average Precision at IoU 0.50 of 0.756, substantially surpassing models trained
on synthetic-only or photorealistic-only data. On a 1,200-frame bench test, we
report mAP@0.50/mAP@[0.50:0.95] of 0.943/0.823. By bridging the data gap for
construction-robotics perception, ISC-Perception facilitates rapid development
of custom object detectors and is freely available for research and industrial
use upon request.

</details>


### [7] [SCALE-VLP: Soft-Weighted Contrastive Volumetric Vision-Language Pre-training with Spatial-Knowledge Semantics](https://arxiv.org/abs/2511.02996)
*Ailar Mahdizadeh,Puria Azadi Moghadam,Xiangteng He,Shahriar Mirabbasi,Panos Nasiopoulos,Leonid Sigal*

Main category: cs.CV

TL;DR: SCALE-VLP 是一种软加权对比视觉语言预训练框架，能够有效处理体数据（如CT）中的连续和结构依赖性，同时保持解剖结构并引导语义对齐。相比现有最佳方法，SCALE-VLP在多个任务中表现出色，并且在跨领域迁移中也显示出优越性。


<details>
  <summary>Details</summary>
Motivation: 当前大多数视觉与语言模型仅限于处理2D数据且依赖二元监督，忽视了体数据中的连续和结构依赖性。SCALE-VLP旨在解决这些问题，通过集成体数据的空间语义以及领域意识和知识注入的语义来提高模型性能。

Method: SCALE-VLP采用了软加权对比学习的方法，结合体数据的空间语义和领域相关的知识语义，生成结构一致且语义稳固的表征。该框架能够在有限的监督下工作，同时展现出强大的跨任务迁移能力和跨领域泛化能力。

Result: SCALE-VLP相较于最先进的方法，CT报告检索的Top-1精确度提高了4.3倍，异常检测提升10%，报告生成的ROUGE-L和BERT-F1分别为0.44和0.89；在零样本评估的外部数据集上，观察到了持续的性能提升。

Conclusion: SCALE-VLP框架通过引入体数据的空间和领域特殊性的知识，能够在少监督条件下生成结构一致、语义稳定的表征，并在多项任务上表现优于现有方法，同时展示了强大的跨任务和跨领域泛化能力。

Abstract: Vision-language models (VLMs) have demonstrated strong cross-modal
capabilities, yet most work remains limited to 2D data and assumes binary
supervision (i.e., positive vs. negative pairs), overlooking the continuous and
structured dependencies present in volumetric data such as CT. Existing
approaches often treat volumetric scans as independent 2D slices, compromising
spatial coherence and underutilizing rich clinical semantics. We propose
SCALE-VLP, a soft-weighted contrastive vision-language pre-training framework
that integrates (i) volumetric spatial semantics to preserve anatomical
structure and (ii) domain-aware, knowledge-infused semantics (e.g.,
radiological ontologies) to guide alignment. This yields structurally
consistent and semantically grounded representations under limited supervision,
demonstrating strong cross-task transferability (retrieval, report generation,
and classification), and cross-domain generalizability with consistent gains
without further fine-tuning. In particular, compared to the previous state of
the art, SCALE-VLP achieves up to 4.3x higher top-1 CT-report retrieval,
improves abnormality classification by 10 points, and reaches ROUGE-L 0.44 and
BERT-F1 0.89 for report generation. Further, in zero-shot evaluation on an
out-of-domain external dataset, we observe consistent gains, indicating the
cross-task and cross-domain generalization ability of SCALE-VLP.

</details>


### [8] [Learning with less: label-efficient land cover classification at very high spatial resolution using self-supervised deep learning](https://arxiv.org/abs/2511.03004)
*Dakota Hester,Vitor S. Martins,Lucas B. Ferreira,Thainara M. A. Lima*

Main category: cs.CV

TL;DR: 研究介绍了一种仅使用少量标注数据（1,000个图像块）进行州级1米分辨率土地覆盖分类的方法，通过自监督预训练减少了对大量人工标注数据的需求，并在密西西比州的8类土地覆盖分类中实现了87.14%的整体准确率和75.58%的宏F1得分。


<details>
  <summary>Details</summary>
Motivation: 土地覆盖分类的数据标注需求巨大，阻碍了高分辨率土地覆盖制图的广泛应用。基于深度学习的土地覆盖语义分割方法在1米分辨率土地覆盖分类上表现出色，但训练数据收集的难度限制了其应用。因此，本研究提出了一种基于自监督学习的方法来减少对大量标注数据的需求。

Method: 使用'Bootstrap Your Own Latent'预训练策略和大量未标注的彩色红外航空图像对ResNet-101卷积编码器进行预训练，然后将训练好的编码器权重转移到多个深度语义分割架构中，并通过非常小的训练数据集进行微调。

Result: 在密西西比州的土地覆盖分类中，该研究获得了87.14%的整体准确率和75.58%的宏F1得分，特别是对于开放水域和森林区的准确分类。然而，作物、草地和裸地之间的精确划分仍具有挑战性。

Conclusion: 自监督学习是一种有效的策略，可减少对大量手动标注数据的需求，直接解决了高分辨率土地覆盖制图的主要限制问题。

Abstract: Deep learning semantic segmentation methods have shown promising performance
for very high 1-m resolution land cover classification, but the challenge of
collecting large volumes of representative training data creates a significant
barrier to widespread adoption of such models for meter-scale land cover
mapping over large areas. In this study, we present a novel label-efficient
approach for statewide 1-m land cover classification using only 1,000 annotated
reference image patches with self-supervised deep learning. We use the
"Bootstrap Your Own Latent" pre-training strategy with a large amount of
unlabeled color-infrared aerial images (377,921 256x256 1-m pixel patches) to
pre-train a ResNet-101 convolutional encoder. The learned encoder weights were
subsequently transferred into multiple deep semantic segmentation architectures
(FCN, U-Net, Attention U-Net, DeepLabV3+, UPerNet, PAN), which were then
fine-tuned using very small training dataset sizes with cross-validation (250,
500, 750 patches). Among the fine-tuned models, we obtained the 87.14% overall
accuracy and 75.58% macro F1 score using an ensemble of the best performing
U-Net models for comprehensive 1-m, 8-class land cover mapping, covering more
than 123 billion pixels over the state of Mississippi, USA. Detailed
qualitative and quantitative analysis revealed accurate mapping of open water
and forested areas, while highlighting challenges in accurate delineation
between cropland, herbaceous, and barren land cover types. These results show
that self-supervised learning is an effective strategy for reducing the need
for large volumes of manually annotated data, directly addressing a major
limitation to high spatial resolution land cover mapping at scale.

</details>


### [9] [SLIP: Structural-aware Language-Image Pretraining for Vision-Language Alignment](https://arxiv.org/abs/2511.03019)
*Wenbo Lu*

Main category: cs.CV

TL;DR: SLIP是一种新的Vision-Language预训练方法，它通过在结构化图中建模相邻实体之间的关系，将图像文本对作为有结构联系的样本处理，从而提高了跨模态对齐的效果。实验表明，SLIP在未见过和少量样本的情况下，在跨模态检索和分类任务上均优于CLIP。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language预训练方法将图像-文本对视为孤立的训练样本，忽视了图像和文本对之间的关系。本文受神经科学证据启发，提出了SLIP方法，旨在利用结构化的监督来提高跨模态对齐的效果。

Method: SLIP通过结构对比损失函数，不仅对齐了模态，还建模了结构化图中相邻实体之间的关系。为此，本文构建了一个大规模的Amazon产品共购多模态图数据集。

Result: 实验结果显示，SLIP在跨模态检索和分类任务中，不论是未见过还是少量样本的情况，均优于CLIP。这表明关系监督对于跨模态对齐非常重要。

Conclusion: SLIP通过结构化的监督，提高了跨模态对齐的效果，展示了其在未见过和少量样本情况下的优势。

Abstract: Vision-Language Pretraining (VLP) has achieved remarkable success across
various downstream tasks, but such gains are largely driven by scaling up on
training data. Yet, literature methods treat image-text pairs as isolated
training examples; this neglects the rich relational structure naturally
present in many domains, such as e-commerce product co-purchase graphs and
social recommendation networks. Inspired by neuroscientific evidence that human
encodes knowledge as relationship cognitive maps, we introduce Structure-aware
Language-Image Pretraining (SLIP). SLIP integrates a structural contrastive
loss to align modalities while also modeling relationships between neighboring
entities in a structured graph. To support this paradigm, we construct a
large-scale Amazon Product Co-purchase Multimodal Graph Dataset, enabling
structured cross-modality supervision at scale. Experiment results show that
SLIP consistently outperforms CLIP on cross-modal retrieval and classification
tasks in both zero-shot and few-shot settings, showing the value of relational
supervision for cross-modal alignment.

</details>


### [10] [From Propagation to Prediction: Point-level Uncertainty Evaluation of MLS Point Clouds under Limited Ground Truth](https://arxiv.org/abs/2511.03053)
*Ziyang Xu,Olaf Wysocki,Christoph Holst*

Main category: cs.CV

TL;DR: 本文提出了一种基于学习的框架用于评估移动激光扫描（MLS）点云的不确定性，该框架结合了最优邻域估计和几何特征提取，实验表明可以使用几何特征预测点级别的不确定性，并提出了学习基于的不确定性评估研究的新视角。


<details>
  <summary>Details</summary>
Motivation: 在高精度应用中，准确评估移动激光扫描（MLS）点云的不确定性至关重要，但是获得地面真实数据进行评估通常成本高昂且在许多实际应用中不可行，因此提出了一个不依赖于地面真实数据的基于学习的方法框架。

Method: 该研究提出了一种框架，它结合了最优邻域估计和几何特征提取，并使用XGBoost和随机森林模型来评估不确定性。

Result: 实验结果证明了提出的框架的有效性，XGBoost模型在精度上与随机森林模型相当，但在效率上提高了约3倍。此外，几何特征能够预测点级别的不确定性，用C2C距离量化。

Conclusion: 这项研究表明MLS点云的不确定性是可学习的，提供了一种新的基于学习的角度来看待不确定性评估研究。

Abstract: Evaluating uncertainty is critical for reliable use of Mobile Laser Scanning
(MLS) point clouds in many high-precision applications such as Scan-to-BIM,
deformation analysis, and 3D modeling. However, obtaining the ground truth (GT)
for evaluation is often costly and infeasible in many real-world applications.
To reduce this long-standing reliance on GT in uncertainty evaluation research,
this study presents a learning-based framework for MLS point clouds that
integrates optimal neighborhood estimation with geometric feature extraction.
Experiments on a real-world dataset show that the proposed framework is
feasible and the XGBoost model delivers fully comparable accuracy to Random
Forest while achieving substantially higher efficiency (about 3 times faster),
providing initial evidence that geometric features can be used to predict
point-level uncertainty quantified by the C2C distance. In summary, this study
shows that MLS point clouds' uncertainty is learnable, offering a novel
learning-based viewpoint towards uncertainty evaluation research.

</details>


### [11] [DentalSplat: Dental Occlusion Novel View Synthesis from Sparse Intra-Oral Photographs](https://arxiv.org/abs/2511.03099)
*Yiyi Miao,Taoyu Wu,Tong Chen,Sihao Li,Ji Jiang,Youpeng Yang,Angelos Stefanidis,Limin Yu,Jionglong Su*

Main category: cs.CV

TL;DR: 提出了一种名为DentalSplat的框架，用于从稀疏的正畸图像中进行3D重建，特别适合远程正畸诊疗场景。该方法利用先验引导的稠密立体重建模型初始化点云，并结合尺度自适应修剪策略以及光学流和梯度正则化来提高重建质量和渲染保真度。实验显示，DentalSplat在处理稀疏输入时表现优异，且优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在正畸治疗中，特别是远程医疗背景下，通过多个视角观察患者的咬合状况有助于及时做出临床决策。然而，传统3D Gaussian Splatting (3DGS) 流程需要密集的多视角输入和精确的相机姿态初始化，这对于通常仅有三个稀疏图像（前视图和双侧颊视图）的正畸案例而言是不现实的。因此，研究提出了DentalSplat框架以解决这一问题。

Method: DentalSplat结合了先验引导的稠密立体重建模型，以初始点云，并运用尺度自适应修剪策略优化3DGS的训练效率和重建质量。对于极端稀疏的视点场景，该方法还加入光学流作为几何约束，并结合梯度正则化来增强渲染的保真度。该方法在950个病例的大规模数据集上进行了验证，并且在设计用于模拟远程正畸影像条件下195个视频案例的数据集中，进一步证明了其有效性。

Result: 实验结果显示，所提出的方法能够有效处理稀疏输入，并实现了比现有技术更好的新视角合成质量和牙齿咬合可视化。

Conclusion: 通过利用先验知识和技术创新，DentalSplat成功地解决了从有限视图中进行高质量3D重建的问题，特别是在正畸远程诊疗中，不仅提高了临床决策的效率，也提高了患者的治疗体验。

Abstract: In orthodontic treatment, particularly within telemedicine contexts,
observing patients' dental occlusion from multiple viewpoints facilitates
timely clinical decision-making. Recent advances in 3D Gaussian Splatting
(3DGS) have shown strong potential in 3D reconstruction and novel view
synthesis. However, conventional 3DGS pipelines typically rely on densely
captured multi-view inputs and precisely initialized camera poses, limiting
their practicality. Orthodontic cases, in contrast, often comprise only three
sparse images, specifically, the anterior view and bilateral buccal views,
rendering the reconstruction task especially challenging. The extreme sparsity
of input views severely degrades reconstruction quality, while the absence of
camera pose information further complicates the process. To overcome these
limitations, we propose DentalSplat, an effective framework for 3D
reconstruction from sparse orthodontic imagery. Our method leverages a
prior-guided dense stereo reconstruction model to initialize the point cloud,
followed by a scale-adaptive pruning strategy to improve the training
efficiency and reconstruction quality of 3DGS. In scenarios with extremely
sparse viewpoints, we further incorporate optical flow as a geometric
constraint, coupled with gradient regularization, to enhance rendering
fidelity. We validate our approach on a large-scale dataset comprising 950
clinical cases and an additional video-based test set of 195 cases designed to
simulate real-world remote orthodontic imaging conditions. Experimental results
demonstrate that our method effectively handles sparse input scenarios and
achieves superior novel view synthesis quality for dental occlusion
visualization, outperforming state-of-the-art techniques.

</details>


### [12] [Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class Discovery via Self-Supervised Learning](https://arxiv.org/abs/2511.03120)
*Botong. Zhao,Xubin. Wang,Shujing. Lyu,Yue. Lu*

Main category: cs.CV

TL;DR: IC DefectNCD是一个用于集成电路缺陷检测和新型缺陷发现的支持集自由框架。该方法在没有大量人工标注和面对罕见缺陷的情况下，能够稳定且精确地发现问题区域，并且可以识别和分类未见过的缺陷。验证数据集覆盖了三个关键制造阶段和15种缺陷类型，实验表明该方法在缺陷检测和未见过的缺陷分类方面都表现出色.


<details>
  <summary>Details</summary>
Motivation: IC制造过程中存在大量难以人工标注的罕见缺陷，现有的监督和无监督方法往往性能不稳定或效果不佳。为此，提出了一种新的识别和分类芯片缺陷的方法，特别是对于新类别的缺陷发现更加有效和稳定.

Method: IC DefectNCD通过结合正常图像特征的提取，以及缺陷区域的自适应二值化策略来定位缺陷。再通过软掩码引导的注意力机制提高对缺陷区域的敏感度，并抑制背景噪音，最终实现对未知缺陷的有效识别与分类.

Result: 实验结果表明，IC DefectNCD在实际数据集上对缺陷检测和未见过的缺陷分类均有很好的表现，展示了该方法在处理罕见和新型缺陷时的有效性及鲁棒性.

Conclusion: IC DefectNCD作为一个无支持集的方法，在面对罕见和复杂的集成电路制造缺陷方面，展示出了优秀的性能。这种方法为新型缺陷的识别提出了一个新的思路，有可能在集成电路的制造过程中提高质量和效率.

Abstract: Integrated circuit manufacturing is highly complex, comprising hundreds of
process steps. Defects can arise at any stage, causing yield loss and
ultimately degrading product reliability. Supervised methods require extensive
human annotation and struggle with emergent categories and rare, data scarce
defects. Clustering-based unsupervised methods often exhibit unstable
performance due to missing priors. We propose IC DefectNCD, a support set free
framework that leverages Image Intrinsic Priors in IC SEM images for defect
detection and novel class discovery. We first develop Self Normal Information
Guided IC Defect Detection, aggregating representative normal features via a
learnable normal information extractor and using reconstruction residuals to
coarsely localize defect regions. To handle saliency variations across defects,
we introduce an adaptive binarization strategy that produces stable subimages
focused on core defective areas. Finally, we design Self Defect Information
Guided IC Defect Classification, which incorporates a soft mask guided
attention mechanism to inject spatial defect priors into the teacher student
model. This enhances sensitivity to defective regions, suppresses background
interference, and enables recognition and classification of unseen defects. We
validate the approach on a real world dataset spanning three key fabrication
stages and covering 15 defect types. Experiments demonstrate robust performance
on both defect detection and unseen defect classification.

</details>


### [13] [Accelerating Physical Property Reasoning for Augmented Visual Cognition](https://arxiv.org/abs/2511.03126)
*Hongbo Lan,Zhenlin An,Haoyu Li,Vaibhav Singh,Longfei Shangguan*

Main category: cs.CV

TL;DR: \\sysname is a system designed to accelerate vision-guided physical property reasoning, reducing the end-to-end latency from 10--20 minutes to less than 6 seconds while maintaining or slightly improving object-level estimation accuracy and showing better performance in material segmentation and voxel-level inference in real-world scenarios.


<details>
  <summary>Details</summary>
Motivation: The paper aims to reduce the run-time latency of vision-guided physical property reasoning, enabling faster and more efficient augmented visual cognition in real-world environments.

Method: \\sysname achieves its goals through a combination of rapid geometric 3D reconstruction, efficient semantic feature fusion, and parallel view encoding.

Result: \\sysname achieves a 62.9$\times$--287.2$\times$ speedup on the ABO dataset while maintaining or slightly improving object-level physical property estimation accuracy. It also shows superior performance in material segmentation and voxel-level inference, and demonstrates consistent high performance in real-world scenarios with smart glasses.

Conclusion: The paper concludes that \\sysname successfully accelerates physical property reasoning while maintaining accuracy, and it effectively localizes objects of interest in cluttered, real-world environments, thereby improving the practicality of augmented visual cognition systems.

Abstract: This paper introduces \sysname, a system that accelerates vision-guided
physical property reasoning to enable augmented visual cognition. \sysname
minimizes the run-time latency of this reasoning pipeline through a combination
of both algorithmic and systematic optimizations, including rapid geometric 3D
reconstruction, efficient semantic feature fusion, and parallel view encoding.
Through these simple yet effective optimizations, \sysname reduces the
end-to-end latency of this reasoning pipeline from 10--20 minutes to less than
6 seconds. A head-to-head comparison on the ABO dataset shows that \sysname
achieves this 62.9$\times$--287.2$\times$ speedup while not only reaching
on-par (and sometimes slightly better) object-level physical property
estimation accuracy(e.g. mass), but also demonstrating superior performance in
material segmentation and voxel-level inference than two SOTA baselines. We
further combine gaze-tracking with \sysname to localize the object of interest
in cluttered, real-world environments, streamlining the physical property
reasoning on smart glasses. The case study with Meta Aria Glasses conducted at
an IKEA furniture store demonstrates that \sysname achives consistently high
performance compared to controlled captures, providing robust property
estimations even with fewer views in real-world scenarios.

</details>


### [14] [Deploying Rapid Damage Assessments from sUAS Imagery for Disaster Response](https://arxiv.org/abs/2511.03132)
*Thomas Manzini,Priyankari Perali,Robin R. Murphy*

Main category: cs.CV

TL;DR: 本文介绍了一种AI/ML系统，用于通过小型无人机系统图像自动化建筑物损坏评估，已在联邦宣布的灾害（飓风Debby和Helene）中部署。解决了灾难响应中由于图像数量过多，专家难以及时评估的问题。该模型基于21,716个建筑物损坏标签的最大已知数据集训练，并在18分钟内完成了415个建筑物的评估。


<details>
  <summary>Details</summary>
Motivation: 灾害发生时需要快速准确地评估损失，但人工评估无人机收集的大量图像在时间和资源上存在挑战。AI/ML技术可帮助加速这一过程，虽然已有使用卫星图像评估损失的研究，但在小型无人机系统中还未有实际应用的先例。

Method: 该研究通过开发并部署基于小型无人机系统图像的建筑物损坏评估模型来解决实际数据处理难题。利用包含21,716个建筑物损坏标签的最大已知数据集进行训练，并由91名灾难现场专家接受操作培训。

Result: 最佳模型在飓风Debby和Helene的响应中部署，并在约18分钟内评估了415个建筑物。

Conclusion: 该工作首次展示了AI/ML技术在灾难响应中进行损失评估的实际应用，提供了实践经验和教训，对AI/ML研究和用户社区有益。

Abstract: This paper presents the first AI/ML system for automating building damage
assessment in uncrewed aerial systems (sUAS) imagery to be deployed
operationally during federally declared disasters (Hurricanes Debby and
Helene). In response to major disasters, sUAS teams are dispatched to collect
imagery of the affected areas to assess damage; however, at recent disasters,
teams collectively delivered between 47GB and 369GB of imagery per day,
representing more imagery than can reasonably be transmitted or interpreted by
subject matter experts in the disaster scene, thus delaying response efforts.
To alleviate this data avalanche encountered in practice, computer vision and
machine learning techniques are necessary. While prior work has been deployed
to automatically assess damage in satellite imagery, there is no current state
of practice for sUAS-based damage assessment systems, as all known work has
been confined to academic settings. This work establishes the state of practice
via the development and deployment of models for building damage assessment
with sUAS imagery. The model development involved training on the largest known
dataset of post-disaster sUAS aerial imagery, containing 21,716 building damage
labels, and the operational training of 91 disaster practitioners. The best
performing model was deployed during the responses to Hurricanes Debby and
Helene, where it assessed a combined 415 buildings in approximately 18 minutes.
This work contributes documentation of the actual use of AI/ML for damage
assessment during a disaster and lessons learned to the benefit of the AI/ML
research and user communities.

</details>


### [15] [Finetuning-Free Personalization of Text to Image Generation via Hypernetworks](https://arxiv.org/abs/2511.03156)
*Sagar Shrestha,Gopal Sharma,Luowei Zhou,Suren Kumar*

Main category: cs.CV

TL;DR: 通过使用直接从主题图像预测LoRA适应权重的Hypernetwork，研究提出了无需额外细调的个性化方法。此外，还引入了Hybrid-Model Classifier-Free Guidance以增强组合泛化能力，实验证明该方法在人物定制性能方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统上个性化文本到图像扩散模型依赖昂贵且耗时的细调。虽然有些方法试图减少这种开销，但仍然需要额外的细调或大规模骨干模型才能获得满意的结果。于是，作者探索了一个新的方向：无需细调的个性化，通过Hypernetwork提出直接预测LoRA适应权重的方法。同时，研究还提出了Hybrid-Model Classifier-Free Guidance以进一步增强输出的泛化能力。

Method: 作者提出了一种基于Hypernetwork的方法，该方法能够直接从主题图像预测LoRA适应权重，无需对每个主题进行单独优化。在此基础上，研究还引入了Hybrid-Model Classifier-Free Guidance来结合基础扩散模型的组合强度和个人化模型的主题保真度，以提高样本的质量。此外，输出规范化也用于稳定Hypernetwork。

Result: 通过CelebA-HQ, AFHQ-v2, DreamBench等实验，证明了该方法能够在人物定制性能方面表现出色，表明Hypernetworks作为一个可扩展和有效的方法，对于开放式类别的人物定制非常有前景。

Conclusion: 实验结果表明，基于Hypernetwork的方法无需对每个主题进行单独优化的同时，仍能保持良好的主题保真度和一致提示。通过引入Hybrid-Model Classifier-Free Guidance也提高了组合泛化能力，展示了Hypernetworks对于开放式类别人物定制的有效性和可扩展性。

Abstract: Personalizing text-to-image diffusion models has traditionally relied on
subject-specific fine-tuning approaches such as
DreamBooth~\cite{ruiz2023dreambooth}, which are computationally expensive and
slow at inference. Recent adapter- and encoder-based methods attempt to reduce
this overhead but still depend on additional fine-tuning or large backbone
models for satisfactory results. In this work, we revisit an orthogonal
direction: fine-tuning-free personalization via Hypernetworks that predict
LoRA-adapted weights directly from subject images. Prior hypernetwork-based
approaches, however, suffer from costly data generation or unstable attempts to
mimic base model optimization trajectories. We address these limitations with
an end-to-end training objective, stabilized by a simple output regularization,
yielding reliable and effective hypernetworks. Our method removes the need for
per-subject optimization at test time while preserving both subject fidelity
and prompt alignment. To further enhance compositional generalization at
inference time, we introduce Hybrid-Model Classifier-Free Guidance (HM-CFG),
which combines the compositional strengths of the base diffusion model with the
subject fidelity of personalized models during sampling. Extensive experiments
on CelebA-HQ, AFHQ-v2, and DreamBench demonstrate that our approach achieves
strong personalization performance and highlights the promise of hypernetworks
as a scalable and effective direction for open-category personalization.

</details>


### [16] [Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation](https://arxiv.org/abs/2511.03163)
*Yun-Chen Lin,Jiayuan Huang,Hanyuan Zhang,Sergi Kavtaradze,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 提出了一种基于深度引导的肝脏解剖标志分割框架，结合了视觉基础编码器的语义和几何线索。通过SRFT-GaLore方法实现了模型的高效微调，并通过跨注意力融合模块整合RGB和深度特征，提高了分割精度和鲁棒性。这种方法在公开的L3D数据集和新构建的LLSD数据集上都表现出色，展示了跨数据集的一致性与适应性。


<details>
  <summary>Details</summary>
Motivation: 在腹腔镜肝脏手术中，2D视频流限制了深度感知，地标定位变得复杂。虽然有研究利用单目视觉线索提高地标检测，但融合RGB和深度特征以及调整大规模视觉模型以适应手术领域仍然是挑战。提出了一种集成视觉基础编码器的方法来解决这些问题。

Method: 利用Segment Anything Model V2（SAM2）编码器提取RGB特征，Depth Anything V2（DA2）编码器提取深度感知特征，通过SRFT-GaLore方法实现了高效微调，并使用跨注意力融合模块整合RGB和深度特征。构建了Laparoscopic Liver Surgical Dataset（LLSD）作为外部验证基准。

Result: 与D2GPLand相比，在公共L3D数据集上，该方法在Dice Similarity Coefficient上提高了4.85%，在Average Symmetric Surface Distance上减少了11.78点；在LLSD数据集上，模型保持了竞争力，显著优于基于SAM的基准模型。

Conclusion: SRFT-GaLore增强的双编码器框架使在实时、深度受限的手术环境中进行精确分割成为可能，并展示了在其他手术环境中的鲁棒性和适应性。

Abstract: Accurate detection and delineation of anatomical structures in medical
imaging are critical for computer-assisted interventions, particularly in
laparoscopic liver surgery where 2D video streams limit depth perception and
complicate landmark localization. While recent works have leveraged monocular
depth cues for enhanced landmark detection, challenges remain in fusing RGB and
depth features and in efficiently adapting large-scale vision models to
surgical domains. We propose a depth-guided liver landmark segmentation
framework integrating semantic and geometric cues via vision foundation
encoders. We employ Segment Anything Model V2 (SAM2) encoder to extract RGB
features and Depth Anything V2 (DA2) encoder to extract depth-aware features.
To efficiently adapt SAM2, we introduce SRFT-GaLore, a novel low-rank gradient
projection method that replaces the computationally expensive SVD with a
Subsampled Randomized Fourier Transform (SRFT). This enables efficient
fine-tuning of high-dimensional attention layers without sacrificing
representational power. A cross-attention fusion module further integrates RGB
and depth cues. To assess cross-dataset generalization, we also construct a new
Laparoscopic Liver Surgical Dataset (LLSD) as an external validation benchmark.
On the public L3D dataset, our method achieves a 4.85% improvement in Dice
Similarity Coefficient and a 11.78-point reduction in Average Symmetric Surface
Distance compared to the D2GPLand. To further assess generalization capability,
we evaluate our model on LLSD dataset. Our model maintains competitive
performance and significantly outperforms SAM-based baselines, demonstrating
strong cross-dataset robustness and adaptability to unseen surgical
environments. These results demonstrate that our SRFT-GaLore-enhanced
dual-encoder framework enables scalable and precise segmentation under
real-time, depth-constrained surgical settings.

</details>


### [17] [SurgAnt-ViVQA: Learning to Anticipate Surgical Events through GRU-Driven Temporal Cross-Attention](https://arxiv.org/abs/2511.03178)
*Shreyas C. Dhake,Jiayuan Huang,Runlong He,Danyal Z. Khan,Evangelos B. Mazomenos,Sophia Bano,Hani J. Marcus,Danail Stoyanov,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 介绍了一种新的VQA数据集PitVQA-Anticipation和视频语言模型SurgAnt-ViVQA，用于前瞻性的外科手术推理。SurgAnt-ViVQA在PitVQA-Anticipation和EndoVis数据集上进行了测试，并超出了现有的对比基线。该模型利用了时间循环和门控融合机制，以实现更准确的未来预测。数据集和模型共同提高了手术VQA的前瞻性能，有助于实时手术辅助。


<details>
  <summary>Details</summary>
Motivation: 现有的VQA系统主要针对当前场景，但缺乏对未来步骤或器械需要的预测能力。因此，本文提出了一种新的面向未来的VQA数据集PitVQA-Anticipation，以及一个专注于未来事件预测的视频语言模型SurgAnt-ViVQA，以改善有限视野下手术过程中的实时协助。

Method: 模型为SurgAnt-ViVQA，采用GRU门控时序交叉注意模块，双向GRU编码帧到帧的动力学，同时门控机制在标记级别注入视觉上下文到语言流中，参数效率的微调使语言骨干适应外科领域。测试结果显示，模型在两项数据集上的性能超过基准。实验还展示了时序循环和门控融合机制对性能提升的主要贡献。

Result: SurgAnt-ViVQA在校验数据集上超过了基线模型，展示了在8帧预算下获得最佳的流畅性和在32帧预算下改善时间估算的能力。模型改进了手术场景中VQA任务的前瞻性能。

Conclusion: PitVQA-Anticipation数据集和SurgAnt-ViVQA模型提供了面向前瞻的手术VQA性能的全面基准，并强调了有针对性的时间建模在获取可靠的、面向未来的手术协助中的重要性。

Abstract: Anticipating forthcoming surgical events is vital for real-time assistance in
endonasal transsphenoidal pituitary surgery, where visibility is limited and
workflow changes rapidly. Most visual question answering (VQA) systems reason
on isolated frames with static vision language alignment, providing little
support for forecasting next steps or instrument needs. Existing surgical VQA
datasets likewise center on the current scene rather than the near future. We
introduce PitVQA-Anticipation, the first VQA dataset designed for forward
looking surgical reasoning. It comprises 33.5 hours of operative video and
734,769 question answer pairs built from temporally grouped clips and expert
annotations across four tasks: predicting the future phase, next step, upcoming
instrument, and remaining duration. We further propose SurgAnt-ViVQA, a video
language model that adapts a large language model using a GRU Gated Temporal
Cross-Attention module. A bidirectional GRU encodes frame to frame dynamics,
while an adaptive gate injects visual context into the language stream at the
token level. Parameter efficient fine tuning customizes the language backbone
to the surgical domain. SurgAnt-ViVQA tested upon on PitVQA-Anticipation and
EndoVis datasets, surpassing strong image and video based baselines. Ablations
show that temporal recurrence and gated fusion drive most of the gains. A frame
budget study indicates a trade-off: 8 frames maximize fluency, whereas 32
frames slightly reduce BLEU but improve numeric time estimation. By pairing a
temporally aware encoder with fine grained gated cross-attention, SurgAnt-ViVQA
advances surgical VQA from retrospective description to proactive anticipation.
PitVQA-Anticipation offers a comprehensive benchmark for this setting and
highlights the importance of targeted temporal modeling for reliable, future
aware surgical assistance.

</details>


### [18] [PETWB-REP: A Multi-Cancer Whole-Body FDG PET/CT and Radiology Report Dataset for Medical Imaging Research](https://arxiv.org/abs/2511.03194)
*Le Xue,Gang Feng,Wenbo Zhang,Yichi Zhang,Lanlan Li,Shuqi Wang,Liling Peng,Sisi Peng,Xin Gao*

Main category: cs.CV

TL;DR: PETWB-REP是一个包含490名不同癌症类型患者的18F-氟脱氧葡萄糖正电子发射断层扫描/计算机断层扫描(PET/CT)以及相应放射科报告的数据集。数据集旨在支持医学图像、放射组学、人工智能和多模态学习的研究。


<details>
  <summary>Details</summary>
Motivation: 目前公开的大规模医学成像数据集较为缺乏，特别是那些结合功能成像、结构成像以及详细临床报告的数据集更为稀缺。为此，研究人员创建了PETWB-REP数据集来弥补这一不足，推动人工智能模型的开发验证以及回顾性临床研究。

Method: 数据集收集了490名患者的数据，包括PET和CT图像、去标识化文本报告和结构化临床元数据。涵盖的癌症类型包括肺癌、肝癌、乳腺癌、前列腺癌和卵巢癌等常见癌症。

Result: PETWB-REP数据集提供了大量的医学成像数据，能够支持医学图像、放射组学、人工智能和多模态学习的研究与应用。

Conclusion: PETWB-REP数据集的创建，填补了公开可用的大型医学成像数据集的一个重要空白，为各类研究提供了宝贵的资源。

Abstract: Publicly available, large-scale medical imaging datasets are crucial for
developing and validating artificial intelligence models and conducting
retrospective clinical research. However, datasets that combine functional and
anatomical imaging with detailed clinical reports across multiple cancer types
remain scarce. Here, we present PETWB-REP, a curated dataset comprising
whole-body 18F-Fluorodeoxyglucose (FDG) Positron Emission Tomography/Computed
Tomography (PET/CT) scans and corresponding radiology reports from 490 patients
diagnosed with various malignancies. The dataset primarily includes common
cancers such as lung cancer, liver cancer, breast cancer, prostate cancer, and
ovarian cancer. This dataset includes paired PET and CT images, de-identified
textual reports, and structured clinical metadata. It is designed to support
research in medical imaging, radiomics, artificial intelligence, and
multi-modal learning.

</details>


### [19] [QG-CoC: Question-Guided Chain-of-Captions for Large Multimodal Models](https://arxiv.org/abs/2511.03206)
*Kuei-Chun Kao,Hsu Tzu-Yin,Yunqi Hong,Ruochen Wang,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: 提出了一个新的零样本提示方法Question-Guided Chain-of-Captions (QG-CoC)，来解决当前多模态大语言模型在多图像场景下遇到的问题。实验表明，QG-CoC在多图像和单图像基准测试中表现出色，特别是在现有提示方法失效的挑战性场景中表现出更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型在处理多图像情境时存在两个关键问题：细粒度感知不足以及对多个视觉输入的有效推理能力低下。虽然许多研究集中在单图像或特定约束场景上，但对于更为广泛且复杂的多图像推理任务的理解和解决问题尚未得到充分研究。因此，论文旨在填补这一空白。

Method: 提出的QG-CoC方法是一种零样本提示方法，用于处理任意数量图像的问题。该方法通过问题指引的连贯图像描述方式，来解决多图像感知和推理的难题。通过在公开和闭源的多模态语言模型上进行评估，展示了该方法的有效性和鲁棒性。

Result: 实验结果表明，提出的QG-CoC方法在多种模型和基准测试中表现出较强的性能，特别是在现有提示方法表现不佳的多图像复杂任务上取得了显著提升。

Conclusion: 论文通过提出QG-CoC，展示了如何有效解决当前多模态大语言模型在处理多图像时遇到的问题，并展示了该方法在各种挑战性场景中的优越性能。

Abstract: Recently, Multimodal Large Language Models (MLLMs) encounter two key issues
in multi-image contexts: (1) a lack of fine-grained perception across disparate
images, and (2) a diminished capability to effectively reason over and
synthesize information from multiple visual inputs. However, while various
prompting methods aim to describe visual content, many existing studies focus
primarily on single-image settings or specific, constrained scenarios. This
leaves a critical gap in understanding and addressing how MLLMs tackle more
general and complex multi-image reasoning tasks. Thus, we first extensively
investigate how current prompting methods perceive fine-grained visual details
and process visual information when dealing with multiple images. Our findings
reveal that existing prompting methods fall short in attending to needed clues
and seamlessly integrating perception and reasoning. Inspired by the findings,
we propose a new zero-shot prompting method, Question-Guided Chain-of-Captions
(QG-CoC), a generalized prompting approach that effectively handles problems
with an arbitrary number of images. We evaluate our method on various
open-source and closed-source MLLMs for multi-image and single-image
benchmarks. Experimental results indicate that QG-CoC demonstrates competitive
performance across tasks and exhibits robust improvements in the challenging
scenarios where existing prompting methods fail.

</details>


### [20] [Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation](https://arxiv.org/abs/2511.03219)
*Pengyu Jie,Wanquan Liu,Rui He,Yihui Wen,Deyu Meng,Chenqiang Gao*

Main category: cs.CV

TL;DR: 研究提出了一种结合图像混合技术和生成合成的新范式——配对扩散指导，以增强密集预测的任务表现。通过创建图像的现实和合成配对，并进行限制性的图像外观混合，保证监督一直使用原始硬掩模，这种方法能避免合成-真实域偏移，同时扩大数据多样性并保持像素级别的语义一致性。通过自适应调整混合强度和损失权重，该方法还实现在训练过程中逐渐锚定到真实数据，以减轻分布偏差。实验结果显示该方法在多个数据集上的分割性能表现优越，优于基准方法。



<details>
  <summary>Details</summary>
Motivation: 现有的图像增强方法主要通过样本混合或生成合成来提高任务性能。但是，混合方法出现了软标签模糊，而生成合成方法则存在忽略了掩模条件的结构效益以及合成-真实数据间的偏移问题。为了解决这些问题，本研究提出了一种结合图像混合技术和生成合成的新范式。


Method: 本研究提出了一种新的范式——配对扩散指导，通过将每个真实图像和在其掩模条件下生成的合成图像配对，并进行限制性的图像外观混合来避免数据偏移，同时保持像素级别的语义一致性。此外，通过自适应调整混合强度和损失权重，该方法实现了在训练过程中逐渐锚定到真实数据，减小分布偏差。


Result: 实验表明，该方法通过结合标签保留混合，扩散驱动的多样性，和自适应锚点重新定位，实现了广泛有效的内窥镜分割。


Conclusion: 整体来看，该方法提出的配对扩散指导框架解决了现有方法在区分真实和合成样本时可能遇到的问题，实现在保持高精度的同时显著提升泛化能力。

Abstract: Augmentation for dense prediction typically relies on either sample mixing or
generative synthesis. Mixing improves robustness but misaligned masks yield
soft label ambiguity. Diffusion synthesis increases apparent diversity but,
when trained as common samples, overlooks the structural benefit of mask
conditioning and introduces synthetic-real domain shift. We propose a paired,
diffusion-guided paradigm that fuses the strengths of both. For each real
image, a synthetic counterpart is generated under the same mask and the pair is
used as a controllable input for Mask-Consistent Paired Mixing (MCPMix), which
mixes only image appearance while supervision always uses the original hard
mask. This produces a continuous family of intermediate samples that smoothly
bridges synthetic and real appearances under shared geometry, enlarging
diversity without compromising pixel-level semantics. To keep learning aligned
with real data, Real-Anchored Learnable Annealing (RLA) adaptively adjusts the
mixing strength and the loss weight of mixed samples over training, gradually
re-anchoring optimization to real data and mitigating distributional bias.
Across Kvasir-SEG, PICCOLO, CVC-ClinicDB, a private NPC-LES cohort, and ISIC
2017, the approach achieves state-of-the-art segmentation performance and
consistent gains over baselines. The results show that combining
label-preserving mixing with diffusion-driven diversity, together with adaptive
re-anchoring, yields robust and generalizable endoscopic segmentation.

</details>


### [21] [Transformer-Progressive Mamba Network for Lightweight Image Super-Resolution](https://arxiv.org/abs/2511.03232)
*Sichen Guo,Wenjie Li,Yuanyang Liu,Guangwei Gao,Jian Yang,Chia-Wen Lin*

Main category: cs.CV

TL;DR: T-PMambaSR 提出了一种轻量级的超分辨率框架，结合了基于窗口的自注意力和渐进式Mamba，通过建立细粒度的建模范式，逐步增强特征表示。此外，还引入了自适应高频细化模块(AHFRM)，以恢复在变换器和Mamba处理过程中丢失的高频细节。实验表明，T-PMambaSR 在计算成本较低的情况下，性能优于最近的变换器或基于Mamba的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Mamba的方法在特征表示的效率上存在不足。为了改进这一点，提出了一种新的轻量级的超分辨率框架，提高特征表示的效率，同时降低计算成本。

Method: T-PMambaSR 结合了基于窗口的自注意力机制与渐进式的Mamba，实现了细粒度的建模，并引入了自适应高频细化模块（AHFRM），用于恢复在变换器和Mamba处理过程中的高频细节丢失。

Result: T-PMambaSR 在增强模型感受野和表达能力的同时，能够在计算成本较低的情况下，相比最近的变换器和基于Mamba的方法，取得了更好的性能提升。

Conclusion: 该研究提出的方法，在提升了超分辨率能力的同时，显著降低了计算复杂度，是一种有效且高效的解决方案。

Abstract: Recently, Mamba-based super-resolution (SR) methods have demonstrated the
ability to capture global receptive fields with linear complexity, addressing
the quadratic computational cost of Transformer-based SR approaches. However,
existing Mamba-based methods lack fine-grained transitions across different
modeling scales, which limits the efficiency of feature representation. In this
paper, we propose T-PMambaSR, a lightweight SR framework that integrates
window-based self-attention with Progressive Mamba. By enabling interactions
among receptive fields of different scales, our method establishes a
fine-grained modeling paradigm that progressively enhances feature
representation with linear complexity. Furthermore, we introduce an Adaptive
High-Frequency Refinement Module (AHFRM) to recover high-frequency details lost
during Transformer and Mamba processing. Extensive experiments demonstrate that
T-PMambaSR progressively enhances the model's receptive field and
expressiveness, yielding better performance than recent Transformer- or
Mamba-based methods while incurring lower computational cost. Our codes will be
released after acceptance.

</details>


### [22] [Decoupled Multi-Predictor Optimization for Inference-Efficient Model Tuning](https://arxiv.org/abs/2511.03245)
*Liwei Luo,Shuaitengyuan Li,Dongwei Ren,Qilong Wang,Pengfei Zhu,Qinghua Hu*

Main category: cs.CV

TL;DR: 本文提出了一种解耦多预测器优化方法，以解决早期阶段提供低级特征和高级判别特征的挑战，可以更有效地进行模型推理。该方法通过架构设计和模型优化有效地将早期阶段的表征能力和判别能力解耦，实验表明在减少计算成本的同时优于其他方法。 


<details>
  <summary>Details</summary>
Motivation: 实现一个具有高效推理能力的模型是一个未解决的关键挑战；尤其是在早期阶段提供低级基础特征的同时供给高级判别特征。为了解决这个问题，我们提出了一个有效的解决方案。

Method: 本文引入了轻量级旁路模块，以将浅层特征从早期阶段进行功能性分解，同时开发了一个基于高阶统计的预测器，以有效增强其判别功能。此外，该研究还提出了一个解耦优化策略，以便合理训练多预测器架构。 

Result: 实验结果表明DMPO相较于其他方法可以有效地减少计算成本。

Conclusion: DMPO方法可以有效地将早期阶段的表征能力和判别能力解耦，为实际部署提供了高效的推理模型。

Abstract: Recently, remarkable progress has been made in large-scale pre-trained model
tuning, and inference efficiency is becoming more crucial for practical
deployment. Early exiting in conjunction with multi-stage predictors, when
cooperated with a parameter-efficient fine-tuning strategy, offers a
straightforward way to achieve an inference-efficient model. However, a key
challenge remains unresolved: How can early stages provide low-level
fundamental features to deep stages while simultaneously supplying high-level
discriminative features to early-stage predictors? To address this problem, we
propose a Decoupled Multi-Predictor Optimization (DMPO) method to effectively
decouple the low-level representative ability and high-level discriminative
ability in early stages. First, in terms of architecture, we introduce a
lightweight bypass module into multi-stage predictors for functional
decomposition of shallow features from early stages, while a high-order
statistics-based predictor is developed for early stages to effectively enhance
their discriminative ability. To reasonably train our multi-predictor
architecture, a decoupled optimization is proposed to allocate two-phase loss
weights for multi-stage predictors during model tuning, where the initial
training phase enables the model to prioritize the acquisition of
discriminative ability of deep stages via emphasizing representative ability of
early stages, and the latter training phase drives discriminative ability
towards earlier stages as much as possible. As such, our DMPO can effectively
decouple representative and discriminative abilities in early stages in terms
of architecture design and model optimization. Experiments across various
datasets and pre-trained backbones demonstrate that DMPO clearly outperforms
its counterparts when reducing computational cost.

</details>


### [23] [Enhancing Medical Image Segmentation via Heat Conduction Equation](https://arxiv.org/abs/2511.03260)
*Rong Wu,Yim-Sang Yu*

Main category: cs.CV

TL;DR: 本文提出了一种结合Mamba状态空间模块和热传导操作符的新型混合架构，在计算预算内实现了高效的全局上下文建模和长距离依赖推理，提高了多模态腹部CT和MRI数据集的分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有的模型难以同时在实际计算预算下实现高效的全局上下文建模和长距离依赖推理。

Method: 提出了一种新型混合架构，结合了Mamba状态空间模块和热传导操作符，在瓶颈层中模拟频域热扩散，提高语义抽象。

Result: 实验结果表明，所提出的模型在多模态腹部CT和MRI数据集上表现优于基准模型，证明了其有效性和泛化能力。

Conclusion: 研究结果表明，将状态空间动力学与基于热的全局扩散相结合为医学分割任务提供了一种可伸缩且可解释的解决方案。

Abstract: Medical image segmentation has been significantly advanced by deep learning
architectures, notably U-Net variants. However, existing models struggle to
achieve efficient global context modeling and long-range dependency reasoning
under practical computational budgets simultaneously. In this work, we propose
a novel hybrid architecture utilizing U-Mamba with Heat Conduction Equation.
Our model combines Mamba-based state-space modules for efficient long-range
reasoning with Heat Conduction Operators (HCOs) in the bottleneck layers,
simulating frequency-domain thermal diffusion for enhanced semantic
abstraction. Experimental results on multimodal abdominal CT and MRI datasets
demonstrate that the proposed model consistently outperforms strong baselines,
validating its effectiveness and generalizability. It suggest that blending
state-space dynamics with heat-based global diffusion offers a scalable and
interpretable solution for medical segmentation tasks.

</details>


### [24] [IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection](https://arxiv.org/abs/2511.03267)
*Bingyang Guo,Hongjie Li,Ruiyun Yu,Hanzhe Liang,Jinbao Wang*

Main category: cs.CV

TL;DR: 本文开发了一个针对实际工业场景的3D点云异常检测数据集（IEC3D-AD），并提出了一种新的3D-AD范式（GMANet）来生成合成点云样本，提高异常检测任务的执行效果。该方法在IEC3D-AD以及其他数据集上测试有效。


<details>
  <summary>Details</summary>
Motivation: 传统3D-AD数据集（如Real3D-AD和MVTec 3D-AD）无法完全捕捉到真实工业环境中的复杂性和细微缺陷，从而限制了对工业设备组件（IEC）如轴承、环和螺栓的精准异常检测研究。因此，需要一个更具代表性的数据集和改进的方法来解决这个问题。

Method: 本文提出了一个新的3D-AD模型（GMANet）。该模型首先利用几何形态学分析生成合成的点云样本，然后通过空间不一致优化减少正常点和异常点之间的差距，增强重叠。模型是在工业环境下直接收集的点云数据集上训练得到的。

Result: 通过在工业环境下开发的新数据集（IEC3D-AD）上进行实验，证明了模型的有效性。并与现有的数据集进行了对比，展示出更高的准确性。同样在其他数据集上也取得了满意的性能。

Conclusion: 本文通过开发新的数据集（IEC3D-AD）和新的3D-AD模型（GMANet）来克服传统数据集的限制，提高了工业环境下的异常检测性能。

Abstract: 3D anomaly detection (3D-AD) plays a critical role in industrial
manufacturing, particularly in ensuring the reliability and safety of core
equipment components. Although existing 3D datasets like Real3D-AD and MVTec
3D-AD offer broad application support, they fall short in capturing the
complexities and subtle defects found in real industrial environments. This
limitation hampers precise anomaly detection research, especially for
industrial equipment components (IEC) such as bearings, rings, and bolts. To
address this challenge, we have developed a point cloud anomaly detection
dataset (IEC3D-AD) specific to real industrial scenarios. This dataset is
directly collected from actual production lines, ensuring high fidelity and
relevance. Compared to existing datasets, IEC3D-AD features significantly
improved point cloud resolution and defect annotation granularity, facilitating
more demanding anomaly detection tasks. Furthermore, inspired by generative
2D-AD methods, we introduce a novel 3D-AD paradigm (GMANet) on IEC3D-AD. This
paradigm generates synthetic point cloud samples based on geometric
morphological analysis, then reduces the margin and increases the overlap
between normal and abnormal point-level features through spatial discrepancy
optimization. Extensive experiments demonstrate the effectiveness of our method
on both IEC3D-AD and other datasets.

</details>


### [25] [Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising](https://arxiv.org/abs/2511.03272)
*Shuangquan Lyu,Steven Mao,Yue Ma*

Main category: cs.CV

TL;DR: 提出了一个新方法，用于长视频的可控视频修补和延长，通过改进文本到视频的扩散模型，能够生成高保真度的长视频片段。并通过实验证明其在质量和感知真实性方面优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视频修补和延长技术在处理长视频时难以保证高质量，而新方法采用LoRA调优技术和时序去噪策略，以实现长视频的高保真度修补和延长任务。解决现有技术难以实现长视频序列一致性和可控制性的挑战。

Method: 使用LoRA技术对已有大型预训练视频扩散模型（如Alibaba的Wan 2.1模型）进行高效微调，用于生成带有遮罩区域的视频；采用时间上重叠融合技术，使用高阶解算器防止长序列视频中的漂移现象，确保生成的视频在长序列中的一致性和真实感。

Result: 通过处理数百帧的修补和延长任务，实验证明新方法在PSNR/SSIM质量指标和LPIPS感知真实性上均优于基准Wan 2.1模型和VACE。实现了在参数高效性和性能优越性上的平衡。

Conclusion: 新方法提供了一种有效的长视频编辑方式，解决了长视频修补和延长的挑战，这将对视频编辑和生成领域的发展产生积极影响。

Abstract: Generating long videos remains a fundamental challenge, and achieving high
controllability in video inpainting and outpainting is particularly demanding.
To address both of these challenges simultaneously and achieve controllable
video inpainting and outpainting for long video clips, we introduce a novel and
unified approach for long video inpainting and outpainting that extends
text-to-video diffusion models to generate arbitrarily long, spatially edited
videos with high fidelity. Our method leverages LoRA to efficiently fine-tune a
large pre-trained video diffusion model like Alibaba's Wan 2.1 for masked
region video synthesis, and employs an overlap-and-blend temporal co-denoising
strategy with high-order solvers to maintain consistency across long sequences.
In contrast to prior work that struggles with fixed-length clips or exhibits
stitching artifacts, our system enables arbitrarily long video generation and
editing without noticeable seams or drift. We validate our approach on
challenging inpainting/outpainting tasks including editing or adding objects
over hundreds of frames and demonstrate superior performance to baseline
methods like Wan 2.1 model and VACE in terms of quality (PSNR/SSIM), and
perceptual realism (LPIPS). Our method enables practical long-range video
editing with minimal overhead, achieved a balance between parameter efficient
and superior performance.

</details>


### [26] [Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models](https://arxiv.org/abs/2511.03317)
*Minghao Fu,Guo-Hua Wang,Tianyu Cui,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一个名为Diffusion-SDPO的新方法，用于解决扩散模型在生成符合人类偏好图像时的质量下降问题，通过自适应调整输家分支的梯度，以确保赢家分支输出质量不会下降。该方法简单且与现有模型兼容，并且在标准文本到图像基准测试中表现出了优于其他方法的效果。代码可以公开访问。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的直接偏好优化方法在优化过程中可能会导致生成图像质量的下降，尤其是偏好边际的扩大会导致图像的重建误差增加，影响生成质量。作者希望解决这个问题，使得生成图像既能反映用户的偏好，又能保持高质量。

Method: 提出了名为Diffusion-SDPO的方法，该方法在优化过程中引入了一个保护机制，通过自适应调整输家分支的梯度大小，以保证赢家分支的输出不会减少。此外，还通过一阶分析得到了一个封闭形式的缩放系数，以确保优选输出的误差不会增加。

Result: 实验结果显示，使用Diffusion-SDPO方法可以显著提高在自动化偏好、美学和提示对齐指标上的表现，并且在标准的文本到图像生成基准测试中优于其他基准方法。同时，这种方法具有较低的计算开销，适用于多种不同的模型。

Conclusion: 本文提出了一种名为Diffusion-SDPO的新方法，该方法通过自适应调整输家输出的梯度来解决偏好优化中的质量下降问题，不仅保持了赢家输出的质量，还可以提高模型的性能。

Abstract: Text-to-image diffusion models deliver high-quality images, yet aligning them
with human preferences remains challenging. We revisit diffusion-based Direct
Preference Optimization (DPO) for these models and identify a critical
pathology: enlarging the preference margin does not necessarily improve
generation quality. In particular, the standard Diffusion-DPO objective can
increase the reconstruction error of both winner and loser branches.
Consequently, degradation of the less-preferred outputs can become sufficiently
severe that the preferred branch is also adversely affected even as the margin
grows. To address this, we introduce Diffusion-SDPO, a safeguarded update rule
that preserves the winner by adaptively scaling the loser gradient according to
its alignment with the winner gradient. A first-order analysis yields a
closed-form scaling coefficient that guarantees the error of the preferred
output is non-increasing at each optimization step. Our method is simple,
model-agnostic, broadly compatible with existing DPO-style alignment frameworks
and adds only marginal computational overhead. Across standard text-to-image
benchmarks, Diffusion-SDPO delivers consistent gains over preference-learning
baselines on automated preference, aesthetic, and prompt alignment metrics.
Code is publicly available at https://github.com/AIDC-AI/Diffusion-SDPO.

</details>


### [27] [SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding](https://arxiv.org/abs/2511.03325)
*Mauro Orazio Drago,Luca Carlini,Pelinsu Celebi Balyemez,Dennis Pierantozzi,Chiara Lena,Cesare Hassan,Danail Stoyanov,Elena De Momi,Sophia Bano,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 提出了一种名为SurgViVQA的手术视频问答系统，用于增强手术过程中的理解，该系统能够通过融合视频和文本特征来捕捉动态场景中的关键信息，并对模型进行了多项评估，显示其超越了现有的基于图像的视频问答模型。


<details>
  <summary>Details</summary>
Motivation: 当前的视频问答系统主要依赖于静态图像特征，缺乏对动态过程的理解，特别是在手术过程中，实时捕捉手术动作和工具-组织交互是至关重要的。SurgViVQA旨在通过扩展静态图像的视觉推理到动态手术场景，来解决这个问题。

Method: SurgViVQA使用了一个Masked Video--Text Encoder来融合视频和问题特征，之后由一个经过微调的大型语言模型解码为连贯的答案。为了评估性能，研究者还编译了一个名为REAL-Colon-VQA的结肠镜检查视频数据集。该数据集包括与运动相关的问题和诊断属性，以及格式化问题以评估模型的鲁棒性。

Result: 实验验证显示SurgViVQA在常见的VQA基准模型上表现出色，尤其是在关键字准确性方面，SurgViVQA比PitVQA在REAL-Colon-VQA上提高了11%，在EndoVis18-VQA上提高了9%。此外，对问题的扰动实验还进一步证实了其泛化能力和对问题措辞变化的稳健性。

Conclusion: SurgViVQA与REAL-Colon-VQA数据集为手术视频问答系统中的时间意识理解提供了一个框架，使得AI模型可以更有效地解释动态程序背景。

Abstract: Video Question Answering (VideoQA) in the surgical domain aims to enhance
intraoperative understanding by enabling AI models to reason over temporally
coherent events rather than isolated frames. Current approaches are limited to
static image features, and available datasets often lack temporal annotations,
ignoring the dynamics critical for accurate procedural interpretation. We
propose SurgViVQA, a surgical VideoQA model that extends visual reasoning from
static images to dynamic surgical scenes. It uses a Masked Video--Text Encoder
to fuse video and question features, capturing temporal cues such as motion and
tool--tissue interactions, which a fine-tuned large language model (LLM) then
decodes into coherent answers. To evaluate its performance, we curated
REAL-Colon-VQA, a colonoscopic video dataset that includes motion-related
questions and diagnostic attributes, as well as out-of-template questions with
rephrased or semantically altered formulations to assess model robustness.
Experimental validation on REAL-Colon-VQA and the public EndoVis18-VQA dataset
shows that SurgViVQA outperforms existing image-based VQA benchmark models,
particularly in keyword accuracy, improving over PitVQA by +11\% on
REAL-Colon-VQA and +9\% on EndoVis18-VQA. A perturbation study on the questions
further confirms improved generalizability and robustness to variations in
question phrasing. SurgViVQA and the REAL-Colon-VQA dataset provide a framework
for temporally-aware understanding in surgical VideoQA, enabling AI models to
interpret dynamic procedural contexts more effectively. Code and dataset
available at https://github.com/madratak/SurgViVQA.

</details>


### [28] [Multi-Object Tracking Retrieval with LLaVA-Video: A Training-Free Solution to MOT25-StAG Challenge](https://arxiv.org/abs/2511.03332)
*Yi Yang,Yiming Xu,Timo Kaiser,Hao Cheng,Bodo Rosenhahn,Michael Ying Yang*

Main category: cs.CV

TL;DR: 报告提出了一个针对MOT25-StAG挑战的任务建模和两种模型结合的解决方案，取得了第二名的成绩。


<details>
  <summary>Details</summary>
Motivation: 准确地定位和跟踪符合特定自由形式语言查询的多个对象，使用复杂现实世界的视频数据作为输入，解决MOT25-StAG挑战的任务

Method: 将任务建模为视频检索问题，采用两阶段零样本方法，结合最新的追踪模型FastTracker和多模态大型语言模型LLaVA-Video的优势

Result: 在MOT25-StAG测试集上，该方法实现了m-HIoU为20.68和HOTA为10.73的得分

Conclusion: 该方法在MOT25-StAG挑战中取得了第二名的成绩

Abstract: In this report, we present our solution to the MOT25-Spatiotemporal Action
Grounding (MOT25-StAG) Challenge. The aim of this challenge is to accurately
localize and track multiple objects that match specific and free-form language
queries, using video data of complex real-world scenes as input. We model the
underlying task as a video retrieval problem and present a two-stage, zero-shot
approach, combining the advantages of the SOTA tracking model FastTracker and
Multi-modal Large Language Model LLaVA-Video. On the MOT25-StAG test set, our
method achieves m-HIoU and HOTA scores of 20.68 and 10.73 respectively, which
won second place in the challenge.

</details>


### [29] [UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions](https://arxiv.org/abs/2511.03334)
*Guozhen Zhang,Zixiang Zhou,Teng Hu,Ziqiao Peng,Youliang Zhang,Yi Chen,Yuan Zhou,Qinglin Lu,Limin Wang*

Main category: cs.CV

TL;DR: 我们提出了一种名为UniAVGen的框架，用于联合音频和视频生成，它通过引入一种不对称的跨模态交互机制和模态感知的分类器自由引导策略，实现了更精确的时空同步和语义一致性。该框架同时支持联合音频视频生成、视频到音频配音和音频驱动的视频合成等任务，具有强大的泛化能力。实验表明，即使使用较少的训练样本，UniAVGen在音频视频同步、音色一致性和情绪一致性方面都能表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的音频-视频生成方法因跨模态建模不足而导致口型同步问题和语义一致性不足。为此，我们设计了一个新的框架来解决这些问题。

Method: UniAVGen采用双分支联合合成架构，引入了不对称跨模态交互机制和模态感知的分类器自由引导策略，以增强音频和视频的时空同步和语义一致性。同时，此框架支持多种音频-视频任务，具有很好的泛化能力和灵活性。

Result: 实验结果表明，尽管训练样本的数量仅为现有方法的4%，UniAVGen在音频视频同步、音色一致性和情绪一致性等方面优于现有的方法。

Conclusion: UniAVGen提供了一种有效的方法，能够在统一的框架下实现高质量的音频视频联合生成和其他相关任务。

Abstract: Due to the lack of effective cross-modal modeling, existing open-source
audio-video generation methods often exhibit compromised lip synchronization
and insufficient semantic consistency. To mitigate these drawbacks, we propose
UniAVGen, a unified framework for joint audio and video generation. UniAVGen is
anchored in a dual-branch joint synthesis architecture, incorporating two
parallel Diffusion Transformers (DiTs) to build a cohesive cross-modal latent
space. At its heart lies an Asymmetric Cross-Modal Interaction mechanism, which
enables bidirectional, temporally aligned cross-attention, thus ensuring
precise spatiotemporal synchronization and semantic consistency. Furthermore,
this cross-modal interaction is augmented by a Face-Aware Modulation module,
which dynamically prioritizes salient regions in the interaction process. To
enhance generative fidelity during inference, we additionally introduce
Modality-Aware Classifier-Free Guidance, a novel strategy that explicitly
amplifies cross-modal correlation signals. Notably, UniAVGen's robust joint
synthesis design enables seamless unification of pivotal audio-video tasks
within a single model, such as joint audio-video generation and continuation,
video-to-audio dubbing, and audio-driven video synthesis. Comprehensive
experiments validate that, with far fewer training samples (1.3M vs. 30.1M),
UniAVGen delivers overall advantages in audio-video synchronization, timbre
consistency, and emotion consistency.

</details>


### [30] [Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2511.03367)
*Gahyeon Kim,Sohee Kim,Seokju Lee*

Main category: cs.CV

TL;DR: AAPL提出了一种新的方法，通过引入对抗性令牌嵌入来使微调的提示集中于视觉上区分性强的特征，从而提高提示学习的效果。在多场景实验中，AAPL的表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的提示学习方法难以在完全未见过的类别中泛化。本文探索了基于图像的增强策略对提示学习的支持以及它们与软提示框架的交互，旨在提高模型的跨类别泛化能力。

Method: AAPL通过添加对抗性令牌嵌入来解耦增强引入的表面视觉差异与类别相关的语义表示，使模型集中在具有区分性的视觉特征上，从而实现更好的零样本学习效果。

Result: 在11个基准数据集上的综合实验表明，AAPL在少样本、零样本、跨数据集和领域泛化等场景中优于现有的方法。

Conclusion: AAPL不仅改进了提示学习框架，还揭示了基于图像的增强对提示学习的重要作用。这一方法为未来的研究提供了新的方向和可能的改进点。

Abstract: Recent advances in large-scale vision and language models have led to
significant progress in zero-shot learning tasks. Methods such as CoOp and
CoCoOp have shown that replacing handcrafted prompts with learnable vectors,
known as prompt learning, can result in improved performance. However, these
models often struggle to generalize to entirely unseen categories. While
traditional zero-shot learning techniques benefit from various data
augmentation strategies, prompt learning has primarily focused on text-based
modifications, leaving the potential of image-based augmentation largely
unexplored. In this work, we explore how image-level augmentations,
particularly those that introduce attribute-specific variations, can support
and enhance prompt learning. Our analysis examines the interaction between
these augmentations and soft prompt frameworks, revealing their potential to
improve generalization. We also identify a limitation in existing methods, such
as CoCoOp, which do not provide explicit guidance for learning prompts that
focus on semantically meaningful visual features. To address this, we propose
Adding Attributes to Prompt Learning, AAPL, a novel method that introduces
adversarial token embeddings to decouple superficial visual variations
introduced by augmentation from class-relevant semantic representations. This
decoupling enables the learned prompts to concentrate on visually
discriminative features that align with the target categories. We conduct
comprehensive experiments on eleven benchmark datasets, and AAPL consistently
outperforms existing methods across few-shot, zero-shot, cross-dataset, and
domain generalization settings. Our source code is publicly available at:
https://github.com/Gahyeonkim09/AAPL

</details>


### [31] [Generalizing Shape-from-Template to Topological Changes](https://arxiv.org/abs/2511.03459)
*Kevin Manogue,Tomasz M Schang,Dilara Kuş,Jonas Müller,Stefan Zachow,Agniva Sengupta*

Main category: cs.CV

TL;DR: 提出了一个扩展的形状从模板重建方法，该方法能够在存在拓扑变化的情况下进行表面重建，特别是对于撕裂和切割等变化。通过在模板的空间域上划分来最小化能量函数，实现物理合理性和重投影一致性的联合编码。该方法在合成和真实数据上都表现出了比基线方法更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的形状从模板（SfT）方法在处理随变形伴随发生的拓扑变化时效果不佳。为了解决这一问题，本研究提出了一个扩展的SfT方法，使其能够在存在拓扑变化的情况下进行表面重建。

Method: 方法首先以经典SfT解决方案初始化，然后迭代地通过最小化一个能量函数来适应模板，该函数联合编码了物理合理性和重投影一致性。通过划分模板的空间域来适应这些变化，这种方法能够处理撕裂和切割等不同类型的变化。

Result: 实验表明，本研究提出的方法在合成和真实数据上都表现出了比基线方法更好的性能，能够更准确地捕获撕裂、切割等重要拓扑事件。

Conclusion: 本研究为存在拓扑变化的形状从模板重建问题提供了第一个通用框架，并展示了其在实际应用中的优越性。

Abstract: Reconstructing the surfaces of deformable objects from correspondences
between a 3D template and a 2D image is well studied under Shape-from-Template
(SfT) methods; however, existing approaches break down when topological changes
accompany the deformation. We propose a principled extension of SfT that
enables reconstruction in the presence of such changes. Our approach is
initialized with a classical SfT solution and iteratively adapts the template
by partitioning its spatial domain so as to minimize an energy functional that
jointly encodes physical plausibility and reprojection consistency. We
demonstrate that the method robustly captures a wide range of practically
relevant topological events including tears and cuts on bounded 2D surfaces,
thereby establishing the first general framework for topological-change-aware
SfT. Experiments on both synthetic and real data confirm that our approach
consistently outperforms baseline methods.

</details>


### [32] [Human Mesh Modeling for Anny Body](https://arxiv.org/abs/2511.03589)
*Romain Brégier,Guénolé Fiche,Laura Bravo-Sánchez,Thomas Lucas,Matthieu Armando,Philippe Weinzaepfel,Grégory Rogez,Fabien Baradel*

Main category: cs.CV

TL;DR: 介绍了一种名为Anny的简单、连续、可解释的人体模型，基于人类体征数据而非昂贵的3D扫描，支持各种人体形态的变化。


<details>
  <summary>Details</summary>
Motivation: 现有模型主要依赖于昂贵的3D扫描和有限的人群形状空间，且往往带有隐私属性限制。因此，开发一种简单、开放、可解释且具有广泛应用前景的人体模型十分必要。Anny旨在通过Anthropometric数据提供一个通用且精确的人体形态模型。

Method: Anny利用了Anthropometric数据和WHO人口统计数据来创建适应各种人体形态的模型，可以通过设定参数（如性别、年龄、身高、体重等）来控制人体形态的变化，且模型本身是连续、可解释的。此外，还生成了一个包含80万照片质量人体模型的数据集Anny-One，用以展示该模型的性能。

Result: Anny所生成的HMR模型与基于扫描的人体模型相比，在性能上没有明显差异，同时保持了良好的可解释性和广泛代表性。更具创新意义的是，这种模型是开源的，可直接用于3D人体建模任务。

Conclusion: Anny提供了一个新颖且实用的解决方法，使得在没有昂贵3D扫描器的情况下也可创建出高质量的人体模型。其开源特性使得更多的研究和商业应用成为可能。

Abstract: Parametric body models are central to many human-centric tasks, yet existing
models often rely on costly 3D scans and learned shape spaces that are
proprietary and demographically narrow. We introduce Anny, a simple, fully
differentiable, and scan-free human body model grounded in anthropometric
knowledge from the MakeHuman community. Anny defines a continuous,
interpretable shape space, where phenotype parameters (e.g. gender, age,
height, weight) control blendshapes spanning a wide range of human forms --
across ages (from infants to elders), body types, and proportions. Calibrated
using WHO population statistics, it provides realistic and demographically
grounded human shape variation within a single unified model. Thanks to its
openness and semantic control, Anny serves as a versatile foundation for 3D
human modeling -- supporting millimeter-accurate scan fitting, controlled
synthetic data generation, and Human Mesh Recovery (HMR). We further introduce
Anny-One, a collection of 800k photorealistic humans generated with Anny,
showing that despite its simplicity, HMR models trained with Anny can match the
performance of those trained with scan-based body models, while remaining
interpretable and broadly representative. The Anny body model and its code are
released under the Apache 2.0 license, making Anny an accessible foundation for
human-centric 3D modeling.

</details>


### [33] [Part-Aware Bottom-Up Group Reasoning for Fine-Grained Social Interaction Detection](https://arxiv.org/abs/2511.03666)
*Dongkeun Kim,Minsu Cho,Suha Kwak*

Main category: cs.CV

TL;DR: 本文提出了一种基于身体部位的细粒度社交互动检测的框架，通过增强个体特征并通过相似性推理来推断社交群组，从而更准确识别社交信号。


<details>
  <summary>Details</summary>
Motivation: 现有社交互动检测方法主要依赖于整体表示，忽略了细微的人际交互线索，导致难于捕捉局部社交信号，影响了对社交群体的推理准确率。

Method: 该方法首先检测和增强个体特征，然后通过基于相似性的推理来推断群体配置，考虑到空间关系和细微的社交线索，以提高群组推理的准确性。

Result: 在NVI数据集上的实验表明，新方法超过了先前的方法，实现了最新的领域先进水平。

Conclusion: 提出的方法更为准确地捕捉到了社交互动的细微线索，提高了群体推理的准确率。

Abstract: Social interactions often emerge from subtle, fine-grained cues such as
facial expressions, gaze, and gestures. However, existing methods for social
interaction detection overlook such nuanced cues and primarily rely on holistic
representations of individuals. Moreover, they directly detect social groups
without explicitly modeling the underlying interactions between individuals.
These drawbacks limit their ability to capture localized social signals and
introduce ambiguity when group configurations should be inferred from social
interactions grounded in nuanced cues. In this work, we propose a part-aware
bottom-up group reasoning framework for fine-grained social interaction
detection. The proposed method infers social groups and their interactions
using body part features and their interpersonal relations. Our model first
detects individuals and enhances their features using part-aware cues, and then
infers group configuration by associating individuals via similarity-based
reasoning, which considers not only spatial relations but also subtle social
cues that signal interactions, leading to more accurate group inference.
Experiments on the NVI dataset demonstrate that our method outperforms prior
methods, achieving the new state of the art.

</details>


### [34] [Disentangled Concepts Speak Louder Than Words:Explainable Video Action Recognition](https://arxiv.org/abs/2511.03725)
*Jongseo Lee,Wooil Lee,Gyeong-Moon Park,Seong Tae Kim,Jinwoo Choi*

Main category: cs.CV

TL;DR: 本文提出了DANCE框架，用于视频动作识别，通过分解动作的概念类型（运动动力、物体和场景）来提升模型解释的清晰度，并且其在多个数据集上的实验验证了其解释性和性能的有效性。DANCE还对模型调试、编辑和失败分析有益。


<details>
  <summary>Details</summary>
Motivation: 当前基于显著性的解释方法会产生纠缠的解释，无法明确模型预测是依赖于运动还是空间上下文，而语言方法虽然提供了结构但是难以解释运动。因此，提出了DANCE框架来改善这些挑战。

Method: DANCE框架包括定义运动动力概念为人姿态序列，使用大型语言模型自动提取物体和场景的概念，并且通过事前概念瓶颈设计来强制这种预测方式。

Result: DANCE在多个数据集上显著提高了解释的清晰度，并且具有很强的解释性，有助于模型调试、编辑和失败分析。用户研究验证了DANCE的解释性优越。

Conclusion: DANCE框架通过分解动作识别中的概念类型，提供了一种清晰且有效的解释方式，可以用于多个应用场景。

Abstract: Effective explanations of video action recognition models should disentangle
how movements unfold over time from the surrounding spatial context. However,
existing methods based on saliency produce entangled explanations, making it
unclear whether predictions rely on motion or spatial context. Language-based
approaches offer structure but often fail to explain motions due to their tacit
nature -- intuitively understood but difficult to verbalize. To address these
challenges, we propose Disentangled Action aNd Context concept-based
Explainable (DANCE) video action recognition, a framework that predicts actions
through disentangled concept types: motion dynamics, objects, and scenes. We
define motion dynamics concepts as human pose sequences. We employ a large
language model to automatically extract object and scene concepts. Built on an
ante-hoc concept bottleneck design, DANCE enforces prediction through these
concepts. Experiments on four datasets -- KTH, Penn Action, HAA500, and UCF-101
-- demonstrate that DANCE significantly improves explanation clarity with
competitive performance. We validate the superior interpretability of DANCE
through a user study. Experimental results also show that DANCE is beneficial
for model debugging, editing, and failure analysis.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [35] [FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels](https://arxiv.org/abs/2511.02872)
*Jiedong Jiang,Wanyi He,Yuefeng Wang,Guoxiong Gao,Yongle Hu,Jingting Wang,Nailing Guan,Peihao Wu,Chunbo Dai,Liang Xiao,Bin Dong*

Main category: cs.LG

TL;DR: 本文介绍了FATE（正式代数定理评估）基准系列，这是在形式代数领域设计的新基准，以解决最新大型语言模型（LLMs）在正式定理证明方面与现代数学研究之间的差距。FATE由两个新组件组成，FATE-H和FATE-X，每个包含100个抽象代数和交换代数的问题。实验结果表明，LLMs在FATE-H和FATE-X上的表现与竞赛数学相比存在明显差距。研究还发现，模型的自然语言推理比将其形式化的能力更准确。


<details>
  <summary>Details</summary>
Motivation: 最近的大型语言模型在正式定理证明方面取得了显著进展，特别是在IMO等数学竞赛基准上的表现令人印象深刻。然而，这些竞赛并未反映出现代数学研究中的深度、广度和抽象性。为此，我们引入了FATE，它旨在填补这一空白，为正式代数设置新的基准，并推动向更高级的数学推理发展。

Method: 本文介绍了两个新的组件，FATE-H和FATE-X，每个包含100个抽象和交换代数的问题。FATE系列涵盖了从本科作业到超越博士资格考试的难度范围。研究还评估了最先进的模型在FATE-H和FATE-X上的表现，并与数学竞赛的表示进行了比较。此外，还进行了两阶段的评估以揭示关于模型的表现差距的具体细节。最后，还对比了专业证明器与通用模型的表现。

Result: 验证了LLMs在FATE-H和FATE-X上的表现相较于竞赛数学而言存在显著差距，最佳模型仅在FATE-H上达到3%的准确率，在FATE-X上则为0%。通过两阶段评估，揭示了模型在自然语言推理方面比形式化推理更准确。并系统地分类了在形式化过程中出现的常见错误。此外，与专用证明器相比，通用模型在自然语言推理阶段表现更优。

Conclusion: FATE提供了一个稳健且具有挑战性的基准，为通向研究级别的形式数学推理提供了重要的检查点。

Abstract: Recent advances in large language models (LLMs) have demonstrated impressive
capabilities in formal theorem proving, particularly on contest-based
mathematical benchmarks like the IMO. However, these contests do not reflect
the depth, breadth, and abstraction of modern mathematical research. To bridge
this gap, we introduce FATE (Formal Algebra Theorem Evaluation), a new
benchmark series in formal algebra designed to chart a course toward advanced
mathematical reasoning. We present two new components, FATE-H and FATE-X, each
with 100 problems in abstract and commutative algebra. The FATE series spans a
difficulty spectrum from undergraduate exercises to problems exceeding PhD
qualifying exams. Notably, FATE-X is the first formal benchmark to surpass both
PhD-level exam difficulty and the coverage of the Mathlib library. Our
evaluations of state-of-the-art LLM provers on this new benchmark reveal a
stark performance gap compared to contest math: the best model achieves only 3%
(pass@64) accuracy on FATE-H and 0% on FATE-X. Our two-stage evaluation reveals
that models' natural-language reasoning is notably more accurate than their
ability to formalize this reasoning. We systematically classify the common
errors that arise during this formalization process. Furthermore, a comparative
study shows that a specialized prover can exhibit less effective reflection
than general-purpose models, reducing its accuracy at the natural-language
stage. We believe FATE provides a robust and challenging benchmark that
establishes essential checkpoints on the path toward research-level formal
mathematical reasoning.

</details>


### [36] [Test-time Adaptation of Tiny Recursive Models](https://arxiv.org/abs/2511.02886)
*Ronan Killian McGovern*

Main category: cs.LG

TL;DR: 该论文提出了一种方法，通过在公开的ARC任务上预训练一个小递归模型，并在竞赛限定的计算资源内微调该模型，使得模型在竞赛任务上的表现达到了6.67%的得分，而无需使用额外的计算资源和大量的计算成本。


<details>
  <summary>Details</summary>
Motivation: 旨在探索如何在有限计算资源下优化模型性能，尤其是在涉及复杂任务迁移学习的场景中，以达到竞赛要求的安全和效率标准。

Method: 从公开任务中预训练一个小型递归模型后，通过在竞赛任务上进行微调，使得模型能够在控制的计算预算内获得最佳性能表现。具体来说，模型首先在1280个公开任务上进行预训练，然后在竞赛期间利用半私有任务进行进一步微调。

Result: 该方法在半私有评估任务上的微调使得模型达到了6.67%的得分，证明了这种方法的有效性。与之前需要大量计算资源的方法相比，这种方法更加高效且成本更低。

Conclusion: 论文展示了在有限计算资源下通过模型微调提高模型性能的可行性，这种方法能够在不牺牲性能的前提下，显著减少了计算成本。

Abstract: Prior to the close of the 2025 ARC Prize competition, the leading open source
approach - known as TRM, or Tiny Recursive Models - involved training a 7M
parameter recursive neural network on augmented variants of ARC tasks. That
approach scored approximately 7.8% on the public ARC AGI II evaluation set, but
required a level of compute far in excess of what is allowed during the
competition. This paper shows that, by starting from a tiny recursive model
that has been pre-trained on public ARC tasks, one can efficiently fine-tune on
competition tasks within the allowed compute limits. Specifically, a model was
pre-trained on 1,280 public tasks for 700k+ optimizer steps over 48 hours on
4xH100 SXM GPUs to obtain a ~10% score on the public evaluation set. That model
was then post-trained in just 12,500 gradient steps during the competition to
reach a score of 6.67% on semi-private evaluation tasks. Notably, such
post-training performance is achieved by full-fine tuning of the tiny model,
not LoRA fine-tuning or fine-tuning of task embeddings alone.

</details>


### [37] [Predicting Weekly Fishing Concentration Zones through Deep Learning Integration of Heterogeneous Environmental Spatial Datasets](https://arxiv.org/abs/2511.02887)
*Chaitanya Rele,Aditya Rathod,Kaustubh Natu,Saurabh Kulkarni,Ajay Koli,Swapnali Makdey*

Main category: cs.LG

TL;DR: 利用海洋学参数预测潜在渔区，提高准确性，支持可持续捕捞。


<details>
  <summary>Details</summary>
Motivation: 解决北印度洋沿海社区渔民寻找高产渔场的不确定性问题。

Method: 提出一个基于AI的框架，利用海表温度和叶绿素浓度等海洋学参数预测潜在渔区。

Result: 研究表明该框架能减少搜索时间，降低燃料消耗，促进资源有效利用。

Conclusion: 该方法可以支持渔民，提高渔区识别的准确性，提供区域特异性见解，促进可持续捕捞实践。

Abstract: The North Indian Ocean, including the Arabian Sea and the Bay of Bengal,
represents a vital source of livelihood for coastal communities, yet fishermen
often face uncertainty in locating productive fishing grounds. To address this
challenge, we present an AI-assisted framework for predicting Potential Fishing
Zones (PFZs) using oceanographic parameters such as sea surface temperature and
chlorophyll concentration. The approach is designed to enhance the accuracy of
PFZ identification and provide region-specific insights for sustainable fishing
practices. Preliminary results indicate that the framework can support
fishermen by reducing search time, lowering fuel consumption, and promoting
efficient resource utilization.

</details>


### [38] [An Efficient Classification Model for Cyber Text](https://arxiv.org/abs/2511.03107)
*Md Sakhawat Hossen,Md. Zashid Iqbal Borshon,A. S. M. Badrudduza*

Main category: cs.LG

TL;DR: 提出了一种改进的TF-IDF算法（CTF-IDF）和快速的IRLBA降维算法，用于传统文本分析，使机器学习方法在准确性和计算效率上与深度学习方法相比有所提升，同时减少碳排放影响


<details>
  <summary>Details</summary>
Motivation: 深度学习技术的广泛应用导致计算资源需求和电力消耗增加，进而增加碳排放。为了减少碳足迹，同时保持分析效果，提出了一种更高效的文本分析方法

Method: 通过CTF-IDF算法改进传统TF-IDF算法，并结合快速IRLBA降维算法，应用在传统文本分析管道中，提高机器学习方法的效率和准确性

Result: 实验结果表明，改进后的方法在准确性和时间复杂度上均优于传统的深度学习方法

Conclusion: 优化的文本分析流程表明，在保证一定准确性的前提下，机器学习方法结合新的数据预处理和技术可以更高效、更环保

Abstract: The uprising of deep learning methodology and practice in recent years has
brought about a severe consequence of increasing carbon footprint due to the
insatiable demand for computational resources and power. The field of text
analytics also experienced a massive transformation in this trend of
monopolizing methodology. In this paper, the original TF-IDF algorithm has been
modified, and Clement Term Frequency-Inverse Document Frequency (CTF-IDF) has
been proposed for data preprocessing. This paper primarily discusses the
effectiveness of classical machine learning techniques in text analytics with
CTF-IDF and a faster IRLBA algorithm for dimensionality reduction. The
introduction of both of these techniques in the conventional text analytics
pipeline ensures a more efficient, faster, and less computationally intensive
application when compared with deep learning methodology regarding carbon
footprint, with minor compromise in accuracy. The experimental results also
exhibit a manifold of reduction in time complexity and improvement of model
accuracy for the classical machine learning methods discussed further in this
paper.

</details>


### [39] [Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models](https://arxiv.org/abs/2511.02894)
*W. K. M Mithsara,Ning Yang,Ahmed Imteaj,Hussein Zangoti,Abdur R. Shahid*

Main category: cs.LG

TL;DR: 该论文提出了一种新的框架，利用大型语言模型（LLM）进行人体活动识别（HAR）系统的数据中毒检测和净化，采用了零样本、少量样本学习范式，减少了对大规模数据集的需求，提高了实时适应性和防御机制的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习模型虽然在人体活动识别（HAR）方面有所进步，但仍然容易受到数据中毒攻击。传统防御方法需要大规模有标签的数据集进行训练，对于变化多端的物联网环境适应性不足。因此，该论文旨在减少对大规模数据集的依赖，提升HAR系统的安全性和鲁棒性。

Method: 通过使用大型语言模型（LLM）进行零样本、少量样本学习来识别和净化数据中毒。具体方法包括'角色扮演'提示，让LLM扮演专家角色来评估传感器异常数据；'逐步思考'指示，引导LLM通过分析原始传感器数据识别中毒迹象，并提出可能的干净数据替代方案。这种方法能显著减少对大规模数据集的需求。

Result: 该研究表明，在高度动态的物联网环境中，利用LLM的方法能够有效地检测数据中毒并进行净化，同时保持较低的延迟和通信成本，证明了该方法的实用性和有效性。

Conclusion: 该研究提出了一个有效的框架，利用大型语言模型来进行数据中毒检测和净化，它能够在减少对大规模数据集依赖的同时，提高HAR系统在实时环境中的安全性和鲁棒性。

Abstract: The widespread integration of wearable sensing devices in Internet of Things
(IoT) ecosystems, particularly in healthcare, smart homes, and industrial
applications, has required robust human activity recognition (HAR) techniques
to improve functionality and user experience. Although machine learning models
have advanced HAR, they are increasingly susceptible to data poisoning attacks
that compromise the data integrity and reliability of these systems.
Conventional approaches to defending against such attacks often require
extensive task-specific training with large, labeled datasets, which limits
adaptability in dynamic IoT environments. This work proposes a novel framework
that uses large language models (LLMs) to perform poisoning detection and
sanitization in HAR systems, utilizing zero-shot, one-shot, and few-shot
learning paradigms. Our approach incorporates \textit{role play} prompting,
whereby the LLM assumes the role of expert to contextualize and evaluate sensor
anomalies, and \textit{think step-by-step} reasoning, guiding the LLM to infer
poisoning indicators in the raw sensor data and plausible clean alternatives.
These strategies minimize reliance on curation of extensive datasets and enable
robust, adaptable defense mechanisms in real-time. We perform an extensive
evaluation of the framework, quantifying detection accuracy, sanitization
quality, latency, and communication cost, thus demonstrating the practicality
and effectiveness of LLMs in improving the security and reliability of wearable
IoT systems.

</details>


### [40] [Decoupled Entropy Minimization](https://arxiv.org/abs/2511.03256)
*Jing Ma,Hanlin Li,Xiang Xiang*

Main category: cs.LG

TL;DR: 提出了一种自适应解耦熵最小化(AdaDEM)方法，用于改善机器学习中的多种任务。通过重新设计和解耦经典熵最小化(EM)的方法，研究了其内部机制并解决了其局限性，从而提高了适应性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决经典熵最小化（EM）方法中的局限性，包括奖励崩溃问题和容易类别偏见问题，以提高多任务在机器学习中的性能和鲁棒性。

Method: 提出一种称为自适应解耦熵最小化(AdaDEM)的方法，通过调整和解耦经典EM变为两部分，并引入边缘熵校准器(MEC)来解决奖励崩溃和容易类别偏见问题。

Result: 新方法优于经典EM的变种DEMY*，并在各种有噪声和动态环境下的不完全监督学习任务中表现更优。

Conclusion: 通过解耦方法改进熵最小化机制，能够提高机器学习模型在处理数据噪声和动态变化情况下的表现效果。

Abstract: Entropy Minimization (EM) is beneficial to reducing class overlap, bridging
domain gap, and restricting uncertainty for various tasks in machine learning,
yet its potential is limited. To study the internal mechanism of EM, we
reformulate and decouple the classical EM into two parts with opposite effects:
cluster aggregation driving factor (CADF) rewards dominant classes and prompts
a peaked output distribution, while gradient mitigation calibrator (GMC)
penalizes high-confidence classes based on predicted probabilities.
Furthermore, we reveal the limitations of classical EM caused by its coupled
formulation: 1) reward collapse impedes the contribution of high-certainty
samples in the learning process, and 2) easy-class bias induces misalignment
between output distribution and label distribution. To address these issues, we
propose Adaptive Decoupled Entropy Minimization (AdaDEM), which normalizes the
reward brought from CADF and employs a marginal entropy calibrator (MEC) to
replace GMC. AdaDEM outperforms DEM*, an upper-bound variant of classical EM,
and achieves superior performance across various imperfectly supervised
learning tasks in noisy and dynamic environments.

</details>


### [41] [Zero-shot data citation function classification using transformer-based large language models (LLMs)](https://arxiv.org/abs/2511.02936)
*Neil Byers,Ali Zaidi,Valerie Skye,Chris Beecroft,Kjiersten Fagnan*

Main category: cs.LG

TL;DR: 本论文应用了一个开源的大语言模型（LLM），Llama 3.1-405B，来生成已知包含特定基因组数据集的出版物的结构化数据使用情况标签，并提出了一种新的评估框架来确定方法的有效性。研究结果表明，该模型在无需先前定义类别的零样本数据引文分类任务中可以实现F1得分为0.674。该研究结果受到数据可用性、提示过拟合、计算基础设施和负责任的性能评估所需成本的限制。


<details>
  <summary>Details</summary>
Motivation: 论文目的在于通过使用预训练的大语言模型来解决手动标记和为经典机器学习系统开发训练数据集的问题，以描述出版文献中的数据使用情况，并探索数据的应用方式和原因。

Method: 本文使用开源的大语言模型Llama 3.1-405B，生成结构化数据使用描述标签，并引入了新的评估框架来衡量方法效果。

Result: 研究结果表明，模型在零样本数据引文分类任务中取得了F1得分为0.674，虽有一定局限性，但体现了模型在描述数据使用情况方面的潜力。

Conclusion: 研究成果展示了通过大语言模型描述数据使用情况的能力和挑战，为未来研究提供了方向，并强调了进一步提升性能和克服评估挑战的需求。

Abstract: Efforts have increased in recent years to identify associations between
specific datasets and the scientific literature that incorporates them. Knowing
that a given publication cites a given dataset, the next logical step is to
explore how or why that data was used. Advances in recent years with
pretrained, transformer-based large language models (LLMs) offer potential
means for scaling the description of data use cases in the published
literature. This avoids expensive manual labeling and the development of
training datasets for classical machine-learning (ML) systems. In this work we
apply an open-source LLM, Llama 3.1-405B, to generate structured data use case
labels for publications known to incorporate specific genomic datasets. We also
introduce a novel evaluation framework for determining the efficacy of our
methods. Our results demonstrate that the stock model can achieve an F1 score
of .674 on a zero-shot data citation classification task with no previously
defined categories. While promising, our results are qualified by barriers
related to data availability, prompt overfitting, computational infrastructure,
and the expense required to conduct responsible performance evaluation.

</details>


### [42] [Power Constrained Nonstationary Bandits with Habituation and Recovery Dynamics](https://arxiv.org/abs/2511.02944)
*Fengxu Li,Stephanie M. Carpenter,Matthew P. Buman,Yonatan Mintz*

Main category: cs.LG

TL;DR: 本文提出了针对非平稳环境的ROGUE-TS算法，并通过概率剪辑过程平衡个性化与总体学习，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的算法在个性化策略制定过程中过度强调了探索与利用的平衡，这限制了总体效果的评估，特别是在微随机化实验（MRTs）中，需要开发既能保证总体效果又能提供个性化推荐的即时适应性干预措施。为解决此问题，提出了一种新算法ROGUE-TS及其概率剪辑过程。

Method: 提出了ROGUE-TS算法，结合概率剪辑过程，用于平衡个性化推荐和总体学习，并提供理论保证，确保算法具有次线性遗憾值。同时提出量化平衡遗憾值与最小探索概率的方法。

Result: 实验表明，所提出的ROGUE-TS算法相较于现有方法能够有效降低遗憾值，同时保持较高的统计效力，实现在不显著增加遗憾的情况下可靠检测到治疗效果的目标。

Conclusion: 我们的框架为设计能够平衡个性化和统计有效性的MRT实验提供了实际指导。

Abstract: A common challenge for decision makers is selecting actions whose rewards are
unknown and evolve over time based on prior policies. For instance, repeated
use may reduce an action's effectiveness (habituation), while inactivity may
restore it (recovery). These nonstationarities are captured by the Reducing or
Gaining Unknown Efficacy (ROGUE) bandit framework, which models real-world
settings such as behavioral health interventions. While existing algorithms can
compute sublinear regret policies to optimize these settings, they may not
provide sufficient exploration due to overemphasis on exploitation, limiting
the ability to estimate population-level effects. This is a challenge of
particular interest in micro-randomized trials (MRTs) that aid researchers in
developing just-in-time adaptive interventions that have population-level
effects while still providing personalized recommendations to individuals. In
this paper, we first develop ROGUE-TS, a Thompson Sampling algorithm tailored
to the ROGUE framework, and provide theoretical guarantees of sublinear regret.
We then introduce a probability clipping procedure to balance personalization
and population-level learning, with quantified trade-off that balances regret
and minimum exploration probability. Validation on two MRT datasets concerning
physical activity promotion and bipolar disorder treatment shows that our
methods both achieve lower regret than existing approaches and maintain high
statistical power through the clipping procedure without significantly
increasing regret. This enables reliable detection of treatment effects while
accounting for individual behavioral dynamics. For researchers designing MRTs,
our framework offers practical guidance on balancing personalization with
statistical validity.

</details>


### [43] [Inference-Time Personalized Alignment with a Few User Preference Queries](https://arxiv.org/abs/2511.02966)
*Victor-Alexandru Pădurean,Parameswaran Kamalaruban,Nachiket Kotalwar,Alkis Gotovos,Adish Singla*

Main category: cs.LG

TL;DR: 研究了一种新的用户个性化对齐方法UserAlign，该方法通过少量的查询比较用户偏好，从而从生成模型的固定响应池中选择最符合用户偏好的响应。实验结果表明，UserAlign在个性化文本和图像生成任务中表现优秀。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化对齐方法要么需要大量的用户偏好查询，要么需要用户以文本形式明确指定偏好。本研究旨在找到一种更有效的方法，以较少的用户交互获得更好的个性化生成结果。

Method: UserAlign基于逻辑多臂老虎机（logistic bandits）的最佳臂识别理论框架，通过用户提供的少量对比反馈快速识别出最佳生成响应。此方法假设用户的反馈是稳定的且不含噪声，从而提高个性化对齐的效率。

Result: 实验表明，UserAlign在个性化文本和图像生成任务中表现出色，能够有效地通过少量用户反馈快速识别出最佳的个性化生成响应。具体来说，实验结果验证了UserAlign的效率和效果。

Conclusion: UserAlign是一种有效的用户个性化生成对齐方法，通过少量比较查询来快速识别出最符合用户偏好的生成响应。这种方法在未来个性化生成模型的对齐上具有潜在的应用价值。

Abstract: We study the problem of aligning a generative model's response with a user's
preferences. Recent works have proposed several different formulations for
personalized alignment; however, they either require a large amount of user
preference queries or require that the preference be explicitly specified as a
text input. In this paper, we propose a novel inference-time personalized
alignment method, UserAlign, that elicits the user's preferences with a few
queries as pairwise response comparisons. In particular, UserAlign builds on
the theoretical framework of best-arm identification in logistic bandits and
selects a personalized response from a fixed pool of the model's generated
responses. The key idea is to consider the user's feedback consistent and
noise-free, and incorporate it into the theoretical framework to identify the
best response quickly. Experimental results across several tasks, involving
personalized text and image generation, showcase the effectiveness of UserAlign
in achieving personalized alignment.

</details>


### [44] [Adaptive-Sensorless Monitoring of Shipping Containers](https://arxiv.org/abs/2511.03022)
*Lingqing Shen,Chi Heem Wong,Misaki Mito,Arnab Chakrabarti*

Main category: cs.LG

TL;DR: 本文提出了一种残差校正方法，即适应性无传感器监测框架，用于校正无传感器模型中的系统性偏差。该框架在3.48万个数据点上进行了训练和评估，并且展示了比传统无传感器模型更好的性能表现。适应性无传感器模型能够实现更准确的货物监测，早期风险检测，以及降低全球航运中的完全连通性依赖度。 


<details>
  <summary>Details</summary>
Motivation: 为了减少货物在运输过程中质量退化，监测货柜内的温度和湿度是必要的。但是无传感器监控可能会与实时数据差异较大，导致用户混淆。提出了一个新的残差校正方法以解决这些问题。 

Method: 本文介绍了一种新的残差校正方法，该方法是一种用于校正无传感器模型中系统性偏差的通用框架。通过观察实时的遥测数据，可以进行模型校正，使其更加准确。 

Result: 适应性无传感器监测模型在实验数据集上与无传感器模型相比，温湿度的平均绝对误差有所下降，温度为2.24-2.31°C （无传感器模型为2.43°C），相对湿度为5.72-7.09% （无传感器模型为7.99%）。此外，温湿度的均方根误差也有所降低，温度为3.19-3.26°C （无传感器模型为3.38°C），相对湿度为7.70-9.12% （无传感器模型为10.0%）。

Conclusion: 适应性无传感器监测方法能够实现更好的准确性，早期的风险检测和对全球航运过程中的完全连通性较低的依赖性。

Abstract: Monitoring the internal temperature and humidity of shipping containers is
essential to preventing quality degradation during cargo transportation.
Sensorless monitoring -- machine learning models that predict the internal
conditions of the containers using exogenous factors -- shows promise as an
alternative to monitoring using sensors. However, it does not incorporate
telemetry information and correct for systematic errors, causing the
predictions to differ significantly from the live data and confusing the users.
In this paper, we introduce the residual correction method, a general framework
for correcting for systematic biases in sensorless models after observing live
telemetry data. We call this class of models ``adaptive-sensorless''
monitoring. We train and evaluate adaptive-sensorless models on the 3.48
million data points -- the largest dataset of container sensor readings ever
used in academic research -- and show that they produce consistent improvements
over the baseline sensorless models. When evaluated on the holdout set of the
simulated data, they achieve average mean absolute errors (MAEs) of 2.24 $\sim$
2.31$^\circ$C (vs 2.43$^\circ$C by sensorless) for temperature and 5.72 $\sim$
7.09% for relative humidity (vs 7.99% by sensorless) and average root
mean-squared errors (RMSEs) of 3.19 $\sim$ 3.26$^\circ$C for temperature (vs
3.38$^\circ$C by sensorless) and 7.70 $\sim$ 9.12% for relative humidity (vs
10.0% by sensorless). Adaptive-sensorless models enable more accurate cargo
monitoring, early risk detection, and less dependence on full connectivity in
global shipping.

</details>


### [45] [Leveraging Discrete Function Decomposability for Scientific Design](https://arxiv.org/abs/2511.03032)
*James C. Bowden,Sergey Levine,Jennifer Listgarten*

Main category: cs.LG

TL;DR: 提出了一种新的分布优化算法DADO，它能够利用设计变量的分解结构来提高优化效率。


<details>
  <summary>Details</summary>
Motivation: 在AI驱动的科学研究和工程实践中，我们经常需要根据用户指定的特性在计算机模拟中设计离散对象。然而，现有的分布优化算法无法利用科学应用程序中一些特性预测器的可分解性。因此，提出了一种新的分布优化算法，以提高优化效率并解决这些问题。

Method: 提出了一个新的分布优化算法，称为分解感知分布优化算法（DADO），它可以利用设计变量的可分解性结构。该算法的核心是一个单因子化的“搜索分布”——一个学习的生成模型，用于有效地在搜索空间中进行导航，通过图消息传递协调因子之间的优化过程。

Result: 该算法的应用展示了可以在保持给定特性的同时，更有效地生成搜索分布模型，提高设计效率和质量。在证明算法的有效性方面，我们使用了蛋白质设计等实际案例。

Conclusion: DADO通过利用设计变量的分解结构，为分布优化问题提供了一种新颖且高效的解决方案。

Abstract: In the era of AI-driven science and engineering, we often want to design
discrete objects in silico according to user-specified properties. For example,
we may wish to design a protein to bind its target, arrange components within a
circuit to minimize latency, or find materials with certain properties. Given a
property predictive model, in silico design typically involves training a
generative model over the design space (e.g., protein sequence space) to
concentrate on designs with the desired properties. Distributional optimization
-- which can be formalized as an estimation of distribution algorithm or as
reinforcement learning policy optimization -- finds the generative model that
maximizes an objective function in expectation. Optimizing a distribution over
discrete-valued designs is in general challenging because of the combinatorial
nature of the design space. However, many property predictors in scientific
applications are decomposable in the sense that they can be factorized over
design variables in a way that could in principle enable more effective
optimization. For example, amino acids at a catalytic site of a protein may
only loosely interact with amino acids of the rest of the protein to achieve
maximal catalytic activity. Current distributional optimization algorithms are
unable to make use of such decomposability structure. Herein, we propose and
demonstrate use of a new distributional optimization algorithm,
Decomposition-Aware Distributional Optimization (DADO), that can leverage any
decomposability defined by a junction tree on the design variables, to make
optimization more efficient. At its core, DADO employs a soft-factorized
"search distribution" -- a learned generative model -- for efficient navigation
of the search space, invoking graph message-passing to coordinate optimization
across linked factors.

</details>


### [46] [Data-Efficient Realized Volatility Forecasting with Vision Transformers](https://arxiv.org/abs/2511.03046)
*Emi Soroka,Artem Arzyn*

Main category: cs.LG

TL;DR: 本论文探讨了在期权数据中应用Vision Transformer (ViT)模型，以从隐含波动率曲面预测资产未来30天的实际波动性。结果显示ViT可以学习到IV表面上的季节性模式和非线性特征，表明这是一种有前景的研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer架构在财务时间序列预测中的表现出了潜力，但在期权数据的应用上仍然很少被探索。本研究旨在开发适用于期权数据的Transformer模型，并探索其可行性。

Method: 本研究使用了Vision Transformer（ViT）架构，该架构通常用于现代图像识别和分类系统，通过训练ViT模型将其应用于预测资产未来30天的实际波动性。模型输入是包含了日期信息的隐含波动率曲面。

Result: 结果显示，ViT可以学习到隐含波动率曲面中的季节性模式和非线性特征，这表明ViT适用于这种类型的任务。

Conclusion: 研究表明，ViT作为一种复杂模型，在期权数据的时间序列预测任务中展现出良好的性能，具有进一步研究的潜力。

Abstract: Recent work in financial machine learning has shown the virtue of complexity:
the phenomenon by which deep learning methods capable of learning highly
nonlinear relationships outperform simpler approaches in financial forecasting.
While transformer architectures like Informer have shown promise for financial
time series forecasting, the application of transformer models for options data
remains largely unexplored. We conduct preliminary studies towards the
development of a transformer model for options data by training the Vision
Transformer (ViT) architecture, typically used in modern image recognition and
classification systems, to predict the realized volatility of an asset over the
next 30 days from its implied volatility surface (augmented with date
information) for a single day. We show that the ViT can learn seasonal patterns
and nonlinear features from the IV surface, suggesting a promising direction
for model development.

</details>


### [47] [The Curved Spacetime of Transformer Architectures](https://arxiv.org/abs/2511.03060)
*Riccardo Di Sipio,Jairo Diaz-Rodriguez,Luis Serrano*

Main category: cs.LG

TL;DR: 该研究提出了一种将Transformer语言模型与广义相对论类比的几何框架，通过实验验证了模型内部的表示空间存在类似引力场的曲率效应。


<details>
  <summary>Details</summary>
Motivation: 通过将Transformer中的查询和键比作广义相对论中的有效度量，探索语言模型内部的表示空间是否存在类似引力场的曲率效应，从而深化对于Transformer模型机制的理解。

Method: 利用Transformer中的注意力机制来模拟曲率效应，通过堆叠的层模拟易动量在时间上的演化，通过反向传播模拟作用原理解剖学习轨迹在参数空间的形状。设计实验以展示和测试这种曲率的存在及其对模型行为的影响。

Result: 实验结果表明Transformer模型内部确实存在类似引力场的曲率效应，证明了模型在特征空间中表征路径的弯曲与重组行为。同时，通过控制上下文的实际改动来模拟爱因斯坦的日蚀实验，进一步证明了曲率的存在。

Conclusion: 该研究将Transformer模型内部的表示空间比作具有曲率的地带，并证明了该比拟的合理性。此研究更深入地理解了Transformer的工作原理，指导了未来在更复杂、结构化的环境中的应用。

Abstract: We present a geometric framework for understanding Transformer-based language
models, drawing an explicit analogy to General Relativity. Queries and keys
induce an effective metric on representation space, and attention acts as a
discrete connection that implements parallel transport of value vectors across
tokens. Stacked layers provide discrete time-slices through which token
representations evolve on this curved manifold, while backpropagation plays the
role of a least-action principle that shapes loss-minimizing trajectories in
parameter space. If this analogy is correct, token embeddings should not
traverse straight paths in feature space; instead, their layer-wise steps
should bend and reorient as interactions mediated by embedding space curvature.
To test this prediction, we design experiments that expose both the presence
and the consequences of curvature: (i) we visualize a curvature landscape for a
full paragraph, revealing how local turning angles vary across tokens and
layers; (ii) we show through simulations that excess counts of sharp/flat
angles and longer length-to-chord ratios are not explainable by dimensionality
or chance; and (iii) inspired by Einstein's eclipse experiment, we probe
deflection under controlled context edits, demonstrating measurable,
meaning-consistent bends in embedding trajectories that confirm
attention-induced curvature.

</details>


### [48] [Online Learning to Rank under Corruption: A Robust Cascading Bandits Approach](https://arxiv.org/abs/2511.03074)
*Fatemeh Ghaffari,Siddarth Sitaraman,Xutong Liu,Xuchuang Wang,Mohammad Hajiesmaili*

Main category: cs.LG

TL;DR: 提出了一种名为MSUCB的算法，该算法在存在点击欺诈的情况下也能有效工作，通过使用新型的中位数平均估计算法来抵抗偏差样本的影响，确保学习过程的准确性和用户满意度。实验显示，该算法在不受污染时能达到最优的对数遗憾，在存在最小程度的污染时遗憾增加也最小，持续优于现有的方法。


<details>
  <summary>Details</summary>
Motivation: 面对在线学习排名系统中常见的点击欺诈和其它操纵行为，传统方法容易受到偏差反馈的影响，导致学习过程中的误导，影响用户体验，因此急需一种新型算法来增强系统的稳健性。

Method: 该研究引入了一种新的中位数平均估计算法，命名为MSUCB。这种算法在正常情况下表现得像标准平均算法，但在存在腐败时能有效地过滤掉异常值和被篡改的数据样本，这样尽管增加了抵抗污染的能力但没有额外的性能损失，同时更新每轮的估算值可以加速经验收敛。因此它在没有腐败时能达到最优对数遗憾，在存在腐败时遗憾的增加度是最小的。

Result: 实验结果表明，该算法比现有的最佳方法显示出显著的遗憾改善，特别是在不受污染和受到一定程度污染的情况下的性能均佳，具体提高了97.35%和91.60%的遗憾改善。这证明了策略的有效性以及在实际应用中的潜力。

Conclusion: 研究证明，通过使用结合了中位数步骤来抵抗偏差的新型估算器，MSUCB在不受污染时能达到最优的对数遗憾，并且在存在腐败时遗憾增加由总体腐败量附加而非累计。这使得它在实践中成为一种有效且稳健的算法，特别是在面对点击欺诈行为时。

Abstract: Online learning to rank (OLTR) studies how to recommend a short ranked list
of items from a large pool and improves future rankings based on user clicks.
This setting is commonly modeled as cascading bandits, where the objective is
to maximize the likelihood that the user clicks on at least one of the
presented items across as many timesteps as possible. However, such systems are
vulnerable to click fraud and other manipulations (i.e., corruption), where
bots or paid click farms inject corrupted feedback that misleads the learning
process and degrades user experience. In this paper, we propose MSUCB, a robust
algorithm that incorporates a novel mean-of-medians estimator, which to our
knowledge is applied to bandits with corruption setting for the first time.
This estimator behaves like a standard mean in the absence of corruption, so no
cost is paid for robustness. Under corruption, the median step filters out
outliers and corrupted samples, keeping the estimate close to its true value.
Updating this estimate at every round further accelerates empirical convergence
in experiments. Hence, MSUCB achieves optimal logarithmic regret in the absence
of corruption and degrades gracefully under corruptions, with regret increasing
only by an additive term tied to the total corruption. Comprehensive and
extensive experiments on real-world datasets further demonstrate that our
approach consistently outperforms prior methods while maintaining strong
robustness. In particular, it achieves a \(97.35\%\) and a \(91.60\%\) regret
improvement over two state-of-the-art methods.

</details>


### [49] [Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies](https://arxiv.org/abs/2511.03095)
*Gaia Grosso,Sai Sumedh R. Hindupur,Thomas Fel,Samuel Bright-Thonney,Philip Harris,Demba Ba*

Main category: cs.LG

TL;DR: 本文提出了一种新的异常检测方法SparKer，该方法能够高效地在高维数据中识别异常。通过使用稀疏化的高斯核聚类，SparKer在半监督Neyman-Pearson框架下训练，用于局部建模样本中可能含有的异常与无异常样本的似然比。其展示了在科学研究、开放世界的新颖性检测、入侵检测和生成模型验证等实际场景中的有效性。这种方法既具有可解释性、效率，又兼具可扩展性。


<details>
  <summary>Details</summary>
Motivation: 基于现有的人工智能技术在科学领域中的应用虽然广泛，但是异常检测的统计性质控制不够，弱信号或稀疏信号容易被正常数据掩盖。为了填补这一研究空白，本文提出了新的异常检测方法SparKer。

Method: SparKer通过稀疏的高斯核自组织集合提出，该集合用于在表示空间中自适应地分割统计失衡区域，以在弱先验信息的情况下识别异常。具体方法在半监督Neyman-Pearson框架下，通过局部建模似然比来检测异常。

Result: 实验结果表明，即使是在包含数千维度的表达空间中，这种方法也能利用极少数（例如三四组）的核来识别出统计上显著的异常地点，展示了垃圾箱技术在现实高维问题中的有效性，以及具备的可解释、效率和可扩展性。

Conclusion: SparKer作为一种新型的异常检测工具，通过利用其独特的结构来高效解决实际场景中的高维异常检测问题。

Abstract: Modern artificial intelligence has revolutionized our ability to extract rich
and versatile data representations across scientific disciplines. Yet, the
statistical properties of these representations remain poorly controlled,
causing misspecified anomaly detection (AD) methods to falter. Weak or rare
signals can remain hidden within the apparent regularity of normal data,
creating a gap in our ability to detect and interpret anomalies. We examine
this gap and identify a set of structural desiderata for detection methods
operating under minimal prior information: sparsity, to enforce parsimony;
locality, to preserve geometric sensitivity; and competition, to promote
efficient allocation of model capacity. These principles define a class of
self-organizing local kernels that adaptively partition the representation
space around regions of statistical imbalance. As an instantiation of these
principles, we introduce SparKer, a sparse ensemble of Gaussian kernels trained
within a semi-supervised Neyman--Pearson framework to locally model the
likelihood ratio between a sample that may contain anomalies and a nominal,
anomaly-free reference. We provide theoretical insights into the mechanisms
that drive detection and self-organization in the proposed model, and
demonstrate the effectiveness of this approach on realistic high-dimensional
problems of scientific discovery, open-world novelty detection, intrusion
detection, and generative-model validation. Our applications span both the
natural- and computer-science domains. We demonstrate that ensembles containing
only a handful of kernels can identify statistically significant anomalous
locations within representation spaces of thousands of dimensions, underscoring
both the interpretability, efficiency and scalability of the proposed approach.

</details>


### [50] [Scaling Multi-Agent Environment Co-Design with Diffusion Models](https://arxiv.org/abs/2511.03100)
*Hao Xiang Li,Michael Amir,Amanda Prorok*

Main category: cs.LG

TL;DR: 本文提出了Diffusion Co-Design (DiCoDe)，一种用于改进多智能体系统性能的可拓展且样本高效的联合优化框架。DiCoDe通过引入Projected Universal Guidance (PUG) 技术和批评者拟合机制，实现了环境分布和智能体策略的高效探索和适应，显著提高了仓库自动化、多智能体路径寻找及风电场优化等场景下的表现。在仓库优化中的测试中，DiCoDe相比现有最佳方法增加了39%的收益，减少了66%的模拟样本。这项研究推动了实际应用中的联合设计领域发展。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统的联合设计面临环境高维度和样本效率低下的挑战。提出DiCoDe框架，旨在解决这些挑战，提高实际应用场景中联合设计的效率和性能。

Method: 通过Projective Universal Guidance (PUG) 技术探索最大化奖励的环境分布，并利用批评者拟合机制共享知识，使得引导扩散模型能够更好地适应智能体策略的变化，从而提高环境策略对的性能。

Result: DiCoDe在多个挑战的多智能体环境联合设计基准上取得了更好的环境策略对，在仓库自动化测试中，实现了比最新技术高出39%的收益，同时降低了66%的模拟样本。

Conclusion: DiCoDe不仅提高了多智能体系统性能，也展示了在实际部署联合设计方面的潜力。

Abstract: The agent-environment co-design paradigm jointly optimises agent policies and
environment configurations in search of improved system performance. With
application domains ranging from warehouse logistics to windfarm management,
co-design promises to fundamentally change how we deploy multi-agent systems.
However, current co-design methods struggle to scale. They collapse under
high-dimensional environment design spaces and suffer from sample inefficiency
when addressing moving targets inherent to joint optimisation. We address these
challenges by developing Diffusion Co-Design (DiCoDe), a scalable and
sample-efficient co-design framework pushing co-design towards practically
relevant settings. DiCoDe incorporates two core innovations. First, we
introduce Projected Universal Guidance (PUG), a sampling technique that enables
DiCoDe to explore a distribution of reward-maximising environments while
satisfying hard constraints such as spatial separation between obstacles.
Second, we devise a critic distillation mechanism to share knowledge from the
reinforcement learning critic, ensuring that the guided diffusion model adapts
to evolving agent policies using a dense and up-to-date learning signal.
Together, these improvements lead to superior environment-policy pairs when
validated on challenging multi-agent environment co-design benchmarks including
warehouse automation, multi-agent pathfinding and wind farm optimisation. Our
method consistently exceeds the state-of-the-art, achieving, for example, 39%
higher rewards in the warehouse setting with 66% fewer simulation samples. This
sets a new standard in agent-environment co-design, and is a stepping stone
towards reaping the rewards of co-design in real world domains.

</details>


### [51] [FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation](https://arxiv.org/abs/2511.03113)
*Jiameng Chen,Yida Xiong,Kun Li,Hongzhi Zhang,Xiantao Cai,Wenbin Hu,Jia Wu*

Main category: cs.LG

TL;DR: FP-AbDiff 是一种新型抗体生成器，它通过结合物理规律和深度生物学先验，解决了现有模型缺乏动态一致性和数据稀缺导致的泛化能力差的问题。在设计CDR-H3时，FP-AbDiff比前一种最佳模型提高了25%，并且在六CDR协同设计任务中表现出优越的几何精度和氨基酸回收率。


<details>
  <summary>Details</summary>
Motivation: 现有抗体生成模型存在缺乏动态一致性导致物理上不可行的结构，以及由于数据稀缺和结构偏差导致的泛化能力差，因此需要一种既能保持物理一致性又能利用生物学先验的新方法来改进抗体设计。

Method: FP-AbDiff 通过在生成过程中引入Fokker-Planck方程物理规律，并结合SE(3)等变扩散框架中的深度生物学先验，解决了现有模型存在的两个核心挑战。具体来说，这种方法通过最小化FPE残差损失，使局部学习的去噪评分能够组成全局一致的概率流。

Result: FP-AbDiff 在RabD基准测试中表现出了优越的性能，特别是在CDR-H3的新设计任务中，它的均方根偏差比之前的最佳模型AbX提高了25%，并且在六CDR协同设计任务中，保持了更优的几何精密度和与功能相关的CDR-H3环氨基酸回收率。

Conclusion: 通过将生成动力学与物理规律对齐，FP-AbDiff 提高了生成抗体的鲁棒性和泛化能力，提出了一种基于物理真实可行性和功能性的抗体设计的原则性方法。

Abstract: Computational antibody design holds immense promise for therapeutic
discovery, yet existing generative models are fundamentally limited by two core
challenges: (i) a lack of dynamical consistency, which yields physically
implausible structures, and (ii) poor generalization due to data scarcity and
structural bias. We introduce FP-AbDiff, the first antibody generator to
enforce Fokker-Planck Equation (FPE) physics along the entire generative
trajectory. Our method minimizes a novel FPE residual loss over the mixed
manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising
scores to assemble into a globally coherent probability flow. This
physics-informed regularizer is synergistically integrated with deep biological
priors within a state-of-the-art SE(3)-equivariant diffusion framework.
Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a
new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean
Square Deviation of 0.99 {\AA} when superposing on the variable region, a 25%
improvement over the previous state-of-the-art model, AbX, and the highest
reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored
in the more challenging six-CDR co-design task, where our model delivers
consistently superior geometric precision, cutting the average full-chain Root
Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain
Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By
aligning generative dynamics with physical laws, FP-AbDiff enhances robustness
and generalizability, establishing a principled approach for physically
faithful and functionally viable antibody design.

</details>


### [52] [An Augmentation Overlap Theory of Contrastive Learning](https://arxiv.org/abs/2511.03114)
*Qi Zhang,Yifei Wang,Yisen Wang*

Main category: cs.LG

TL;DR: 本文提出了基于数据增强重叠的理论，解释了自我监督对比学习的有效性，无需额外模块即可评估表示并预测下游任务表现。代码已公开。


<details>
  <summary>Details</summary>
Motivation: 当前自我监督对比学习取得巨大成功，但其机制尚不明确。本文旨在阐明其工作的潜在机制。

Method: 放松假设条件，从数据增强重叠角度解释对比学习的有效性，并开发了一个无监督的评估指标。

Result: 提出的理论接近真实的下游表现，评估方法精度高，无需额外模块。

Conclusion: 基于数据增强重叠的理论有助于理解对比学习的有效性，开发的无监督评估指标可以准确地评估表示，并预测其在下游任务上的表现。

Abstract: Recently, self-supervised contrastive learning has achieved great success on
various tasks. However, its underlying working mechanism is yet unclear. In
this paper, we first provide the tightest bounds based on the widely adopted
assumption of conditional independence. Further, we relax the conditional
independence assumption to a more practical assumption of augmentation overlap
and derive the asymptotically closed bounds for the downstream performance. Our
proposed augmentation overlap theory hinges on the insight that the support of
different intra-class samples will become more overlapped under aggressive data
augmentations, thus simply aligning the positive samples (augmented views of
the same sample) could make contrastive learning cluster intra-class samples
together. Moreover, from the newly derived augmentation overlap perspective, we
develop an unsupervised metric for the representation evaluation of contrastive
learning, which aligns well with the downstream performance almost without
relying on additional modules. Code is available at
https://github.com/PKU-ML/GARC.

</details>


### [53] [From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation](https://arxiv.org/abs/2511.03128)
*Najrin Sultana,Md Rafi Ur Rashid,Kang Gu,Shagufta Mehnaz*

Main category: cs.LG

TL;DR: 引入了静态和动态欺骗器框架，评估大规模语言模型面对对抗性输入时的鲁棒性。这些框架能够生成与原文意义相似但能误导模型的输入，以更系统地评估模型的稳定性。研究展示了强大的跨模型传输能力。


<details>
  <summary>Details</summary>
Motivation: 强大语言模型在遭遇复杂的对抗性输入时需要评估其鲁棒性，而现有的评估方法缺乏系统性和适应性，引入更创新的方法是必要的。

Method: 开发了两个新型攻击框架：静态欺骗器（StaDec）和动态欺骗器（DyDec），依靠大规模语言模型本身的能力生成模仿文本并且有一定欺骗性的对抗输入。它们构成了连续不断的、自动化的攻击管道，可以跨模型传输，并随模型进步而改进。

Result: 证实了新型攻击框架能有效地生成对抗输入，对评估语言模型的鲁棒性提供了一种新的更系统的方法。这些框架生成的抗扰输入能混淆语言模型，即便在不解密原内容和模型内部机制的情况下也能成功。

Conclusion: 这项工作展示了有效评估大规模语言模型应对对抗性输入鲁棒性的新方法，并且说明，面对越来越强大的语言模型，该方法可以持续进化且跨模型使用。

Abstract: LLMs can provide substantial zero-shot performance on diverse tasks using a
simple task prompt, eliminating the need for training or fine-tuning. However,
when applying these models to sensitive tasks, it is crucial to thoroughly
assess their robustness against adversarial inputs. In this work, we introduce
Static Deceptor (StaDec) and Dynamic Deceptor (DyDec), two innovative attack
frameworks designed to systematically generate dynamic and adaptive adversarial
examples by leveraging the understanding of the LLMs. We produce subtle and
natural-looking adversarial inputs that preserve semantic similarity to the
original text while effectively deceiving the target LLM. By utilizing an
automated, LLM-driven pipeline, we eliminate the dependence on external
heuristics. Our attacks evolve with the advancements in LLMs and demonstrate
strong transferability across models unknown to the attacker. Overall, this
work provides a systematic approach for the self-assessment of an LLM's
robustness. We release our code and data at
https://github.com/Shukti042/AdversarialExample.

</details>


### [54] [Test Time Adaptation Using Adaptive Quantile Recalibration](https://arxiv.org/abs/2511.03148)
*Paria Mehrbod,Pedro Vianna,Geraldin Nanfack,Guy Wolf,Eugene Belilovsky*

Main category: cs.LG

TL;DR: 提出了一种新的测试时自适应技术AQR，能够通过调整预激活分布来增强模型在不同数据分布环境中的泛化能力。该方法通过在通道级别上对分位数进行对齐来捕获激活分布的全貌，并且具备较高的稳定性与准确性。实验表明，AQR在多个数据集和架构上优于现有的自适应基线方法，展示了其在现实世界中的潜在应用价值。


<details>
  <summary>Details</summary>
Motivation: 传统的领域自适应方法往往依赖于目标域的先验知识或需要重新训练模型，这在动态或资源受限的环境中限制了其应用。为了解决这一问题，该研究提出了AQR策略，旨在通过更有效的机制来实现测试时的自适应。

Method: AQR是一种新的自适应技术，它通过在通道级别上对分位数进行对齐来修改预激活分布。这种方法弥补了先前技术在捕捉复杂激活分布方面的不足，并具备跨不同归一化层（如BatchNorm, GroupNorm, 或LayerNorm）的推广能力。此外，AQR引入了一种鲁棒的尾部校准策略，以提高在不同批次大小下的稳定性和精度。

Result: 在CIFAR-10-C, CIFAR-100-C, 和ImageNet-C等多个数据集上进行的实验表明，与现有的测试时自适应基线方法相比，AQR在各种设置中表现出更高的适应性和鲁棒性，实现了显著的性能提升。

Conclusion: 该研究提出的AQR方法不仅能够实现无监督自适应，而且具备较强的跨场景和跨架构泛化能力，展示了其在处理动态不可预测数据分布的现实世界场景中的巨大潜力。

Abstract: Domain adaptation is a key strategy for enhancing the generalizability of
deep learning models in real-world scenarios, where test distributions often
diverge significantly from the training domain. However, conventional
approaches typically rely on prior knowledge of the target domain or require
model retraining, limiting their practicality in dynamic or
resource-constrained environments. Recent test-time adaptation methods based on
batch normalization statistic updates allow for unsupervised adaptation, but
they often fail to capture complex activation distributions and are constrained
to specific normalization layers. We propose Adaptive Quantile Recalibration
(AQR), a test-time adaptation technique that modifies pre-activation
distributions by aligning quantiles on a channel-wise basis. AQR captures the
full shape of activation distributions and generalizes across architectures
employing BatchNorm, GroupNorm, or LayerNorm. To address the challenge of
estimating distribution tails under varying batch sizes, AQR incorporates a
robust tail calibration strategy that improves stability and precision. Our
method leverages source-domain statistics computed at training time, enabling
unsupervised adaptation without retraining models. Experiments on CIFAR-10-C,
CIFAR-100-C, and ImageNet-C across multiple architectures demonstrate that AQR
achieves robust adaptation across diverse settings, outperforming existing
test-time adaptation baselines. These results highlight AQR's potential for
deployment in real-world scenarios with dynamic and unpredictable data
distributions.

</details>


### [55] [Forecast2Anomaly (F2A): Adapting Multivariate Time Series Foundation Models for Anomaly Prediction](https://arxiv.org/abs/2511.03149)
*Atif Hassan,Tarun Kumar,Ashish Mishra,Sergey Serebryakov,Satish Kumar Mopur,Phanidhar Koganti,Murthy Chelankuri,Ramanagopal Vogety,Suparna Bhattacharya,Martin Foltin*

Main category: cs.LG

TL;DR: 提出了一种新的预测异常的方法Forecast2Anomaly (F2A)，它通过联合预测-异常损失和检索增强生成模块，使时间序列基础模型具备了零样本预测异常的能力。在各种真实世界数据集上，该方法优于现有方法，表现出了强大的零样本预测异常的能力。


<details>
  <summary>Details</summary>
Motivation: 当前异常预测方法受限于特定系统，难以泛化到随时间变化的异常模式。本文提出了一种新框架Forecast2Anomaly (F2A)，以解决这一问题，通过联合预测-异常损失和检索增强生成模块来实现零样本预测异常的能力。

Method: 通过联合预测-异常损失和检索增强生成模块，使时间序列基础模型具备了零样本预测异常的能力。该方法的关键创新在于：一是提出了联合预测-异常损失，使模型能够准确预测未来的信号，即使在异常的时间点上也如此。二是引入了检索增强生成模块，该模块从历史相关景象中检索并基于此预测。在推断时，该组件能够动态适应分布变化，使F2A能够跟踪演变的异常，而无需更新模型。通过结合定向微调和动态检索，F2A实现了稳健的时间序列基础模型的零样本预测异常。

Result: F2A在16个不同的数据集和多种时间序列基础模型上进行了广泛的实验，并且优于现有方法，表现出了强大的零样本预测异常的能力。

Conclusion: F2A通过联合预测-异常损失和检索增强生成模块，解决了当前异常预测方法无法泛化到随时间变化的异常模式的问题，提供了一个可伸缩的、零样本预测异常的解决方案，适用于实际应用。

Abstract: Forecasting anomalies (anomaly prediction) in multivariate time series from
different real-world, dynamic, and complex systems is vital for preempting
critical failures, leading to a substantial minimization in operational costs
and human labor. Yet, existing methods are limited to specific systems while
failing to generalize to evolving anomaly patterns over time. In contrast,
pretrained Time Series Foundation Models (TSFMs) have recently demonstrated
strong generalization and zero-shot forecasting capabilities. However, their
potential remains untapped for anomaly prediction, a task fundamentally
different from forecasting normal behavior. Thus, we present Forecast2Anomaly
(F2A), a novel framework that empowers TSFMs with anomaly prediction abilities
through two key innovations. First, we propose a joint forecast-anomaly loss
that fine-tunes TSFMs to accurately forecast future signals even at anomalous
time points. Second, we introduce a Retrieval-Augmented Generation (RAG) module
that retrieves historically relevant horizons and conditions predictions on
them. This component dynamically adapts to distributional shifts at inference
time, enabling F2A to track evolving anomalies without requiring model updates.
By combining targeted fine-tuning with dynamic retrieval, F2A bridges the gap
between robust TSFM zero-shot forecasting and zero-shot anomaly prediction.
Extensive experiments across 16 diverse datasets and multiple TSFM backbones
show that F2A consistently outperforms state-of-the-art methods, offering a
scalable, zero-shot anomaly prediction solution for real-world applications.

</details>


### [56] [Efficient Linear Attention for Multivariate Time Series Modeling via Entropy Equality](https://arxiv.org/abs/2511.03190)
*Mingtao Zhang,Guoli Yang,Zhanxing Zhu,Mengzhu Wang,Xiaoying Bai*

Main category: cs.LG

TL;DR: 提出了一种新型的线性注意力机制，解决了现有注意力机制在处理长序列时计算复杂度高的问题。通过理论证明和熵的严格凹性，开发了一种线性复杂度计算选择性注意力的能力的算法，适用于时空序列模型。实验证明了该方法的有效性，优于或与现有方法相当，在内存使用和计算时间上大幅减少。


<details>
  <summary>Details</summary>
Motivation: 现有的注意力机制在处理长序列时，由于其O(n^2)计算复杂度导致了可扩展性问题。为了解决这一问题，提出了新的线性注意力机制，减小了模型的计算复杂度和内存使用量。

Method: 提出基于熵的线性注意力机制，利用熵的严格凹性提出了一个可以计算选择性注意力的能力的算法，使复杂度降至O(n)。该方法在准确性和计算效率之间取得了平衡。

Result: 该方法在四组时空数据集上的实验表明，它不仅能够达到优于或和现有最佳方法相当的预测性能，同时还能大大减少内存使用和计算时间，提高了模型的可扩展性。

Conclusion: 研究证明，注意力在空间时间序列建模中主要是通过获得平衡且适当的权重分布，使其性能优越，而不仅仅是依靠softmax的非线性。同时提出了一种有效的线性注意力机制，可以显著降低现有的计算复杂度，并证明了其在预测性能上的优越性。

Abstract: Attention mechanisms have been extensively employed in various applications,
including time series modeling, owing to their capacity to capture intricate
dependencies; however, their utility is often constrained by quadratic
computational complexity, which impedes scalability for long sequences. In this
work, we propose a novel linear attention mechanism designed to overcome these
limitations. Our approach is grounded in a theoretical demonstration that
entropy, as a strictly concave function on the probability simplex, implies
that distributions with aligned probability rankings and similar entropy values
exhibit structural resemblance. Building on this insight, we develop an
efficient approximation algorithm that computes the entropy of
dot-product-derived distributions with only linear complexity, enabling the
implementation of a linear attention mechanism based on entropy equality.
Through rigorous analysis, we reveal that the effectiveness of attention in
spatio-temporal time series modeling may not primarily stem from the
non-linearity of softmax but rather from the attainment of a moderate and
well-balanced weight distribution. Extensive experiments on four
spatio-temporal datasets validate our method, demonstrating competitive or
superior forecasting performance while achieving substantial reductions in both
memory usage and computational time.

</details>


### [57] [Cross-Modal Alignment via Variational Copula Modelling](https://arxiv.org/abs/2511.03196)
*Feng Wu,Tsai Hor Chan,Fuying Wang,Guosheng Yin,Lequan Yu*

Main category: cs.LG

TL;DR: 本文提出了一种新的基于copula的多模态学习框架，它可以捕获不同模态之间的复杂交互，通过假设每个模态的高斯混合分布和联合分布的copula模型，生成缺失模态的准确表示，并在公开的MIMIC数据集上展示了优于其他竞争对手的性能表现。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，数据模态非常普遍，需要开发多模态学习方法来合并来自多个模态的各种信息，主要挑战是如何适当地对齐和融合不同模态的表示，以便形成一个联合分布。现有的方法主要依赖于串联或克罗内克乘积，这简化了模态之间的交互结构，需要更复杂地建模交互。除此之外，更高阶交互的潜在表示的联合分布尚未得到充分探索。因此，本文提出了一种新的基于copula的多模态学习框架，旨在克服这些挑战。

Method: 本方法假设每个模态的高斯混合分布，并在联合分布上使用copula模型，以有效对齐模态的边际分布，从而根据现有的模态信息生成缺失模态的准确表示。

Result: 在公开的MIMIC数据集上的广泛实验表明，该模型的性能优于其他竞争对手。此外，该方法可以准确生成缺失模态的表示，这表明该模型可以用于处理多模态数据中的缺失数据问题。

Conclusion: 本文提出了一种新的基于copula的多模态学习框架，通过利用高斯混合分布假设和联合分布的copula模型，可以更有效地对齐和融合不同模态的信息，生成准确的表示，从而处理多模态数据中的各种问题。

Abstract: Various data modalities are common in real-world applications (e.g.,
electronic health records, medical images and clinical notes in healthcare). It
is essential to develop multimodal learning methods to aggregate various
information from multiple modalities. The main challenge is how to
appropriately align and fuse the representations of different modalities into a
joint distribution. Existing methods mainly rely on concatenation or the
Kronecker product, oversimplifying the interaction structure between modalities
and indicating a need to model more complex interactions. Additionally, the
joint distribution of latent representations with higher-order interactions is
underexplored. Copula is a powerful statistical structure for modelling the
interactions among variables, as it naturally bridges the joint distribution
and marginal distributions of multiple variables. We propose a novel
copula-driven multimodal learning framework, which focuses on learning the
joint distribution of various modalities to capture the complex interactions
among them. The key idea is to interpret the copula model as a tool to align
the marginal distributions of the modalities efficiently. By assuming a
Gaussian mixture distribution for each modality and a copula model on the joint
distribution, our model can generate accurate representations for missing
modalities. Extensive experiments on public MIMIC datasets demonstrate the
superior performance of our model over other competitors. The code is available
at https://github.com/HKU-MedAI/CMCM.

</details>


### [58] [A Probabilistic U-Net Approach to Downscaling Climate Simulations](https://arxiv.org/abs/2511.03197)
*Maryam Alipourhajiagha,Pierre-Louis Lemaire,Youssef Diouane,Julie Carreau*

Main category: cs.LG

TL;DR: 本文提出了一种基于概率U-Net的统计降尺度方法，用于将气候模型的输出从较粗的分辨率降尺度为较细的分辨率，以满足气候变影响研究的需求。通过评估四个不同的训练目标，发现WMSE-MS-SSIM在某些情况下对极端值具有较好的性能，而afCRPS更能捕捉到空间上的变化性。


<details>
  <summary>Details</summary>
Motivation: 气候模型输出通常在较粗的分辨率上产生，而气候变化影响研究常需要更高的空间分辨率。统计降尺度可以填补这一差距，因此本文采用概率U-Net进行改进，以适应气候研究的需求。

Method: 本文采用了一种结合确定性U-Net和变分隐空间的概率U-Net架构，用以捕捉可预测不确定性。对四个不同的训练目标（包括afCRPS和WMSE-MS-SSIM）进行了评估，探索了降水和温度从16倍粗分辨率降至精细分辨率的效果。

Result: 研究结果表明，WMSE-MS-SSIM对某些设置下的极端值表现良好，而afCRPS则更擅长描述跨尺度的空间变化。

Conclusion: 该研究表明，结合了确定性与概率方法的降尺度策略能够有效提高降水和温度预测的精准度，提供了改善气候模型输出分辨率的潜在途径。

Abstract: Climate models are limited by heavy computational costs, often producing
outputs at coarse spatial resolutions, while many climate change impact studies
require finer scales. Statistical downscaling bridges this gap, and we adapt
the probabilistic U-Net for this task, combining a deterministic U-Net backbone
with a variational latent space to capture aleatoric uncertainty. We evaluate
four training objectives, afCRPS and WMSE-MS-SSIM with three settings for
downscaling precipitation and temperature from $16\times$ coarser resolution.
Our main finding is that WMSE-MS-SSIM performs well for extremes under certain
settings, whereas afCRPS better captures spatial variability across scales.

</details>


### [59] [A Feedback-Control Framework for Efficient Dataset Collection from In-Vehicle Data Streams](https://arxiv.org/abs/2511.03239)
*Philipp Reis,Philipp Rigoll,Christian Steinhauser,Jacob Langner,Eric Sax*

Main category: cs.LG

TL;DR: 本文提出了FCDC数据收集范式，它将数据收集视为一个闭环控制系统，通过在线概率模型连续近似收集数据的分布状态，并根据反馈信号（如似然和马氏距离）动态调节样本保留，从而提高数据集的多样性，防止冗余积累。实验表明，FCDC可减少39.8%的数据存储，并提高25.9%的数据集平衡度。 


<details>
  <summary>Details</summary>
Motivation: 当前AI系统受限于数据的质量和多样性，许多数据集的收集方式在开放循环中累计冗余样本，导致存储效率低、标注成本高且泛化能力有限，因此提出了FCDC作为一种解决方法。 

Method: FCDC通过在线概率模型不断近似已收集数据分布状态，并根据反馈信号如似然和马氏距离来动态调节样本保留，从而在反馈机制下动态平衡探索与利用，保持数据集多样性，防止冗余积累。 

Result: 在合成数据集和真实数据流上进行的实验表明，FCDC可以提高数据集平衡度25.9%，减少39.8%的存储需求。 

Conclusion: 通过将数据收集视为可积极控制的过程，FCDC实现了数据收集阶段的自我调节、反馈驱动机制，为数据驱动的AI核心发展开创了新的前景。

Abstract: Modern AI systems are increasingly constrained not by model capacity but by
the quality and diversity of their data. Despite growing emphasis on
data-centric AI, most datasets are still gathered in an open-loop manner which
accumulates redundant samples without feedback from the current coverage. This
results in inefficient storage, costly labeling, and limited generalization. To
address this, this paper introduces \ac{FCDC}, a paradigm that formulates data
collection as a closed-loop control problem. \ac{FCDC} continuously
approximates the state of the collected data distribution using an online
probabilistic model and adaptively regulates sample retention using based on
feedback signals such as likelihood and Mahalanobis distance. Through this
feedback mechanism, the system dynamically balances exploration and
exploitation, maintains dataset diversity, and prevents redundancy from
accumulating over time. Besides showcasing the controllability of \ac{FCDC} on
a synthetic dataset, experiments on a real data stream show that \ac{FCDC}
produces more balanced datasets by $\SI{25.9}{\percent}$ while reducing data
storage by $\SI{39.8}{\percent}$. These results demonstrate that data
collection itself can be actively controlled, transforming collection from a
passive pipeline stage into a self-regulating, feedback-driven process at the
core of data-centric AI.

</details>


### [60] [A unified physics-informed generative operator framework for general inverse problems](https://arxiv.org/abs/2511.03241)
*Gang Bao,Yaohua Zang*

Main category: cs.LG

TL;DR: 本文介绍了一种新的生成神经算子框架IGNO，用于解决由偏微分方程（PDE）支配的逆问题。该框架能在缺少标注数据集和特定测量类型的情况下，解决逆问题，并在挑战性的逆问题中保持准确性、稳定性和可扩展性。同时，IGNO还能在不同噪声水平和未见过的目标上表现出色，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当测量数据稀疏、噪点较多时，或底层系数是高维或间断时，解决受偏微分方程支配的逆问题变得困难，现有深度学习方法在这些情况下大多不适用。因此，希望通过IGNO来克服现有方法的不足，提高处理此类问题的能力。这些挑战推动了IGNO的开发。

Method: IGNO包括两个主要部分：首先，它将高维间断系数场编码到低维潜在空间中，这一过程由神经算子解码器引导以重建系数和偏微分方程解；然后，训练完全基于物理约束，依靠偏微分方程残留物，同时逆问题解决经过高效的梯度导向优化在潜在空间中进行，并通过先验的归一化流模型加速。

Result: IGNO在一系列挑战性逆问题中展现了优越性能，如从解为基础的测量中恢复间断系数以及EIT问题（基于算子的测量）等，能够在噪音严重的条件下保持准确、稳定和可扩展性，其性能优于现有的最优方法，且在不同噪音水平和全新的未见过的目标上都能表现出色。

Conclusion: IGNO作为一个统一且强大的框架，能够解决广泛的计算科学领域的挑战性逆问题，证明了其作为实用科学工具的重要地位。

Abstract: Solving inverse problems governed by partial differential equations (PDEs) is
central to science and engineering, yet remains challenging when measurements
are sparse, noisy, or when the underlying coefficients are high-dimensional or
discontinuous. Existing deep learning approaches either require extensive
labeled datasets or are limited to specific measurement types, often leading to
failure in such regimes and restricting their practical applicability. Here, a
novel generative neural operator framework, IGNO, is introduced to overcome
these limitations. IGNO unifies the solution of inverse problems from both
point measurements and operator-valued data without labeled training pairs.
This framework encodes high-dimensional, potentially discontinuous coefficient
fields into a low-dimensional latent space, which drives neural operator
decoders to reconstruct both coefficients and PDE solutions. Training relies
purely on physics constraints through PDE residuals, while inversion proceeds
via efficient gradient-based optimization in latent space, accelerated by an a
priori normalizing flow model. Across a diverse set of challenging inverse
problems, including recovery of discontinuous coefficients from solution-based
measurements and the EIT problem with operator-based measurements, IGNO
consistently achieves accurate, stable, and scalable inversion even under
severe noise. It consistently outperforms the state-of-the-art method under
varying noise levels and demonstrates strong generalization to
out-of-distribution targets. These results establish IGNO as a unified and
powerful framework for tackling challenging inverse problems across
computational science domains.

</details>


### [61] [Extending Fair Null-Space Projections for Continuous Attributes to Kernel Methods](https://arxiv.org/abs/2511.03304)
*Felix Störck,Fabian Hinder,Barbara Hammer*

Main category: cs.LG

TL;DR: 该论文提出了一种针对连续公平性问题的新方法，将其应用于核方法，并展示了其在支持向量回归中的有效性。这种方法适用于连续保护属性，且与模型和公平性得分无关。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习系统被广泛整合到日常生活中，公平性变得愈加重要。现有文献大多数集中在离散的情况下评估潜在偏差，对于连续属性的文献较少。本文旨在解决连续保护属性的情况下的公平性问题，提高模型的适用性与效果。 

Method: 该研究采用了一种泛化的核方法来解决连续公平性问题，提出了针对连续保护属性且能够与模型和公平性得分无关的方法，配合支持向量回归使用。这是对现有文献中迭代空闲空间投影策略的改进。

Result: 实验结果表明，新提出的方法在多个数据集上表现良好，与当前其他方法相比具有竞争力或有所改进。 

Conclusion: 研究提供了处理连续保护属性情况下的模型和公平性得分无关的新方法，展示了其广泛适用性和优越性。

Abstract: With the on-going integration of machine learning systems into the everyday
social life of millions the notion of fairness becomes an ever increasing
priority in their development. Fairness notions commonly rely on protected
attributes to assess potential biases. Here, the majority of literature focuses
on discrete setups regarding both target and protected attributes. The
literature on continuous attributes especially in conjunction with regression
-- we refer to this as \emph{continuous fairness} -- is scarce. A common
strategy is iterative null-space projection which as of now has only been
explored for linear models or embeddings such as obtained by a non-linear
encoder. We improve on this by generalizing to kernel methods, significantly
extending the scope. This yields a model and fairness-score agnostic method for
kernel embeddings applicable to continuous protected attributes. We demonstrate
that our novel approach in conjunction with Support Vector Regression (SVR)
provides competitive or improved performance across multiple datasets in
comparisons to other contemporary methods.

</details>


### [62] [Diffusion Language Models are Super Data Learners](https://arxiv.org/abs/2511.03276)
*Jinjie Ni,Qian Liu,Longxu Dou,Chao Du,Zili Wang,Hang Yan,Tianyu Pang,Michael Qizhe Shieh*

Main category: cs.LG

TL;DR: 扩散语言模型在训练周期足够长且数据量有限时，能够超越自回归模型。这种优势随着数据量和模型规模的不同而变化，主要归因于三个因素：任何顺序建模、超密集计算和内置的蒙特卡洛增强。在大规模实验中，DLM表现尤为出色，甚至在计算预算、模型参数和数据量严格匹配的情况下也超过了AR模型。更重要的是，验证集交叉熵的增加并不一定导致下游表现下降。


<details>
  <summary>Details</summary>
Motivation: 研究的重点在于观察和分析在受限预训练条件下，扩散语言模型在特定数据量下能比自回归模型表现更优的趋势及其背后的原因。研究目的在于进一步理解DLM的工作机制，并探索其在不同条件下的潜力。

Method: 实验在严格控制的数据集和计算资源条件下进行，使用了多个DLM模型与自回归模型进行对比，评估两者在不同规模和质量的数据集及计算负载下的表现。特别关注了模型训练周期、数据量以及模型核心机制对最终性能的影响。

Result: 研究表明，当数据受限时，经过多轮迭代的双向去噪过程与任何顺序建模相结合，能够为扩散语言模型带来显著的优势，甚至在严格匹配自回归模型计算条件和参数的情况下也表现更优。此外，通过仅重复标准预训练数据却仍取得优秀性能的结果进一步证明了DLM的有效性。

Conclusion: 扩散语言模型具有超越自回归模型的潜力，在数据量有限的情况下尤为突出，这主要是由于其特有的模型机制和训练流程带来的。这些发现为后续研究提供了理论依据和应用方向，特别是在有限数据量的场景中，推动了自然语言处理领域的技术进步。

Abstract: Under strictly controlled pre-training settings, we observe a Crossover: when
unique data is limited, diffusion language models (DLMs) consistently surpass
autoregressive (AR) models by training for more epochs. The crossover shifts
later with more or higher-quality data, earlier with larger models, and
persists across dense and sparse architectures. We attribute the gains to three
compounding factors: (1) any-order modeling, (2) super-dense compute from
iterative bidirectional denoising, and (3) built-in Monte Carlo augmentation;
input or parameter noise improves AR under data constraint but cannot close the
gap. At scale, a 1.7B DLM trained with a ~1.5T-token compute budget on 10B
unique Python tokens overtakes an AR coder trained with strictly matched
settings. In addition, a 1B-parameter DLM achieves > 56% accuracy on HellaSwag
and > 33% on MMLU using only 1B tokens, without any special tricks, just by
repeating standard pre-training data. We also show that rising validation
cross-entropy does not imply degraded downstream performance in this regime.

</details>


### [63] [A Probabilistic Approach to Pose Synchronization for Multi-Reference Alignment with Applications to MIMO Wireless Communication Systems](https://arxiv.org/abs/2511.03280)
*Rob Romijnders,Gabriele Cesa,Christos Louizos,Kumar Pratik,Arash Behboodi*

Main category: cs.LG

TL;DR: 论文提出了一种新的算法来处理多参考对齐问题，通过将相对姿态作为隐患变量进行边缘化，从而移除全局对称性，提高了收敛性。该方法在实验中表现出更低的重建误差，且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 处理从分子成像到无线通信等领域的多参考对齐问题，特别是在冷冻电子显微镜、计算机视觉以及无线通信系统中普遍存在对齐和重建信号的需求。为解决这些领域中的对齐问题，需要一种新的方法来提升系统性能。论文动机是找到一种能够提高多参考对齐能力的新算法。

Method: 使用概率模型来处理多参考对齐问题，提出了一种将相对姿态作为隐患变量进行边缘化的处理方法。这种方法将全局对称性移除，简化了问题处理，提升了解决方案的直接性和收敛性，同时减少了计算成本，避免了集中化方法的三次运算复杂度。此外，算法通过循环一致性进一步减少了计算负担，提高了效率。

Result: 实验结果显示，所提出的算法在多参考对齐问题上表现出更好的性能，具体表现为更低的重建误差，并且由于计算过程的去中心化，计算成本更低，显示出优秀的实用价值。

Conclusion: 通过采用概率模型并利用相对姿态作为隐患变量来边缘化处理多参考对齐问题，论文提供了一种有效的方法来解决这些问题，实验结果表明这种方法在多个实验设置下均表现出了更好的性能和更低的重建误差。

Abstract: From molecular imaging to wireless communications, the ability to align and
reconstruct signals from multiple misaligned observations is crucial for system
performance. We study the problem of multi-reference alignment (MRA), which
arises in many real-world problems, such as cryo-EM, computer vision, and, in
particular, wireless communication systems. Using a probabilistic approach to
model MRA, we find a new algorithm that uses relative poses as nuisance
variables to marginalize out -- thereby removing the global symmetries of the
problem and allowing for more direct solutions and improved convergence. The
decentralization of this approach enables significant computational savings by
avoiding the cubic scaling of centralized methods through cycle consistency.
Both proposed algorithms achieve lower reconstruction error across experimental
settings.

</details>


### [64] [SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration](https://arxiv.org/abs/2511.03344)
*Elif Arslan,Jacobus G. M. van der Linden,Serge Hoogendoorn,Marco Rinaldi,Emir Demirović*

Main category: cs.LG

TL;DR: 一种称为SORTD的新框架被提出，用于提高稀疏决策树学习的可扩展性，可以有效地枚举Rashomon集合中的决策树，从而在任何实际应用中使探索Rashomon集合变得更加实用。SORTD框架可以根据目标值顺序枚举决策树从而使得该框架具有任意时间性能，并且可以处理任何可分离且完全有序的目标函数。实验表明，与现有技术相比，SORTD可以加快运行时间多达两个数量级。


<details>
  <summary>Details</summary>
Motivation: 稀疏决策树学习旨在找到在大小限制内的最准确的单一决策树，但由于最优决策树的搜索是NP难的，所以需要一种新方法来枚举性能相似但结构不同的决策树集合（即Rashomon集合），而现有的方法耗时过多，故发明了SORTD来解决这个问题。

Method: 提出了一种称为SORTD的新框架，该框架可以迅速枚举出Rashomon集合中的决策树，且这些树是按照目标值排序的。SORTD是第一个不受限于特定目标函数的枚举框架，它可以处理任何可分离且完全有序的目标函数。此外，SORTD允许对枚举的树集使用其他可分离的目标函数进行后续评估，并且具有任意时间性能。

Result: 实验结果显示，与现有技术相比，SORTD方法的运行时间提高了两个数量级。SORTD框架是对探索Rashomon集合的一个改进，可以使实际应用中稀疏决策树的学习更加有用、更加实际。SORTD可以计算任何可分离且完全有序的目标函数的Rashomon集合，并支持使用其他可分离的目标函数进行后续评估。

Conclusion: 通过SORTD框架，可以更加有效地探索决策树的Rashomon集合，提高了稀疏决策树学习的实用性和可扩展性，是高风险应用的理想选择。

Abstract: Sparse decision tree learning provides accurate and interpretable predictive
models that are ideal for high-stakes applications by finding the single most
accurate tree within a (soft) size limit. Rather than relying on a single
"best" tree, Rashomon sets-trees with similar performance but varying
structures-can be used to enhance variable importance analysis, enrich
explanations, and enable users to choose simpler trees or those that satisfy
stakeholder preferences (e.g., fairness) without hard-coding such criteria into
the objective function. However, because finding the optimal tree is NP-hard,
enumerating the Rashomon set is inherently challenging. Therefore, we introduce
SORTD, a novel framework that improves scalability and enumerates trees in the
Rashomon set in order of the objective value, thus offering anytime behavior.
Our experiments show that SORTD reduces runtime by up to two orders of
magnitude compared with the state of the art. Moreover, SORTD can compute
Rashomon sets for any separable and totally ordered objective and supports
post-evaluating the set using other separable (and partially ordered)
objectives. Together, these advances make exploring Rashomon sets more
practical in real-world applications.

</details>


### [65] [DQN Performance with Epsilon Greedy Policies and Prioritized Experience Replay](https://arxiv.org/abs/2511.03670)
*Daniel Perkins,Oscar J. Escobar,Luke Green*

Main category: cs.LG

TL;DR: 研究了有限环境中Deep Q-Networks(DQN), 重点关注epsilon-greedy探索策略和优先经验回放对学习效率、收敛行为和奖励优化的影响。研究发现优先经验回放可以加速收敛并提高回报。


<details>
  <summary>Details</summary>
Motivation: 希望更好地理解epsilon-greedy探索策略和优先经验回放在有限环境中DQN中的影响，从而为资源受限环境下的强化学习提供实用建议。

Method: 通过系统实验评估epsilon衰减时间表的变化如何影响DQN的学习效率、收敛行为和奖励优化，同时比较了均匀、无回放和优先策略下的仿真结果。

Result: 研究表明优先经验回放可以导致更快的收敛和更高的回报，这表明在训练DQN时，探索策略和记忆管理之间存在权衡和交互作用。

Conclusion: 研究结果强调了探索策略和记忆管理之间的权衡，提出了在资源受限环境下进行稳健的强化学习的实用建议。

Abstract: We present a detailed study of Deep Q-Networks in finite environments,
emphasizing the impact of epsilon-greedy exploration schedules and prioritized
experience replay. Through systematic experimentation, we evaluate how
variations in epsilon decay schedules affect learning efficiency, convergence
behavior, and reward optimization. We investigate how prioritized experience
replay leads to faster convergence and higher returns and show empirical
results comparing uniform, no replay, and prioritized strategies across
multiple simulations. Our findings illuminate the trade-offs and interactions
between exploration strategies and memory management in DQN training, offering
practical recommendations for robust reinforcement learning in
resource-constrained settings.

</details>


### [66] [Structured Matrix Scaling for Multi-Class Calibration](https://arxiv.org/abs/2511.03685)
*Eugène Berta,David Holzmüller,Michael I. Jordan,Francis Bach*

Main category: cs.LG

TL;DR: 本文提出了在多类别校准时使用结构化正则化、鲁棒预处理和高效优化来管理偏差-方差权衡的新方法，这些方法超越了常见的基于逻辑回归的校准技术，并提供了现成的开源实现。


<details>
  <summary>Details</summary>
Motivation: 本文从理论上论证了基于逻辑回归的参数校准函数在二元分类和多类分类中的应用，并指出了使用更复杂的校准方法在多类校准时面临的挑战，即参数数量的增加和有限校准数据可能导致过拟合的问题。

Method: 通过广泛的实验，本文展示了使用结构化正则化、鲁棒预处理和高效优化来管理偏差-方差权衡的方法在多类别校准中的有效性，这些方法超越了常见的基于逻辑回归的校准技术，并提供了现成的开源实现。

Result: 本文提出的方法在多类别校准中获得了比现有基于逻辑回归的校准技术更显著的结果改进。

Conclusion: 本文的工作为解决多类别校准时面临的挑战提供了有效方法，并通过开放式源代码包的形式使这些方法易于使用。

Abstract: Post-hoc recalibration methods are widely used to ensure that classifiers
provide faithful probability estimates. We argue that parametric recalibration
functions based on logistic regression can be motivated from a simple
theoretical setting for both binary and multiclass classification. This insight
motivates the use of more expressive calibration methods beyond standard
temperature scaling. For multi-class calibration however, a key challenge lies
in the increasing number of parameters introduced by more complex models, often
coupled with limited calibration data, which can lead to overfitting. Through
extensive experiments, we demonstrate that the resulting bias-variance tradeoff
can be effectively managed by structured regularization, robust preprocessing
and efficient optimization. The resulting methods lead to substantial gains
over existing logistic-based calibration techniques. We provide efficient and
easy-to-use open-source implementations of our methods, making them an
attractive alternative to common temperature, vector, and matrix scaling
implementations.

</details>


### [67] [Reinforcement Learning Using known Invariances](https://arxiv.org/abs/2511.03473)
*Alexandru Cioba,Aya Kayal,Laura Toni,Sattar Vakili,Alberto Bernacchia*

Main category: cs.LG

TL;DR: 本论文提出了一种在强化学习中利用环境对称性的理论和算法框架，通过开发了一种基于核函数的强化学习变体（LSVI），该变体利用不变核函数来编码奖励和过渡动态中的不变性，从而提高了学习效率。实验表明，这种方法在特定任务中比标准核函数方法性能更好，证明了结构先验在设计更高效的强化学习算法中的价值。


<details>
  <summary>Details</summary>
Motivation: 在实际的强化学习问题中，环境可能具有固有的对称性，可以利用这些对称性来提高学习效率。因此，通过开发一种新的基于核学习的强化学习方法来充分利用这些对称性是一种有效的策略。

Method: 论文提出了一个基于乐观的最小二乘价值迭代的对称性感知变体，使用不变核函数来编码奖励和过渡动态中的不变性。通过这种设置，算法可以更好地利用环境中的对称性。

Result: 理论分析证明了在使用不变核函数的方法下，可以获得比传统方法更少的信息增益和覆盖数，从而提高了样本效率。实验验证了理论改进，在自定义的Frozen Lake环境和2D放置设计问题中，对称性感知的RL方法在性能上明显优于标准的核函数方法。

Conclusion: 研究证明了在设计更高效的强化学习算法时，利用结构先验（如对称性）的重要性，并展示了通过这种方式可以显著提高学习效率。

Abstract: In many real-world reinforcement learning (RL) problems, the environment
exhibits inherent symmetries that can be exploited to improve learning
efficiency. This paper develops a theoretical and algorithmic framework for
incorporating known group symmetries into kernel-based RL. We propose a
symmetry-aware variant of optimistic least-squares value iteration (LSVI),
which leverages invariant kernels to encode invariance in both rewards and
transition dynamics. Our analysis establishes new bounds on the maximum
information gain and covering numbers for invariant RKHSs, explicitly
quantifying the sample efficiency gains from symmetry. Empirical results on a
customized Frozen Lake environment and a 2D placement design problem confirm
the theoretical improvements, demonstrating that symmetry-aware RL achieves
significantly better performance than their standard kernel counterparts. These
findings highlight the value of structural priors in designing more
sample-efficient reinforcement learning algorithms.

</details>


### [68] [NAP: Attention-Based Late Fusion for Automatic Sleep Staging](https://arxiv.org/abs/2511.03488)
*Alvise Dei Rossi,Julia van der Meer,Markus H. Schmidt,Claudio L. A. Bassetti,Luigi Fiorillo,Francesca Faraci*

Main category: cs.LG

TL;DR: 本文介绍了一种新的注意力机制模型NAP，用于处理多模态的多导睡眠图信号，并实现了零样本泛化的效果。NAP能够适应不同的输入维度，通过融合来自预训练单通道模型的输出，该模型在多个数据集上均表现出色，并达到了最先进的零样本泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理多导睡眠图数据时，有限制地使用固定的模态集合或通道，未能充分利用其内在的多模态特性。因此，我们引入NAP模型，以应对这一局限性，提高多模态数据处理的效果。

Method: NAP是一种基于注意力机制的模型，学习通过一个三轴注意力机制集合同多个预测流，该机制捕获时间、空间和预测器层次的依赖关系。NAP被训练以适应不同的输入维度，并通过融合预训练单通道模型的输出实现其功能。

Result: NAP在多个数据集上表现出超越单独预测器和简单合并预测器的效果，并实现了零样本泛化的最佳性能。

Conclusion: 该方法不仅适用于自动睡眠分期，还可能应用于其他多模态生理信号处理任务中。

Abstract: Polysomnography signals are highly heterogeneous, varying in modality
composition (e.g., EEG, EOG, ECG), channel availability (e.g., frontal,
occipital EEG), and acquisition protocols across datasets and clinical sites.
Most existing models that process polysomnography data rely on a fixed subset
of modalities or channels and therefore neglect to fully exploit its inherently
multimodal nature. We address this limitation by introducing NAP (Neural
Aggregator of Predictions), an attention-based model which learns to combine
multiple prediction streams using a tri-axial attention mechanism that captures
temporal, spatial, and predictor-level dependencies. NAP is trained to adapt to
different input dimensions. By aggregating outputs from frozen, pretrained
single-channel models, NAP consistently outperforms individual predictors and
simple ensembles, achieving state-of-the-art zero-shot generalization across
multiple datasets. While demonstrated in the context of automated sleep staging
from polysomnography, the proposed approach could be extended to other
multimodal physiological applications.

</details>


### [69] [Why Less is More (Sometimes): A Theory of Data Curation](https://arxiv.org/abs/2511.03492)
*Elvis Dohmatob,Mohammad Pezeshki,Reyhane Askari-Hemmat*

Main category: cs.LG

TL;DR: 本文提出了一种理论框架，用于解决现代机器学习中的一个核心悖论：何时使用较少的数据更为有利。研究表明，在一定的条件下，小规模的精选数据集可以优于大规模的数据集，并给出了具体的相变曲线，其结果在ImageNet数据集上得到了验证。


<details>
  <summary>Details</summary>
Motivation: 面对挑战传统“更多即更好”的经典尺度定律的方法如LIMO和s1，本文提出并研究了用数据克选策略解决现代机器学习中的核心悖论，即在何时应当使用较少的数据而非更多数据的问题。这个问题在当前机器学习的应用中变得尤为重要。

Method: 研究了由不完美的oracle根据难度和正确性选择训练实例的数据克选策略，提出了在标签不可知和标签可知的情况下用于精确测试误差的精确尺度定律曲线。该研究还提供了小规模精选数据集在这种条件下优于大规模集的具体相变曲线。通过理论分析，本文证明了标签选择性地对于提高模型性能的程度。此外，该框架还为近年观察到的大型语言模型数学推理中的矛盾性数据资料策略提供了原则性的解释。最后，通过在ImageNet上的实验验证了理论推测和假设。

Result: 研究表明，当数据集被精细的选择和调整时，在一定条件下小规模精选数据集可以比大规模数据集表现更好，得到了用于解释何时时刻应减少数据使用的理论框架。实验结果证实了理论预测，证明了在某些条件下，小规模数据集可以提高模型的准确率，甚至可以缓解模型崩溃。

Conclusion: 研究建立了一个理论框架，准确地定义了何时减少数据集是有益的，通过推导出标签选择性和数据集规模的精确相变曲线，以及在ImageNet上的验证，说明了在特定条件下，有选择地减少数据不仅能提高模型性能，还能防止模型崩溃。

Abstract: This paper introduces a theoretical framework to resolve a central paradox in
modern machine learning: When is it better to use less data? This question has
become critical as classical scaling laws suggesting ``more is more'' (Sun et
al., 2025) are challenged by methods like LIMO (``less is more'') and s1 (Ye et
al., 2025; Muenighoff et al., 2025), which achieve superior performance with
small, aggressively curated datasets. Here, we study data curation strategies
where an imperfect oracle selects the training examples according to their
difficulty and correctness. Our results provide exact scaling law curves for
test error under both label-agnostic and label-aware curation rules, revealing
when and why keeping only a subset of data can improve generalization. In
contrast to classical scaling laws, we show that under certain conditions,
small curated datasets can outperform full datasets, and we provide analytical
conditions for this by deriving precise phase transition curves tied to data
size and quality. We validate these theoretical claims with empirical results
on ImageNet, confirming our predictions about when curation improves accuracy
and can even mitigate model collapse. Furthermore, our framework provides a
principled explanation for the contradictory curation strategies recently
observed in LLM mathematical reasoning.

</details>


### [70] [Learning Without Critics? Revisiting GRPO in Classical Reinforcement Learning Environments](https://arxiv.org/abs/2511.03527)
*Bryan L. M. de Oliveira,Felipe V. Frujeri,Marcos P. C. M. Queiroz,Luana G. B. Martins,Telma W. de L. Soares,Luckeciano C. Melo*

Main category: cs.LG

TL;DR: 该研究首次系统地研究了Group Relative Policy Optimization (GRPO)在单一任务强化学习环境中的表现，包括离散和连续控制任务。结果表明，对于远期任务来说，学习到的critic仍然是必要的，而在短期任务中，GRPO表现出更好的性能。此外，实验还发现，较小的分组规模在GRPO中表现更好，而较大的折扣系数则有利于GRPO的表现，除了HalfCheetah任务外，在该任务中早期终止的缺乏使得中等程度的折扣更有利。这些发现揭示了GRPO在经典控制中的限制，以及它作为学习价值函数的替代方案在特定条件下的可行性。


<details>
  <summary>Details</summary>
Motivation: 对于原论文，去掉学习critic并使用轨迹组之间的相对优势估计作为替代方法是否行得通提出质疑。系统研究了在标准单一任务强化学习环境中的Group Relative Policy Optimization (GRPO)的优势和局限。这不仅对GRPO本身有价值，也对诸如策略梯度方法等更广泛的方法中的学习模块的作用提供了深刻的见解。

Method: 通过系统地控制实验，分别隔离基础线、时消除、分组采样等方式研究，验证了各种可能的情况。本研究在一个标准的单一任务强化学习环境中评估GRPO的表现，包括实验环境是否为离散控制或连续控制，学习到的批评家是否存在，折扣因子的选择和小组尺寸的大小。

Result: 这篇论文发现对于长期任务，学习到的榜样依然是非常重要的，而在短期任务中，GRPO可以表现出更好的性能而不依赖训练出的baseline。实验还表明GRPO在采用较小的分组规模时表现更好，而较大的折扣系数（除了half cheetah任务中），能展示出GRPO的更强优势。

Conclusion: 这项系统的研究展示了GRPO在标准强化学习环境中在特定条件下的可行性和它的局限性，揭示了学习基线在贪婪策略方法中的重要性，并提供了GRPO优化的建议策略，进而可能为对其他基于政策梯度的学习方法提供了有价值的参考。

Abstract: Group Relative Policy Optimization (GRPO) has emerged as a scalable
alternative to Proximal Policy Optimization (PPO) by eliminating the learned
critic and instead estimating advantages through group-relative comparisons of
trajectories. This simplification raises fundamental questions about the
necessity of learned baselines in policy-gradient methods. We present the first
systematic study of GRPO in classical single-task reinforcement learning
environments, spanning discrete and continuous control tasks. Through
controlled ablations isolating baselines, discounting, and group sampling, we
reveal three key findings: (1) learned critics remain essential for
long-horizon tasks: all critic-free baselines underperform PPO except in
short-horizon environments like CartPole where episodic returns can be
effective; (2) GRPO benefits from high discount factors (gamma = 0.99) except
in HalfCheetah, where lack of early termination favors moderate discounting
(gamma = 0.9); (3) smaller group sizes outperform larger ones, suggesting
limitations in batch-based grouping strategies that mix unrelated episodes.
These results reveal both the limitations of critic-free methods in classical
control and the specific conditions where they remain viable alternatives to
learned value functions.

</details>


### [71] [Byzantine-Robust Federated Learning with Learnable Aggregation Weights](https://arxiv.org/abs/2511.03529)
*Javad Parsa,Amir Hossein Daghestani,André M. H. Teixeira,Mikael Johansson*

Main category: cs.LG

TL;DR: 提出了一种新的抗拜占庭攻击的联邦学习优化问题，该方法通过在聚合过程中引入自适应加权，将聚合权重作为可学习参数，以增强联邦学习的鲁棒性。实验结果表明，即使在高度异质数据和大量恶意客户端的场景下，该方法也能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中存在恶意客户端（拜占庭节点）会导致训练的全球模型不准确，特别是在客户端数据分布异质的情况下。为了提高联邦学习的鲁棒性，本文提出了新的拜占庭抗性联邦学习优化方法。

Method: 提出一种新的拜占庭鲁棒联邦学习优化方法，引入聚合过程中自适应加权方法，视为可学习参数，并与全局模型参数共同优化，基于此提出了交替最小化算法，具有在对抗攻击下的强收敛保证。

Result: 实验结果表明，所提出的方法在不同数据集和攻击场景下，特别是高度异质数据和大量恶意客户的情况下，始终优于现有方法。

Conclusion: 结合新的拜占庭鲁棒性联邦学习优化方法和交替最小化算法，可以提高联邦学习下的抗拜占庭鲁棒性，特别是在高度异质数据和大量恶意客户威胁的情况下。

Abstract: Federated Learning (FL) enables clients to collaboratively train a global
model without sharing their private data. However, the presence of malicious
(Byzantine) clients poses significant challenges to the robustness of FL,
particularly when data distributions across clients are heterogeneous. In this
paper, we propose a novel Byzantine-robust FL optimization problem that
incorporates adaptive weighting into the aggregation process. Unlike
conventional approaches, our formulation treats aggregation weights as
learnable parameters, jointly optimizing them alongside the global model
parameters. To solve this optimization problem, we develop an alternating
minimization algorithm with strong convergence guarantees under adversarial
attack. We analyze the Byzantine resilience of the proposed objective. We
evaluate the performance of our algorithm against state-of-the-art
Byzantine-robust FL approaches across various datasets and attack scenarios.
Experimental results demonstrate that our method consistently outperforms
existing approaches, particularly in settings with highly heterogeneous data
and a large proportion of malicious clients.

</details>


### [72] [Flat Minima and Generalization: Insights from Stochastic Convex Optimization](https://arxiv.org/abs/2511.03548)
*Matan Schliserman,Shira Vansover-Hager,Tomer Koren*

Main category: cs.LG

TL;DR: 本研究探讨了在非负、β平滑的随机凸优化环境中，flat minima和generalization之间的关系，发现了即使是用sharpness-aware算法找到的flat minima，其population风险也可能很高，generalization性能不佳。同时，SAM可能收敛到尖锐的最小值并具有较高的population风险。最终，通过算法稳定性技术建立了SA-GD和SAM的风险上限。


<details>
  <summary>Details</summary>
Motivation: 学习理论的一个核心目标是理解学习算法的泛化行为。有一种日益流行的观点认为，学习算法在实践中表现良好是因为它们趋于收敛到flat minima，这些flat minima一直与大幅改进的泛化性能相关。然而，对于flat minima是否真正改善generalization性能仍需深入研究，特别是在convex优化环境下的特性。因此，此研究旨在深入探索flat minima与算法泛化之间的关系，以及sharpness-aware算法如SA-GD和SAM的泛化性能。

Method: 在非负、β平滑的随机convex优化环境中，研究flat minima的generalization行为，并分析了两种sharpness-aware算法：Sharpness-Aware Gradient Descent (SA-GD) 和 Sharpness-Aware Minimization (SAM)。通过理论分析和模拟实验，评估了这些算法在找到flat和sharp minima时的population风险和泛化性能。还利用了算法稳定性技术来建立population风险的上界。

Result: 即使是flat minima，其population风险在特定情况下也能达到Ω(1)，表明flat minima并不总是带来良好的泛化性能。对于SA-GD，尽管它能找到flat minima，但其population风险可能高达Ω(1)。对于SAM，它可能收敛到sharp minima并导致高population风险。通过算法稳定性技术，建立了SA-GD和SAM的风险上界。

Conclusion: 研究揭示了flat minima与算法泛化行为间的复杂关系，在特定凸优化环境下，并非所有的flat minima都能保证好的泛化性能。因此，sharpness-aware算法并不能作为直接改善generalization性能的方法论推荐。此外，通过算法稳定性技术，提供了一种评估这些算法的泛化上界的方法。

Abstract: Understanding the generalization behavior of learning algorithms is a central
goal of learning theory. A recently emerging explanation is that learning
algorithms are successful in practice because they converge to flat minima,
which have been consistently associated with improved generalization
performance. In this work, we study the link between flat minima and
generalization in the canonical setting of stochastic convex optimization with
a non-negative, $\beta$-smooth objective. Our first finding is that, even in
this fundamental and well-studied setting, flat empirical minima may incur
trivial $\Omega(1)$ population risk while sharp minima generalizes optimally.
Then, we show that this poor generalization behavior extends to two natural
''sharpness-aware'' algorithms originally proposed by Foret et al. (2021),
designed to bias optimization toward flat solutions: Sharpness-Aware Gradient
Descent (SA-GD) and Sharpness-Aware Minimization (SAM). For SA-GD, which
performs gradient steps on the maximal loss in a predefined neighborhood, we
prove that while it successfully converges to a flat minimum at a fast rate,
the population risk of the solution can still be as large as $\Omega(1)$,
indicating that even flat minima found algorithmically using a sharpness-aware
gradient method might generalize poorly. For SAM, a computationally efficient
approximation of SA-GD based on normalized ascent steps, we show that although
it minimizes the empirical loss, it may converge to a sharp minimum and also
incur population risk $\Omega(1)$. Finally, we establish population risk upper
bounds for both SA-GD and SAM using algorithmic stability techniques.

</details>


### [73] [TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and Retrieval](https://arxiv.org/abs/2511.03570)
*Günther Schindler,Maximilian Schambach,Michael Medek,Sam Thelin*

Main category: cs.LG

TL;DR: 我们提出了一种名为TabGemma的无模式嵌入式学习方法，用于处理包含文本、数字和分类字段的表格预测。通过规范化的数值表示和预训练，TabGemma在多个分类任务上建立了新的基准，并在语义丰富的任务上表现出了有竞争力的效果。然而，在回归任务上，随着数据量的增加，它的表现稍逊于传统的方法，这表明数值建模和长上下文扩展仍然需要进一步的研究。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型的预训练技术不断发展，但在表格预测中对于混合类型的字段的处理，特别是在数值处理和上下文限制的问题上，仍有很大挑战。因此，本论文旨在引入一种自适应学习方案，以更好地利用大规模语言模型的能力进行表格预测，尤其是在数值字段的处理和上下文大小的限制问题上提供解决方案。

Method: 我们提出了TabGemma，一个不依赖于模式的预训练模型，它将表格行视为序列，并提出了一种使用科学符号对数字进行规范化的方法。我们还引入了进一步的微调，使用大规模的真实世界数据集和目标填充目标。在推理阶段，我们使用了一个紧凑的n元组检索方法来选择包含在128k标记窗口内的信息行。通过这种方式，TabGemma能够在大量的预测条件下灵活地工作，而无需过多人工干预。

Result: 实验结果表明，TabGemma在多个分类基准测试上建立了新的状态，并且随着上下文行数量的增加而持续改进。同时，在回归任务上，它在样本数量较少的情况下表现出竞争力，但在样本数量大的情况下，其表现不如传统的方法。这表明大规模语言模型用于表格预测仍然是一个很有前景的研究领域，但在数值处理和上下文规模上仍然有改进空间。

Conclusion: TabGemma证明了大规模语言模型可以处理复杂的表格数据，特别是在数值处理和上下文大小的问题上，但同时也揭示了模型在回归任务上的限制。这对于推动数值建模技术和上下文扩展技术的发展提出了挑战。

Abstract: We study LLMs for tabular prediction with mixed text, numeric, and
categorical fields. We introduce TabGemma, a schema-agnostic in-context learner
that treats rows as sequences and tackles two practical hurdles when adapting
pretrained LLMs for tabular predictions: unstable numeric tokenization and
limited context size. We propose to canonicalize numbers via signed scientific
notation and continue pretraining of a 12B Gemma 3 model with a target
imputation objective using a large-scale real world dataset. For inference, we
use a compact n-gram-based retrieval to select informative exemplars that fit
within a 128k-token window.
  On semantically rich benchmarks, TabGemma establishes a new state of the art
on classification across low- and high-data regimes and improves monotonically
with more context rows. For regression, it is competitive at small sample sizes
but trails conventional approaches as data grows. Our results show that LLMs
can be effective tabular in-context learners on highly semantic tasks when
paired with dedicated numeric handling and context retrieval, while motivating
further advances in numeric modeling and long-context scaling.

</details>


### [74] [Towards Formalizing Reinforcement Learning Theory](https://arxiv.org/abs/2511.03618)
*Shangtong Zhang*

Main category: cs.LG

TL;DR: 本文使用Lean 4定理证明器和Mathlib库正式化了基于马可夫样本的$Q$-学习和线性时序差分（TD）学习的几乎处处收敛性，这一工作为形式化收敛的强化学习结果提供了重要步骤。相关代码可在https://github.com/ShangtongZhang/rl-theory-in-lean访问。


<details>
  <summary>Details</summary>
Motivation: 在强化学习领域早期发展中，$Q$-学习和线性TD学习的收敛性研究是一个主要的研究方向，而如今这种研究又重新受到广泛关注。本文使用Lean 4定理证明器和Mathlib库正式验证了这些算法的几乎处处收敛性。这种研究不仅能加深我们的理解，而且为形式化验证提供了重要尝试。

Method: 本文在Robbins-Siegmund定理的基础之上，使用Lean 4定理证明器和Mathlib库正式化了$Q$-学习和线性TD学习的收敛性验证，并且这些算法是基于马可夫样本的。

Result: 本文正式验证了$Q$-学习和线性TD学习在基于马可夫样本条件下的几乎处处收敛性，为这些算法的进一步形式化研究提供了框架和基础。代码及详细证明可以在指定的GitHub仓库查看。

Conclusion: 本文成功地使用Lean 4和Mathlib库验证了$Q$-learning和线性TD学习的几乎处处收敛性。未来的工作可以在此基础上进一步研究收敛速度和其他形式的收敛性。

Abstract: In this paper, we formalize the almost sure convergence of $Q$-learning and
linear temporal difference (TD) learning with Markovian samples using the Lean
4 theorem prover based on the Mathlib library. $Q$-learning and linear TD are
among the earliest and most influential reinforcement learning (RL) algorithms.
The investigation of their convergence properties is not only a major research
topic during the early development of the RL field but also receives increasing
attention nowadays. This paper formally verifies their almost sure convergence
in a unified framework based on the Robbins-Siegmund theorem. The framework
developed in this work can be easily extended to convergence rates and other
modes of convergence. This work thus makes an important step towards fully
formalizing convergent RL results. The code is available at
https://github.com/ShangtongZhang/rl-theory-in-lean.

</details>


### [75] [nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN](https://arxiv.org/abs/2511.03634)
*Alexander Pfefferle,Johannes Hog,Lennart Purucker,Frank Hutter*

Main category: cs.LG

TL;DR: nanoTabPFN是一个简化且轻量级的TabPFN v2架构实现，使用预生成的训练数据，使其更易于被学生和研究人员使用，并大幅降低了训练对计算资源的需求。在小数据集上，它可以在单个GPU上进行一分钟的预训练，达到传统机器学习基线性能，速度比TabPFN v2快160,000倍。代码可在https://github.com/automl/nanoTabPFN访问。


<details>
  <summary>Details</summary>
Motivation: 现有开源的表格基础模型实现复杂，通常包含超过10,000行代码，缺乏架构文档或代码质量，难以理解和调整以适应新的实验。为使这类模型对学生和研究人员更加友好，我们推出了nanoTabPFN，使其训练所需计算资源大大减少，从而适应教学目的。

Method: nanoTabPFN简化了TabPFN v2架构，并配套使用了预生成训练数据的训练循环，确保模型易于理解和使用。

Result: 在小数据场景下，nanoTabPFN在单个GPU上只需一分钟预训练，便可以达到传统机器学习基线的性能，预训练速度比TabPFN v2快160,000倍，极大减少了对大型计算资源的需求。

Conclusion: nanoTabPFN的设计与实现让学生和研究人员更易于理解与使用表格基础模型，并为入门级用户提供了入门教学的可能。代码开源可直接访问。

Abstract: Tabular foundation models such as TabPFN have revolutionized predictive
machine learning for tabular data. At the same time, the driving factors of
this revolution are hard to understand. Existing open-source tabular foundation
models are implemented in complicated pipelines boasting over 10,000 lines of
code, lack architecture documentation or code quality. In short, the
implementations are hard to understand, not beginner-friendly, and complicated
to adapt for new experiments. We introduce nanoTabPFN, a simplified and
lightweight implementation of the TabPFN v2 architecture and a corresponding
training loop that uses pre-generated training data. nanoTabPFN makes tabular
foundation models more accessible to students and researchers alike. For
example, restricted to a small data setting it achieves a performance
comparable to traditional machine learning baselines within one minute of
pre-training on a single GPU (160,000x faster than TabPFN v2 pretraining). This
eliminated requirement of large computational resources makes pre-training
tabular foundation models accessible for educational purposes. Our code is
available at https://github.com/automl/nanoTabPFN.

</details>


### [76] [Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online RL](https://arxiv.org/abs/2511.03695)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: 离线强化学习（RL）允许使用固定数据进行训练，但部署到动态环境中时，由于分布偏移和不可靠的价值估计问题，离线学习的策略往往会表现不佳。我们引入了一种名为行为自适应Q学习（BAQ）的框架，以实现从离线到在线RL的平滑且可靠的过渡。BAQ通过将来自离线数据的隐式行为模型用于在线微调时提供行为一致性信号。这种方法在标准基准测试中，比之前的方法表现更优，恢复更快，更稳健，总体性能更高。研究结果表明，隐式行为适应是可靠地部署实际世界策略的一种稳健和实际的解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决离线强化学习策略在动态环境下因分布偏移和不可靠价值估计而导致的应用性能问题，提出一种从离线学习平滑过渡到在线学习的方法。

Method: 介绍了一种新方法——行为自适应Q学习(BAQ)，该方法利用离线数据中的隐式行为模型，在线微调时提供行为一致性信号，并设计了一个双重目标损失函数，根据不确定性情况调整离线与在线策略的一致性。

Result: BAQ在标准基准测试中，表现出比先前方法更快的恢复速度，更高的稳健性和整体性能。结果显示，这表明了隐式行为适应是一种稳健且实际的解决方案，可用于可靠地部署实际世界策略。

Conclusion: 我们证明，通过行为自适应机制可以解决从离线到在线的学习中的主要问题，例如分布偏移和价值估算误差，这种机制不仅能稳定在线更新，还能加速适应新场景，是一个稳健且实际的方法，有助于可靠地部署真实世界的策略。

Abstract: Offline reinforcement learning (RL) enables training from fixed data without
online interaction, but policies learned offline often struggle when deployed
in dynamic environments due to distributional shift and unreliable value
estimates on unseen state-action pairs. We introduce Behavior-Adaptive
Q-Learning (BAQ), a framework designed to enable a smooth and reliable
transition from offline to online RL. The key idea is to leverage an implicit
behavioral model derived from offline data to provide a behavior-consistency
signal during online fine-tuning. BAQ incorporates a dual-objective loss that
(i) aligns the online policy toward the offline behavior when uncertainty is
high, and (ii) gradually relaxes this constraint as more confident online
experience is accumulated. This adaptive mechanism reduces error propagation
from out-of-distribution estimates, stabilizes early online updates, and
accelerates adaptation to new scenarios. Across standard benchmarks, BAQ
consistently outperforms prior offline-to-online RL approaches, achieving
faster recovery, improved robustness, and higher overall performance. Our
results demonstrate that implicit behavior adaptation is a principled and
practical solution for reliable real-world policy deployment.

</details>


### [77] [Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2511.03710)
*Guanning Zeng,Zhaoyi Zhou,Daman Arora,Andrea Zanette*

Main category: cs.LG

TL;DR: 本文提出了一种基于收缩估计的奖励基准方法，用于改善Reinforcement Learning with Verifiable Rewards (RLVR)中的政策梯度估计，提高了训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 在强化学习的梯度方法中，通常使用每提示任务的奖励平均值来稳定训练。但这种方法在小样本情况下估计误差较大，作者受到斯坦因悖论的启发，提出了一种结合每提示和跨提示奖励平均的收缩估计方法来提高估计准确性。

Method: 提出了一种新的基准方法，该方法使用收缩估计器结合每提示和跨提示奖励平均，以改进整体每提示奖励平均估计精度。理论分析证明该方法能有效降低政策梯度估计的方差。此方法无需额外超参数或计算，是一个现成的替换标准经验平均基准的方法。

Result: 实验表明，对比传统经验平均基准，新的收缩基准方法可一直获得较低方差的梯度更新，增强训练的稳定性。

Conclusion: 本文提出了一个新的基准方法来改进RLVR中的政策梯度估计，从而提高训练稳定性。这项研究为提升复杂模型的训练效率提供了一种新的思考方向。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for post-training large reasoning models (LRMs) using
policy-gradient methods such as GRPO. To stabilize training, these methods
typically center trajectory rewards by subtracting the empirical mean for each
prompt. Statistically, this centering acts as a control variate (or baseline),
reducing the variance of the policy-gradient estimator.
  Typically, the mean reward is estimated using per-prompt empirical averages
for each prompt in a batch. Drawing inspiration from Stein's paradox, we
propose using shrinkage estimators that combine per-prompt and across-prompt
means to improve the overall per-prompt mean estimation accuracy --
particularly in the low-generation regime typical of RLVR. Theoretically, we
construct a shrinkage-based baseline that provably yields lower-variance
policy-gradient estimators across algorithms. Our proposed baseline serves as a
drop-in replacement for existing per-prompt mean baselines, requiring no
additional hyper-parameters or computation. Empirically, shrinkage baselines
consistently outperform standard empirical-mean baselines, leading to
lower-variance gradient updates and improved training stability.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [78] [Robust reduced-order model predictive control using peak-to-peak analysis of filtered signals](https://arxiv.org/abs/2511.03002)
*Johannes Köhler,Carlo Scholz,Melanie Zeilinger*

Main category: eess.SY

TL;DR: 本文提出了一种针对大规模线性系统模型预测控制（MPC）的设计方案，通过使用降阶模型（ROM）和鲁棒控制工具，结合MPC框架，实现了计算可行性和约束满足性。


<details>
  <summary>Details</summary>
Motivation: 大规模线性系统的模型预测控制通常面临的挑战是计算效率和约束满足性之间的权衡。因此，设计一种在保持计算效率的同时能够保证鲁棒性能和约束满足性的控制方案是很有意义的。

Method: 该方法首先通过分析误差，然后通过预测一个误差边界系统来获得对完整阶模型输出的有保证的边界，该边界用于制定一个鲁棒的ROM基MPC。此外，还利用了滤波信号来进一步提高性能。

Result: 在一个100维的质量-弹簧-阻尼系统上进行了方法验证，相对传统方法，保守性降低了四个数量级，表明所提方法的有效性。

Conclusion: 该研究提出了一种新的方法，通过在MPC框架内使用降阶模型和鲁棒控制工具，可以有效地解决大规模线性系统的控制问题。

Abstract: We address the design of a model predictive control (MPC) scheme for
large-scale linear systems using reduced-order models (ROMs). Our approach uses
a ROM, leverages tools from robust control, and integrates them into an MPC
framework to achieve computational tractability with robust constraint
satisfaction. Our key contribution is a method to obtain guaranteed bounds on
the predicted outputs of the full-order system by predicting a (scalar)
error-bounding system alongside the ROM. This bound is then used to formulate a
robust ROM-based MPC that guarantees constraint satisfaction and robust
performance. Our method is developed step-by-step by (i) analysing the error,
(ii) bounding the peak-to-peak gain, an (iii) using filtered signals. We
demonstrate our method on a 100-dimensional mass-spring-damper system,
achieving over four orders of magnitude reduction in conservatism relative to
existing approaches.

</details>


### [79] [Oscillation Analysis and Damping Control for a Proposed North American AC-DC Macrogrid](https://arxiv.org/abs/2511.03017)
*Kaustav Chatterjee,Sameer Nekkalapu,Antos Varghese,Marcelo Elizondo,Quan Nguyen,Xiaoyuan Fan*

Main category: eess.SY

TL;DR: 本文通过详细基于模型的模拟研究评估了通过多端直流(MTDC)宏电网将北美东部和西部互联(EI和WI)连接带来的潜在风险，特别是小信号稳定性问题。研究了MTDC集成后，EI和WI之间的区域模式可能发生变化，导致不稳定振荡的风险，并设计了附加强阻尼控制器以减轻该风险。


<details>
  <summary>Details</summary>
Motivation: 近期的研究提出通过MTDC宏电网连接北美东部和西部互联(EI和WI)，但未全面研究这种互联带来的小信号稳定性挑战。本文旨在填补这一空白，评估这种连接的小信号稳定性风险并提出解决措施。

Method: 本文一是开发了一个定制的动态MTDC系统模型，并将其与EI和WI的行业等级模型结合，这些模型包含了高水平的基于换流器的能源资源。二是通过基于模型振荡分析来识别和表征潜在模式转变与不足阻尼模式。三是设计了利用广域反馈调节选定换流站有功功率设定点的附加阻尼控制器。最后采用频率扫描方法进行基于数据驱动模型线性化和控制器合成。

Result: 研究突出了MTDC系统集成后小信号稳定性的风险，识别出哪些模式受到影响并且阻尼不足。设计的控制器能够有效缓解这些不稳定问题，并且在不同操作条件和故障场景下进行了充分测试。

Conclusion: 研究提出的方法能够有效评估MTDC集成带来的小信号稳定性问题，并通过设计有效的附加阻尼控制器解决了这些问题，为未来的宏电网整合提供了宝贵的见解和实施方案。

Abstract: In recent years, several studies conducted by both industry and U.S.
Department of Energy (DOE)-funded initiatives have proposed linking North
America's Eastern and Western Interconnections (EI and WI) through a
multiterminal DC (MTDC) macrogrid. These studies have explored the advantages
and opportunities of the proposed configuration from the perspectives of
capacity sharing and frequency support. However, the potential challenges of
small-signal stability arising from this interconnection have not been
thoroughly examined. To address this gap, detailed model-based simulation
studies are performed in this paper to assess the risks of poorly damped
inter-area oscillations in the proposed macrogrid. A custom-built dynamic model
of the MTDC system is developed and integrated with industry-grade models of
the EI and WI, incorporating high levels of inverter-based energy resources.
Through model-based oscillation analysis, potential shifts in inter-area modes
for both EI and WI, resulting from the MTDC integration are characterized, and
modes with inadequate damping are identified. Furthermore, to mitigate the
risks of unstable oscillations, supplementary damping controllers are designed
for the MTDC system, leveraging wide-area feedback to modulate active power set
points at selected converter stations. A frequency scanning approach is
employed for data-driven model linearization and controller synthesis. The
damping performance is evaluated under the designed operating conditions and
selected contingency scenarios.

</details>


### [80] [Quantifying Power Systems Resilience Using Statistical Analysis and Bayesian Learning](https://arxiv.org/abs/2511.03043)
*Apsara Adhikari,Charlotte Wertz,Anamika Dubey,Arslan Ahmad,Ian Dobson*

Main category: eess.SY

TL;DR: 研究提出了一种框架，利用统计和贝叶斯学习方法，定量建模天气参数与电力系统韧性指标之间的关系，揭示风速、温度和降水对电力系统韧性的影响，并发现这些天气变量共同作用时的影响比单独作用更显著。此框架有助于理解天气事件对电力系统性能的影响，支持决策者制定更有效的风险管理、资源配置和适应气候变化的策略


<details>
  <summary>Details</summary>
Motivation: 近年来极端天气事件的增加对电网的影响日益显著，造成大规模停电，影响了电力系统的韧性。然而，关于系统性建模天气参数以量化韧性的工作非常有限。因此，提出了一个框架，用于量化天气参数对电力系统韧性指标的影响

Method: 利用统计和贝叶斯学习方法，结合实际公开的停电和天气数据，研究了影响特定地区韧性指标的关键天气变量，包括风速、温度和降水。通过研究伊利诺伊州库克县和佛罗里达州迈阿密-戴德县的情况，展示了这些天气参数在韧性分析和风险评估中的重要性

Result: 此研究发现，这些天气变量的共同影响比单独影响更显著。这表明，天气事件对电力系统性能的影响是多方面的，且相互作用复杂

Conclusion: 该框架为理解天气事件如何影响电力系统性能提供了有价值的观点，有助于决策者制定更有效的风险管理、资源配置和适应气候变化的策略

Abstract: The increasing frequency and intensity of extreme weather events is
significantly affecting the power grid, causing large-scale outages and
impacting power system resilience. Yet limited work has been done on
systematically modeling the impacts of weather parameters to quantify
resilience. This study presents a framework using statistical and Bayesian
learning approaches to quantitatively model the relationship between weather
parameters and power system resilience metrics. By leveraging real-world
publicly available outage and weather data, we identify key weather variables
of wind speed, temperature, and precipitation influencing a particular region's
resilience metrics. A case study of Cook County, Illinois, and Miami-Dade
County, Florida, reveals that these weather parameters are critical factors in
resiliency analysis and risk assessment. Additionally, we find that these
weather variables have combined effects when studied jointly compared to their
effects in isolation. This framework provides valuable insights for
understanding how weather events affect power distribution system performance,
supporting decision-makers in developing more effective strategies for risk
mitigation, resource allocation, and adaptation to changing climatic
conditions.

</details>


### [81] [MHE in Output Feedback Control of Uncertain Nonlinear Systems via IQCs](https://arxiv.org/abs/2511.03221)
*Yang Guo,Stefan Streif*

Main category: eess.SY

TL;DR: 提出了一种针对含有非线性约束的非线性系统的移动地平线估计(MHE)方法，该方法适用于参数不确定性和静态非线性不确定性，并且提出了一个新的可检测性概念，使得系统在外部扰动下输入到状态稳定。


<details>
  <summary>Details</summary>
Motivation: 为了应对具有非线性约束和不确定性的系统的挑战，本论文旨在提出一种新的MHE方案，可以处理参数不确定性和非参数不确定性的系统。此外，引入了一种基于IQC的新的可检测性定义，以提升系统的稳定性。

Method: 该方法利用积分二次约束（IQC）来定义一种新的可检测性，该可检测性能够用于不确定系统的分析。基于这种新的可检测性定义，提出了一个MHE公式，使得不确定系统，控制器以及MHE构成的闭环系统在外部扰动下面向状态稳定。

Result: 本研究提出了一个适用于非线性不确定性系统的MHE方案，并且证明了在引入新可检测性定义的基础上，闭环系统在外部扰动下面向状态稳定。

Conclusion: 结果表明，所提出的MHE方案能够有效地处理非线性约束和不确定性系统，并且提高了闭环系统的稳定性。

Abstract: We propose a moving horizon estimation (MHE) scheme for general nonlinear
constrained systems with parametric or static nonlinear uncertainties and a
predetermined state feedback controller that is assumed to robustly stabilize
the system in the absence of estimation errors. Leveraging integral quadratic
constraints (IQCs), we introduce a new notion of detectability that is robust
to possibly non-parametric uncertainties and verifiable in practice. Assuming
that the uncertain system driven by the controller satisfies this notion of
detectability, we provide an MHE formulation such that the closed-loop system
formed of the uncertain system, the controller and MHE is input-to-state stable
w.r.t. exogenous disturbances.

</details>


### [82] [Theoretical and Experimental Limitations of RoCoF Estimation](https://arxiv.org/abs/2511.03249)
*Gutierrez-Florensa,F. Sanniti,D. Tedeschi,L. Sigrist,A. Ortega,F. Milano*

Main category: eess.SY

TL;DR: 该论文提出了一种基于微分几何和流体力学概念的强大数值方法来改进现代电力系统的RoCoF估计，特别是在低惯性和以转换器为主的发电资产背景下。该方法通过使用高速采样实验测量进行测试，并且可以改进基于RoCoF的自动低频减载控制逻辑，从而提高保护系统的响应质量。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统的低惯性和转换器为主导的发电方式增加了瞬态严重性，使得频率和RoCoF的估计变得更加复杂和不准确。该论文旨在解决这一问题，提出了一种新的、强大的数值方法。

Method: 该论文提出了一种基于微分几何和流体力学概念的数值方法，旨在更精确地估计RoCoF。通过高速采样的实验测量对该方法进行了测试，并用其改进了RoCoF的低频减载控制逻辑，使其更快更有效。同时，该方法还提供了关于事故性质的信息，以帮助改进保护系统的响应。

Result: 该方法能够在瞬态严重性和发电系统低惯性的情况下更精确地估计RoCoF，有助于改进基于RoCoF的保护系统，如自动低频减载功能。通过实验测量验证了该方法的有效性，相较于传统方法具有更高的准确性和效率。

Conclusion: 通过引入微分几何和流体力学的概念，该论文提出了一种有效的RoCoF估计方法，增强了对现代电力系统瞬态严重性条件下频率变化的管理能力。这种方法可以改进现有的保护系统，并提高了自动低频减载控制逻辑的效率和响应速度。

Abstract: A precise estimation of the Rate of Change of Frequency (RoCoF) is crucial
for secure power system operation. In fact, RoCoF is strictly related to the
amount of the available physical and/or virtual inertia of the system and the
severity of the active power unbalance following a disturbance. For this
reason, it is widely exploited in different protection systems, e.g.,
Anti-Islanding, Under Frequency Load Shedding (UFLS) and wide-area protection
systems. The new paradigm of modern power systems, with a low-inertia and
converter-based generation assets, is increasing the transient severity, making
the frequency and the RoCoF estimation more complex and less precise for the
actual devices. This work addresses this issue by proposing a numerically
robust approach based on concepts inherited from differential geometry and
fluid mechanics. The proposed approach is then tested with high-sampling real
experimental measurements and used to develop a faster control logic for a
RoCoF-based UFLS control scheme. The proposed approach provides information to
protections regarding the nature of the contingency which can be used to
improve its response.

</details>


### [83] [Evolutionary Dynamics in Continuous-time Finite-state Mean Field Games - Part II: Stability](https://arxiv.org/abs/2511.03297)
*Leonardo Pedroso,Andrea Agazzi,W. P. M. H. Heemels,Mauro Salazar*

Main category: eess.SY

TL;DR: 研究了在连续时间内具有有限状态和行动集的大玩家群体动态博弈。提出了混合同步纳什均衡（MSNE）的概念，并研究了MSNE在进化动力学下的稳定性和长期可行性。


<details>
  <summary>Details</summary>
Motivation: 研究大规模动态博弈中，混合同步纳什均衡的稳定性和长期可行性，以捕获人口分布对玩家奖励的影响，并理解这类均衡在实际博弈中的长期稳定性。

Method: 提出了一种进化模型和新解决方案概念——混合同步纳什均衡（MSNE），并研究其在进化动力学下的稳定性的条件，包括结构条件和收益映射条件。

Result: 得到了确保MSNE在局部和全局上稳定性的条件，这些条件描述了当MSNE在大规模动态博弈中可以被策略偏离时，如何持久存在。

Conclusion: 通过分析MSNE在进化动力学下的稳定性，提供了关于其在大规模种群动态博弈中的长期稳定性的见解。

Abstract: We study a dynamic game with a large population of players who choose actions
from a finite set in continuous time. Each player has a state in a finite state
space that evolves stochastically with their actions. A player's reward depends
not only on their own state and action but also on the distribution of states
and actions across the population, capturing effects such as congestion in
traffic networks. In Part I, we introduced an evolutionary model and a new
solution concept - the mixed stationary Nash Equilibrium (MSNE) - which
coincides with the rest points of the mean field evolutionary model under
meaningful families of revision protocols. In this second part, we investigate
the evolutionary stability of MSNE. We derive conditions on both the structure
of the MSNE and the game's payoff map that ensure local and global stability
under evolutionary dynamics. These results characterize when MSNE can robustly
emerge and persist against strategic deviations, thereby providing insight into
its long-term viability in large population dynamic games.

</details>


### [84] [Lightwave Power Transfer-Enabled Underwater Optical ISAC Systems under Ship Attitude Variation](https://arxiv.org/abs/2511.03366)
*Kapila W. S. Palitharathna,Constantinos Psomas,Ioannis Krikidis*

Main category: eess.SY

TL;DR: 本文提出了一种利用光波能量传输的水下光学集成传感和通信（O-ISAC）系统。该系统中，安装在海面船只上的接入点通过光波信号与海底传感器及目标节点进行通信，传感器在获取能量的同时向接入点上传数据，而接入点则使用针孔摄像机组估计目标节点的位置。研究中考虑了船只角度变化的影响，推导出目标定位的均方误差（MSE）和上行传输速率的闭型近似公式，并通过分析和模拟验证了模型和公式的有效性，揭示了通信与传感之间的基本权衡关系，并为系统设计提供了重要见解，包括多相机系统的最佳camera放置和能量收集-使用比率（0.55）的最优值。


<details>
  <summary>Details</summary>
Motivation: 提出了一种光波能量传输的水下光学集成传感和通信（O-ISAC）系统，能够实现在复杂的海况条件下传感器和通信设备的能量收集及位置估计，并探讨了通信与传感之间的基本权衡关系。

Method: 模型了船只由于海浪引起的纵横摇运动影响，然后推导了目标定位的均方误差（MSE）和上行传输速率的闭合形式近似公式，并通过仿真和理论分析验证了模型的有效性，研究了合理的相机布局和能量收集-使用比率。

Result: 仿真和理论分析结果展示了良好的一致，表明所提出的模型和推导公式是有效的；此外，提出了通信与传感之间的权衡关系，适用于海洋应用中的光学集成传感和通信系统，展示了在一定角度变化下的最小均方误差为$10^{-2}$ $	ext{m}^2$和最优能量收集-使用比率为0.55。

Conclusion: 本文中研究的O-ISAC系统展示了一种有效的能量收集和位置估计机制，为在海上条件下实现传感器和通信设备的有效利用提供了新的可能性，通过有效的能量收集-使用比率和合理的相机布局来降低定位误差。

Abstract: In this paper, we propose a lightwave power transfer-enabled underwater
optical integrated sensing and communication (O-ISAC) system, where an access
point (AP) mounted on a seasurface ship transmits lightwave signals to two
nodes, namely ($i$) a seabed sensor that harvests energy and transmits uplink
information to the AP, and ($ii$) a sensing target whose position is estimated
by the AP using an array of pinhole cameras. To capture practical deployment
conditions, the ship attitude variation is modeled through its roll, pitch, and
yaw angles, each following a Gaussian distribution under low-to-moderate sea
states. Closed-form approximations are derived for the mean squared error (MSE)
of target localization and the achievable uplink data rate. Analytical and
simulation results demonstrate excellent agreement, validating the proposed
models and derived expressions, while revealing the fundamental
communication-sensing tradeoff in the O-ISAC system. The results further
provide valuable design insights, including the optimal camera placement on the
ship to minimize localization error, achieving a minimum MSE of $10^{-2}$
$\text{m}^2$ with multiple cameras under roll, pitch, and yaw angle variation
of $10^{\circ}$, and the optimal harvest-use ratio of $0.55$ for the considered
setup.

</details>


### [85] [A Digital Twin of Evaporative Thermo-Fluidic Process in Fixation Unit of DoD Inkjet Printers](https://arxiv.org/abs/2511.03379)
*Samarth Toolhally,Joeri Roelofs,Siep Weiland,Amritam Das*

Main category: eess.SY

TL;DR: 本文提出了一种用于热流体干燥过程的固定单元的模块化数字双胞胎，通过来自有限传感器数据的推断，实现实时监控纸张上的时空温度效应


<details>
  <summary>Details</summary>
Motivation: 在喷墨打印中，纸张的最佳含水量对于打印的质量至关重要，然而通过热空气喷涂实现最佳含水量是一个复杂的过程，需要精确的监控和校正。因此，需要开发一种模块化的数字双胞胎来模拟和监测固定单元的热流体干燥过程，以确保和提高打印质量

Method: 本文采用了一个图理论模型来表现固定单元的不同部分，并通过非线性的边界效应模型蒸发，采用$	ext{PIE}$框架和$	ext{Luenberger}$状态估计器来构建一个统一的方法来模拟并实现固定单元的状态估计

Result: 根据商用打印机的真实数据，证明了所提出的固定单元的数字双胞胎模型的准确性和有效性。该模型能够实时监测和估计纸张上每个部分的时空温度效应，从而指导喷墨打印的最佳含水量控制

Conclusion: 开发的固定单元的数字双胞胎在智能打印和温度控制领域提供了新的解决思路，这种方法能够显著的提高打印质量和效率，有较大的应用前景

Abstract: In inkjet printing, optimal paper moisture is crucial for print quality,
achieved through hot-air impingement in the fixation unit. This paper presents
a modular digital twin of the fixation unit, modeling the thermo-fluidic drying
process and monitoring its spatio-temporal performance. The novel approach
formulates the digital twin as an infinite-dimensional state estimator that
infers fixation states from limited sensor data, while remaining robust to
disturbances. Modularity is achieved through a graph-theoretic model, where
each node represents thermo-fluidic dynamics in different sections of the
fixation unit. Evaporation is modeled as a nonlinear boundary effect coupled
with node dynamics via Linear Fractional Representation. Using the Partial
Integral Equation (PIE) framework, we develop a unified approach for stability,
input-output analysis, simulation, and rapid prototyping, validated with
operational data from a commercial printer. An $\mathcal{H}_{\infty}$-optimal
Luenberger state estimator is then synthesized to estimate thermal states from
available sensor data, enabling real-time monitoring of spatio-temporal thermal
effects on paper sheets.

</details>


### [86] [System Identification of a Moored ASV with Recessed Moon Pool via Deterministic and Bayesian Hankel-DMDc](https://arxiv.org/abs/2511.03482)
*Giorgio Palma,Ivan Santic,Andrea Serani,Lorenzo Minno,Matteo Diez*

Main category: eess.SY

TL;DR: 本研究使用富氏动态模式分解（HDMDc）及其贝叶斯扩展（BHDMDc）来识别实验中自主水面车辆（ASV）的系统动力学模型。在此实验中，采用了一种带有凹形月池的Codevintec CK-14e ASV，在波浪中模拟实际海况下的性能。研究结果表明，HDMDc 和 BHDMDc 能够准确预测未见过波浪条件下的ASV动态反应，证明了HDMDc在不同海况下的广泛应用性和准确性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于需要识别自主水面车在不同海况下的复杂系统动力学，并寻找合适的数据驱动方法来进行高精度的建模。基于Hankel动态模式分解，此方法不仅可以进行精确预测，还能利用贝叶斯扩展来处理超参数选择造成的不确定性。

Method: 研究所采用的方法为Hankel动态模式分解（HDMDc）及贝叶斯Hankel动态模式分解（BHDMDc），从自主水面车的运动和缆绳载荷的测量数据中构建数据驱动的简化模型。这种方法可以从动态数据中提取系统动力学性质，并可通过贝叶斯扩展来估计模型的不确定性。

Result: 实验结果表明，HDMDc和BHDMDc能准确预测ASV在未见过的规则和不规则波浪条件下的动态响应，验证了此模型在实际应用中的有效性和泛化性能。

Conclusion: 研究得出HDMDc是一种数据驱动的系统识别方法，能够准确地模拟自主水面车在不同海况下的动态行为。这些模型在训练集未见的波浪条件下仍能保持良好的泛化性能，显示出其在系统识别中的优势。

Abstract: This study addresses the system identification of a small autonomous surface
vehicle (ASV) under moored conditions using Hankel dynamic mode decomposition
with control (HDMDc) and its Bayesian extension (BHDMDc). Experiments were
carried out on a Codevintec CK-14e ASV in the towing tank of CNR-INM, under
both irregular and regular head-sea wave conditions. The ASV under
investigation features a recessed moon pool, which induces nonlinear responses
due to sloshing, thereby increasing the modelling challenge. Data-driven
reduced-order models were built from measurements of vessel motions and mooring
loads. The HDMDc framework provided accurate deterministic predictions of
vessel dynamics, while the Bayesian formulation enabled uncertainty-aware
characterization of the model response by accounting for variability in
hyperparameter selection. Validation against experimental data demonstrated
that both HDMDc and BHDMDc can predict the vessel's response to unseen regular
and irregular wave excitations. In conclusion, the study shows that HDMDc-based
ROMs are a viable data-driven alternative for system identification,
demonstrating for the first time their generalization capability for a sea
condition different from the training set, achieving high accuracy in
reproducing vessel dynamics.

</details>


### [87] [Data-driven Modeling of Grid-following Control in Grid-connected Converters](https://arxiv.org/abs/2511.03494)
*Amir Bahador Javadi,Philip Pong*

Main category: eess.SY

TL;DR: 本文研究了将基于转换器的资源作为传统发电机在无损传输线连接到无限母线系统中的替代方案的应用。此设置用于生成合成数据，以评估这些方法在捕捉系统动态方面的有效性。



<details>
  <summary>Details</summary>
Motivation: 随着电力系统的演变，加上可再生能源的集成和智能电网技术的实施，对于能够准确捕捉现代电网复杂动态的灵活且可扩展的建模方法的需求也在增加。


Method: 本文使用了转换器为基础的资源替代传统发电机，并在这个配置下生成合成数据来测试用于直接从数据识别动态系统的几种方法的有效性。


Result: 本文通过生成的合成数据，成功地评估了几种方法在捕捉系统动态上的能力。


Conclusion: 研究结果表明，基于转换器的资源可以有效地模拟传统发电机的行为，并且生成的合成数据可以准确地测试出直接从数据识别动态系统的方法的有效性。


Abstract: As power systems evolve with the integration of renewable energy sources and
the implementation of smart grid technologies, there is an increasing need for
flexible and scalable modeling approaches capable of accurately capturing the
complex dynamics of modern grids. To meet this need, various methods, such as
the sparse identification of nonlinear dynamics and deep symbolic regression,
have been developed to identify dynamical systems directly from data. In this
study, we examine the application of a converter-based resource as a
replacement for a traditional generator within a lossless transmission line
linked to an infinite bus system. This setup is used to generate synthetic data
in grid-following control mode, enabling the evaluation of these methods in
effectively capturing system dynamics.

</details>


### [88] [Powered Descent Trajectory Optimization of Chandrayaan-3 using Radau Collocation and Controllable Sets](https://arxiv.org/abs/2511.03594)
*Suraj Kumar,Aditya Rallapalli,Ashok Kumar Kakula,Bharat Kumar GVP*

Main category: eess.SY

TL;DR: 该论文介绍了印度Chandrayaan-3任务的软着陆轨迹设计，使用伪谱Radau配置优化框架，并通过航路点优化增强了轨迹对状态和控制扰动的鲁棒性。论文还权衡了燃料消耗和鲁棒性的关系，为任务规划提供了实用见解。


<details>
  <summary>Details</summary>
Motivation: 印度第四个实现月球软着陆的国家，该论文旨在通过优化和增强轨迹鲁棒性，提高Chandrayaan-3任务的成功率和性能。

Method: 采用伪谱Radau配置优化框架进行轨迹设计，并使用基于航路点的优化来增强空间着陆过程的鲁棒性。

Result: 研究结果显示，通过提出的方法，能够在确保轨迹鲁棒性的同时有效控制燃料消耗。这种权衡优化提供了任务规划中的实用信息。

Conclusion: 该研究展示了在月球着陆任务中应用伪谱优化和鲁棒性增强的有效性，对未来的类似任务提供了重要参考。

Abstract: India achieved a significant milestone on August $23^{\text{rd}}$ 2023,
becoming the fourth country to accomplish a soft landing on the Moon. This
paper presents the powered descent trajectory design for the Chandrayaan-3
mission. The optimization framework is based on pseudospectral Radau
collocation, and controllability-based waypoint refinement is employed to
further enhance the robustness of the trajectory against state and control
perturbations. Furthermore, the trade-off between fuel consumption and
robustness is explicitly quantified, providing insights into the practical
considerations of mission planning.

</details>


### [89] [Artificial-reference tracking MPC with probabilistically validated performance on industrial embedded systems](https://arxiv.org/abs/2511.03603)
*Victor Gracia,Pablo Krupa,Filiberto Fele,Teodoro Alamo*

Main category: eess.SY

TL;DR: 该论文提出了一种适用于嵌入式系统的高效实现方法，用于解决带有人工参考的模型预测控制（MPC）问题，通过利用一种新开发的结构利用的首次阶方法求解。该方法能够在计算成本较低的情况下，加入积分无偏移方案、放松约束参数和软约束等实用特性，适用于多种应用场合。此外，论文还提供了一套对闭环系统进行长期操作的闭环系统性能验证框架，并在PLC上的硬件在环设置中，通过控制一个非线性连续搅拌反应器来展示了这种方法的应用。最后，对闭环系统的约束违规和每一步MPC优化算法迭代次数进行了概率验证。


<details>
  <summary>Details</summary>
Motivation: 由于工业嵌入式系统的计算资源有限，目前的实现往往过度简化先进控制技术（如MPC），本文的动机是为这些系统提供一个更实用、计算成本较低的MPC实现方法，以更好地适应现实环境的需求。

Method: 通过利用一个新开发的首次阶方法，提出了一种适用于嵌入式系统的MPC实现，该方法通过概率性能验证框架，确保了系统的长期表现和可行性。具体实现包括集成的无偏移方案、放松约束参数和软约束。这种方法是专为在计算资源有限的嵌入式系统中实现而设计的。

Result: 方法表现良好，能够适应多个应用领域，并在硬件在环测试中显示了满意的性能，如约束不侵扰和优化算法的迭代次数少等特征都得到了验证。

Conclusion: 该论文提出了一种适用于嵌入式系统的高效实现MPC问题的方法，该方法满足了实际应用中的多种需求，证明了其在计算成本较低的情况下进行先进控制的可能性。

Abstract: Industrial embedded systems are typically used to execute simple control
algorithms due to their low computational resources. Despite these limitations,
the implementation of advanced control techniques such as Model Predictive
Control (MPC) has been explored by the control community in recent years,
typically considering simple linear formulations or explicit ones to facilitate
the online computation of the control input. These simplifications often lack
features and properties that are desirable in real-world environments. In this
article, we present an efficient implementation for embedded systems of MPC for
tracking with artificial reference, solved via a recently developed
structure-exploiting first-order method. This formulation is tailored to a wide
range of applications by incorporating essential practical features at a small
computational cost, including integration with an offset-free scheme, back-off
parameters that enable constraint tightening, and soft constraints that
preserve feasibility under disturbances or plant-model mismatch. We accompany
this with a framework for probabilistic performance validation of the
closed-loop system over long-term operation. We illustrate the applicability of
the approach on a Programmable Logic Controller (PLC), incorporated in a
hardware-in-the-loop setup to control a nonlinear continuous stirred-tank
reactor. The behavior of the closed-loop system is probabilistically validated
with respect to constraint violations and the number of iterations required at
each time step by the MPC optimization algorithm.

</details>


### [90] [A Constant-Gain Equation-Error Framework for Airliner Aerodynamic Monitoring Using QAR Data](https://arxiv.org/abs/2511.03678)
*Ruiying Wen,Yuntao Dai,Hongyong Wang*

Main category: eess.SY

TL;DR: 本文提出了一种新的方法——常数增益方程误差方法(CG-EEM)，克服了使用QAR数据监测飞机服役期间气动性能的挑战。通过大量飞行数据验证，CG-EEM能够准确、一致地提取气动参数并识别不同飞机性能差异，为全机队性能监测提供了一种稳健、可扩展、计算效率高的工具。


<details>
  <summary>Details</summary>
Motivation: 使用运营中的快速访问记录器(QAR)数据监测飞机服役期间的气动性能面临着重大挑战，特别是在缺乏关键参数的情况下，常规状态传播滤波器不适合作此用途。标准递归估计器在低激励巡航行中也表现不佳，因此需要一种新的方法来克服这些问题。

Method: 提出了一种新的常数增益方程误差方法(CG-EEM)，该方法在低信号噪声比和静止特性条件下使用常数增益估计器，且该常数增益估计器类似于卡尔曼滤波器。这种方法适用于低激励巡航数据，解决了标准递归估计器在该框架下过早收敛或不稳定的问题。

Result: CG-EEM在超过200次飞行的大规模数据集上得到了验证，结果表明CG-EEM能提取高质量的气动参数，且所抽取的参数具有物理合理性，同时能够正确识别飞机类型之间的性能差异。这使得CG-EEM可以作为全机队性能监控和性能退化早期预警的有力工具。

Conclusion: CG-EEM是第一个能够从QAR数据中提取高质量气动参数的方法，为全机队性能监控提供了一种稳健、可扩展和计算效率高的工具。

Abstract: Monitoring the in-service aerodynamic performance of airliners is critical
for operational efficiency and safety, but using operational Quick Access
Recorder (QAR) data for this purpose presents significant challenges. This
paper first establishes that the absence of key parameters, particularly
aircraft moments of inertia, makes conventional state-propagation filters
fundamentally unsuitable for this application. This limitation necessitates a
decoupled, Equation-Error Method (EEM). However, we then demonstrate through a
comparative analysis that standard recursive estimators with time-varying
gains, such as Recursive Least Squares (RLS), also fail within an EEM
framework, exhibiting premature convergence or instability when applied to
low-excitation cruise data. To overcome these dual challenges, we propose and
validate the Constant-Gain Equation-Error Method (CG-EEM). This framework
employs a custom estimator with a constant, Kalman-like gain, which is
perfectly suited to the stationary, low-signal-to-noise characteristics of
cruise flight. The CG-EEM is extensively validated on a large, multi-fleet
dataset of over 200 flights, where it produces highly consistent, physically
plausible aerodynamic parameters and correctly identifies known performance
differences between aircraft types. The result is a robust, scalable, and
computationally efficient tool for fleet-wide performance monitoring and the
early detection of performance degradation.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [91] [List Decoding and New Bicycle Code Constructions for Quantum LDPC Codes](https://arxiv.org/abs/2511.02951)
*Sheida Rabeti,Hessam Mahdavifar*

Main category: cs.IT

TL;DR: 本文提出了一种新的解码器MBBP-LD，用于Quantum Low-Density Parity-Check (QLDPC) 码，该解码器在保留标准BP解码器的线性时间复杂度的同时，显著降低了逻辑错误率。该方法通过引入新的决策规则，在最新的bicycle (BB) 码参数上取得了40%的逻辑错误率降低，相较于最先进的短QLDPC码解码器BP-OSD。此外，探索了一类新的UB码，减少了解码时的多项式搜索空间，提高了性能和效率。


<details>
  <summary>Details</summary>
Motivation: 论文旨在通过改进解码算法，降低量子码的逻辑错误率，以提高量子纠错码的性能。引入了新的决策规则，以增强传统BP解码器的效力，且该方法具有较高的时间效率，适合大规模量子码的实现。此外，还提出了一类新的UB码，用以减少搜索空间，进一步提高解码效率。


Method: 提出了一种新的解码器MBBP-LD，用于Quantum Low-Density Parity-Check (QLDPC) 码。此解码器基于Multiple-Bases Belief-Propagation (MBBP) 框架扩展而来，旨在改善逻辑错误率。文中设计了一个新的决策规则，替代传统的least-metric selector (LMS) 准则，进一步降低了逻辑错误率。同时，探索了一种新型的UB码，与传统的双变量自行车码相比，它降低了多项式搜索空间的复杂度。


Result: 在最新的bicycle (BB) 码参数lockquote{[144,12,12]}quote{} 上，MBBP-LD 解码器相较于最先进的短QLDPC码解码器BP-OSD，降低了高达40%的逻辑错误率，同时保持了普通BP解码器的线性时间复杂度。此外，对于新提出的UB码，模拟结果显示这类码在多种BP解码器下具有良好的性能。


Conclusion: 本文展示了MBBP-LD解码器在降低逻辑错误率方面的优越性能，同时保持了线性时间复杂度。新提出的UB码进一步简化了搜索空间，提高了编码和解码的效率。结果表明，MBBP-LD是一种有效的解码方法，适用于量子纠错码系统优化。


Abstract: In this paper, we propose a new decoder, called the Multiple-Bases
Belief-Propagation List Decoder (MBBP-LD), for Quantum Low-Density Parity-Check
(QLDPC) codes. It extends the Multiple-Bases Belief-Propagation (MBBP)
framework, originally developed for classical cyclic LDPC codes. The proposed
method preserves the linear-time complexity of standard BP decoder while
improving the logical error rate. To further reduce the logical error rate, a
new decision rule is introduced for the post-processing list decoder,
outperforming the conventional least-metric selector (LMS) criterion. For the
recently developed and implemented bivariate bicycle (BB) code with parameters
\([[144,12,12]]\), our proposed MBBP-LD decoder achieves up to 40\% lower
logical error rate compared to the state-of-the-art decoder for short QLDPC
codes, i.e., BP with ordered-statistics decoding (BP-OSD), while retaining the
linear-time complexity of the plain BP decoder. In addition, we explore a new
subclass of BB codes, that we refer to as the univariate bicycle (UB) codes,
specifically with lower-weight parity checks (\(w=6,8\)). This reduces the
polynomial search space for the code compared to general BB codes, i.e., by
reducing the search space over two polynomial components in BB codes to just a
single polynomial component in UB codes. Simulations demonstrate the promising
performance of these codes under various types of BP decoders.

</details>


### [92] [A Tsallis-Entropy Lens on Genetic Variation](https://arxiv.org/abs/2511.03063)
*Margarita Geleta,Daniel Mas Montserrat,Alexander G. Ioannidis*

Main category: cs.IT

TL;DR: 本文介绍了一种基于Tsallis熵的固定指数$F_q$，它可以根据$q$参数的不同，更精细地区分不同变体频率的遗传变异，并且在实际数据和模拟数据中展示了其在识别地域结构，以及隔离迁徙事件和创始效应方面的能力。


<details>
  <summary>Details</summary>
Motivation: 动机是为了解决传统$F_{	extbf{ST}}$统计量在面对不同变体频率时精度不足的问题，提出一种能够根据变异频率进行更精细区分的统计量$F_q$。通过利用Tsallis $q$-熵，$F_q$可以在刻画变异时对稀有变异和常见变异加权不同，从而提供比$F_{	extbf{ST}}$更细致的视角。此外，$F_q$还在追溯族群分化和历史事件方面进行了应用展示。

Method: 本文的方法主要是通过引入Tsallis $q$-熵来重新定义固定指数$F_q$，使之成为传统$F_{	extbf{ST}}$的一个泛化版本，并通过不同$q$值来调整统计量对稀有或常见变异的敏感度。具体来说，$F_q$度量了亚群相对于整个群体在Tsallis $q$-熵损失上的比例。这种指标具有数学上的理论基础，并且可以在实际生物数据以及模拟人口数据中得到应用，从而用来跟踪区域性群体的结构乃至更复杂的历史过程。

Result: 研究结果显示，$F_q$在捕捉不同频率的遗传变异的同时，也能够更准确地定位到具体哪个亚群引起地域结构上的差异，更好地审视种群结构，识别遗传多样性，以及更加敏感地捕捉隔离-迁移事件和创始效应。这些发现说明，$F_q$可以作为一种分辨率更高的工具，用于人群遗传结构和混合历史的研究之中。

Conclusion: 结论是，$F_q$通过灵活的$q$参数，提供了一种更为精细化的方式去分析遗传结构和变异性，尤其是在面对极端频率分布的遗传数据时更能凸显其分析效用。这个方法为遗传学研究提供了一个强大且多用途的工具，能帮助研究者更深入地理解遗传变异和历史事件的时间标记。

Abstract: We introduce an information-theoretic generalization of the fixation
statistic, the Tsallis-order $q$ F-statistic, $F_q$, which measures the
fraction of Tsallis $q$-entropy lost within subpopulations relative to the
pooled population. The family nests the classical variance-based fixation index
$F_{\textbf{ST}}$ at $q{=}2$ and a Shannon-entropy analogue at $q{=}1$, whose
absolute form equals the mutual information between alleles and population
labels. By varying $q$, $F_q$ acts as a spectral differentiator that up-weights
rare variants at low $q$, while $q{>}1$ increasingly emphasizes common
variants, providing a more fine-grained view of differentiation than
$F_{\textbf{ST}}$ when allele-frequency spectra are skewed. On real data (865
Oceanian genomes with 1,823,000 sites) and controlled genealogical simulations
(seeded from 1,432 founders from HGDP and 1000 Genomes panels, with 322,216
sites), we show that $F_q$ in One-vs-Rest (OVR) and Leave-One-Out (LOO) modes
provides clear attribution of which subpopulations drive regional structure,
and sensitively timestamps isolation-migration events and founder effects.
$F_q$ serves as finer-resolution complement for simulation audits and
population-structure summaries.

</details>


### [93] [Constacyclic codes with best-known parameters](https://arxiv.org/abs/2511.03323)
*Zekai Chen,Min Sha*

Main category: cs.IT

TL;DR: 文章构建了多个长度为$n$、维数接近$n/2$，且最小距离至少为$cn/\log_q n$的$q$元凸循环码族，它们包含很多参数最优的凸循环码。研究还探讨了长度$n$的不同形式。


<details>
  <summary>Details</summary>
Motivation: 论文的动机在于构建具有特定性质（维数接近$n/2$且最小距离至少为$cn/\log_q n$）的$q$元凸循环码族，并寻求最优参数的凸循环码。通过不同形式的长度$n$考虑凸循环码的特性，进一步扩展这些码族的应用潜力。

Method: 该研究主要通过数学构造的方法来构建这些特定性质的凸循环码族，具体定义了要研究的码族并利用代数方法来计算其性质。

Result: 成功构建了维数接近$n/2$，最小距离至少为$cn/\log_q n$的$q$元凸循环码族，且这些码族中包含大量具有最优或接近最优参数的凸循环码。

Conclusion: 研究表明，通过特定的构建方法，可以有效地找到具有重要性质（如维数和最小距离）的凸循环码族。这种方法不仅丰富了凸循环码的研究，也为实际应用场景提供了新的可能性。

Abstract: In this paper, we construct several infinite families of $q$-ary constacyclic
codes over a finite field $\mathbb{F}_q$ with length $n$, dimension around
$n/2$, and minimum distance at least $cn/\log_q n$ for some positive constant
$c$. They contain many constacyclic codes with optimal, or almost-optimal, or
best-known parameters. We also consider various forms of the length $n$.

</details>


### [94] [The (+)-(L, P)-TGRS code](https://arxiv.org/abs/2511.03398)
*Zhonghao Liang,Chenlu Jia,Qunying Liao*

Main category: cs.IT

TL;DR: 该论文研究了一种特殊类型的非Reed-Solomon线性码,称为(+)-(L, P)-TGRS码。文章提出了这种码的检验矩阵，并探讨了其非最大距离可分性和非Reed-Solomon性质。此外，还给出了该码不是自对偶或自正交的充分条件，并构造了两类自正交码，推广了之前Ding等人2025年的结果。最后，提供了几个示例来说明这些理论结果的应用。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机在于研究非Reed-Solomon类型的线性码，特别是在Hu等人于2025年提出的问题的基础上，进一步探讨(+)-(L, P)-TGRS码的性质，从而扩展这一领域的研究范围。

Method: 首先，介绍了(+)-(L, P)-TGRS码的检验矩阵。随后，提出了C为NMDS（非最大距离可分）的充分和必要条件，以及其非Reed-Solomon性质的证明。再次，给出了C不是自对偶或自正交的充分条件，并构造了这两类自正交码。最后，通过实例验证了理论结果的有效性。

Result: 文章部分回答了Hu等人提出的两个开放性问题，拓展了他们的结论。与此同时，改进了关于非Reed-Solomon码的一些结果，并推广了Ding等人关于自正交码的发现。

Conclusion: 本篇论文通过研究(+)-(L, P)-TGRS码的性质，不仅部分解决了已有理论中的开放性问题，还引入了新的理论方法，为非Reed-Solomon码的研究提供了新的视角和具体实例。

Abstract: The construction of the non-Reed-Solomon (in short, non-RS) type linear code
has been one of the research hotspots in recent years. In 2025, Hu et al.
constructed some non-RS MDS codes by defining the (L, P)-twisted generalized
Reed-Solomon code (in short, (L, P)-TGRS). In this paper, we focus on the
(+)-(L, P)-TGRS code C. We firstly present a parity-check matrix. Secondly, we
give a sufficient and necessary condition for C to be NMDS which partially
answers two open problems proposed by Hu et al. in 2025, and prove that C is
non-RS for 2k > n which partially improves the corresponding result given by Hu
et al. in 2025,. Thirdly, we give a sufficient condition for C not to be
self-dual or self-orthogonal, respectively, furthermore, we construct two
classes of self-orthogonal codes which is a promotion of the corresponding
result given by Ding et al. in 2025. Finally, some examples are given.

</details>


### [95] [On the Fundamental Scaling Laws of Fluid Antenna Systems](https://arxiv.org/abs/2511.03415)
*Xusheng Zhu,Farshad Rostami Ghadi,Tuo Wu,Kaitao Meng,Chao Wang,Gui Zhou*

Main category: cs.IT

TL;DR: 本文揭示了流体天线系统(FAS)在真实环境中，符号误码率(SER)的基本增长规律，并提出了提升SER性能的设计指导原则：扩展天线的运动范围以增强多样性，而不是简单地增加有限空间内的端口密度。


<details>
  <summary>Details</summary>
Motivation: 当前关于流体天线系统的符号误码率的精确理论框架研究较少。本文旨在填补这一空白，通过揭示其基本增长规律来优化无线通信性能。

Method: 通过推导适用于大类调制方案的符号误码率的紧致闭式渐进表达式，本文建立了相关理论框架。该框架可用于全面描述多样性和编码增益，并指导最优设计。

Result: 本文建立了符号误码率与信道空间相关性的基本增长规律，并提出：增加天线的运动范围可实质上改善符号误码率，而仅仅增大端口密度在有限空间内则效果有限。

Conclusion: 研究结果指明了显著降低流体天线系统的符号误码率的有效途径，并为这种系统的最优设计提供了明确指导。

Abstract: Fluid antenna systems (FAS) offer a promising paradigm for enhancing wireless
communication by exploiting spatial diversity, yet a rigorous analytical
framework for their error probability has been notably absent. To this end,
this paper addresses this critical gap by unveiling the \textbf{fundamental
scaling laws} that govern the symbol error rate (SER) of FAS in realistic,
spatially correlated channels. To establish these laws, we derive a tight,
closed-form asymptotic expression for the SER applicable to a general class of
modulation schemes. This result is pivotal as it establishes the fundamental
scaling law governing the relationship between SER and the channel's spatial
correlation structure. Based on this framework, we provide a complete
characterization of the diversity and coding gains. The analysis culminates in
a definitive design directive: SER can be fundamentally improved by expanding
the antenna's movement space to increase diversity, while merely increasing
port density within a constrained space yields diminishing returns.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [96] [Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge](https://arxiv.org/abs/2511.03070)
*Drago Plecko,Patrik Okanovic,Torsten Hoefler,Elias Bareinboim*

Main category: cs.AI

TL;DR: 本文构建了一个基准测试来评估大型语言模型（LLMs）对描述现实世界分布的知识掌握情况。结果显示，LLMs在掌握这些知识方面表现不佳，并且没有自然地内化现实世界的统计信息。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）被当作强大的现实世界分布的通用近似器，但统计学中的维度灾难理论挑战了这一观点。本文的动机是验证LLMs是否能够访问并理解描述现实世界的分布知识。

Method: 本文开发了一个基准测试，通过对LLMs进行测试来评估它们对现实世界分布的知识掌握情况，并根据Pearl的因果层级理论进行解释。测试领域包括经济、健康、教育和社会行为。

Result: 测试结果显示，LLMs在理解和掌握现实世界的分布知识方面表现不佳，且未能自然地内化这些统计信息。这意味着LLMs不具备Pearl因果层级的第一层观测分布知识，因此它们对于干预和反事实层面的知识也非常有限。

Conclusion: LLMs虽然在多个领域内广泛使用且拥有强大的文本处理能力，但在掌握描述现实世界概率分布的知识方面仍然存在明显不足。这表明它们尚未达到在现实世界中进行更高级智能任务的能力。

Abstract: Artificial intelligence (AI) systems hold great promise for advancing various
scientific disciplines, and are increasingly used in real-world applications.
Despite their remarkable progress, further capabilities are expected in order
to achieve more general types of intelligence. A critical distinction in this
context is between factual knowledge, which can be evaluated against true or
false answers (e.g., "what is the capital of England?"), and probabilistic
knowledge, reflecting probabilistic properties of the real world (e.g., "what
is the sex of a computer science graduate in the US?"). In this paper, our goal
is to build a benchmark for understanding the capabilities of LLMs in terms of
knowledge of probability distributions describing the real world. Given that
LLMs are trained on vast amounts of text, it may be plausible that they
internalize aspects of these distributions. Indeed, LLMs are touted as powerful
universal approximators of real-world distributions. At the same time,
classical results in statistics, known as curse of dimensionality, highlight
fundamental challenges in learning distributions in high dimensions,
challenging the notion of universal distributional learning. In this work, we
develop the first benchmark to directly test this hypothesis, evaluating
whether LLMs have access to empirical distributions describing real-world
populations across domains such as economics, health, education, and social
behavior. Our results demonstrate that LLMs perform poorly overall, and do not
seem to internalize real-world statistics naturally. When interpreted in the
context of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that
language models do not contain knowledge on observational distributions (Layer
1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional
(Layer 2) and counterfactual (Layer 3) knowledge of these models is also
limited.

</details>


### [97] [SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators](https://arxiv.org/abs/2511.03092)
*Jonathan Li,Nasim Farahini,Evgenii Iuliugin,Magnus Vesterlund,Christian Haggstrom,Guangtao Wang,Shubhangi Upasani,Ayush Sachdeva,Rui Li,Faline Fu,Chen Wu,Ayesha Siddiqua,John Long,Tuowen Zhao,Matheen Musaddiq,Hakan Zeffer,Yun Du,Mingran Wang,Qinghua Li,Bo Li,Urmish Thakker,Raghu Prabhakar*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型使用KV缓存压缩技术对精度的影响，并开发了一种名为SnapStream的方法，实现了在大规模部署中压缩KV缓存的同时保持较高的精度，特别是在静态图和持续批处理框架中。SnapStream在生产环境中性能优越，提高了内存使用效率，并且对精度影响很小。这是首次在生产推理系统中实现稀疏KV注意力技术。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在处理长文本时需要大量的内存，现有技术如StreamingLLM和SnapKV尚未广泛应用于工业框架中。本文旨在调查这些技术对现代语言模型精度的影响，并开发一种适用于大规模生产的KV缓存压缩方法。

Method: 开发了一种名为SnapStream的KV缓存压缩技术，该方法可以在不显著降低模型精度的情况下，实现有效的内存节省。SnapStream专为静态图和持续批处理框架设计，适用于大规模部署。

Result: 实验结果表明，SnapStream能够在保持较高精度的同时，大幅提高内存使用效率。在DeepSeek-671B模型上的测试显示出，SnapStream在长文本上下文环境下的精度影响最小，同时实现了四倍的内存使用效率提升。

Conclusion: 通过在生产环境中部署SnapStream，证明了稀疏KV注意力技术可以在大规模工业部署中有效运作，减少了对高端硬件的需求，降低了云计算的成本。这项研究建立了在静态图和持续批处理框架中实现稀疏KV注意力技术的先例。

Abstract: The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+
context length support have resulted in increasing demands for on-chip memory
to support large KV caches. Techniques such as StreamingLLM and SnapKV
demonstrate how to control KV cache size while maintaining model accuracy. Yet,
these techniques are not commonly used within industrial deployments using
frameworks like vLLM or SGLang. The reason is twofold: on one hand, the static
graphs and continuous batching methodology employed by these frameworks make it
difficult to admit modifications to the standard multi-head attention
algorithm, while on the other hand, the accuracy implications of such
techniques on modern instruction-following and reasoning models are not well
understood, obfuscating the need for implementing these techniques. In this
paper, we explore these accuracy implications on Llama-3.1-8B-Instruct and
DeepSeek-R1, and develop SnapStream, a KV cache compression method that can be
deployed at scale. We demonstrate the efficacy of SnapStream in a 16-way
tensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators
running at 128k context length and up to 1832 tokens per second in a real
production setting. SnapStream enables $4\times$ improved on-chip memory usage
and introduces minimal accuracy degradation on LongBench-v2, AIME24 and
LiveCodeBench. To the best of our knowledge, this is the first implementation
of sparse KV attention techniques deployed in a production inference system
with static graphs and continuous batching.

</details>


### [98] [Large language models require a new form of oversight: capability-based monitoring](https://arxiv.org/abs/2511.03106)
*Katherine C. Kellogg,Bingyang Ye,Yifan Hu,Guergana K. Savova,Byron Wallace,Danielle S. Bitterman*

Main category: cs.AI

TL;DR: 提出了一种新的组织原则，即基于能力的监控，以适应大型语言模型在医疗保健中应用的监督需求。该原则基于大型语言模型的通用性质和其在不同下游任务中重用内部能力的事实，即通过监控共享的模型能力而不是独立评估每个下游任务来识别系统性弱点、长尾错误和新出现的行为。


<details>
  <summary>Details</summary>
Motivation: 为了更好地监督在医疗保健领域广泛应用的大型语言模型，需要一种新的方法来覆盖传统的基于任务的监控。基于能力的监控基于大型语言模型的通用性质和不同任务中重用内部能力的事实。

Method: 描述了基于能力的监控如何围绕共享模型能力（如摘要、推理、翻译或安全护栏）组织监控，以检测由基于任务的监控可能遗漏的系统性弱点、长尾错误和新出现的行为。

Result: 展示了基于能力的监控如何为安全、适应性和协作监控大型语言模型和其他未来的通用人工智能模型在医疗保健中的应用提供可扩展的基础。

Conclusion: 提出了一种新的、基于能力的监控方法，适用于大型语言模型和其他通用人工智能模型在医疗保健中的应用，并为开发者、组织领导者和专业学会提供了实施该方法的指导。

Abstract: The rapid adoption of large language models (LLMs) in healthcare has been
accompanied by scrutiny of their oversight. Existing monitoring approaches,
inherited from traditional machine learning (ML), are task-based and founded on
assumed performance degradation arising from dataset drift. In contrast, with
LLMs, inevitable model degradation due to changes in populations compared to
the training dataset cannot be assumed, because LLMs were not trained for any
specific task in any given population. We therefore propose a new organizing
principle guiding generalist LLM monitoring that is scalable and grounded in
how these models are developed and used in practice: capability-based
monitoring. Capability-based monitoring is motivated by the fact that LLMs are
generalist systems whose overlapping internal capabilities are reused across
numerous downstream tasks. Instead of evaluating each downstream task
independently, this approach organizes monitoring around shared model
capabilities, such as summarization, reasoning, translation, or safety
guardrails, in order to enable cross-task detection of systemic weaknesses,
long-tail errors, and emergent behaviors that task-based monitoring may miss.
We describe considerations for developers, organizational leaders, and
professional societies for implementing a capability-based monitoring approach.
Ultimately, capability-based monitoring will provide a scalable foundation for
safe, adaptive, and collaborative monitoring of LLMs and future generalist
artificial intelligence models in healthcare.

</details>


### [99] [miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward](https://arxiv.org/abs/2511.03108)
*Azim Ospanov,Farzan Farnia,Roozbeh Yousefzadeh*

Main category: cs.AI

TL;DR: 本文分析了miniF2F基准测试中的正式和非正式陈述，指出AI系统在参与数学奥林匹克竞赛中的表现，发现现有最佳模型的准确性约为36%，远低于单独的自动形式化和定理证明的准确率。通过纠正所有错误和不一致，作者发布了miniF2F-v2版本，该版本的定理证明管道的最佳准确性提高到了70%.


<details>
  <summary>Details</summary>
Motivation: 作者希望从AI系统的角度深入分析miniF2F基准测试中的正式和非正式陈述，以理解现有最佳模型在这一任务中的表现，以及改善基准测试能否帮助社区更好地评估正式合理性的进展和模型的成功与失败模式.

Method: 通过分析基准测试中的正式和非正式陈述，指出问题和提出改进方案，发布miniF2F-v2版本，并评估改进后的定理证明管道的表现.

Result: 最佳定理证明管道在miniF2F-v2上的准确率为70%，较原始miniF2F版本的40%有了显著提高，但发现模型自动形式化和推理之间的明显不一致.

Conclusion: 高质量的基准测试不仅可以帮助社区更好地评估正式合理性领域的进步，而且可以更好地诊断自动形式化和定理证明模型的成功与失败模式。

Abstract: We perform a thorough analysis of the formal and informal statements in the
miniF2F benchmark from the perspective of an AI system that is tasked to
participate in a math Olympiad consisting of the problems in miniF2F. In such
setting, the model has to read and comprehend the problems in natural language,
formalize them in Lean language, then proceed with proving the problems, and it
will get credit for each problem if the formal proof corresponds to the
original informal statement presented to the model. Our evaluation results
reveal that the best accuracy of such pipeline can be about 36% using the SoTA
models in the literature, considerably lower than the individual SoTA
accuracies, 97% and 69% reported in the autoformalization and theorem proving
literature. Analyzing the failure modes, we trace back a considerable portion
of this drop to discrepancies between the formal and informal statements for
more than half of the problems in miniF2F. We proceed with correcting all the
errors, discrepancies and simplifications in formal and informal statements,
and present the miniF2F-v2 with fully verified formal and informal statements
and proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to
the best accuracy of 70%, a significant improvement from the 40% on the
original miniF2F, yet indicating considerable misalignment between the
autoformalization models and theorem provers. Our deep analysis suggests that a
higher quality benchmark can help the community better evaluate progress in the
field of formal reasoning and also better diagnose the failure and success
modes of autoformalization and theorem proving models. Our dataset is available
at https://github.com/roozbeh-yz/miniF2F_v2.

</details>


### [100] [Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks](https://arxiv.org/abs/2511.03137)
*Shipeng Cen,Ying Tan*

Main category: cs.AI

TL;DR: 研究提出了一种新型优化算法，结合了烟花算法和多模态大型语言模型，适用于复杂高维任务，实验表明该方法在多个问题实例上实现了或超过了最新水平(SOTA)的结果。


<details>
  <summary>Details</summary>
Motivation: 优化问题日益复杂，传统优化方法效率低下且难以解决问题的非凸、高维特性。研究旨在利用大型语言模型改进优化算法的设计，以应对这些挑战。

Method: 选择烟花算法作为基本优化器，并引入多模态大型语言模型来支持优化。提出了关键部分(CP)的概念，利用多模态大型语言模型优化信息，以拓展烟花算法适用于复杂任务。

Result: 该方法在旅行商问题(TSP)和电子设计自动化问题(EDA)上的实验结果表明，该算法在多个问题上达到了或超过了最新水平(SOTA)的结果。

Conclusion: 该研究展示了大型语言模型在优化算法中应用于复杂任务的潜力，未来可能更广泛地应用在优化领域中。

Abstract: As optimization problems grow increasingly complex and diverse, advancements
in optimization techniques and paradigm innovations hold significant
importance. The challenges posed by optimization problems are primarily
manifested in their non-convexity, high-dimensionality, black-box nature, and
other unfavorable characteristics. Traditional zero-order or first-order
methods, which are often characterized by low efficiency, inaccurate gradient
information, and insufficient utilization of optimization information, are
ill-equipped to address these challenges effectively. In recent years, the
rapid development of large language models (LLM) has led to substantial
improvements in their language understanding and code generation capabilities.
Consequently, the design of optimization algorithms leveraging large language
models has garnered increasing attention from researchers. In this study, we
choose the fireworks algorithm(FWA) as the basic optimizer and propose a novel
approach to assist the design of the FWA by incorporating multi-modal large
language model(MLLM). To put it simply, we propose the concept of Critical
Part(CP), which extends FWA to complex high-dimensional tasks, and further
utilizes the information in the optimization process with the help of the
multi-modal characteristics of large language models. We focus on two specific
tasks: the \textit{traveling salesman problem }(TSP) and \textit{electronic
design automation problem} (EDA). The experimental results show that FWAs
generated under our new framework have achieved or surpassed SOTA results on
many problem instances.

</details>


### [101] [A Proprietary Model-Based Safety Response Framework for AI Agents](https://arxiv.org/abs/2511.03138)
*Qi Li,Jianjun Xu,Pingtao Wei,Jiu Li,Peiqiang Zhao,Jiwei Shi,Xuan Zhang,Yanhui Yang,Xiaodong Hui,Peng Xu,Wenqin Shao*

Main category: cs.AI

TL;DR: 本文提出了一种新的安全响应框架，用于系统性地保护大型语言模型（LLMs）的安全性。此框架在输入层面使用监督微调的安全分类模型，在输出层面集成检索增强生成（RAG）技术，使得LLMs的数据回复更加安全，有效防止信息伪造与增加结果可追溯性。实验表明，相比于基线模型，本文提出的安全控制模型在安全评分上有了显著提高，表现出了出色的保护能力。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛应用，其安全性问题日益显现，严重影响其在关键领域的可靠应用。为了应对这一挑战，本文研究旨在构建一种新的安全响应框架来提高LLMs的安全性，以使其能够为用户提供更为可信赖的服务。

Method: 此框架包含两部分：输入层面采用基于监督微调的安全分类模型，使用细粒度四级分类体系（安全、不安全、有条件安全、需重点关注）来识别并处理用户查询中的风险，输出层面整合了检索增强生成（RAG）技术和特定微调的解释模型，确保所有回复基于实时可信的知识库。这种方法不仅防止了信息伪造，还实现了结果的可追溯性。

Result: 实验结果表明，相比基线模型TinyR1-Safety-8B，本文的安全控制模型在公开的安全评价基准上有着显著更高的安全得分。在内部开发的高风险测试集中，该框架的组件达到了完美的100%安全得分，展示了其在复杂风险场景下出色的保护能力。

Conclusion: 研究为构建高安全性和高信任度的大型语言模型应用程序提供了一条有效的工程途径。

Abstract: With the widespread application of Large Language Models (LLMs), their
associated security issues have become increasingly prominent, severely
constraining their trustworthy deployment in critical domains. This paper
proposes a novel safety response framework designed to systematically safeguard
LLMs at both the input and output levels. At the input level, the framework
employs a supervised fine-tuning-based safety classification model. Through a
fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused
Attention), it performs precise risk identification and differentiated handling
of user queries, significantly enhancing risk coverage and business scenario
adaptability, and achieving a risk recall rate of 99.3%. At the output level,
the framework integrates Retrieval-Augmented Generation (RAG) with a
specifically fine-tuned interpretation model, ensuring all responses are
grounded in a real-time, trustworthy knowledge base. This approach eliminates
information fabrication and enables result traceability. Experimental results
demonstrate that our proposed safety control model achieves a significantly
higher safety score on public safety evaluation benchmarks compared to the
baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk
test set, the framework's components attained a perfect 100% safety score,
validating their exceptional protective capabilities in complex risk scenarios.
This research provides an effective engineering pathway for building
high-security, high-trust LLM applications.

</details>


### [102] [Uncovering Bugs in Formal Explainers: A Case Study with PyXAI](https://arxiv.org/abs/2511.03169)
*Xuanxiang Huang,Yacine Izza,Alexey Ignatiev,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 该论文开发了一种用于验证形式解释器的新方法，并报告了对公开可用的形式解释器PyXAI的评估。结果显示，PyXAI在大多数分析的数据集上计算出错误的解释，这证明了所提出的新验证方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有形式可解释人工智能（XAI）提供了与其他非形式方法相比独特的理论保证，但实践中这些形式解释器的实际实现验证却很少被关注。

Method: 开发了一种新的方法来验证形式解释器，并使用该方法评估了公开可用的形式解释器PyXAI的正确性。

Result: 实验结果显示，PyXAI在大多数数据集上计算出错误的解释，这表明了新的验证方法的重要性。

Conclusion: 证明了验证形式解释器的新方法的必要性，并强调了实践中正确实现形式XAI的挑战。

Abstract: Formal explainable artificial intelligence (XAI) offers unique theoretical
guarantees of rigor when compared to other non-formal methods of
explainability. However, little attention has been given to the validation of
practical implementations of formal explainers. This paper develops a novel
methodology for validating formal explainers and reports on the assessment of
the publicly available formal explainer PyXAI. The paper documents the
existence of incorrect explanations computed by PyXAI on most of the datasets
analyzed in the experiments, thereby confirming the importance of the proposed
novel methodology for the validation of formal explainers.

</details>


### [103] [Adobe Summit Concierge Evaluation with Human in the Loop](https://arxiv.org/abs/2511.03186)
*Yiru Chen,Sally Fang,Sai Sree Harsha,Dan Luo,Vaishnavi Muppala,Fei Wu,Shun Jiang,Kun Qian,Yunyao Li*

Main category: cs.AI

TL;DR: Summit Concierge是一个为Adobe Summit开发的领域特定AI助理，能够处理各种与事件相关的查询，并在数据稀疏、质量保证和快速部署等现实世界约束条件下运作。我们采用了一种结合提示工程、检索定位和轻量级人类验证的工作流程，并描述了系统的架构、开发流程和实际部署结果。研究发现敏捷、反馈驱动的开发可以使AI助手在冷启动场景中实现可扩展性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在企业环境中，生成式AI助手有显著潜力提高生产力，简化信息访问，改善用户体验。针对Adobe Summit的特定需求，我们开发了Summit Concierge，能够处理各种与事件相关的查询，并且能够在数据稀疏、质量保证和快速部署等现实世界约束条件下运作。开发这样的AI助手的动机是解决多方面挑战，并在这些约束条件下提供可靠的解决方案。

Method: 我们采用了一种结合提示工程（Prompt Engineering）、检索定位（Retrieval Grounding）和轻量级人类验证（Lightweight Human Validation）的工作流程。其中提示工程用于生成高质量的提示，以引导模型生成所需输出；检索定位确保模型可以访问相关知识库中的数据，以提供准确的回答；轻量级人类验证则为确保AI助手的输出质量和可靠性提供了一种机制。这种工作流程下，开发人员和用户可以不断地迭代和改进AI助手的表现。我们还描述了系统的架构和开发过程，强调了敏捷、反馈驱动的开发方法的重要性。

Result: 研究结果表明，这种结合提示工程、检索定位和轻量级人类验证的人工智能助手工作流程有助于在数据稀疏且需要快速部署的情况下提供准确且可靠的解决方案。它展示了如何在冷启动情况下建立AI助手的可扩展性和可靠性。我们还讨论了在实际应用场景中AI助手的实际部署结果及其性能表现。

Conclusion: 总的来说，Summit Concierge展示了在企业环境中开发领域特定AI助手的可行性。通过对提示工程、检索定位和轻量级人类验证的有效结合，能够在数据稀疏、质量保证和快速部署等情况下提供有效的解决方案。敏捷、反馈驱动的开发方法对于确保此类AI助手的可扩展性和可靠性至关重要，特别是在冷启动场景中。

Abstract: Generative AI assistants offer significant potential to enhance productivity,
streamline information access, and improve user experience in enterprise
contexts. In this work, we present Summit Concierge, a domain-specific AI
assistant developed for Adobe Summit. The assistant handles a wide range of
event-related queries and operates under real-world constraints such as data
sparsity, quality assurance, and rapid deployment. To address these challenges,
we adopt a human-in-the-loop development workflow that combines prompt
engineering, retrieval grounding, and lightweight human validation. We describe
the system architecture, development process, and real-world deployment
outcomes. Our experience shows that agile, feedback-driven development enables
scalable and reliable AI assistants, even in cold-start scenarios.

</details>


### [104] [From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers](https://arxiv.org/abs/2511.03235)
*Yi-Fei Liu,Yi-Long Lu,Di He,Hang Zhang*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）能够从最少的定量输入中模拟人类心理特质的相关结构。它们的表现令人惊讶，与人源数据中的相互关系模式高度一致。LLMs通过信息选择和压缩阶段，再从这些摘要中进行推理，从而精准预测个体的心理特质。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）是否能够通过最小的定量输入来建模人类心理特质的相关结构。这有助于理解LLMs在心理模拟中的能力和新兴推理机制。 

Method: 通过对816个个体的Big Five性格量表上的回答进行提示，让LLMs模拟他们在其他九个心理量表上的回答，并分析生成回答的过程和底层机制。 

Result: LLMs在预测人类心理结构上的表现显著，其生成的答案之间的相互关系模式与人源数据高度一致（$R^2 > 0.89$）。这表明LLMs能够通过抽象和推理，精准预测个体的心理特质。 

Conclusion: LLMs可以精准预测个体的心理特质，并在此过程中展现了强大的模拟能力和新兴的推理机制。这不仅提供了强大的心理模拟工具，还为理解人类心理结构提供了新的视角。

Abstract: Psychological constructs within individuals are widely believed to be
interconnected. We investigated whether and how Large Language Models (LLMs)
can model the correlational structure of human psychological traits from
minimal quantitative inputs. We prompted various LLMs with Big Five Personality
Scale responses from 816 human individuals to role-play their responses on nine
other psychological scales. LLMs demonstrated remarkable accuracy in capturing
human psychological structure, with the inter-scale correlation patterns from
LLM-generated responses strongly aligning with those from human data $(R^2 >
0.89)$. This zero-shot performance substantially exceeded predictions based on
semantic similarity and approached the accuracy of machine learning algorithms
trained directly on the dataset. Analysis of reasoning traces revealed that
LLMs use a systematic two-stage process: First, they transform raw Big Five
responses into natural language personality summaries through information
selection and compression, analogous to generating sufficient statistics.
Second, they generate target scale responses based on reasoning from these
summaries. For information selection, LLMs identify the same key personality
factors as trained algorithms, though they fail to differentiate item
importance within factors. The resulting compressed summaries are not merely
redundant representations but capture synergistic information--adding them to
original scores enhances prediction alignment, suggesting they encode emergent,
second-order patterns of trait interplay. Our findings demonstrate that LLMs
can precisely predict individual participants' psychological traits from
minimal data through a process of abstraction and reasoning, offering both a
powerful tool for psychological simulation and valuable insights into their
emergent reasoning capabilities.

</details>


### [105] [Towards Scalable Web Accessibility Audit with MLLMs as Copilots](https://arxiv.org/abs/2511.03471)
*Ming Gu,Ziwei Wang,Sicen Lai,Zirui Gao,Sheng Zhou,Jiajun Bu*

Main category: cs.AI

TL;DR: 提出了一种名为AAA的自动化审计框架，该框架结合了人类和AI的力量，通过GRASP和MaC两个关键创新，实现了可扩展的网页无障碍性审计。GRASP是一种基于图的多模态采样方法，MaC则是用于支持审计员的多模态语言模型助手。实验结果表明，小规模语言模型在经过微调后可以成为胜任的专家，并且能够提高实际审计的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 当前网站用户界面大多数都不符合无障碍访问标准，主要是因为现有的审计方法资源密集且无法扩展。本文提出了一个名为AAA的人机合作审计框架，以解决这个问题。

Method: 该框架的设计基于两个创新：GRASP，一种基于图的多模态采样方法，用于确保页面覆盖率；MaC，一种多模态大规模语言模型助手，通过跨模态推理和对高能耗工作的智能辅助支持审计员的工作。此外，为了验证该方法的有效性，还构建了四个用于核对审计管道各关键阶段的新数据集。

Result: 实验结果表明，当经过适当的微调后，小规模语言模型可以作为有成效的专家参与网页无障碍性审计，从而提高了审计的实际效率和效果。

Conclusion: 本文贡献了一个名为AAA的框架，该框架结合了人类和AI的力量，实现了可扩展的网页无障碍性审计，并为审计过程的不同阶段提供了新的基准数据集。

Abstract: Ensuring web accessibility is crucial for advancing social welfare, justice,
and equality in digital spaces, yet the vast majority of website user
interfaces remain non-compliant, due in part to the resource-intensive and
unscalable nature of current auditing practices. While WCAG-EM offers a
structured methodology for site-wise conformance evaluation, it involves great
human efforts and lacks practical support for execution at scale. In this work,
we present an auditing framework, AAA, which operationalizes WCAG-EM through a
human-AI partnership model. AAA is anchored by two key innovations: GRASP, a
graph-based multimodal sampling method that ensures representative page
coverage via learned embeddings of visual, textual, and relational cues; and
MaC, a multimodal large language model-based copilot that supports auditors
through cross-modal reasoning and intelligent assistance in high-effort tasks.
Together, these components enable scalable, end-to-end web accessibility
auditing, empowering human auditors with AI-enhanced assistance for real-world
impact. We further contribute four novel datasets designed for benchmarking
core stages of the audit pipeline. Extensive experiments demonstrate the
effectiveness of our methods, providing insights that small-scale language
models can serve as capable experts when fine-tuned.

</details>


### [106] [Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)](https://arxiv.org/abs/2511.03545)
*Sebastian Ordyniak,Giacomo Paesani,Mateusz Rychlicki,Stefan Szeider*

Main category: cs.AI

TL;DR: 本文对各种机器学习模型中的解释问题进行了全面的理论研究，重点关注具有透明内部机制的模型。研究了归纳和对比解释问题的局部和全局变体，并分析了决策树、决策集、决策列表、布尔电路及其集成等模型的解释复杂性，填补了可解释人工智能领域的一个重要空白，为XAI研究提供了基础见解，促进了AI领域的透明度和问责制讨论。


<details>
  <summary>Details</summary>
Motivation: 面对现有机器学习模型解释性的不透明问题，本文旨在理解并简化那些具有透明解释机制的机器学习模型的解释问题，以提高AI系统的透明度和责任感，促进AI领域更深入的研究和应用。

Method: 本文针对不同类型的机器学习模型，如决策树、决策集、决策列表、布尔电路等，研究了关联解释问题和对比解释问题的局部性和全局性变体，分析其参数化复杂性。

Result: 本文填补了可解释性AI研究的一个重要空白，研究结果有助于更好地理解如何生成不同类型机器学习模型的解释，为机器学习模型的解释性提供了一个坚实的基础。

Conclusion: 本文的研究结果表明了在机器学习模型中生成解释的复杂性和挑战性，为进一步探讨可解释性AI提供了重要的研究方向，进而推动AI系统的透明度和问责制。

Abstract: This paper presents a comprehensive theoretical investigation into the
parameterized complexity of explanation problems in various machine learning
(ML) models. Contrary to the prevalent black-box perception, our study focuses
on models with transparent internal mechanisms. We address two principal types
of explanation problems: abductive and contrastive, both in their local and
global variants. Our analysis encompasses diverse ML models, including Decision
Trees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,
each offering unique explanatory challenges. This research fills a significant
gap in explainable AI (XAI) by providing a foundational understanding of the
complexities of generating explanations for these models. This work provides
insights vital for further research in the domain of XAI, contributing to the
broader discourse on the necessity of transparency and accountability in AI
systems.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [107] [Optimizing the nnU-Net model for brain tumor (Glioma) segmentation Using a BraTS Sub-Saharan Africa (SSA) dataset](https://arxiv.org/abs/2511.02893)
*Chukwuemeka Arua Kalu,Adaobi Chiazor Emegoakor,Fortune Okafor,Augustine Okoh Uchenna,Chijioke Kelvin Ukpai,Godsent Erere Onyeugbo*

Main category: eess.IV

TL;DR: 研究使用了BraTS撒哈拉以南非洲数据集，结果显示nnU-Net模型在原始数据集上训练的效果更好。该发现强调了数据质量和适当的增强方法在建立准确的、具有泛化性的医学图像分割模型中的重要性，尤其是对于代表性不足的地区。


<details>
  <summary>Details</summary>
Motivation: 研究表明，使用原始数据集搭配强大的在线增强方法比使用离线增强的数据集获得更好的结果。强调了数据质量和适当的数据增强方法在构建准确、泛化的医学图像分割模型，特别是对于代表性不足的地区的重要性。

Method: nnU-Net模型在最初的60例患者数据上进行训练，并与在离线增强数据集（360例）上训练的模型进行比较。研究采用BraTS撒哈拉以南非洲数据集，包含60个多模态MRI病例，用于胶质瘤患者的医学图像分割。

Result: 研究表明，nnU-Net在原始数据集上获得的Dice分数为0.84，比在离线增强数据集上训练得到的结果要好。这表明过量的数据增强可能会导致模型泛化能力下降，而适当的数据增强则有助于维持模型的实用性和准确性。

Conclusion: 此研究强调了优质数据和支持性数据增强方法在医学图像分割模型开发，特别是在代表性不足地区的应用中的关键作用。

Abstract: Medical image segmentation is a critical achievement in modern medical
science, developed over decades of research. It allows for the exact
delineation of anatomical and pathological features in two- or
three-dimensional pictures by utilizing notions like pixel intensity, texture,
and anatomical context. With the advent of automated segmentation, physicians
and radiologists may now concentrate on diagnosis and treatment planning while
intelligent computers perform routine image processing tasks.
  This study used the BraTS Sub-Saharan Africa dataset, a selected subset of
the BraTS dataset that included 60 multimodal MRI cases from patients with
glioma. Surprisingly, the nnU Net model trained on the initial 60 instances
performed better than the network trained on an offline-augmented dataset of
360 cases. Hypothetically, the offline augmentations introduced artificial
anatomical variances or intensity distributions, reducing generalization. In
contrast, the original dataset, when paired with nnU Net's robust online
augmentation procedures, maintained realistic variability and produced better
results. The study achieved a Dice score of 0.84 for whole tumor segmentation.
These findings highlight the significance of data quality and proper
augmentation approaches in constructing accurate, generalizable medical picture
segmentation models, particularly for under-represented locations.

</details>


### [108] [Domain-Adaptive Transformer for Data-Efficient Glioma Segmentation in Sub-Saharan MRI](https://arxiv.org/abs/2511.02928)
*Ilerioluwakiiye Abolade,Aniekan Udo,Augustine Ojo,Abdulbasit Oyetunji,Hammed Ajigbotosho,Aondana Iorumbur,Confidence Raymond,Maruf Adewole*

Main category: eess.IV

TL;DR: 这篇论文提出了SegFormer3D-plus，一种结合了放射组学特征和变压器架构的方法，用于改善非洲地区胶质瘤分割的精准度。此方法能有效处理不同设备和协议带来的问题，并在改善肿瘤亚区域的勾画和边界定位方面显示了卓越效果。


<details>
  <summary>Details</summary>
Motivation: 由于非洲撒哈拉以南地区MRI基础设施有限，且存在一定协议异质性，使得胶质瘤分割的任务具有挑战性。这项工作旨在开发一种能够在不同数据域间表现出色的模型，以应对资源有限的国家的医疗挑战。

Method: 该方法主要包括四个步骤：(1) 利用直方图匹配实现不同扫描仪之间强度的一致性；(2) 通过PCA降维后的K-均值聚类算法进行放射组学特征提取，并用以域感知的分层采样；(3) 使用一种具有频域意识的特征提取和空间-通道注意机制的双路径编码器；(4) 引入复合同类-交叉熵损失来加强边界细化。SegFormer3D-plus是在BraTS 2023数据集上预训练，随后用BraTS-Africa数据进行微调。

Result: 在非洲临床扫描资料的异质环境下，SegFormer3D-plus相比其他方法，在改善肿瘤亚区域的勾画和边界定位准确性方面显示出明显优势，特别是在资源有限的情况下具有广泛的应用价值。

Conclusion: 通过结合放射组学特征和先进的Transformer架构，SegFormer3D-plus为解决资源有限地区胶质瘤分割难题提供了可能。本研究的结果强调了领域自适应方法对于提高放射图像分析准确性的潜在价值。

Abstract: Glioma segmentation is critical for diagnosis and treatment planning, yet
remains challenging in Sub-Saharan Africa due to limited MRI infrastructure and
heterogeneous acquisition protocols that induce severe domain shift. We propose
SegFormer3D-plus, a radiomics-guided transformer architecture designed for
robust segmentation under domain variability. Our method combines: (1)
histogram matching for intensity harmonization across scanners, (2) radiomic
feature extraction with PCA-reduced k-means for domain-aware stratified
sampling, (3) a dual-pathway encoder with frequency-aware feature extraction
and spatial-channel attention, and (4) composite Dice-Cross-Entropy loss for
boundary refinement. Pretrained on BraTS 2023 and fine-tuned on BraTS-Africa
data, SegFormer3D-plus demonstrates improved tumor subregion delineation and
boundary localization across heterogeneous African clinical scans, highlighting
the value of radiomics-guided domain adaptation for resource-limited settings.

</details>


### [109] [SAAIPAA: Optimizing aspect-angles-invariant physical adversarial attacks on SAR target recognition models](https://arxiv.org/abs/2511.03192)
*Isar Lemeire,Yee Wei Law,Sang-Heon Lee,Will Meakin,Tat-Jun Chin*

Main category: eess.IV

TL;DR: 本文提出了一种名为SAR方面角不变的物理对抗攻击(SAAIPAA)的新框架，用于对基于反射器的对抗性扰动进行物理建模，当攻击者不知道SAR平台的角度时，该框架也能有效运作。SAAIPAA在白盒设置下实现了80%以上的欺骗率，当角度已知时，平均欺骗率为99.2%。在黑盒设置中，攻击在某些模型之间有很好的传递性，但在另一些模型中则较差。此外，该研究还提出了一种使用MSTAR数据集生成密集采样的方位角SAR数据集边界框的方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对基于对抗性扰动的攻击，提出了一种新的物理对抗攻击的建模方法，旨在改善对抗性扰动的效果，并在不确定SAR平台角度的情况下仍保持有效性。同时，研究还探讨了物理对抗攻击在不同模型间的传递性，以及在黑盒攻击设置下的表现。

Method: 提出了SAR方面角不变的物理对抗攻击(SAAIPAA)框架，通过在每个方位象限中部署至少一个反射器并优化反射器朝向来实现攻击有效性的增强。该方法同时利用MSTAR数据集生成边界框来验证其有效性。

Result: SAAIPAA在所有测试条件下均表现出很高的欺骗率，在不同模型间表现出良好的传递性。同时，在一定程度上可以改善对抗攻击在未知模型下的表现。具体来说，在白盒设置中，欺骗率达到80%以上；当角度信息已知时，平均欺骗率为99.2%。它在黑盒环境下对Resnet50到DenseNet121的模型之间有更好的传递性，但对MobileNetV2的效果较差。此外，研究提出了一种利用MSTAR数据集生成密集采样方位角SAR数据集边界框的方法，增加了该研究的实际应用价值。

Conclusion: SAAIPAA实现了对反射器引起的对抗性扰动的物理建模，与先前的工作相比表现出更高的严谨性。它可通过在每个方位象限部署至少一个反射器来抵抗不确定平台角度的问题，并展示了在黑盒和白盒环境下的攻击有效性和传递性。

Abstract: Synthetic aperture radar (SAR) enables versatile, all-time, all-weather
remote sensing. Coupled with automatic target recognition (ATR) leveraging
machine learning (ML), SAR is empowering a wide range of Earth observation and
surveillance applications. However, the surge of attacks based on adversarial
perturbations against the ML algorithms underpinning SAR ATR is prompting the
need for systematic research into adversarial perturbation mechanisms. Research
in this area began in the digital (image) domain and evolved into the physical
(signal) domain, resulting in physical adversarial attacks (PAAs) that
strategically exploit corner reflectors as attack vectors to evade ML-based
ATR. This paper proposes a novel framework called SAR Aspect-Angles-Invariant
Physical Adversarial Attack (SAAIPAA) for physics-based modelling of
reflector-actuated adversarial perturbations, which improves on the rigor of
prior work. A unique feature of SAAIPAA is its ability to remain effective even
when the attacker lacks knowledge of the SAR platform's aspect angles, by
deploying at least one reflector in each azimuthal quadrant and optimizing
reflector orientations. The resultant physical evasion attacks are efficiently
realizable and optimal over the considered range of aspect angles between a SAR
platform and a target, achieving state-of-the-art fooling rates (over 80% for
DenseNet-121 and ResNet50) in the white-box setting. When aspect angles are
known to the attacker, an average fooling rate of 99.2% is attainable. In
black-box settings, although the attack efficacy of SAAIPAA transfers well
between some models (e.g., from ResNet50 to DenseNet121), the transferability
to some models (e.g., MobileNetV2) can be improved. A useful outcome of using
the MSTAR dataset for the experiments in this article, a method for generating
bounding boxes for densely sampled azimuthal SAR datasets is introduced.

</details>


### [110] [Morpho-Genomic Deep Learning for Ovarian Cancer Subtype and Gene Mutation Prediction from Histopathology](https://arxiv.org/abs/2511.03365)
*Gabriela Fernandes*

Main category: eess.IV

TL;DR: 开发了一种新的深度学习管道，通过整合定量细胞核形态学和深层卷积图像特性，使用H&E染色直肠图像直接进行卵巢癌症亚型分类和基因突变检测，提高了癌症诊断的准确性并降低成本。与基因组数据对标，模型具有较高的分类准确率及一定程度的突变预测能力，验证了组织学表型含有可测量的基因信号。


<details>
  <summary>Details</summary>
Motivation: 晚期诊断和广泛的亚型异质性使卵巢癌成为女性最致命的癌症之一。现有诊断方法不能揭示有助于精确抗癌的基因组变化。

Method: 这项研究开发了一种深度学习管道，结合ResNet-50 CNN编码器和Vision Transformer，以捕捉局部形态学纹理和组织背景。使用来自TCGA和公开数据集的约45000个图像补丁进行模型培训和调整，评估其在亚型分类和基因突变预测方面的性能。利用特征重要性分析，直接量化基因突变与组织学表型之间的联系。

Result: 模型在卵巢癌亚型分类方面的整体准确率为84.2%，宏平均AUC为0.87。模型在TP53突变预测方面的AUC为0.82，BRCA1突变预测方面的AUC为0.76，而ARID1A突变预测方面则为0.73。研究表明，细胞核粘度和离心性是预测TP53基因突变的关键因素。

Conclusion: 这项研究利用深度学习技术探索了组织学表型是否可以直接编码基因信号，验证了其组织学特性可以量化并衡量出相关基因突变。这种方法有望为卵巢癌的筛查和诊断提供一种低成本的、精确的组织病理学途径。

Abstract: Ovarian cancer remains one of the most lethal gynecological malignancies,
largely due to late diagnosis and extensive heterogeneity across subtypes.
Current diagnostic methods are limited in their ability to reveal underlying
genomic variations essential for precision oncology. This study introduces a
novel hybrid deep learning pipeline that integrates quantitative nuclear
morphometry with deep convolutional image features to perform ovarian cancer
subtype classification and gene mutation inference directly from Hematoxylin
and Eosin (H&E) histopathological images. Using $\sim45,000$ image patches
sourced from The Cancer Genome Atlas (TCGA) and public datasets, a fusion model
combining a ResNet-50 Convolutional Neural Network (CNN) encoder and a Vision
Transformer (ViT) was developed. This model successfully captured both local
morphological texture and global tissue context. The pipeline achieved a robust
overall subtype classification accuracy of $84.2\%$ (Macro AUC of $0.87 \pm
0.03$). Crucially, the model demonstrated the capacity for gene mutation
inference with moderate-to-high accuracy: $AUC_{TP53} = 0.82 \pm 0.02$,
$AUC_{BRCA1} = 0.76 \pm 0.04$, and $AUC_{ARID1A} = 0.73 \pm 0.05$. Feature
importance analysis established direct quantitative links, revealing that
nuclear solidity and eccentricity were the dominant predictors for TP53
mutation. These findings validate that quantifiable histological phenotypes
encode measurable genomic signals, paving the way for cost-effective, precision
histopathology in ovarian cancer triage and diagnosis.

</details>
