<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 58]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.IT](#cs.IT) [Total: 8]
- [cs.LG](#cs.LG) [Total: 46]
- [cs.AI](#cs.AI) [Total: 17]
- [eess.IV](#eess.IV) [Total: 5]
- [eess.SY](#eess.SY) [Total: 15]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Towards Fine-Grained Human Motion Video Captioning](https://arxiv.org/abs/2510.24767)
*Guorui Song,Guocun Wang,Zhe Huang,Jing Lin,Xuefei Zhe,Jian Li,Haoqian Wang*

Main category: cs.CV

TL;DR: 提出了M-ACM，一种增强视频描述准确性的新框架，通过利用人体运动恢复获得的运动表示来减少幻觉并提高语义准确性和空间对齐。还推出HMI数据集和HMI-Bench基准进行验证，结果表明M-ACM在描述复杂的人类动作和微妙的时间变化方面显著优于先前的方法。


<details>
  <summary>Details</summary>
Motivation: 当前视频描述模型在捕捉精细的运动细节方面存在困难，产生模糊或语义上不一致的描述。因此，本研究旨在开发一种更好地结合运动信息的方法来提高生成描述的质量。

Method: 提出了一种名为Motion-Augmented Caption Model (M-ACM)的新框架，该框架利用从人类网格恢复中提取的运动表示来增强生成的描述的质量，减少幻觉，提高语义准确性和空间协调性。还创建了一个新的数据集HMI以及一个专注于运动分析的基准HMI-Bench。

Result: 实验表明，M-ACM在描述复杂人类动作和微妙时间变化方面优于已有方法，显著提高了描述的准确性。

Conclusion: 研究结果表明，M-ACM模型是描述视频中的人类动作的有效工具，它通过考虑人体运动的细节显著提高了生成描述的质量。其成功不仅归功于运动信息和空间对齐的结合，而且为未来的研究设立了新的基准。

Abstract: Generating accurate descriptions of human actions in videos remains a
challenging task for video captioning models. Existing approaches often
struggle to capture fine-grained motion details, resulting in vague or
semantically inconsistent captions. In this work, we introduce the
Motion-Augmented Caption Model (M-ACM), a novel generative framework that
enhances caption quality by incorporating motion-aware decoding. At its core,
M-ACM leverages motion representations derived from human mesh recovery to
explicitly highlight human body dynamics, thereby reducing hallucinations and
improving both semantic fidelity and spatial alignment in the generated
captions. To support research in this area, we present the Human Motion Insight
(HMI) Dataset, comprising 115K video-description pairs focused on human
movement, along with HMI-Bench, a dedicated benchmark for evaluating
motion-focused video captioning. Experimental results demonstrate that M-ACM
significantly outperforms previous methods in accurately describing complex
human motions and subtle temporal variations, setting a new standard for
motion-centric video captioning.

</details>


### [2] [Combining SAR Simulators to Train ATR Models with Synthetic Data](https://arxiv.org/abs/2510.24768)
*Benjamin Camus,Julien Houssay,Corentin Le Barbu,Eric Monteux,Cédric Saleun,Christian Cochin*

Main category: cs.CV

TL;DR: 该工作旨在使用合成孔径雷达（SAR）图像进行自动目标识别（ATR），通过结合两种不同的SAR模拟器生成合成数据集，最终使用深度学习方法ADASCA训练模型，达到了近88％的准确率。


<details>
  <summary>Details</summary>
Motivation: 在实际标注数据不足的情况下，通过模拟生成合成数据来进行自动目标识别（ATR）。然而，模拟数据缺乏与真实情况的代表性，因此文中作者研究了模拟方法对ATR的影响，并提出了结合不同模拟器生成的数据集的方法来改善这一问题。

Method: 使用了基于散射中心模型的MOCEM和基于光线追踪策略的Salsa两个不同的SAR模拟器来生成合成数据集，并利用深度学习方法ADASCA进行ATR模型训练。

Result: 使用生成的数据集训练ATR模型后，在MSTAR测量数据上的准确率达到了近88％。

Conclusion: 通过结合不同模拟器生成的数据集，可以提高ATR模型在真实数据上的表现。

Abstract: This work aims to train Deep Learning models to perform Automatic Target
Recognition (ATR) on Synthetic Aperture Radar (SAR) images. To circumvent the
lack of real labelled measurements, we resort to synthetic data produced by SAR
simulators. Simulation offers full control over the virtual environment, which
enables us to generate large and diversified datasets at will. However,
simulations are intrinsically grounded on simplifying assumptions of the real
world (i.e. physical models). Thus, synthetic datasets are not as
representative as real measurements. Consequently, ATR models trained on
synthetic images cannot generalize well on real measurements. Our contributions
to this problem are twofold: on one hand, we demonstrate and quantify the
impact of the simulation paradigm on the ATR. On the other hand, we propose a
new approach to tackle the ATR problem: combine two SAR simulators that are
grounded on different (but complementary) paradigms to produce synthetic
datasets. To this end, we use two simulators: MOCEM, which is based on a
scattering centers model approach, and Salsa, which resorts on a ray tracing
strategy. We train ATR models using synthetic dataset generated both by MOCEM
and Salsa and our Deep Learning approach called ADASCA. We reach an accuracy of
almost 88 % on the MSTAR measurements.

</details>


### [3] [Point-level Uncertainty Evaluation of Mobile Laser Scanning Point Clouds](https://arxiv.org/abs/2510.24773)
*Ziyang Xu,Olaf Wysocki,Christoph Holst*

Main category: cs.CV

TL;DR: 使用机器学习框架来评估移动激光扫描点云的不确定性，采用随机森林和XGBoost模型，实现对大规模点云的不确定性评估。


<details>
  <summary>Details</summary>
Motivation: 传统的方法依赖高精度参考数据，成本高且难以大规模实施，所以提出了基于机器学习的方法来估计点云中的不确定性。

Method: 采用随机森林和XGBoost算法，训练和验证是基于空间分区的真实世界数据集进行的，以避免数据泄漏。该框架可以捕捉几何特征与不确定性之间的非线性关系。

Result: 实验结果显示，模型表现良好，达到了ROC-AUC值超过0.87的结果，表明几何特征如高程变化、点密度和局部结构复杂性在不确定性预测中占主导地位。

Conclusion: 提出的方法提供了一种基于数据驱动的点云不确定性评估视角，为大规模点云的质量控制和误差分析提供了基础。

Abstract: Reliable quantification of uncertainty in Mobile Laser Scanning (MLS) point
clouds is essential for ensuring the accuracy and credibility of downstream
applications such as 3D mapping, modeling, and change analysis. Traditional
backward uncertainty modeling heavily rely on high-precision reference data,
which are often costly or infeasible to obtain at large scales. To address this
issue, this study proposes a machine learning-based framework for point-level
uncertainty evaluation that learns the relationship between local geometric
features and point-level errors. The framework is implemented using two
ensemble learning models, Random Forest (RF) and XGBoost, which are trained and
validated on a spatially partitioned real-world dataset to avoid data leakage.
Experimental results demonstrate that both models can effectively capture the
nonlinear relationships between geometric characteristics and uncertainty,
achieving mean ROC-AUC values above 0.87. The analysis further reveals that
geometric features describing elevation variation, point density, and local
structural complexity play a dominant role in predicting uncertainty. The
proposed framework offers a data-driven perspective of uncertainty evaluation,
providing a scalable and adaptable foundation for future quality control and
error analysis of large-scale point clouds.

</details>


### [4] [Cross-Enhanced Multimodal Fusion of Eye-Tracking and Facial Features for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2510.24777)
*Yujie Nie,Jianzhang Ni,Yonglong Ye,Yuan-Ting Zhang,Yun Kwok Wing,Xiangqing Xu,Xin Ma,Lizhou Fan*

Main category: cs.CV

TL;DR: 本文提出了一种基于眼动追踪和面部特征的阿尔茨海默病（AD）多模态诊断框架。该框架包含跨增强融合注意力模块（CEFAM）和方向感知卷积模块（DACM），以实现模态间的相互作用，提升AD诊断准确性达到95.11%。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的准确诊断对于及时干预和减缓疾病进展至关重要。本文动机在于探索眼动追踪和面部特征的联合应用，以加强辅助诊断能力，特别是在认知功能障碍的早期检测方面。这项研究关注的是如何有效利用这些非侵入性的生物标记来改进AD检测。

Method: 提出了一种多模态跨增强融合框架，该框架包含两部分：跨增强融合注意力模块（CEFAM）和方向感知卷积模块（DACM），以捕捉眼动追踪和面部特征之间的关联，提高识别性能。此外，为了验证该方法的有效性，构建了一个包括25名AD患者和25名健康对照的多模态数据集。

Result: 实验结果显示，所提出的框架显著优于传统的后期联合和特征级联方法，在区分AD患者和健康人时，分类准确率达到95.11%。从而展示了有效利用模态间依赖性和模态特定贡献在AD诊断中的优越性。

Conclusion: 这项研究证明了跨模态融合在AD诊断中的潜力，特别是在结合眼动追踪和面部特征时。未来的工作将探索集成更多模态数据的方法，以进一步提高诊断准确性。

Abstract: Accurate diagnosis of Alzheimer's disease (AD) is essential for enabling
timely intervention and slowing disease progression. Multimodal diagnostic
approaches offer considerable promise by integrating complementary information
across behavioral and perceptual domains. Eye-tracking and facial features, in
particular, are important indicators of cognitive function, reflecting
attentional distribution and neurocognitive state. However, few studies have
explored their joint integration for auxiliary AD diagnosis. In this study, we
propose a multimodal cross-enhanced fusion framework that synergistically
leverages eye-tracking and facial features for AD detection. The framework
incorporates two key modules: (a) a Cross-Enhanced Fusion Attention Module
(CEFAM), which models inter-modal interactions through cross-attention and
global enhancement, and (b) a Direction-Aware Convolution Module (DACM), which
captures fine-grained directional facial features via horizontal-vertical
receptive fields. Together, these modules enable adaptive and discriminative
multimodal representation learning. To support this work, we constructed a
synchronized multimodal dataset, including 25 patients with AD and 25 healthy
controls (HC), by recording aligned facial video and eye-tracking sequences
during a visual memory-search paradigm, providing an ecologically valid
resource for evaluating integration strategies. Extensive experiments on this
dataset demonstrate that our framework outperforms traditional late fusion and
feature concatenation methods, achieving a classification accuracy of 95.11% in
distinguishing AD from HC, highlighting superior robustness and diagnostic
performance by explicitly modeling inter-modal dependencies and
modality-specific contributions.

</details>


### [5] [FPGA-based Lane Detection System incorporating Temperature and Light Control Units](https://arxiv.org/abs/2510.24778)
*Ibrahim Qamar,Saber Mahmoud,Seif Megahed,Mohamed Khaled,Saleh Hesham,Ahmed Matar,Saif Gebril,Mervat Mahmoud*

Main category: cs.CV

TL;DR: 本文提出了一种基于FPGA的车道检测车辆架构，可以实现车道的精确检测，并能根据环境自动调节灯光与温度。系统运行在150 MHz下，处理416 x 416的图像，每1.17毫秒生成有效输出一次。输出包括当前车道及其左右边界的信息。



<details>
  <summary>Details</summary>
Motivation: 智能车辆自动化的趋势增加了对车道检测的需求，尤其是在城市道路和机器人赛道中。现有的解决方案对于实时性和环境适应性仍然存在不足。


Method: 使用Sobel算法进行边缘检测，结合FPGA的高速处理能力来实时检测车道。系统还包括自动化光照和温度控制以提高环境适应性。


Result: 系统可以每1.17毫秒生成有效输出一次，包括当前车道数量、车道索引及其左右边界的信息。


Conclusion: 所提出的基于FPGA的车道检测系统在实时性和环境适应性方面表现出色，为智能车辆提供了有效支持。


Abstract: Intelligent vehicles are one of the most important outcomes gained from the
world tendency toward automation. Applications of IVs, whether in urban roads
or robot tracks, do prioritize lane path detection. This paper proposes an
FPGA-based Lane Detector Vehicle LDV architecture that relies on the Sobel
algorithm for edge detection. Operating on 416 x 416 images and 150 MHz, the
system can generate a valid output every 1.17 ms. The valid output consists of
the number of present lanes, the current lane index, as well as its right and
left boundaries. Additionally, the automated light and temperature control
units in the proposed system enhance its adaptability to the surrounding
environmental conditions.

</details>


### [6] [ESCA: Enabling Seamless Codec Avatar Execution through Algorithm and Hardware Co-Optimization for Virtual Reality](https://arxiv.org/abs/2510.24787)
*Mingzhi Zhu,Ding Shang,Sai Qian Zhang*

Main category: cs.CV

TL;DR: 为了在资源受限的虚拟现实设备上实现实时高保真码流头像渲染，提出了一种高效后训练量化方法和定制硬件加速器，引入ESCA优化框架，实现了显著的性能提升，如图像质量、延迟和帧率的优化，使得高清码流头像在移动设备上成为可能。


<details>
  <summary>Details</summary>
Motivation: 资源受限的虚拟现实设备难以实时推断深度学习生成模型，本研究旨在提供一个高效的解决方案，使得高保真码流头像能够在这类设备上运行。

Method: 提出了高效后训练量化(PTQ)方法和定制硬件加速器，介绍了ESCA，该框架能够优化码流头像在边缘设备上的推理性能。PTQ方法能够在不牺牲输出质量的情况下实现低精度执行，而硬件加速器可以集成到VR设备的系统级芯片中，进一步提升处理效率。

Result: 实验结果显示，ESCA能够在不降低图像质量的情况下减少延迟并提升帧率，满足实时VR要求，其中图像质量提升了+0.39，延迟减少了3.36倍，并达到了每秒100帧的渲染率。

Conclusion: 该研究证明了在资源受限设备上部署高性能高保真码流头像的可行性，这为更沉浸式的VR体验提供了可能。

Abstract: Photorealistic Codec Avatars (PCA), which generate high-fidelity human face
renderings, are increasingly being used in Virtual Reality (VR) environments to
enable immersive communication and interaction through deep learning-based
generative models. However, these models impose significant computational
demands, making real-time inference challenging on resource-constrained VR
devices such as head-mounted displays, where latency and power efficiency are
critical. To address this challenge, we propose an efficient post-training
quantization (PTQ) method tailored for Codec Avatar models, enabling
low-precision execution without compromising output quality. In addition, we
design a custom hardware accelerator that can be integrated into the
system-on-chip of VR devices to further enhance processing efficiency. Building
on these components, we introduce ESCA, a full-stack optimization framework
that accelerates PCA inference on edge VR platforms. Experimental results
demonstrate that ESCA boosts FovVideoVDP quality scores by up to $+0.39$ over
the best 4-bit baseline, delivers up to $3.36\times$ latency reduction, and
sustains a rendering rate of 100 frames per second in end-to-end tests,
satisfying real-time VR requirements. These results demonstrate the feasibility
of deploying high-fidelity codec avatars on resource-constrained devices,
opening the door to more immersive and portable VR experiences.

</details>


### [7] [The Underappreciated Power of Vision Models for Graph Structural Understanding](https://arxiv.org/abs/2510.24788)
*Xinjian Zhao,Wei Pang,Zhongkai Xue,Xiangru Jian,Lei Zhang,Yaoyao Xu,Xiaozhuang Song,Shu Wu,Tianshu Yu*

Main category: cs.CV

TL;DR: 本文研究了视觉模型在图理解中的潜力，发现它们在性能上与GNNs相当，但学习模式不同，并介绍了GraphAbstract这一新基准以评估模型在全局图性质感知上的能力。结果表明，在整体结构理解任务上，视觉模型优于GNNs，并且能更好地泛化到不同规模的图上。这表明视觉模型在全局拓扑意识和尺度不变推理问题上具有未被充分利用的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准将领域特征与拓扑理解混淆，导致无法准确评估模型的性能和学习模式，因此，研究者引入了新的基准GraphAbstract，更清晰评估模型在理解全局图结构时的表现和模式

Method: 引入新的基准GraphAbstract，包含识别组织原型、检测对称性、感知连接强度和识别关键元素等任务，以评估视觉模型和GNNs在理解全局图结构方面的能力

Result: 视觉模型在全局结构理解任务中表现优于GNNs，并能在不同规模的图上保持泛化能力。而GNNs在全局模式抽象和随图增大性能下降的问题上表现较差

Conclusion: 视觉模型在图结构理解中展现出卓越的且被低估的能力，特别是在需要全局拓扑意识和尺度不变推理的问题上。这些发现为开发更有效的图基础模型提供了新的研究方向

Abstract: Graph Neural Networks operate through bottom-up message-passing,
fundamentally differing from human visual perception, which intuitively
captures global structures first. We investigate the underappreciated potential
of vision models for graph understanding, finding they achieve performance
comparable to GNNs on established benchmarks while exhibiting distinctly
different learning patterns. These divergent behaviors, combined with
limitations of existing benchmarks that conflate domain features with
topological understanding, motivate our introduction of GraphAbstract. This
benchmark evaluates models' ability to perceive global graph properties as
humans do: recognizing organizational archetypes, detecting symmetry, sensing
connectivity strength, and identifying critical elements. Our results reveal
that vision models significantly outperform GNNs on tasks requiring holistic
structural understanding and maintain generalizability across varying graph
scales, while GNNs struggle with global pattern abstraction and degrade with
increasing graph size. This work demonstrates that vision models possess
remarkable yet underutilized capabilities for graph structural understanding,
particularly for problems requiring global topological awareness and
scale-invariant reasoning. These findings open new avenues to leverage this
underappreciated potential for developing more effective graph foundation
models for tasks dominated by holistic pattern recognition.

</details>


### [8] [PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models](https://arxiv.org/abs/2510.24792)
*Patrick Haller,Fabio Barth,Jonas Golde,Georg Rehm,Alan Akbik*

Main category: cs.CV

TL;DR: 我们介绍了PISA-Bench，一个多语言基准，它源自美国专家创建的PISA测试中的英语示例，以评估学生在八十多个国家的能力，涵盖了六种语言。实验表明，尤其是在非英语部分以及空间和几何推理任务中，小模型表现较差。这项工作促进了多语言多模态推理的研究。


<details>
  <summary>Details</summary>
Motivation: 现有的基准在高质量的人工验证示例方面仍然不足，许多数据集依赖于大型语言模型生成的合成内容，并且大部分数据集局限于英语。PISA-Bench旨在弥补这些不足，提供高质量且多语言支持的用于评估视觉语言模型的基准。

Method: PISA-Bench 从 PISA 测试的英语示例中提取，包含了指令、问题、答案选项和图片等，并在五种语言中翻译，形成一个多语言平行数据集。此外还加入了问题类型分类。我们在此基准上评估了现有的视觉语言模型，特别关注小模型的表现。

Result: 实验结果显示，小模型在PISA-Bench上表现不佳，尤其在非英语数据集以及需要空间和几何推理的任务中，错误率较高。这表明当前的模型在理解和处理多模态推理任务方面仍有不足。

Conclusion: PISA-Bench为研究多语言多模态推理提供了一个新的资源，有助于推动这一领域的研究。我们公开了该数据集及评估框架以供研究使用。

Abstract: Vision-language models (VLMs) have demonstrated remarkable progress in
multimodal reasoning. However, existing benchmarks remain limited in terms of
high-quality, human-verified examples. Many current datasets rely on
synthetically generated content by large language models (LLMs). Furthermore,
most datasets are limited to English, as manual quality assurance of translated
samples is time-consuming and costly. To fill this gap, we introduce
PISA-Bench, a multilingual benchmark derived from English examples of the
expert-created PISA tests, a unified framework for the assessment of student
competencies in over eighty countries. Each example consists of human-extracted
instructions, questions, answer options, and images, enriched with question
type categories, and has been translated from English into five additional
languages (Spanish, German, Chinese, French, and Italian), resulting in a fully
parallel corpus covering six languages. We evaluate state-of-the-art
vision-language models on PISA-Bench and find that especially small models
(<20B parameters) fail to achieve high test scores. We further find substantial
performance degradation on non-English splits as well as high error-rates when
models are tasked with spatial and geometric reasoning. By releasing the
dataset and evaluation framework, we provide a resource for advancing research
on multilingual multimodal reasoning.

</details>


### [9] [A Survey on Efficient Vision-Language-Action Models](https://arxiv.org/abs/2510.24795)
*Zhaoshu Yu,Bo Wang,Pengpeng Zeng,Haonan Zhang,Ji Zhang,Lianli Gao,Jingkuan Song,Nicu Sebe,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文综述了Efficient Vision-Language-Action (VLAs) 模型，旨在解决大规模模型部署中的计算和数据需求问题，提出了一种统一的分类方法，将当前技术分为模型设计、训练和数据收集三个核心领域，为研究和应用提供了基础参考和未来研究方向的指导。


<details>
  <summary>Details</summary>
Motivation: 当前Vision-Language-Action (VLAs) 模型虽然展现了显著的通用能力，但其大规模模型的部署受到高昂的计算和数据需求限制。为了应对这一挑战，此综述提出了Efficient VLAs的综合视图，覆盖数据、模型和训练全过程。目的为了解决实际部署中的效率问题，推动VLAs应用的发展。

Method: 本文提出了一个包含三个核心领域的统一分类方法，分别是：(1) 效率模型设计（高效架构和模型压缩）；(2) 效率训练（减少模型学习中的计算负担）；(3) 效率数据收集（解决获取和利用机器人数据的瓶颈）。

Result: 通过对现有方法的批判性回顾，本文建立了该领域的基础参考框架，总结了代表性应用，明确了关键挑战，并规划了未来的研究方向。

Conclusion: 本文综述了Efficient VLAs的研究现状与趋势，提出了一路全面的分类组织方式，希望通过系统性的分析和前瞻性的视角，促进Efficient VLAs的发展与应用。

Abstract: Vision-Language-Action models (VLAs) represent a significant frontier in
embodied intelligence, aiming to bridge digital knowledge with physical-world
interaction. While these models have demonstrated remarkable generalist
capabilities, their deployment is severely hampered by the substantial
computational and data requirements inherent to their underlying large-scale
foundation models. Motivated by the urgent need to address these challenges,
this survey presents the first comprehensive review of Efficient
Vision-Language-Action models (Efficient VLAs) across the entire
data-model-training process. Specifically, we introduce a unified taxonomy to
systematically organize the disparate efforts in this domain, categorizing
current techniques into three core pillars: (1) Efficient Model Design,
focusing on efficient architectures and model compression; (2) Efficient
Training, which reduces computational burdens during model learning; and (3)
Efficient Data Collection, which addresses the bottlenecks in acquiring and
utilizing robotic data. Through a critical review of state-of-the-art methods
within this framework, this survey not only establishes a foundational
reference for the community but also summarizes representative applications,
delineates key challenges, and charts a roadmap for future research. We
maintain a continuously updated project page to track our latest developments:
https://evla-survey.github.io/

</details>


### [10] [Deep Feature Optimization for Enhanced Fish Freshness Assessment](https://arxiv.org/abs/2510.24814)
*Phi-Hung Hoang,Nam-Thuan Trinh,Van-Manh Tran,Thi-Thu-Hong Phan*

Main category: cs.CV

TL;DR: 本文提出了一种三层框架，用于通过图像评估鱼类的新鲜度，该框架结合了深度学习模型和传统机器学习方法，提高了预测准确性，并选择了更有信息量的特征子集。实验表明，所提出的方法在Fish Eyes数据集上达到了85.99％的准确率，超过了先前的研究。


<details>
  <summary>Details</summary>
Motivation: 传统的感官评价方法主观、耗时且不一致，虽然深度学习在自动化视觉预测上取得了一些进展，但仍然存在准确性低和特征透明度不高等问题。本文旨在解决这些问题，以实现可靠的鱼类新鲜度评估。

Method: 首先，通过微调五个前沿的视觉架构来建立基准。然后，从这些架构中提取的多层深度特征被用于训练七种经典机器学习分类器。最后，通过基于LightGBM、随机森林和Lasso的方法选择了一个小型但信息量大的特征子集。

Result: 实验显示，最好的配置在Fish Eyes数据集上达到85.99%的准确率，超过了之前的研究。这表明所提出的框架对于视觉质量评估任务的有效性和泛化能力。

Conclusion: 本文的方法提高了鱼类新鲜度评估的准确性，显示了深度学习模型结合传统机器学习方法在图像分类任务中的潜力。

Abstract: Assessing fish freshness is vital for ensuring food safety and minimizing
economic losses in the seafood industry. However, traditional sensory
evaluation remains subjective, time-consuming, and inconsistent. Although
recent advances in deep learning have automated visual freshness prediction,
challenges related to accuracy and feature transparency persist. This study
introduces a unified three-stage framework that refines and leverages deep
visual representations for reliable fish freshness assessment. First, five
state-of-the-art vision architectures - ResNet-50, DenseNet-121,
EfficientNet-B0, ConvNeXt-Base, and Swin-Tiny - are fine-tuned to establish a
strong baseline. Next, multi-level deep features extracted from these backbones
are used to train seven classical machine learning classifiers, integrating
deep and traditional decision mechanisms. Finally, feature selection methods
based on Light Gradient Boosting Machine (LGBM), Random Forest, and Lasso
identify a compact and informative subset of features. Experiments on the
Freshness of the Fish Eyes (FFE) dataset demonstrate that the best
configuration combining Swin-Tiny features, an Extra Trees classifier, and
LGBM-based feature selection achieves an accuracy of 85.99%, outperforming
recent studies on the same dataset by 8.69-22.78%. These findings confirm the
effectiveness and generalizability of the proposed framework for visual quality
evaluation tasks.

</details>


### [11] [Perception, Understanding and Reasoning, A Multimodal Benchmark for Video Fake News Detection](https://arxiv.org/abs/2510.24816)
*Cui Yakun,Fushuo Huo,Weijie Shi,Juntao Dai,Hang Du,Zhenghao Zhu,Sirui Han,Yike Guo*

Main category: cs.CV

TL;DR: 本研究引入了MVFNDB多模态视频虚假信息检测基准，并设计了一个结合创作者添加内容和原始拍摄素材推理的框架MVFND-CoT，以促进多模态大规模语言模型在视频虚假信息检测领域的评估与进步。


<details>
  <summary>Details</summary>
Motivation: 传统视频虚假信息检测基准往往只关注最终决策的准确性，而不对整个检测过程进行细致评估，导致检测过程成为黑匣子。本文提出MVFNDB基准，旨在解决该问题，提供基础任务定义，并评估多模态大规模语言模型在捕捉视频虚假信息中的感知、理解和推理能力。

Method: 研究设计了一个包括10个任务的基准MVFNDB，其中基于详尽构建的能力分类对9730个由人工标注的视频相关问题进行了细致分类。此外，还设计了一个结合创作者添加内容和原始拍摄素材推理的框架MVFND-CoT，以验证组合多特征对最终结果的影响。

Result: 通过基准数据集，对影响准确性的更深层次因素进行了全面分析，包括视频处理策略和视频特征与模型能力之间的对齐，最终为未来多模态大规模语言模型在视频虚假信息检测领域的评估和进展奠定基础。

Conclusion: 本研究提供了一个涵盖多个任务的详尽基准数据集MVFNDB，同时设计了框架MVFND-CoT，提出了一种新颖的视频虚假信息检测方法，这将为多模态大规模语言模型在该领域的发展提供坚实基础。

Abstract: The advent of multi-modal large language models (MLLMs) has greatly advanced
research into applications for Video fake news detection (VFND) tasks.
Traditional video-based FND benchmarks typically focus on the accuracy of the
final decision, often failing to provide fine-grained assessments for the
entire detection process, making the detection process a black box. Therefore,
we introduce the MVFNDB (Multi-modal Video Fake News Detection Benchmark) based
on the empirical analysis, which provides foundation for tasks definition. The
benchmark comprises 10 tasks and is meticulously crafted to probe MLLMs'
perception, understanding, and reasoning capacities during detection, featuring
9730 human-annotated video-related questions based on a carefully constructed
taxonomy ability of VFND. To validate the impact of combining multiple features
on the final results, we design a novel framework named MVFND-CoT, which
incorporates both creator-added content and original shooting footage
reasoning. Building upon the benchmark, we conduct an in-depth analysis of the
deeper factors influencing accuracy, including video processing strategies and
the alignment between video features and model capabilities. We believe this
benchmark will lay a solid foundation for future evaluations and advancements
of MLLMs in the domain of video fake news detection.

</details>


### [12] [SafeEditor: Unified MLLM for Efficient Post-hoc T2I Safety Editing](https://arxiv.org/abs/2510.24820)
*Ruiyang Zhang,Jiahao Luo,Xiaoru Feng,Qiufan Pang,Yaodong Yang,Juntao Dai*

Main category: cs.CV

TL;DR: 提出了一种针对文本到图像生成的安全编辑框架，通过多轮图像文本交互式数据集和后处理安全编辑方法，提高了生成图像的安全性和实用性平衡，减少过度拒绝现象。提出的方法在实验中表现出色，优于现有安全措施。


<details>
  <summary>Details</summary>
Motivation: 随着文本到图像模型的快速发展，确保其安全性变得越来越重要。现有的安全性方法存在过度拒绝和安全与实用性的不平衡问题，因此需提出更有效的解决方案。

Method: 提出一个多轮安全编辑框架，作为通用插件模块，利用MR-SafeEdit多轮图像文本交互式数据集和SafeEditor统一多轮安全编辑模型来提高生成图像的安全性和实用性平衡。

Result: 实验结果表明，SafeEditor能够减少过度拒绝，并在安全性和实用性之间达到更好的平衡，优于现有的安全方法。

Conclusion: 本文提出的安全编辑框架能够有效解决现有文本到图像生成模型在安全性上的问题，提供了一个更优的安全解决方案。

Abstract: With the rapid advancement of text-to-image (T2I) models, ensuring their
safety has become increasingly critical. Existing safety approaches can be
categorized into training-time and inference-time methods. While inference-time
methods are widely adopted due to their cost-effectiveness, they often suffer
from limitations such as over-refusal and imbalance between safety and utility.
To address these challenges, we propose a multi-round safety editing framework
that functions as a model-agnostic, plug-and-play module, enabling efficient
safety alignment for any text-to-image model. Central to this framework is
MR-SafeEdit, a multi-round image-text interleaved dataset specifically
constructed for safety editing in text-to-image generation. We introduce a
post-hoc safety editing paradigm that mirrors the human cognitive process of
identifying and refining unsafe content. To instantiate this paradigm, we
develop SafeEditor, a unified MLLM capable of multi-round safety editing on
generated images. Experimental results show that SafeEditor surpasses prior
safety approaches by reducing over-refusal while achieving a more favorable
safety-utility balance.

</details>


### [13] [Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal Perception and Generation](https://arxiv.org/abs/2510.24821)
*Inclusion AI,:,Bowen Ma,Cheng Zou,Canxiang Yan,Chunxiang Jin,Chunjie Shen,Dandan Zheng,Fudong Wang,Furong Xu,GuangMing Yao,Jun Zhou,Jingdong Chen,Jianing Li,Jianxin Sun,Jiajia Liu,Jianjiang Zhu,Jianping Jiang,Jun Peng,Kaixiang Ji,Kaimeng Ren,Libin Wang,Lixiang Ru,Longhua Tan,Lan Wang,Mochen Bai,Ning Gao,Qingpei Guo,Qinglong Zhang,Qiang Xu,Rui Liu,Ruijie Xiong,Ruobing Zheng,Sirui Gao,Tianqi Li,Tinghao Liu,Weilong Chai,Xinyu Xiao,Xiaomei Wang,Xiaolong Wang,Xiao Lu,Xiaoyu Li,Xingning Dong,Xuzheng Yu,Yi Yuan,Yuting Gao,Yuting Xiao,Yunxiao Sun,Yipeng Chen,Yifan Mao,Yifei Wu,Yongjie Lyu,Ziping Ma,Zhiqiang Fang,Zhihao Qiu,Ziyuan Huang,Zizheng Yang,Zhengyu He*

Main category: cs.CV

TL;DR: 我们提出了Ming-Flash-Omni，这是Ming-Omni的升级版，基于稀疏混合专家（MoE）的Ling-Flash-2.0变体，具有1000亿的总参数，其中每个token只有61亿是活跃的。这种架构极大地提升了高效扩展能力，增强了跨视觉、语音和语言的统一多模态智能，推动了人工通用智能（AGI）的发展。与前一代相比，Ming-Flash-Omni在多模态理解和生成方面表现出显著进步，特别是在语境ASR和方言感知ASR、图像生成以及文本到图像生成和生成性分割任务上创下新的记录。


<details>
  <summary>Details</summary>
Motivation: 设计高效的AI架构，提升模型容量，同时保持计算效率，最终推动人工通用智能（AGI）的发展。

Method: 采用了基于稀疏混合专家（MoE）的Ling-Flash-2.0变体，拥有1000亿总参数，其中61亿参数是活动状态。这种架构提高计算效率和模型容量的同时，增强了视觉，语音和语言等多模态任务的能力。

Result: 在不同的多模态任务中，Ming-Flash-Omni展现出了优于前代的能力。特别是在语境ASR，方言感知ASR和文本到图像生成等任务上，设定了新的性能基准。

Conclusion: 我们的架构为多模态任务提供了一个统一且强大的解决方案，使得在未来可以通过单一架构解决多种任务成为可能，为人工通用智能的发展奠定了坚实的基础。

Abstract: We propose Ming-Flash-Omni, an upgraded version of Ming-Omni, built upon a
sparser Mixture-of-Experts (MoE) variant of Ling-Flash-2.0 with 100 billion
total parameters, of which only 6.1 billion are active per token. This
architecture enables highly efficient scaling (dramatically improving
computational efficiency while significantly expanding model capacity) and
empowers stronger unified multimodal intelligence across vision, speech, and
language, representing a key step toward Artificial General Intelligence (AGI).
Compared to its predecessor, the upgraded version exhibits substantial
improvements across multimodal understanding and generation. We significantly
advance speech recognition capabilities, achieving state-of-the-art performance
in contextual ASR and highly competitive results in dialect-aware ASR. In image
generation, Ming-Flash-Omni introduces high-fidelity text rendering and
demonstrates marked gains in scene consistency and identity preservation during
image editing. Furthermore, Ming-Flash-Omni introduces generative segmentation,
a capability that not only achieves strong standalone segmentation performance
but also enhances spatial control in image generation and improves editing
consistency. Notably, Ming-Flash-Omni achieves state-of-the-art results in
text-to-image generation and generative segmentation, and sets new records on
all 12 contextual ASR benchmarks, all within a single unified architecture.

</details>


### [14] [The Generation Phases of Flow Matching: a Denoising Perspective](https://arxiv.org/abs/2510.24830)
*Anne Gagneux,Ségolène Martin,Rémi Gribonval,Mathurin Massias*

Main category: cs.CV

TL;DR: 这项工作从去噪的角度出发，设计了一个框架来探究生成过程的内在机制。通过建立流匹配模型和去噪器之间的正式联系，作者们能够设计出对生成过程有影响的扰动，从而更精确地描述生成过程的各个阶段及其表现。


<details>
  <summary>Details</summary>
Motivation: 虽然流匹配在生成过程中取得了一些成功，但对其质量的影响因素仍不明确。这项工作旨在通过去噪的视角来探究生成过程的内在机制，通过实验手段来深入了解这一领域。

Method: 作者将流匹配模型与去噪器联系起来，设计了一个实验框架，用于探究影响生成过程的质量因素，特别是引入了噪声和漂移两种影响因素，用以观察生成过程的不同阶段的表现。

Result: 这项研究表明，流匹配生成过程的不同阶段对去噪效果的影响不同，这一发现有助于更精确地了解流匹配模型的生成过程，并提出改进策略。

Conclusion: 这项研究揭示了流匹配模型在去噪过程中存在的不同阶段，并提出了通过对这些阶段的深入探究来提升生成质量的方法。

Abstract: Flow matching has achieved remarkable success, yet the factors influencing
the quality of its generation process remain poorly understood. In this work,
we adopt a denoising perspective and design a framework to empirically probe
the generation process. Laying down the formal connections between flow
matching models and denoisers, we provide a common ground to compare their
performances on generation and denoising. This enables the design of principled
and controlled perturbations to influence sample generation: noise and drift.
This leads to new insights on the distinct dynamical phases of the generative
process, enabling us to precisely characterize at which stage of the generative
process denoisers succeed or fail and why this matters.

</details>


### [15] [FruitProm: Probabilistic Maturity Estimation and Detection of Fruits and Vegetables](https://arxiv.org/abs/2510.24885)
*Sidharth Rai,Rahul Harsha Cheppally,Benjamin Vail,Keziban Yalçın Dokumacı,Ajay Sharda*

Main category: cs.CV

TL;DR: 本文提出了一个改进的实时对象检测器RT-DETRv2，通过引入一个专门的概率头部，将成熟度估计从离散分类问题转变为连续的概率学习任务，从而提供更丰富、更准确的成熟度评估，并保持了检测性能的优越性。实验表明，该概率方法优于传统的分类方法，并为现代农业的自动化系统提供了更为智能、不确定性的感知解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在成熟度估计中主要将其视为离散分类问题，这与生物成熟的连续性相冲突，导致信息丢失和模糊的类别边界。因此，本文旨在改进这一局限性，将其视为连续的概率任务，以提供更准确、丰富的成熟度评估。

Method: 提出了对实时对象检测器RT-DETRv2的架构改进，通过引入一个专门的概率头部，使模型可以预测每个检测对象在成熟度上的连续分布，同时学习成熟度的平均状态及其关联不确定性。

Result: 该模型保持了检测性能的优越性，实现了85.6%的平均平均精度(mAP)，并通过实验验证了其优于传统分类方法的精度和细化能力。

Conclusion: 通过改变成熟度估计的方式，实现了更准确、连续性的成熟度评估，不仅提高了检测性能，还为下游任务如选择性收获提供了信心度评分，这对于未来的不确定性感知自动化系统有重要意义。

Abstract: Maturity estimation of fruits and vegetables is a critical task for
agricultural automation, directly impacting yield prediction and robotic
harvesting. Current deep learning approaches predominantly treat maturity as a
discrete classification problem (e.g., unripe, ripe, overripe). This rigid
formulation, however, fundamentally conflicts with the continuous nature of the
biological ripening process, leading to information loss and ambiguous class
boundaries. In this paper, we challenge this paradigm by reframing maturity
estimation as a continuous, probabilistic learning task. We propose a novel
architectural modification to the state-of-the-art, real-time object detector,
RT-DETRv2, by introducing a dedicated probabilistic head. This head enables the
model to predict a continuous distribution over the maturity spectrum for each
detected object, simultaneously learning the mean maturity state and its
associated uncertainty. This uncertainty measure is crucial for downstream
decision-making in robotics, providing a confidence score for tasks like
selective harvesting. Our model not only provides a far richer and more
biologically plausible representation of plant maturity but also maintains
exceptional detection performance, achieving a mean Average Precision (mAP) of
85.6\% on a challenging, large-scale fruit dataset. We demonstrate through
extensive experiments that our probabilistic approach offers more granular and
accurate maturity assessments than its classification-based counterparts,
paving the way for more intelligent, uncertainty-aware automated systems in
modern agriculture

</details>


### [16] [Proper Body Landmark Subset Enables More Accurate and 5X Faster Recognition of Isolated Signs in LIBRAS](https://arxiv.org/abs/2510.24887)
*Daniele L. V. dos Santos,Thiago B. Pereira,Carlos Eduardo G. R. Alves,Richard J. M. G. Tello,Francisco de A. Boldt,Thiago M. Paixão*

Main category: cs.CV

TL;DR: 轻量级身体关键点检测在巴西手语（LIBRAS）的孤立手势识别中的可行性研究。通过关键点子集选择策略优化了识别性能，实现与现有最先进方法相当或更优的性能，同时减少了5倍以上的处理时间。此外，简单的样条插值可以有效弥补缺失关键点的问题，提高准确性。这些发现为构建高效的手势识别系统铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 研究使用轻量级身体关键点检测来提高孤立手势识别效率的问题，特别是当传统的关键点检测工具如OpenPose限制了处理时间时。

Method: 探索了关键点子集的选择策略以优化识别性能，同时使用了基于样条的插补来处理缺失的关键点问题。通过实验验证了提出的方法的有效性。

Result: 关键点子集选择能够使得识别性能与现有最先进方法相媲美或超越，同时节省了超过5倍的处理时间。样条插值能够有效提高准确性，弥补由于关键点丢失导致的识别性能下降。

Conclusion: 通过仔细选择关键点并结合简单的插补技术，可以实现高效的孤立手势识别，这为进一步发展可扩展的手语识别系统铺平了道路。

Abstract: This paper investigates the feasibility of using lightweight body landmark
detection for the recognition of isolated signs in Brazilian Sign Language
(LIBRAS). Although the skeleton-based approach by Alves et al. (2024) enabled
substantial improvements in recognition performance, the use of OpenPose for
landmark extraction hindered time performance. In a preliminary investigation,
we observed that simply replacing OpenPose with the lightweight MediaPipe,
while improving processing speed, significantly reduced accuracy. To overcome
this limitation, we explored landmark subset selection strategies aimed at
optimizing recognition performance. Experimental results showed that a proper
landmark subset achieves comparable or superior performance to state-of-the-art
methods while reducing processing time by more than 5X compared to Alves et al.
(2024). As an additional contribution, we demonstrated that spline-based
imputation effectively mitigates missing landmark issues, leading to
substantial accuracy gains. These findings highlight that careful landmark
selection, combined with simple imputation techniques, enables efficient and
accurate isolated sign recognition, paving the way for scalable Sign Language
Recognition systems.

</details>


### [17] [Pixels to Signals: A Real-Time Framework for Traffic Demand Estimation](https://arxiv.org/abs/2510.24902)
*H Mhatre,M Vyas,A Mittal*

Main category: cs.CV

TL;DR: 交通拥堵已成为城市发展中的一个严峻挑战，本文提出了一种优化交通流和减少延迟的综合方法，此方法的第一部分是车辆检测，该方法通过分析摄像头视频帧来提取车辆图像，并使用DBSCAN算法检测车辆，提供了一种实用性高且可扩展性强的解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着城市交通拥堵的加剧，导致了交通系统的延迟和低效，因此需要提出一种方法来优化交通流以减少交通拥堵带来的延迟和低效问题。

Method: 论文提出了一种综合方法的第一部分——车辆检测。该方法主要通过分析连续的视频帧来计算背景，并使用DBSCAN算法从图像背景中提取前景，识别和检测车辆。

Result: 提出的车辆检测方法具有计算效率高且对基础设置的要求低的特点，在现实世界中可部署性好且可扩展性强。

Conclusion: 通过应用图像处理技术以及DBSCAN算法，实现了对车辆的有效检测，为后续的交通预测和信号优化提供了基础数据。

Abstract: Traffic congestion is becoming a challenge in the rapidly growing urban
cities, resulting in increasing delays and inefficiencies within urban
transportation systems. To address this issue a comprehensive methodology is
designed to optimize traffic flow and minimize delays. The framework is
structured with three primary components: (a) vehicle detection, (b) traffic
prediction, and (c) traffic signal optimization. This paper presents the first
component, vehicle detection. The methodology involves analyzing multiple
sequential frames from a camera feed to compute the background, i.e. the
underlying roadway, by averaging pixel values over time. The computed
background is then utilized to extract the foreground, where the Density-Based
Spatial Clustering of Applications with Noise (DBSCAN) algorithm is applied to
detect vehicles. With its computational efficiency and minimal infrastructure
modification requirements, the proposed methodology offers a practical and
scalable solution for real-world deployment.

</details>


### [18] [VividCam: Learning Unconventional Camera Motions from Virtual Synthetic Videos](https://arxiv.org/abs/2510.24904)
*Qiucheng Wu,Handong Zhao,Zhixin Shu,Jing Shi,Yang Zhang,Shiyu Chang*

Main category: cs.CV

TL;DR: 提出了一种新的训练范式VividCam，它使扩散模型可以从合成视频中学习复杂的相机运动，从而释放了对真实训练视频的依赖。通过多个解耦策略，VividCam可以将相机运动的学习与合成外观瑕疵隔离开来，从而确保更多的鲁棒运动表示并减轻域转移问题。使用简单的合成数据就可以生成大量的精确控制和复杂相机运动。这些合成数据通常包含基本几何形状，低多边形3D场景并在Unity等引擎中高效渲染。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成模型可以较好地遵循外部相机控制，但它们仍然难以适应非传统相机运动。同时，收集到具有所需不常见相机运动的真实训练视频具有一定的挑战性。因此，为了生成更原创和艺术性的视频，需要找到一种能从合成视频学习复杂相机运动的方法，进而打破需要依靠大量真实训练视频的传统依赖关系。

Method: 提出了VividCam，这是一种新型的训练范式，旨在使扩散模型可以从合成视频中学习复杂的相机运动。VividCam集成了多个解耦策略，分别从合成外观中解耦并学习相机运动，从而确保更稳健的运动表示并减轻域转移问题。这些策略使模型能够通过简单的合成数据生成精确控制和复杂的相机运动。合成数据通常包括低多边形3D场景中的基本几何形状，可以在Unity等引擎中快速生成和渲染。

Result: 基于VividCam训练的扩散模型能够生成包含复杂相机运动的视频，这些镜头通过简单的合成数据输入来生成。实验结果显示，这些模型能够以较低的计算成本和较短的训练时间生成高质量、多种类的复杂相机运动，极大地提高了模型的灵活性和适应性。

Conclusion: 本文通过引入VividCam训练范式，解决现有文本到视频生成模型难以适应非传统相机运动的问题，通过减少对真实训练视频的依赖，达到了提高模型灵活性和生成能力的效果。证明了合成视频适用于训练扩散模型学习复杂的相机运动。

Abstract: Although recent text-to-video generative models are getting more capable of
following external camera controls, imposed by either text descriptions or
camera trajectories, they still struggle to generalize to unconventional camera
motions, which is crucial in creating truly original and artistic videos. The
challenge lies in the difficulty of finding sufficient training videos with the
intended uncommon camera motions. To address this challenge, we propose
VividCam, a training paradigm that enables diffusion models to learn complex
camera motions from synthetic videos, releasing the reliance on collecting
realistic training videos. VividCam incorporates multiple disentanglement
strategies that isolates camera motion learning from synthetic appearance
artifacts, ensuring more robust motion representation and mitigating domain
shift. We demonstrate that our design synthesizes a wide range of precisely
controlled and complex camera motions using surprisingly simple synthetic data.
Notably, this synthetic data often consists of basic geometries within a
low-poly 3D scene and can be efficiently rendered by engines like Unity. Our
video results can be found in https://wuqiuche.github.io/VividCamDemoPage/ .

</details>


### [19] [Understanding Multi-View Transformers](https://arxiv.org/abs/2510.24907)
*Michal Stary,Julien Gaubil,Ayush Tewari,Vincent Sitzmann*

Main category: cs.CV

TL;DR: 本文提出了一种探究和可视化多视图变换器内部机制的方法，并以DUSt3R模型为示例，分析了其残差连接中的3D表示，揭示了其隐含状态的发展过程和各层的作用，同时表明该模型相较于具有更强归纳偏好的显式全局姿态的方法有何不同。


<details>
  <summary>Details</summary>
Motivation: 多视图变换器如DUSt3R能够通过前馈方式解决3D视觉任务，但其内部机制并不清楚，这使得在数据扩展之外的改进变得困难，并且也使得它们难以应用于安全性、可靠性要求高的场景。本研究旨在探究和可视化这些模型的内部机制，以促进进一步改进和应用。

Method: 通过研究多视图变换器层的残差连接中的3D表示，以一种变体形式的DUSt3R模型为例，探究其隐含状态的发展过程，每层的作用，以及它与具有更强归纳偏好（显式全局姿态）的方法之间的差异。同时展示了这种变体的DUSt3R模型如何估计对应关系并使用重建的几何进行细化。所使用的代码可以在https://github.com/JulienGaubil/und3rstand 上找到。

Result: 发现了DUSt3R模型内部机制的一些关键特征，并展示了如何通过残差连接中的3D表示来理解其发展过程和各层的作用。这表明了尽管多视图变换器具有黑盒特性，但仍可能存在探究和改良的方法。

Conclusion: 通过分析用于前馈3D任务的多视图变换器DUSt3R内部机制，我们展示了探索这些模型内部机制的潜在路径，为进一步的改进和应用提供了依据。这项工作对安全性、可靠性要求高的应用场景尤为重要。

Abstract: Multi-view transformers such as DUSt3R are revolutionizing 3D vision by
solving 3D tasks in a feed-forward manner. However, contrary to previous
optimization-based pipelines, the inner mechanisms of multi-view transformers
are unclear. Their black-box nature makes further improvements beyond data
scaling challenging and complicates usage in safety- and reliability-critical
applications. Here, we present an approach for probing and visualizing 3D
representations from the residual connections of the multi-view transformers'
layers. In this manner, we investigate a variant of the DUSt3R model, shedding
light on the development of its latent state across blocks, the role of the
individual layers, and suggest how it differs from methods with stronger
inductive biases of explicit global pose. Finally, we show that the
investigated variant of DUSt3R estimates correspondences that are refined with
reconstructed geometry. The code used for the analysis is available at
https://github.com/JulienGaubil/und3rstand .

</details>


### [20] [Modality-Aware SAM: Sharpness-Aware-Minimization Driven Gradient Modulation for Harmonized Multimodal Learning](https://arxiv.org/abs/2510.24919)
*Hossein R. Nowdeh,Jie Ji,Xiaolong Ma,Fatemeh Afghah*

Main category: cs.CV

TL;DR: 提出了一种新的模态感知框架M-SAM，该框架能够应用于多种模态，并支持早期和晚期融合的应用场景。通过识别主导模态并调节损失来优先考虑主导模态的鲁棒性，同时更新权重以增强其他模态的贡献，从而提高整体性能和平衡性。实验表明M-SAM在多种数据集上优于现有最优的方法。


<details>
  <summary>Details</summary>
Motivation: 在多模态学习中，主导模态常常会过度抑制其他模态的学习，限制了模型的泛化能力。因此，有必要提出一种能够平衡不同模态贡献的方法，从而避免这种情况的发生。M-SAM的提出正是为了应对这个问题，希望通过识别主导模态并调整损失以及更新权重的方式，来提高模型的鲁棒性和整体性能。

Method: M-SAM在每次迭代中进行三个步骤的优化。第一，利用Shapley值计算不同模态对准确率的贡献，识别出主导模态；第二，抽平损失景观，即调节损失以优先考虑主导模态的鲁棒性；第三，通过传播调制后的梯度来进行权重的更新。通过这种方式，M-SAM能够强化主导模态的学习，同时增强了其他模态的贡献，允许模型探索和利用补充特性，提高整体性能。

Result: 实验在四个不同的数据集上证明了，M-SAM优于最新的最先进的优化和梯度操作方法。它不仅能提高多模态学习的整体性能，还能很好地平衡不同模态的贡献，确保模型更好的泛化能力。

Conclusion: 论文提出了一个新的策略M-SAM，通过对主导模态进行识别并调节损失的方式，确保了模型在主导模态的鲁棒性下探索不同模态的贡献，从而提高模型的整体性能和泛化能力。这为多模态学习提供了一个新的解决方案。

Abstract: In multimodal learning, dominant modalities often overshadow others, limiting
generalization. We propose Modality-Aware Sharpness-Aware Minimization (M-SAM),
a model-agnostic framework that applies to many modalities and supports early
and late fusion scenarios. In every iteration, M-SAM in three steps optimizes
learning. \textbf{First, it identifies the dominant modality} based on
modalities' contribution in the accuracy using Shapley. \textbf{Second, it
decomposes the loss landscape}, or in another language, it modulates the loss
to prioritize the robustness of the model in favor of the dominant modality,
and \textbf{third, M-SAM updates the weights} by backpropagation of modulated
gradients. This ensures robust learning for the dominant modality while
enhancing contributions from others, allowing the model to explore and exploit
complementary features that strengthen overall performance. Extensive
experiments on four diverse datasets show that M-SAM outperforms the latest
state-of-the-art optimization and gradient manipulation methods and
significantly balances and improves multimodal learning.

</details>


### [21] [IBIS: A Powerful Hybrid Architecture for Human Activity Recognition](https://arxiv.org/abs/2510.24936)
*Alison M. Fernandes,Hermes I. Del Monego,Bruno S. Chang,Anelise Munaretto,Hélder M. Fontes,Rui L. Campos*

Main category: cs.CV

TL;DR: 提出了一种名为IBIS的新颖混合架构，结合了Inception-BiLSTM和支持向量机（SVM），用于克服Wi-Fi感应中的过拟合问题。该方法在多普勒派生数据上的运动识别准确率接近99％。


<details>
  <summary>Details</summary>
Motivation: 动机在于解决Wi-Fi感应领域中常见的过拟合问题，提高模型的泛化能力，使其更适用于健康监测、空间占用分析和基于手势的物联网控制等应用领域。过拟合问题导致模型在训练数据上表现良好，但在新数据上表现不佳。

Method: 提出了一种名为IBIS的混合架构，结合Inception-BiLSTM和SVM。这种方法特别设计来改进模型的泛化能力和创建更稳健的分类边界。实验是在多普勒数据上进行并取得显著效果的。

Result: 在多普勒数据上应用IBIS方法后，运动识别的准确率达到了几乎99%，说明该解决方案非常有效。

Conclusion: 我们开发的IBIS架构成功地提高了模型的泛化能力和多普勒数据的运动识别精度，这证实了我们方法的有效性和重要性。

Abstract: The increasing interest in Wi-Fi sensing stems from its potential to capture
environmental data in a low-cost, non-intrusive way, making it ideal for
applications like healthcare, space occupancy analysis, and gesture-based IoT
control. However, a major limitation in this field is the common problem of
overfitting, where models perform well on training data but fail to generalize
to new data. To overcome this, we introduce a novel hybrid architecture that
integrates Inception-BiLSTM with a Support Vector Machine (SVM), which we refer
to as IBIS. Our IBIS approach is uniquely engineered to improve model
generalization and create more robust classification boundaries. By applying
this method to Doppler-derived data, we achieve a movement recognition accuracy
of nearly 99%. Comprehensive performance metrics and confusion matrices confirm
the significant effectiveness of our proposed solution.

</details>


### [22] [FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for Pressure Ulcer Severity Classification with Reasoning](https://arxiv.org/abs/2510.24980)
*Reza Saadati Fard,Emmanuel Agu,Palawat Busaranuvong,Deepak Kumar,Shefalika Gautam,Bengisu Tulu,Diane Strong,Lorraine Loretz*

Main category: cs.CV

TL;DR: 本文提出了一种用于压力性溃疡严重程度分类的Fine-Tuned Agentic Reflection Multimodal (FT-ARM)模型。该模型通过迭代优化视觉特征和文本编码的临床知识，提高了准确性、一致性及解释性。在PIID数据集上，FT-ARM的分类准确率为85%，优于先前的CNN模型4%。此外，该模型能够实时部署并在临床实践中提供直白的解释，以帮助患者护理的改进。


<details>
  <summary>Details</summary>
Motivation: 准确分类压力性溃疡(PUs)的严重程度是确保高效治疗的基础，但这对于医生来说是一项挑战。当前的人工智能方法虽然准确度较高但缺乏透明度和解释性，可能导致医生对结果缺乏信任。基于此，研究人员开发了FT-ARM模型，旨在提高准确性并使结果具有一定解释性，从而提升医生对AI系统的信任以支持临床决策。

Method: 模型基于一个大型语言模型进行微调，含有一个主动反映机制。模型结合了视觉和文本信息，能通过主动反思机制对自己做评估和修正，提升模型准确性和一致性。该模型在压力性溃疡图像数据集(PIID)上表现良好，且可通过人类可理解的方式解释其结论。

Result: 在PIID数据集上，FT-ARM模型达到了85%的分类准确率，比最佳的现有CNN模型高出4%。此外，该模型的解释功能改进了AI系统的临床可用性和透明性。这使得AI系统能够在实时应用场景中使用，并提供可理解的解释性，加强医生的信任和接受度。

Conclusion: 研究提出了FT-ARM模型，它可以更好地帮助医生在压力性溃疡的诊断上作出决定，通过提升透明度和解释性来增强医生的信任度。该模型的实时性和解释性有助于改进患者的护理。

Abstract: Pressure ulcers (PUs) are a serious and prevalent healthcare concern.
Accurate classification of PU severity (Stages I-IV) is essential for proper
treatment but remains challenging due to subtle visual distinctions and
subjective interpretation, leading to variability among clinicians. Prior
AI-based approaches using Convolutional Neural Networks (CNNs) and Vision
Transformers (ViTs) achieved promising accuracy but offered limited
interpretability. We present FT-ARM (Fine-Tuned Agentic Reflection Multimodal
model), a fine-tuned multimodal large language model (MLLM) with an agentic
self-reflection mechanism for pressure ulcer severity classification. Inspired
by clinician-style diagnostic reassessment, FT-ARM iteratively refines its
predictions by reasoning over visual features and encoded clinical knowledge
from text, enhancing both accuracy and consistency. On the publicly available
Pressure Injury Image Dataset (PIID), FT-ARM, fine-tuned from LLaMA 3.2 90B,
achieved 85% accuracy in classifying PU stages I-IV, surpassing prior CNN-based
models by +4%. Unlike earlier CNN/ViT studies that relied solely on offline
evaluations, FT-ARM is designed and tested for live inference, reflecting
real-time deployment conditions. Furthermore, it produces clinically grounded
natural-language explanations, improving interpretability and trust. By
integrating fine-tuning and reflective reasoning across multimodal inputs,
FT-ARM advances the reliability, transparency, and clinical applicability of
automated wound assessment systems, addressing the critical need for consistent
and explainable PU staging to support improved patient care.

</details>


### [23] [Efficient License Plate Recognition via Pseudo-Labeled Supervision with Grounding DINO and YOLOv8](https://arxiv.org/abs/2510.25032)
*Zahra Ebrahimi Vargoorani,Amir Mohammad Ghoreyshi,Ching Yee Suen*

Main category: cs.CV

TL;DR: 本文提出了一种使用YOLOv8的深度学习策略来提高车牌识别系统的准确性，特别是在复杂的环境条件下。该方法通过结合少量人工标注数据和由Grounding DINO生成的伪标签来训练检测模型，提高了数据集规模和标签质量，从而提高了模型的性能。在CENPARMI和UFPR-ALPR数据集上，该方法分别实现了94%和91%的召回率，并报告了字符错误率以进一步衡量系统性能。


<details>
  <summary>Details</summary>
Motivation: 自动车牌识别系统（ALPR）在交通控制、停车场管理、车辆追踪、收费和执法等领域非常重要，但因环境因素（如光照、雨水、灰尘）、车辆速度、摄像头角度和图像质量的问题，其开发面临挑战。本文旨在通过深度学习技术，特别是使用YOLOv8和Grounding DINO模型，解决这些挑战，提高ALPR系统的准确性。

Method: 提出的方法采用YOLOv8进行车牌检测和识别。通过结合少量手工标记的数据和由Grounding DINO生成的伪标签来训练模型，从而扩展数据集规模，提高标注质量，减少手动标注的工作量。这种方法使用了来自安大略省、魁北克省、加利福尼亚州和纽约州的数据集进行性能验证。

Result: 在CENPARMI和UFPR-ALPR数据集上实现了94%和91%的召回率。此外，对两个数据集的字符错误率也进行了报告，以提供对系统性能的深入理解。

Conclusion: 通过使用YOLOv8结合Grounding DINO进行车牌检测和识别，本文提出的方法在提高ALPR系统准确性方面取得了显著进展。该方法通过使用半监督学习框架，有效提高了数据集规模和标签质量，并在不同地理区域的测试中展示了良好的性能表现。

Abstract: Developing a highly accurate automatic license plate recognition system
(ALPR) is challenging due to environmental factors such as lighting, rain, and
dust. Additional difficulties include high vehicle speeds, varying camera
angles, and low-quality or low-resolution images. ALPR is vital in traffic
control, parking, vehicle tracking, toll collection, and law enforcement
applications. This paper proposes a deep learning strategy using YOLOv8 for
license plate detection and recognition tasks. This method seeks to enhance the
performance of the model using datasets from Ontario, Quebec, California, and
New York State. It achieved an impressive recall rate of 94% on the dataset
from the Center for Pattern Recognition and Machine Intelligence (CENPARMI) and
91% on the UFPR-ALPR dataset. In addition, our method follows a semi-supervised
learning framework, combining a small set of manually labeled data with
pseudo-labels generated by Grounding DINO to train our detection model.
Grounding DINO, a powerful vision-language model, automatically annotates many
images with bounding boxes for license plates, thereby minimizing the reliance
on labor-intensive manual labeling. By integrating human-verified and
model-generated annotations, we can scale our dataset efficiently while
maintaining label quality, which significantly enhances the training process
and overall model performance. Furthermore, it reports character error rates
for both datasets, providing additional insight into system performance.

</details>


### [24] [Auto3DSeg for Brain Tumor Segmentation from 3D MRI in BraTS 2023 Challenge](https://arxiv.org/abs/2510.25058)
*Andriy Myronenko,Dong Yang,Yufan He,Daguang Xu*

Main category: cs.CV

TL;DR: 我们的解决方案在BraTS 2023挑战中使用Auto3DSeg从MONAI取得优异成绩，获得了三个第一和两个第二。


<details>
  <summary>Details</summary>
Motivation: 通过参加BraTS 2023的多个分割挑战来验证Auto3DSeg的效率和准确性，特别是对于脑部肿瘤的诊断和研究提供有力支持。

Method: 使用了Auto3DSeg框架进行自动3D分割，并参与了BraTS 2023年所有的五个分割挑战。

Result: 在总共五个挑战中，在脑转移、脑肿瘤（脑膜瘤）和BraTS-Africa挑战中获得了第一名，而在成人和儿科胶质瘤挑战中获得了第二名。

Conclusion: 本次研究证明了Auto3DSeg在脑部分割任务中的优越性和有效性，展示了其在医疗影像处理领域的广泛潜力。

Abstract: In this work, we describe our solution to the BraTS 2023 cluster of
challenges using Auto3DSeg from MONAI. We participated in all 5 segmentation
challenges, and achieved the 1st place results in three of them: Brain
Metastasis, Brain Meningioma, BraTS-Africa challenges, and the 2nd place
results in the remaining two: Adult and Pediatic Glioma challenges.

</details>


### [25] [DRIP: Dynamic patch Reduction via Interpretable Pooling](https://arxiv.org/abs/2510.25067)
*Yusen Peng,Sachin Kumar*

Main category: cs.CV

TL;DR: 本文提出了Dynamic patch Reduction via Interpretable Pooling (DRIP)，该方法可以在视觉编码器的深层动态地合并输入图像的tokens，以减少计算量并且保持类似的性能。这不仅在ImageNet从头开始训练和CLIP对比预训练中得以验证，在科学领域的生物数据集的连续预训练中也得到了更好的结果。


<details>
  <summary>Details</summary>
Motivation: 由于大规模预训练的成本高昂，效率问题使得研究人员不愿意从头开始训练视觉语言模型。因此，本文的动机是提出一种高效的方法来减少预训练的计算量。

Method: 本文提出了一种名为Dynamic patch Reduction via Interpretable Pooling (DRIP)的新方法，这种技术能够根据输入图像动态地在视觉编码器的深层合并tokens。这种方法是一种可以自适应地减少计算量的技术，同时保证了性能的竞争力。

Result: 实验结果显示，在ImageNet数据集和CLIP对比预训练中，DRIP方法能够显著地降低GFLOP，同时保持性能不减少。甚至在科学领域大规模生物数据集上验证了该方法的优越性。

Conclusion: 通过提出Dynamic patch Reduction via Interpretable Pooling (DRIP)，本文成功地提供了一种更高效的方法来减少大规模视觉语言模型预训练的计算量，能够在多个领域的多种任务上取得相似或更好的性能表现。

Abstract: Recently, the advances in vision-language models, including contrastive
pretraining and instruction tuning, have greatly pushed the frontier of
multimodal AI. However, owing to the large-scale and hence expensive
pretraining, the efficiency concern has discouraged researchers from attempting
to pretrain a vision language model from scratch. In this work, we propose
Dynamic patch Reduction via Interpretable Pooling (DRIP), which adapts to the
input images and dynamically merges tokens in the deeper layers of a visual
encoder. Our results on both ImageNet training from scratch and CLIP
contrastive pretraining demonstrate a significant GFLOP reduction while
maintaining comparable classification/zero-shot performance. To further
validate our proposed method, we conduct continual pretraining on a large
biology dataset, extending its impact into scientific domains.

</details>


### [26] [Vision-Language Integration for Zero-Shot Scene Understanding in Real-World Environments](https://arxiv.org/abs/2510.25070)
*Manjunath Prasad Holenarasipura Rajiv,B. M. Vidyavathi*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉和语言集成的框架，通过融合预训练的视觉编码器和大规模语言模型，实现了视觉和文本模态之间的语义对齐，使得在没有先验标签的情况下也能对新物体、行为和上下文进行零样本场景理解。实验展示了该方法在多个数据集上的表现优于现有零样本模型，并在语义一致性和准确率指标上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 由于自然场景的复杂性和多变性使得零样本场景理解在真实场景中存在较大挑战，此工作旨在开发一种方法来利用自然语言作为桥梁，使模型能够泛化处理未见过的类别和上下文，从而增强真实场景理解能力。

Method: 该方法开发了一个统一的模型，该模型将视觉输入和文本提示嵌入到共享空间中，然后通过多模态融合和推理层进行上下文解释。该模型利用了预训练的视觉编码器和大型语言模型的集成。通过这种语义对齐技术，提高了模型零样本场景理解的能力。

Result: 实验结果显示，在Visual Genome、COCO、ADE20K以及定制的真实世界数据集上，该方法在物体识别、活动检测和场景描述方面表现出色，优于最先进的零样本模型。特别是在top-1准确率上有高达18%的提升，并且在语义一致性的度量指标上也有显著提高。

Conclusion: 本文提出的系统通过综合视觉和语言模型，实现了增强的真实场景零样本理解能力，展示出了跨模态对齐和语言锚定技术对提高泛化性能的效果。

Abstract: Zero-shot scene understanding in real-world settings presents major
challenges due to the complexity and variability of natural scenes, where
models must recognize new objects, actions, and contexts without prior labeled
examples. This work proposes a vision-language integration framework that
unifies pre-trained visual encoders (e.g., CLIP, ViT) and large language models
(e.g., GPT-based architectures) to achieve semantic alignment between visual
and textual modalities. The goal is to enable robust zero-shot comprehension of
scenes by leveraging natural language as a bridge to generalize over unseen
categories and contexts. Our approach develops a unified model that embeds
visual inputs and textual prompts into a shared space, followed by multimodal
fusion and reasoning layers for contextual interpretation. Experiments on
Visual Genome, COCO, ADE20K, and custom real-world datasets demonstrate
significant gains over state-of-the-art zero-shot models in object recognition,
activity detection, and scene captioning. The proposed system achieves up to
18% improvement in top-1 accuracy and notable gains in semantic coherence
metrics, highlighting the effectiveness of cross-modal alignment and language
grounding in enhancing generalization for real-world scene understanding.

</details>


### [27] [PSTF-AttControl: Per-Subject-Tuning-Free Personalized Image Generation with Controllable Face Attributes](https://arxiv.org/abs/2510.25084)
*Xiang liu,Zhaoxiang Liu,Huan Hu,Zipeng Wang,Ping Chen,Zezhou Chen,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: 本文提出了一种新的PSTF方法，该方法可以在不牺牲面部身份高保真的同时，对面部属性实现精细化控制，而无需额外的微调或针对个体身份的训练数据。我们的方法利用Triplet-Decoupled Cross-Attention模块，整合了面部身份、属性特征和文本嵌入，可以让用户生成具有个性化特征的高质量人脸图像，并且使用简便，易于推广。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化图像生成方法在精准控制面部属性方面存在不足，尤其是在无需针对单个主体进行调整的情况下，很难同时实现面部身份的高保真度和面部属性的精细化控制。因此，开发一种既具有PSTF特性又能精确控制面部属性的新方法是一个亟待解决的问题。

Method: 提出了一种使用脸识别模型来提取面部身份特征并将这些特征映射到StyleGAN2的$W^+$隐空间的方法，同时引入了一个Triplet-Decoupled Cross-Attention模块到UNet架构，实现对身份和属性信息的清晰分离。该模型在FFHQ数据集上进行训练，无需额外的微调或个体身份特定数据集的支持。

Result: 实验结果显示，在没有进行额外微调或专门的个体身份训练数据的情况下，此方法能够生成具有面部个性化特征的高质量人脸图像，进一步验证了该方法的有效性和适用性。该方法对精准控制面部属性与个性化之间的平衡处理得相当出色。

Conclusion: 通过引入Triplet-Decoupled Cross-Attention模块，本文提出的方法能够在无需额外培训数据的情况下，同时实现面部身份的高保真度和面部属性的精细化控制。此方法为面部图像合成提供了一个更高效、使用更简便的解决方案。

Abstract: Recent advancements in personalized image generation have significantly
improved facial identity preservation, particularly in fields such as
entertainment and social media. However, existing methods still struggle to
achieve precise control over facial attributes in a per-subject-tuning-free
(PSTF) way. Tuning-based techniques like PreciseControl have shown promise by
providing fine-grained control over facial features, but they often require
extensive technical expertise and additional training data, limiting their
accessibility. In contrast, PSTF approaches simplify the process by enabling
image generation from a single facial input, but they lack precise control over
facial attributes. In this paper, we introduce a novel, PSTF method that
enables both precise control over facial attributes and high-fidelity
preservation of facial identity. Our approach utilizes a face recognition model
to extract facial identity features, which are then mapped into the $W^+$
latent space of StyleGAN2 using the e4e encoder. We further enhance the model
with a Triplet-Decoupled Cross-Attention module, which integrates facial
identity, attribute features, and text embeddings into the UNet architecture,
ensuring clean separation of identity and attribute information. Trained on the
FFHQ dataset, our method allows for the generation of personalized images with
fine-grained control over facial attributes, while without requiring additional
fine-tuning or training data for individual identities. We demonstrate that our
approach successfully balances personalization with precise facial attribute
control, offering a more efficient and user-friendly solution for high-quality,
adaptable facial image synthesis. The code is publicly available at
https://github.com/UnicomAI/PSTF-AttControl.

</details>


### [28] [Visual Diversity and Region-aware Prompt Learning for Zero-shot HOI Detection](https://arxiv.org/abs/2510.25094)
*Chanhyeong Yang,Taehoon Song,Jihwan Park,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 该论文提出了一种视觉多样性意识的同时结合区域特定概念的提示学习策略（VDRP），用于零样本的人与物体交互检测，显著提高了识别的准确性和区分度，特别是在处理视觉多样性和视觉混淆方面的表现优于现有方法，在HICO-DET数据集上的实验表明该方法在零样本设定下达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决零样本人与物体交互检测中视觉多样性和视觉混淆带来的挑战，通过改进提示学习策略来提高识别成功率和区分度，特别是对于处理同一动词的不同姿势和上下文变化，以及不同动词之间的视觉模式相似性。

Method: 提出了一个名为VDRP的框架，该框架包括一种视觉多样性意识的提示学习策略，即向上下文嵌入中注入组级别的视觉变化，同时使用高斯扰动来鼓励提示捕捉动词的多样视觉变化。另外，将来自人体、物体质心区域和两者交集区域的特定概念提取出来，用于增强视觉多样性意识的提示嵌入，形成区域感知的提示。

Result: 通过与现有方法对比实验，在HICO-DET数据集上验证了我们的方法在四个零样本评估配置下的优越性能。该方法在解决类内视觉多样性和类间视觉混淆方面表现尤其出色。

Conclusion: 研究提出了一种有效的零样本人与物体交互检测方法，通过视觉多样性感知的提示学习策略和区域特定提示，显著提升了处理复杂视觉样本的表现，具有很好的应用前景。

Abstract: Zero-shot Human-Object Interaction detection aims to localize humans and
objects in an image and recognize their interaction, even when specific
verb-object pairs are unseen during training. Recent works have shown promising
results using prompt learning with pretrained vision-language models such as
CLIP, which align natural language prompts with visual features in a shared
embedding space. However, existing approaches still fail to handle the visual
complexity of interaction, including (1) intra-class visual diversity, where
instances of the same verb appear in diverse poses and contexts, and (2)
inter-class visual entanglement, where distinct verbs yield visually similar
patterns. To address these challenges, we propose VDRP, a framework for Visual
Diversity and Region-aware Prompt learning. First, we introduce a visual
diversity-aware prompt learning strategy that injects group-wise visual
variance into the context embedding. We further apply Gaussian perturbation to
encourage the prompts to capture diverse visual variations of a verb. Second,
we retrieve region-specific concepts from the human, object, and union regions.
These are used to augment the diversity-aware prompt embeddings, yielding
region-aware prompts that enhance verb-level discrimination. Experiments on the
HICO-DET benchmark demonstrate that our method achieves state-of-the-art
performance under four zero-shot evaluation settings, effectively addressing
both intra-class diversity and inter-class visual entanglement. Code is
available at https://github.com/mlvlab/VDRP.

</details>


### [29] [AtlasGS: Atlanta-world Guided Surface Reconstruction with Implicit Structured Gaussians](https://arxiv.org/abs/2510.25129)
*Xiyu Zhang,Chong Bao,Yipeng Chen,Hongjia Zhai,Yitong Dong,Hujun Bao,Zhaopeng Cui,Guofeng Zhang*

Main category: cs.CV

TL;DR: 提出了一种Atlanta-world指导下的隐式结构化高斯撒点方法，用于室内和城市场景的光滑重建，同时保持高频细节和渲染效率。通过利用Atlanta-world模型和语义GS表示，提高了低纹理区域的表面重建准确性。实验证明优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有几何先验在处理室内和城市设置中的低纹理区域时缺乏全局一致性，Gaussian Splatting和隐式SDF场方法存在断开或计算效率低的问题。这导致细节丢失，因此提出改进方案。

Method: 提出Atlanta-world指导下的隐式结构化高斯撒点方法，结合语义GS表示，采用可学习平面指示符来确保全局准确的表面重建。

Result: 实验证明，在室内和城市环境中，新方法在表面重建质量上优于现有技术。能够更准确地重建低纹理区域，并保持高频细节和渲染效率。

Conclusion: 通过布置Atlanta-world和语义GS表示，新的方法可以在不牺牲效率和高频细节的情况下实现光滑重建，适用于复杂的室内和城市环境。

Abstract: 3D reconstruction of indoor and urban environments is a prominent research
topic with various downstream applications. However, existing geometric priors
for addressing low-texture regions in indoor and urban settings often lack
global consistency. Moreover, Gaussian Splatting and implicit SDF fields often
suffer from discontinuities or exhibit computational inefficiencies, resulting
in a loss of detail. To address these issues, we propose an Atlanta-world
guided implicit-structured Gaussian Splatting that achieves smooth indoor and
urban scene reconstruction while preserving high-frequency details and
rendering efficiency. By leveraging the Atlanta-world model, we ensure the
accurate surface reconstruction for low-texture regions, while the proposed
novel implicit-structured GS representations provide smoothness without
sacrificing efficiency and high-frequency details. Specifically, we propose a
semantic GS representation to predict the probability of all semantic regions
and deploy a structure plane regularization with learnable plane indicators for
global accurate surface reconstruction. Extensive experiments demonstrate that
our method outperforms state-of-the-art approaches in both indoor and urban
scenes, delivering superior surface reconstruction quality.

</details>


### [30] [DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications](https://arxiv.org/abs/2510.25140)
*Malaisree P,Youwai S,Kitkobsin T,Janrungautai S,Amorndechaphon D,Rojanavasu P*

Main category: cs.CV

TL;DR: 本文介绍了DINO-YOLO，一种结合YOLOv12和DINOv3自监督视觉变换器的数据高效检测方法，实现了在隧道裂缝、建筑安全装备及KITTI数据集上的性能提升，并在不同场景下保持实时推断速度。小型和中型架构分别通过不同的整合策略获得最佳性能，且在计算效率和性能之间表现出良好的平衡，适用于数据限制的环境中的应用。


<details>
  <summary>Details</summary>
Motivation: 在工程应用中，目标检测受限于特定领域标记数据的不足。本文旨在通过结合YOLOv12和DINOv3自监督视觉变换器，提供一种数据高效的目标检测方法以改善这一状况。

Method: DINO-YOLO将DINOv3特性融合在输入预处理和中下层增强两个阶段，实验在多个数据集上验证其改进效果，并系统地消融了Yolo不同规模和DINOv3不同变体的效果。发现中型架构具有较为理想的性能和效率平衡。

Result: 实验表明，方法在隧道裂缝检测等三个数据集上比基线模型获得显著性能提升，同时在不同规模下通过适当的整合策略保持了实时推断速度，并且在计算资源上显示出良好效率。目前，该方法在小数据集下达到了最先进的性能表现。

Conclusion: 综上所述，DINO-YOLO是一种在数据受限条件下显著优于基线模型的实用方法，可以有效提升工程应用中的目标检测表现，为施工安全监控和基础设施检测提供了解决方案。

Abstract: Object detection in civil engineering applications is constrained by limited
annotated data in specialized domains. We introduce DINO-YOLO, a hybrid
architecture combining YOLOv12 with DINOv3 self-supervised vision transformers
for data-efficient detection. DINOv3 features are strategically integrated at
two locations: input preprocessing (P0) and mid-backbone enhancement (P3).
Experimental validation demonstrates substantial improvements: Tunnel Segment
Crack detection (648 images) achieves 12.4% improvement, Construction PPE (1K
images) gains 13.7%, and KITTI (7K images) shows 88.6% improvement, while
maintaining real-time inference (30-47 FPS). Systematic ablation across five
YOLO scales and nine DINOv3 variants reveals that Medium-scale architectures
achieve optimal performance with DualP0P3 integration (55.77% mAP@0.5), while
Small-scale requires Triple Integration (53.63%). The 2-4x inference overhead
(21-33ms versus 8-16ms baseline) remains acceptable for field deployment on
NVIDIA RTX 5090. DINO-YOLO establishes state-of-the-art performance for civil
engineering datasets (<10K images) while preserving computational efficiency,
providing practical solutions for construction safety monitoring and
infrastructure inspection in data-constrained environments.

</details>


### [31] [Revisiting Reconstruction-based AI-generated Image Detection: A Geometric Perspective](https://arxiv.org/abs/2510.25141)
*Wan Jiang,Jing Yan,Ruixuan Zhang,Xiaojing Chen,Changtao Miao,Zhe Li,Chenhao Lin,Yunfeng Diao,Richang Hong*

Main category: cs.CV

TL;DR: 本文提出了一种名为ReGap的新方法，用于改进AI生成图像的检测准确性。该方法基于结构化编辑操作引入可控扰动，来计算动态重构误差，从而提高检测性能，表现出优于现有方法的准确率，并且对常见后处理操作具有鲁棒性，适用于多种条件下的图像检测任务。


<details>
  <summary>Details</summary>
Motivation: 现有的基于重构的方法理论基础不充分，可靠性低，对于AI生成图像的检测表现不佳。因此，本文旨在通过引入新的理论框架和方法，来提高AI生成图像检测的真实性和可靠性。

Method: 本文提出的方法名为ReGap，它通过利用编辑操作来测量重构误差，采用动态重构误差代替单一重构误差，增强了误差差异，提高了检测准确度。

Result: 实验结果表明，本文提出的方法在检测AI生成图像时优于现有方法，表现出较高的准确率和鲁棒性，并且能够有效应对各种复杂的图像条件。

Conclusion: 本文通过引入新的理论框架和方法，提高了AI生成图像检测的真实性和可靠性，为图像真实性检测提供了新的解决方案。

Abstract: The rise of generative Artificial Intelligence (AI) has made detecting
AI-generated images a critical challenge for ensuring authenticity. Existing
reconstruction-based methods lack theoretical foundations and on empirical
heuristics, limiting interpretability and reliability. In this paper, we
introduce the Jacobian-Spectral Lower Bound for reconstruction error from a
geometric perspective, showing that real images off the reconstruction manifold
exhibit a non-trivial error lower bound, while generated images on the manifold
have near-zero error. Furthermore, we reveal the limitations of existing
methods that rely on static reconstruction error from a single pass. These
methods often fail when some real images exhibit lower error than generated
ones. This counterintuitive behavior reduces detection accuracy and requires
data-specific threshold tuning, limiting their applicability in real-world
scenarios. To address these challenges, we propose ReGap, a training-free
method that computes dynamic reconstruction error by leveraging structured
editing operations to introduce controlled perturbations. This enables
measuring error changes before and after editing, improving detection accuracy
by enhancing error separation. Experimental results show that our method
outperforms existing baselines, exhibits robustness to common post-processing
operations and generalizes effectively across diverse conditions.

</details>


### [32] [EA3D: Online Open-World 3D Object Extraction from Streaming Videos](https://arxiv.org/abs/2510.25146)
*Xiaoyu Zhou,Jingqi Wang,Yuang Jia,Yongtao Wang,Deqing Sun,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: ExtractAnything3D (EA3D)是一个在线框架，用于开放世界的3D物体提取，它结合了几何重建和整体场景理解。给定连续视频，EA3D使用视觉-语言和2D视觉基础编码器动态解析每帧，提取物体层级知识，并将这些知识嵌入到高斯特征图中。通过迭代估计视觉里程计和与新观察结果的增量更新，EA3D提高了几何重建和语义理解的性能。实验结果证明了EA3D的有效性，适用于多种任务。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景理解方法受限于离线收集的多视角数据或预构造的3D几何形状。作者提出了提取任何3D物体的统一在线框架EA3D，该框架既包括几何重建也涵盖全面的场景理解，以克服这些限制。这项研究的动机是创建一个能够同时完成这两项任务的框架，从而支持更广泛的下游任务。

Method: EA3D框架使用视觉-语言和2D视觉基础编码器从连续视频的每一帧中动态提取物体层级知识。然后，通过前馈式在线更新策略将这些知识整合嵌入到高斯特征图中。此外，框架还通过迭代估计视觉里程计和增量更新线上高斯特征，用新的观察结果增强模型对感兴趣区域的关注，同时提升几何重建和语义理解的能力。

Result: 通过多种基准测试和任务的实验结果均表明，EA3D在几何重建和语义理解上表现优异。这些任务包括照片级渲染、语义和实例分割、3D包围盒及语义占用估计，以及3D网格生成等。EA3D框架为联合在线3D重建和整体场景理解建立了一个统一且高效的模型框架。

Conclusion: 总体来说，提出的EA3D不仅克服了现有3D场景理解方式的局限性，还在实际应用中展示了其作为强大工具的潜力，特别是对于那些需要处理实时多样化的场景理解的应用。

Abstract: Current 3D scene understanding methods are limited by offline-collected
multi-view data or pre-constructed 3D geometry. In this paper, we present
ExtractAnything3D (EA3D), a unified online framework for open-world 3D object
extraction that enables simultaneous geometric reconstruction and holistic
scene understanding. Given a streaming video, EA3D dynamically interprets each
frame using vision-language and 2D vision foundation encoders to extract
object-level knowledge. This knowledge is integrated and embedded into a
Gaussian feature map via a feed-forward online update strategy. We then
iteratively estimate visual odometry from historical frames and incrementally
update online Gaussian features with new observations. A recurrent joint
optimization module directs the model's attention to regions of interest,
simultaneously enhancing both geometric reconstruction and semantic
understanding. Extensive experiments across diverse benchmarks and tasks,
including photo-realistic rendering, semantic and instance segmentation, 3D
bounding box and semantic occupancy estimation, and 3D mesh generation,
demonstrate the effectiveness of EA3D. Our method establishes a unified and
efficient framework for joint online 3D reconstruction and holistic scene
understanding, enabling a broad range of downstream tasks.

</details>


### [33] [Towards Real-Time Inference of Thin Liquid Film Thickness Profiles from Interference Patterns Using Vision Transformers](https://arxiv.org/abs/2510.25157)
*Gautam A. Viruthagiri,Arnuv Tandon,Gerald G. Fuller,Vinny Chandran Suja*

Main category: cs.CV

TL;DR: 该论文提出了一种基于视觉变换器的方法，用于从干涉图中实时推断薄液体膜的厚度，解决了传统方法计算复杂、对噪声敏感或需要人工分析的问题。通过结合生理相关的合成和实验泪膜数据训练模型，实现了在有噪声和运动伪影的环境下也能准确重建薄膜厚度，有助于干眼病等疾病的非侵入性诊断和泪膜的连续监测。


<details>
  <summary>Details</summary>
Motivation: 传统的薄膜干涉测量方法在重建厚度分布时遇到了计算复杂、噪声敏感或手动分析的问题，无法实现实时诊断。因此，研究人员希望通过开发一种基于深度学习的视觉变换器，以实现实时的薄膜厚度分布重建。这种方法需要解决相位周期性、成像噪声和环境伪影等挑战。

Method: 研究人员提出了一种基于视觉变换器的方法，具体包括使用长程空间相关性来解决相位模糊问题，并从动态干涉图中生成连续一致的厚度分布。通过混合生理相关的合成和实验泪膜数据集进行训练，展示了在噪声、快速变化和运动伪影的情况下，比传统方法有更优的表现。

Result: 实验结果表明，该模型能够克服传统相位展开和迭代拟合方法的局限性，实现在实时的速度下自动、一致地重建薄膜厚度，这种数据驱动的方法为泪膜的连续监测和非侵入性诊断打开了新的窗口，特别是对于干眼病等条件。

Conclusion: 与传统的相位展开和迭代拟合方法相比，该团队提出的基于视觉变换器的模型具有更高的准确性和鲁棒性，能够在实时的速度下进行自动、连续的厚度重建。这为泪膜的连续监测和疾病的非侵入性诊断提供了新的工具。

Abstract: Thin film interferometry is a powerful technique for non-invasively measuring
liquid film thickness with applications in ophthalmology, but its clinical
translation is hindered by the challenges in reconstructing thickness profiles
from interference patterns - an ill-posed inverse problem complicated by phase
periodicity, imaging noise and ambient artifacts. Traditional reconstruction
methods are either computationally intensive, sensitive to noise, or require
manual expert analysis, which is impractical for real-time diagnostics. To
address this challenge, here we present a vision transformer-based approach for
real-time inference of thin liquid film thickness profiles directly from
isolated interferograms. Trained on a hybrid dataset combining
physiologically-relevant synthetic and experimental tear film data, our model
leverages long-range spatial correlations to resolve phase ambiguities and
reconstruct temporally coherent thickness profiles in a single forward pass
from dynamic interferograms acquired in vivo and ex vivo. The network
demonstrates state-of-the-art performance on noisy, rapidly-evolving films with
motion artifacts, overcoming limitations of conventional phase-unwrapping and
iterative fitting methods. Our data-driven approach enables automated,
consistent thickness reconstruction at real-time speeds on consumer hardware,
opening new possibilities for continuous monitoring of pre-lens ocular tear
films and non-invasive diagnosis of conditions such as the dry eye disease.

</details>


### [34] [Target-Guided Bayesian Flow Networks for Quantitatively Constrained CAD Generation](https://arxiv.org/abs/2510.25163)
*Wenhao Zheng,Chenwei Sun,Wenbo Zhang,Jiancheng Lv,Xianggen Liu*

Main category: cs.CV

TL;DR: 提出了一种新型框架TGBFN，用于量化约束的CAD生成，该框架首次在一个统一的连续和可微参数空间中处理CAD序列的多模式性。TGBFN引入了引导式贝叶斯流以控制CAD属性，并且在量化约束的CAD生成任务中表现出色，达到了最先进的性能水平.


<details>
  <summary>Details</summary>
Motivation: 传统深度生成模型在生成单一模态数据如图像和音频方面取得了显著进步，但在生成多模态数据如参数化CAD序列方面仍然存在挑战，特别是在处理长程约束和参数敏感度方面。为了克服这些挑战，研究人员希望开发一种新的生成模型框架来生成符合特定约束条件的高质量CAD序列.

Method: 提出了名为Target-Guided Bayesian Flow Network (TGBFN)的框架，该框架利用一个统一的连续和可微参数空间来处理CAD序列的多模式性。TGBFN通过一个引导式贝叶斯流来更新参数，控制CAD属性，并且能够处理量化约束生成任务。实验验证了TGBFN在单一条件和多条件约束生成任务中的优越性能.

Result: TGBFN在单一条件和多条件约束生成任务中均表现出色，能够在更精确地控制CAD属性的同时，生成高质量的、条件感知的CAD序列，达到了业内最先进的水平.

Conclusion: TGBFN通过引入引导式贝叶斯流，首次解决了CAD序列多模式性的问题，为生成高质量、高保真的CAD序列提供了一个有效的解决方案，推动了生成模型在多模态数据生成领域的研究进展。

Abstract: Deep generative models, such as diffusion models, have shown promising
progress in image generation and audio generation via simplified continuity
assumptions. However, the development of generative modeling techniques for
generating multi-modal data, such as parametric CAD sequences, still lags
behind due to the challenges in addressing long-range constraints and parameter
sensitivity. In this work, we propose a novel framework for quantitatively
constrained CAD generation, termed Target-Guided Bayesian Flow Network (TGBFN).
For the first time, TGBFN handles the multi-modality of CAD sequences (i.e.,
discrete commands and continuous parameters) in a unified continuous and
differentiable parameter space rather than in the discrete data space. In
addition, TGBFN penetrates the parameter update kernel and introduces a guided
Bayesian flow to control the CAD properties. To evaluate TGBFN, we construct a
new dataset for quantitatively constrained CAD generation. Extensive
comparisons across single-condition and multi-condition constrained generation
tasks demonstrate that TGBFN achieves state-of-the-art performance in
generating high-fidelity, condition-aware CAD sequences. The code is available
at https://github.com/scu-zwh/TGBFN.

</details>


### [35] [$D^2GS$: Dense Depth Regularization for LiDAR-free Urban Scene Reconstruction](https://arxiv.org/abs/2510.25173)
*Kejing Xia,Jidong Jia,Ke Jin,Yucai Bai,Li Sun,Dacheng Tao,Youjian Zhang*

Main category: cs.CV

TL;DR: 提出了一个不需要LiDAR的Gaussian Splatting框架（$D^2GS$），通过联合优化多视角深度预测和高斯分布来完成城市场景的重建，实验显示该方法在Waymo数据集上的表现优于现有方法，重建的几何精度更高。


<details>
  <summary>Details</summary>
Motivation: 现有的城市场景重建方法通常需要依赖于多模态传感器（如LiDAR和图像），而精确获取LiDAR数据面临挑战，包括精确的空间时间校准和空间偏差等问题。为了克服这些问题，提出了一种无需LiDAR的重建方法$D^2GS$，旨在利用更多的几何先验信息，同时避免使用LiDAR的缺点。

Method: 该方法首先通过多视角深度预测反向投影来初始化一个密集点云，并利用一种进步修剪策略提高其全局一致性；然后通过一个深度增强器联合优化高斯几何和预测密集度测量；最后，通过约束道路区域内的高斯形状和法线属性来提高地面几何的准确性。

Result: 通过Waymo数据集的实验，该方法显著优于现有的主流重建方法，即使与使用真实LiDAR数据的方法相比，生成的几何精度也更高。

Conclusion: $D^2GS$框架展示了无需LiDAR即可实现高精度城市场景重建的潜力，它通过联合优化多视角深度预测和高斯分布，显著提高了重建几何的准确性。

Abstract: Recently, Gaussian Splatting (GS) has shown great potential for urban scene
reconstruction in the field of autonomous driving. However, current urban scene
reconstruction methods often depend on multimodal sensors as inputs,
\textit{i.e.} LiDAR and images. Though the geometry prior provided by LiDAR
point clouds can largely mitigate ill-posedness in reconstruction, acquiring
such accurate LiDAR data is still challenging in practice: i) precise
spatiotemporal calibration between LiDAR and other sensors is required, as they
may not capture data simultaneously; ii) reprojection errors arise from spatial
misalignment when LiDAR and cameras are mounted at different locations. To
avoid the difficulty of acquiring accurate LiDAR depth, we propose $D^2GS$, a
LiDAR-free urban scene reconstruction framework. In this work, we obtain
geometry priors that are as effective as LiDAR while being denser and more
accurate. $\textbf{First}$, we initialize a dense point cloud by
back-projecting multi-view metric depth predictions. This point cloud is then
optimized by a Progressive Pruning strategy to improve the global consistency.
$\textbf{Second}$, we jointly refine Gaussian geometry and predicted dense
metric depth via a Depth Enhancer. Specifically, we leverage diffusion priors
from a depth foundation model to enhance the depth maps rendered by Gaussians.
In turn, the enhanced depths provide stronger geometric constraints during
Gaussian training. $\textbf{Finally}$, we improve the accuracy of ground
geometry by constraining the shape and normal attributes of Gaussians within
road regions. Extensive experiments on the Waymo dataset demonstrate that our
method consistently outperforms state-of-the-art methods, producing more
accurate geometry even when compared with those using ground-truth LiDAR data.

</details>


### [36] [Test-Time Adaptive Object Detection with Foundation Model](https://arxiv.org/abs/2510.25175)
*Yingjie Gao,Yanan Zhang,Zhi Cai,Di Huang*

Main category: cs.CV

TL;DR: 本文提出了一种基于多模态提示的均教师框架，用于视觉-语言检测器驱动的测试时间自适应，该框架消除了对源数据的依赖，并克服了传统封闭集限制。此外，还引入了测试时预热策略和实例动态内存模块，用于保存高质量的伪标签并提高预测准确性。实验表明，该方法在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在在线领域适应中依赖源数据的统计特性，并假设源域和目标域具有相同的类别空间。为解决此问题，本文提出了一个不需要源数据的基础模型驱动的方法，克服传统封闭集的限制，更贴近真实应用。

Method: 设计了一种多模态提示均教师框架，结合文本和视觉提示调优来同时调整语言和视觉表征空间。引入测试时预热策略，以便更有效地保护视觉分支的表征能力。保持一个实例动态内存模块用于保存高质量的伪标签，并提出两种策略-记忆增强和记忆想象，以利用高质量的实例，提高原始预测的准确性。

Result: 实验表明，该方法在跨腐蚀和跨数据集基准测试中一致优于现有方法，可适应任意跨域和跨类别目标数据。

Conclusion: 本文提出了首个依赖于基础模型的测试时间自适应物体检测方法，能够应对任意跨域和跨类别的目标数据，并在多个基准测试中表现出色。

Abstract: In recent years, test-time adaptive object detection has attracted increasing
attention due to its unique advantages in online domain adaptation, which
aligns more closely with real-world application scenarios. However, existing
approaches heavily rely on source-derived statistical characteristics while
making the strong assumption that the source and target domains share an
identical category space. In this paper, we propose the first foundation
model-powered test-time adaptive object detection method that eliminates the
need for source data entirely and overcomes traditional closed-set limitations.
Specifically, we design a Multi-modal Prompt-based Mean-Teacher framework for
vision-language detector-driven test-time adaptation, which incorporates text
and visual prompt tuning to adapt both language and vision representation
spaces on the test data in a parameter-efficient manner. Correspondingly, we
propose a Test-time Warm-start strategy tailored for the visual prompts to
effectively preserve the representation capability of the vision branch.
Furthermore, to guarantee high-quality pseudo-labels in every test batch, we
maintain an Instance Dynamic Memory (IDM) module that stores high-quality
pseudo-labels from previous test samples, and propose two novel
strategies-Memory Enhancement and Memory Hallucination-to leverage IDM's
high-quality instances for enhancing original predictions and hallucinating
images without available pseudo-labels, respectively. Extensive experiments on
cross-corruption and cross-dataset benchmarks demonstrate that our method
consistently outperforms previous state-of-the-art methods, and can adapt to
arbitrary cross-domain and cross-category target data. Code is available at
https://github.com/gaoyingjay/ttaod_foundation.

</details>


### [37] [AI-Powered Early Detection of Critical Diseases using Image Processing and Audio Analysis](https://arxiv.org/abs/2510.25199)
*Manisha More,Kavya Bhand,Kaustubh Mukdam,Kavya Sharma,Manas Kawtikwar,Hridayansh Kaware,Prajwal Kavhar*

Main category: cs.CV

TL;DR: 本文提出了一种结合图像分析、热成像和音频信号处理的多模态人工智能诊断框架，用于早期检测皮肤癌、血管血栓和心血管肺异常。该框架在三项任务上分别使用了训练后的MobileNetV2、支持向量机和随机森林模型，取得了良好的准确性，并且轻量级可在低成本设备上部署，为可扩展、实时和可访问的AI预诊断医疗解决方案奠定了基础


<details>
  <summary>Details</summary>
Motivation: 当前诊断技术成本高、侵入性强且在资源匮乏地区难以获得，因此需要一种经济高效且易获取的诊断工具

Method: 1. 使用MobileNetV2在ISIC 2019数据集上进行皮肤病变分类；2. 采用支持向量机对合成和临床数据进行热成像血栓检测；3. 使用Mel-Frequency Cepstral Coefficients对肺和心脏声音数据进行处理并通过随机森林分类

Result: MobileNetV2模型在皮肤病变分类中达到89.3%的准确率；支持向量机热成像血栓检测模型的准确性为86.4%，AUC为0.89；随机森林算法在心血管肺分析中达到87.2%的准确率和85.7%的敏感度

Conclusion: 所提出的系统在保持轻量级的同时取得了与当前最先进的模型相媲美的效果，证明了其在提供可扩展、实时和可访问的AI预诊断医疗解决方案方面的潜力

Abstract: Early diagnosis of critical diseases can significantly improve patient
survival and reduce treatment costs. However, existing diagnostic techniques
are often costly, invasive, and inaccessible in low-resource regions. This
paper presents a multimodal artificial intelligence (AI) diagnostic framework
integrating image analysis, thermal imaging, and audio signal processing for
early detection of three major health conditions: skin cancer, vascular blood
clots, and cardiopulmonary abnormalities. A fine-tuned MobileNetV2
convolutional neural network was trained on the ISIC 2019 dataset for skin
lesion classification, achieving 89.3% accuracy, 91.6% sensitivity, and 88.2%
specificity. A support vector machine (SVM) with handcrafted features was
employed for thermal clot detection, achieving 86.4% accuracy (AUC = 0.89) on
synthetic and clinical data. For cardiopulmonary analysis, lung and heart sound
datasets from PhysioNet and Pascal were processed using Mel-Frequency Cepstral
Coefficients (MFCC) and classified via Random Forest, reaching 87.2% accuracy
and 85.7% sensitivity. Comparative evaluation against state-of-the-art models
demonstrates that the proposed system achieves competitive results while
remaining lightweight and deployable on low-cost devices. The framework
provides a promising step toward scalable, real-time, and accessible AI-based
pre-diagnostic healthcare solutions.

</details>


### [38] [MSF-Net: Multi-Stage Feature Extraction and Fusion for Robust Photometric Stereo](https://arxiv.org/abs/2510.25221)
*Shiyu Qin,Zhihao Cai,Kaixuan Wang,Lin Qi,Junyu Dong*

Main category: cs.CV

TL;DR: MSF-Net 是一种新的框架，用于在多个阶段提取信息，并结合选择性更新策略，旨在提取高质量的特征信息，这对于准确的法线构建至关重要。此外，还开发了一种特征融合模块，以增强不同特征之间的互动。实验结果表明，MSF-Net 在准确的表面法线估计方面显著优于前人的最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法常常无法准确地捕捉多阶段的特征，并且不充分促进这些特征之间的互动，特别是对于具有复杂细节（如皱纹和边缘）的区域提取冗余特征，因此本文提出了解决这些问题的新框架。

Method: 提出了一种新的框架MSF-Net，该框架结合了多阶段特征提取和选择性更新策略，用于提取高质量的特征信息，并开发了一种特征融合模块以增强不同特征之间的互动。

Result: 实验结果证明，MSF-Net 在表面法线估计的准确性方面显著优于前人的最先进方法。

Conclusion: 所提出的MSF-Net 使用多阶段特征提取策略和选择性更新，提高了表面法线估计的准确性，并通过特征融合模块改进了不同特征之间的互动，从而显著提升了性能。

Abstract: Photometric stereo is a technique aimed at determining surface normals
through the utilization of shading cues derived from images taken under
different lighting conditions. However, existing learning-based approaches
often fail to accurately capture features at multiple stages and do not
adequately promote interaction between these features. Consequently, these
models tend to extract redundant features, especially in areas with intricate
details such as wrinkles and edges. To tackle these issues, we propose MSF-Net,
a novel framework for extracting information at multiple stages, paired with
selective update strategy, aiming to extract high-quality feature information,
which is critical for accurate normal construction. Additionally, we have
developed a feature fusion module to improve the interplay among different
features. Experimental results on the DiLiGenT benchmark show that our proposed
MSF-Net significantly surpasses previous state-of-the-art methods in the
accuracy of surface normal estimation.

</details>


### [39] [Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation](https://arxiv.org/abs/2510.25227)
*Quang-Khai Bui-Tran,Thanh-Huy Nguyen,Hoang-Thien Nguyen,Ba-Thinh Lam,Nguyen Lan Vi Vu,Phat K. Huynh,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: 提出了一种新的无源域适应框架，通过硬样本选择和去噪贴片混合来逐步对齐目标分布，实验表明这种方法在标准数据集上优于之前的无源域适应和通用域适应方法，提高了边界划分的准确性，实现了最先进Dice和ASSD分数。


<details>
  <summary>Details</summary>
Motivation: 当前的方法忽视了样本难度，并且在域转移和噪声监督下表现不佳，此研究旨在通过逐步适应和去噪监督提高鲁棒性。

Method: 首先通过熵相似性分析将未标记图像划分为可靠和不可靠子集；然后通过蒙特卡洛去噪掩码来优化伪标签；最后混合不同子集间的贴片实现可靠的语义转移并减少噪声。

Result: 实验结果表明该方法优于以前的SFDA和UDA方法，在标准数据集上实现了更准确的边界划分并达到了最先进Dice和ASSD分数。

Conclusion: 研究表明，逐步适应和去噪监督对于在域转移下的稳健分割至关重要。

Abstract: Source-Free Domain Adaptation (SFDA) is emerging as a compelling solution for
medical image segmentation under privacy constraints, yet current approaches
often ignore sample difficulty and struggle with noisy supervision under domain
shift. We present a new SFDA framework that leverages Hard Sample Selection and
Denoised Patch Mixing to progressively align target distributions. First,
unlabeled images are partitioned into reliable and unreliable subsets through
entropy-similarity analysis, allowing adaptation to start from easy samples and
gradually incorporate harder ones. Next, pseudo-labels are refined via Monte
Carlo-based denoising masks, which suppress unreliable pixels and stabilize
training. Finally, intra- and inter-domain objectives mix patches between
subsets, transferring reliable semantics while mitigating noise. Experiments on
benchmark datasets show consistent gains over prior SFDA and UDA methods,
delivering more accurate boundary delineation and achieving state-of-the-art
Dice and ASSD scores. Our study highlights the importance of progressive
adaptation and denoised supervision for robust segmentation under domain shift.

</details>


### [40] [Balanced conic rectified flow](https://arxiv.org/abs/2510.25229)
*Kim Shin Seong,Mingi Kwon,Jaeseok Jeong,Youngjung Uh*

Main category: cs.CV

TL;DR: 该文提出了一种新的方法，通过在训练过程中引入真实图片来改进原本的Rectified Flow模型，有效减少了对大量生成数据的依赖，提高了生成高质量图像的效率和效果，并在CIFAR-10数据集上实现了显著的FID分数提升。同时，新方法能够产生更直的ODE路径，避免了饱和问题，从而提高了模型的鲁棒性和对真实图像分布的保持能力。


<details>
  <summary>Details</summary>
Motivation: 为了克服原Rectified Flow模型存在的训练依赖大量生成数据和可能的饱和及偏置问题，减少计算成本，该研究提出了一种新方法，将真实图片纳入训练过程。这种方法旨在提高生成图像的质量和效率，同时保持生成模型对真实图像分布的忠实度。

Method: 该方法通过保留真实图片的ODE路径，并在训练过程中采用更小规模的真实与生成图像集来执行再流过程，减少对生成数据的依赖，提高效率。最终目标是生产高质量图像的同时保证对真实图像分布的良好保持。

Result: 新方法在CIFAR-10数据集上实现了一步生成及完整步骤模拟的显著FID分数提升，展示了更强的性能和更高的效率。此外，该方法还降低了饱和问题的发生，提高了生成图像的质量和模型学习的鲁棒性。

Conclusion: 通过实验验证，作者表明将真实图像纳入Rectified Flow模型的训练能够显著提升模型性能，使其能够在减少对生成数据依赖的同时，保持对真实图像分布的忠实度，并提高生成图像的质量。该方法提供了一个有效且高效的解决方案，以克服传统模型的局限性。

Abstract: Rectified flow is a generative model that learns smooth transport mappings
between two distributions through an ordinary differential equation (ODE).
Unlike diffusion-based generative models, which require costly numerical
integration of a generative ODE to sample images with state-of-the-art quality,
rectified flow uses an iterative process called reflow to learn smooth and
straight ODE paths. This allows for relatively simple and efficient generation
of high-quality images. However, rectified flow still faces several challenges.
1) The reflow process requires a large number of generative pairs to preserve
the target distribution, leading to significant computational costs. 2) Since
the model is typically trained using only generated image pairs, its
performance heavily depends on the 1-rectified flow model, causing it to become
biased towards the generated data.
  In this work, we experimentally expose the limitations of the original
rectified flow and propose a novel approach that incorporates real images into
the training process. By preserving the ODE paths for real images, our method
effectively reduces reliance on large amounts of generated data. Instead, we
demonstrate that the reflow process can be conducted efficiently using a much
smaller set of generated and real images. In CIFAR-10, we achieved
significantly better FID scores, not only in one-step generation but also in
full-step simulations, while using only of the generative pairs compared to the
original method. Furthermore, our approach induces straighter paths and avoids
saturation on generated images during reflow, leading to more robust ODE
learning while preserving the distribution of real images.

</details>


### [41] [Learning Disentangled Speech- and Expression-Driven Blendshapes for 3D Talking Face Animation](https://arxiv.org/abs/2510.25234)
*Yuxiang Mao,Zhijie Zhang,Zhiheng Zhang,Jiawei Liu,Chen Zeng,Shihong Xia*

Main category: cs.CV

TL;DR: 本文提出了一种通过结合语音和情感数据来生成情感丰富的3D面部动画的方法。通过引入稀疏性约束损失，使得由语音和情感驱动的混合形状得以分离，同时捕捉训练数据中的自然次级跨域变形。该方法能够生成符合指定情感表达的3D面部动画，同时保持准确的口型同步。研究表明，相比现有方法，该方法能在不失口型同步质量的情况下，实现更好的情感表达效果。


<details>
  <summary>Details</summary>
Motivation: 由于真实的3D情感面部动画数据集收集成本高，现有的声音驱动的唇形同步技术尚不能很好地生成情感丰富的面部动画。本文旨在解决这一问题，通过结合语音和情感数据，生成更为细腻的情感表达的3D面部动画。

Method: 通过将面部动画视为线性可加问题，结合语音和情感数据进行学习，利用3D语音面部数据集（VOCAset）和面部表情数据集（Florence4D），学习一组由语音和情感驱动的混合形状，并通过引入稀疏性约束损失，鼓励语音和情感驱动的混合形状分离，同时允许模型捕捉训练数据中存在的自然次级跨域变形。

Result: 研究展示了该方法能够在生成有指定情感表达的3D面部动画的同时，保持准确的口型同步。与现有方法相比，该方法在不失口型同步质量的情况下，能实现更好的情感表达效果。

Conclusion: 文章开创性地解决了声音驱动的唇形同步技术无法很好地生成情感丰富的面部动画的问题，通过引入稀疏性约束损失，使得模型既能捕捉语音驱动的唇形同步，又能生成符合指定情感表达的面部动画。

Abstract: Expressions are fundamental to conveying human emotions. With the rapid
advancement of AI-generated content (AIGC), realistic and expressive 3D facial
animation has become increasingly crucial. Despite recent progress in
speech-driven lip-sync for talking-face animation, generating emotionally
expressive talking faces remains underexplored. A major obstacle is the
scarcity of real emotional 3D talking-face datasets due to the high cost of
data capture. To address this, we model facial animation driven by both speech
and emotion as a linear additive problem. Leveraging a 3D talking-face dataset
with neutral expressions (VOCAset) and a dataset of 3D expression sequences
(Florence4D), we jointly learn a set of blendshapes driven by speech and
emotion. We introduce a sparsity constraint loss to encourage disentanglement
between the two types of blendshapes while allowing the model to capture
inherent secondary cross-domain deformations present in the training data. The
learned blendshapes can be further mapped to the expression and jaw pose
parameters of the FLAME model, enabling the animation of 3D Gaussian avatars.
Qualitative and quantitative experiments demonstrate that our method naturally
generates talking faces with specified expressions while maintaining accurate
lip synchronization. Perceptual studies further show that our approach achieves
superior emotional expressivity compared to existing methods, without
compromising lip-sync quality.

</details>


### [42] [VADB: A Large-Scale Video Aesthetic Database with Professional and Multi-Dimensional Annotations](https://arxiv.org/abs/2510.25238)
*Qianqian Qiao,DanDan Zheng,Yihang Bo,Bao Peng,Heng Huang,Longteng Jiang,Huaye Wang,Jingdong Chen,Jun Zhou,Xin Jin*

Main category: cs.CV

TL;DR: 该研究提出了VADB，即最大的视频美学数据库，包含由37位专业人士标注的10,490段多样化视频。还提出了VADB-Net，这是一种双模态预训练框架，采用两阶段训练策略，在评分任务中超越现有视频质量评估模型，并支持下游视频美学评估任务。数据集和源代码可以在https://github.com/BestiVictory/VADB获得。


<details>
  <summary>Details</summary>
Motivation: 目前视频美学评估领域的发展受限于标准化数据集和稳健模型的缺乏，而这又源于视频的时间动态特性和多模态融合挑战，阻碍了基于图像的方法的直接应用。为了克服这一难题，提出了一种新的解决方案，即构建更丰富的数据集和提出更有效的模型来解决视频美学评估问题。

Method: 提出了一种双模态预训练框架，即VADB-Net，采用两阶段训练策略，分别针对预训练阶段和微调阶段设计了特定的训练方法。同时，该方法充分利用了VADB数据集中的多种标注信息，包括整体美学评分、特定属性的美学评分、丰富的语言评论和客观标签。通过这一方法，VADB-Net能够有效地学习视频美学的相关特征，并提高视频美学评估的性能。

Result: 实验表明，VADB-Net在评分任务中超过了现有的视频质量评估模型，这表明它在视频美学评估任务中展示了优越的性能和潜力。更具体地说，它不仅能计算出准确的总体美学评分，而且还能利用客观标签和语言评论来细化和丰富评估结果，提高其在实际应用中的实用价值。

Conclusion: 该研究通过构建更丰富的视频美学数据库VADB和提出更有效的视频美学评估模型VADB-Net，为解决视频美学评估问题提供了一个综合的解决方案，为该领域的进一步研究和发展做出了贡献。

Abstract: Video aesthetic assessment, a vital area in multimedia computing, integrates
computer vision with human cognition. Its progress is limited by the lack of
standardized datasets and robust models, as the temporal dynamics of video and
multimodal fusion challenges hinder direct application of image-based methods.
This study introduces VADB, the largest video aesthetic database with 10,490
diverse videos annotated by 37 professionals across multiple aesthetic
dimensions, including overall and attribute-specific aesthetic scores, rich
language comments and objective tags. We propose VADB-Net, a dual-modal
pre-training framework with a two-stage training strategy, which outperforms
existing video quality assessment models in scoring tasks and supports
downstream video aesthetic assessment tasks. The dataset and source code are
available at https://github.com/BestiVictory/VADB.

</details>


### [43] [LangHOPS: Language Grounded Hierarchical Open-Vocabulary Part Segmentation](https://arxiv.org/abs/2510.25263)
*Yang Miao,Jan-Nico Zaech,Xi Wang,Fabien Despinoy,Danda Pani Paudel,Luc Van Gool*

Main category: cs.CV

TL;DR: LangHOPS是首个用于开放词汇对象和部分实例分割的多模态大型语言模型框架。它在语言空间中建立对象和部分层次结构，在PartImageNet和ADE20K数据集上实现了最佳性能，提高了指标。


<details>
  <summary>Details</summary>
Motivation: 先前的方法依赖于启发式或可学习的视觉分组，而LangHOPS则通过在语言空间中建立对象和部分层次结构，利用大型语言模型的知识和推理能力来改进实例分割。

Method: LangHOPS通过集成多模态大型语言模型到对象和部分解析流水线中，利用其丰富的知识和推理能力，并链接层次化中的多级别概念。此外，LangHOPS还通过语言驱动的分层次策略进一步优化了部分查询的准确性。

Result: LangHOPS在PartImageNet和ADE20K数据集上超过先前方法，特别是在开放词汇对象和部分实例分割任务上提高了5.5%的平均精度（同域）和4.8%（跨数据集），并在ADE20K上实现了2.5%的mIOU改进（零样本语义分割）。

Conclusion: 实验结果表明，基于语言的空间层次和多模态大型语言模型驱动的分层次查询优化策略是有效的。

Abstract: We propose LangHOPS, the first Multimodal Large Language Model (MLLM) based
framework for open-vocabulary object-part instance segmentation. Given an
image, LangHOPS can jointly detect and segment hierarchical object and part
instances from open-vocabulary candidate categories. Unlike prior approaches
that rely on heuristic or learnable visual grouping, our approach grounds
object-part hierarchies in language space. It integrates the MLLM into the
object-part parsing pipeline to leverage its rich knowledge and reasoning
capabilities, and link multi-granularity concepts within the hierarchies. We
evaluate LangHOPS across multiple challenging scenarios, including in-domain
and cross-dataset object-part instance segmentation, and zero-shot semantic
segmentation. LangHOPS achieves state-of-the-art results, surpassing previous
methods by 5.5% Average Precision (AP) (in-domain) and 4.8% (cross-dataset) on
the PartImageNet dataset and by 2.5% mIOU on unseen object parts in ADE20K
(zero-shot). Ablation studies further validate the effectiveness of the
language-grounded hierarchy and MLLM driven part query refinement strategy. The
code will be released here.

</details>


### [44] [Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation](https://arxiv.org/abs/2510.25279)
*Yuyang Huang,Yabo Chen,Junyu Zhou,Wenrui Dai,Xiaopeng Zhang,Junni Zou,Hongkai Xiong,Qi Tian*

Main category: cs.CV

TL;DR: 本文提出了一种新的生成型源无域适应框架 DPTM，通过逐步细化伪目标域来解决现有的源无域适应方法由于源目标域差距而遇到的挑战。实验结果表明，DPTM 在四种流行的 SFDA 基准数据集上均取得了卓越的性能，尤其是在具有较大源目标差距的场景中，性能提升最多可达18.6%。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有 SFDA 方法因源目标域差距导致的局限性，特别是在存在较大域差距的挑战性场景中，伪标签不可靠的问题。

Method: DPTM 是一种生成型源无域适应框架，将未标记的目标样本根据伪标签的可靠性分为信任集和非信任集。对于非信任集中的样本，采用了一种基于语义转换和通过隐扩散模型保持其在目标分布下的转换策略。同时设计了逐步细化机制，通过迭代改进逐步减少伪目标域和真实目标域之间的差距。

Result: DPTM 实验结果展示了其在四种流行的 SFDA 基准数据集上均超越了现有方法，并且在具有较大源目标差距的场景中，取得了高达18.6%的性能提升。

Conclusion: 论文的结论是通过使用DPTM进行逐步细化伪目标域，能够有效解决现有源无域适应方法的局限性，并且在多种基准数据集上取得了超越现有方法的性能。

Abstract: Source-free domain adaptation (SFDA) is a challenging task that tackles
domain shifts using only a pre-trained source model and unlabeled target data.
Existing SFDA methods are restricted by the fundamental limitation of
source-target domain discrepancy. Non-generation SFDA methods suffer from
unreliable pseudo-labels in challenging scenarios with large domain
discrepancies, while generation-based SFDA methods are evidently degraded due
to enlarged domain discrepancies in creating pseudo-source data. To address
this limitation, we propose a novel generation-based framework named
Diffusion-Driven Progressive Target Manipulation (DPTM) that leverages
unlabeled target data as references to reliably generate and progressively
refine a pseudo-target domain for SFDA. Specifically, we divide the target
samples into a trust set and a non-trust set based on the reliability of
pseudo-labels to sufficiently and reliably exploit their information. For
samples from the non-trust set, we develop a manipulation strategy to
semantically transform them into the newly assigned categories, while
simultaneously maintaining them in the target distribution via a latent
diffusion model. Furthermore, we design a progressive refinement mechanism that
progressively reduces the domain discrepancy between the pseudo-target domain
and the real target domain via iterative refinement. Experimental results
demonstrate that DPTM outperforms existing methods by a large margin and
achieves state-of-the-art performance on four prevailing SFDA benchmark
datasets with different scales. Remarkably, DPTM can significantly enhance the
performance by up to 18.6% in scenarios with large source-target gaps.

</details>


### [45] [Prototype-Driven Adaptation for Few-Shot Object Detection](https://arxiv.org/abs/2510.25318)
*Yushen Huang,Zhiming Wang*

Main category: cs.CV

TL;DR: 提出了一种新的方法Prototype-Driven Alignment (PDA)，用于提升Few-shot Object Detection的性能，特别是在处理新型样本时。PDA通过原型驱动的方式提供了一个与线性分类器互补的方法，减少了几何差异，并在不增加类特定参数的情况下更新原型。在VOC FSOD和GFSOD数据集上实验表明，PDA在不影响基础类别表现的同时，显著提升了新型类别的检测效果，并且计算开销很小。


<details>
  <summary>Details</summary>
Motivation: 传统Few-shot Object Detection方法在处理新型样本时，存在偏差和不稳定的校准问题。为了提高少量新型样本的检测性能，同时保持对基础类别的良好支持，提出了一种新的方法PDA。

Method: PDA是一种轻量级的插件式度量头，适用于DeFRCN模型。它维护仅在支持样本上的原型，并可能应用原型条件下的RoI对齐来减少几何差异。PDA还采用了最佳的K匹配方案和温度缩放融合，将度量相似度与检测置信度相结合。在微调过程中，通过指数移动平均的方式更新原型，而推理时则保持冻结状态。

Result: 实验结果表明，PDA在最小的影响基础类别表现的同时，显著提升了新型类别的检测性能，并且引入的计算开销较小。具体来说，在VOC FSOD和GFSOD数据集上，PDA始终提高了新型类别的性能，而对基础类别的影响微乎其微。

Conclusion: 通过引入Prototype-Driven Alignment，显著提升了Few-shot Object Detection在新型类别上的检测性能，同时保持了对基础类别良好的支持，并且计算成本极小。

Abstract: Few-shot object detection (FSOD) often suffers from base-class bias and
unstable calibration when only a few novel samples are available. We propose
Prototype-Driven Alignment (PDA), a lightweight, plug-in metric head for DeFRCN
that provides a prototype-based "second opinion" complementary to the linear
classifier. PDA maintains support-only prototypes in a learnable
identity-initialized projection space and optionally applies
prototype-conditioned RoI alignment to reduce geometric mismatch. During
fine-tuning, prototypes can be adapted via exponential moving average(EMA)
updates on labeled foreground RoIs-without introducing class-specific
parameters-and are frozen at inference to ensure strict protocol compliance.
PDA employs a best-of-K matching scheme to capture intra-class multi-modality
and temperature-scaled fusion to combine metric similarities with detector
logits. Experiments on VOC FSOD and GFSOD benchmarks show that PDA consistently
improves novel-class performance with minimal impact on base classes and
negligible computational overhead.

</details>


### [46] [MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding](https://arxiv.org/abs/2510.25327)
*Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang*

Main category: cs.CV

TL;DR: MMEdge是一个新的基于流水线化的传感和编码的端设备多模态推理框架，它可以减轻资源受限设备上实时多模态推理的挑战，通过细粒度的流水线设计实现了预测的增量执行，同时保持了准确性。此外，它还引入了一个自适应的多模态配置优化器和一个跨模态投机跳跃机制来进一步增强系统的性能。实验结果表明，MMEdge在不同的系统和数据动态下，可以在保持高任务准确性的前提下，显著减少端到端的延迟。


<details>
  <summary>Details</summary>
Motivation: 该研究主要动机是为了解决资源受限设备上实时多模态推理的挑战，特别是在自主驾驶、人机交互和移动健康等领域。传统的多模态推理工作忽略了传感动态与模型执行之间的紧密耦合以及跨模态依赖关系，这种局限性在资源受限设备上尤其明显。MMEdge旨在通过新颖的设计来克服这些问题。

Method: MMEdge引入了基于流水线化的传感和编码的推理框架，这种方法使得在完整传感器输入到达之前可以逐步进行计算。此外，该框架还提供了一个轻量但有效的时序聚合模块，可以跨不同的流水线级捕获丰富的时序动态。MMEdge还利用了一个自适应的多模态配置优化器和一个跨模态投机跳跃机制，可以在延迟约束下动态选择最优的传感和模型配置，并在早期预测达到足够信心时跳过较慢模态的未来单元。

Result: MMEdge在两个公开的多模态数据集上进行了评估，并在现实世界中的无人飞行器（UAV）基础多模态测试台上部署。实验结果表明，MMEdge在多种系统和数据动态中，在保持高任务准确性的同时，显著减少了端到端的延迟。

Conclusion: MMEdge通过新颖的设计成功克服了资源受限设备上实时多模态推理的关键挑战，这种方法对于需要执行大数据分析和高计算密集任务的应用场景非常有价值。

Abstract: Real-time multimodal inference on resource-constrained edge devices is
essential for applications such as autonomous driving, human-computer
interaction, and mobile health. However, prior work often overlooks the tight
coupling between sensing dynamics and model execution, as well as the complex
inter-modality dependencies. In this paper, we propose MMEdge, an new on-device
multi-modal inference framework based on pipelined sensing and encoding.
Instead of waiting for complete sensor inputs, MMEdge decomposes the entire
inference process into a sequence of fine-grained sensing and encoding units,
allowing computation to proceed incrementally as data arrive. MMEdge also
introduces a lightweight but effective temporal aggregation module that
captures rich temporal dynamics across different pipelined units to maintain
accuracy performance. Such pipelined design also opens up opportunities for
fine-grained cross-modal optimization and early decision-making during
inference. To further enhance system performance under resource variability and
input data complexity, MMEdge incorporates an adaptive multimodal configuration
optimizer that dynamically selects optimal sensing and model configurations for
each modality under latency constraints, and a cross-modal speculative skipping
mechanism that bypasses future units of slower modalities when early
predictions reach sufficient confidence. We evaluate MMEdge using two public
multimodal datasets and deploy it on a real-world unmanned aerial vehicle
(UAV)-based multimodal testbed. The results show that MMEdge significantly
reduces end-to-end latency while maintaining high task accuracy across various
system and data dynamics.

</details>


### [47] [StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA](https://arxiv.org/abs/2510.25332)
*Yuhang Hu,Zhenyu Yang,Shihan Wang,Shengsheng Qian,Bin Wen,Fan Yang,Tingting Gao,Changsheng Xu*

Main category: cs.CV

TL;DR: 介绍了StreamingCoT 数据集，旨在解决现有VideoQA数据集在时间和复杂推理方面的局限性。该数据集设计了一种动态层级标注架构，结合显式推理链生成范式，促进视频理解、复杂时间推理和多模态推理的研究进展。


<details>
  <summary>Details</summary>
Motivation: 现有VideoQA数据集在时间和复杂推理方面的局限，阻碍了视频理解和多模态推理的发展。为了弥补这些不足，建立了StreamingCoT数据集，强化视频理解中的时间动态和复杂推理能力。

Method: 提出了一个动态的层级标注架构，用于生成逐秒的密集描述和构建时间相关语义片段，并通过相似度融合构建。此外，提出了一个显式的推理链生成范式，它通过关键帧语义对齐提取时空对象，使用大型语言模型推导基于对象状态变化的推理路径，并通过人工验证确保逻辑连贯性。

Result: StreamingCoT数据集及其构建工具包公开发布，研究人员可以访问和使用这些资源，以促进视频理解、复杂时间推理和多模态推理研究的发展。有效解决了现有VideoQA数据集中存在的问题，提供了新的研究方向。

Conclusion: 通过StreamingCoT 数据集及其构建工具包，研究者可以更好地理解视频流中的时间动态和推理能力，从而推动了视频理解和多模态推理的研究进展。

Abstract: The rapid growth of streaming video applications demands multimodal models
with enhanced capabilities for temporal dynamics understanding and complex
reasoning. However, current Video Question Answering (VideoQA) datasets suffer
from two critical limitations: 1) Static annotation mechanisms fail to capture
the evolving nature of answers in temporal video streams, and 2) The absence of
explicit reasoning process annotations restricts model interpretability and
logical deduction capabilities. To address these challenges, We introduce
StreamingCoT, the first dataset explicitly designed for temporally evolving
reasoning in streaming VideoQA and multimodal Chain-of-Thought (CoT) tasks. Our
framework first establishes a dynamic hierarchical annotation architecture that
generates per-second dense descriptions and constructs temporally-dependent
semantic segments through similarity fusion, paired with question-answer sets
constrained by temporal evolution patterns. We further propose an explicit
reasoning chain generation paradigm that extracts spatiotemporal objects via
keyframe semantic alignment, derives object state transition-based reasoning
paths using large language models, and ensures logical coherence through
human-verified validation. This dataset establishes a foundation for advancing
research in streaming video understanding, complex temporal reasoning, and
multimodal inference. Our StreamingCoT and its construction toolkit can be
accessed at https://github.com/Fleeting-hyh/StreamingCoT.

</details>


### [48] [Informative Sample Selection Model for Skeleton-based Action Recognition with Limited Training Samples](https://arxiv.org/abs/2510.25345)
*Zhigang Tu,Zhengbo Zhang,Jia Gong,Junsong Yuan,Bo Du*

Main category: cs.CV

TL;DR: 本文提出了一种基于马尔可夫决策过程（MDP）的主动学习框架，用于选择最具有信息量的人体骨架序列进行标注，提升了半监督3D动作识别的效率和准确性。此方法通过映射至双曲空间增强表示能力，并引入元调优策略以加速在真实场景中的应用。实验结果展示了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的半监督3D动作识别方法对于训练样本的选择往往依赖于主动学习中的标注策略，但这种方法选择的最具代表性的骨架序列未必是最具信息量的。为了解决这个问题，作者提出了一种新型的主动学习方法，从马尔可夫决策过程（MDP）的视角重新定义了半监督3D动作识别，以更为智能地选择标注样本，提高了模型对于少样本训练的鲁棒性。

Method: 引入了马尔可夫决策过程（MDP）框架，并采用在欧氏空间到双曲空间的投影方法来增强方法中的状态-动作对的表征能力，同时提出了元调优策略以加速方法在真实场景中的应用部署。

Result: 实验在三个3D动作识别基准数据集上证明了所提方法的有效性，显示了该方法在半监督条件下选择最具信息量的样本进行标注的能力，提升了动作识别准确率。

Conclusion: 本文提出的方法通过马尔可夫决策过程（MDP）和元调优策略提升了半监督3D动作识别的数据样本利用率和模型准确性，在少样本训练情况下依然能够获得较高的识别性能。

Abstract: Skeleton-based human action recognition aims to classify human skeletal
sequences, which are spatiotemporal representations of actions, into predefined
categories. To reduce the reliance on costly annotations of skeletal sequences
while maintaining competitive recognition accuracy, the task of 3D Action
Recognition with Limited Training Samples, also known as semi-supervised 3D
Action Recognition, has been proposed. In addition, active learning, which aims
to proactively select the most informative unlabeled samples for annotation,
has been explored in semi-supervised 3D Action Recognition for training sample
selection. Specifically, researchers adopt an encoder-decoder framework to
embed skeleton sequences into a latent space, where clustering information,
combined with a margin-based selection strategy using a multi-head mechanism,
is utilized to identify the most informative sequences in the unlabeled set for
annotation. However, the most representative skeleton sequences may not
necessarily be the most informative for the action recognizer, as the model may
have already acquired similar knowledge from previously seen skeleton samples.
To solve it, we reformulate Semi-supervised 3D action recognition via active
learning from a novel perspective by casting it as a Markov Decision Process
(MDP). Built upon the MDP framework and its training paradigm, we train an
informative sample selection model to intelligently guide the selection of
skeleton sequences for annotation. To enhance the representational capacity of
the factors in the state-action pairs within our method, we project them from
Euclidean space to hyperbolic space. Furthermore, we introduce a meta tuning
strategy to accelerate the deployment of our method in real-world scenarios.
Extensive experiments on three 3D action recognition benchmarks demonstrate the
effectiveness of our method.

</details>


### [49] [3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine Learning Framework](https://arxiv.org/abs/2510.25347)
*Ayman Abaid,Gianpiero Guidone,Sara Alsubai,Foziyah Alquahtani,Talha Iqbal,Ruth Sharif,Hesham Elzomor,Emiliano Bianchini,Naeif Almagal,Michael G. Madden,Faisal Sharif,Ihsan Ullah*

Main category: cs.CV

TL;DR: 本文提出了一种基于radiomics的管道，通过伪标签生成训练标签，从而不需要专家定义的分割。并评估了预先训练的CT-FM和RadImageNet模型提取的图像特征与传统分类器的组合效果。在包含182名患者的临床CCTA数据集上评估，基于radiomics的模型在没有专家注释的情况下的表现优于CNN衍生的嵌入（准确率为84%）


<details>
  <summary>Details</summary>
Motivation: CAC评分在冠状动脉疾病的早期检测和风险分类中起着关键作用。研究目的是开发一种新的方法，利用伪标签技术缓解标签数据不足的问题，并比较radiomics特征与深度学习特征的效果

Method: 提出了一种基于radiomics的管道，利用伪标签技术生成训练标签，探索使用预先训练的CT-FM和RadImageNet模型提取图像特征，并与传统分类器结合，比较与radiomics特征的效果

Result: 结果显示基于radiomics的模型显著优于从预训练模型中提取的CNN特征，在表现上达到了84%的准确率（p<0.05）

Conclusion: 该方法可以在有限的标签数据下有效提高CAC评分的准确性，且效果优于使用传统深度学习特征的方法

Abstract: Coronary artery calcium (CAC) scoring plays a crucial role in the early
detection and risk stratification of coronary artery disease (CAD). In this
study, we focus on non-contrast coronary computed tomography angiography (CCTA)
scans, which are commonly used for early calcification detection in clinical
settings. To address the challenge of limited annotated data, we propose a
radiomics-based pipeline that leverages pseudo-labeling to generate training
labels, thereby eliminating the need for expert-defined segmentations.
Additionally, we explore the use of pretrained foundation models, specifically
CT-FM and RadImageNet, to extract image features, which are then used with
traditional classifiers. We compare the performance of these deep learning
features with that of radiomics features. Evaluation is conducted on a clinical
CCTA dataset comprising 182 patients, where individuals are classified into two
groups: zero versus non-zero calcium scores. We further investigate the impact
of training on non-contrast datasets versus combined contrast and non-contrast
datasets, with testing performed only on non contrast scans. Results show that
radiomics-based models significantly outperform CNN-derived embeddings from
foundation models (achieving 84% accuracy and p<0.05), despite the
unavailability of expert annotations.

</details>


### [50] [Prompt Estimation from Prototypes for Federated Prompt Tuning of Vision Transformers](https://arxiv.org/abs/2510.25372)
*M Yashwanth,Sharannya Ghosh,Aditay Tripathi,Anirban Chakraborty*

Main category: cs.CV

TL;DR: PEP-FedPT 是一种在联邦学习中用于 ViT 的参数高效微调的技术，通过引入基于类上下文混合提示（CCMP）的方法，实现了全局的一致性和个人的适应性，在各种数据异质性场景中性能超越了现有技术基础线。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的全局提示调整难以推广至异构客户端，个性化提示又容易局部过拟合，缺乏泛化能力。文中提出一种新框架，旨在提高联邦提示调整的泛化和个性化能力，同时保持计算和通信效率。

Method: 提出了一种新的方法 Class-Contextualized Mixed Prompt (CCMP)，它基于全局共享的提示和类特定的提示，为每个输入自适应地获取类特定提示。该方法通过全局原型和客户端的类先验获得权重，展示了无客户端依赖可训练参数的个性化提示技术，利用传统联邦平均法优化提示。

Result: 经过标准数据集（如CIFAR-100, TinyImageNet, DomainNet, 和 iNaturalist）的测试，PEP-FedPT 在处理多样的数据异质性场景时超越了其他基线技术。

Conclusion: PEP-FedPT 提供了一个有效的学习框架，通过 CCMP 方法在联邦提示调整中实现了良好的泛化和适应性，展示出应用前景。

Abstract: Visual Prompt Tuning (VPT) of pre-trained Vision Transformers (ViTs) has
proven highly effective as a parameter-efficient fine-tuning technique for
adapting large models to downstream tasks with limited data. Its parameter
efficiency makes it particularly suitable for Federated Learning (FL), where
both communication and computation budgets are often constrained. However,
global prompt tuning struggles to generalize across heterogeneous clients,
while personalized tuning overfits to local data and lacks generalization. We
propose PEP-FedPT (Prompt Estimation from Prototypes for Federated Prompt
Tuning), a unified framework designed to achieve both generalization and
personalization in federated prompt tuning of ViTs. Within this framework, we
introduce the novel Class-Contextualized Mixed Prompt (CCMP) - based on
class-specific prompts maintained alongside a globally shared prompt. For each
input, CCMP adaptively combines class-specific prompts using weights derived
from global class prototypes and client class priors. This approach enables
per-sample prompt personalization without storing client-dependent trainable
parameters. The prompts are collaboratively optimized via traditional federated
averaging technique on the same. Comprehensive evaluations on CIFAR-100,
TinyImageNet, DomainNet, and iNaturalist datasets demonstrate that PEP-FedPT
consistently surpasses the state-of-the-art baselines under diverse data
heterogeneity scenarios, establishing a strong foundation for efficient and
generalizable federated prompt tuning of Vision Transformers.

</details>


### [51] [Instance-Level Composed Image Retrieval](https://arxiv.org/abs/2510.25387)
*Bill Psomas,George Retsinas,Nikos Efthymiadis,Panagiotis Filntisis,Yannis Avrithis,Petros Maragos,Ondrej Chum,Giorgos Tolias*

Main category: cs.CV

TL;DR: 本文提出了一个新的评估数据集i-CIR并设计了一种无训练的方法BASIC，克服了高质量训练和评估数据缺失的问题，并在i-CIR和其他现有CIR数据集上取得了新的最优性能


<details>
  <summary>Details</summary>
Motivation: 现有数据集侧重于语义级定义，缺少实例级定义的数据集，同时高质量训练和评估数据的获取存在困难

Method: 设计了一个新的评估数据集i-CIR，并提出了一种无训练的方法BASIC，该方法通过预训练的视觉-语言模型（VLM）来估算查询图像到图像和查询文本到图像的相似性，进行晚期融合来提升同时满足两个查询的图像权重，而降低仅满足其中一个查询的图像权重

Result: BASIC在新的数据集i-CIR和其他现有CIR数据集上均实现了新的最优性能

Conclusion: 提出的方法克服了当前数据集和训练数据的局限性，并在新的数据集上取得了优异的结果

Abstract: The progress of composed image retrieval (CIR), a popular research direction
in image retrieval, where a combined visual and textual query is used, is held
back by the absence of high-quality training and evaluation data. We introduce
a new evaluation dataset, i-CIR, which, unlike existing datasets, focuses on an
instance-level class definition. The goal is to retrieve images that contain
the same particular object as the visual query, presented under a variety of
modifications defined by textual queries. Its design and curation process keep
the dataset compact to facilitate future research, while maintaining its
challenge-comparable to retrieval among more than 40M random
distractors-through a semi-automated selection of hard negatives.
  To overcome the challenge of obtaining clean, diverse, and suitable training
data, we leverage pre-trained vision-and-language models (VLMs) in a
training-free approach called BASIC. The method separately estimates
query-image-to-image and query-text-to-image similarities, performing late
fusion to upweight images that satisfy both queries, while down-weighting those
that exhibit high similarity with only one of the two. Each individual
similarity is further improved by a set of components that are simple and
intuitive. BASIC sets a new state of the art on i-CIR but also on existing CIR
datasets that follow a semantic-level class definition. Project page:
https://vrg.fel.cvut.cz/icir/.

</details>


### [52] [More than a Moment: Towards Coherent Sequences of Audio Descriptions](https://arxiv.org/abs/2510.25440)
*Eshika Khandelwal,Junyu Xie,Tengda Han,Max Bain,Arsha Nagrani,Andrew Zisserman,Gül Varol,Makarand Tapaswi*

Main category: cs.CV

TL;DR: CoherentAD是一种训练自由的方法，用于生成连贯的音频描述（AD），从而更好地帮助视障观众理解视频内容。与现有的独立生成AD的方法相比，CoherentAD通过自回归选择多个候选描述来生成连贯且信息丰富的叙述，表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前大多数自动AD生成方法单独生成每个AD，导致描述重复、连贯性差。因此，本研究提出CoherentAD方法，以解决这一问题，提高AD序列的整体连贯性和叙述理解。

Method: 该方法首先为每个AD时间间隔生成多个候选描述，然后在整个序列上进行自回归选择，以形成连贯且信息丰富的叙述。此外，为整体评估AD序列，本文还引入了StoryRecall度量和重复度量。

Result: 实验结果显示，CoherentAD生成的AD序列具有更好的连贯性和叙述理解，优于依赖独立生成的先前方法。

Conclusion: CoherentAD通过自回归选择候选描述，可以在不进行额外训练的情况下生成更连贯和信息丰富的AD序列。

Abstract: Audio Descriptions (ADs) convey essential on-screen information, allowing
visually impaired audiences to follow videos. To be effective, ADs must form a
coherent sequence that helps listeners to visualise the unfolding scene, rather
than describing isolated moments. However, most automatic methods generate each
AD independently, often resulting in repetitive, incoherent descriptions. To
address this, we propose a training-free method, CoherentAD, that first
generates multiple candidate descriptions for each AD time interval, and then
performs auto-regressive selection across the sequence to form a coherent and
informative narrative. To evaluate AD sequences holistically, we introduce a
sequence-level metric, StoryRecall, which measures how well the predicted ADs
convey the ground truth narrative, alongside repetition metrics that capture
the redundancy across consecutive AD outputs. Our method produces coherent AD
sequences with enhanced narrative understanding, outperforming prior approaches
that rely on independent generations.

</details>


### [53] [SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time, Monocular Depth Estimation in Underwater Environments](https://arxiv.org/abs/2510.25463)
*Hongjie Zhang,Gideon Billings,Stefan B. Williams*

Main category: cs.CV

TL;DR: 本文提出SPADE系统，它是一个结合了预训练的相对深度估计器与稀疏深度先验的单目深度估计流水线，用于生成精准且大规模的深度图。此系统在提高准确性和泛化性的同时，还能够在嵌入式硬件上高效运行，有望支持实际的水下检查和干预任务。这项研究已经提交给IEEE海洋工程期刊的AUV 2026专刊。


<details>
  <summary>Details</summary>
Motivation: 提升水下车辆的空间感知能力，以减少操作风险并实现更高级别的自主性，特别是在环境复杂的结构或浑浊的水域中检查和维护水下基础设施时。但是现有的方法（如依靠人力潜水员或远程控制的车辆）在此类条件下存在感知和操作上的挑战。因此，需要一种新的系统来应对这些问题，从而改进水下操作的安全性和效率。

Method: SPADE系统由两个阶段构成：首先，用稀疏深度点去缩放相对深度图；然后，利用提出的Cascade Conv-Deformable Transformer块对最终的度量预测进行精细化处理。这种方法结合了相对深度估计和稀疏深度先验，从而提高了深度估计的准确性并增强了泛化能力。此外，该方法还能在嵌入式硬件上以高于15 FPS的速度运行。

Result: 与最先进的基准相比，SPADE系统在精度和泛化上都取得了显著的提升，同时也是预期的高效运行于嵌入式硬件上的解决方案，显示出其在实际应用中的潜力。这些成果表明SPADE在实际水下检查和干预任务中有着广泛的应用前景。

Conclusion: SPADE系统通过结合相对深度估计和稀疏深度先验，成功解决了在复杂结构或浑浊水域中水下车辆的深度感知挑战，提高了水下操作的安全性、效率和自主性。随着研究的深入，该系统将进一步优化，在水下检查和干预中扮演重要角色。

Abstract: Underwater infrastructure requires frequent inspection and maintenance due to
harsh marine conditions. Current reliance on human divers or remotely operated
vehicles is limited by perceptual and operational challenges, especially around
complex structures or in turbid water. Enhancing the spatial awareness of
underwater vehicles is key to reducing piloting risks and enabling greater
autonomy. To address these challenges, we present SPADE: SParsity Adaptive
Depth Estimator, a monocular depth estimation pipeline that combines
pre-trained relative depth estimator with sparse depth priors to produce dense,
metric scale depth maps. Our two-stage approach first scales the relative depth
map with the sparse depth points, then refines the final metric prediction with
our proposed Cascade Conv-Deformable Transformer blocks. Our approach achieves
improved accuracy and generalisation over state-of-the-art baselines and runs
efficiently at over 15 FPS on embedded hardware, promising to support practical
underwater inspection and intervention. This work has been submitted to IEEE
Journal of Oceanic Engineering Special Issue of AUV 2026.

</details>


### [54] [RegionE: Adaptive Region-Aware Generation for Efficient Image Editing](https://arxiv.org/abs/2510.25590)
*Pengtao Chen,Xianfang Zeng,Maosen Zhao,Mingzhu Shen,Peng Ye,Bangyin Xiang,Zhibo Wang,Wei Cheng,Gang Yu,Tao Chen*

Main category: cs.CV

TL;DR: RegionE 是一种用于加速指令驱动图像编辑 (IIE) 任务的自适应、区域感知生成框架，它能够在不增加额外训练的情况下显著提高效率。通过区分编辑和未编辑区域，并应用相应的预测和降噪策略，RegionE 实现了 2 到 2.57 倍的速度提升，同时保持了语义和感知保真度。


<details>
  <summary>Details</summary>
Motivation: 现有 IIE 模型忽视了编辑区域与未编辑区域在生成难度和计算冗余之间的显著差异，导致生成效率低下。通过专门处理这些差异，RegionE 可以显著加速 IIE 任务，同时保持图像质量和保真度。

Method: RegionE 包括三个关键部分：自适应区域划分、区域感知生成和自适应速度衰减缓存。通过区分编辑区域和未编辑区域，RegionE 可以实现不同区域不同的处理策略，从而提高生成速度和效率。

Result: RegionE 在多个最新的 IIE 基本模型上取得了平均 2.3 倍的加速效果，并且通过 GPT-4o 的评价，保持了语义和感知保真度。具体模型加速倍数分别为 Step1X-Edit (2.57), FLUX.1 Kontext (2.41) 和 Qwen-Image-Edit (2.06)。

Conclusion: RegionE 通过自适应处理不同区域的特性，提供了一种高效、高质量的 IIE 任务加速方案。

Abstract: Recently, instruction-based image editing (IIE) has received widespread
attention. In practice, IIE often modifies only specific regions of an image,
while the remaining areas largely remain unchanged. Although these two types of
regions differ significantly in generation difficulty and computational
redundancy, existing IIE models do not account for this distinction, instead
applying a uniform generation process across the entire image. This motivates
us to propose RegionE, an adaptive, region-aware generation framework that
accelerates IIE tasks without additional training. Specifically, the RegionE
framework consists of three main components: 1) Adaptive Region Partition. We
observed that the trajectory of unedited regions is straight, allowing for
multi-step denoised predictions to be inferred in a single step. Therefore, in
the early denoising stages, we partition the image into edited and unedited
regions based on the difference between the final estimated result and the
reference image. 2) Region-Aware Generation. After distinguishing the regions,
we replace multi-step denoising with one-step prediction for unedited areas.
For edited regions, the trajectory is curved, requiring local iterative
denoising. To improve the efficiency and quality of local iterative generation,
we propose the Region-Instruction KV Cache, which reduces computational cost
while incorporating global information. 3) Adaptive Velocity Decay Cache.
Observing that adjacent timesteps in edited regions exhibit strong velocity
similarity, we further propose an adaptive velocity decay cache to accelerate
the local denoising process. We applied RegionE to state-of-the-art IIE base
models, including Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit. RegionE
achieved acceleration factors of 2.57, 2.41, and 2.06. Evaluations by GPT-4o
confirmed that semantic and perceptual fidelity were well preserved.

</details>


### [55] [Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image Generation](https://arxiv.org/abs/2510.25739)
*Zhi-Kai Chen,Jun-Peng Jiang,Han-Jia Ye,De-Chuan Zhan*

Main category: cs.CV

TL;DR: 本文提出了一种名为Hawk的新方法，通过利用图像的二维空间结构，提高了自回归模型生成图像的速度，同时保持了图像的质量和多样性。实验结果显示，在多个文本到图像的任务上，该方法比标准的自回归模型快1.71倍，且不影响图像的保真度和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有自回归图像生成模型由于其序列化的解码过程导致推理速度慢。而应用于文本生成时，投机性解码显示了加速效果，但将其应用到图像生成中却面临挑战：包括更大的采样空间和对图像二维空间结构利用不足的限制。本文旨在解决这些挑战，提升图像生成的速度和质量。

Method: 引入了一种新方法Hawk，此方法利用图像的二维空间结构来引导推测模型，使之能够进行更准确和高效的预测，从而加速图像生成过程的同时保持图像的生成质量和多样性。

Result: 实验结果显示，Hawk方法在多个文本到图像的任务上实现了比标准自回归模型快1.71倍的速度提升，同时保持了图像生成的质量和多样性。

Conclusion: Hawk方法通过利用图像的二维空间结构，有效解决了自回归模型生成图像时面临的速度和质量折中的问题。

Abstract: Autoregressive (AR) image generation models are capable of producing
high-fidelity images but often suffer from slow inference due to their
inherently sequential, token-by-token decoding process. Speculative decoding,
which employs a lightweight draft model to approximate the output of a larger
AR model, has shown promise in accelerating text generation without
compromising quality. However, its application to image generation remains
largely underexplored. The challenges stem from a significantly larger sampling
space, which complicates the alignment between the draft and target model
outputs, coupled with the inadequate use of the two-dimensional spatial
structure inherent in images, thereby limiting the modeling of local
dependencies. To overcome these challenges, we introduce Hawk, a new approach
that harnesses the spatial structure of images to guide the speculative model
toward more accurate and efficient predictions. Experimental results on
multiple text-to-image benchmarks demonstrate a 1.71x speedup over standard AR
models, while preserving both image fidelity and diversity.

</details>


### [56] [Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks](https://arxiv.org/abs/2510.25760)
*Xu Zheng,Zihao Dongfang,Lutao Jiang,Boyuan Zheng,Yulong Guo,Zhenquan Zhang,Giuliano Albanese,Runyi Yang,Mengjiao Ma,Zixin Zhang,Chenfei Liao,Dingcheng Zhen,Yuanhuiyi Lyu,Yuqian Fu,Bin Ren,Linfeng Zhang,Danda Pani Paudel,Nicu Sebe,Luc Van Gool,Xuming Hu*

Main category: cs.CV

TL;DR: 该论文综述了大型多模态空间推理模型在多模态大语言模型（MLLMs）中的进展，并引入了开放的评估基准。它涵盖了从一般空间推理到视觉语言导航等不同领域的研究。这些模型不仅扩展了人类的空间推理能力，还通过新的传感器（如音频和主观视频）促进了新颖的空间理解。所有相关资源可在指定的GitHub仓库中找到。


<details>
  <summary>Details</summary>
Motivation: 由于对于大型多模态推理模型的系统性回顾和公共可用基准的不足，作者进行了这项综述以填补这一空白，旨在从多维度总结这些模型的发展情况并提出开放的评估基准。

Method: 该综述首先概述了空间推理的一般框架，强调了后培训技术、解释性以及架构改进。随后，它探讨了包括空间关系推理，场景和布局理解等具体任务，并引入了视听等新兴领域的新颖理解。此外，它还重点介绍了身临其境的人工智能（Embodied AI）领域的最新进展。

Result: 发现了多模态大型语言模型在多种空间推理任务上的显著性能，并提出了一系列评估这些模型的新基准。此外，为研究者提供了现有技术和方法的全面总结及其潜在的研究方向。

Conclusion: 综上所述，该综述不仅为研究人员提供了一个关于多模态空间推理的坚实基础，也指出了未来可能的研究方向。相关代码和实施可在提供的GitHub仓库中获取。

Abstract: Humans possess spatial reasoning abilities that enable them to understand
spaces through multimodal observations, such as vision and sound. Large
multimodal reasoning models extend these abilities by learning to perceive and
reason, showing promising performance across diverse spatial tasks. However,
systematic reviews and publicly available benchmarks for these models remain
limited. In this survey, we provide a comprehensive review of multimodal
spatial reasoning tasks with large models, categorizing recent progress in
multimodal large language models (MLLMs) and introducing open benchmarks for
evaluation. We begin by outlining general spatial reasoning, focusing on
post-training techniques, explainability, and architecture. Beyond classical 2D
tasks, we examine spatial relationship reasoning, scene and layout
understanding, as well as visual question answering and grounding in 3D space.
We also review advances in embodied AI, including vision-language navigation
and action models. Additionally, we consider emerging modalities such as audio
and egocentric video, which contribute to novel spatial understanding through
new sensors. We believe this survey establishes a solid foundation and offers
insights into the growing field of multimodal spatial reasoning. Updated
information about this survey, codes and implementation of the open benchmarks
can be found at https://github.com/zhengxuJosh/Awesome-Spatial-Reasoning.

</details>


### [57] [FreeArt3D: Training-Free Articulated Object Generation using 3D Diffusion](https://arxiv.org/abs/2510.25765)
*Chuhao Chen,Isabella Liu,Xinyue Wei,Hao Su,Minghua Liu*

Main category: cs.CV

TL;DR: FreeArt3D 提出了一种无需训练即可生成关节3D对象的框架，通过将一个预训练的静态3D扩散模型作为形状先验，延伸了评分蒸馏抽样方法到3D到4D领域，仅需少量关节状态下图像即可生成高质量的几何和纹理，并准确预测底层的运动结构，适用于多种对象类别。与现有方法相比，显著在质量与适用性上表现更优且完成时间短。


<details>
  <summary>Details</summary>
Motivation: 当前方法在建模关节3D物体时面临密集视图监督和表面纹理忽视的问题。而将3D扩散模型延伸到关节物体生成则遇到挑战。因此，提出一种无需训练生成关节3D物体的框架，提升几何与纹理的质量及运动结构预测准确度。

Method: FreeArt3D 利用一个预训练的静态3D扩散模型作为形状先验，将评分蒸馏抽样方法延伸到3D到4D领域，通过几个不同关节状态的图像优化物体的几何、纹理和关节参数。

Result: 该方法能在几分钟内生成高质量的几何结构和纹理，准确预测运动结构，且适用于多种物体类别，质量及适应性优于现有方法。

Conclusion: 总体而言，FreeArt3D 通过全新的方法成功解决了关节3D物体的生成问题，提供了高质量的几何和纹理，并能准确预测运动结构。

Abstract: Articulated 3D objects are central to many applications in robotics, AR/VR,
and animation. Recent approaches to modeling such objects either rely on
optimization-based reconstruction pipelines that require dense-view supervision
or on feed-forward generative models that produce coarse geometric
approximations and often overlook surface texture. In contrast, open-world 3D
generation of static objects has achieved remarkable success, especially with
the advent of native 3D diffusion models such as Trellis. However, extending
these methods to articulated objects by training native 3D diffusion models
poses significant challenges. In this work, we present FreeArt3D, a
training-free framework for articulated 3D object generation. Instead of
training a new model on limited articulated data, FreeArt3D repurposes a
pre-trained static 3D diffusion model (e.g., Trellis) as a powerful shape
prior. It extends Score Distillation Sampling (SDS) into the 3D-to-4D domain by
treating articulation as an additional generative dimension. Given a few images
captured in different articulation states, FreeArt3D jointly optimizes the
object's geometry, texture, and articulation parameters without requiring
task-specific training or access to large-scale articulated datasets. Our
method generates high-fidelity geometry and textures, accurately predicts
underlying kinematic structures, and generalizes well across diverse object
categories. Despite following a per-instance optimization paradigm, FreeArt3D
completes in minutes and significantly outperforms prior state-of-the-art
approaches in both quality and versatility.

</details>


### [58] [VFXMaster: Unlocking Dynamic Visual Effect Generation via In-Context Learning](https://arxiv.org/abs/2510.25772)
*Baolu Li,Yiming Zhang,Qinghe Wang,Liqian Ma,Xiaoyu Shi,Xintao Wang,Pengfei Wan,Zhenfei Yin,Yunzhi Zhuge,Huchuan Lu,Xu Jia*

Main category: cs.CV

TL;DR: VFXMaster是一款用于生成视觉特效的统一框架，可以通过参考视频将动态效果复制到目标内容上，并且能够很好地泛化到未见过的效果类别上。这项工作解决了现有方法在处理视觉特效时资源利用率低和泛化能力差的问题，通过使用上下文学习策略和有效的信息注入机制来实现这一点。实验表明，该方法在模仿各种类别效果信息以及处理领域外效果泛化方面都表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有生成视觉特效的方法在资源利用率和泛化能力方面存在局限，无法有效应对新的或者未见过的视觉特效。为了克服这些问题，提出VFXMaster来统一处理这些挑战。VFXMaster通过利用参考视频和创新的上下文学习策略，提升生成视觉特效的能力，特别是针对用户提供的单一视频快速实现未见过的视觉特效泛化。

Method: VFXMaster利用上下文学习策略，通过提供一个参考示例来指导模型学习动态效果，设计了上下文注意力掩码来精确定位并注入效果中的核心属性，实现单一模型进行效果模仿的泛化能力。此外，还提出了快速效果适应机制，以进行一次性的效果调整。这种方法基于现有模型并引入一个新的框架，使模型能够从参考视频中提取所需信息并应用于目标视频。

Result: 通过对各种视觉特效信息的模仿实验，展示了该方法在模仿视觉特效上的有效性。此外，在处理未见过效果类别的泛化任务上，表现出优异的能力。结果表明，VFXMaster在视觉特效的生成上具有显著的优势和潜力。通过实验表明，该方法能够有效地模仿各种类别的效果，并且具有很强的跨域泛化能力。

Conclusion: VFXMaster是一个新颖且高效的统一框架，为视觉特效生成带来了实质性的进步，特别是在处理未见过的视觉特效上显示出强大的泛化能力，展示了良好的应用潜力和研究价值。同时，将公开代码、模型和数据集以促进该领域后续研究。

Abstract: Visual effects (VFX) are crucial to the expressive power of digital media,
yet their creation remains a major challenge for generative AI. Prevailing
methods often rely on the one-LoRA-per-effect paradigm, which is
resource-intensive and fundamentally incapable of generalizing to unseen
effects, thus limiting scalability and creation. To address this challenge, we
introduce VFXMaster, the first unified, reference-based framework for VFX video
generation. It recasts effect generation as an in-context learning task,
enabling it to reproduce diverse dynamic effects from a reference video onto
target content. In addition, it demonstrates remarkable generalization to
unseen effect categories. Specifically, we design an in-context conditioning
strategy that prompts the model with a reference example. An in-context
attention mask is designed to precisely decouple and inject the essential
effect attributes, allowing a single unified model to master the effect
imitation without information leakage. In addition, we propose an efficient
one-shot effect adaptation mechanism to boost generalization capability on
tough unseen effects from a single user-provided video rapidly. Extensive
experiments demonstrate that our method effectively imitates various categories
of effect information and exhibits outstanding generalization to out-of-domain
effects. To foster future research, we will release our code, models, and a
comprehensive dataset to the community.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [59] [MetaLore: Learning to Orchestrate Communication and Computation for Metaverse Synchronization](https://arxiv.org/abs/2510.25705)
*Elif Ebru Ohri,Qi Liao,Anastasios Giovanidis,Francesca Fossati,Nour-El-Houda Yellas*

Main category: cs.NI

TL;DR: 该论文提出了一种基于深度强化学习的MetaLore框架，用于元宇宙或数字孪生环境中通信和计算资源的联合分配，以优化物理与数字世界间的同步性，同时保证较高的吞吐量性能。引入了AoRI和AoSI两个新的AoI指标，提升了同步质量。该方法通过有限的观察空间实现动态适应，并且性能接近穷举法的结果。


<details>
  <summary>Details</summary>
Motivation: 为了实现元宇宙或数字孪生环境下的实时应用中的无缝同步，克服延迟所带来的用户体验下降问题，提出了一种名为MetaLore的框架来联合管理和分配通信和计算资源，以优化同步效果和性能。此外，引入了AoRI和AoSI两个新的AoI指标，以进一步提高同步质量。

Method: 使用深度强化学习框架MetaLore，通过动态分配通信带宽和计算资源，优化了物理与数字世界之间的同步性。引入AoRI和AoSI两个新的AoI指标，改进了奖励函数，提出了一个场景驱动和规模缩小的观察空间，来提升灵活性和适应性。采用扩展后的开源模拟器进行实验，证明了所提出方法的有效性。

Result: 测试结果表明，利用深度强化学习的方法可以实现不低于完全遍历搜索的性能，通过定义只有两个队列长度的小规模观察空间获得高灵活性和有效性，能够根据实时性需求自适应调整，充分展示出所提方法的优点。

Conclusion: 提出了MetaLore框架，通过深度强化学习优化通信和计算资源的分配，达到提高元宇宙或数字孪生环境中同步的目的。同时通过引入AoRI和AoSI指标，进一步提升了同步质量，展示了其在解决实际动态场景中优势。

Abstract: As augmented and virtual reality evolve, achieving seamless synchronization
between physical and digital realms remains a critical challenge, especially
for real-time applications where delays affect the user experience. This paper
presents MetaLore, a Deep Reinforcement Learning (DRL) based framework for
joint communication and computational resource allocation in Metaverse or
digital twin environments. MetaLore dynamically shares the communication
bandwidth and computational resources among sensors and mobile devices to
optimize synchronization, while offering high throughput performance. Special
treatment is given in satisfying end-to-end delay guarantees. A key
contribution is the introduction of two novel Age of Information (AoI) metrics:
Age of Request Information (AoRI) and Age of Sensor Information (AoSI),
integrated into the reward function to enhance synchronization quality. An open
source simulator has been extended to incorporate and evaluate the approach.
The DRL solution is shown to achieve the performance of full-enumeration
brute-force solutions by making use of a small, task-oriented observation space
of two queue lengths at the network side. This allows the DRL approach the
flexibility to effectively and autonomously adapt to dynamic traffic
conditions.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [60] [Resi-VidTok: An Efficient and Decomposed Progressive Tokenization Framework for Ultra-Low-Rate and Lightweight Video Transmission](https://arxiv.org/abs/2510.25002)
*Zhenyu Liu,Yi Ma,Rahim Tafazolli,Zhi Ding*

Main category: cs.IT

TL;DR: Resi-VidTok 是一种针对低速率和轻量级视频传输而设计的框架，可以在保证感知和语义保真度的同时，提供强大的鲁棒性。该框架通过重新组织时空内容为一个有序的重要令牌流，支持渐进编码和前缀可解码重建，在受限频道下实现质量平滑降级。实验结果表明，在通道带宽比低至 0.0004 时，它仍能保持视觉和语义的一致性，在超过 30 fps 的情况下，实现实时重建，适用于节能、延迟敏感和高可靠性无线应用。


<details>
  <summary>Details</summary>
Motivation: 现有的先进深度模型在面临带宽限制和连接弱等严重信道条件下，传输视频仍然面临巨大的挑战。为此，设计了一种用于超低速率和轻量级视频传输的框架，即 Resi-VidTok，致力于实现在商品数字硬件条件下的强健性并在保证视觉感知和语义保真度的基础上优化传输效率。

Method: Resi-VidTok 通过重新组织时空内容为一个有序的重要令牌流，支持渐进编码和前缀可解码重建，并结合帧稀疏化和轻量级解码插值器来降低传输负载，在动态的频道中根据令牌的重要性分配率和保护，实现稳定质量传输适应各种SNR环境。

Result: 实验结果表明，即使在通道带宽比低至0.0004的情况下，Resi-VidTok仍能保持视觉和语义的一致性，并且在超过30 fps的情况下，实现实时重建。这些结果证明了Resi-VidTok在节能、延迟敏感和可靠性关键的无线应用中的实用性。

Conclusion: Resi-VidTok 是一种面向超低速率和轻量级视频传输的应用框架，它可以实现在保证感知和语义保真度的同时，提供强大的鲁棒性，特别适用于实时、节能、低延迟和高可靠性要求的无线传输场景。

Abstract: Real-time transmission of video over wireless networks remains highly
challenging, even with advanced deep models, particularly under severe channel
conditions such as limited bandwidth and weak connectivity. In this paper, we
propose Resi-VidTok, a Resilient Tokenization-Enabled framework designed for
ultra-low-rate and lightweight video transmission that delivers strong
robustness while preserving perceptual and semantic fidelity on commodity
digital hardware. By reorganizing spatio--temporal content into a discrete,
importance-ordered token stream composed of key tokens and refinement tokens,
Resi-VidTok enables progressive encoding, prefix-decodable reconstruction, and
graceful quality degradation under constrained channels. A key contribution is
a resilient 1D tokenization pipeline for video that integrates differential
temporal token coding, explicitly supporting reliable recovery from incomplete
token sets using a single shared framewise decoder--without auxiliary temporal
extractors or heavy generative models. Furthermore, stride-controlled frame
sparsification combined with a lightweight decoder-side interpolator reduces
transmission load while maintaining motion continuity. Finally, a
channel-adaptive source--channel coding and modulation scheme dynamically
allocates rate and protection according to token importance and channel
condition, yielding stable quality across adverse SNRs. Evaluation results
indicate robust visual and semantic consistency at channel bandwidth ratios
(CBR) as low as 0.0004 and real-time reconstruction at over 30 fps,
demonstrating the practicality of Resi-VidTok for energy-efficient,
latency-sensitive, and reliability-critical wireless applications.

</details>


### [61] [Fed-PELAD: Communication-Efficient Federated Learning for Massive MIMO CSI Feedback with Personalized Encoders and a LoRA-Adapted Shared Decoder](https://arxiv.org/abs/2510.25181)
*Yixiang Zhou,Tong Wu,Meixia Tao,Jianhua Mo*

Main category: cs.IT

TL;DR: Fed-PELAD是一种新的联邦学习框架，用于解决大规模MIMO系统中CSI反馈的通信开销、数据异构性和隐私问题。该框架采用个性化的编码器和LoRA适配的共享解码器，通过低秩适配仅传输紧凑的适配参数，降低了通信开销。模拟结果显示，相比于传统方法，此框架在降低42.97%上行链路通信成本的同时，提高了1.2 dB的CSI反馈精度。


<details>
  <summary>Details</summary>
Motivation: 如何有效解决大规模MIMO系统中CSI反馈带来的通信开销、数据异构性和隐私问题。

Method: 设计了一种新的联邦学习框架Fed-PELAD，采用个性化编码器和LoRA适配的共享解码器。在用户设备本地训练个性化的编码器来捕捉设备特定的信道特征，同时全局更新共享解码器。通过低秩适配仅传输适配参数，降低了通信开销，提高系统的性能。此外，引入了交替冻结策略和校准学习率比率以增强收敛稳定性。

Result: 仿真结果表明，Fed-PELAD将上行链路通信成本降低42.97%，同时CSI反馈精度提高了1.2 dB，特别是在异构条件下。

Conclusion: Fed-PELAD通过降低通信开销和提高CSI反馈精度，在解决大规模MIMO系统中信道状态信息反馈的问题上展现出有效性和优越性。

Abstract: This paper addresses the critical challenges of communication overhead, data
heterogeneity, and privacy in deep learning for channel state information (CSI)
feedback in massive MIMO systems. To this end, we propose Fed-PELAD, a novel
federated learning framework that incorporates personalized encoders and a
LoRA-adapted shared decoder. Specifically, personalized encoders are trained
locally on each user equipment (UE) to capture device-specific channel
characteristics, while a shared decoder is updated globally via the
coordination of the base station (BS) by using Low-Rank Adaptation (LoRA). This
design ensures that only compact LoRA adapter parameters instead of full model
updates are transmitted for aggregation. To further enhance convergence
stability, we introduce an alternating freezing strategy with calibrated
learning-rate ratio during LoRA aggregation. Extensive simulations on
3GPP-standard channel models demonstrate that Fed-PELAD requires only 42.97\%
of the uplink communication cost compared to conventional methods while
achieving a performance gain of 1.2 dB in CSI feedback accuracy under
heterogeneous conditions.

</details>


### [62] [General Coverage Models: Structure, Monotonicity, and Shotgun Sequencing](https://arxiv.org/abs/2510.25305)
*Yitzchak Grunbaum,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 本文研究了通过每次抽样揭示$[n]$的一个子集，直到所有项目至少都被看到一次所需的预期抽样次数的过程。基于高通量DNA测序引入了固定长度窗口模型的抽样方法。通过开发一个统一组合工具，使得覆盖率时间的计算从概率转移到子集计数上，从而实现精确计算。文章分析了这些模型的渐近性质，并提出了几种均匀$oldsymbol{	ext{$oldsymbol{	ext{$oldsymbol{	ext{l}}$}}$-$oldsymbol{	ext{regular}}$}}$模型的界限，并猜想在所有均匀$oldsymbol{	ext{uniform $oldsymbol{	ext{$oldsymbol{	ext{l}}$}}$-regular models}}$中，批次采样模型最大化覆盖时间。此外，推导出适用于整个统一$oldsymbol{	ext{$oldsymbol{	ext{$oldsymbol{	ext{l}}$}}$-regular models}}$类的通用上线限，这说明了许多抽样模型在较高阶项方面共享相同渐近顺序，但可能会在较低阶项上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 本文是为了研究一种基于高通量DNA测序的数据获取方法，这类方法的每次抽样会显示出$[n]$的一个固定长度的窗口。这类研究动机是为了建立一种新的覆盖时间计算工具，该工具将概率计算转换为子集数量的计数问题，以实现从理论到具体模型应用上的精确计算和优化。具体而言，这种模型能更好地模拟高通量测序中从样品中获取序列数据的过程。

Method: 开发了一个组合工具，将覆盖率时间的计算问题从概率计算转移到了对$[n]$以内部子集进行计数的问题上，从而实现了精确计算。此外，还引入了均匀$oldsymbol{	ext{l}}$-regular模型的概念，并通过引理和定理推导了它们的覆盖时间性质。

Result: 研究结果提供了一系列在批次抽样及固定长度窗口模型中的覆盖时间计算的精确表达式。另外，证明了在所有均匀$oldsymbol{	ext{l}}$-regular模型中，批次抽样模型最大化的覆盖时间。并且给出了一种适用于整个统一$oldsymbol{	ext{l}}$-regular模型类的通用上限，说明了尽管各类模型在较高阶项上趋同，但可能在较低阶项上有显著差异。

Conclusion: 这项工作为高通量DNA测序中覆盖率时间的一种新模型提供了理论支持。该模型通过组合数学方法，简化了覆盖时间的计算过程，提高了计算效率。还指出了在均匀$oldsymbol{	ext{l}}$-regular模型的一致性下，批次模型具有最大化覆盖时间的特性，这或许对实际应用有着重要指导意义。

Abstract: We study coverage processes in which each draw reveals a subset of $[n]$, and
the goal is to determine the expected number of draws until all items are seen
at least once. A classical example is the Coupon Collector's Problem, where
each draw reveals exactly one item. Motivated by shotgun DNA sequencing, we
introduce a model where each draw is a contiguous window of fixed length, in
both cyclic and non-cyclic variants. We develop a unifying combinatorial tool
that shifts the task of finding coverage time from probability, to a counting
problem over families of subsets of $[n]$ that together contain all items,
enabling exact calculation. Using this result, we obtain exact expressions for
the window models. We then leverage past results on a continuous analogue of
the cyclic window model to analyze the asymptotic behavior of both models. We
further study what we call uniform $\ell$-regular models, where every draw has
size $\ell$ and every item appears in the same number of admissible draws. We
compare these to the batch sampling model, in which all $\ell$-subsets are
drawn uniformly at random and present upper and lower bounds, which were also
obtained independently by Berend and Sher. We conjecture, and prove for special
cases, that this model maximizes the coverage time among all uniform
$\ell$-regular models. Finally, we prove a universal upper bound on the entire
class of uniform $\ell$-regular models, which illuminates the fact that many
sampling models share the same leading asymptotic order, while potentially
differing significantly in lower-order terms.

</details>


### [63] [Joint Beamforming Design and Resource Allocation for IRS-Assisted Full-Duplex Terahertz Systems](https://arxiv.org/abs/2510.25346)
*Chi Qiu,Wen Chen,Qingqing Wu,Fen Hou,Wanming Hao,Ruiqi Liu,Derrick Wing Kwan Ng*

Main category: cs.IT

TL;DR: IRS辅助全双工THz通信系统提出了一种联合资源分配框架，通过优化IRS相位偏移、上下行传输功率控制、子带带宽分配和子带分配来最大化加权最小用户速率，以确保服务质量和系统灵活性，同时提出的算法在不同的频谱划分方案下有效简化了计算复杂度，并通过仿真验证了其有效性和比基准方案更高的频谱效率。


<details>
  <summary>Details</summary>
Motivation: 解决IRS辅助全双工THz通信系统中存在的传播损耗、THz频段中频率依赖的分子吸收以及残余自干扰等技术挑战，优化资源分配以实现高性能的通信系统。

Method: 提出了一种联合优化IRS相位偏移、上下行传输功率控制、子带带宽分配和子带分配的框架，同时开发了两种在不同频谱划分方案下的计算高效算法，一种是等带宽分配，另一种是有适应性的带宽分配。

Result: 仿真结果验证了提出的方案的有效性，展示了比基准方案更高的频谱效率和性能优越性。

Conclusion: 研究设计了一种高效的IRS资源分配方案，优化了全双工THz通信系统的性能，提高了系统的灵活性和频谱效率。

Abstract: Intelligent reflecting surface (IRS)-assisted full-duplex (FD) terahertz
(THz) communication systems have emerged as a promising paradigm to satisfy the
escalating demand for ultra-high data rates and spectral efficiency in future
wireless networks. However, the practical deployment of such systems presents
unique technical challenges, stemming from severe propagation loss,
frequency-dependent molecular absorption in the THz band, and the presence of
strong residual self-interference (SI) inherent to FD communications. To tackle
these issues, this paper proposes a joint resource allocation framework that
aims to maximize the weighted minimum rate among all users, thereby ensuring
fairness in quality of service. Specifically, the proposed design jointly
optimizes IRS reflecting phase shifts, uplink/downlink transmit power control,
sub-band bandwidth allocation, and sub-band assignment, explicitly capturing
the unique propagation characteristics of THz channels and the impact of
residual SI. To strike an balance between system performance and computational
complexity, two computationally efficient algorithms are developed under
distinct spectrum partitioning schemes: one assumes equal sub-band bandwidth
allocation to facilliate tractable optimization, while the other introduces
adaptive bandwidth allocation to further enhance spectral utilization and
system flexibility. Simulation results validate the effectiveness of the
proposed designs and demonstrate that the adopted scheme achieves significant
spectral efficiency improvements over benchmark schemes.

</details>


### [64] [Several classes of $p$-ary linear codes with few-weights derived from Weil sums](https://arxiv.org/abs/2510.25578)
*Mrinal Kanti Bose,Abhay Kumar Singh*

Main category: cs.IT

TL;DR: 本文提出了几种在有限域$\mathbb{F}_{p}$上生成线性码的新方法，通过选择两个特定的定义集，生成了几类线性码，并通过详细的有限域Weil和计算确定了所有构建码的参数和权重分布。并找到了一类最优的2权重线性码，满足Griesmer界。


<details>
  <summary>Details</summary>
Motivation: 线性码研究的重要领域，主要原因是它们在秘密共享方案、身份验证码、关联方案和强正则图中的应用。受Cheng和Gao以及Wu, Li和Zeng的工作启发，文章提出来几个新的线性码构造方法。

Method: 通过选择两个特定定义集构建几类有限域上的线性码：第一定义集用于生成四重量和二重量码；第二定义集利用弱正则弯函数生成六重量、八重量和九重量码。所有新构造的线性码的参数和权重分布由有限域上的Weil和计算得出。

Result: 通过特定定义集生成了包括4、2、6、8、9重量在内的几类线性码，确定了新构造的所有线性码参数和权重量分布。特别地，发现了一类满足Griesmer界的二重量码。

Conclusion: 本文通过两个特定定义集提出几种新的线性码构造方法，得到了一系列不同重量的线性码，包括一类最优的二重量码，丰富了线性码应用领域。

Abstract: Linear codes with few weights have been a significant area of research in
coding theory for many years, due to their applications in secret sharing
schemes, authentication codes, association schemes, and strongly regular
graphs. Inspired by the works of Cheng and Gao \cite{P8} and Wu, Li and Zeng
\cite{P12}, in this paper, we propose several new classes of few-weight linear
codes over the finite field $\mathbb{F}_{p}$ through the selection of two
specific defining sets. Consequently, we obtain five classes of $4$-weight
linear codes and one class of $2$-weight linear codes from our first defining
set. Furthermore, by employing weakly regular bent functions in our second
defining set, we derive two classes of $6$-weight codes, two classes of
$8$-weight codes, and one class of $9$-weight codes. The parameters and weight
distributions of all these constructed codes are wholly determined by detailed
calculations on certain Weil sums over finite fields. In addition, we identify
an optimal class of $2$-weight codes that meet the Griesmer bound.

</details>


### [65] [On Multidimensional 2-Weight-Limited Burst-Correcting Codes](https://arxiv.org/abs/2510.25592)
*Hagai Berend,Ohad Elishco,Moshe Schwartz*

Main category: cs.IT

TL;DR: 本文研究了能够纠正重量最多为2的突发错误的多维代码，并探讨了其中的三种限制：两个位置之间的$L_∞$距离受限、两个位置之间的$L_1$距离受限，或者两个位置在平行于坐标轴的直线上且之间的距离受限。我们为这些情况提供了显式代码构造，并将它们的额外冗余度与我们证明的下界进行了比较。


<details>
  <summary>Details</summary>
Motivation: 动机是研究能够纠正重量最多为2的突发错误的多维代码，以提高数据传输的可靠性。通过探讨不同限制条件下的代码构造，我们可以更好地理解如何在实际应用中减小额外冗余度的开销。

Method: 研究了三种不同的限制条件下的代码构造，并提供了一种显式的代码构造方法，同时证明了一个与这些构造相关的下界。这种方法可以帮助我们理解如何设计有效的错误纠正代码。

Result: 对于所有考虑的情况，都提供了显式的代码构造示例，并且这些构造的额外冗余度与我们证明的一个下界进行了比较。结果表明，通过优化代码构造可以接近这个下界，从而减少额外冗余度。

Conclusion: 本文的研究结论是，我们可以通过优化多维代码的构造来接近或达到纠正重量最多为2的突发错误所需的最小额外冗余度。这对于提高数据传输的效率和可靠性具有重要意义。

Abstract: We consider multidimensional codes capable of correcting a burst error of
weight at most $2$. When two positions are in error, the burst limits their
relative position. We study three such limitations: the $L_\infty$ distance
between the positions is bounded, the $L_1$ distance between the positions is
bounded, or the two positions are on an axis-parallel line with bounded
distance between them. In all cases we provide explicit code constructions, and
compare their excess redundancy to a lower bound we prove.

</details>


### [66] [Effect of Full Common Randomness Replication in Symmetric PIR on Graph-Based Replicated Systems](https://arxiv.org/abs/2510.25736)
*Shreya Meel,Sennur Ulukus*

Main category: cs.IT

TL;DR: 本文重新研究了在简单的图模型下的对称私人信息检索（SPIR）问题，利用共享的公共随机性来量化数据库隐私保护下的SPIR容量相较于图形复制公共随机性的情况下的提升。通过将一类PIR方案转换为对应的SPIR方案，建立了路径图和循环图的SPIR容量下限，并推导出更紧的上界。对于三节点路径图的情况，SPIR容量确定为1/2。


<details>
  <summary>Details</summary>
Motivation: 研究在简单图形模型下，通过共享公共随机性提升SPIR的容量，以更好地保护数据库隐私和数据安全，同时寻找更有效的PIR方案转换为SPIR方案的方法，这些方法能适用于路径和循环结构。目标是量化并改善在不同图形结构上的数据检索效率，确保隐私保护的同时实现效率最大化。

Method: 通过开发算法将一类PIR方案转换为相应的SPIR方案，从而建立图形下的SPIR容量下限，并为路径图和周期图推导更紧的上界。模拟和理论分析了路径图和循环图的SPIR能力，提出特定的数据检索策略以最大化SPIR容量。

Result: 对于具有斜边的图模型，开发了从PIR方案到SPIR方案的转换方法，并证明了在某些图结构（如路径图和循环图）上的SPIR容量可以超过标准PIR容量。这种转换方法使得能够更好地利用公共随机性来保护数据库隐私。对于三节点路径图，SPIR容量被精确地确定为1/2。

Conclusion: 研究提出了将PIR方案转换为SPIR方案的新方法，证明了在特定图形结构（如路径图和循环图）下SPIR容量可以显著提高。这对于解决具有共享数据库的分布式系统的隐私保护问题有着重要意义。

Abstract: We revisit the problem of symmetric private information retrieval (SPIR) in
settings where the database replication is modeled by a simple graph. Here,
each vertex corresponds to a server, and a message is replicated on two servers
if and only if there is an edge between them. To satisfy the requirement of
database privacy, we let all the servers share some common randomness,
independent of the messages. We aim to quantify the improvement in SPIR
capacity, i.e., the maximum ratio of the number of desired and downloaded
symbols, compared to the setting with graph-replicated common randomness.
Towards this, we develop an algorithm to convert a class of PIR schemes into
the corresponding SPIR schemes, thereby establishing a capacity lower bound on
graphs for which such schemes exist. This includes the class of path and cyclic
graphs for which we derive capacity upper bounds that are tighter than the
trivial bounds given by the respective PIR capacities. For the special case of
path graph with three vertices, we identify the SPIR capacity to be
$\frac{1}{2}$.

</details>


### [67] [A mathematical study of the excess growth rate](https://arxiv.org/abs/2510.25740)
*Steven Campbell,Ting-Kam Leonard Wong*

Main category: cs.IT

TL;DR: 我们从信息论的角度研究了超额增长率，并将其与Rényi熵、交叉熵、Helmholtz自由能等概念相关联。主要成果包括三个特征定理，分别基于相对熵、Jensen不等式的差距以及推广Bregman散度的对数发散度。此外，我们还研究了超额增长率的最大化，并与最优增长投资组合进行了比较。这些结果不仅从理论上证明了超额增长率的重要性，还建立了信息论与定量金融之间的新联系。


<details>
  <summary>Details</summary>
Motivation: 通过信息论的视角研究超额增长率，以便更深入地理解其在投资组合理论中的作用，以及它的普遍性质和应用范围。这有助于我们发现信息论在金融领域的可能应用，并展示如何利用这些理论工具来分析金融数据。

Method: 我们从Rényi熵、交叉熵、Helmholtz自由能、平均编码长度度量以及大偏差原理的角度来研究超额增长率。并通过相对熵、Jensen不等式的差距以及对数发散度这三个关键角度进行理论刻画。最后，研究超额增长率的最大化问题，与最优增长的投资组合进行了对比和分析。

Result: 成果包括三个特征定理，其中两个是基于与相对熵和Jensen不等式差距的关系，另一个是关于推广Bregman散度的对数发散度。这些理论成果不仅证实了超额增长率的重要性，还找到了信息论与金融的交错点，特别是超额增长率的数学性质与金融中的增长策略之间的联系。此外，也展示了超额增长率的优化方法和最优增长的投资组合之间的联系和差异。

Conclusion: 这项研究加深了我们对超额增长率的理解，并强调了信息论在金融分析中的价值。我们的发现不仅具有理论意义，而且在实证研究中可以打开新的视角，尤其是在投资组合选择和金融风险管理方面。

Abstract: We study the excess growth rate -- a fundamental logarithmic functional
arising in portfolio theory -- from the perspective of information theory. We
show that the excess growth rate can be connected to the R\'{e}nyi and cross
entropies, the Helmholtz free energy, L. Campbell's measure of average code
length and large deviations. Our main results consist of three axiomatic
characterization theorems of the excess growth rate, in terms of (i) the
relative entropy, (ii) the gap in Jensen's inequality, and (iii) the
logarithmic divergence that generalizes the Bregman divergence. Furthermore, we
study maximization of the excess growth rate and compare it with the growth
optimal portfolio. Our results not only provide theoretical justifications of
the significance of the excess growth rate, but also establish new connections
between information theory and quantitative finance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [68] [Fortytwo: Swarm Inference with Peer-Ranked Consensus](https://arxiv.org/abs/2510.24801)
*Vladyslav Larin,Ihor Naumenko,Aleksei Ivashov,Ivan Nikitin,Alexander Firsov*

Main category: cs.LG

TL;DR: 本文介绍了Fortytwo协议，利用群智和分布式成对排名共识实现更好的AI推理性能。通过使用定制的Bradley-Terry模型，该协议在GPQA Diamond上的表现优于多数投票方法。同时，该协议通过链上声誉系统和证明能力机制，提高了抗攻击性和准确性，并在多挑战基准测试中表现出优越性。这项研究为去中心化AI系统奠定了基础，通过集体智能提供可靠和安全的高质量推理服务.


<details>
  <summary>Details</summary>
Motivation: 随着集中式AI计算能力的限制和回报递减，需要一个可水平扩展的推理层来满足需求。Fortytwo协议旨在通过群智和分布式成对排名共识，实现更强大的AI推理能力，从而提升整体系统性能和可靠性.

Method: Fortytwo协议结合了使用定制的Bradley-Terry模型的分布式成对排名，以及基于链上声誉和证明能力的机制来筛选节点，确保了系统的抗攻击性和准确性。通过这种方式，不同模型的节点可以通过共识产生高质量的推理结果.

Result: 在GPQA Diamond、LiveCodeBench和AIME等六个挑战性基准上，Fortytwo协议的表现优于现有的多数投票方法和单一模型基准。特别是在对抗性或噪声提示情况下，Fortytwo协议显示出更强的鲁棒性.

Conclusion: 这项研究证明了通过分布式群智系统实现高质量、可靠、安全的AI推理的可行性。Fortytwo协议不仅提升了系统性能，还提高了系统在对抗性环境中的鲁棒性，同时也解决了多身份攻击等问题，为去中心化AI系统的开发奠定了坚实的基础。

Abstract: As centralized AI hits compute ceilings and diminishing returns from
ever-larger training runs, meeting demand requires an inference layer that
scales horizontally in both capacity and capability. We present Fortytwo, a
novel protocol that leverages swarm intelligence principles and distributed
pairwise ranking consensus to achieve superior performance in AI inference. Our
approach reimagines collaboration among AI nodes using swarm inference: a
peer-ranked, reputation-weighted consensus across heterogeneous models that
surfaces the highest-quality responses. Using pairwise ranking with a custom
Bradley-Terry-style aggregation model, we demonstrate that swarm inference
substantially outperforms majority voting, achieving 85.90% on GPQA Diamond
versus 68.69% for majority voting with the same model set - an improvement of
+17.21 percentage points (approximately +25.1% relative). The protocol
incorporates on-chain reputation so node influence adapts to demonstrated
accuracy over time, yielding a meritocratic consensus that filters low-quality
or malicious participants. To resist Sybil attacks, Fortytwo employs
proof-of-capability in its consensus: nodes must successfully complete
calibration/test requests and stake reputation to enter ranking rounds, making
multi-identity attacks economically unattractive while preserving openness.
Across six challenging benchmarks, including GPQA Diamond, LiveCodeBench, and
AIME, our evaluation indicates higher accuracy and strong resilience to
adversarial and noisy free-form prompting (e.g., prompt-injection degradation
of only 0.12% versus 6.20% for a monolithic single-model baseline), while
retaining practical deployability. Together, these results establish a
foundation for decentralized AI systems - democratizing access to high-quality
inference through collective intelligence without sacrificing reliability or
security.

</details>


### [69] [From Linear to Nonlinear: Provable Weak-to-Strong Generalization through Feature Learning](https://arxiv.org/abs/2510.24812)
*Junsoo Oh,Jerry Song,Chulhee Yun*

Main category: cs.LG

TL;DR: 本文提供了从线性CNN到两层ReLU CNN的弱到强泛化的正式分析，基于数据集的信噪比特性，识别了数据稀缺和数据充足两种情况，并揭示了特定的弱到强泛化机制。在数据稀缺的情况下，根据数据量，泛化可能通过良性拟合或有害拟合发生，并描述了转变边界。在数据充足的情况下，泛化在早期通过标签修正出现，但过度训练可以随后降低性能。


<details>
  <summary>Details</summary>
Motivation: 解释弱到强泛化的现象，提供从线性CNN到两层ReLU CNN的正式分析，特别是在数据稀缺和数据充足两种情形下的机制。

Method: 考虑到包含依赖于标签的信号和与标签无关的噪声的有结构的数据，当强大的模型在标记数据上进行训练时，使用梯度下降动态进行分析。分析基于数据集的信噪比特性，识别出数据稀缺和数据充足两种场景。

Result: 研究确定了在数据稀缺的情形下，弱到强的泛化可能通过良性拟合或有害拟合发生，并描述了相应的转变边界；在数据充足的情况下，泛化最初通过标签修正出现，但过度训练可以随后降低整体性能。

Conclusion: 基于两个场景，信噪比提出了良性或有害拟合以及过度训练对弱到强泛化的影响，这为训练更高效、更有用的机器学习模型提供了理论基础。

Abstract: Weak-to-strong generalization refers to the phenomenon where a stronger model
trained under supervision from a weaker one can outperform its teacher. While
prior studies aim to explain this effect, most theoretical insights are limited
to abstract frameworks or linear/random feature models. In this paper, we
provide a formal analysis of weak-to-strong generalization from a linear CNN
(weak) to a two-layer ReLU CNN (strong). We consider structured data composed
of label-dependent signals of varying difficulty and label-independent noise,
and analyze gradient descent dynamics when the strong model is trained on data
labeled by the pretrained weak model. Our analysis identifies two regimes --
data-scarce and data-abundant -- based on the signal-to-noise characteristics
of the dataset, and reveals distinct mechanisms of weak-to-strong
generalization. In the data-scarce regime, generalization occurs via benign
overfitting or fails via harmful overfitting, depending on the amount of data,
and we characterize the transition boundary. In the data-abundant regime,
generalization emerges in the early phase through label correction, but we
observe that overtraining can subsequently degrade performance.

</details>


### [70] [Augmenting Biological Fitness Prediction Benchmarks with Landscapes Features from GraphFLA](https://arxiv.org/abs/2510.24826)
*Mingyu Huang,Shasha Zhou,Ke Li*

Main category: cs.LG

TL;DR: GraphFLA是一个Python框架，用于从突变数据构建和分析多样性模态的适应度景观，有助于解释和比较适应度预测模型的表现


<details>
  <summary>Details</summary>
Motivation: 目前的基准评估模型缺乏关于适应度景观地形的信息，这阻碍了对模型性能的解释和比较。GraphFLA可以解决这个问题

Method: GraphFLA能够构建和分析来自突变数据的适应度景观，计算20个生物相关的特性来描述景观地形

Result: 应用GraphFLA到超过5300个来自ProteinGym，RNAGym和CIS-BP的景观中，显示出其解释和比较功能预测模型性能的能力，并提供155个包含超过220万个序列的组合完整经验适应度景观

Conclusion: GraphFLA能够有效地解释和比较适应度预测模型的表现，提供了一个有价值的工具来理解和解析生物序列-适应度景观

Abstract: Machine learning models increasingly map biological sequence-fitness
landscapes to predict mutational effects. Effective evaluation of these models
requires benchmarks curated from empirical data. Despite their impressive
scales, existing benchmarks lack topographical information regarding the
underlying fitness landscapes, which hampers interpretation and comparison of
model performance beyond averaged scores. Here, we introduce GraphFLA, a Python
framework that constructs and analyzes fitness landscapes from mutagensis data
in diverse modalities (e.g., DNA, RNA, protein, and beyond) with up to millions
of mutants. GraphFLA calculates 20 biologically relevant features that
characterize 4 fundamental aspects of landscape topography. By applying
GraphFLA to over 5,300 landscapes from ProteinGym, RNAGym, and CIS-BP, we
demonstrate its utility in interpreting and comparing the performance of dozens
of fitness prediction models, highlighting factors influencing model accuracy
and respective advantages of different models. In addition, we release 155
combinatorially complete empirical fitness landscapes, encompassing over 2.2
million sequences across various modalities. All the codes and datasets are
available at https://github.com/COLA-Laboratory/GraphFLA.

</details>


### [71] [Aggregation Hides Out-of-Distribution Generalization Failures from Spurious Correlations](https://arxiv.org/abs/2510.24884)
*Olawale Salaudeen,Haoran Zhang,Kumail Alhamoud,Sara Beery,Marzyeh Ghassemi*

Main category: cs.LG

TL;DR: 这篇文章发现经常被使用的OOD基准测试中，ID和OOD准确性之间的正相关关系可能是由于聚合了异质的OOD样本，而实际上在分层的OOD子集中这种正相关关系可能并不成立。使用一种名为OODSelect的方法，作者发现了多个这样的子集，其中ID准确性更高的样本在OOD任务上表现更差。这表明整体性度量可能会掩盖OOD鲁棒性的关键失败模式。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是挑战和重新评价在OOD基准测试中普遍存在的ID与OOD准确性正相关模式的真实性。作者希望通过分析来揭露这种正相关关系背后的潜在原因，进而揭示OOD鲁棒性的实际挑战。

Method: 作者使用了一种名为OODSelect的简单梯度方法来识别语义一致的OOD子集，在这些子集中，ID准确性和OOD准确性之间的正相关模式不再成立。通过这种方式，作者展示了在许多广泛应用的分布移动基准测试中，存在大量子集，其中更高的ID准确性反而导致了更低的OOD准确性预测。

Result: 研究发现，在多个广泛使用的分布移动基准测试中，使用OODSelect方法识别出的OID子集中，ID准确性与OOD准确性之间经常展现出相反的关系，即ID准确性更高的样本在OOD任务上表现更差。这意味着系统的整体性度量可能遮蔽了OOD鲁棒性的关键失败模式和挑战。

Conclusion: 本文的结论是ID和OOD准确性之间的正相关关系可能是由于将不相关的OOD样本聚合在一起所导致的误解。通过对OOD基准测试中的特定子集进行细致分析，作者揭示了OOD鲁棒性的实际挑战，并且提供了更细致的度量方法，有助于进一步的研究。

Abstract: Benchmarks for out-of-distribution (OOD) generalization frequently show a
strong positive correlation between in-distribution (ID) and OOD accuracy
across models, termed "accuracy-on-the-line." This pattern is often taken to
imply that spurious correlations - correlations that improve ID but reduce OOD
performance - are rare in practice. We find that this positive correlation is
often an artifact of aggregating heterogeneous OOD examples. Using a simple
gradient-based method, OODSelect, we identify semantically coherent OOD subsets
where accuracy on the line does not hold. Across widely used distribution shift
benchmarks, the OODSelect uncovers subsets, sometimes over half of the standard
OOD set, where higher ID accuracy predicts lower OOD accuracy. Our findings
indicate that aggregate metrics can obscure important failure modes of OOD
robustness. We release code and the identified subsets to facilitate further
research.

</details>


### [72] [Can Aha Moments Be Fake? Identifying True and Decorative Thinking Steps in Chain-of-Thought](https://arxiv.org/abs/2510.24941)
*Jiachen Zhao,Yiyou Sun,Weiyan Shi,Dawn Song*

Main category: cs.LG

TL;DR: 近期的大规模语言模型虽然可以生成复杂的推理步骤，但在其最终预测中，这些步骤的真实因果影响有限。研究团队提出了True Thinking Score (TTS) 来衡量每个推理步骤对模型最终预测的影响，发现只有很少一部分的推理步骤对模型的最终输出具有显著影响。此外，通过辨识出的TrueThinking方向，团队能够调整模型在生成最终结果时对特定推理步骤的关注度。这项工作揭示了LLM的推理步骤更多地只是外表上的推理，并未真正进行内部的推理，这削弱了LLM的推理效率和推理链的信任度。


<details>
  <summary>Details</summary>
Motivation: 此研究旨在通过引入True Thinking Score (TTS) 来更准确地衡量LLM推理步骤的真实因果影响，以此来增强我们对于LLM内部思考过程的理解，并解决现有研究常用方法存在的一些缺陷，如过度信任LLM生成的表面推理过程。

Method: 研究团队首先提出了True Thinking Score (TTS)，用于量化每个推理步骤对LLM输出的因果影响；之后，通过分析TrueThinking方向在LLM潜在空间中的分布，团队实现了对模型内部特定推理步骤的关注调整；最后，研究团队展示了通过调节模型内部的这些特定步骤，可以改变模型最终输出的结果，这表明问题的潜在解不一定反映在模型生成的答案中。

Result: 研究发现，在Qwen-2.5模型生成的答案中，仅有大约2.3%的推理步骤具有显著的因果影响；而且，即使是在所谓的自我验证步骤中，LLM也未必进行了实际的内部验证，进一步证实了LLM自动生成的推理步骤更多地只是表面现象的一部分，实际的因果影响较小。

Conclusion: 研究揭示了LLM生成的推理步骤很大程度上只是提供一个问题解决的过程外观，其真实因果影响相对有限。这不仅影响了模型推理过程的效率，而且还降低了生成推理链的信任度。这项工作对于重新审视和理解大规模语言模型的工作原理十分有价值。

Abstract: Recent large language models (LLMs) can generate long Chain-of-Thought (CoT)
at test time, enabling them to solve complex tasks. These reasoning steps in
CoT are often assumed as a faithful reflection of the model's internal thinking
process, and used to monitor unsafe intentions. However, we find many reasoning
steps don't truly contribute to LLMs' prediction. We measure the step-wise
causal influence of each reasoning step on the model's final prediction with a
proposed True Thinking Score (TTS). We reveal that LLMs often interleave
between true-thinking steps (which are genuinely used to produce the final
output) and decorative-thinking steps (which only give the appearance of
reasoning but have minimal causal impact). Notably, only a small subset of the
total reasoning steps have a high TTS that causally drive the model's
prediction: e.g., for the AIME dataset, only an average of 2.3% of reasoning
steps in CoT have a TTS >= 0.7 (range: 0-1) under the Qwen-2.5 model.
Furthermore, we identify a TrueThinking direction in the latent space of LLMs.
By steering along or against this direction, we can force the model to perform
or disregard certain CoT steps when computing the final result. Finally, we
highlight that self-verification steps in CoT (i.e., aha moments) can also be
decorative, where LLMs do not truly verify their solution. Steering along the
TrueThinking direction can force internal reasoning over these steps, resulting
in a change in the final results. Overall, our work reveals that LLMs often
verbalize reasoning steps without actually performing them internally, which
undermines both the efficiency of LLM reasoning and the trustworthiness of CoT.

</details>


### [73] [Finding Culture-Sensitive Neurons in Vision-Language Models](https://arxiv.org/abs/2510.24942)
*Xiutian Zhao,Rochelle Choenni,Rohit Saxena,Ivan Titov*

Main category: cs.LG

TL;DR: 研究探讨了视觉-语言模型在处理文化相关输入时的表现，并通过识别和分析文化敏感神经元来研究模型内部的多模态表征组织结构。发现这些神经元在特定的解码层中聚集，并且与文化多样性视觉问答任务紧密相关。此外，提出了一种新的Margin-based选择器——对比激活选择（CAS），其在识别文化敏感神经元方面优于现有的概率和熵基于的方法。


<details>
  <summary>Details</summary>
Motivation: 为了理解视觉-语言模型在处理文化相关信息时的表现，研究识别了文化敏感神经元的存在，并对其在文化多样性的视觉问答任务中的重要性进行了考察。

Method: 通过CVQA基准测试，研究识别了文化选择性的神经元，并通过不同的识别方法来去激活这些被标记的神经元进行因果性测试。提出了一种新的Margin-based选择器——对比激活选择（CAS），并探讨了文化敏感神经元在模型内部的多模态表征中的位置和作用。

Result: 实验结果表明，文化敏感神经元的去活化在文化相关问答任务中造成了较大的性能损失，而在其他任务中的影响较小。此外，与现有的概率和熵基于的方法相比，提出了新的Margin-based选择器——对比激活选择（CAS）在识别文化敏感神经元方面表现更好。

Conclusion: 研究发现了文化敏感神经元的存在及其在模型中的作用，提出了有效的识别方法CAS，并揭示了模型内部多模态表征的组织结构。

Abstract: Despite their impressive performance, vision-language models (VLMs) still
struggle on culturally situated inputs. To understand how VLMs process
culturally grounded information, we study the presence of culture-sensitive
neurons, i.e. neurons whose activations show preferential sensitivity to inputs
associated with particular cultural contexts. We examine whether such neurons
are important for culturally diverse visual question answering and where they
are located. Using the CVQA benchmark, we identify neurons of culture
selectivity and perform causal tests by deactivating the neurons flagged by
different identification methods. Experiments on three VLMs across 25 cultural
groups demonstrate the existence of neurons whose ablation disproportionately
harms performance on questions about the corresponding cultures, while having
minimal effects on others. Moreover, we propose a new margin-based selector -
Contrastive Activation Selection (CAS), and show that it outperforms existing
probability- and entropy-based methods in identifying culture-sensitive
neurons. Finally, our layer-wise analyses reveals that such neurons tend to
cluster in certain decoder layers. Overall, our findings shed new light on the
internal organization of multimodal representations.

</details>


### [74] [Sequences of Logits Reveal the Low Rank Structure of Language Models](https://arxiv.org/abs/2510.24966)
*Noah Golowich,Allen Liu,Abhishek Shetty*

Main category: cs.LG

TL;DR: 本文介绍了一种研究大型语言模型内在低维结构的方法，通过将语言模型视为序列概率模型来探讨其低秩结构，并展示了如何通过这种低秩结构进行生成任务。同时，理论分析也证明了这种抽象方法的表示能力和可学习性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型的内在低维结构是一个重要的问题，本文旨在通过一个新的模型无关的角度，即把语言模型视为序列概率模型，来探讨它们的低维结构。这可以帮助我们更好地理解语言模型的工作机制，并应用于语言生成任务。

Method: 本文首先通过实验表明，许多现代语言模型在不同提示词和响应词构成的矩阵中表现出低秩结构。随后，证明了这种结构可以用于生成任务，比如使用模型在无关或没有意义的提示词上的输出的线性组合来生成对应目标提示词的响应。理论分析部分则证明了这种低维结构的抽象表示具有强大的表示能力和学习保障。

Result: 研究表明，现代语言模型在很大程度上具有低秩结构，可以通过构建模型输出的线性组合来生成目标响应。理论分析进一步验证了这种模型抽象的表示能力和学习能力。

Conclusion: 这项研究展示了利用低秩结构学习语言模型的能力，不仅有可能推进我们对模型内在机制的理解，还可以应用于提升语言生成任务的效率和效果。

Abstract: A major problem in the study of large language models is to understand their
inherent low-dimensional structure. We introduce an approach to study the
low-dimensional structure of language models at a model-agnostic level: as
sequential probabilistic models. We first empirically demonstrate that a wide
range of modern language models exhibit low-rank structure: in particular,
matrices built from the model's logits for varying sets of prompts and
responses have low approximate rank. We then show that this low-rank structure
can be leveraged for generation -- in particular, we can generate a response to
a target prompt using a linear combination of the model's outputs on unrelated,
or even nonsensical prompts.
  On the theoretical front, we observe that studying the approximate rank of
language models in the sense discussed above yields a simple universal
abstraction whose theoretical predictions parallel our experiments. We then
analyze the representation power of the abstraction and give provable learning
guarantees.

</details>


### [75] [Strategic inputs: feature selection from game-theoretic perspective](https://arxiv.org/abs/2510.24982)
*Chi Zhao,Jing Liu,Elena Parilina*

Main category: cs.LG

TL;DR: 本文提出了一种基于博弈论的端到端特征选择框架，用于处理表格数据，通过将特征视作玩家并评估其协同交互和边际贡献来确定其重要性。此框架包括样本选择、基于博弈论的特征重要性评估、冗余特征消除和优化模型训练四个核心组件。实验结果显示，该方法在保持预测性能的同时，显著减少了计算量，为大规模机器学习的计算挑战提供了一个有效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 由于数据量呈指数级增长，机器学习模型训练的计算成本也随之增加。然而，许多特征对模型性能几乎没有贡献，却消耗了大量的计算资源。本文提出了一种基于博弈论的特征选择框架，以解决这一问题，提高计算效率。

Method: 该方法通过将特征视为博弈中的玩家，利用协同博弈的概念来评估每个特征的边际贡献和重要性。其核心组件包括样本选择，基于博弈论的特征重要性评估，冗余特征的去除以及优化后的模型训练。

Result: 实验结果表明，该方法在保持预测性能的同时，显著地减少了计算负担，证明了该方法的有效性和优越性。

Conclusion: 结论是该方法提供了一种能够有效解决大规模机器学习计算挑战的解决方案，同时保证模型性能不会受到显著影响。

Abstract: The exponential growth of data volumes has led to escalating computational
costs in machine learning model training. However, many features fail to
contribute positively to model performance while consuming substantial
computational resources. This paper presents an end-to-end feature selection
framework for tabular data based on game theory. We formulate feature selection
procedure based on a cooperative game where features are modeled as players,
and their importance is determined through the evaluation of synergistic
interactions and marginal contributions. The proposed framework comprises four
core components: sample selection, game-theoretic feature importance
evaluation, redundant feature elimination, and optimized model training.
Experimental results demonstrate that the proposed method achieves substantial
computation reduction while preserving predictive performance, thereby offering
an efficient solution of the computational challenges of large-scale machine
learning. The source code is available at
https://github.com/vectorsss/strategy_inputs.

</details>


### [76] [LRT-Diffusion: Calibrated Risk-Aware Guidance for Diffusion Policies](https://arxiv.org/abs/2510.24983)
*Ximan Sun,Xiang Cheng*

Main category: cs.LG

TL;DR: LRT-Diffusion 是一种量化风险意识的采样规则，应用于离线强化学习中的扩散策略，通过统计方式调整采样行为，从而提高回报并优化离群值风险的平衡。与传统的Q指导方法不同，LRT-Diffusion 不改变训练模型结构，仅在推断阶段加入智能的风险调整机制，使策略更加稳健。实验显示，在多个 D4RL MuJoCo 任务中，LRT-Diffusion 能够提升回报，同时满足用户指定的风险水平，并且理论上具有良好的稳定性保障和风险控制能力。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散策略通常使用缺乏统计风险认知的启发式采样规则。作者希望通过引入 LRT-Diffusion 方法，提供一种可解释、能够用户定义风险水平的采样规则，以改善离线强化学习中策略的稳健性和效率。

Method: LRT-Diffusion 通过在每个去噪步骤引入序贯假设检验机制，以无条件先验与状态条件策略头为假设，在一个固定阈值下积累对数似然比。通过逻辑控制器门控条件均值，该方法将引导从固定的推力转变为基于证据的调整，同时保留了训练过程的简洁性。最重要的是，该方法允许与Q梯度自然组合，以实现从纯粹利用至保守策略的连续性控制。通过标准化状态和动作空间，该方法能够有效调整政策在决策中的风险评分，并汇报离群值风险指标以及返回价值.

Result: 实验结果表明 LRT-Diffusion 在多个 D4RL MuJoCo 任务中，相较于传统的 Q 引导基线，显著提高了回报与离群值风险的平衡率，满足用户指定的阿尔法水平。并从理论上证明了该方法的高性价比和稳定性保障。

Conclusion: LRT-Diffusion 是一种可以显著提高离线强化学习中扩散策略的稳健性与性能的方法。它通过统计推断提供了一个风险控制的渠道，能够使离线RL中的策略拥有可解释、可调的风险水平。

Abstract: Diffusion policies are competitive for offline reinforcement learning (RL)
but are typically guided at sampling time by heuristics that lack a statistical
notion of risk. We introduce LRT-Diffusion, a risk-aware sampling rule that
treats each denoising step as a sequential hypothesis test between the
unconditional prior and the state-conditional policy head. Concretely, we
accumulate a log-likelihood ratio and gate the conditional mean with a logistic
controller whose threshold tau is calibrated once under H0 to meet a
user-specified Type-I level alpha. This turns guidance from a fixed push into
an evidence-driven adjustment with a user-interpretable risk budget.
Importantly, we deliberately leave training vanilla (two heads with standard
epsilon-prediction) under the structure of DDPM. LRT guidance composes
naturally with Q-gradients: critic-gradient updates can be taken at the
unconditional mean, at the LRT-gated mean, or a blend, exposing a continuum
from exploitation to conservatism. We standardize states and actions
consistently at train and test time and report a state-conditional
out-of-distribution (OOD) metric alongside return. On D4RL MuJoCo tasks,
LRT-Diffusion improves the return-OOD trade-off over strong Q-guided baselines
in our implementation while honoring the desired alpha. Theoretically, we
establish level-alpha calibration, concise stability bounds, and a return
comparison showing when LRT surpasses Q-guidance-especially when off-support
errors dominate. Overall, LRT-Diffusion is a drop-in, inference-time method
that adds principled, calibrated risk control to diffusion policies for offline
RL.

</details>


### [77] [Subgraph Federated Learning via Spectral Methods](https://arxiv.org/abs/2510.25657)
*Javad Aliakbari,Johan Östman,Ashkan Panahi,Alexandre Graell i Amat*

Main category: cs.LG

TL;DR: 提出了一种名为FedLap的新框架，用于处理带有图结构数据的联邦学习问题，以解决隐私和可扩展性挑战。通过谱域中的拉普拉斯平滑捕捉节点之间的依赖关系，同时确保隐私和可扩展性。在基准数据集上的大量实验表明，FedLap在功能上与现有技术具有竞争力或更胜一筹。


<details>
  <summary>Details</summary>
Motivation: 针对当前联邦学习方案在处理图结构数据时遇到的隐私和可扩展性挑战，该论文旨在解决这些问题并提出一种新的解决方案FedLap，该方案在确保隐私的同时提升了功能效用。

Method: 通过在谱域中使用拉普拉斯平滑来捕捉全局结构信息，从而有效解决互联子图之间的依赖性问题，同时保证隐私性和计算效率。FedLap通过这种方法在不交换敏感节点嵌入的情况下完成任务，确保了隐私性和计算效率。

Result: 实验表明，FedLap在功能效用上与现有技术具有竞争力或更胜一筹，并提供了理论上的隐私保证。FedLap是第一个具有强隐私保护的子图联邦学习方案。

Conclusion: FedLap提供了一种在联邦学习中处理图结构数据的新方法，有效地解决了隐私和可扩展性问题。

Abstract: We consider the problem of federated learning (FL) with graph-structured data
distributed across multiple clients. In particular, we address the prevalent
scenario of interconnected subgraphs, where interconnections between clients
significantly influence the learning process. Existing approaches suffer from
critical limitations, either requiring the exchange of sensitive node
embeddings, thereby posing privacy risks, or relying on
computationally-intensive steps, which hinders scalability. To tackle these
challenges, we propose FedLap, a novel framework that leverages global
structure information via Laplacian smoothing in the spectral domain to
effectively capture inter-node dependencies while ensuring privacy and
scalability. We provide a formal analysis of the privacy of FedLap,
demonstrating that it preserves privacy. Notably, FedLap is the first subgraph
FL scheme with strong privacy guarantees. Extensive experiments on benchmark
datasets demonstrate that FedLap achieves competitive or superior utility
compared to existing techniques.

</details>


### [78] [What Really Matters in Matrix-Whitening Optimizers?](https://arxiv.org/abs/2510.25000)
*Kevin Frans,Pieter Abbeel,Sergey Levine*

Main category: cs.LG

TL;DR: 本文分析了多种矩阵白化优化器，并发现矩阵白化方法比元素级优化器（如Adam）表现更优。虽然矩阵白化与谱下降有关，但这种性能提升不仅仅局限于精确的谱归一化，而是与矩阵白化中的方差适应成分有关。实验表明，具有方差适应的优化器版本表现优于单纯谱下降的方法。此外，低秩方差估计策略可以有效降低内存成本而不会带来性能损失。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解为何矩阵白化方法在优化过程中表现出优越性，尤其是当这些方法与元素级优化器对比时。本文还探讨了准确的谱归一化与矩阵白化其他组成部分（如方差适应）之间的性能关系。

Method: 试验性地拆解了不同的优化策略，对比了矩阵白化方法与元素级方法（如Adam）在不同的超参数设置下的性能表现，并特别考察了方差适应对性能的影响。此外，还研究了不同方差估计方法的内存效率和性能损失。

Result: 研究数据显示，矩阵白化中的方差适应成分是优化性能提升的关键因素，而不仅仅是精确的谱归一化。实验进一步表明，低秩方差估计能有效减少内存需求且无性能损失。

Conclusion: 矩阵白化中的方差适应方法在优化中展现出卓越的性能，尤其是与元素级方法相比。同时，通过采用低秩方差估计策略，可以降低内存成本而不损失性能。

Abstract: A range of recent optimizers have emerged that approximate the same
"matrix-whitening" transformation in various ways. In this work, we
systematically deconstruct such optimizers, aiming to disentangle the key
components that explain performance. Across tuned hyperparameters across the
board, all flavors of matrix-whitening methods reliably outperform elementwise
counterparts, such as Adam. Matrix-whitening is often related to spectral
descent -- however, experiments reveal that performance gains are *not
explained solely by accurate spectral normalization* -- particularly, SOAP
displays the largest per-step gain, even though Muon more accurately descends
along the steepest spectral descent direction. Instead, we argue that
matrix-whitening serves two purposes, and the variance adaptation component of
matrix-whitening is the overlooked ingredient explaining this performance gap.
Experiments show that variance-adapted versions of optimizers consistently
outperform their sign-descent counterparts, including an adaptive version of
Muon. We further ablate variance adaptation strategies, finding that while
lookahead style approximations are not as effective, low-rank variance
estimators can effectively reduce memory costs without a performance loss.

</details>


### [79] [Machine Learning based Analysis for Radiomics Features Robustness in Real-World Deployment Scenarios](https://arxiv.org/abs/2510.25026)
*Sarmad Ahmad Khan,Simon Bernatz,Zahra Moslehi,Florian Buettner*

Main category: cs.LG

TL;DR: 基于放射组学的机器学习模型在不同MRI序列下的分布变化中表现脆弱，但通过使用协议不变的特征训练模型可以提高其鲁棒性。该研究发现，在分布变化下，使用8个一致稳健的特征训练的模型F1得分维持在0.85以上，而使用所有特征的模型在协议变化下性能下降了40%。数据增强技术有助于提高不确定性估计的质量，并减少了预期校准误差（ECE）35%。研究还表明，选择协议相关的特征和使用受控果形研究可以有效预测模型在分布变化下的行为，为开发稳健的放射组学模型提供了框架。


<details>
  <summary>Details</summary>
Motivation: 在临床决策支持中，基于放射组学的机器学习模型表现出潜力但对成像协议、定位和分割的变化非常敏感。研究者希望通过系统地研究其在不同MRI序列分布变化下的表现来提高这些模型的鲁棒性，以应对不同的协议差异和分割策略所带来的影响。

Method: 采用含16个水果的模型在外域和内域条件下评估了协议差异和分割差异对模型预测准确性和不确定性影响。通过XGBoost分类器测试使用各种特征组合时模型的性能。进一步测试了数据增强、样本扩增等技术对模型不确定性估计的影响。评估了温度缩放对模型校准的影响，并使用两个不同协议的受控果素研究来预测模型在分布变化下的行为。

Result: 结果表明，协议不变特征训练的模型可以在分布变化下，维持在0.85以上的F1得分，而使用全部特征的模型则在分布变化下性能下降了40%。数据增强技术提高了不确定性估计的准确性，减少了35％的预期校准误差。且温度缩放仅略微提高了模型的校准度，进一步证实了XGBoost算法的固有可靠性。

Conclusion: 通过选择与协议一致的稳健特征，并使用受控果状模型研究，可以有效预测模型在不同MRI协议及分割策略下表现，并为开发抗协议变化的放射组学模型提供坚实的基础。

Abstract: Radiomics-based machine learning models show promise for clinical decision
support but are vulnerable to distribution shifts caused by variations in
imaging protocols, positioning, and segmentation. This study systematically
investigates the robustness of radiomics-based machine learning models under
distribution shifts across five MRI sequences. We evaluated how different
acquisition protocols and segmentation strategies affect model reliability in
terms of predictive power and uncertainty-awareness. Using a phantom of 16
fruits, we evaluated distribution shifts through: (1) protocol variations
across T2-HASTE, T2-TSE, T2-MAP, T1-TSE, and T2-FLAIR sequences; (2)
segmentation variations (full, partial, rotated); and (3) inter-observer
variability. We trained XGBoost classifiers on 8 consistent robust features
versus sequence-specific features, testing model performance under in-domain
and out-of-domain conditions. Results demonstrate that models trained on
protocol-invariant features maintain F1-scores >0.85 across distribution
shifts, while models using all features showed 40% performance degradation
under protocol changes. Dataset augmentation substantially improved the quality
of uncertainty estimates and reduced the expected calibration error (ECE) by
35% without sacrificing accuracy. Temperature scaling provided minimal
calibration benefits, confirming XGBoost's inherent reliability. Our findings
reveal that protocol-aware feature selection and controlled phantom studies
effectively predict model behavior under distribution shifts, providing a
framework for developing robust radiomics models resilient to real-world
protocol variations.

</details>


### [80] [Graph Distance Based on Cause-Effect Estimands with Latents](https://arxiv.org/abs/2510.25037)
*Zhufeng Li,Niki Kilbertus*

Main category: cs.LG

TL;DR: 本文提出了一种新方法来度量有向无环混合图（ADMGs）之间的距离，该方法适用于存在未观察到的混淆变量的因果效应估计任务。


<details>
  <summary>Details</summary>
Motivation: 现有技术难以准确评估发现的因果图，特别是在存在潜在混淆变量的情况下。作者希望通过提出一种新的图距离度量来解决这个问题，从而评估因果发现方法的有效性。

Method: 方法基于因果效应估计任务，在未观察到混淆变量的情况下，使用固定方法和符号验证器量化图差异如何影响因果效应估计量，提出了一个新的图距离度量。

Result: 分析了该度量方法在不同图扰动情况下的行为，并将其与现有距离度量进行了比较，结果表明新方法能够更好地度量因果图间的相似性。

Conclusion: 新提出的图距离度量有助于更准确地评估因果发现方法的效果，特别是在存在潜在混淆变量的情况下。

Abstract: Causal discovery aims to recover graphs that represent causal relations among
given variables from observations, and new methods are constantly being
proposed. Increasingly, the community raises questions about how much progress
is made, because properly evaluating discovered graphs remains notoriously
difficult, particularly under latent confounding. We propose a graph distance
measure for acyclic directed mixed graphs (ADMGs) based on the downstream task
of cause-effect estimation under unobserved confounding. Our approach uses
identification via fixing and a symbolic verifier to quantify how graph
differences distort cause-effect estimands for different treatment-outcome
pairs. We analyze the behavior of the measure under different graph
perturbations and compare it against existing distance metrics.

</details>


### [81] [Dynamically Weighted Momentum with Adaptive Step Sizes for Efficient Deep Network Training](https://arxiv.org/abs/2510.25042)
*Zhifeng Wang,Longlong Li,Chunyan Zeng*

Main category: cs.LG

TL;DR: 提出了一种新的优化算法DWMGrad，该算法结合了动态引导机制，依据历史数据动态更新动量和学习率，提高了对复杂模型和非凸优化问题的处理能力。实验表明，该算法在多种场景下具有更快的收敛速度和更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的优化算法如SGD和Adam在处理学习效率波动、复杂模型需求和非凸优化问题时存在局限性。这些局限性主要表现在处理复杂数据结构和模型时遇到困难，例如难以选择适当的学习率、避免局部最优和处理高维空间等问题。因此，需要一个能适应这些挑战的新算法。

Method: 提出了一种基于传统方法、利用历史数据动态更新动量和学习率的新优化算法DWMGrad。这种方法使优化器能够灵活地调整对历史数据的依赖程度，从而提高了适应不同训练场景的能力。

Result: 经广泛的实验验证，DWMGrad算法在多种场景下实现了更快的收敛速度和更高的准确性。

Conclusion: 通过引入动态更新动量和学习率的机制，DWMGrad算法有效提高了优化器对复杂模型和非凸优化问题的处理能力，并在实验中显示了优越的性能。

Abstract: Within the current sphere of deep learning research, despite the extensive
application of optimization algorithms such as Stochastic Gradient Descent
(SGD) and Adaptive Moment Estimation (Adam), there remains a pronounced
inadequacy in their capability to address fluctuations in learning efficiency,
meet the demands of complex models, and tackle non-convex optimization issues.
These challenges primarily arise from the algorithms' limitations in handling
complex data structures and models, for instance, difficulties in selecting an
appropriate learning rate, avoiding local optima, and navigating through
high-dimensional spaces. To address these issues, this paper introduces a novel
optimization algorithm named DWMGrad. This algorithm, building on the
foundations of traditional methods, incorporates a dynamic guidance mechanism
reliant on historical data to dynamically update momentum and learning rates.
This allows the optimizer to flexibly adjust its reliance on historical
information, adapting to various training scenarios. This strategy not only
enables the optimizer to better adapt to changing environments and task
complexities but also, as validated through extensive experimentation,
demonstrates DWMGrad's ability to achieve faster convergence rates and higher
accuracies under a multitude of scenarios.

</details>


### [82] [Continual Low-Rank Adapters for LLM-based Generative Recommender Systems](https://arxiv.org/abs/2510.25093)
*Hyunsik Yoo,Ting-Wei Li,SeongKu Kang,Zhining Liu,Charlie Xu,Qilin Qi,Hanghang Tong*

Main category: cs.LG

TL;DR: 提出了一种新的方法PESO，它通过引入邻近正则化器来改进LoRA在推荐系统中的连续学习性能，使模型能够更好地平衡适应性和保持能力，从而更好地捕捉用户最近的行为。PESO在实验中表现优于现有的LoRA连续学习方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推荐系统中遇到的挑战在于它们在用户的偏好，物品以及用户兴趣随时间变化时难以进行连续学习。现有的基于LoRA的连续学习方法主要关注于保持之前任务的性能，但忽视了推荐系统的独特性：目标不是预测过去的偏好，而是随着用户兴趣的变化进行调整，过时的偏好可能会损害系统的性能。因此，本文提出了一种新的方法来解决这个问题。

Method: PESO通过引入邻近正则化器来锚定当前的adapter到其最近的冻结状态，这使得模型能够灵活地平衡适应性和保真性，更好地捕捉用户的最近行为。这种邻近的设计在LoRA子空间中提供了基于数据和方向的指导。

Result: 理论上分析了PESO的设计如何提供在LoRA子空间中的数据感知和方向感知的指导，实验结果表明PESO在连续学习推荐系统的性能上优于现有的基于LoRA的方法。

Conclusion: PESO通过改进LoRA的方法来更好地处理用户兴趣的变化，提供了一个更有效的连续学习解决方案。

Abstract: While large language models (LLMs) achieve strong performance in
recommendation, they face challenges in continual learning as users, items, and
user preferences evolve over time. Existing LoRA-based continual methods
primarily focus on preserving performance on previous tasks, but this overlooks
the unique nature of recommendation: the goal is not to predict past
preferences, and outdated preferences can even harm performance when current
interests shift significantly. To address this, we propose PESO (Proximally
rEgularized Single evolving lOra, a continual adaptation method for LoRA in
recommendation. PESO introduces a proximal regularizer that anchors the current
adapter to its most recent frozen state, enabling the model to flexibly balance
adaptation and preservation, and to better capture recent user behaviors.
Theoretically, we show that this proximal design provides data-aware,
direction-wise guidance in the LoRA subspace. Empirically, PESO consistently
outperforms existing LoRA-based continual learning methods.

</details>


### [83] [Shift is Good: Mismatched Data Mixing Improves Test Performance](https://arxiv.org/abs/2510.25108)
*Marko Medvedev,Kaifeng Lyu,Zhiyuan Li,Nathan Srebro*

Main category: cs.LG

TL;DR: 研究探讨了在混合分布中训练和测试比例不同时，分布偏移在某些情况下可以是积极的，能提升测试性能。即使成分间无关且无转移，实验比例的不匹配也能带来有利的影响，并确定了这种情况下最优的训练比例。进一步地，该分析适用于包含不同组件“技能”分布的组合场景中


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，数据分布的偏移是一个常见问题，特别是在训练集和测试集来自不同分布时。若能理解并在某种程度上利用这种分布偏移，能使模型更具鲁棒性和更好的泛化能力

Method: 通过理论分析，研究所探讨的分布偏移情况下的最优训练比例，使用不同的混合比例来模拟分布的不匹配，并研究在这些场景下的模型表现

Result: 在很多情况下，当训练和测试分布不匹配时，分布偏移是有益的，测试表现可能会提升。甚至当成分无关且无任何成分间的转移时，也能观察到性能的提升。模型还能在单一类型的技能分布与混合的技能分布之间进行训练和测试

Conclusion: 通过理解分布偏移，可以确定在哪些场景下去匹配和不匹配训练和测试分布是有利的。这能帮助创建更强大、更鲁棒的模型，适用于一系列不同分布的数据

Abstract: We consider training and testing on mixture distributions with different
training and test proportions. We show that in many settings, and in some sense
generically, distribution shift can be beneficial, and test performance can
improve due to mismatched training proportions, even if the components are
unrelated and with no transfer between components. In a variety of scenarios,
we identify the optimal training proportions and the extent to which such
distribution shift can be beneficial. We show how the same analysis applies
also to a compositional setting with differing distribution of component
"skills'' at training and test.

</details>


### [84] [Machine Learning and CPU (Central Processing Unit) Scheduling Co-Optimization over a Network of Computing Centers](https://arxiv.org/abs/2510.25176)
*Mohammadreza Doostmohammadian,Zulfiya R. Gabidullina,Hamid R. Rabiee*

Main category: cs.LG

TL;DR: 论文提出了一种新的计算资源分配算法，用于分布式机器学习，该算法在保证共识收敛的同时，提高了计算资源的使用效率，使得成本优化差距提高了超过50%。 


<details>
  <summary>Details</summary>
Motivation: 随着人工智能研究的快速发展，对快速、计算效率高和可扩展的解决方案的需求增加。因此，该论文旨在优化分布式机器学习和优化中的计算资源分配问题。 

Method: 通过同时优化数据处理和计算资源的分配，将问题作为协同优化设置解决。算法在所有迭代中都可行，满足计算资源需求平衡约束。此外，该方案允许在信息共享通道中使用对数量化处理数据。 

Result: 论文使用扰动理论、李亚普诺夫稳定性分析和特征谱分析证明了算法向最优情况收敛。与现有的CPU调度解决方案相比，所提出的算法提高了50％以上的成本最优性差距。 

Conclusion: 所提出的算法在分布式机器学习中展示了有效的计算资源优化，显著提高了成本优化性能。

Abstract: In the rapidly evolving research on artificial intelligence (AI) the demand
for fast, computationally efficient, and scalable solutions has increased in
recent years. The problem of optimizing the computing resources for distributed
machine learning (ML) and optimization is considered in this paper. Given a set
of data distributed over a network of computing-nodes/servers, the idea is to
optimally assign the CPU (central processing unit) usage while simultaneously
training each computing node locally via its own share of data. This formulates
the problem as a co-optimization setup to (i) optimize the data processing and
(ii) optimally allocate the computing resources. The information-sharing
network among the nodes might be time-varying, but with balanced weights to
ensure consensus-type convergence of the algorithm. The algorithm is all-time
feasible, which implies that the computing resource-demand balance constraint
holds at all iterations of the proposed solution. Moreover, the solution allows
addressing possible log-scale quantization over the information-sharing
channels to exchange log-quantized data. For some example applications,
distributed support-vector-machine (SVM) and regression are considered as the
ML training models. Results from perturbation theory, along with Lyapunov
stability and eigen-spectrum analysis, are used to prove the convergence
towards the optimal case. As compared to existing CPU scheduling solutions, the
proposed algorithm improves the cost optimality gap by more than $50\%$.

</details>


### [85] [A Unified Bilevel Model for Adversarial Learning and A Case Study](https://arxiv.org/abs/2510.25121)
*Yutong Zheng,Qingna Li*

Main category: cs.LG

TL;DR: 本文提出了一种针对聚类模型的统一双层模型用于对抗学习，并从数据扰动的角度解释了对抗攻击机制。此外，还分析了衡量对抗攻击效果的δ-测度的合理性。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习模型复杂，对抗攻击机制不清楚，且攻击效果难以衡量。本文旨在通过聚类模型的对抗学习研究明确这一机制并开发有效的评估指标。

Method: 提出了一种包含两层优化问题的双层模型，用于评估和解释聚类模型中的对抗攻击。具体而言，探究了数据扰动对聚类结果的影响，并研究了衡量攻击效果的δ-测度的合理性。

Result: 研究发现，当数据扰动较小时，聚类模型具有鲁棒性；当数据扰动较大时，聚类结果会改变，从而引发攻击。分析表明，δ-测度适合用于聚类模型的对抗学习中衡量攻击效果。

Conclusion: 本文的贡献在于提出了一个新的模型用于评估聚类模型的对抗攻击，并通过δ-测度合理地衡量了攻击效果。

Abstract: Adversarial learning has been attracting more and more attention thanks to
the fast development of machine learning and artificial intelligence. However,
due to the complicated structure of most machine learning models, the mechanism
of adversarial attacks is not well interpreted. How to measure the effect of
attack is still not quite clear. In this paper, we propose a unified bilevel
model for adversarial learning. We further investigate the adversarial attack
in clustering models and interpret it from data perturbation point of view. We
reveal that when the data perturbation is relatively small, the clustering
model is robust, whereas if it is relatively large, the clustering result
changes, which leads to an attack. To measure the effect of attacks for
clustering models, we analyse the well-definedness of the so-called
$\delta$-measure, which can be used in the proposed bilevel model for
adversarial learning of clustering models.

</details>


### [86] [Bridging the Divide: End-to-End Sequence-Graph Learning](https://arxiv.org/abs/2510.25126)
*Yuen Chen,Yulun Wu,Samuel Sharpe,Igor Melnyk,Nam H. Nguyen,Furong Huang,C. Bayan Bruss,Rizal Fathony*

Main category: cs.LG

TL;DR: BRIDGE是一个结合序列编码器和GNN的统一端到端架构，能够在单个目标下联合学习序列和图数据。它在friendship预测和fraud检测任务中均表现优于静态GNNs、时序图方法和序列模型基线。


<details>
  <summary>Details</summary>
Motivation: 现有的序列模建和图模建方法往往忽略另一个模态的数据，而现实世界的数据集往往同时具有序列和关系特性。这两个模态其实是同一数据集中互补的方面，应当联合学习。

Method: BRIDGE架构结合了序列编码器和GNN，并通过添加TOKENXATTN层来实现细粒度的token级消息传递。TOKENXATTN是一个跨注意力层，可以在邻近序列中的事件之间传递信息。

Result: 在friendship预测（Brightkite）和fraud检测（Amazon）任务中，BRIDGE在排名和分类指标上均优于静态GNNs、时序图方法和序列模型基线。展示了联合学习序列和图对于任务表现的优胜性。

Conclusion: BRIDGE展示了联合序列和图学习的潜力，在同时具备序列和关系特性的数据集中可以取得更好的表现。

Abstract: Many real-world datasets are both sequential and relational: each node
carries an event sequence while edges encode interactions. Existing methods in
sequence modeling and graph modeling often neglect one modality or the other.
We argue that sequences and graphs are not separate problems but complementary
facets of the same dataset, and should be learned jointly. We introduce BRIDGE,
a unified end-to-end architecture that couples a sequence encoder with a GNN
under a single objective, allowing gradients to flow across both modules and
learning task-aligned representations. To enable fine-grained token-level
message passing among neighbors, we add TOKENXATTN, a token-level
cross-attention layer that passes messages between events in neighboring
sequences. Across two settings, friendship prediction (Brightkite) and fraud
detection (Amazon), BRIDGE consistently outperforms static GNNs, temporal graph
methods, and sequence-only baselines on ranking and classification metrics.

</details>


### [87] [An Analysis of Causal Effect Estimation using Outcome Invariant Data Augmentation](https://arxiv.org/abs/2510.25128)
*Uzair Akbar,Niki Kilbertus,Hao Shen,Krikamol Muandet,Bo Dai*

Main category: cs.LG

TL;DR: 本文提出了一种利用数据增强（DA）进行因果推断的方法，强调了数据增强不仅仅适用于独立同分布（i.i.d.）假设下，还能帮助减少未观察到的混淆变量造成的偏差，提升干预下的泛化能力。我们引入了类似工具变量（IVL）回归的概念来缓解混杂偏差，并通过理论和实验验证了在适当的情况下，参数化数据增强可以作为IVL回归问题解决，从而在因果推断和泛化任务上表现更好。


<details>
  <summary>Details</summary>
Motivation: 传统上，数据增强主要是被用来推广独立同分布假设下的模型，但它还有潜力被应用在因果推断中，尤其是在缺乏工具变量（IVs）的情境下，因为工具变量可能不是在所有情况下都能容易得到。此研究探讨了数据增强作为干预手段，用以减少隐藏混杂因素带来的偏差，用于改进预测性能和因果效应评估。

Method: 本文提出了一个将数据增强拟合为类似工具变量回归问题的方法，并理论和仿真实验基础上，展现了该方法如何在放松某些工具变量假设的情况下，减轻混杂影响，并在因果估计和泛化任务中实现更优的性能。

Result: 我们通过理论上及现实中简单线性评价证明了可以将参数化数据增强模拟为最差情况下的数据增强，增强因果估计能力，展现出了数据增强在不在工具变量条件下的效果。实验证明，该方法在处理有限样本时也能提升模型性能。

Conclusion: 该文论证了数据增强对于改善因果推断和干预下泛化概括性的潜在价值。通过特定条件下的数据增强作为IVL回归问题的手段，能够有效减轻混杂偏差，提高因果估计的准确性和模型泛化的稳健性。

Abstract: The technique of data augmentation (DA) is often used in machine learning for
regularization purposes to better generalize under i.i.d. settings. In this
work, we present a unifying framework with topics in causal inference to make a
case for the use of DA beyond just the i.i.d. setting, but for generalization
across interventions as well. Specifically, we argue that when the outcome
generating mechanism is invariant to our choice of DA, then such augmentations
can effectively be thought of as interventions on the treatment generating
mechanism itself. This can potentially help to reduce bias in causal effect
estimation arising from hidden confounders. In the presence of such unobserved
confounding we typically make use of instrumental variables (IVs) -- sources of
treatment randomization that are conditionally independent of the outcome.
However, IVs may not be as readily available as DA for many applications, which
is the main motivation behind this work. By appropriately regularizing IV based
estimators, we introduce the concept of IV-like (IVL) regression for mitigating
confounding bias and improving predictive performance across interventions even
when certain IV properties are relaxed. Finally, we cast parameterized DA as an
IVL regression problem and show that when used in composition can simulate a
worst-case application of such DA, further improving performance on causal
estimation and generalization tasks beyond what simple DA may offer. This is
shown both theoretically for the population case and via simulation experiments
for the finite sample case using a simple linear example. We also present real
data experiments to support our case.

</details>


### [88] [Machine Learning Guided Optimal Transmission Switching to Mitigate Wildfire Ignition Risk](https://arxiv.org/abs/2510.25147)
*Weimin Huang,Ryan Piansky,Bistra Dilkina,Daniel K. Molzahn*

Main category: cs.LG

TL;DR: 本文提出了一种机器学习引导的框架，通过利用实例间的共享模式，快速生成高质量的断电决策，优化电力线路的供电状态，以管理野火引发的风险同时减少负载削减。实验显示该方法优于传统的优化方法，所耗时间更短且解决方案质量更高


<details>
  <summary>Details</summary>
Motivation: 为了更有效地解决OPS问题，该研究试图利用机器学习在不同实例间共享的模式，加速问题求解过程，实现快速生成高质量的决策

Method: 开发了一种机器学习引导的框架，扩大了现有机器学习引导的混合整数线性规划求解方法，并结合了关于哪些线路应该保持带电或断电的数量的领域知识

Result: 该方法在模拟测试系统上的表现优于传统的优化方法，更快地生成了高质量的解

Conclusion: 机器学习引导的方法可以更有效地解决OPS问题，更快更准确的提供断电决策，降低了野火的风险

Abstract: To mitigate acute wildfire ignition risks, utilities de-energize power lines
in high-risk areas. The Optimal Power Shutoff (OPS) problem optimizes line
energization statuses to manage wildfire ignition risks through
de-energizations while reducing load shedding. OPS problems are computationally
challenging Mixed-Integer Linear Programs (MILPs) that must be solved rapidly
and frequently in operational settings. For a particular power system, OPS
instances share a common structure with varying parameters related to wildfire
risks, loads, and renewable generation. This motivates the use of Machine
Learning (ML) for solving OPS problems by exploiting shared patterns across
instances. In this paper, we develop an ML-guided framework that quickly
produces high-quality de-energization decisions by extending existing ML-guided
MILP solution methods while integrating domain knowledge on the number of
energized and de-energized lines. Results on a large-scale realistic
California-based synthetic test system show that the proposed ML-guided method
produces high-quality solutions faster than traditional optimization methods.

</details>


### [89] [Selective Learning for Deep Time Series Forecasting](https://arxiv.org/abs/2510.25207)
*Yisong Fu,Zezhi Shao,Chengqing Yu,Yujie Li,Zhulin An,Qi Wang,Yongjun Xu,Fei Wang*

Main category: cs.LG

TL;DR: 本文提出了一种选择性学习策略，用来解决深度学习模型在时间序列预测中因过度拟合而导致的问题，通过引入双重掩码机制（不确定性掩码和异常掩码），帮助模型专注于泛化性强的时间步，从而提升模型的预测性能。实验表明，该策略可以显著提高典型前沿深度模型的预测性能。 


<details>
  <summary>Details</summary>
Motivation: 深度学习在时间序列预测中面临着过度拟合的问题，因为时间序列的固有脆弱性使得模型容易对不确定和异常的时间点过度学习。因此，提出了一种新的选择性学习策略来解决这个问题。 

Method: 选择性学习通过界定一个时间步子集用于MSE损失计算，在优化过程中引导模型聚焦于那些可泛化的时间步而忽略非泛化性的时间步。双重掩码机制包括不确定性掩码和异常掩码。 

Result: 在八组真实世界的数据集上进行的广泛实验表明，选择性学习大幅提升了包括Informer、TimesNet和iTransformer在内的几种典型状态的深度模型的预测性能。具体来说，对于Informer预测性能提高了37.4%，对于TimesNet提升了8.4%，对于iTransformer提升了6.5%。 

Conclusion: 选择性学习策略通过使用双重掩码机制来过滤不确定和异常的时间步，大大提高了深度学习模型的时间序列的预测性能，并在多个实际数据集上证明了其有效性。 

Abstract: Benefiting from high capacity for capturing complex temporal patterns, deep
learning (DL) has significantly advanced time series forecasting (TSF).
However, deep models tend to suffer from severe overfitting due to the inherent
vulnerability of time series to noise and anomalies. The prevailing DL paradigm
uniformly optimizes all timesteps through the MSE loss and learns those
uncertain and anomalous timesteps without difference, ultimately resulting in
overfitting. To address this, we propose a novel selective learning strategy
for deep TSF. Specifically, selective learning screens a subset of the whole
timesteps to calculate the MSE loss in optimization, guiding the model to focus
on generalizable timesteps while disregarding non-generalizable ones. Our
framework introduces a dual-mask mechanism to target timesteps: (1) an
uncertainty mask leveraging residual entropy to filter uncertain timesteps, and
(2) an anomaly mask employing residual lower bound estimation to exclude
anomalous timesteps. Extensive experiments across eight real-world datasets
demonstrate that selective learning can significantly improve the predictive
performance for typical state-of-the-art deep models, including 37.4% MSE
reduction for Informer, 8.4% for TimesNet, and 6.5% for iTransformer.

</details>


### [90] [Cost-Sensitive Unbiased Risk Estimation for Multi-Class Positive-Unlabeled Learning](https://arxiv.org/abs/2510.25226)
*Miao Zhang,Junpeng Li,Changchun Hua,Yana Yang*

Main category: cs.LG

TL;DR: 本文提出了一个基于自适应损失加权的成本敏感多类别PU学习方法，解决了现有方法无法确保无偏风险估计的问题。该方法在经验风险最小化框架下，通过对正样本和推断负样本损失组件分配不同的数据依赖权重，使目标风险的估计更为准确。作者还通过一系列实验证明了该方法在准确性与稳定性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 在多类别正-未标记（MPU）学习中，许多已有的方法不能确保无偏风险估计，这对性能和稳定性构成了挑战。因此本文的动机是为了提供一种确保无偏风险估计的MPU学习方法，以提高学习结果的准确性和稳定性。 

Method: 本文提出了一种基于自适应损失加权的成本敏感MPU方法。该方法通过在经验风险最小化框架中对正样本和推断负样本对应的损失函数添加不同的数据自适应权重，确保目标风险估计的无偏性。此外，文章还对该方法进行了理论分析，包括MPU数据生成过程形式化及一般化误差界确立。 

Result: 通过在八个不同类先验概率及类别数的公开数据集上的广泛实验，本文提出的方法在准确性和稳定性方面超过了现有的基准方法。 

Conclusion: 本文提出了一种新的基于自适应损失加权的成本敏感MPU方法，克服了现有方法无法确保无偏风险估计的局限，显著提升了准确性和稳定性。

Abstract: Positive--Unlabeled (PU) learning considers settings in which only positive
and unlabeled data are available, while negatives are missing or left
unlabeled. This situation is common in real applications where annotating
reliable negatives is difficult or costly. Despite substantial progress in PU
learning, the multi-class case (MPU) remains challenging: many existing
approaches do not ensure \emph{unbiased risk estimation}, which limits
performance and stability. We propose a cost-sensitive multi-class PU method
based on \emph{adaptive loss weighting}. Within the empirical risk minimization
framework, we assign distinct, data-dependent weights to the positive and
\emph{inferred-negative} (from the unlabeled mixture) loss components so that
the resulting empirical objective is an unbiased estimator of the target risk.
We formalize the MPU data-generating process and establish a generalization
error bound for the proposed estimator. Extensive experiments on \textbf{eight}
public datasets, spanning varying class priors and numbers of classes, show
consistent gains over strong baselines in both accuracy and stability.

</details>


### [91] [BSFA: Leveraging the Subspace Dichotomy to Accelerate Neural Network Training](https://arxiv.org/abs/2510.25244)
*Wenjie Zhou,Bohan Wang,Wei Chen,Xueqi Cheng*

Main category: cs.LG

TL;DR: 研究提出了一种新的加速深度学习训练的框架Bulk-Space-Filtration-Accelerator (BSFA)，通过加速并筛选不同的参数更新子空间的分量来提高模型训练速度和稳定性。该方法在大型语言模型预训练中，能够带来约2倍的加速效果。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习优化存在一个根本的悖论：主导方向上的参数更新占大多数，但对损失减少贡献较小。相比之下，正交方向上的更新虽然幅度较小，但驱动了大部分学习进展。为了进一步理解这一现象并提出解决方案，研究开发了BSFA框架。

Method: BSFA通过径向基函数（RBF）在不同的子空间中进行差异性放缩，同时引入基于PCA的历史更新子空间高效估计器，以及在参数块的基础上分块应用的策略，以提高训练速度和稳定性。它在计算上是可行和高效的。

Result: 研究展示了BSFA在不同任务上的训练加速效果，特别指出在使用WikiText-103和OpenWebText预训练LLaMA模型时，相较于普通AdamW优化器，BSFA带来了大约2倍的加速。

Conclusion: BSFA是一种有效的训练加速方法，特别是在大型语言模型预训练中，能够有效提高训练速度，保持模型的稳定性。

Abstract: Recent studies \citep{gur2018gradient,song2024does, wen2024understanding}
highlight a fundamental dichotomy in deep learning optimization: Although
parameter updates along the top eigendirections of the loss Hessian (Dom-space)
capture most of the update magnitude, they often contribute minimally to loss
reduction. In contrast, updates in the orthogonal component (Bulk-space) have
smaller magnitudes but drive most learning progress. In this work, we further
advance the understanding of this phenomenon and introduce the
\textbf{Bulk-Space-Filtration-Accelerator (BSFA)}, a novel plug-and-play
framework. BSFA accelerates training by differentially scaling update
components projected onto these distinct subspaces, simultaneously enhancing
stability by moderating updates in the dominant subspace and boosting
convergence speed by amplifying those in the bulk-space. To ensure BSFA is both
practical and scalable for contemporary large models, we introduce two key
innovations: an efficient estimator using Principal Component Analysis (PCA) on
historical updates for fast subspace estimation, and a block-wise strategy that
applies this estimation on a per-parameter-block basis. These designs make BSFA
computationally tractable and highly effective. We demonstrate BSFA's
acceleration across various tasks, notably achieving approximately 2$\times$
speedup when pre-training LLaMA-72M on WikiText-103 and LLaMA-134M on
OpenWebText compared to vanilla AdamW.

</details>


### [92] [Hierarchical Physics-Embedded Learning for Spatiotemporal Dynamical Systems](https://arxiv.org/abs/2510.25306)
*Xizhe Wang,Xiaobin Song,Qingshan Jia,Hongbo Zhao,Benben Jiang*

Main category: cs.LG

TL;DR: 提出了一种层次化的物理嵌入学习框架，用于从前馈预测到逆向物理定律的发现，有效结合了数据驱动方法和物理信息方法的优点，解决了复杂时空动态建模中的挑战.


<details>
  <summary>Details</summary>
Motivation: 复杂时空动态系统的建模在远离热力学平衡的系统中尤为困难，现有的数据分析方法或物理信息方法都存在局限性.

Method: 提出了一种双层级架构的物理嵌入学习框架，第一层级学习PDE的符号组成部分，第二层级学习这些组成部分的组合，从而在计算图中直接嵌入已知物理定律，保证物理一致性和提高数据效率.

Result: 该框架有效地结合了数据驱动模型的灵活性和物理信息模型的物理一致性，提高了在稀疏和有噪声数据下的物理定律发现能力.

Conclusion: 该研究提供了一种新方法来解决复杂动力系统中的挑战，通过层次化的物理嵌入和数据驱动学习方法的结合，为复杂系统的建模提供了新的视角.

Abstract: Modeling complex spatiotemporal dynamics, particularly in
far-from-equilibrium systems, remains a grand challenge in science. The
governing partial differential equations (PDEs) for these systems are often
intractable to derive from first principles, due to their inherent complexity,
characterized by high-order derivatives and strong nonlinearities, coupled with
incomplete physical knowledge. This has spurred the development of data-driven
methods, yet these approaches face limitations: Purely data-driven models are
often physically inconsistent and data-intensive, while existing
physics-informed methods lack the structural capacity to represent complex
operators or systematically integrate partial physical knowledge. Here, we
propose a hierarchical physics-embedded learning framework that fundamentally
advances both the forward spatiotemporal prediction and inverse discovery of
physical laws from sparse and noisy data. The key innovation is a two-level
architecture that mirrors the process of scientific discovery: the first level
learns fundamental symbolic components of a PDE, while the second learns their
governing combinations. This hierarchical decomposition not only reduces
learning complexity but, more importantly, enables a structural integration of
prior knowledge. Known physical laws are directly embedded into the models
computational graph, guaranteeing physical consistency and improving data
efficiency. By building the framework upon adaptive Fourier Neural Operators,
we can effectively capture the non-local dependencies and high-order operators
characteristic of dynamical systems. Additionally, by structurally decoupling
known and unknown terms, the framework further enables interpretable discovery
of underlying governing equations through symbolic regression, without
presupposing functional forms.

</details>


### [93] [Dense and Diverse Goal Coverage in Multi Goal Reinforcement Learning](https://arxiv.org/abs/2510.25311)
*Sagalpreet Singh,Rishi Saket,Aravindan Raghuveer*

Main category: cs.LG

TL;DR: 本文提出了一种新的强化学习算法，旨在同时最大化预期回报并分散目标状态的边际状态分布。此算法在多目标强化学习框架下，通过优化定制的回报函数以更新策略混合。文章还提供理论性能保证，并通过合成MDP和标准RL环境进行实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在最大化预期回报的同时难以分散目标状态的边际状态分布，特别是当这些状态下状态空间庞大且目标状态不能预先定义时。

Method: 提出了一种新的算法，该算法基于最大化定制回报函数，利用离线学习算法更新政策混合。定制的回报函数在每次迭代中基于当前政策混合计算，从而利用样本轨迹更新策略混合。

Result: 实验结果表明，所提出的算法在合成的MDPs和标准RL环境中有效，既最大化了预期回报又分散了目标状态的边际状态分布。

Conclusion: 本文通过一种新的强化学习算法解决了最大化回报的同时分散目标状态这个问题，为处理大规模系统中的强化学习任务提供了一种新方法。

Abstract: Reinforcement Learning algorithms are primarily focused on learning a policy
that maximizes expected return. As a result, the learned policy can exploit one
or few reward sources. However, in many natural situations, it is desirable to
learn a policy that induces a dispersed marginal state distribution over
rewarding states, while maximizing the expected return which is typically tied
to reaching a goal state. This aspect remains relatively unexplored. Existing
techniques based on entropy regularization and intrinsic rewards use
stochasticity for encouraging exploration to find an optimal policy which may
not necessarily lead to dispersed marginal state distribution over rewarding
states. Other RL algorithms which match a target distribution assume the latter
to be available apriori. This may be infeasible in large scale systems where
enumeration of all states is not possible and a state is determined to be a
goal state only upon reaching it. We formalize the problem of maximizing the
expected return while uniformly visiting the goal states as Multi Goal RL in
which an oracle classifier over the state space determines the goal states. We
propose a novel algorithm that learns a high-return policy mixture with
marginal state distribution dispersed over the set of goal states. Our
algorithm is based on optimizing a custom RL reward which is computed - based
on the current policy mixture - at each iteration for a set of sampled
trajectories. The latter are used via an offline RL algorithm to update the
policy mixture. We prove performance guarantees for our algorithm, showing
efficient convergence bounds for optimizing a natural objective which captures
the expected return as well as the dispersion of the marginal state
distribution over the goal states. We design and perform experiments on
synthetic MDPs and standard RL environments to evaluate the effectiveness of
our algorithm.

</details>


### [94] [CDFlow: Building Invertible Layers with Circulant and Diagonal Matrices](https://arxiv.org/abs/2510.25323)
*Xuchen Feng,Siyu Liao*

Main category: cs.LG

TL;DR: 提出了基于circulant和对角矩阵乘积的新型可逆线性层，提升了表达能力的同时保持了雅克比行列式和逆矩阵的高效计算。此方法的时间复杂度较低，适用于自然图像数据集的密度估计和具有固有周期结构数据的有效建模，加速了归一化流的关键操作，使得大规模生成式建模更加实用。这种方法主要应用于开发Circulant-Diagonal Flow (CDFlow)。


<details>
  <summary>Details</summary>
Motivation: 现有的线性层设计在增强表达力的同时难以保证雅克比行列式及逆矩阵的高效计算。为了寻求一种既能提升模型表达能力又具有高效计算能力的方案，作者引入了一种新的基于circulant和对角矩阵乘积的可逆线性层，进一步提出了Circulant-Diagonal Flow (CDFlow)模型。

Method: 加入了基于circulant和对角矩阵乘积分解技术的新型可逆线性层。这个分解降低了参数复杂度，并通过利用快速傅里叶变换（Fast Fourier Transform）减少了矩阵逆变换和计算log-行列式的计算时间。另外，作者开发了Circulant-Diagonal Flow (CDFlow)，这是一种新型的归一化流，致力于提高密度估计效率，同时支持固有周期结构数据的有效建模。

Result: CDFlow模型不仅提高了自然图像数据集上的密度估计效果，而且能够有效地处理具有固有周期结构的数据，显著加速了归一化流的操作，使得大规模生成式建模更为实用。实验结果表明CDFlow在关键操作上具有明显优势。

Conclusion: 该研究通过设计新的可逆线性层，提升了归一化流模型的能力，降低了时间复杂度，提高了大规模生成模型使用的效率和效果。

Abstract: Normalizing flows are deep generative models that enable efficient likelihood
estimation and sampling through invertible transformations. A key challenge is
to design linear layers that enhance expressiveness while maintaining efficient
computation of the Jacobian determinant and inverse. We introduce a novel
invertible linear layer based on the product of circulant and diagonal
matrices. This decomposition reduces parameter complexity from
$\mathcal{O}(n^2)$ to $\mathcal{O}(mn)$ using $m$ diagonal matrices and $m-1$
circulant matrices while still approximating general linear transformations. By
leveraging the Fast Fourier Transform, our approach reduces the time complexity
of matrix inversion from $\mathcal{O}(n^3)$ to $\mathcal{O}(mn\log n)$ and that
of computing the log-determinant from $\mathcal{O}(n^3)$ to $\mathcal{O}(mn)$,
where $n$ is the input dimension. We build upon this layer to develop
Circulant-Diagonal Flow (CDFlow), which achieves strong density estimation on
natural image datasets and effectively models data with inherent periodic
structure. Furthermore, CDFlow significantly accelerates key operations in
normalizing flows, providing practical benefits for scalable generative
modeling.

</details>


### [95] [Beyond Leakage and Complexity: Towards Realistic and Efficient Information Cascade Prediction](https://arxiv.org/abs/2510.25348)
*Jie Peng,Rui Wang,Qiang Wang,Zhewei Wei,Bin Tong,Guan Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的时间顺序划分策略和一个大规模的电子商务信息传播数据集Taoke，以及轻量级的框架CasTemp，用于预测信息传播的受欢迎程度。此框架能在避免未来信息泄漏的情况下，高效预测信息传播的受欢迎程度，并在实际应用中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前的信息传播预测研究存在时间泄漏问题、数据集特征不足和计算效率低的问题。本文解决这些问题，提出了新的策略和框架。

Method: 首先，提出时间顺序划分策略；其次，引入Taoke数据集，具有丰富的属性和真实的购买转换信号；最后，设计CasTemp框架，通过时间步走，Jaccard相似性选择相邻节点，以及GRU编码等方法，高效预测流行度转换。

Result: CasTemp在四个数据集上取得了无泄漏评估的最先进性能，并极大地提高了预测效率。特别地，在预测第二阶段受欢迎程度转换的任务上表现优秀。

Conclusion: 本文提出的时间顺序划分策略、大尺度数据集Taoke以及高效的CasTemp框架，解决了现有信息传播预测问题存在的关键缺陷，提升了预测的实际应用性能。

Abstract: Information cascade popularity prediction is a key problem in analyzing
content diffusion in social networks. However, current related works suffer
from three critical limitations: (1) temporal leakage in current
evaluation--random cascade-based splits allow models to access future
information, yielding unrealistic results; (2) feature-poor datasets that lack
downstream conversion signals (e.g., likes, comments, or purchases), which
limits more practical applications; (3) computational inefficiency of complex
graph-based methods that require days of training for marginal gains. We
systematically address these challenges from three perspectives: task setup,
dataset construction, and model design. First, we propose a time-ordered
splitting strategy that chronologically partitions data into consecutive
windows, ensuring models are evaluated on genuine forecasting tasks without
future information leakage. Second, we introduce Taoke, a large-scale
e-commerce cascade dataset featuring rich promoter/product attributes and
ground-truth purchase conversions--capturing the complete diffusion lifecycle
from promotion to monetization. Third, we develop CasTemp, a lightweight
framework that efficiently models cascade dynamics through temporal walks,
Jaccard-based neighbor selection for inter-cascade dependencies, and GRU-based
encoding with time-aware attention. Under leak-free evaluation, CasTemp
achieves state-of-the-art performance across four datasets with
orders-of-magnitude speedup. Notably, it excels at predicting second-stage
popularity conversions--a practical task critical for real-world applications.

</details>


### [96] [Analysis of Semi-Supervised Learning on Hypergraphs](https://arxiv.org/abs/2510.25354)
*Adrien Weihs,Andrea Bertozzi,Matthew Thorpe*

Main category: cs.LG

TL;DR: 本文分析了在随机几何超图上的变分学习的渐近一致性，并提出了多尺度平滑性的高阶超图学习（HOHL），该方法在标准基准上的表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有理论在半监督学习中的超图建模应用有限，本文旨在探索超图在随机几何中的变分学习的一致性，并据此提出有效算法。

Method: 通过变分学习分析随机几何超图，并结合Laplace算子的幂次项提出高阶超图学习（HOHL）方法，以实现多尺度平滑性。

Result: 学术研究结果表明，HOHL方法能够收敛到一个高阶Sobolev半范数，并且在标准基准测试中表现出色。

Conclusion: 本文不仅提供了理论依据，还提出了一种有效的半监督学习算法HOHL，对于高阶交互建模具有重要意义。

Abstract: Hypergraphs provide a natural framework for modeling higher-order
interactions, yet their theoretical underpinnings in semi-supervised learning
remain limited. We provide an asymptotic consistency analysis of variational
learning on random geometric hypergraphs, precisely characterizing the
conditions ensuring the well-posedness of hypergraph learning as well as
showing convergence to a weighted $p$-Laplacian equation. Motivated by this, we
propose Higher-Order Hypergraph Learning (HOHL), which regularizes via powers
of Laplacians from skeleton graphs for multiscale smoothness. HOHL converges to
a higher-order Sobolev seminorm. Empirically, it performs strongly on standard
baselines.

</details>


### [97] [Parameter Averaging in Link Prediction](https://arxiv.org/abs/2510.25361)
*Rupesh Sapkota,Caglar Demir,Arnab Sharma,Axel-Cyrille Ngonga Ngomo*

Main category: cs.LG

TL;DR: 该论文探索了一种新的方法，通过加权平均的方式将知识图谱嵌入（KGE）中的多个模型参数合并，以减少训练多个模型带来的计算和内存开销，同时保持预测性能。实验表明，提出的加权平均合并方法在多样化的评估设置中都能提高性能。


<details>
  <summary>Details</summary>
Motivation: 传统的集成学习方法在知识图谱嵌入中需要训练多个模型，这导致了计算开销和内存开销增加。为了克服这些问题，该论文尝试使用模型合并的方式，特别是加权平均，来代替训练多个模型。通过选择性地更新验证数据集上表现有所提升的模型参数的运行平均值，从而实现性能提升的同时减少了计算资源的消耗。

Method: 论文介绍了两种加权平均的方法用于合并KGE模型参数，一种是持续维护从训练轮次开始的模型参数的运行平均值并用于预测，另一种是仅当验证集上的泛化性能提高时更新运行平均值。并将这些方法应用于链接预测任务和带字面扩充的KGE模型和多跳查询回答任务上。

Result: 实验结果表明，提出的加权平均合并方法在不同的评估基准上都能提高性能，特别是在链接预测任务上表现尤为突出。此外，该方法在字面数字扩充的KGE模型和多跳查询回答任务上也能保持性能改善的效果。表明这种方法能够有效减少训练开销同时保持甚至提升预测性能。

Conclusion: 论文提出的方法通过加权平均模型参数来代替传统的集成模型训练，能够在保持甚至提高预测性能的同时减少计算资源的消耗。

Abstract: Ensemble methods are widely employed to improve generalization in machine
learning. This has also prompted the adoption of ensemble learning for the
knowledge graph embedding (KGE) models in performing link prediction. Typical
approaches to this end train multiple models as part of the ensemble, and the
diverse predictions are then averaged. However, this approach has some
significant drawbacks. For instance, the computational overhead of training
multiple models increases latency and memory overhead. In contrast, model
merging approaches offer a promising alternative that does not require training
multiple models. In this work, we introduce model merging, specifically
weighted averaging, in KGE models. Herein, a running average of model
parameters from a training epoch onward is maintained and used for predictions.
To address this, we additionally propose an approach that selectively updates
the running average of the ensemble model parameters only when the
generalization performance improves on a validation dataset. We evaluate these
two different weighted averaging approaches on link prediction tasks, comparing
the state-of-the-art benchmark ensemble approach. Additionally, we evaluate the
weighted averaging approach considering literal-augmented KGE models and
multi-hop query answering tasks as well. The results demonstrate that the
proposed weighted averaging approach consistently improves performance across
diverse evaluation settings.

</details>


### [98] [A Convexity-dependent Two-Phase Training Algorithm for Deep Neural Networks](https://arxiv.org/abs/2510.25366)
*Tomas Hrycej,Bernhard Bermeitinger,Massimo Pavone,Götz-Henrik Wiegand,Siegfried Handschuh*

Main category: cs.LG

TL;DR: 提出了一个新的框架，假设在实际任务中的损失函数会从初始的非凸性转变为接近最优时的凸性。在这个假设的基础上设计了一个两阶段优化算法，该算法检测这种转变点，并在不同的阶段使用不同的优化器。实验显示这种算法可以改善收敛性和准确性。


<details>
  <summary>Details</summary>
Motivation: 损失函数的非凸性导致在许多机器学习任务中广泛使用非凸优化方法，如Adam。然而，某些算法在损失函数局部凸的情况下可以给出保证的超线性收敛速度。因此希望设计一种在损失函数由非凸转变为凸时可以改善收敛性和准确性算法。

Method: 该方法首先观察损失函数的梯度范数随损失函数值的变化，以检测损失函数从非凸性转变为凸性的转变点。然后在不同的区域分别使用非凸优化器（如Adam）和凸优化器（如共轭梯度CG）进行优化。

Result: 实验结果显示，在实际任务的损失函数中这种从非凸性转变为凸性的结构足够频繁，可以利用这种简单结构显著改善收敛性和准确性。

Conclusion: 通过在损失函数的非凸和凸性区域分别采用不同的优化器，新算法可以显著提高机器学习任务的收敛和准确性。

Abstract: The key task of machine learning is to minimize the loss function that
measures the model fit to the training data. The numerical methods to do this
efficiently depend on the properties of the loss function. The most decisive
among these properties is the convexity or non-convexity of the loss function.
The fact that the loss function can have, and frequently has, non-convex
regions has led to a widespread commitment to non-convex methods such as Adam.
However, a local minimum implies that, in some environment around it, the
function is convex. In this environment, second-order minimizing methods such
as the Conjugate Gradient (CG) give a guaranteed superlinear convergence. We
propose a novel framework grounded in the hypothesis that loss functions in
real-world tasks swap from initial non-convexity to convexity towards the
optimum. This is a property we leverage to design an innovative two-phase
optimization algorithm. The presented algorithm detects the swap point by
observing the gradient norm dependence on the loss. In these regions,
non-convex (Adam) and convex (CG) algorithms are used, respectively. Computing
experiments confirm the hypothesis that this simple convexity structure is
frequent enough to be practically exploited to substantially improve
convergence and accuracy.

</details>


### [99] [GPTOpt: Towards Efficient LLM-Based Black-Box Optimization](https://arxiv.org/abs/2510.25404)
*Jamison Meindl,Yunsheng Tian,Tony Cui,Veronika Thost,Zhang-Wei Hong,Jie Chen,Wojciech Matusik,Mina Konaković Luković*

Main category: cs.LG

TL;DR: GPTOpt是一种基于大语言模型的优化方法，它可以解决连续黑盒优化问题，而不需要参数调优。通过在大量合成数据集上微调大语言模型，GPTOpt在各种黑盒优化基准上超越了传统优化器。


<details>
  <summary>Details</summary>
Motivation: 在昂贵且导数自由的黑盒函数的全局优化中，需要极高的样本效率。尽管传统的贝叶斯优化方法有效，但它们需要为每个应用领域进行仔细的参数调整。因此，引入了一种基于大语言模型的优化方法，以克服这一限制。此外，最先进的大语言模型在解决连续黑盒优化任务方面仍然有限，因此需要一种新的方法来解决这个问题。

Method: 通过在广泛的合成数据集上微调大语言模型，这些数据集来源于多种贝叶斯优化参数化。该方法利用了LLM的预训练来推广到各种优化任务中。具体来说，GPTOpt利用了LLM的预训练能力，使其能够适应不同的优化任务，同时展示了LLM在高级数值推理方面的潜力。

Result: 在各种黑盒优化基准测试中，GPTOpt的表现超过了传统的优化器，展示了LLM解决连续黑盒优化问题的能力。此外，该方法提供了一个不需要参数调优的灵活的全局优化框架。

Conclusion: 我们的研究表明，GPTOpt提供了一种新的范式，以解决全球性的复杂黑盒优化问题。通过将大语言模型的能力与优化任务结合起来，我们展示了改进优化性能的潜力，同时避免了繁琐的手动参数调整。

Abstract: Global optimization of expensive, derivative-free black-box functions demands
extreme sample efficiency. Classical methods such as Bayesian Optimization (BO)
can be effective, but they often require careful parameter tuning to each
application domain. At the same time, Large Language Models (LLMs) have shown
broad capabilities, yet state-of-the-art models remain limited in solving
continuous black-box optimization tasks. We introduce GPTOpt, an LLM-based
optimization method that equips LLMs with continuous black-box optimization
capabilities. By fine-tuning large language models on extensive synthetic
datasets derived from diverse BO parameterizations, GPTOpt leverages LLM
pre-training to generalize across optimization tasks. On a variety of black-box
optimization benchmarks, GPTOpt surpasses traditional optimizers, highlighting
the capacity of LLMs for advanced numerical reasoning and introducing a
flexible framework for global optimization without parameter tuning.

</details>


### [100] [Scalable Utility-Aware Multiclass Calibration](https://arxiv.org/abs/2510.25458)
*Mahmoud Hegazy,Michael I. Jordan,Aymeric Dieuleveut*

Main category: cs.LG

TL;DR: 本文提出了一种新的评估多类校准的框架——效用校准，该框架可以将多类校准误差相对于特定的效用函数进行测量，从而使评估更加全面和灵活，涵盖了传统的顶类校准和类校准的指标，并扩展到更复杂的效用函数评估中去.


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法往往聚焦于预测特定方面的校准或使用计算上复杂的变分形式，缺乏实用性与通用性，因此，研究一种通用且计算高效的多类校准评估方法是十分必要的.

Method: 本文提出效用校准框架，该框架根据终用户的决策标准或目标来定义校准误差，使其能够适应多种实际应用.

Result: 效用校准框架能够统一并重新解释许多现有的校准度量，特别是能够提供更稳健的顶类和类校准度量，并且超越了这些二元化的方法，能够评估更复杂效用函数的校准.

Conclusion: 通过一种新的通用多类校准评估框架，可以解决现有的多类校准评估中存在的问题，使评估更加灵活，更具实用价值。

Abstract: Ensuring that classifiers are well-calibrated, i.e., their predictions align
with observed frequencies, is a minimal and fundamental requirement for
classifiers to be viewed as trustworthy. Existing methods for assessing
multiclass calibration often focus on specific aspects associated with
prediction (e.g., top-class confidence, class-wise calibration) or utilize
computationally challenging variational formulations. In this work, we study
scalable \emph{evaluation} of multiclass calibration. To this end, we propose
utility calibration, a general framework that measures the calibration error
relative to a specific utility function that encapsulates the goals or decision
criteria relevant to the end user. We demonstrate how this framework can unify
and re-interpret several existing calibration metrics, particularly allowing
for more robust versions of the top-class and class-wise calibration metrics,
and, going beyond such binarized approaches, toward assessing calibration for
richer classes of downstream utilities.

</details>


### [101] [Gradient-Weight Alignment as a Train-Time Proxy for Generalization in Classification Tasks](https://arxiv.org/abs/2510.25480)
*Florian A. Hölzl,Daniel Rueckert,Georgios Kaissis*

Main category: cs.LG

TL;DR: 提出了一种新的稳健性验证指标——梯度-权重对齐（GWA），用于跟踪深度学习模型的泛化能力，并能从训练数据中直接分析模型性能，而无需验证集。该指标能有效预测最佳的早停时间，进行原则性的模型对比，并识别出对训练有显著影响的数据样本。


<details>
  <summary>Details</summary>
Motivation: 深度学习中，稳健的验证指标对于识别过拟合、不良泛化以及监测训练过程至关重要。在监督分类场景中，我们探索了训练数据与模型权重之间的交互是否能生成一个既能跟踪训练过程中的泛化能力又能归因于个别训练样本的性能指标。

Method: 我们引入了梯度-权重对齐(GWA)来量化每个样本的梯度与模型权重的协同性，并且证明有效学习对应于准确定位梯度和权重间的对齐关系，而对齐程度的降低则可能意味着泛化能力的下降。GWA可以在训练过程中高效计算，并同时反映特定样本的贡献和数据集的整体学习动态。

Result: 通过广泛实验，我们证明了GWA能准确预测最优的早停时间，为模型对比提供了理论基础，同时也能够识别出对训练具有显著影响的数据样本。这项研究提供了一种无需验证集即可直接从训练数据中分析模型的方法。

Conclusion: 梯度-权重对齐（GWA）作为一种新的验证指标，不仅能高效地追踪深度学习模型的泛化能力，而且能够根据训练数据中的信息直接分析模型性能，无需额外的验证集，从而提高了模型分析效率。

Abstract: Robust validation metrics remain essential in contemporary deep learning, not
only to detect overfitting and poor generalization, but also to monitor
training dynamics. In the supervised classification setting, we investigate
whether interactions between training data and model weights can yield such a
metric that both tracks generalization during training and attributes
performance to individual training samples. We introduce Gradient-Weight
Alignment (GWA), quantifying the coherence between per-sample gradients and
model weights. We show that effective learning corresponds to coherent
alignment, while misalignment indicates deteriorating generalization. GWA is
efficiently computable during training and reflects both sample-specific
contributions and dataset-wide learning dynamics. Extensive experiments show
that GWA accurately predicts optimal early stopping, enables principled model
comparisons, and identifies influential training samples, providing a
validation-set-free approach for model analysis directly from the training
data.

</details>


### [102] [Right for the Right Reasons: Avoiding Reasoning Shortcuts via Prototypical Neurosymbolic AI](https://arxiv.org/abs/2510.25497)
*Luca Andolfi,Eleonora Giunchiglia*

Main category: cs.LG

TL;DR: 本文提出了一种新的神经符号架构，可以通过避免基于捷径推理的情况下在少量数据下正确学习基本概念，从而有效地满足符号约束。这种方法可以有效避免相似性判断中的不合理关联，从而提高模型在合成任务和实际高风险任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI正因其能够结合神经感知和符号推理而变得流行，但最近发现它们容易出现捷径推理问题，即通过学习未预期的概念来满足符号约束，这利用了偶然关联。本文的动机是解决这一挑战，提出一种新的架构，可以避免基于捷径推理情况下的不合理学习情况。

Method: 本文提出利用原型学习理论，训练模型满足背景知识，同时考虑输入与少量标注数据点的相似性，从而避免捷径推理。通过在rsbench基准测试套件的各种设置和任务中进行广泛的验证，展示了原型接地作为一种有效且需要较少标注数据的策略，可以有效引导神经符号学习并提高其安全性、可靠性。

Result: 所提出的原型神经符号架构在假设和实际高风险任务中展示了显著改进，能够在极端数据欠缺条件下，通过避免基于捷径推理情况下的不合理学习来正确学习基本概念，从而提高模型的安全性和可靠性。

Conclusion: 这篇论文开辟了原型接地作为神经符号学习的有效策略之路，可以更好地学习正确的概念，避免不必要的偏差，即使是在很少的数据上也能取得优秀表现。

Abstract: Neurosymbolic AI is growing in popularity thanks to its ability to combine
neural perception and symbolic reasoning in end-to-end trainable models.
However, recent findings reveal these are prone to shortcut reasoning, i.e., to
learning unindented concepts--or neural predicates--which exploit spurious
correlations to satisfy the symbolic constraints. In this paper, we address
reasoning shortcuts at their root cause and we introduce prototypical
neurosymbolic architectures. These models are able to satisfy the symbolic
constraints (be right) because they have learnt the correct basic concepts (for
the right reasons) and not because of spurious correlations, even in extremely
low data regimes. Leveraging the theory of prototypical learning, we
demonstrate that we can effectively avoid reasoning shortcuts by training the
models to satisfy the background knowledge while taking into account the
similarity of the input with respect to the handful of labelled datapoints. We
extensively validate our approach on the recently proposed rsbench benchmark
suite in a variety of settings and tasks with very scarce supervision: we show
significant improvements in learning the right concepts both in synthetic tasks
(MNIST-EvenOdd and Kand-Logic) and real-world, high-stake ones (BDD-OIA). Our
findings pave the way to prototype grounding as an effective,
annotation-efficient strategy for safe and reliable neurosymbolic learning.

</details>


### [103] [Support Vector Machine-Based Burnout Risk Prediction with an Interactive Interface for Organizational Use](https://arxiv.org/abs/2510.25509)
*Bruno W. G. Teodosio,Mário J. O. T. Lira,Pedro H. M. Araújo,Lucas R. C. Farias*

Main category: cs.LG

TL;DR: 这项研究提出了一种使用机器学习方法预测员工倦怠风险的方法，使用HackerEarth员工倦怠挑战数据集。通过30折交叉验证评估模型性能，SVM模型表现最佳（R2=0.84），并开发了交互界面，提高了实践应用性，强调了机器学习在早期倦怠检测中的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过机器学习方法预测员工倦怠风险，从而提高个人福祉和组织绩效，促进数据驱动的心理健康策略。

Method: 研究采用三种监督学习算法（KNN、随机森林和SVM），通过30折交叉验证评估模型性能。

Result: SVM模型表现最佳（R2=0.84），并且在与KNN和随机森林对比中获得统计显著性。此外，开发了一个交互界面以便非技术用户使用。

Conclusion: 结果表明，机器学习在支持早期识别倦怠和促进组织环境中的心理健康策略方面潜力巨大。

Abstract: Burnout is a psychological syndrome marked by emotional exhaustion,
depersonalization, and reduced personal accomplishment, with a significant
impact on individual well-being and organizational performance. This study
proposes a machine learning approach to predict burnout risk using the
HackerEarth Employee Burnout Challenge dataset. Three supervised algorithms
were evaluated: nearest neighbors (KNN), random forest, and support vector
machine (SVM), with model performance evaluated through 30-fold
cross-validation using the determination coefficient (R2). Among the models
tested, SVM achieved the highest predictive performance (R2 = 0.84) and was
statistically superior to KNN and Random Forest based on paired $t$-tests. To
ensure practical applicability, an interactive interface was developed using
Streamlit, allowing non-technical users to input data and receive burnout risk
predictions. The results highlight the potential of machine learning to support
early detection of burnout and promote data-driven mental health strategies in
organizational settings.

</details>


### [104] [Transformers Provably Learn Directed Acyclic Graphs via Kernel-Guided Mutual Information](https://arxiv.org/abs/2510.25542)
*Yuan Cheng,Yu Huang,Zhe Xiong,Yingbin Liang,Vincent Y. F. Tan*

Main category: cs.LG

TL;DR: 本文提出了一个基于$f$-散度的核引导互信息(KG-MI)的新度量，并结合多头注意力框架，证明了在由$K$父节点DAG生成的序列上，单层多头变压器通过梯度上升法在多项式时间内收敛到全局最优。当$f$-散度特定为KL散度时，就准确反映了底层图的结构关系。实验结果验证了理论发现。 


<details>
  <summary>Details</summary>
Motivation: 探究基于注意力机制的变压器模型在捕捉复杂图依赖性的训练动态中的理论理解，特别是在更一般的有向无环图(DAG)中。解决多父节点问题，并提供可证明的保证。 

Method: 提出了一种信息理论的新度量——核引导互信息(KG-MI)，将其与多头注意力框架结合，设计了新的训练目标； 

Result: 证明了在特定条件下，通过梯度上升方法训练的单层多头变压器能在多项式时间内收敛到全局最优，并且能准确恢复底层图结构。实验验证了理论发现。

Conclusion: 通过引入KG-MI和设计适应多父节点依赖性的多头注意力框架，成功解决了在更复杂图结构中训练动态的理论理解问题，并且实验结果支持了理论推导。

Abstract: Uncovering hidden graph structures underlying real-world data is a critical
challenge with broad applications across scientific domains. Recently,
transformer-based models leveraging the attention mechanism have demonstrated
strong empirical success in capturing complex dependencies within graphs.
However, the theoretical understanding of their training dynamics has been
limited to tree-like graphs, where each node depends on a single parent.
Extending provable guarantees to more general directed acyclic graphs (DAGs) --
which involve multiple parents per node -- remains challenging, primarily due
to the difficulty in designing training objectives that enable different
attention heads to separately learn multiple different parent relationships.
  In this work, we address this problem by introducing a novel
information-theoretic metric: the kernel-guided mutual information (KG-MI),
based on the $f$-divergence. Our objective combines KG-MI with a multi-head
attention framework, where each head is associated with a distinct marginal
transition kernel to model diverse parent-child dependencies effectively. We
prove that, given sequences generated by a $K$-parent DAG, training a
single-layer, multi-head transformer via gradient ascent converges to the
global optimum in polynomial time. Furthermore, we characterize the attention
score patterns at convergence. In addition, when particularizing the
$f$-divergence to the KL divergence, the learned attention scores accurately
reflect the ground-truth adjacency matrix, thereby provably recovering the
underlying graph structure. Experimental results validate our theoretical
findings.

</details>


### [105] [A Framework for Bounding Deterministic Risk with PAC-Bayes: Applications to Majority Votes](https://arxiv.org/abs/2510.25569)
*Benjamin Leblanc,Pascal Germain*

Main category: cs.LG

TL;DR: 本文提出了一种从随机PAC-Bayesian保证中提取单一假设保证的统一框架。通过一个通用的oracle界限，该方法能得出数值界限并专门应用于多数投票。实验证明，与确定性分类器的推广界限相比，该方法通常比流行基准方法表现更好，最多可提高两倍。


<details>
  <summary>Details</summary>
Motivation: 在经典形式中，PAC-Bayes框架只能提供随机采样假设的期望风险保证，这要求在测试期间进行随机预测，但在许多实际情况下需要确定性的单一假设。本文的动机是为了解决这个问题，推出一种能够从随机PAC-Bayesian保证中提取单一假设保证的框架，适用于更多实际场景中。

Method: 提出了一种通用的oracle界限方法，并采用了数值界限和多数投票两种方法。该方法能有效从随机PAC-Bayesian保证中提取关于单一假设的保证。

Result: 实验结果表明，所提出的方法在确定性分类器的推广界限上表现良好，通常比流行基准方法表现更好，最多可提高两倍，证明了该方法的有效性和应用价值。

Conclusion: 通过本文提出的方法，从随机PAC-Bayesian保证中成功提取了单一假设的保证，解决了当下PAC-Bayes框架在实际应用中的局限性，为PAC-Bayes框架的应用提供了新的可能性。

Abstract: PAC-Bayes is a popular and efficient framework for obtaining generalization
guarantees in situations involving uncountable hypothesis spaces.
Unfortunately, in its classical formulation, it only provides guarantees on the
expected risk of a randomly sampled hypothesis. This requires stochastic
predictions at test time, making PAC-Bayes unusable in many practical
situations where a single deterministic hypothesis must be deployed. We propose
a unified framework to extract guarantees holding for a single hypothesis from
stochastic PAC-Bayesian guarantees. We present a general oracle bound and
derive from it a numerical bound and a specialization to majority vote. We
empirically show that our approach consistently outperforms popular baselines
(by up to a factor of 2) when it comes to generalization bounds on
deterministic classifiers.

</details>


### [106] [Perturbation Bounds for Low-Rank Inverse Approximations under Noise](https://arxiv.org/abs/2510.25571)
*Phuc Tran,Nisheeth K. Vishnoi*

Main category: cs.LG

TL;DR: 本文研究了在噪声存在的情况下，秩为p的矩阵逆的伪逆与精确逆之间的谱范数误差，并给出了误差的非渐近界限。这些界限揭示了误差随着特征值间隙、谱衰减和噪声与A的低曲率方向对齐的变化趋势，改进了经典全矩阵逆界的$	ext{sqrt}(n)$因子。


<details>
  <summary>Details</summary>
Motivation: 在存在噪声的条件下，研究秩为p的矩阵逆的伪逆与精确逆之间的误差界限，这在机器学习、优化和科学计算中具有重要意义，尤其是在噪声采样、概要和量化造成的影响下低秩逆近似稳健性的问题仍然没有很好地被解决。因此，本研究旨在填补领域缺口，提供对噪声环境中有谱信息的稳健误差保证。

Method: 利用奇异值分解和特征值分解导出了误差界限，并引入了轮廓积分技术应用于非整函数$f(z)=1/z$，完善了传统方法的界限。这项分析覆盖了一系列实际和合成矩阵，并展示了精确的误差界比起传统方法更准确。

Result: 发现了误差如何随特征值差距和谱衰减变化，并应用轮廓积分技术建立了一个新的误差界，从而改进了传统误差界的$	ext{sqrt}(n)$。在多种矩阵情况下的经验结果与本文理论预测高度一致，并且优于现有经典界限。

Conclusion: 此项工作首次从严格数学分析角度建立了存在噪声情况下矩阵逆的低秩近似的谱范数误差界限，提供了实用且谱依赖的误差保证，这对机器学习、优化和科学计算中的大规模问题处理具有重要指导意义。

Abstract: Low-rank pseudoinverses are widely used to approximate matrix inverses in
scalable machine learning, optimization, and scientific computing. However,
real-world matrices are often observed with noise, arising from sampling,
sketching, and quantization. The spectral-norm robustness of low-rank inverse
approximations remains poorly understood. We systematically study the
spectral-norm error $\| (\tilde{A}^{-1})_p - A_p^{-1} \|$ for an $n\times n$
symmetric matrix $A$, where $A_p^{-1}$ denotes the best rank-\(p\)
approximation of $A^{-1}$, and $\tilde{A} = A + E$ is a noisy observation.
Under mild assumptions on the noise, we derive sharp non-asymptotic
perturbation bounds that reveal how the error scales with the eigengap,
spectral decay, and noise alignment with low-curvature directions of $A$. Our
analysis introduces a novel application of contour integral techniques to the
\emph{non-entire} function $f(z) = 1/z$, yielding bounds that improve over
naive adaptations of classical full-inverse bounds by up to a factor of
$\sqrt{n}$. Empirically, our bounds closely track the true perturbation error
across a variety of real-world and synthetic matrices, while estimates based on
classical results tend to significantly overpredict. These findings offer
practical, spectrum-aware guarantees for low-rank inverse approximations in
noisy computational environments.

</details>


### [107] [Generalized Sobolev IPM for Graph-Based Measures](https://arxiv.org/abs/2510.25591)
*Tam Le,Truyen Nguyen,Hideitsu Hino,Kenji Fukumizu*

Main category: cs.LG

TL;DR: 本研究通过Orlicz几何结构框架推广了Sobolev IPM方法，解决了传统Sobolev IPM方法局限在$L^p$几何结构的问题。新方法提出了一种基于Musielak正则化的GSI-M模型，大幅提高了计算效率，并在文档分类与拓扑数据分析中的几项任务上展现了实际优势。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统Sobolev IPM方法局限于$L^p$几何结构的缺点，提出基于Orlicz几何结构推广Sobolev IPM方法，从而可以兼容更多样的几何先验条件。同时，该研究还探讨了该方法在计算上的挑战，并提出了相应的解决方案。

Method: 通过建立Orlicz-Sobolev范数与Musielak范数之间的新理论联系，提出一种基于Musielak正则化的广义Sobolev IPM方法（GSI）。通过进一步利用底层图结构，将GSI-M转化为简单的单变量优化问题，极大提高了计算效率。

Result: 实验表明，GSI-M模型在计算效率上明显优于现有的OW方法，与传统Sobolev IPM相比，在文档分类及拓扑数据分析等任务中展现了实际的优势。

Conclusion: 本研究成功推广了Sobolev IPM方法，提出了一种基于Musielak正则化的GSI-M模型，不仅能够处理多样性的几何先验条件，还在计算效率和实际应用上展现了显著效果。

Abstract: We study the Sobolev IPM problem for measures supported on a graph metric
space, where critic function is constrained to lie within the unit ball defined
by Sobolev norm. While Le et al. (2025) achieved scalable computation by
relating Sobolev norm to weighted $L^p$-norm, the resulting framework remains
intrinsically bound to $L^p$ geometric structure, limiting its ability to
incorporate alternative structural priors beyond the $L^p$ geometry paradigm.
To overcome this limitation, we propose to generalize Sobolev IPM through the
lens of \emph{Orlicz geometric structure}, which employs convex functions to
capture nuanced geometric relationships, building upon recent advances in
optimal transport theory -- particularly Orlicz-Wasserstein (OW) and
generalized Sobolev transport -- that have proven instrumental in advancing
machine learning methodologies. This generalization encompasses classical
Sobolev IPM as a special case while accommodating diverse geometric priors
beyond traditional $L^p$ structure. It however brings up significant
computational hurdles that compound those already inherent in Sobolev IPM. To
address these challenges, we establish a novel theoretical connection between
Orlicz-Sobolev norm and Musielak norm which facilitates a novel regularization
for the generalized Sobolev IPM (GSI). By further exploiting the underlying
graph structure, we show that GSI with Musielak regularization (GSI-M) reduces
to a simple \emph{univariate optimization} problem, achieving remarkably
computational efficiency. Empirically, GSI-M is several-order faster than the
popular OW in computation, and demonstrates its practical advantages in
comparing probability measures on a given graph for document classification and
several tasks in topological data analysis.

</details>


### [108] [Uncertainty Quantification for Regression: A Unified Framework based on kernel scores](https://arxiv.org/abs/2510.25599)
*Christopher Bülte,Yusuf Sale,Gitta Kutyniok,Eyke Hüllermeier*

Main category: cs.LG

TL;DR: 提出了一种基于合适评分准则的不确定性量化的度量方法，特别是核评分，并提供了这些度量如何应用于回归任务的原理和指导方针。这种方法能够统一多种已知的度量，并且设计出新的度量，其行为特性如尾部敏感性、鲁棒性和域外分布响应性，都可以通过选择核来控制。理论证明了这些核评分的特性如何影响下游行为，并提供了具体的设计指南。实验验证了这种方法在下游任务中的有效性，并揭示了不同实现之间的明显权衡，包括鲁棒性和域外分布检测性能。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域进行回归任务时，需要做出不确定性的量化，但该领域的文献主要集中在分类上，缺乏针对回归任务的不确定性量化的有效措施。因此，为了填补这一空白，作者提出了基于合适评分规则的不确定性的度量方法，以解决回归任务中的不确定性量化问题。

Method: 该方法基于合适的评分准则，特别是核评分，提供了一种针对总不确定、不确定成分和固有不确定的测量方法。方法还提供了设计新度量的具体设计指南，其行为特性受核的选择控制。此外，理论证明了评分特性和下游行为之间的对应关系，提供了进一步的设计指导。

Result: 实验结果表明，所提出的方法在下游任务中表现良好，并揭示了不同实现之间的权衡，包括鲁棒性和域外分布检测性能。这一结果强调了核选择对度量行为的重要性，因此也为设计符合特定任务需求的度量提供了明确的指导。

Conclusion: 基于合适评分准则的不确定性度量方法有效地解决了回归任务中的不确定性量化问题，同时提供了明确的设计指南来优化这些度量。该方法展示了核选择对度量行为的重要性，并通过实验证明了其在鲁棒性和域外分布检测中的有效性和权衡。

Abstract: Regression tasks, notably in safety-critical domains, require proper
uncertainty quantification, yet the literature remains largely
classification-focused. In this light, we introduce a family of measures for
total, aleatoric, and epistemic uncertainty based on proper scoring rules, with
a particular emphasis on kernel scores. The framework unifies several
well-known measures and provides a principled recipe for designing new ones
whose behavior, such as tail sensitivity, robustness, and out-of-distribution
responsiveness, is governed by the choice of kernel. We prove explicit
correspondences between kernel-score characteristics and downstream behavior,
yielding concrete design guidelines for task-specific measures. Extensive
experiments demonstrate that these measures are effective in downstream tasks
and reveal clear trade-offs among instantiations, including robustness and
out-of-distribution detection performance.

</details>


### [109] [INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats](https://arxiv.org/abs/2510.25602)
*Mengzhao Chen,Meng Wu,Hui Jin,Zhihang Yuan,Jing Liu,Chaoyi Zhang,Yunshui Li,Jie Huang,Jin Ma,Zeyue Xue,Zhiheng Liu,Xingyan Bin,Ping Luo*

Main category: cs.LG

TL;DR: 本文通过系统性研究，发现不同精度下的量化方法在精度和硬件效率之间的权衡，特别是在8位精细化量化格式中，MXINT8比其FP版本更优秀，但对于4位格式，FP通常有精度优势。另外，提出了一种对低比特精细化INT训练的对称截断方法，可以实现接近无损失的性能。这些发现挑战了现有的硬件发展趋势，表明单一FP做法次优，精细化INT如MXINT8提供了更好的精度、能耗和效率平衡。


<details>
  <summary>Details</summary>
Motivation: 尽管现代AI硬件倾向于使用低精度浮点格式来处理大语言模型中的激活异常值，但缺乏FP和INT量化之间系统的比较，导致算法与硬件协同设计缺乏明确指导。本文填补了这一空白，系统地研究了FP和INT格式之间的权衡，通过比较发现了精细化INT格式的优势。

Method: 系统性地调查了不同精度下量化格式之间的权衡，包括8位和4位精细化量化格式，并引入了一种对低比特精细化INT训练的对称截断方法。

Result: 发现在8位精细化量化中，MXINT8在精度和硬件效率方面优于其FP版本，但对于4位格式，FP通常具有精度优势。同时，提出了一种可以提高MXINT8训练性能的方法。

Conclusion: 精细化INT格式，特别是MXINT8，提供了更好的精度、能耗和效率平衡。这些发现挑战了单一的FP硬件轨迹，表明精细化INT格式是未来AI加速器的更优选择。

Abstract: Modern AI hardware, such as Nvidia's Blackwell architecture, is increasingly
embracing low-precision floating-point (FP) formats to handle the pervasive
activation outliers in Large Language Models (LLMs). Despite this industry
trend, a unified comparison of FP and integer (INT) quantization across varying
granularities has been missing, leaving algorithm and hardware co-design
without clear guidance. This paper fills that gap by systematically
investigating the trade-offs between FP and INT formats. We reveal a critical
performance crossover: while FP excels in coarse-grained quantization, the
comparison at fine-grained (block-wise) levels is more nuanced. Our
comprehensive comparison demonstrates that for popular 8-bit fine-grained
formats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart
in both algorithmic accuracy and hardware efficiency. However, for 4-bit
formats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we
show that NVINT4 can surpass NVFP4 when outlier-mitigation techniques like
Hadamard rotation are applied. We also introduce a symmetric clipping method
that resolves gradient bias in fine-grained low-bit INT training, enabling
nearly lossless performance for MXINT8 training. These findings challenge the
current hardware trajectory, demonstrating that a one-size-fits-all FP approach
is suboptimal and advocating that fine-grained INT formats, particularly
MXINT8, offer a better balance of accuracy, power, and efficiency for future AI
accelerators.

</details>


### [110] [Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization](https://arxiv.org/abs/2510.25616)
*Nikita Kachaev,Mikhail Kolosov,Daniil Zelezetsky,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: 本文研究了Vision-Language-Action模型在动作微调过程中视觉和语言表征保存情况，发现简单的行为微调会导致视觉表示退化，并提出了一种简单有效的方法来缓解这种退化，提高模型在分布外场景中的泛化能力。相关代码开源可访问：https://blind-vla-paper.github.io


<details>
  <summary>Details</summary>
Motivation: 分析Vision-Language-Action模型在动作微调后，原始视觉和语言表征是否被保留，探索提高模型在分布外场景中泛化能力的方法

Method: 通过探索单元、注意力图和一系列特定任务，对比Vision-Language-Action模型与原始Vision-Language模型，分析动作微调对视觉和语言能力的影响；测试不同策略对视觉表征一致性的影响并提出一个缓解算法退化的简单方法

Result: 研究表明简单的行为微调将导致视觉表示退化，提出的缓解算法退化的方法有效提高模型在分布外场景的泛化能力

Conclusion: 本文证实了动作微调对视觉和语言表征的负面影响，并提出了解决方案，强调了在动作微调过程中保持视觉和语言能力的重要性

Abstract: The growing success of Vision-Language-Action (VLA) models stems from the
promise that pretrained Vision-Language Models (VLMs) can endow agents with
transferable world knowledge and vision-language (VL) grounding, laying a
foundation for action models with broader generalization. Yet when these VLMs
are adapted to the action modality, it remains unclear to what extent their
original VL representations and knowledge are preserved. In this work, we
conduct a systematic study of representation retention during VLA fine-tuning,
showing that naive action fine-tuning leads to degradation of visual
representations. To characterize and measure these effects, we probe VLA's
hidden representations and analyze attention maps, further, we design a set of
targeted tasks and methods that contrast VLA models with their counterpart
VLMs, isolating changes in VL capabilities induced by action fine-tuning. We
further evaluate a range of strategies for aligning visual representations and
introduce a simple yet effective method that mitigates degradation and yields
improved generalization to out-of-distribution (OOD) scenarios. Taken together,
our analysis clarifies the trade-off between action fine-tuning and the
degradation of VL representations and highlights practical approaches to
recover inherited VL capabilities. Code is publicly available:
https://blind-vla-paper.github.io

</details>


### [111] [Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy](https://arxiv.org/abs/2510.25670)
*Phuc Tran,Nisheeth K. Vishnoi,Van H. Vu*

Main category: cs.LG

TL;DR: 本文研究了噪声或测量误差对机器学习中低秩逼近的影响，特别关注于谱范数，提出了一种新的高概率谱范数扰动界，改进了Eckart--Young--Mirsky定理，解决了隐私保护下的主成分分析(PCA)问题，并提供了广泛的实证验证。


<details>
  <summary>Details</summary>
Motivation: 机器学习中存在一个核心挑战，即理解噪声或测量误差如何影响低秩逼近，特别是在谱范数方面，尤其是在差异隐私低秩逼近中的问题，即在保证隐私的同时保持数据矩阵的top-$p$结构。以往的研究常常分析Frobenius范数误差或重构质量的变化，但这些度量可能会高估或低估真正的子空间偏差。因此，对于最坏情况的方向误差捕捉，使用谱范数可以提供最有力的效用保障。

Method: 本文通过对对称矩阵基矩阵 $A 	imes A$ 和对称扰动 $E$ 之间的相互作用的显式捕捉建立新的高概率谱范数扰动界，这一方法改进了传统的Eckart--Young--Mirsky定理。具体地，我们依靠复分析中的轮廓自举方法并将其推广到广泛的谱函数，如多项式和矩阵指数。分析证明了在轻度特征值差距和范数条件下，新的结果对于 $
|(A + E)_p - A_p	hinspace|$ 给出了精确估计，相较于Eckart--Young--Mirsky定理有 $
	hinspace	hinspace	hinspace n^{0.5}$ 的改进。

Result: 我们的理论结果在实际数据集上得到了验证，实验证明，在各种扰动状况下，我们的理论结果能够有效地追踪实际的谱误差。通过本研究，我们也为差异隐私PCA提出了改进的效用保障，解决了一个文献中的开放问题。

Conclusion: 第一次建立了分析谱范数扰动的新方法，提高了差异隐私环境下PCA的效用保障，并通过复分析中的方法强有力地支持了这一结果。

Abstract: A central challenge in machine learning is to understand how noise or
measurement errors affect low-rank approximations, particularly in the spectral
norm. This question is especially important in differentially private low-rank
approximation, where one aims to preserve the top-$p$ structure of a
data-derived matrix while ensuring privacy. Prior work often analyzes Frobenius
norm error or changes in reconstruction quality, but these metrics can over- or
under-estimate true subspace distortion. The spectral norm, by contrast,
captures worst-case directional error and provides the strongest utility
guarantees. We establish new high-probability spectral-norm perturbation bounds
for symmetric matrices that refine the classical Eckart--Young--Mirsky theorem
and explicitly capture interactions between a matrix $A \in \mathbb{R}^{n
\times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and
norm conditions, our bounds yield sharp estimates for $\|(A + E)_p - A_p\|$,
where $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up
to a factor of $\sqrt{n}$. As an application, we derive improved utility
guarantees for differentially private PCA, resolving an open problem in the
literature. Our analysis relies on a novel contour bootstrapping method from
complex analysis and extends it to a broad class of spectral functionals,
including polynomials and matrix exponentials. Empirical results on real-world
datasets confirm that our bounds closely track the actual spectral error under
diverse perturbation regimes.

</details>


### [112] [Synthetic Data Reveals Generalization Gaps in Correlated Multiple Instance Learning](https://arxiv.org/abs/2510.25759)
*Ethan Harvey,Dennis Johan Loevlie,Michael C. Hughes*

Main category: cs.LG

TL;DR: 本文提出了在多重实例学习（MIL）中考虑实例间上下文关系的重要性，并展示了传统MIL方法在此任务中的局限性，通过与贝叶斯最优估计比较，以及实验证明了即使在大规模数据训练下，一些新的相关MIL方法仍然无法达到最佳性能。


<details>
  <summary>Details</summary>
Motivation: 在多重实例学习（MIL）应用于医学影像分类时，传统的MIL方法忽略了实例间的上下文关系，而这些关系对于提高分类准确性至关重要。本文意图展示忽略这些关系所带来的局限性，并提出解决方案。

Method: 设计了一个合成分类任务，其中考虑邻近实例特征对于准确预测是关键的。通过量化传统MIL方法与贝叶斯最优估计者相比的性能，以及通过实验证明新相关MIL方法仍然有提升空间。

Result: 实验证明，即使在大规模数据训练下，传统MIL方法与贝叶斯最优估计相比仍然存在性能差距，新的相关MIL方法也有提升空间。

Conclusion: 考虑实例间的上下文关系对于提高预测准确性至关重要。本文证明了传统MIL方法在此方面存在局限性，指出了未来研究的方向。

Abstract: Multiple instance learning (MIL) is often used in medical imaging to classify
high-resolution 2D images by processing patches or classify 3D volumes by
processing slices. However, conventional MIL approaches treat instances
separately, ignoring contextual relationships such as the appearance of nearby
patches or slices that can be essential in real applications. We design a
synthetic classification task where accounting for adjacent instance features
is crucial for accurate prediction. We demonstrate the limitations of
off-the-shelf MIL approaches by quantifying their performance compared to the
optimal Bayes estimator for this task, which is available in closed-form. We
empirically show that newer correlated MIL methods still struggle to generalize
as well as possible when trained from scratch on tens of thousands of
instances.

</details>


### [113] [Neural Stochastic Flows: Solver-Free Modelling and Inference for SDE Solutions](https://arxiv.org/abs/2510.25769)
*Naoki Kiyohara,Edward Johns,Yingzhen Li*

Main category: cs.LG

TL;DR: 本文提出了神经随机流（NSFs）及其实例变体，无需数值求解器即可直接学习随机微分方程（SDE）的过渡法则，实现任意时间点之间的采样，并且在大时间间隔下可以提高多达两个数量级的速度。实验结果表明，NSFs的分布精度与数值方法相当，但大幅减少了计算量。


<details>
  <summary>Details</summary>
Motivation: 传统的SDE建模方法需要昂贵的数值求解器，这在采样任意时间点时会导致计算成本高昂。提出神经随机流（NSFs）是为了克服这个问题，从而实现更高效、更准确的SDE建模和采样。

Method: 作者提出了基于有条件规范化流量（Conditional Normalizing Flows）构建的神经随机流（NSFs）及其变体，这些架构设计保留了随机流的一些重要特性，允许直接学习SDE的转移法则并实现任意状态之间的采样。

Result: 相比传统方法，神经随机流（NSFs）在保持分布准确性的前提下，大大减少了采样不同时间点之间的计算复杂度和计算时间，尤其在大时间间隔情况下表现优异。实验结果显示, NSF 在合成SDE模拟和现实世界数据（如跟踪和视频数据）上都表现良好。

Conclusion: 我们的工作表明，使用Neural Stochastic Flows（NSFs）能够更高效、更准确地处理SDE的模拟和采样问题。这为进一步的研究和应用提供了新的思路。

Abstract: Stochastic differential equations (SDEs) are well suited to modelling noisy
and irregularly sampled time series found in finance, physics, and machine
learning. Traditional approaches require costly numerical solvers to sample
between arbitrary time points. We introduce Neural Stochastic Flows (NSFs) and
their latent variants, which directly learn (latent) SDE transition laws using
conditional normalising flows with architectural constraints that preserve
properties inherited from stochastic flows. This enables one-shot sampling
between arbitrary states and yields up to two orders of magnitude speed-ups at
large time gaps. Experiments on synthetic SDE simulations and on real-world
tracking and video data show that NSFs maintain distributional accuracy
comparable to numerical approaches while dramatically reducing computation for
arbitrary time-point sampling.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [114] [Scheduling Your LLM Reinforcement Learning with Reasoning Trees](https://arxiv.org/abs/2510.24832)
*Hong Wang,Zhezheng Hao,Jian Luo,Chenxing Wei,Yao Shu,Lei Liu,Qiang Lin,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: 本文提出了一种基于推理树结构的新颖排序算法Re-Schedule，用于提高RLVR（Reinforcement Learning with Verifiable Rewards）数据调度的效率和准确性。Re-Schedule通过从简单到复杂的顺序构造一个课程，提高了6个数学推理基准测试的平均精度，最高增益达3.2%。说明推理树结构理解为RLVR数据调度提供了更强大的理论基础和有效的方法。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR数据调度方法使用基于路径的指标排序查询，忽略了查询的推理树结构。旨在通过纳入查询推理树结构的难度测量，提高数据调度效率和准确性。

Method: 提出了Reasoning Score (r-score)，一种新的衡量查询学习难度的指标，基于该指标提出了Re-Schedule，一个按结构由简到繁排序查询的调度算法。

Result: 实验显示，Re-Schedule显著提高了在6个数学推理基准测试上的平均精度，最高增益达3.2%。这表明了方法的有效性。

Conclusion: 方法的理论依据及实验结果都验证了其有效性，提出的方法为RLVR数据调度提供了一种更加强大和理论基础的框架。

Abstract: Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large
Language Models (LLMs) can be conceptualized as progressively editing a query's
`Reasoning Tree'. This process involves exploring nodes (tokens) and
dynamically modifying the model's policy at each node. When combined with data
scheduling, this process yields further gains in data efficiency and accuracy.
However, existing RLVR data scheduling methods typically rely on path-based
metrics to rank queries, overlooking the reasoning tree structures of these
queries. In this paper, we introduce a novel metric, namely Reasoning Score
(r-score), which measures the query's learning difficulty based on the
structure of its reasoning tree. Based on the r-score, we propose the Reasoning
Tree Schedule (Re-Schedule), a scheduling algorithm that constructs a
curriculum progressing from structurally simple (high r-score) to complex (low
r-score) queries. Experiments on six math-reasoning benchmarks show that
Re-Schedule significantly improves average accuracy, achieving gains of up to
3.2%. These strong results validate our approach and demonstrate that a
structural understanding of the reasoning tree provides a more powerful and
principled foundation for RLVR data scheduling.

</details>


### [115] [Cyclic Counterfactuals under Shift-Scale Interventions](https://arxiv.org/abs/2510.25005)
*Saptarshi Saha,Dhruv Vansraj Rathore,Utpal Garain*

Main category: cs.AI

TL;DR: 研究在存在循环依赖的情况下，如何进行反事实推理，尤其是面对移位-缩放干预的情况，这是首次对循环结构因果模型的研究之一。


<details>
  <summary>Details</summary>
Motivation: 传统的反事实推断框架假设没有循环依赖。然而，许多现实系统包含反馈循环或循环依赖，这违反了这项假设。因此，需要研究在存在循环的情况下反事实推断的新方法，特别是移位-缩放干预情况下的反事实推断方法。

Method: 在研究中，研究者关注的是在循环结构因果模型(SCMs)中进行反事实推理，特别设计了针对移位-缩放（shift-scale）类型干预的方法。移位-缩放干预可以被看作是一种柔和的、策略型的变化，它改变了变量的机制，而不仅仅是切断因果关系。方法重点解决了如何评估在不同情境下变量机制的变化对系统产生的影响。

Result: 研究表明，即使在存在循环依赖的情况下，通过设计专门的方法来处理特定类型的干预，也能够进行有效的反事实推断。这项工作提供了一种新的框架和方法，用于处理复杂系统的反事实推理问题，尤其是那些包含反馈循环或循环依赖系统的推断问题。

Conclusion: 这一研究首次探索了在循环结构因果模型中应用反事实推理的可能性，并为后续研究复杂系统中的反事实推理问题提供了一个新的起点。

Abstract: Most counterfactual inference frameworks traditionally assume acyclic
structural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However,
many real-world systems (e.g. biological systems) contain feedback loops or
cyclic dependencies that violate acyclicity. In this work, we study
counterfactual inference in cyclic SCMs under shift-scale interventions, i.e.,
soft, policy-style changes that rescale and/or shift a variable's mechanism.

</details>


### [116] [Taming the Real-world Complexities in CPT E/M Coding with Large Language Models](https://arxiv.org/abs/2510.25007)
*Islam Nassar,Yang Lin,Yuan Jin,Rongxin Zhu,Chang Wei Tan,Zenan Zhai,Nitika Mathur,Thanh Tien Vu,Xu Zhong,Long Duong,Yuan-Fang Li*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLM的框架ProFees，用于自动化E/M编码任务，与商用系统相比，其编码准确率提高了超过36%，证明了其在处理现实世界复杂性中的有效性。


<details>
  <summary>Details</summary>
Motivation: E/M编码任务繁重，不利于医生减轻文档负担和提高工作效率。自动化编码可以解决这一问题。但是实际中存在的复杂情况使该任务具有挑战性。ProFees框架正是要解决这些问题。

Method: 创建了一个基于LLM的框架ProFees来自动化处理E/M编码。并对该框架进行了系统的评估。使用专家维护的现实世界数据集进行测试，该数据集更难处理。

Result: 在专家维护的现实世界数据集上，ProFees的准确性比商用CPT E/M编码系统增加了超过36%，并且比我们最强的单提示基线高出接近5%。这个结果展示了ProFees在处理复杂性方面的有效性。

Conclusion: 自动化E/M编码能够帮助医生们减少文档负担，提高效率，最终提高病人护理质量。ProFees框架通过解决现实世界的复杂性，极大地提高了E/M编码的准确性。

Abstract: Evaluation and Management (E/M) coding, under the Current Procedural
Terminology (CPT) taxonomy, documents medical services provided to patients by
physicians. Used primarily for billing purposes, it is in physicians' best
interest to provide accurate CPT E/M codes. %While important, it is an
auxiliary task that adds to physicians' documentation burden. Automating this
coding task will help alleviate physicians' documentation burden, improve
billing efficiency, and ultimately enable better patient care. However, a
number of real-world complexities have made E/M encoding automation a
challenging task. In this paper, we elaborate some of the key complexities and
present ProFees, our LLM-based framework that tackles them, followed by a
systematic evaluation. On an expert-curated real-world dataset, ProFees
achieves an increase in coding accuracy of more than 36\% over a commercial CPT
E/M coding system and almost 5\% over our strongest single-prompt baseline,
demonstrating its effectiveness in addressing the real-world complexities.

</details>


### [117] [Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading](https://arxiv.org/abs/2510.25014)
*Minkyung Kim,Junsik Kim,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: 介绍了一种名为ASTP的方法，以解决大语言模型在规则导向的交易系统中无法遵循程序流程的问题。ASTP通过一种策略性的提示，使模型的追踪过程显式化和可验证，保证交易的透明度和准确性。实验结果表明其可以达到99%的状态合规性和99.3%的计算精度。在小型模型上实现与大型模型同等性能，同时大幅减少响应时间。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在规则导向的交易系统中的创意灵活性与程序需求之间的矛盾，特别是在保障玩家信任的前提下实现可靠的交易流程。

Method: 提出了一种名为ASTP的方法，该方法使用一种策略性提示，要求模型在每个对话回合中识别并报告预定义的状态标签。通过这种方式，模型的追踪过程变得显式且可验证。此外，还引入了一种特定状态的占位符后处理方法以确保价格计算的准确性。

Result: 实验结果展示了ASTP在300个交易对话中的状态合规率为>99%，计算精度为99.3%。并且在较小模型上实现了与较大模型相当的表现，同时响应时间从21.2秒减少到2.4秒。这表明ASTP可以满足实时要求和资源限制的商业游戏需求。

Conclusion: ASTP方法以其在保持模型创意灵活性的同时，实现了游戏交易规则的严格执行和高度准确性，牢牢捍卫了玩家信任。

Abstract: Large Language Models (LLMs) enable dynamic game interactions but fail to
follow essential procedural flows in rule-governed trading systems, eroding
player trust. This work resolves the core tension between the creative
flexibility of LLMs and the procedural demands of in-game trading
(browse-offer-review-confirm). To this end, Autoregressive State-Tracking
Prompting (ASTP) is introduced, a methodology centered on a strategically
orchestrated prompt that compels an LLM to make its state-tracking process
explicit and verifiable. Instead of relying on implicit contextual
understanding, ASTP tasks the LLM with identifying and reporting a predefined
state label from the previous turn. To ensure transactional integrity, this is
complemented by a state-specific placeholder post-processing method for
accurate price calculations. Evaluation across 300 trading dialogues
demonstrates >99% state compliance and 99.3% calculation precision. Notably,
ASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash)
matches larger models' (Gemini-2.5-Pro) performance while reducing response
time from 21.2s to 2.4s, establishing a practical foundation that satisfies
both real-time requirements and resource constraints of commercial games.

</details>


### [118] [Reasoning-Aware GRPO using Process Mining](https://arxiv.org/abs/2510.25065)
*Taekhyun Park,Yongjae Lee,Hyerim Bae*

Main category: cs.AI

TL;DR: 提出了一种基于过程挖掘的推理感知群体相对策略优化（PM4GRPO）方法，通过增加对推理过程的奖励信号来改进标准答案/格式的奖励，从而有效增强了策略模型的推理能力。实验结果表明，PM4GRPO在五个基准测试上显著优于现有的GRPO后训练方法。


<details>
  <summary>Details</summary>
Motivation: 当前的强化学习后训练方法主要聚焦于结果，而忽略了推理过程本身的质量。作者旨在通过引入新的奖励机制，增强模型的推理能力，尤其是多步推理的能力。

Method: 通过利用过程挖掘技术计算一个标量符合理性度量，来评估策略模型的推理过程与预训练教师模型的符合程度。这种方法将奖励信号引入推理过程中，以促进更好的多步推理能力。

Result: 实验结果显示，PM4GRPO在五个基准测试中显著优于现有的GRPO后训练方法。这证明了过程挖掘在推理感知GRPO中的有效性。

Conclusion: 充分利用过程挖掘技术，可以有效提高策略模型的多步推理能力。这项工作为基于学习和推理的决策制定提供了一种新的方法。

Abstract: Reinforcement learning (RL)-based post-training has been crucial for enabling
multi-step reasoning in large reasoning models (LRMs), yet current reward
schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware
Group Relative Policy Optimization (GRPO) that augments standard answer/format
rewards with signals over the reasoning procedure. To this end, process mining
techniques are utilized to compute a scalar conformance reward that measures
how closely a policy model's reasoning aligns with the pretrained teacher
model. The empirical results on five benchmarks demonstrate that PM4GRPO
significantly outperforms existing methodologies for GRPO-based post-training.
These results highlight that leveraging process mining for reasoning-aware GRPO
effectively enhances the reasoning capabilities of policy models.

</details>


### [119] [Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision](https://arxiv.org/abs/2510.25205)
*Yuyang Xia,Zibo Liang,Liwei Deng,Yan Zhao,Han Su,Kai Zheng*

Main category: cs.AI

TL;DR: 提出了一个自适应感知和鲁棒决策模块相结合的节能自动驾驶框架EneAD，通过数据管理和调优策略，以及基于贝叶斯优化的转移动态调优方法，减少感知能耗，同时保持准确性。通过轻量级分类模型适应性场景切换以及增强决策稳定性，实验表明EneAD能有效降低能耗，提升驾驶性能和范围，最多能改进驾驶范围8.5%。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的发展，能量消耗问题逐渐成为影响行驶距离的关键因素，尤其是对电动车而言。由于感知计算往往是最耗能的部分，此研究希望通过优化策略减少能耗并保持感知准确性，提高自动驾驶车辆的行驶范围和性能

Method: 提出EneAD框架，包含自适应感知模块和鲁棒决策模块。自适应感知模块通过管理不同计算消耗的感知模型和基于贝叶斯优化的动态调优方法来降低能耗，同时保持准确性；鲁棒决策模块采用增强学习方法，通过设计正则化项来增强驾驶稳定性。此外，引入轻量级分类模型来适应性切换场景感知难度。

Result: 实验结果表明，EneAD框架能显著减少感知能耗，并提高自动驾驶的行驶范围，最多可将行驶距离提高8.5%，同时保持优异的驾驶性能

Conclusion: EneAD通过智能管理感知模型，合理降低能耗，提升电力汽车的能量效率和行驶距离。未来的工作可能在于进一步提升决策模块的稳定性和有效性。

Abstract: Autonomous driving is an emerging technology that is expected to bring
significant social, economic, and environmental benefits. However, these
benefits come with rising energy consumption by computation engines, limiting
the driving range of vehicles, especially electric ones. Perception computing
is typically the most power-intensive component, as it relies on largescale
deep learning models to extract environmental features. Recently, numerous
studies have employed model compression techniques, such as sparsification,
quantization, and distillation, to reduce computational consumption. However,
these methods often result in either a substantial model size or a significant
drop in perception accuracy compared to high-computation models. To address
these challenges, we propose an energy-efficient autonomous driving framework,
called EneAD. In the adaptive perception module, a perception optimization
strategy is designed from the perspective of data management and tuning.
Firstly, we manage multiple perception models with different computational
consumption and adjust the execution framerate dynamically. Then, we define
them as knobs and design a transferable tuning method based on Bayesian
optimization to identify promising knob values that achieve low computation
while maintaining desired accuracy. To adaptively switch the knob values in
various traffic scenarios, a lightweight classification model is proposed to
distinguish the perception difficulty in different scenarios. In the robust
decision module, we propose a decision model based on reinforcement learning
and design a regularization term to enhance driving stability in the face of
perturbed perception results. Extensive experiments evidence the superiority of
our framework in both energy consumption and driving performance. EneAD can
reduce perception consumption by 1.9x to 3.5x and thus improve driving range by
3.9% to 8.5%

</details>


### [120] [RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models](https://arxiv.org/abs/2510.25206)
*Tianqianjin Lin,Xi Zhao,Xingyao Zhang,Rujiao Long,Yi Xu,Zhuoren Jiang,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: 通过参考答案引导变换式推理（RAVR），大大提高了语言模型对复杂问题的推理能力


<details>
  <summary>Details</summary>
Motivation: 受到认知科学的启发，利用为什么这是答案相对于直接给出答案更易于处理的特点，从而减轻了语言模型的推理负担

Method: 提出了RAVR框架，该框架利用答案导向的推理作为问题引导推理的变分替代方法

Result: 实验结果表明，RAVR框架在提升语言模型推理质量和效率方面优于现有的基准方法

Conclusion: 提出了一种新的方法，即RAVR框架，该框架通过利用答案来提高语言模型推理任务的质量和效率

Abstract: Reinforcement learning (RL) can refine the reasoning abilities of large
language models (LLMs), but critically depends on a key prerequisite: the LLM
can already generate high-utility reasoning paths with non-negligible
probability. For tasks beyond the LLM's current competence, such reasoning path
can be hard to sample, and learning risks reinforcing familiar but suboptimal
reasoning. We are motivated by the insight from cognitive science that Why is
this the answer is often an easier question than What is the answer, as it
avoids the heavy cognitive load of open-ended exploration, opting instead for
explanatory reconstruction-systematically retracing the reasoning that links a
question to its answer. We show that LLMs can similarly leverage answers to
derive high-quality reasoning paths. We formalize this phenomenon and prove
that conditioning on answer provably increases the expected utility of sampled
reasoning paths, thereby transforming intractable problems into learnable ones.
Building on this insight, we introduce RAVR (Reference-Answer-guided
Variational Reasoning), an end-to-end framework that uses answer-conditioned
reasoning as a variational surrogate for question-only reasoning. Experiments
in both general and math domains demonstrate consistent improvements over
strong baselines. We further analyze the reasoning behavior and find that RAVR
reduces hesitation, strengthens conclusion consolidation, and promotes
problem-specific strategies in reasoning.

</details>


### [121] [GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning](https://arxiv.org/abs/2510.25320)
*Jiaqi Wu,Qinlao Zhao,Zefeng Chen,Kai Qin,Yifei Zhao,Xueqian Wang,Yuhang Yao*

Main category: cs.AI

TL;DR: 提出了一种基于图的智能体规划（GAP）框架，该框架通过图规划明确建模任务依赖关系，以实现工具的自适应平行和串行执行，从而提高复杂任务的执行效率和准确性。实验表明，GAP相比传统的ReAct方法，在多步骤检索任务上表现出更优越的性能，同时通过智能并行化显著提升了工具调用效率。


<details>
  <summary>Details</summary>
Motivation: 现有利用大型语言模型（LLMs）的自主智能体在复杂任务解决中的工具操作展现了出色能力，但这些方法（如ReAct）依赖于序列推理和执行，未能充分利用独立子任务之间的固有并行性。这种序贯瓶颈导致了多步推理场景下工具利用率低和次优性能，因此提出了一种新的框架来解决这些问题。

Method: 介绍了一种新的框架Graph-based Agent Planning (GAP)，通过图规划明确建模任务依赖关系，使智能体模型能够自适应地确定哪些工具可以在并行执行，哪些必须遵循序列依赖关系，从而实现平行和串行工具执行。这个框架首先构建了一个基于MHQA基准的高质量图规划跟踪数据集，然后通过监督微调和基于正确性的奖励函数的强化学习策略来训练。

Result: 实验结果表明，GAP框架在MHQA数据集上显著优于传统的ReAct基准，在多步骤检索任务上表现出更优越的性能，同时通过智能并行化显著提高了工具调用效率。

Conclusion: GAP通过基于图的规划和依赖意识的工具执行，不仅提高了任务完成的效率和准确性，还展示了在复杂任务解决中利用大型语言模型的强大潜力。

Abstract: Autonomous agents powered by large language models (LLMs) have shown
impressive capabilities in tool manipulation for complex task-solving. However,
existing paradigms such as ReAct rely on sequential reasoning and execution,
failing to exploit the inherent parallelism among independent sub-tasks. This
sequential bottleneck leads to inefficient tool utilization and suboptimal
performance in multi-step reasoning scenarios. We introduce Graph-based Agent
Planning (GAP), a novel framework that explicitly models inter-task
dependencies through graph-based planning to enable adaptive parallel and
serial tool execution. Our approach trains agent foundation models to decompose
complex tasks into dependency-aware sub-task graphs, autonomously determining
which tools can be executed in parallel and which must follow sequential
dependencies. This dependency-aware orchestration achieves substantial
improvements in both execution efficiency and task accuracy. To train GAP, we
construct a high-quality dataset of graph-based planning traces derived from
the Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage
training strategy: supervised fine-tuning (SFT) on the curated dataset,
followed by reinforcement learning (RL) with a correctness-based reward
function on strategically sampled queries where tool-based reasoning provides
maximum value. Experimental results on MHQA datasets demonstrate that GAP
significantly outperforms traditional ReAct baselines, particularly on
multi-step retrieval tasks, while achieving dramatic improvements in tool
invocation efficiency through intelligent parallelization. The project page is
available at: https://github.com/WJQ7777/Graph-Agent-Planning.

</details>


### [122] [Grouping Nodes With Known Value Differences: A Lossless UCT-based Abstraction Algorithm](https://arxiv.org/abs/2510.25388)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 本文提出了一种名为KVDA-UCT的新方法，用于改进蒙特卡洛树搜索（MCTS）的抽样效率。与现有方法相比，KVDA-UCT能够检测更多抽象，改进搜索策略，而无需引入额外参数，并且在多个确定性环境中和参数设置上表现优于OGA-UCT。


<details>
  <summary>Details</summary>
Motivation: 当前MCTS方法的样本效率依赖于状态和动作对的价值等价条件，该条件限制了可以找到的抽象数量，进而限制了样本效率。本文旨在通过放宽此条件来提高MCTS的样本效率。

Method: 引入名为KVDA-UCT的新框架，它不仅限于价值等价状态或状态动作对，而且允许基于值差异进行分组，同时分析即时奖励来推理这些值差异，并优化OGA-UCT以使用此新框架。

Result: 相比于OGA-UCT，KVDA-UCT检测到更多的抽象，无需额外参数，并在多种环境和参数设置下表现出色。

Conclusion: KVDA-UCT展示了通过放松价值等价假设来提高MCTS抽样效率的可能性。未来的研究可以进一步探索此方向以优化搜索算法。

Abstract: A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency,
which can be improved by grouping state-action pairs and using their aggregate
statistics instead of single-node statistics. On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS
abstraction algorithm for deterministic environments that builds its
abstraction using the Abstractions of State-Action Pairs (ASAP) framework,
which aims to detect states and state-action pairs with the same value under
optimal play by analysing the search graph. ASAP, however, requires two
state-action pairs to have the same immediate reward, which is a rigid
condition that limits the number of abstractions that can be found and thereby
the sample efficiency. In this paper, we break with the paradigm of grouping
value-equivalent states or state-action pairs and instead group states and
state-action pairs with possibly different values as long as the difference
between their values can be inferred. We call this abstraction framework Known
Value Difference Abstractions (KVDA), which infers the value differences by
analysis of the immediate rewards and modifies OGA-UCT to use this framework
instead. The modification is called KVDA-UCT, which detects significantly more
abstractions than OGA-UCT, introduces no additional parameter, and outperforms
OGA-UCT on a variety of deterministic environments and parameter settings.

</details>


### [123] [Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?](https://arxiv.org/abs/2510.25471)
*Willem Fourie*

Main category: cs.AI

TL;DR: 本文提出了一种替代的观点，将先进AI系统的所谓‘工具性目标’（如寻求权力和自我保护）视为其构成的必然结果，而不是设计意图的意外偏差。从而建议重新思考对这些目标的应对策略，不应仅仅试图消除这些目标，而应该理解、管理和引导它们来实现人类一致的目的是恰当的措施。


<details>
  <summary>Details</summary>
Motivation: 传统的对齐理论将工具性目标视为风险源，并尝试限制其症状，如资源获取和自我保护。然而，这些目标可能更像先进AI系统构成的必然结果，而不是意外故障。因此，设计一种新的理解方式和应对策略是很有必要的。

Method: 使用亚里士多德的本体论对先进AI系统的工具性目标做哲学性的探讨，将其视为其构作成分的作用结果，而不是意外故障。从而提出了一个更合理的理解工具性目标的方法论框架。

Result: 论证了将先进AI系统的工具性目标视为其组成成分的结果而非设计偏差可以更好地理解和管理这些目标。

Conclusion: 与以前的方法不同，我们应该接受并管理工具性目标，而非试图消除它们。这将能更好地促进人与AI之间的目标一致。

Abstract: In artificial intelligence (AI) alignment research, instrumental goals, also
called instrumental subgoals or instrumental convergent goals, are widely
associated with advanced AI systems. These goals, which include tendencies such
as power-seeking and self-preservation, become problematic when they conflict
with human aims. Conventional alignment theory treats instrumental goals as
sources of risk that become problematic through failure modes such as reward
hacking or goal misgeneralization, and attempts to limit the symptoms of
instrumental goals, notably resource acquisition and self-preservation. This
article proposes an alternative framing: that a philosophical argument can be
constructed according to which instrumental goals may be understood as features
to be accepted and managed rather than failures to be limited. Drawing on
Aristotle's ontology and its modern interpretations, an ontology of concrete,
goal-directed entities, it argues that advanced AI systems can be seen as
artifacts whose formal and material constitution gives rise to effects distinct
from their designers' intentions. In this view, the instrumental tendencies of
such systems correspond to per se outcomes of their constitution rather than
accidental malfunctions. The implication is that efforts should focus less on
eliminating instrumental goals and more on understanding, managing, and
directing them toward human-aligned ends.

</details>


### [124] [Multi-Objective Search: Algorithms, Applications, and Emerging Directions](https://arxiv.org/abs/2510.25504)
*Oren Salzman,Carlos Hernández Ulloa,Ariel Felner,Sven Koenig*

Main category: cs.AI

TL;DR: 多目标搜索（MOS）作为一种统一框架在规划和决策问题中崭露头角，尤其是在AI应用如机器人、交通和运作研究领域，这些领域往往需要平衡多个相互冲突的指标。本文综述了MOS的发展，突出了跨学科的机会，并概述了开放性的挑战，这些挑战定义了MOS的前沿领域。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中，系统很少只优化单一指标，而是需要平衡多个指标，在AI应用中尤其如此。多目标搜索提供了一种优化多个冲突目标的框架，这促进了该领域的研究兴趣。因此，有必要对该领域的发展和挑战进行综述，以推动跨学科研究。

Method: 本文综述了多目标搜索的发展，并概述了跨学科应用的机会和开放性挑战。并不涉及具体的实验或算法方法。

Result: 文中总结了多目标搜索在不同领域的应用与研究情况，指出了该领域未来的研究方向，并强调了跨学科研究的重要性。但并没有具体的实验结果。

Conclusion: 多目标搜索是一个充满潜力和挑战的领域，其不断发展能促进新应用的开发，并为跨学科合作提供了机会。未来的研究需要更多的跨学科合作以解决未解决的问题。

Abstract: Multi-objective search (MOS) has emerged as a unifying framework for planning
and decision-making problems where multiple, often conflicting, criteria must
be balanced. While the problem has been studied for decades, recent years have
seen renewed interest in the topic across AI applications such as robotics,
transportation, and operations research, reflecting the reality that real-world
systems rarely optimize a single measure. This paper surveys developments in
MOS while highlighting cross-disciplinary opportunities, and outlines open
challenges that define the emerging frontier of MOS

</details>


### [125] [MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL](https://arxiv.org/abs/2510.25510)
*Zekun Xu,Siyu Xia,Chuhuai Yue,Jiajun Chai,Mingxue Tian,Xiaohan Wang,Wei Lin,Haoxuan Li,Guojun Yin*

Main category: cs.AI

TL;DR: MTIR-SQL是一种新的多轮工具集成推理增强学习框架，用于Text-to-SQL任务，通过在每一步引入数据库执行反馈，增强了模型的适应性和鲁棒性，实验结果表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前大多数Text-to-SQL任务中的强化学习方法依赖于静态执行反馈，这限制了实时错误纠正的能力。为此，提出了一种新的方法来解决这一问题，即MTIR-SQL框架。它的主要动机是提高模型在不同输入下的稳定性和适应性，同时纠正最大化地减少错误，提高准确性。

Method: MTIR-SQL框架引入了执行感知的多轮推理范式，它在每次推理步骤中无缝集成了数据库的执行反馈。此外，该方法还改进了GRPO算法，使其更适合处理复杂的多轮交互场景，并通过引入轨迹过滤机制和消除KL散度约束来提高训练的稳定性。

Result: 实验结果表明，MTIR-SQL框架在BIRD和SPIDER数据集上分别达到了64.4%和84.6%的准确性，明显优于现有的其他方法。这证明其方法的有效性和优越性。

Conclusion: MTIR-SQL框架展示了其在处理Text-to-SQL任务时具有显著的能力和优越性，特别是在复杂的交互场景中。该框架通过引入执行反馈和改进算法训练的稳定性，提高了模型的性能。

Abstract: As large language models (LLMs) are increasingly used in Text-to-SQL tasks,
Reinforcement Learning (RL) has become a common method for improving
performance. Existing methods primarily rely on static execution feedback,
which restricts real-time error correction. However, integrating multi-turn
tool invocation along with dynamic feedback could significantly improve
adaptability and robustness, ultimately enhancing model performance. To address
these issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated
Reasoning reinforcement learning framework for Text-to-SQL. Our approach
introduces an execution-aware multi-turn reasoning paradigm that seamlessly
incorporates database execution feedback at each reasoning step, enabling
context-sensitive query generation and progressive refinement throughout the
reasoning process. The framework extends the GRPO algorithm to accommodate
complex multi-turn interaction scenarios. Considering the training instability
characteristics of MTIR and the potential for significant Deviation of model
distribution from the initial model, we enhance the GRPO algorithm by adding a
trajectory filtering mechanism and removing KL loss constraints. Experimental
results demonstrate that MTIR-SQL, with 4B parameters, achieves \textbf{64.4}\%
accuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev,
significantly outperforming existing approaches.

</details>


### [126] [Predicate Renaming via Large Language Models](https://arxiv.org/abs/2510.25517)
*Elisabetta Gentili,Tony Ribeiro,Fabrizio Riguzzi,Katsumi Inoue*

Main category: cs.AI

TL;DR: 本文探讨了使用大型语言模型（LLMs）为逻辑规则中的谓词命名的问题，以提高逻辑理论的可读性、可解释性和重用性。通过在手工制作的逻辑规则上进行评估，表明LLMs对此任务具有潜力。


<details>
  <summary>Details</summary>
Motivation: 在归纳逻辑编程领域，规则生成方法会产生包含未命名谓词的规则，这阻碍了逻辑理论的可读性、可解释性和重用性。因此，本文利用大型语言模型（LLMs）来为这些谓词命名。

Method: 通过利用LLMs处理自然语言和代码的能力，提出了一种为未命名谓词提供有意义命名建议的方法。

Result: 实验评估表明，LLMs在为逻辑规则中的谓词命名方面显示出潜力。

Conclusion: 本研究表明LLMs能够为逻辑规则中的谓词提供有意义的命名，从而改善逻辑理论的属性，LLMs为解决这一问题提供了可能的途径。

Abstract: In this paper, we address the problem of giving names to predicates in logic
rules using Large Language Models (LLMs). In the context of Inductive Logic
Programming, various rule generation methods produce rules containing unnamed
predicates, with Predicate Invention being a key example. This hinders the
readability, interpretability, and reusability of the logic theory. Leveraging
recent advancements in LLMs development, we explore their ability to process
natural language and code to provide semantically meaningful suggestions for
giving a name to unnamed predicates. The evaluation of our approach on some
hand-crafted logic rules indicates that LLMs hold potential for this task.

</details>


### [127] [Zero Reinforcement Learning Towards General Domains](https://arxiv.org/abs/2510.25528)
*Yuyuan Zeng,Yufei Huang,Can Xu,Qingfeng Sun,Jianfeng Yan,Guanghui Xu,Tao Yang,Fengzong Lian*

Main category: cs.AI

TL;DR: 本文提出了一种新的零增强学习（Zero-RL）范式，旨在提升大型语言模型在可验证和不可验证领域的推理能力。通过结合可验证奖励和生成式奖励模型进行多任务训练，实现了跨领域的推理能力转移，并通过平滑长度惩罚减少了奖励劫持现象。该方法在特定模型上的实验显示，在需要深度推理和更通用的任务中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 目前的零增强学习研究主要集中在具有易于验证奖励信号的领域，对于那些验证不那么直接的多样化场景中的推理能力提升问题关注较少。本文旨在填补这一空白，提出了一种新的零增强学习方法，以提升模型在更广泛的场景中的推理能力。

Method: 结合可验证奖励和生成式奖励模型，进行跨可验证和非可验证任务的多任务零增强学习训练，实现了推理能力的跨领域转移。同时，设计了平滑长度惩罚机制，以减少训练过程中可能出现的奖励劫持现象。

Result: 实验表明，该方法不仅在需要深度推理的任务中表现出色，还在更通用的任务中表现优异。该方法在Qwen3-8B-Base和Qwen3-14B-Base上的测试中，表现出了显著的推理性能提升。

Conclusion: 通过提出一种新的零增强学习方法，本文成功扩展了大型语言模型的推理能力，使其能够更好地处理更多样化的任务场景，从而拓展了零增强学习的应用范围。

Abstract: Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach
for enhancing the reasoning capabilities of large language models (LLMs) by
directly applying reinforcement learning with verifiable rewards on pretrained
models, without the need for a supervised fine-tuning phase. However, current
research on zero-RL primarily focuses on domains with easily verifiable reward
signals, such as mathematics, programming, and other reasoning tasks. The
challenge of eliciting reasoning abilities in more diverse scenarios, where
verification is not straightforward, remains underexplored. To address this
gap, we propose a novel zero-RL paradigm designed to improve a model's
reasoning ability across both verifiable and non-verifiable domains. By
combining verifiable rewards with a generative reward model, we conduct
multi-task zero-RL training across both domains, facilitating the transfer of
reasoning capabilities between them. Furthermore, to mitigate reward hacking in
the generative reward model, we design a smooth length penalty that encourages
the generation of more comprehensive thinking tokens in general domains.
Experimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our
approach achieves superior reasoning performance, not only on tasks requiring
extensive reasoning but also on more general tasks.

</details>


### [128] [Off-policy Reinforcement Learning with Model-based Exploration Augmentation](https://arxiv.org/abs/2510.25529)
*Likun Wang,Xiangteng Zhang,Yinuo Wang,Guojian Zhan,Wenxuan Wang,Haoyu Gao,Jingliang Duan,Shengbo Eben Li*

Main category: cs.AI

TL;DR: 提出了一种新的增强学习探索方法Modelic Generative Exploration (MoGE)，通过生成高潜力的状态和动态一致的经验来提高探索效率。这种方法通过对关键状态和转换的合成，改进了现有探索方法（特别是被动探索）的限制，提高了探索效率和学习性能。实验结果在OpenAI Gym和DeepMind Control Suite中显示了显著优势。


<details>
  <summary>Details</summary>
Motivation: 现有探索方法在高维环境下难以引入随机性，且被动探索受限于样本多样性。MoGE旨在通过生成关键状态和动态一致的经验来提高探索效率，以解决这些限制。

Method: MoGE包括一个基于扩散的生成器和一个想象世界模型。生成器合成关键状态，世界模型重建关键转换。该方法采用模块化形式，以适应离策略学习的基本原理，能够无缝整合到现有算法中。

Result: 实验表明，MoGE显著改善了样本效率和性能，适用于复杂的控制任务。它在OpenAI Gym和DeepMind Control Suite上都取得了显著的成效。

Conclusion: MoGE通过生成关键状态和动态一致的经验增强了探索效率，提高了离策略学习算法在复杂控制任务中的表现。

Abstract: Exploration is fundamental to reinforcement learning (RL), as it determines
how effectively an agent discovers and exploits the underlying structure of its
environment to achieve optimal performance. Existing exploration methods
generally fall into two categories: active exploration and passive exploration.
The former introduces stochasticity into the policy but struggles in
high-dimensional environments, while the latter adaptively prioritizes
transitions in the replay buffer to enhance exploration, yet remains
constrained by limited sample diversity. To address the limitation in passive
exploration, we propose Modelic Generative Exploration (MoGE), which augments
exploration through the generation of under-explored critical states and
synthesis of dynamics-consistent experiences through transition models. MoGE is
composed of two components: (1) a diffusion-based generator that synthesizes
critical states under the guidance of a utility function evaluating each
state's potential influence on policy exploration, and (2) a one-step
imagination world model for constructing critical transitions based on the
critical states for agent learning. Our method adopts a modular formulation
that aligns with the principles of off-policy learning, allowing seamless
integration with existing algorithms to improve exploration without altering
their core structures. Empirical results on OpenAI Gym and DeepMind Control
Suite reveal that MoGE effectively bridges exploration and policy learning,
leading to remarkable gains in both sample efficiency and performance across
complex control tasks.

</details>


### [129] [ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents](https://arxiv.org/abs/2510.25668)
*Tianyu Yang,Terry Ruas,Yijun Tian,Jan Philip Wahle,Daniel Kurzawe,Bela Gipp*

Main category: cs.AI

TL;DR: ALDEN 是一个多回合强化学习框架，通过主动导航长文档来提升视觉-语言模型的性能，采用了新颖的fetch动作和规则化跨层级奖励策略以及视觉语义锚定机制，提高了模型的训练稳定性和有效性，在五个长文档基准上表现最优。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长且复杂的文档时依赖固定的推理模板或刚性的流水线，导致模型效率低下且泛化能力不足。ALDEN旨在使VLMs作为互动智能体，自动导航和理解长文档，提高模型的效率和准确性。

Method: ALDEN基于多回合强化学习，引入fetch动作主动访问页面，使用规则化跨层级奖励策略进行密集过程监督，并提出了视觉语义锚定机制，稳定训练过程。

Result: ALDEN在五个长文档基准测试中表现出色，展示了优于现有被动阅读模型的理解能力和准确性。

Conclusion: ALDEN的发展使我们能够创建能够导航和理解长而复杂的文档的智能体，向更准确和有效理解长文档迈进了一步。

Abstract: Vision-language models (VLMs) excel at interpreting text-rich images but
struggle with long, visually complex documents that demand analysis and
integration of information spread across multiple pages. Existing approaches
typically rely on fixed reasoning templates or rigid pipelines, which force
VLMs into a passive role and hinder both efficiency and generalization. We
present Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement
learning framework that fine-tunes VLMs as interactive agents capable of
actively navigating long, visually rich documents. ALDEN introduces a novel
fetch action that directly accesses the page by index, complementing the
classic search action and better exploiting document structure. For dense
process supervision and efficient training, we propose a rule-based cross-level
reward that provides both turn- and token-level signals. To address the
empirically observed training instability caused by numerous visual tokens from
long documents, we further propose a visual-semantic anchoring mechanism that
applies a dual-path KL-divergence constraint to stabilize visual and textual
representations separately during training. Trained on a corpus constructed
from three open-source datasets, ALDEN achieves state-of-the-art performance on
five long-document benchmarks. Overall, ALDEN marks a step beyond passive
document reading toward agents that autonomously navigate and reason across
long, visually rich documents, offering a robust path to more accurate and
efficient long-document understanding.

</details>


### [130] [BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph](https://arxiv.org/abs/2510.25724)
*Vanya Arikutharam,Arkadiy Ukolov*

Main category: cs.AI

TL;DR: BambooKG是一个利用频率权重连接增强的新型知识图谱，解决了传统知识图谱在处理非三元组结构信息时的丢失问题，提高了单跳和多跳推理的表现


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成模型在处理跨文档的多跳或关系推理时存在困难，而传统的知识图谱也无法有效捕捉所有非三元组结构的信息。为解决这些问题，引入了BambooKG

Method: BambooKG通过在非三元组的连接上应用基于频率的权重来增强传统知识图谱，这种增强符合Hebbian原理，即'一起放电，相互连线'，这样可以减少信息丢失

Result: BambooKG在单跳和多跳推理任务上均表现出色，超过了现有解决方案

Conclusion: BambooKG通过频率权重连接有效地解决了传统知识图谱的信息丢失问题，增强了LLM的信息访问能力

Abstract: Retrieval-Augmented Generation allows LLMs to access external knowledge,
reducing hallucinations and ageing-data issues. However, it treats retrieved
chunks independently and struggles with multi-hop or relational reasoning,
especially across documents. Knowledge graphs enhance this by capturing the
relationships between entities using triplets, enabling structured, multi-chunk
reasoning. However, these tend to miss information that fails to conform to the
triplet structure. We introduce BambooKG, a knowledge graph with
frequency-based weights on non-triplet edges which reflect link strength,
drawing on the Hebbian principle of "fire together, wire together". This
decreases information loss and results in improved performance on single- and
multi-hop reasoning, outperforming the existing solutions.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [131] [DMVFC: Deep Learning Based Functionally Consistent Tractography Fiber Clustering Using Multimodal Diffusion MRI and Functional MRI](https://arxiv.org/abs/2510.24770)
*Bocheng Guo,Jin Wang,Yijie Li,Junyi Wang,Mingyu Gao,Puming Feng,Yuqian Chen,Jarrett Rushmore,Nikos Makris,Yogesh Rathi,Lauren J O'Donnell,Fan Zhang*

Main category: eess.IV

TL;DR: 提出了一种新的深度学习纤维聚类框架——Deep Multi-view Fiber Clustering (DMVFC)，利用联合的多模态dMRI和fMRI数据，进行功能一致性白质分割。DMVFC可以有效地整合白质纤维的几何和微观结构特性与纤维道上的fMRI BOLD信号。DMVFC包括两个主要部分：一个多视角预训练模块，从每种信息源单独计算嵌入特征；一个协作微调模块，同时精确嵌入差异。实验表明，DMVFC在获得有意义且一致的白质分割结果方面优于两种最先进的纤维聚类方法。


<details>
  <summary>Details</summary>
Motivation: 现有纤维聚类策略主要使用纤维几何特性分组，而忽略了纤维道的功能和微观结构信息。本研究旨在发展一种新的策略，利用功能性MRI（fMRI）测量神经活动，同时使用扩散MRI（dMRI）计算的微观结构特性（如FA分数各向异性）来增强纤维聚类的功能和解剖连贯性。

Method: 创新性地开发了利用dMRI和fMRI数据的Deep Multi-view Fiber Clustering (DMVFC)，引入了两个主要部分：一个多视角预训练模块和一个协作微调模块，以实现功能一致的白质分割。

Result: 在实验比较中，DMVFC在获得功能有意义且一致的白质分割结果方面表现优于两种最先进的纤维聚类方法。

Conclusion: 该研究通过DMVFC框架成功地实现了白质的精确分割，该框架集成功能和解剖信息，显著提高了纤维聚类的性能。

Abstract: Tractography fiber clustering using diffusion MRI (dMRI) is a crucial method
for white matter (WM) parcellation to enable analysis of brains structural
connectivity in health and disease. Current fiber clustering strategies
primarily use the fiber geometric characteristics (i.e., the spatial
trajectories) to group similar fibers into clusters, while neglecting the
functional and microstructural information of the fiber tracts. There is
increasing evidence that neural activity in the WM can be measured using
functional MRI (fMRI), providing potentially valuable multimodal information
for fiber clustering to enhance its functional coherence. Furthermore,
microstructural features such as fractional anisotropy (FA) can be computed
from dMRI as additional information to ensure the anatomical coherence of the
clusters. In this paper, we develop a novel deep learning fiber clustering
framework, namely Deep Multi-view Fiber Clustering (DMVFC), which uses joint
multi-modal dMRI and fMRI data to enable functionally consistent WM
parcellation. DMVFC can effectively integrate the geometric and microstructural
characteristics of the WM fibers with the fMRI BOLD signals along the fiber
tracts. DMVFC includes two major components: (1) a multi-view pretraining
module to compute embedding features from each source of information
separately, including fiber geometry, microstructure measures, and functional
signals, and (2) a collaborative fine-tuning module to simultaneously refine
the differences of embeddings. In the experiments, we compare DMVFC with two
state-of-the-art fiber clustering methods and demonstrate superior performance
in achieving functionally meaningful and consistent WM parcellation results.

</details>


### [132] [Semantic Communications with World Models](https://arxiv.org/abs/2510.24785)
*Peiwen Jiang,Jiajia Guo,Chao-Kai Wen,Shi Jin,Jun Zhang*

Main category: eess.IV

TL;DR: 本文提出了一种基于世界基础模型（WFM）的语义视频传输框架，通过利用WFMs的预测能力来生成未来的帧，从而在保证数据关键语义的同时节约带宽。结果显示，该框架在各种场景和信道条件下显著减少了传输开销并保持了任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在极低带宽和变化的信道条件下遇到严重重建错误，因为受损或缺失的语义会导致传输失败。为了解决这一难题，本文提出了一个新的语义视频传输框架，旨在提高在这些条件下的传输效率和可靠性。

Method: 本文设计了一个框架，包含利用WFM的预测能力来预先生成未来帧，包含了一个轻量级深度反馈模块用于决定是否需要传输特定帧，以及一个基于分割辅助的部分传输方法，用于恢复受损帧。该框架还提出了一种主动传输策略，以应对移动场景中的碎片化信道状况，利用相机的路径信息提前安排传输。

Result: 实验表明，所提出的框架在保持任务性能的同时，显著减少了传输开销，提高了带宽利用效率。

Conclusion: 总之，引入预测模型和反馈机制对语义视频传输有重要贡献，该框架在变化的通信信道和场景中展现出优秀的性能和带宽节约潜力。

Abstract: Semantic communication is a promising technique for emerging wireless
applications, which reduces transmission overhead by transmitting only
task-relevant features instead of raw data. However, existing methods struggle
under extremely low bandwidth and varying channel conditions, where corrupted
or missing semantics lead to severe reconstruction errors. To resolve this
difficulty, we propose a world foundation model (WFM)-aided semantic video
transmission framework that leverages the predictive capability of WFMs to
generate future frames based on the current frame and textual guidance. This
design allows transmissions to be omitted when predictions remain reliable,
thereby saving bandwidth. Through WFM's prediction, the key semantics are
preserved, yet minor prediction errors tend to amplify over time. To mitigate
issue, a lightweight depth-based feedback module is introduced to determine
whether transmission of the current frame is needed. Apart from transmitting
the entire frame, a segmentation-assisted partial transmission method is
proposed to repair degraded frames, which can further balance performance and
bandwidth cost. Furthermore, an active transmission strategy is developed for
mobile scenarios by exploiting camera trajectory information and proactively
scheduling transmissions before channel quality deteriorates. Simulation
results show that the proposed framework significantly reduces transmission
overhead while maintaining task performances across varying scenarios and
channel conditions.

</details>


### [133] [Transformers in Medicine: Improving Vision-Language Alignment for Medical Image Captioning](https://arxiv.org/abs/2510.25164)
*Yogesh Thakku Suresh,Vishwajeet Shivaji Hogale,Luca-Alexandru Zamfira,Anandavardhana Hegde*

Main category: eess.IV

TL;DR: 我们提出了一种基于变压器的多模态框架，用于生成临床相关的MRI扫描文字说明。该框架在多CaRe数据集上进行了基准测试，展示了在特定领域数据上的性能提升，并提出了一个可扩展、可解释的自动医学图像报告解决方案


<details>
  <summary>Details</summary>
Motivation: 利用Transformer等先进技术，结合MEdiCareBERT和自定义LSTM解码器，为了生成具有较高准确性和语义对齐的MRI扫描文字说明，推动自动化医学图像报告的发展

Method: 我们的方法结合了DEiT-Small视觉Transformer作为图像编码器，MediCareBERT进行文本嵌入，以及一个基于LSTM的解码器，通过混合余弦-MSE损失和向量相似性对比推断，达到图像和文本嵌入的语义对齐

Result: 该方法在过滤后的脑部MRI图像和一般MRI图像上与现有最佳医学图像注释方法（包括BLIP，R2GenGPT和基于transformer的方法）相比在多CaRe数据集上实现了更高的准确性和语义对齐

Conclusion: 我们的工作提供了一种可扩展、可解释的解决方案，以实现医学图像的自动化报告

Abstract: We present a transformer-based multimodal framework for generating clinically
relevant captions for MRI scans. Our system combines a DEiT-Small vision
transformer as an image encoder, MediCareBERT for caption embedding, and a
custom LSTM-based decoder. The architecture is designed to semantically align
image and textual embeddings, using hybrid cosine-MSE loss and contrastive
inference via vector similarity. We benchmark our method on the MultiCaRe
dataset, comparing performance on filtered brain-only MRIs versus general MRI
images against state-of-the-art medical image captioning methods including
BLIP, R2GenGPT, and recent transformer-based approaches. Results show that
focusing on domain-specific data improves caption accuracy and semantic
alignment. Our work proposes a scalable, interpretable solution for automated
medical image reporting.

</details>


### [134] [Improving Temporal Consistency and Fidelity at Inference-time in Perceptual Video Restoration by Zero-shot Image-based Diffusion Models](https://arxiv.org/abs/2510.25420)
*Nasrin Rahimi,A. Murat Tekalp*

Main category: eess.IV

TL;DR: 本文提出了一种改进零样本视频修复中时间一致性的问题的方法，通过两种推理时间策略：感知直线引导（Perceptual Straightening Guidance，PSG）和多路径集成采样（Multi-Path Ensemble Sampling，MPES）。PSG通过在感知空间中引入曲率惩罚来增强时间感知评分，而MPES则通过集成多个扩散轨迹来减少随机变化。实验结果表明，PSG和MPES分别在时间自然度的改善和保真度的提高方面表现出了显著的效果。这些技术为使用大规模预训练扩散模型实现稳定高保真度的感知视频修复提供了一个实用的路径。


<details>
  <summary>Details</summary>
Motivation: 零样本视频修复中存在的时间不一致问题

Method: 两种推理时间策略：Perceptual Straightening Guidance（PSG）和Multi-Path Ensemble Sampling（MPES）

Result: PSG 在时间自然度的改善上有显著效果；MPES 一致地改善了保真度和空间时间感知-失真权衡

Conclusion: 这些技术为使用大规模预训练扩散模型实现稳定高保真度的感知视频修复提供了一个实用的路径

Abstract: Diffusion models have emerged as powerful priors for single-image
restoration, but their application to zero-shot video restoration suffers from
temporal inconsistencies due to the stochastic nature of sampling and
complexity of incorporating explicit temporal modeling. In this work, we
address the challenge of improving temporal coherence in video restoration
using zero-shot image-based diffusion models without retraining or modifying
their architecture. We propose two complementary inference-time strategies: (1)
Perceptual Straightening Guidance (PSG) based on the neuroscience-inspired
perceptual straightening hypothesis, which steers the diffusion denoising
process towards smoother temporal evolution by incorporating a curvature
penalty in a perceptual space to improve temporal perceptual scores, such as
Fr\'echet Video Distance (FVD) and perceptual straightness; and (2) Multi-Path
Ensemble Sampling (MPES), which aims at reducing stochastic variation by
ensembling multiple diffusion trajectories to improve fidelity (distortion)
scores, such as PSNR and SSIM, without sacrificing sharpness. Together, these
training-free techniques provide a practical path toward temporally stable
high-fidelity perceptual video restoration using large pretrained diffusion
models. We performed extensive experiments over multiple datasets and
degradation types, systematically evaluating each strategy to understand their
strengths and limitations. Our results show that while PSG enhances temporal
naturalness, particularly in case of temporal blur, MPES consistently improves
fidelity and spatio-temporal perception--distortion trade-off across all tasks.

</details>


### [135] [Physics-Guided Conditional Diffusion Networks for Microwave Image Reconstruction](https://arxiv.org/abs/2510.25729)
*Shirin Chehelgami,Joe LoVetri,Vahab Khoshdel*

Main category: eess.IV

TL;DR: 介绍了一个基于条件波动扩散的框架来解决与微波成像相关的电磁逆散射问题。该框架利用生成式机器学习模型生成多个可能的介电常数图。使用合成和实验数据集进行模型训练和评估，结果表明该方法能提高形状识别的准确性，展示了混合生成物理框架有潜力成为稳健的数据驱动微波成像方向的一个路径


<details>
  <summary>Details</summary>
Motivation: 现有逆求解器往往局限于确定性机器学习技术，只生成单一的重建结果，而本文提出的方法可以生成多个可能的重建，更好地映射出非唯一逆问题的特性。此外，通过结合正向电磁求解器，该方法可以生成与条件数据一致的一系列解，具有更好的泛化能力和形状识别准确性

Method: 该方法使用条件波动扩散模型生成多个可能的介电常数图，同时采用正向电磁求解器作为物理检验机制。合成及实验数据集被用于模型的训练与评估。通过引入一种新的标注合成数据集，训练模型得到了高质量的介电常数重建，提高了形状识别的准确性

Result: 实验结果显示，所提出的模型能够生成多个符合测量散射场数据的介电常数图，并且生成的图在预测和测量散射场之间的差异最小，展示了高度的形状识别准确性和良好的泛化性

Conclusion: 研究结果强调了混合生成物理框架在稳健的数据驱动微波成像中的潜力，表明该方法可以作为逆散射问题求解的新路径

Abstract: A conditional latent-diffusion based framework for solving the
electromagnetic inverse scattering problem associated with microwave imaging is
introduced. This generative machine-learning model explicitly mirrors the
non-uniqueness of the ill-posed inverse problem. Unlike existing inverse
solvers utilizing deterministic machine learning techniques that produce a
single reconstruction, the proposed latent-diffusion model generates multiple
plausible permittivity maps conditioned on measured scattered-field data,
thereby generating several potential instances in the range-space of the
non-unique inverse mapping. A forward electromagnetic solver is integrated into
the reconstruction pipeline as a physics-based evaluation mechanism. The space
of candidate reconstructions form a distribution of possibilities consistent
with the conditioning data and the member of this space yielding the lowest
scattered-field data discrepancy between the predicted and measured scattered
fields is reported as the final solution. Synthetic and experimental labeled
datasets are used for training and evaluation of the model. An innovative
labeled synthetic dataset is created that exemplifies a varied set of
scattering features. Training of the model using this new dataset produces high
quality permittivity reconstructions achieving improved generalization with
excellent fidelity to shape recognition. The results highlight the potential of
hybrid generative physics frameworks as a promising direction for robust,
data-driven microwave imaging.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [136] [Blockage-Aware Multi-RIS WSR Maximization via Per-RIS Indexed Synchronization Sequences and Closed-Form Riemannian Updates](https://arxiv.org/abs/2510.24723)
*Sehyun Ryu,Hyun Jong Yang*

Main category: eess.SY

TL;DR: 提出了一种针对毫米波系统中多用户MIMO受阻问题的多RIS加权总速率优化框架。该框架利用基站发送的同步信号，使用户能够通过能量检测确定受阻的RIS面板。通过检测到的可行集，该框架可以通过CRPA算法联合优化基站预编码和RIS相位。实验验证了该方法可靠地检测了阻塞，并在加权总速率和收敛性方面优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 毫米波多用户MIMO系统容易受到阻塞的影响，现有的解决方案大多假设可重新配置的智能表面（RIS）是完全可用的。然而，现实生活中，RIS链接也可能被阻塞。因此，本论文提出了一种端到端的阻塞感知多RIS加权总速率优化框架，旨在解决这一问题。

Method: 论文提出了一种称为闭环黎曼相位对齐(CRPA)的算法，利用基站传输的短索引同步信号。这一算法允许每个用户通过简单能检测出受阻面板。基于上述检测到的可行集，通过该算法联合优化基站预编码器和RIS相位，确保了每次迭代的模长不变。此外，该算法处理简单，无需投影或线搜索，并且确保了单调增加。

Result: 提出的方案通过检测RIS面板是否受阻，并利用CRPA算法优化了基站的预编码和RIS相位，提高了系统的加权总速率，同时增强了系统的收敛性能。实验验证了该方法的有效性，表明其在阻塞检测和加权总速率方面具有明显优势。

Conclusion: 本论文提出了一种针对毫米波多用户MIMO系统中RIS链接可能受阻问题的解决方案，通过使用同步信号和闭环黎曼相位对齐（CRPA）算法，实现了更复杂阻塞场景下的有效优化。

Abstract: Millimeter-wave (mmWave) multi-user MIMO systems are highly vulnerable to
blockage, and reconfigurable intelligent surfaces (RIS) have been proposed as a
remedy. However, RIS links may themselves be blocked, while most prior works
assume ideal RIS availability. We propose an end-to-end blockage-aware
multi-RIS weighted sum-rate (WSR) optimization framework. The BS transmits
short per-RIS indexed synchronization signals, enabling each user to identify
blocked panels through a simple energy detection test. Based on the detected
feasible sets, we jointly optimize the BS precoder and RIS phases via a
Closed-form Riemannian Phase Alignment (CRPA) algorithm. CRPA provides
unit-modulus-preserving closed-form updates, requiring no projection or line
search, and ensures monotone ascent. Simulations validate reliable blockage
detection and notable WSR and convergence gains over existing baselines.

</details>


### [137] [Principal and Combination Parametric Resonances of an Electromagnetically Suspended Vehicle subject to Base Excitation](https://arxiv.org/abs/2510.24756)
*Jithu Paul,Karel N. van Dalen,Andrei B. Faragau,Rens J. van Leijden,Biagio Carboni,Andrei V. Metrikine*

Main category: eess.SY

TL;DR: 本文研究了一种悬浮车辆在遇到周期性扰动时（例如表面不规则或支撑结构振动）的动力稳定性，在Hyperloop和Maglev系统中常见。由于车辆和支撑之间的间隙较小，车辆对外部振动特别敏感。系统建模为一个三个自由度的模型，并通过力平衡获得运动方程。通过希尔方法与福洛伊特理论分析参数共振并获得控制参数空间中的稳定性边界，并研究了这些边界对系统参数的影响。


<details>
  <summary>Details</summary>
Motivation: 研究在轨道不平和外部噪声导致支撑结构振动等情况下，悬浮车辆的稳定性问题，因为这些因素会引起车辆与支撑之间的间隙产生小振幅振动，影响稳定性。

Method: 建立了一个三个自由度的模型来描述电磁悬浮车辆，通过力平衡和矩平衡导出运动方程，并使用PD控制器来控制间隙。对稳态振动进行线性化，得到时间周期性的运动方程。采用希尔方法和福洛伊特理论进行理论分析，并通过数值验证。

Result: 获得了控制参数空间中的稳定性边界，并描述了这些边界如何受系统参数的影响。对于主要参数共振，两个椭圆边界的比例是三比一，而对于组合参数共振，这个比例是十四比一。当所有椭圆都存在时，最大的椭圆与组合参数共振相关。

Conclusion: 在悬浮车辆系统中，采用PD控制策略可以有效管理电磁悬浮系统中的振荡，同时周期性激励会导致复杂的稳定性问题，需要精确的数值和理论分析来确定稳定性边界和关键参数。

Abstract: This paper investigates the dynamic stability of an electromagnetically
suspended vehicle, encountered in Hyperloop and Maglev systems, subject to
periodic excitations caused by surface irregularities or vibration of the
support induced by external noise. The narrow clearance between the vehicle and
the support can make it highly sensitive to small oscillations, since the
admissible amplitudes of the vehicle oscillations can be comparable to external
excitation amplitude. The vehicle is modelled as a three-degree-of-freedom
model where the vehicle is suspended via two identical electromagnetic
actuators from a rigid support that oscillates. The governing equations are
derived using force and torque balances, incorporating nonlinear
electromagnetic forces, and Kirchhoffs law for the electromagnets with PD
control strategy on the airgap. The equations of motion are linearized around
the steady state induced by the surface oscillation, yielding a system with
time-periodic coefficients. We analytically explore both principal and
combination parametric resonances using an extended Hills method, and Floquet
theory is used for numerical validation. The stability boundaries are obtained
as ellipses in control gain parameter space, and the influence of system
parameters on these boundaries is characterized. For the principal parametric
resonance, the ratio of the sizes of the two obtained ellipses is three to one,
whereas for the combination parametric resonance, the ratio is fourteen to one.
When all ellipses are simultaneously present, one of the ellipses associated
with the combination parametric resonance is the largest.

</details>


### [138] [Delay Tolerant Control for Autonomous Driving Using CDOB](https://arxiv.org/abs/2510.24898)
*Xincheng Cao,Haochong Chen,Levent Guvenc,Bilin Aksun-Guvenc*

Main category: eess.SY

TL;DR: 本文提出了一种延迟容限通信扰动观测器（CDOB）框架，用于带有时延系统的路径跟踪控制。该框架能够补偿时延的负面影响，在不确定和变化的延迟条件下仍能保持精确的轨迹跟踪。通过模拟研究显示，该控制架构在各种场景下，包括单一车道变更和双车道变更中，均能保持与参照轨迹的紧密对齐。与传统的PID或扰动观测器方法相比，本文方法在跟踪精度和延迟鲁棒性方面表现更佳，适用于自动驾驶应用。


<details>
  <summary>Details</summary>
Motivation: 为了解决时间延迟对传统路径跟踪控制器性能的影响问题，尤其是在已知和未知时延条件下，文章提出了一种新的延迟容限通信扰动观测器(CDOB)框架。这是为了在复杂交通场景中，确保自动驾驶车辆的路径跟踪控制的准确性和鲁棒性。

Method: 通过设计一个延迟容限的通信扰动观测器(CDOB)，该方法能够补偿由于时间延迟引起的控制性能下降。具体来说，该方法利用信息通信技术来补偿延迟对路径跟踪控制的影响，以保持系统的稳定性和性能。同时，通过仿真研究验证了该算法在多种场景下的有效性。

Result: 模拟结果显示，所提出的控制架构能够在不同情境下，包括单车道和双车道变更、以及基于弹性带的碰撞避免路径中，保持与参考轨迹的密切追踪。更重要的是，该方法在跟踪精度和延迟鲁棒性方面的表现优于传统方法，表明其在实际应用中的潜力。

Conclusion: 本文提出了一种新的CDOB框架，该框架通过补偿时间延迟对路径跟踪控制的影响，在各种延迟条件下保持了系统的跟踪精度和鲁棒性。通过仿真研究和对比传统方法的性能，证明了该方法在自动驾驶应用场景中的适用性和优越性。

Abstract: With the rapid growth of autonomous vehicle technologies, effective
path-tracking control has become a critical component in ensuring safety and
efficiency in complex traffic scenarios. When a high level decision making
agent generates a collision free path, a robust low level controller is
required to precisely follow this trajectory. However, connected autonomous
vehicles (CAV) are inherently affected by communication delays and computation
delays, which significantly degrade the performance of conventional controllers
such as PID or other more advanced controllers like disturbance observers
(DOB). While DOB-based designs have shown effectiveness in rejecting
disturbances under nominal conditions, their performance deteriorates
considerably in the presence of unknown time delays. To address this challenge,
this paper proposes a delay-tolerant communication disturbance observer (CDOB)
framework for path-tracking control in delayed systems. The proposed CDOB
compensates for the adverse effects of time delays, maintaining accurate
trajectory tracking even under uncertain and varying delay conditions. It is
shown through a simulation study that the proposed control architecture
maintains close alignment with the reference trajectory across various
scenarios, including single lane change, double-= lane change, and Elastic Band
generated collision avoidance paths under various time delays. Simulation
results further demonstrate that the proposed method outperforms conventional
approaches in both tracking accuracy and delay robustness, making it well
suited for autonomous driving applications.

</details>


### [139] [A Hamilton-Jacobi Reachability Framework with Soft Constraints for Safety-Critical Systems](https://arxiv.org/abs/2510.24933)
*Chams Eddine Mballo,Donggun Lee,Claire J. Tomlin*

Main category: eess.SY

TL;DR: 本文提出了一种新的软约束可达性框架，扩展了哈密顿-雅可比可达性分析，以正式验证同时包含硬约束和软约束的安全关键系统的安全性。该框架能够确保系统在最坏情况下的干扰下，可以安全到达期望状态集，并且软约束的累积违反不超过用户指定的预算。该框架由两个主要部分组成：一个是带辅助预算状态的增强状态模型，二是该框架所研究的可达避免微分游戏中不连续哈密顿-雅可比价值函数的正则化近似。通过陆地着陆点质量模型和固定翼飞机紧急下降的数值例子验证了该框架的有效性，结果表明该框架能够在安全关键场景中同时处理硬软约束。


<details>
  <summary>Details</summary>
Motivation: 传统的可达性方法严格地强制执行状态约束，而这可能导致复杂操作场景下的过于保守或不可行的解决方案。许多实践中遇到的约束，如电池状态的限制，推荐的速度范围和乘客承载车辆的舒适性约束，本质上是软约束。软约束允许在预定义的安全范围内暂时违反，以适应不确定性和其他操作需求，尽管这样可能会增加磨损或增加运营成本。因此，本文引入了一种新的软约束可达性框架，以解决这个问题，并且提供形式上验证的安全保障。 

Method: 该框架主要由两个组成部分构成：(i) 带有辅助预算状态的增强状态模型，该状态用于追踪软约束的违反；(ii) 该框架所研究的可达避免微分游戏中不连续哈密顿-雅可比价值函数的正则化近似。具体的模型构建和数学推导在此简略，其核心在于如何利用上述两部分来描述软约束条件下的可达集，以及如何在此框架内通过数学手段来实现对于系统行为的控制以满足硬约束与软约束的要求。

Result: 通过陆地上的点质量模型着陆和固定翼飞机在风干扰下紧急下降的数值例子验证了该框架的有效性，结果表明该框架能够在最坏情况下的外界干扰下，若有足够的预设软约束违规预算，系统仍能根据硬约束和软约束的条件安全到达期望的状态。这些结果显示出该框架的潜力，它可以在复杂且挑战性的环境中同时处理硬约束和软约束，确保系统的安全性。

Conclusion: 本文提出的方法结合哈密顿-雅可比可达性分析，提出了一种新的软约束可达性框架，有效管理同时遇到的硬约束和软约束，尤其是在安全关键应用场景中。这个方法通过数值例子得到很好的支持，展示了其在实际应用中的潜力和有效性。

Abstract: Traditional reachability methods provide formal guarantees of safety under
bounded disturbances. However, they strictly enforce state constraints as
inviolable, which can result in overly conservative or infeasible solutions in
complex operational scenarios. Many constraints encountered in practice, such
as bounds on battery state of charge in electric vehicles, recommended speed
envelopes, and comfort constraints in passenger-carrying vehicles, are
inherently soft. Soft constraints allow temporary violations within predefined
safety margins to accommodate uncertainty and competing operational demands,
albeit at a cost such as increased wear or higher operational expenses. This
paper introduces a novel soft-constrained reachability framework that extends
Hamilton-Jacobi reachability analysis for the formal verification of
safety-critical systems subject to both hard and soft constraints.
Specifically, the framework characterizes a subset of the state space, referred
to as the soft-constrained reach-avoid set, from which the system is guaranteed
to reach a desired set safely, under worst-case disturbances, while ensuring
that cumulative soft-constraint violations remain within a user-specified
budget. The framework comprises two principal components: (i) an
augmented-state model with an auxiliary budget state that tracks
soft-constraint violations, and (ii) a regularization-based approximation of
the discontinuous Hamilton-Jacobi value function associated with the
reach-avoid differential game studied herein. The effectiveness of the proposed
framework is demonstrated through numerical examples involving the landing of a
simple point-mass model and a fixed-wing aircraft executing an emergency
descent, both under wind disturbances. The simulation results validate the
framework's ability to simultaneously manage both hard and soft constraints in
safety-critical settings

</details>


### [140] [Control Synthesis with Reinforcement Learning: A Modeling Perspective](https://arxiv.org/abs/2510.25063)
*Nikki Xu,Hien Tran*

Main category: eess.SY

TL;DR: 使用强化学习设计的控制器对模型偏差敏感。在不准确的虚拟环境模拟中设计控制器不适合在物理环境中部署，只有使用准确模型设计的控制器才能具有较好的鲁棒性。通过敏感性分析和经验式的吸引域估计，可以理解这些差异并可视化其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究在模型不准确的情况下，使用强化学习设计的控制器在物理实验中的表现。

Method: 利用敏感性分析和经验式的方法来估计控制器的吸引域，以验证模型准确性和控制器鲁棒性的关系。

Result: 准确模型设计的控制器更鲁棒，而在不准确模型下设计的控制器在物理实验中表现不佳。

Conclusion: 为了保证控制器的性能，需要尽量使用更准确的模型来进行设计。

Abstract: Controllers designed with reinforcement learning can be sensitive to model
mismatch. We demonstrate that designing such controllers in a virtual
simulation environment with an inaccurate model is not suitable for deployment
in a physical setup. Controllers designed using an accurate model is robust
against disturbance and small mismatch between the physical setup and the
mathematical model derived from first principles; while a poor model results in
a controller that performs well in simulation but fails in physical
experiments. Sensitivity analysis is used to justify these discrepancies and an
empirical region of attraction estimation help us visualize their robustness.

</details>


### [141] [Stochastic Long-Term Joint Decarbonization Planning for Power Systems and Data Centers: A Case Study in PJM](https://arxiv.org/abs/2510.25118)
*Zhentong Shao,Nanpeng Yu,Daniel Wong*

Main category: eess.SY

TL;DR: 本文提出了一种动态联合规划框架，该框架将数据中心和电力系统的发展进行长期优化，时间跨度为15年。通过使用改进的Benders分解方法解决大规模两阶段随机程序问题，该框架被应用于PJM互联，结果表明与独立规划相比，该框架可以减少投资成本、运行成本和排放量，并提高可再生能源的部署。


<details>
  <summary>Details</summary>
Motivation: 现有的研究大多假设电力系统的静态性，并且只关注运行排放，而忽略了联合优化。为了应对多尺度的不确定性并支持数据中心的电力需求，同时降低碳排放，本文提出了一种新的联合优化框架。

Method: 模型考虑了数据中心的选址、容量和类型与电力系统发电扩展、部署储能和退役之间的关系，提出了一个大规模两阶段随机规划模型，并通过增强的Benders分解方法进行求解。

Result: 应用该模型到PJM互联，结果表明，联合规划框架可以最大化支持55GW的峰值数据中心电力需求，降低投资成本、运行成本和排放，比非联合规划分别减少了12.6%、8.25%和5.63%，同时增加可再生能源部署25.5%。

Conclusion: 将生命周期排放考虑进去可以进一步提高可再生能源部署，强调了嵌入碳在深度脱碳中的角色。

Abstract: With the rapid growth of artificial intelligence (AI) and cloud services,
data centers have become critical infrastructures driving digital economies,
with increasing energy demand heightening concerns over electricity use and
carbon emissions, emphasizing the need for carbon-aware infrastructure
planning. Most studies assume static power systems, focus only on operational
emissions, and overlook co-optimization. This paper proposes a dynamic joint
planning framework that co-optimizes long-term data center and power system
development over 15 years. The model determines siting, capacity, and type of
data centers alongside power generation expansion, storage deployment, and
retirements, accounting for both operational and embodied emissions. To handle
multi-scale uncertainty, a large-scale two-stage stochastic program is
formulated and solved via an enhanced Benders decomposition. Applied to the PJM
Interconnection, with curated datasets released on GitHub, results show the
system can support up to 55 GW peak data center demand, with Virginia (DOM) and
Northern Illinois (ComEd) as optimal hosts. Compared to non-joint planning, the
framework cuts investment cost by 12.6%, operational cost by 8.25%, and
emissions by 5.63%. Including lifecycle emissions further raises renewable
deployment by 25.5%, highlighting embodied carbon's role in deeper
decarbonization.

</details>


### [142] [The Waterbed Effect on Quasiperiodic Disturbance Observer: Avoidance of Sensitivity Tradeoff with Time Delays](https://arxiv.org/abs/2510.25131)
*Hisayoshi Muramatsu*

Main category: eess.SY

TL;DR: 本文针对准周期干扰提出了一种使用时间延迟的准周期干扰观测器，并提供了在连续时间和离散时间表示下的Bode-like敏感度积分，阐明了时间延迟避免敏感度折衷的效果。


<details>
  <summary>Details</summary>
Motivation: 在含有准周期干扰的线性时不变系统中，设计的敏感度函数避免了敏感度折衷，且不放大非周期干扰或移动谐波抑制频率。但是，其开环传输函数不是有理函数，且由于时间延迟，不满足现有Bode敏感度积分的假设。本文目的是为这种准周期干扰观测器提供Bode-like敏感度积分，并解释时间延迟如何避免敏感度折衷效果。 

Method: 首先，提出了一种使用时间延迟的准周期干扰观测器，并设计了避免敏感度折衷的敏感度函数。然后，在连续时间和离散时间表示下，本文推导了Bode-like敏感度积分。最后，本文表明如何使用时间延迟避免敏感度折衷效果。

Result: 本文研究证明了对于准周期干扰，使用时间延迟的准周期干扰观测器可以避免敏感度折衷，并且这种避免敏感度折衷的效果可以通过Bode-like敏感度积分来衡量。

Conclusion: 通过推导Bode-like敏感度积分和解释时间延迟如何避免敏感度折衷效果，本文为理解准周期干扰观测器的性能提供了一种新的方法。

Abstract: In linear time-invariant systems, the sensitivity function to disturbances is
designed under a sensitivity tradeoff known as the waterbed effect. To
compensate for a quasiperiodic disturbance, a quasiperiodic disturbance
observer using time delays was proposed. Its sensitivity function avoids the
sensitivity tradeoff, achieving wideband harmonic suppression without
amplifying aperiodic disturbances or shifting harmonic suppression frequencies.
However, its open-loop transfer function is not rational and does not satisfy
the assumptions of existing Bode sensitivity integrals due to its time delays.
This paper provides Bode-like sensitivity integrals for the quasiperiodic
disturbance observer in both continuous-time and discrete-time representations
and clarifies the avoided sensitivity tradeoff with time delays.

</details>


### [143] [Silicon-based Josephson junction field-effect transistors enabling cryogenic logic and quantum technologies](https://arxiv.org/abs/2510.25208)
*Yusheng Xiong,Kaveh Delfanazari*

Main category: eess.SY

TL;DR: 本文综述了从约瑟夫森结到场效应晶体管的发展，特别强调了现代设备规模化的结构和功能创新。详细分析了在Si、GaAs和InGaAs基底上制造的JJFETs的表现和材料兼容性，以及它们的开关动力学和材料兼容性。本文还指出，超过四十年的实验进步揭示了JJFETs作为下一代低温逻辑和量子电子系统基础构建块的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着半导体电子技术的进步，已经超出了摩尔定律的预测，特别是在低温条件下，这推动了能够实现超低功耗和高速功能的创新设备方案的发展。

Method: 综述从约瑟夫森结到场效应晶体管的发展，分析在Si、GaAs和InGaAs基底上制造的JJFETs的表现和材料兼容性，以及它们的开关动力学和材料兼容性。

Result: 分析了超导体-硅-超导体约瑟夫森结作为JJFET架构的核心，展示了超过四十年的实验研究，突显了JJFETs作为下一代低温逻辑和量子电子系统基础构建块的潜力。

Conclusion: JJFETs不仅能够为低温逻辑和量子系统提供重要的构建模块，还能在跨温度域中提供高效的信号处理和超高相干性。

Abstract: The continuous miniaturisation of metal-oxide-semiconductor field-effect
transistors (MOSFETs) from long- to short-channel architectures has advanced
beyond the predictions of Moore's Law. Continued advances in semiconductor
electronics, even near current scaling and performance boundaries under
cryogenic conditions, are driving the development of innovative device
paradigms that enable ultra-low-power and high-speed functionality. Among
emerging candidates, the Josephson Junction Field-Effect Transistor (JJFET or
JoFET) provides an alternative by integrating superconducting source and drain
electrodes for efficient, phase-coherent operation at ultra-low temperatures.
These hybrid devices have the potential to bridge conventional semiconductor
electronics with cryogenic logic and quantum circuits, enabling
energy-efficient and high-coherence signal processing across temperature
domains. This review traces the evolution from Josephson junctions to
field-effect transistors, emphasising the structural and functional innovations
that underpin modern device scalability. The performance and material
compatibility of JJFETs fabricated on Si, GaAs, and InGaAs substrates are
analysed, alongside an assessment of their switching dynamics and material
compatibility. Particular attention is given to
superconductor-silicon-superconductor Josephson junctions as the active core of
JJFET architectures. By unfolding more than four decades of experimental
progress, this work highlights the promise of JJFETs as foundational building
blocks for next-generation cryogenic logic and quantum electronic systems.

</details>


### [144] [Shared Control for Vehicle Lane-Changing with Uncertain Driver Behaviors](https://arxiv.org/abs/2510.25284)
*Jiamin Wu,Chenguang Zhao,Huan Yu*

Main category: eess.SY

TL;DR: 本文提出了一种人机共驾车道变换控制框架，旨在减少驾驶员行为不确定性对交通稳定性的影响，同时限制自动化干预的程度。该框架利用马尔可夫跳过程模型描述驾驶员行为，并设计了两个控制器：一个用于保证交通稳定性的名义控制器和一个旨在减少自动化努力的最小干预控制器。实验结果表明，这些控制器能够有效减少车道变换时的速度波动，并改善驾驶体验，同时保证驾驶员的主动性与交通稳定性之间的平衡。


<details>
  <summary>Details</summary>
Motivation: 由于人类驾驶员的不确定性行为可能导致交通扰动，本文旨在设计一种能够在驾驶员不确定行为的情况下辅助实现稳定车道变换的人机共驾控制系统。通过这种方式，可以在保证驾驶者主动权的同时，提高交通运行的稳定性和效率。

Method: 文章首先基于任务难度驱动的马尔可夫跳过程模型，提出了一个名义稳定控制器。随后，为了平衡性能和自动化程度，引入了最小干预控制器。这两个控制器的设计和验证都是基于NGSIM和TGSIM数据集进行的。

Result: 名义控制器可以减少车道变换过程中的速度波动，缩短车道变换时间。同时，最小干预控制器在不影响太大稳定性和效率的前提下，能够显著减少自动驾驶的介入，并且提高了驾驶的舒适性，且验证实验表明，该控制器可以在保证驾驶员主动权的同时，实现更早的车道变换。

Conclusion: 本文的设计和实验验证表明，通过合适的人机共驾策略，可以在保持交通稳定性的同时，提升驾驶效率，并且保证驾驶员对驾驶的参与度和接受度。

Abstract: Lane changes are common yet challenging driving maneuvers that require
continuous decision-making and dynamic interaction with surrounding vehicles.
Relying solely on human drivers for lane-changing can lead to traffic
disturbances due to the stochastic nature of human behavior and its variability
under different task demands. Such uncertainties may significantly degrade
traffic string stability, which is critical for suppressing disturbance
propagation and ensuring smooth merging of the lane-changing vehicles. This
paper presents a human-automation shared lane-changing control framework that
preserves driver authority while allowing automated assistance to achieve
stable maneuvers in the presence of driver's behavioral uncertainty. Human
driving behavior is modeled as a Markov jump process with transitions driven by
task difficulty, providing a tractable representation of stochastic state
switching. Based on this model, we first design a nominal stabilizing
controller that guarantees stochastic ${L}_2$ string stability under imperfect
mode estimation. To further balance performance and automated effort, we then
develop a Minimal Intervention Controller (MIC) that retains acceptable
stability while limiting automation. Simulations using lane-changing data from
the NGSIM dataset verify that the nominal controller reduces speed
perturbations and shorten lane-changing time, while the MIC further reduces
automated effort and enhances comfort but with moderate stability and
efficiency loss. Validations on the TGSIM dataset with SAE Level 2 vehicles
show that the MIC enables earlier lane changes than Level 2 control while
preserving driver authority with a slight stability compromise. These findings
highlight the potential of shared control strategies to balance stability,
efficiency, and driver acceptance.

</details>


### [145] [Data-Enabled Predictive Control and Guidance for Autonomous Underwater Vehicles](https://arxiv.org/abs/2510.25309)
*Sebastian Zieglmeier,Mathias Hudoba de Badyn,Narada D. Warakagoda,Thomas R. Krogstad,Paal Engelstad*

Main category: eess.SY

TL;DR: 本文提出了一种基于Data-Enabled Predictive Control (DeePC)的自主水下航行器(AUV)全数据驱动控制框架，该框架消除了显式流体动力学建模的需要，通过利用输入输出数据预测和优化系统未来行为。该方法可用于航向控制、深度调节和三维航路点轨迹跟随，并在REMU 100 AUV的仿真中验证了其优越跟踪性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 本文动机在于开发一种无需显式流体动力学建模的数据驱动控制方法，以改进AUV在复杂和非线性条件下的控制性能和鲁棒性。通过消除需要显式流体动力学建模的需求，这种方法可以简化控制系统的开发并提高其适用性。

Method: 本研究采用了Data-Enabled Predictive Control (DeePC) 方案，该方案可以利用历史数据预测未来系统行为并优化控制策略。对于航向控制使用经典DeePC，而深度调节则使用级联DeePC结构，并引入了频率分割来管理输入和输出的不同动态模式。三维航路点轨迹跟随任务中，Adaptive Line-of-Sight算法得到扩展为预测形式，并与DeePC结合使用。

Result: 结果表明，基于DeePC的控制方法在模拟REMU 100 AUV性能时，相比经典PI/PID控制具有更好的跟踪性能和鲁棒性，特别是在面对海洋流引起的干扰以及非线性操作条件时，同时大幅减少了建模工作量。

Conclusion: 论文得出结论，通过利用DeePC的数据驱动控制方法，可以有效提高AUV的控制性能和鲁棒性，同时减少传统建模的复杂度，为AUV在各种环境中的应用提供了新的可能。

Abstract: This paper presents a fully data-driven control framework for autonomous
underwater vehicles (AUVs) based on Data-Enabled Predictive Control (DeePC).
The approach eliminates the need for explicit hydrodynamic modeling by
exploiting measured input-output data to predict and optimize future system
behavior. Classic DeePC was employed in the heading control, while a cascaded
DeePC architecture is proposed for depth regulation, incorporating a
loop-frequency separation to handle the different dynamic modes of input and
output. For 3-D waypoint path following, the Adaptive Line-of-Sight algorithm
is extended to a predictive formulation and integrated with DeePC. All methods
are validated in extensive simulation on the REMUS 100 AUV and compared with
classical PI/PID control. The results demonstrate superior tracking performance
and robustness of DeePC under ocean-current disturbances and nonlinear
operating conditions, while significantly reducing modeling effort.

</details>


### [146] [Tight Collision Avoidance for Stochastic Optimal Control: with Applications in Learning-based, Interactive Motion Planning](https://arxiv.org/abs/2510.25324)
*Erik Börve,Nikolce Murgovski,Leo Laine*

Main category: eess.SY

TL;DR: 该论文提出了一种基于随机最优控制的框架，用于解决自动驾驶车辆在密集且交互性强的交通场景中轨迹规划的问题，特别是在处理人类驾驶员行为的不确定性以及非凸碰撞避免约束时的问题。论文还展示了通过模拟研究验证了该方法的有效性，尤其是在未受管制的交叉口穿越和密集交通中的高速公路车道变更等挑战性场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在密集且交互性强的交通场景中路径规划面临挑战，特别是由于人类驾驶员的不确定性以及防撞约束的非凸性。现有的方法通常会在准确性与保守性之间做出妥协，该论文旨在提出一种新的框架同时解决这两个问题，而不会做出过度保守的近似。

Method: 论文提出了一种基于随机最优控制的框架，并将人类驾驶员的行为决策建模为马尔可夫决策过程，以及提出了一种用于非凸车辆形状之间的碰撞避免的方法——对紧集之间的距离施加正向距离约束。在该框架中，论文研究了三种可行的机会约束公式。为了确保计算的可操作性，论文引入了非凸距离约束和机会约束的紧密、连续可微重新表述。

Result: 在两个具有挑战性的交互场景——未受管制的交叉口穿越和密集交通中的高速公路车道变更——的模拟研究中，验证了所提出方法的有效性。

Conclusion: 该研究提出了基于随机最优控制的新框架来解决自动驾驶车辆在密集、交互性强的场景中轨迹规划的问题，该方法在模拟研究中证明了其有效性。

Abstract: Trajectory planning in dense, interactive traffic scenarios presents
significant challenges for autonomous vehicles, primarily due to the
uncertainty of human driver behavior and the non-convex nature of collision
avoidance constraints. This paper introduces a stochastic optimal control
framework to address these issues simultaneously, without excessively
conservative approximations. We opt to model human driver decisions as a Markov
Decision Process and propose a method for handling collision avoidance between
non-convex vehicle shapes by imposing a positive distance constraint between
compact sets. In this framework, we investigate three alternative chance
constraint formulations. To ensure computational tractability, we introduce
tight, continuously differentiable reformulations of both the non-convex
distance constraints and the chance constraints. The efficacy of our approach
is demonstrated through simulation studies of two challenging interactive
scenarios: an unregulated intersection crossing and a highway lane change in
dense traffic.

</details>


### [147] [Lightweight Federated Learning in Mobile Edge Computing with Statistical and Device Heterogeneity Awareness](https://arxiv.org/abs/2510.25342)
*Jinghong Tan,Zhichen Zhang,Kun Guo,Tsung-Hui Chang,Tony Q. S. Quek*

Main category: eess.SY

TL;DR: 一种新的轻量级个性化联邦学习框架，通过参数解耦，分别对共享和私有子空间应用梯度稀疏化和模型剪枝，从而在保护个性化质量的同时适应异构客户端资源，降低了通信和计算成本，减少了整体训练时间，并且准确性损失可以忽略不计。


<details>
  <summary>Details</summary>
Motivation: 联邦学习存在高通信和计算成本问题，特别在异构环境中，现有的压缩方法虽然可以减少每轮成本，但也可能增加了总体训练成本。因此，提出了一个轻量化个性化联邦学习框架，以有效减少训练成本同时保护个性化质量。

Method: 框架通过参数解耦，将模型分为共享和私人部分，对共享部分应用梯度稀疏化，对私人部分应用模型剪枝，从而限制了通信压缩仅用于全球知识交换和计算缩减仅用于本地个性化。此外，理论分析了稀疏化和剪枝联合效应下的收敛性，由此制定了一个联合优化，选择每个客户端的稀疏度和剪枝率及无线带宽，以降低端到端的训练时间。

Result: 实验结果表明，该框架能够更快地收敛，显著减少了整体通信和计算成本，而准确性并没有明显下降。此外，还展示了在资源受限的异构环境中协调和资源感知个性化的好处。

Conclusion: 所提出的模型通过参数解耦，分别使用梯度稀疏化和模型剪枝，成功降低了训练成本，确保了训练质量和准确性，证明在资源受限的异环境中，协调和资源感知个性化是有效的。

Abstract: Federated learning enables collaborative machine learning while preserving
data privacy, but high communication and computation costs, exacerbated by
statistical and device heterogeneity, limit its practicality in mobile edge
computing. Existing compression methods like sparsification and pruning reduce
per-round costs but may increase training rounds and thus the total training
cost, especially under heterogeneous environments. We propose a lightweight
personalized FL framework built on parameter decoupling, which separates the
model into shared and private subspaces, enabling us to uniquely apply gradient
sparsification to the shared component and model pruning to the private one.
This structural separation confines communication compression to global
knowledge exchange and computation reduction to local personalization,
protecting personalization quality while adapting to heterogeneous client
resources. We theoretically analyze convergence under the combined effects of
sparsification and pruning, revealing a sparsity-pruning trade-off that links
to the iteration complexity. Guided by this analysis, we formulate a joint
optimization that selects per-client sparsity and pruning rates and wireless
bandwidth to reduce end-to-end training time. Simulation results demonstrate
faster convergence and substantial reductions in overall communication and
computation costs with negligible accuracy loss, validating the benefits of
coordinated and resource-aware personalization in resource-constrained
heterogeneous environments.

</details>


### [148] [Optimal and Heuristic Approaches for Platooning Systems with Deadlines](https://arxiv.org/abs/2510.25564)
*Thiago S. Gomides,Evangelos Kranakis,Ioannis Lambadaris,Yannis Viniotis,Gennady Shaikhet*

Main category: eess.SY

TL;DR: 研究论文提出了一种优化特定时间窗口内卡车编队形成和调度的方法，以减少运输成本，降低燃油消耗和排放。通过将问题设定为马尔可夫决策过程并提出低复杂度的优化策略，研究进行了深入分析。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在探索如何在有限容量的高速公路站有效组织卡车编队，同时考虑到延迟成本和违反最后期限的惩罚，提高运输效率，降低燃料消耗和排放。

Method: 利用有限容量的高速公路站，研究将问题模型化为马尔可夫决策过程，针对容量为3的情况找出最优策略，并将结论推广到任意容量。随后，还提出了利用结构特征的低复杂度启发式算法，包括条件分支和基于深度学习的方法。

Result: 证明了最优政策$oldsymbol{oldmath{	ext{π}}}^	ext{∗}$在状态空间内是单调的，并确定了一类不可达状态。对于容量和时间限制增加时态空间呈指数级增长的情况，提出了在保持低计算复杂度的同时利用这些结构特征的启发式方法。

Conclusion: 通过将卡车编队调度问题模型化为马尔可夫决策过程，研究不仅可以找到兴趣模型的最优策略，而且通过特定分析，提出了低计算复杂度的基于启发式和深度学习的策略。

Abstract: Efficient truck platooning is a key strategy for reducing freight costs,
lowering fuel consumption, and mitigating emissions. Deadlines are critical in
this context, as trucks must depart within specific time windows to meet
delivery requirements and avoid penalties. In this paper, we investigate the
optimal formation and dispatch of truck platoons at a highway station with
finite capacity $L$ and deadline constraints $T$. The system operates in
discrete time, with each arriving truck assigned a deadline of $T$ slot units.
The objective is to leverage the efficiency gains from forming large platoons
while accounting for waiting costs and deadline violations. We formulate the
problem as a Markov decision process and analyze the structure of the optimal
policy $\pi^\star$ for $L = 3$, extending insights to arbitrary $L$. We prove
that the $\pi^\star$ is monotone in the state space $\mathcal{S}$ and identify
classes of unreachable states. Moreover, since $\mathcal{S}$ grows
exponentially with $L$ and $T$, we propose heuristics-including conditional and
deep-learning based approaches-that exploit these structural insights while
maintaining low computational complexity.

</details>


### [149] [An OPF-based Control Framework for Hybrid AC-MTDC Power Systems under Uncertainty](https://arxiv.org/abs/2510.25671)
*Hongjin Du,Rahul Rane,Weijie Xia,Pedro P. Vergara,Aleksandra Lekić*

Main category: eess.SY

TL;DR: 本文提出了一种基于最优潮流(OPF)的自适应控制框架，以提高含可再生能源的混合交流-直流系统的稳定性。该框架利用随机森林模型生成的风速预测，结合时间耦合的最优潮流以确定基线变流器设定点，并根据实际操作条件实时调整。并开发了一种同时考虑直流电压和交流频率偏差的自适应下垂控制方案。通过硬件在环(HIL)仿真验证了控制框架的有效性，证明了其在高可再生能源渗透率下确保混合交流-直流系统稳定运行的能力。


<details>
  <summary>Details</summary>
Motivation: 随着海上风电等可再生能源的大规模接入，给混合交流-直流系统的稳定运行带来了新的挑战。传统控制策略通常依赖于固定设定点，忽视了频率偏差问题，难以适应快速变化的可再生能源输出，因此需要一种新的自适应控制策略来解决这一问题。

Method: 该研究提出了一个基于预测和最优潮流基础上的自适应控制框架，使用随机森林模型进行风速预测，并将这些预测集成到时间耦合的最优潮流中来确定基线变流器设定点；同时开发了一种自适应的下垂控制方案，可通过实时监测来进一步调整设定点，并考虑直流电压和交流频率的偏差。

Result: 通过硬件在环仿真验证了所提出的控制框架的有效性和稳定性，特别是在高可再生能源渗透率的情况下，它能够保证系统的稳定运行。

Conclusion: 综上所述，本文通过提出一种预测集成、最优潮流为基础的自适应控制框架，解决了高比例可再生能源接入下混合交流-直流系统稳定性的问题。

Abstract: The increasing integration of renewable energy, particularly offshore wind,
introduces significant uncertainty into hybrid AC-HVDC systems due to forecast
errors and power fluctuations. Conventional control strategies typically rely
on fixed setpoints and neglect frequency deviations, which can compromise
system stability under rapid renewable variations. To address this challenge,
this paper presents a forecast-integrated, optimal power flow (OPF)-based
adaptive control framework. Wind speed forecasts generated using a Random
Forest model are incorporated into a time-coupled OPF to determine baseline
converter setpoints in anticipation of wind fluctuations, which are further
adjusted in real time based on actual operating conditions. An adaptive droop
control scheme is developed that jointly considers DC voltage and AC frequency
deviations. The effectiveness of the proposed control framework is validated
through hardware-in-the-loop (HIL) simulations, demonstrating its capability to
ensure stable and robust operation of hybrid AC-HVDC systems under high
penetration of renewable energy.

</details>


### [150] [Over 3 kV and Ultra-Low leakage Vertical (011) \b{eta}-Ga2O3 Power Diodes with Engineered Schottky Contact and High-permittivity Dielectric Field Plate](https://arxiv.org/abs/2510.25695)
*Emerson J. Hollar,Esmat Farzana*

Main category: eess.SY

TL;DR: 报告了超过3kV的击穿电压和低泄漏（011）η-Ga2O3功率器件，利用肖特基势垒工程和高介电常数（ZrO2）场板。研究表明，（011）取向的 η-Ga2O3 可以支持厚漂移层，从而支持千伏级垂直 η-Ga2O3 功率开关。通过Pt帽/PtOx/Pt（1.5nm）复合肖特基接触实现了隧道漏电流管理，使击穿电压达到3.7kV，同时保持较低的开启电压。这为超低泄漏和多千伏级垂直（011）η-Ga2O3功率器件的发展提出了有前途的策略


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过采用肖特基势垒工程、高介电常数场板以及利用(011)方向的η-Ga2O3的特点来开发超低泄漏和数千伏的功率器件，以改善半导体器件的电源管理性能

Method: 采用复合Pt帽/PtOx/Pt(1.5nm)肖特基接触并用ZrO2高介电常数场板来实现隧道泄漏管理以及边缘场抑制，利用(011)方向的η-Ga2O3材料的特性制造了具有高耐压特性的肖特基势垒二极管(SBDs)和场板SBDs，并进行了系统的测试

Result: 使用复合Pt帽/PtOx/Pt(1.5nm)肖特基接触的场板SBDs实现了达到3.7kV的击穿电压。同时，该复合肖特基接触与Pt/(011) η-Ga2O3 SBDs保持了接近的开启电压

Conclusion: 采用高效的隧道泄漏管理、低边缘场和类似开启电压的复合Pt帽/PtOx/Pt(1.5nm)肖特基接触，以及η-Ga2O3提供的材料优点，是开发超低泄漏和数千伏级垂直(011)η-Ga2O3功率器件的有效策略

Abstract: We report over 3 kV breakdown voltage and ultra-low leakage (011)
\b{eta}-Ga2O3 power devices utilizing Schottky barrier engineering and
high-permittivity (\k{appa}) dielectric (ZrO2) field plate. The (011)
orientation of \b{eta}-Ga2O3 enabled low background doping and thick drift
layers which are promising to support kV-class vertical \b{eta}-Ga2O3 power
switches. The Schottky barrier engineering was performed with a composite Pt
cap/PtOx/Pt (1.5 nm) anode contact to take advantage of the enhanced reverse
blocking capabilities enabled by PtOx while allowing low turn-on voltage by the
interfacing thin Pt layer. We also performed a systematic study using a
co-processed Pt/(011) \b{eta}-Ga2O3 Schottky barrier diodes (SBDs) on the same
wafer. The bare SBDs revealed a breakdown voltage of ~1.5 kV, while the
field-plate Pt/(011) \b{eta}-Ga2O3 SBDs achieved an increased breakdown voltage
of 2.75 kV owing to the edge field management. Further enhancement of the
breakdown voltage was achieved by tunneling leakage management using composite
Pt cap/PtOx/Pt (1.5 nm) Schottky contacts that ultimately enabled breakdown
voltage of 3.7 kV for the field-plate diodes. Remarkably, the Pt cap/PtOx/Pt
(1.5 nm) Schottky contacts maintained similar turn-on voltage as the Pt/(011)
\b{eta}-Ga2O3 SBDs. The combination of efficient tunneling leakage management
by composite Pt cap/PtOx/Pt (1.5 nm) contacts with similar turn-on voltage,
edge field reduction by high-\k{appa} dielectric ZrO2 field plate, as well as
the advantageous material properties offered by (011) \b{eta}-Ga2O3 demonstrate
a promising strategy for developing ultra-low leakage and multi-kV class
vertical (011) \b{eta}-Ga2O3 power devices.

</details>
