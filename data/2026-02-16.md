<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 62]
- [cs.NI](#cs.NI) [Total: 5]
- [eess.SY](#eess.SY) [Total: 16]
- [eess.IV](#eess.IV) [Total: 6]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.LG](#cs.LG) [Total: 83]
- [cs.IT](#cs.IT) [Total: 8]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Thermal Imaging for Contactless Cardiorespiratory and Sudomotor Response Monitoring](https://arxiv.org/abs/2602.12361)
*Constantino Álvarez Casado,Mohammad Rahman,Sasan Sharifipour,Nhi Nguyen,Manuel Lage Cañellas,Xiaoting Wu,Miguel Bordallo López*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Thermal infrared imaging captures skin temperature changes driven by autonomic regulation and can potentially provide contactless estimation of electrodermal activity (EDA), heart rate (HR), and breathing rate (BR). While visible-light methods address HR and BR, they cannot access EDA, a standard marker of sympathetic activation. This paper characterizes the extraction of these three biosignals from facial thermal video using a signal-processing pipeline that tracks anatomical regions, applies spatial aggregation, and separates slow sudomotor trends from faster cardiorespiratory components. For HR, we apply an orthogonal matrix image transformation (OMIT) decomposition across multiple facial regions of interest (ROIs), and for BR we average nasal and cheek signals before spectral peak detection. We evaluate 288 EDA configurations and the HR/BR pipeline on 31 sessions from the public SIMULATOR STUDY 1 (SIM1) driver monitoring dataset. The best fixed EDA configuration (nose region, exponential moving average) reaches a mean absolute correlation of $0.40 \pm 0.23$ against palm EDA, with individual sessions reaching 0.89. BR estimation achieves a mean absolute error of $3.1 \pm 1.1$ bpm, while HR estimation yields $13.8 \pm 7.5$ bpm MAE, limited by the low camera frame rate (7.5 Hz). We report signal polarity alternation across sessions, short thermodynamic latency for well-tracked signals, and condition-dependent and demographic effects on extraction quality. These results provide baseline performance bounds and design guidance for thermal contactless biosignal estimation.

</details>


### [2] [LLaMo: Scaling Pretrained Language Models for Unified Motion Understanding and Generation with Continuous Autoregressive Tokens](https://arxiv.org/abs/2602.12370)
*Zekun Li,Sizhe An,Chengcheng Tang,Chuan Guo,Ivan Shugurov,Linguang Zhang,Amy Zhao,Srinath Sridhar,Lingling Tao,Abhay Mittal*

Main category: cs.CV

TL;DR: LLaMo：通过模态特定混合Transformer架构扩展预训练大语言模型，实现运动与语言统一生成与理解，避免灾难性遗忘并消除离散化抖动问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过量化将运动转换为离散表示，存在抖动伪影问题；在有限运动-文本对上微调大语言模型会导致语言能力灾难性遗忘；迫切需要统一运动-语言生成与理解的大模型框架。

Method: 提出LLaMo框架：1）采用模态特定混合Transformer架构扩展预训练LLMs，保护基础模型语言能力；2）将人体运动编码为连续因果潜在空间；3）通过轻量级流匹配头在仅解码器骨干中保持下一个标记预测范式，实现实时流式运动生成（>30 FPS）。

Result: 实验表明LLaMo在一般设置下实现高保真文本到运动生成和运动到文本描述，特别是在零样本运动生成方面表现突出，标志着通用统一运动-语言大模型的重要进展。

Conclusion: LLaMo通过创新的架构设计和训练策略，成功解决了现有方法的局限性，在保持语言能力的同时实现了高质量的运动-语言互转能力，为统一运动-语言理解与生成开辟了新途径。

Abstract: Recent progress in large models has led to significant advances in unified multimodal generation and understanding. However, the development of models that unify motion-language generation and understanding remains largely underexplored. Existing approaches often fine-tune large language models (LLMs) on paired motion-text data, which can result in catastrophic forgetting of linguistic capabilities due to the limited scale of available text-motion pairs. Furthermore, prior methods typically convert motion into discrete representations via quantization to integrate with language models, introducing substantial jitter artifacts from discrete tokenization. To address these challenges, we propose LLaMo, a unified framework that extends pretrained LLMs through a modality-specific Mixture-of-Transformers (MoT) architecture. This design inherently preserves the language understanding of the base model while enabling scalable multimodal adaptation. We encode human motion into a causal continuous latent space and maintain the next-token prediction paradigm in the decoder-only backbone through a lightweight flow-matching head, allowing for streaming motion generation in real-time (>30 FPS). Leveraging the comprehensive language understanding of pretrained LLMs and large-scale motion-text pretraining, our experiments demonstrate that LLaMo achieves high-fidelity text-to-motion generation and motion-to-text captioning in general settings, especially zero-shot motion generation, marking a significant step towards a general unified motion-language large model.

</details>


### [3] [Synthetic Image Detection with CLIP: Understanding and Assessing Predictive Cues](https://arxiv.org/abs/2602.12381)
*Marco Willi,Melanie Mathys,Michael Graber*

Main category: cs.CV

TL;DR: CLIP基础检测器在合成图像检测中表现良好，但在跨生成器泛化时性能下降，主要依赖高级摄影属性而非生成器特定伪影，需要持续更新和更广泛的训练以实现更通用的稳健检测。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型产生近乎逼真的图像，合成图像检测变得越来越重要。现有检测方法常常难以泛化到新的生成模型，并且在实用场景中表现不佳。CLIP作为基础视觉语言模型展现出强大的准确性和泛化能力，但其在合成图像检测中到底学习什么线索仍不明确——是检测明显视觉伪影还是利用微妙的语义偏差？

Method: 研究引入了SynthCLIC数据集，包含真实照片和高质量扩散模型生成的合成图像，旨在减少合成图像检测中的语义偏差。使用具有去相关激活的可解释线性头和基于文本的概念模型，分析CLIP特征在检测中学习的模式。

Result: CLIP基线性检测器在GAN基准测试上达到0.96 mAP，但在高质量扩散数据集SynthCLIC上仅为0.92 mAP，跨生成器家族泛化时更是下降到最低0.37 mAP。研究发现检测器主要依赖于高级摄影属性（如极简风格、镜头光晕或深度分层），而非生成器特定的明显伪影。

Conclusion: CLIP基检测器整体表现良好，但在不同生成架构间泛化不均，这突显了需要持续模型更新和更广泛训练暴露的必要性，同时也肯定了CLIP基方法作为构建更通用、稳健合成图像检测技术的基础。

Abstract: Recent generative models produce near-photorealistic images, challenging the trustworthiness of photographs. Synthetic image detection (SID) has thus become an important area of research. Prior work has highlighted how synthetic images differ from real photographs--unfortunately, SID methods often struggle to generalize to novel generative models and often perform poorly in practical settings. CLIP, a foundational vision-language model which yields semantically rich image-text embeddings, shows strong accuracy and generalization for SID. Yet, the underlying relevant cues embedded in CLIP-features remain unknown. It is unclear, whether CLIP-based detectors simply detect strong visual artifacts or exploit subtle semantic biases, both of which would render them useless in practical settings or on generative models of high quality. We introduce SynthCLIC, a paired dataset of real photographs and high-quality synthetic counterparts from recent diffusion models, designed to reduce semantic bias in SID. Using an interpretable linear head with de-correlated activations and a text-grounded concept-model, we analyze what CLIP-based detectors learn. CLIP-based linear detectors reach 0.96 mAP on a GAN-based benchmark but only 0.92 on our high-quality diffusion dataset SynthCLIC, and generalization across generator families drops to as low as 0.37 mAP. We find that the detectors primarily rely on high-level photographic attributes (e.g., minimalist style, lens flare, or depth layering), rather than overt generator-specific artifacts. CLIP-based detectors perform well overall but generalize unevenly across diverse generative architectures. This highlights the need for continual model updates and broader training exposure, while reinforcing CLIP-based approaches as a strong foundation for more universal, robust SID.

</details>


### [4] [Reproducing DragDiffusion: Interactive Point-Based Editing with Diffusion Models](https://arxiv.org/abs/2602.12393)
*Ali Subhan,Ashir Raza*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: DragDiffusion is a diffusion-based method for interactive point-based image editing that enables users to manipulate images by directly dragging selected points. The method claims that accurate spatial control can be achieved by optimizing a single diffusion latent at an intermediate timestep, together with identity-preserving fine-tuning and spatial regularization. This work presents a reproducibility study of DragDiffusion using the authors' released implementation and the DragBench benchmark. We reproduce the main ablation studies on diffusion timestep selection, LoRA-based fine-tuning, mask regularization strength, and UNet feature supervision, and observe close agreement with the qualitative and quantitative trends reported in the original work. At the same time, our experiments show that performance is sensitive to a small number of hyperparameter assumptions, particularly the optimized timestep and the feature level used for motion supervision, while other components admit broader operating ranges. We further evaluate a multi-timestep latent optimization variant and find that it does not improve spatial accuracy while substantially increasing computational cost. Overall, our findings support the central claims of DragDiffusion while clarifying the conditions under which they are reliably reproducible. Code is available at https://github.com/AliSubhan5341/DragDiffusion-TMLR-Reproducibility-Challenge.

</details>


### [5] [What does RL improve for Visual Reasoning? A Frankenstein-Style Analysis](https://arxiv.org/abs/2602.12395)
*Xirui Li,Ming Li,Tianyi Zhou*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reinforcement learning (RL) with verifiable rewards has become a standard post-training stage for boosting visual reasoning in vision-language models, yet it remains unclear what capabilities RL actually improves compared with supervised fine-tuning as cold-start initialization (IN). End-to-end benchmark gains conflate multiple factors, making it difficult to attribute improvements to specific skills. To bridge the gap, we propose a Frankenstein-style analysis framework including: (i) functional localization via causal probing; (ii) update characterization via parameter comparison; and (iii) transferability test via model merging. Instead, RL induces a consistent inference-time shift primarily in mid-to-late layers, and these mid-to-late refinements are both transferable (via merging) and necessary (via freezing) for RL gains. Overall, our results suggest that RL's reliable contribution in visual reasoning is not a uniform enhancement of visual perception, but a systematic refinement of mid-to-late transformer computation that improves vision-to-reasoning alignment and reasoning performance, highlighting the limitations of benchmark-only evaluation for understanding multimodal reasoning improvements.

</details>


### [6] [ZeroDiff++: Substantial Unseen Visual-semantic Correlation in Zero-shot Learning](https://arxiv.org/abs/2602.12401)
*Zihan Ye,Shreyank N Gowda,Kaile Du,Weijian Luo,Ling Shao*

Main category: cs.CV

TL;DR: 提出ZeroDiff++模型以解决零样本学习中的虚假视觉-语义关联问题，通过扩散模型增强生成特征的多样性并改进测试时生成与适应。


<details>
  <summary>Details</summary>
Motivation: 现有生成式零样本学习存在虚假视觉-语义关联问题：稀缺样本导致误导性关联；传统生成器产生与真实测试样本脱节的特征。

Method: 1) 扩散增强产生多样化噪声样本；2) 监督对比表征学习实例级语义；3) 多视图判别器与Wasserstein互学习；4) 扩散测试时适应(DiffTTA)；5) 扩散测试时生成(DiffGen)实现部分合成特征。

Result: 在三个标准基准上显著超越现有方法，并在训练数据稀缺时仍能保持鲁棒性能。

Conclusion: ZeroDiff++能够更好地学习视觉-语义关联，在零样本学习任务中取得优异表现，缓解数据稀缺问题。

Abstract: Zero-shot Learning (ZSL) enables classifiers to recognize classes unseen during training, commonly via generative two stage methods: (1) learn visual semantic correlations from seen classes; (2) synthesize unseen class features from semantics to train classifiers. In this paper, we identify spurious visual semantic correlations in existing generative ZSL worsened by scarce seen class samples and introduce two metrics to quantify spuriousness for seen and unseen classes. Furthermore, we point out a more critical bottleneck: existing unadaptive fully noised generators produce features disconnected from real test samples, which also leads to the spurious correlation. To enhance the visual-semantic correlations on both seen and unseen classes, we propose ZeroDiff++, a diffusion-based generative framework. In training, ZeroDiff++ uses (i) diffusion augmentation to produce diverse noised samples, (ii) supervised contrastive (SC) representations for instance level semantics, and (iii) multi view discriminators with Wasserstein mutual learning to assess generated features. At generation time, we introduce (iv) Diffusion-based Test time Adaptation (DiffTTA) to adapt the generator using pseudo label reconstruction, and (v) Diffusion-based Test time Generation (DiffGen) to trace the diffusion denoising path and produce partially synthesized features that connect real and generated data, and mitigates data scarcity further. Extensive experiments on three ZSL benchmarks demonstrate that ZeroDiff++ not only achieves significant improvements over existing ZSL methods but also maintains robust performance even with scarce training data. Code would be available.

</details>


### [7] [MonoLoss: A Training Objective for Interpretable Monosemantic Representations](https://arxiv.org/abs/2602.12403)
*Ali Nasiri-Sarvi,Anh Tien Nguyen,Hassan Rivaz,Dimitris Samaras,Mahdi S. Hosseini*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Sparse autoencoders (SAEs) decompose polysemantic neural representations, where neurons respond to multiple unrelated concepts, into monosemantic features that capture single, interpretable concepts. However, standard training objectives only weakly encourage this decomposition, and existing monosemanticity metrics require pairwise comparisons across all dataset samples, making them inefficient during training and evaluation. We study a recent MonoScore metric and derive a single-pass algorithm that computes exactly the same quantity, but with a cost that grows linearly, rather than quadratically, with the number of dataset images. On OpenImagesV7, we achieve up to a 1200x speedup wall-clock speedup in evaluation and 159x during training, while adding only ~4% per-epoch overhead. This allows us to treat MonoScore as a training signal: we introduce the Monosemanticity Loss (MonoLoss), a plug-in objective that directly rewards semantically consistent activations for learning interpretable monosemantic representations. Across SAEs trained on CLIP, SigLIP2, and pretrained ViT features, using BatchTopK, TopK, and JumpReLU SAEs, MonoLoss increases MonoScore for most latents. MonoLoss also consistently improves class purity (the fraction of a latent's activating images belonging to its dominant class) across all encoder and SAE combinations, with the largest gain raising baseline purity from 0.152 to 0.723. Used as an auxiliary regularizer during ResNet-50 and CLIP-ViT-B/32 finetuning, MonoLoss yields up to 0.6\% accuracy gains on ImageNet-1K and monosemantic activating patterns on standard benchmark datasets. The code is publicly available at https://github.com/AtlasAnalyticsLab/MonoLoss.

</details>


### [8] [Prototype-driven fusion of pathology and spatial transcriptomics for interpretable survival prediction](https://arxiv.org/abs/2602.12441)
*Lihe Liu,Xiaoxi Pan,Yinyin Yuan,Lulu Shang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Whole slide images (WSIs) enable weakly supervised prognostic modeling via multiple instance learning (MIL). Spatial transcriptomics (ST) preserves in situ gene expression, providing a spatial molecular context that complements morphology. As paired WSI-ST cohorts scale to population level, leveraging their complementary spatial signals for prognosis becomes crucial; however, principled cross-modal fusion strategies remain limited for this paradigm. To this end, we introduce PathoSpatial, an interpretable end-to-end framework integrating co-registered WSIs and ST to learn spatially informed prognostic representations. PathoSpatial uses task-guided prototype learning within a multi-level experts architecture, adaptively orchestrating unsupervised within-modality discovery with supervised cross-modal aggregation. By design, PathoSpatial substantially strengthens interpretability while maintaining discriminative ability. We evaluate PathoSpatial on a triple-negative breast cancer cohort with paired ST and WSIs. PathoSpatial delivers strong and consistent performance across five survival endpoints, achieving superior or comparable performance to leading unimodal and multimodal methods. PathoSpatial inherently enables post-hoc prototype interpretation and molecular risk decomposition, providing quantitative, biologically grounded explanations, highlighting candidate prognostic factors. We present PathoSpatial as a proof-of-concept for scalable and interpretable multimodal learning for spatial omics-pathology fusion.

</details>


### [9] [Semantic-aware Adversarial Fine-tuning for CLIP](https://arxiv.org/abs/2602.12461)
*Jiacheng Zhang,Jinhao Li,Hanxun Huang,Sarah M. Erfani,Benjamin I. P. Rubinstein,Feng Liu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent studies have shown that CLIP model's adversarial robustness in zero-shot classification tasks can be enhanced by adversarially fine-tuning its image encoder with adversarial examples (AEs), which are generated by minimizing the cosine similarity between images and a hand-crafted template (e.g., ''A photo of a {label}''). However, it has been shown that the cosine similarity between a single image and a single hand-crafted template is insufficient to measure the similarity for image-text pairs. Building on this, in this paper, we find that the AEs generated using cosine similarity may fail to fool CLIP when the similarity metric is replaced with semantically enriched alternatives, making the image encoder fine-tuned with these AEs less robust. To overcome this issue, we first propose a semantic-ensemble attack to generate semantic-aware AEs by minimizing the average similarity between the original image and an ensemble of refined textual descriptions. These descriptions are initially generated by a foundation model to capture core semantic features beyond hand-crafted templates and are then refined to reduce hallucinations. To this end, we propose Semantic-aware Adversarial Fine-Tuning (SAFT), which fine-tunes CLIP's image encoder with semantic-aware AEs. Extensive experiments show that SAFT outperforms current methods, achieving substantial improvements in zero-shot adversarial robustness across 16 datasets. Our code is available at: https://github.com/tmlr-group/SAFT.

</details>


### [10] [A Lightweight and Explainable DenseNet-121 Framework for Grape Leaf Disease Classification](https://arxiv.org/abs/2602.12484)
*Md. Ehsanul Haque,Md. Saymon Hosen Polash,Rakib Hasan Ovi,Aminul Kader Bulbul,Md Kamrul Siam,Tamim Hasan Saykat*

Main category: cs.CV

TL;DR: 本文提出使用优化的DenseNet121进行葡萄叶片病害分类，通过领域特定预处理和可解释性方法，在保持高效计算的同时实现了高精度疾病检测。


<details>
  <summary>Details</summary>
Motivation: 葡萄是全球重要的经济作物，但病害如细菌性腐烂、霜霉病和白粉病严重影响其产量和质量。当前基于YOLO框架的自动方法计算成本高且缺乏可解释性，不适合实际应用，因此需要开发精确、高效且透明的葡萄叶片病害分类方法。

Method: 使用优化的DenseNet121模型进行葡萄叶片病害分类，采用领域特定的预处理技术，并利用Grad-CAM增强模型可解释性。通过迁移学习确保在小型和不平衡样本上的稳定性，并进行模型优化以降低计算需求。

Result: 提出的模型在准确率达到99.27%，F1分数99.28%，特异性99.71%，Kappa值98.86%，推理时间9秒。交叉验证平均准确率为99.12%，优于ResNet18、VGG16、AlexNet和SqueezeNet等基线CNN模型。

Conclusion: 通过有效的架构设计、领域特定预处理和可解释输出，提出的框架在葡萄叶片病害检测中具有可扩展性、高精度和低计算成本的特点，适合实际部署。

Abstract: Grapes are among the most economically and culturally significant fruits on a global scale, and table grapes and wine are produced in significant quantities in Europe and Asia. The production and quality of grapes are significantly impacted by grape diseases such as Bacterial Rot, Downy Mildew, and Powdery Mildew. Consequently, the sustainable management of a vineyard necessitates the early and precise identification of these diseases. Current automated methods, particularly those that are based on the YOLO framework, are often computationally costly and lack interpretability that makes them unsuitable for real-world scenarios. This study proposes grape leaf disease classification using Optimized DenseNet 121. Domain-specific preprocessing and extensive connectivity reveal disease-relevant characteristics, including veins, edges, and lesions. An extensive comparison with baseline CNN models, including ResNet18, VGG16, AlexNet, and SqueezeNet, demonstrates that the proposed model exhibits superior performance. It achieves an accuracy of 99.27%, an F1 score of 99.28%, a specificity of 99.71%, and a Kappa of 98.86%, with an inference time of 9 seconds. The cross-validation findings show a mean accuracy of 99.12%, indicating strength and generalizability across all classes. We also employ Grad-CAM to highlight disease-related regions to guarantee the model is highlighting physiologically relevant aspects and increase transparency and confidence. Model optimization reduces processing requirements for real-time deployment, while transfer learning ensures consistency on smaller and unbalanced samples. An effective architecture, domain-specific preprocessing, and interpretable outputs make the proposed framework scalable, precise, and computationally inexpensive for detecting grape leaf diseases.

</details>


### [11] [Human-Like Coarse Object Representations in Vision Models](https://arxiv.org/abs/2602.12486)
*Andrey Gizdov,Andrea Procopio,Yichen Li,Daniel Harari,Tomer Ullman*

Main category: cs.CV

TL;DR: 该研究发现分割模型对齐人类物理直觉的表征遵循倒U型曲线：小/短期训练/剪枝模型欠分割为团块，大/完整训练模型出现过分割的边界抖动，最优中间粒度最接近人类。这表明人类粗粒度体表征源于资源约束而非特殊偏见，并指向通过早期检查点、中等架构、轻度剪枝等简单调整可获得物理高效表征。


<details>
  <summary>Details</summary>
Motivation: 人类在直觉物理推理中似乎使用粗粒度的‘体积体’来平滑凹面，以视觉细节换取高效的物理预测，但其内部结构尚不清楚。而分割模型虽然优化像素级精确掩码，但可能与人类这种表征不一致。因此研究者探索分割模型何时及如何获得类人体表征。

Method: 使用碰撞时间(TTC)行为范式，建立比较流程和对齐指标，并系统改变模型的训练时长、大小和通过剪枝调整的有效容量，以此来评估模型分割结果与人类行为数据的匹配程度。

Result: 所有实验结果显示，模型与人类行为的对齐性呈现倒U型曲线：小型/短暂训练/重度剪枝模型会产生欠分割形成块状结构；大型/充分训练模型会出现边界抖动的过分割；而中等粒度的表征最匹配人类。资源受限模型更接近人类物理推断表征。

Conclusion: 人类粗粒度体表征主要源于资源约束而非特化偏见。通过调整模型复杂度(如使用早期检查点、中等架构、轻度剪枝)可以激发物理高效的类人表征，这支持了在识别细节与物理可用性间取得平衡的资源理性解释。

Abstract: Humans appear to represent objects for intuitive physics with coarse, volumetric bodies'' that smooth concavities - trading fine visual details for efficient physical predictions - yet their internal structure is largely unknown. Segmentation models, in contrast, optimize pixel-accurate masks that may misalign with such bodies. We ask whether and when these models nonetheless acquire human-like bodies. Using a time-to-collision (TTC) behavioral paradigm, we introduce a comparison pipeline and alignment metric, then vary model training time, size, and effective capacity via pruning. Across all manipulations, alignment with human behavior follows an inverse U-shaped curve: small/briefly trained/pruned models under-segment into blobs; large/fully trained models over-segment with boundary wiggles; and an intermediate ideal body granularity'' best matches humans. This suggests human-like coarse bodies emerge from resource constraints rather than bespoke biases, and points to simple knobs - early checkpoints, modest architectures, light pruning - for eliciting physics-efficient representations. We situate these results within resource-rational accounts balancing recognition detail against physical affordances.

</details>


### [12] [Insertion Network for Image Sequence Correspondence](https://arxiv.org/abs/2602.12489)
*Dingjie Su,Weixiang Hong,Benoit M. Dawant,Bennett A. Landman*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a novel method for establishing correspondence between two sequences of 2D images. One particular application of this technique is slice-level content navigation, where the goal is to localize specific 2D slices within a 3D volume or determine the anatomical coverage of a 3D scan based on its 2D slices. This serves as an important preprocessing step for various diagnostic tasks, as well as for automatic registration and segmentation pipelines. Our approach builds sequence correspondence by training a network to learn how to insert a slice from one sequence into the appropriate position in another. This is achieved by encoding contextual representations of each slice and modeling the insertion process using a slice-to-slice attention mechanism. We apply this method to localize manually labeled key slices in body CT scans and compare its performance to the current state-of-the-art alternative known as body part regression, which predicts anatomical position scores for individual slices. Unlike body part regression, which treats each slice independently, our method leverages contextual information from the entire sequence. Experimental results show that the insertion network reduces slice localization errors in supervised settings from 8.4 mm to 5.4 mm, demonstrating a substantial improvement in accuracy.

</details>


### [13] [Layer-Specific Fine-Tuning for Improved Negation Handling in Medical Vision-Language Models](https://arxiv.org/abs/2602.12498)
*Ali Abbasi,Mehdi Taghipour,Rahmatollah Beheshti*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Negation is a fundamental linguistic operation in clinical reporting, yet vision-language models (VLMs) frequently fail to distinguish affirmative from negated medical statements. To systematically characterize this limitation, we introduce a radiology-specific diagnostic benchmark that evaluates polarity sensitivity under controlled clinical conditions, revealing that common medical VLMs consistently confuse negated and non-negated findings. To enable learning beyond simple condition absence, we further construct a contextual clinical negation dataset that encodes structured claims and supports attribute-level negations involving location and severity. Building on these resources, we propose Negation-Aware Selective Training (NAST), an interpretability-guided adaptation method that uses causal tracing effects (CTEs) to modulate layer-wise gradient updates during fine-tuning. Rather than applying uniform learning rates, NAST scales each layer's update according to its causal contribution to negation processing, transforming mechanistic interpretability signals into a principled optimization rule. Experiments demonstrate improved discrimination of affirmative and negated clinical statements without degrading general vision-language alignment, highlighting the value of causal interpretability for targeted model adaptation in safety-critical medical settings. Code and resources are available at https://github.com/healthylaife/NAST.

</details>


### [14] [Matching of SAR and optical images based on transformation to shared modality](https://arxiv.org/abs/2602.12515)
*Alexey Borisov,Evgeny Myasnikov,Vladislav Myasnikov*

Main category: cs.CV

TL;DR: 提出了将光学和SAR图像转换到共享模态的新方法，以解决两者因物理原理差异导致的匹配困难问题。


<details>
  <summary>Details</summary>
Motivation: 由于光学图像与合成孔径雷达(SAR)图像在获取物理原理上的根本差异，使得这两种类型的图像难以实现精确配准（共配准）。现有的基于模态转换的方法效果有限，需要一种能更好处理这种跨模态匹配的新方法。

Method: 1. 将光学和SAR图像转换到新的共享模态，该模态需满足三个条件：预定数量通道、转换后图像尽可能相似且保持原始图像重要特征的非退化性。2. 在转换后的共享模态图像上，训练RoMa图像匹配模型，该模型原本是针对常规数码照片匹配的领先解决方案。

Result: 在包含光学和SAR图像的公开MultiSenGE数据集上评估，结果表明该方法优于基于原始模态间图像转换和各种特征匹配算法的替代方法。不仅匹配质量更好，而且更具通用性。

Conclusion: 提出的解决方案能够在不重新训练新模态的情况下，直接使用为常规图像预训练的RoMa和DeDoDe现成模型，同时保持光学和SAR图像的高质量匹配。

Abstract: Significant differences in optical images and Synthetic Aperture Radar (SAR) images are caused by fundamental differences in the physical principles underlying their acquisition by Earth remote sensing platforms. These differences make precise image matching (co-registration) of these two types of images difficult. In this paper, we propose a new approach to image matching of optical and SAR images, which is based on transforming the images to a new modality. The new image modality is common to both optical and SAR images and satisfies the following conditions. First, the transformed images must have an equal pre-defined number of channels. Second, the transformed and co-registered images must be as similar as possible. Third, the transformed images must be non-degenerate, meaning they must preserve the significant features of the original images. To further match images transformed to this shared modality, we train the RoMa image matching model, which is one of the leading solutions for matching of regular digital photographs. We evaluated the proposed approach on the publicly available MultiSenGE dataset containing both optical and SAR images. We demonstrated its superiority over alternative approaches based on image translation between original modalities and various feature matching algorithms. The proposed solution not only provides better quality of matching, but is also more versatile. It enables the use of ready-made RoMa and DeDoDe models, pre-trained for regular images, without retraining for a new modality, while maintaining high-quality matching of optical and SAR images.

</details>


### [15] [LiDAR-Anchored Collaborative Distillation for Robust 2D Representations](https://arxiv.org/abs/2602.12524)
*Wonjun Jo,Hyunwoo Ha,Kim Ji-Yeon,Hawook Jeong,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As deep learning continues to advance, self-supervised learning has made considerable strides. It allows 2D image encoders to extract useful features for various downstream tasks, including those related to vision-based systems. Nevertheless, pre-trained 2D image encoders fall short in conducting the task under noisy and adverse weather conditions beyond clear daytime scenes, which require for robust visual perception. To address these issues, we propose a novel self-supervised approach, \textbf{Collaborative Distillation}, which leverages 3D LiDAR as self-supervision to improve robustness to noisy and adverse weather conditions in 2D image encoders while retaining their original capabilities. Our method outperforms competing methods in various downstream tasks across diverse conditions and exhibits strong generalization ability. In addition, our method also improves 3D awareness stemming from LiDAR's characteristics. This advancement highlights our method's practicality and adaptability in real-world scenarios.

</details>


### [16] [Self-Supervised JEPA-based World Models for LiDAR Occupancy Completion and Forecasting](https://arxiv.org/abs/2602.12540)
*Haoran Zhu,Anna Choromanska*

Main category: cs.CV

TL;DR: 该论文提出了AD-LiST-JEPA，一种基于LiDAR的自监督世界模型，用于自动驾驶环境预测。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要能在物理世界中运作，因此需要构建能够捕捉环境时空演化的世界模型来支持长期规划。同时，为了获得可扩展性，需要以自监督方式学习这类模型，而联合嵌入预测架构（JEPA）可以利用大量无标签数据学习世界模型，无需昂贵的人工标注。

Method: 提出了AD-LiST-JEPA，这是一个基于JEPA框架的自监督世界模型，使用LiDAR数据预测未来的时空演化。通过下游的基于LiDAR的占用补全与预测（OCF）任务来评估学习到的表示质量，该任务联合评估感知和预测能力。

Result: 概念验证实验表明，在基于JEPA的世界模型学习后，使用预训练编码器的OCF性能更好。

Conclusion: AD-LiST-JEPA是一种有效的自监督世界模型方法，能够从LiDAR数据中学习驾驶环境的时空表示，并提升下游任务的性能。

Abstract: Autonomous driving, as an agent operating in the physical world, requires the fundamental capability to build \textit{world models} that capture how the environment evolves spatiotemporally in order to support long-term planning. At the same time, scalability demands learning such models in a self-supervised manner; \textit{joint-embedding predictive architecture (JEPA)} enables learning world models via leveraging large volumes of unlabeled data without relying on expensive human annotations. In this paper, we propose \textbf{AD-LiST-JEPA}, a self-supervised world model for autonomous driving that predicts future spatiotemporal evolution from LiDAR data using a JEPA framework. We evaluate the quality of the learned representations through a downstream LiDAR-based occupancy completion and forecasting (OCF) task, which jointly assesses perception and prediction. Proof of concept experiments show better OCF performance with pretrained encoder after JEPA-based world model learning.

</details>


### [17] [PLLM: Pseudo-Labeling Large Language Models for CAD Program Synthesis](https://arxiv.org/abs/2602.12561)
*Yuanbo Li,Dule Shu,Yanying Chen,Matt Klenk,Daniel Ritchie*

Main category: cs.CV

TL;DR: PLLM利用自训练框架，从无标签的3D形状合成CAD程序，无需配对的形状-程序训练数据


<details>
  <summary>Details</summary>
Motivation: 现有CAD程序合成方法依赖配对的形状-程序数据进行监督训练，但这种数据通常难以获得

Method: PLLM基于预训练的CAD能力LLM，通过迭代采样候选程序、选择高保真度执行结果、增强程序来构建合成的程序-形状对，用于微调模型

Result: 在将CAD-Recode从DeepCAD适应到无标签ABC数据集上的实验中，显示出几何保真度和程序多样性的持续提升

Conclusion: PLLM是一个有效的自训练框架，能够在无监督情况下实现CAD程序合成，解决了配对数据稀缺的问题

Abstract: Recovering Computer-Aided Design (CAD) programs from 3D geometries is a widely studied problem. Recent advances in large language models (LLMs) have enabled progress in CAD program synthesis, but existing methods rely on supervised training with paired shape-program data, which is often unavailable. We introduce PLLM, a self-training framework for CAD program synthesis from unlabeled 3D shapes. Given a pre-trained CAD-capable LLM and a shape dataset, PLLM iteratively samples candidate programs, selects high-fidelity executions, and augments programs to construct synthetic program-shape pairs for fine-tuning. We experiment on adapting CAD-Recode from DeepCAD to the unlabeled ABC dataset show consistent improvements in geometric fidelity and program diversity.

</details>


### [18] [The Constant Eye: Benchmarking and Bridging Appearance Robustness in Autonomous Driving](https://arxiv.org/abs/2602.12563)
*Jiabao Wang,Hongyu Zhou,Yuanbo Yang,Jiahao Shao,Yiyi Liao*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Despite rapid progress, autonomous driving algorithms remain notoriously fragile under Out-of-Distribution (OOD) conditions. We identify a critical decoupling failure in current research: the lack of distinction between appearance-based shifts, such as weather and lighting, and structural scene changes. This leaves a fundamental question unanswered: Is the planner failing because of complex road geometry, or simply because it is raining? To resolve this, we establish navdream, a high-fidelity robustness benchmark leveraging generative pixel-aligned style transfer. By creating a visual stress test with negligible geometric deviation, we isolate the impact of appearance on driving performance. Our evaluation reveals that existing planning algorithms often show significant degradation under OOD appearance conditions, even when the underlying scene structure remains consistent. To bridge this gap, we propose a universal perception interface leveraging a frozen visual foundation model (DINOv3). By extracting appearance-invariant features as a stable interface for the planner, we achieve exceptional zero-shot generalization across diverse planning paradigms, including regression-based, diffusion-based, and scoring-based models. Our plug-and-play solution maintains consistent performance across extreme appearance shifts without requiring further fine-tuning. The benchmark and code will be made available.

</details>


### [19] [Unbiased Gradient Estimation for Event Binning via Functional Backpropagation](https://arxiv.org/abs/2602.12590)
*Jinze Chen,Wei Zhai,Han Han,Tiankai Ma,Yang Cao,Bin Li,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Event-based vision encodes dynamic scenes as asynchronous spatio-temporal spikes called events. To leverage conventional image processing pipelines, events are typically binned into frames. However, binning functions are discontinuous, which truncates gradients at the frame level and forces most event-based algorithms to rely solely on frame-based features. Attempts to directly learn from raw events avoid this restriction but instead suffer from biased gradient estimation due to the discontinuities of the binning operation, ultimately limiting their learning efficiency. To address this challenge, we propose a novel framework for unbiased gradient estimation of arbitrary binning functions by synthesizing weak derivatives during backpropagation while keeping the forward output unchanged. The key idea is to exploit integration by parts: lifting the target functions to functionals yields an integral form of the derivative of the binning function during backpropagation, where the cotangent function naturally arises. By reconstructing this cotangent function from the sampled cotangent vector, we compute weak derivatives that provably match long-range finite differences of both smooth and non-smooth targets. Experimentally, our method improves simple optimization-based egomotion estimation with 3.2\% lower RMS error and 1.57$\times$ faster convergence. On complex downstream tasks, we achieve 9.4\% lower EPE in self-supervised optical flow, and 5.1\% lower RMS error in SLAM, demonstrating broad benefits for event-based visual perception. Source code can be found at https://github.com/chjz1024/EventFBP.

</details>


### [20] [Language-Guided Invariance Probing of Vision-Language Models](https://arxiv.org/abs/2511.13494)
*Jae Joong Lee*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent vision-language models (VLMs) such as CLIP, OpenCLIP, EVA02-CLIP and SigLIP achieve strong zero-shot performance, but it is unclear how reliably they respond to controlled linguistic perturbations. We introduce Language-Guided Invariance Probing (LGIP), a benchmark that measures (i) invariance to meaning-preserving paraphrases and (ii) sensitivity to meaning-changing semantic flips in image-text matching. Using 40k MS COCO images with five human captions each, we automatically generate paraphrases and rule-based flips that alter object category, color or count, and summarize model behavior with an invariance error, a semantic sensitivity gap and a positive-rate statistic.
  Across nine VLMs, EVA02-CLIP and large OpenCLIP variants lie on a favorable invariance-sensitivity frontier, combining low paraphrase-induced variance with consistently higher scores for original captions than for their flipped counterparts. In contrast, SigLIP and SigLIP2 show much larger invariance error and often prefer flipped captions to the human descriptions, especially for object and color edits. These failures are largely invisible to standard retrieval metrics, indicating that LGIP provides a model-agnostic diagnostic for the linguistic robustness of VLMs beyond conventional accuracy scores.

</details>


### [21] [QuEPT: Quantized Elastic Precision Transformers with One-Shot Calibration for Multi-Bit Switching](https://arxiv.org/abs/2602.12609)
*Ke Xu,Yixin Wang,Zhongcheng Li,Hao Cui,Jinshui Hu,Xingyi Zhang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Elastic precision quantization enables multi-bit deployment via a single optimization pass, fitting diverse quantization scenarios.Yet, the high storage and optimization costs associated with the Transformer architecture, research on elastic quantization remains limited, particularly for large language models.This paper proposes QuEPT, an efficient post-training scheme that reconstructs block-wise multi-bit errors with one-shot calibration on a small data slice. It can dynamically adapt to various predefined bit-widths by cascading different low-rank adapters, and supports real-time switching between uniform quantization and mixed precision quantization without repeated optimization. To enhance accuracy and robustness, we introduce Multi-Bit Token Merging (MB-ToMe) to dynamically fuse token features across different bit-widths, improving robustness during bit-width switching. Additionally, we propose Multi-Bit Cascaded Low-Rank adapters (MB-CLoRA) to strengthen correlations between bit-width groups, further improve the overall performance of QuEPT. Extensive experiments demonstrate that QuEPT achieves comparable or better performance to existing state-of-the-art post-training quantization methods.Our code is available at https://github.com/xuke225/QuEPT

</details>


### [22] [Vision Token Reduction via Attention-Driven Self-Compression for Efficient Multimodal Large Language Models](https://arxiv.org/abs/2602.12618)
*Omer Faruk Deniz,Ruiyu Mao,Ruochen Li,Yapeng Tian,Latifur Khan*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multimodal Large Language Models (MLLMs) incur significant computational cost from processing numerous vision tokens through all LLM layers. Prior pruning methods operate either before the LLM, limiting generality due to diverse encoder-projector designs or within the LLM using heuristics that are incompatible with FlashAttention. We take a different approach: rather than identifying unimportant tokens, we treat the LLM itself as the optimal guide for compression. Observing that deeper layers naturally transmit vision-to-text information, we introduce Attention-Driven Self-Compression (ADSC), a simple, broadly applicable method that progressively reduces vision tokens using only the LLM's attention mechanism. Our method applies uniform token downsampling at selected layers, forming bottlenecks that encourage the model to reorganize and compress information into the remaining tokens. It requires no score computation, auxiliary modules, or attention modification, and remains fully compatible with FlashAttention. Applied to LLaVA-1.5, ADSC reduces FLOPs by 53.7% and peak KV-cache memory by 56.7%, while preserving 98.2% of the original model performance. Across multiple benchmarks, it outperforms prior pruning approaches in both efficiency and accuracy. Crucially, under high compression ratios, our method remains robust while heuristic-based techniques degrade sharply.

</details>


### [23] [ImageRAGTurbo: Towards One-step Text-to-Image Generation with Retrieval-Augmented Diffusion Models](https://arxiv.org/abs/2602.12640)
*Peijie Qiu,Hariharan Ramshankar,Arnau Ramisa,René Vidal,Amit Kumar K C,Vamsi Salaka,Rahul Bhagat*

Main category: cs.CV

TL;DR: ImageRAGTurbo通过检索增强高效微调少步扩散模型，在保持低延迟的同时提升图像质量和提示对齐度


<details>
  <summary>Details</summary>
Motivation: 现有少步扩散模型虽能减少采样步数，但在一步生成时往往牺牲图像质量和提示对齐度，且训练计算成本高，需一种高效方法来平衡速度与质量

Method: 提出ImageRAGTurbo：1）通过检索相关文本-图像对为生成过程提供上下文信息；2）无需微调即可用检索内容编辑去噪器的潜在空间；3）在潜在空间添加可训练适配器，通过交叉注意力机制将检索内容与目标提示融合

Result: 实验表明该方法能在不增加延迟的情况下生成高质量高保真图像，相比现有方法具有优势

Conclusion: 检索增强为少步扩散模型提供了一种有效的知识注入方式，能显著提升一步生成的质量，同时保持低延迟特性，为高效文本到图像生成提供了新思路

Abstract: Diffusion models have emerged as the leading approach for text-to-image generation. However, their iterative sampling process, which gradually morphs random noise into coherent images, introduces significant latency that limits their applicability. While recent few-step diffusion models reduce the number of sampling steps to as few as one to four steps, they often compromise image quality and prompt alignment, especially in one-step generation. Additionally, these models require computationally expensive training procedures. To address these limitations, we propose ImageRAGTurbo, a novel approach to efficiently finetune few-step diffusion models via retrieval augmentation. Given a text prompt, we retrieve relevant text-image pairs from a database and use them to condition the generation process. We argue that such retrieved examples provide rich contextual information to the UNet denoiser that helps reduce the number of denoising steps without compromising image quality. Indeed, our initial investigations show that using the retrieved content to edit the denoiser's latent space ($\mathcal{H}$-space) without additional finetuning already improves prompt fidelity. To further improve the quality of the generated images, we augment the UNet denoiser with a trainable adapter in the $\mathcal{H}$-space, which efficiently blends the retrieved content with the target prompt using a cross-attention mechanism. Experimental results on fast text-to-image generation demonstrate that our approach produces high-fidelity images without compromising latency compared to existing methods.

</details>


### [24] [Multi-Task Learning with Additive U-Net for Image Denoising and Classification](https://arxiv.org/abs/2602.12649)
*Vikram Lakkavalli,Neelam Sinha*

Main category: cs.CV

TL;DR: AddUNet使用加法跳跃连接替代传统拼接式跳跃，在图像去噪和多任务学习中通过结构正则化实现稳定训练和任务感知的特征分配


<details>
  <summary>Details</summary>
Motivation: 研究UNet架构中的跳跃连接融合方式，旨在通过约束跳跃连接容量来稳定多任务学习优化，同时保持特征维度一致

Method: 提出Additive U-Net，用门控加法融合取代拼接式跳跃连接，保持特征维度不变，并通过这种结构正则化控制编码器-解码器信息流

Result: AddUNet在单任务去噪和联合去噪分类任务中实现竞争性重建性能，训练稳定性提高。在多任务学习中，浅层跳跃连接支持重建任务，深层特征支持分类任务

Conclusion: 简单的跳跃连接约束可作为有效的架构正则化器，实现稳定可扩展的多任务学习而不增加模型复杂度，加法融合能实现隐式任务解耦

Abstract: We investigate additive skip fusion in U-Net architectures for image denoising and denoising-centric multi-task learning (MTL). By replacing concatenative skips with gated additive fusion, the proposed Additive U-Net (AddUNet) constrains shortcut capacity while preserving fixed feature dimensionality across depth. This structural regularization induces controlled encoder-decoder information flow and stabilizes joint optimization. Across single-task denoising and joint denoising-classification settings, AddUNet achieves competitive reconstruction performance with improved training stability. In MTL, learned skip weights exhibit systematic task-aware redistribution: shallow skips favor reconstruction, while deeper features support discrimination. Notably, reconstruction remains robust even under limited classification capacity, indicating implicit task decoupling through additive fusion. These findings show that simple constraints on skip connections act as an effective architectural regularizer for stable and scalable multi-task learning without increasing model complexity.

</details>


### [25] [CBEN -- A Multimodal Machine Learning Dataset for Cloud Robust Remote Sensing Image Understanding](https://arxiv.org/abs/2602.12652)
*Marco Stricker,Masakazu Iwamura,Koichi Kise*

Main category: cs.CV

TL;DR: TLDR: 当前光学与雷达数据结合的多模态深度学习研究多为去云图像，而忽略有云场景，导致在有云条件下性能下降。我们构建了CloudyBigEarthNet数据集，并通过实验证明将有云场景加入训练能显著提升模型在云遮挡下的表现。


<details>
  <summary>Details</summary>
Motivation: 动机：光学卫星图像常受云层干扰，多数研究在云去除或排除有云图像上进行，限制了方法在如自然灾害等关键场景下的实用性与时效性。因此，需开发对云鲁棒的方法，利用不受云影响的雷达数据与有云光学数据结合，以提升在云遮挡条件下的分析能力。

Method: 方法：构建包含云遮挡的成对光学与雷达图像数据集CloudyBigEarthNet，用作训练与评估。对现有结合光学与雷达方法进行有云数据调整训练，并与原方法对比。

Result: 结果：基于平均精度评估，现有最优方法在云图像上进行测试时，性能下降23%-33%。通过对有云光学数据进行适应训练，相对原方案在云遮挡场景下取得17.2%-28.7%的性能提升。

Conclusion: 结论：通过构建含云光学与雷达配对数据集并纳入有云图像进行训练，可以显著增强多模态学习方法对云遮挡的鲁棒性，从而提升其在云影响场景下的实用性。

Abstract: Clouds are a common phenomenon that distorts optical satellite imagery, which poses a challenge for remote sensing. However, in the literature cloudless analysis is often performed where cloudy images are excluded from machine learning datasets and methods. Such an approach cannot be applied to time sensitive applications, e.g., during natural disasters. A possible solution is to apply cloud removal as a preprocessing step to ensure that cloudfree solutions are not failing under such conditions. But cloud removal methods are still actively researched and suffer from drawbacks, such as generated visual artifacts. Therefore, it is desirable to develop cloud robust methods that are less affected by cloudy weather. Cloud robust methods can be achieved by combining optical data with radar, a modality unaffected by clouds. While many datasets for machine learning combine optical and radar data, most researchers exclude cloudy images. We identify this exclusion from machine learning training and evaluation as a limitation that reduces applicability to cloudy scenarios. To investigate this, we assembled a dataset, named CloudyBigEarthNet (CBEN), of paired optical and radar images with cloud occlusion for training and evaluation. Using average precision (AP) as the evaluation metric, we show that state-of-the-art methods trained on combined clear-sky optical and radar imagery suffer performance drops of 23-33 percentage points when evaluated on cloudy images. We then adapt these methods to cloudy optical data during training, achieving relative improvement of 17.2-28.7 percentage points on cloudy test cases compared with the original approaches. Code and dataset are publicly available at: https://github.com/mstricker13/CBEN

</details>


### [26] [Motion Prior Distillation in Time Reversal Sampling for Generative Inbetweening](https://arxiv.org/abs/2602.12679)
*Wooseok Jeon,Seunghyun Shin,Dongmin Shin,Hae-Gon Jeon*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent progress in image-to-video (I2V) diffusion models has significantly advanced the field of generative inbetweening, which aims to generate semantically plausible frames between two keyframes. In particular, inference-time sampling strategies, which leverage the generative priors of large-scale pre-trained I2V models without additional training, have become increasingly popular. However, existing inference-time sampling, either fusing forward and backward paths in parallel or alternating them sequentially, often suffers from temporal discontinuities and undesirable visual artifacts due to the misalignment between the two generated paths. This is because each path follows the motion prior induced by its own conditioning frame. In this work, we propose Motion Prior Distillation (MPD), a simple yet effective inference-time distillation technique that suppresses bidirectional mismatch by distilling the motion residual of the forward path into the backward path. Our method can deliberately avoid denoising the end-conditioned path which causes the ambiguity of the path, and yield more temporally coherent inbetweening results with the forward motion prior. We not only perform quantitative evaluations on standard benchmarks, but also conduct extensive user studies to demonstrate the effectiveness of our approach in practical scenarios.

</details>


### [27] [Channel-Aware Probing for Multi-Channel Imaging](https://arxiv.org/abs/2602.12696)
*Umar Marikkar,Syed Sameed Husain,Muhammad Awais,Sara Atito*

Main category: cs.CV

TL;DR: 针对多通道成像（MCI）数据中通道配置多变导致预训练编码器重用困难的挑战，本文提出通道感知探测（CAP）方法，通过独立特征编码和分离池化机制提升冻结预训练编码器在下游任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 多通道成像数据中通道配置的差异性使得固定通道训练困难，预训练编码器在新通道设置下重用受限。现有研究多关注通过微调改进表征，而如何有效利用冻结的预训练表征进行下游任务研究不足。

Method: 提出通道感知探测（CAP）方法，包含两个核心组件：1）独立特征编码（IFE）对每个通道单独编码；2）分离池化（DCP）先在通道内池化再跨通道聚合。该设计有效利用了MCI数据中的跨通道多样性。

Result: 在三个MCI基准测试上，CAP一致优于默认探测协议，匹配从头开始训练的性能，并显著缩小了与全微调方法（使用相同MCI预训练检查点）的性能差距。

Conclusion: CAP方法通过有效利用多通道成像数据中的跨通道多样性，显著提升了冻结预训练编码器在下游任务中的表现，为解决MCI数据中通道配置多变带来的挑战提供了有效方案。

Abstract: Training and evaluating vision encoders on Multi-Channel Imaging (MCI) data remains challenging as channel configurations vary across datasets, preventing fixed-channel training and limiting reuse of pre-trained encoders on new channel settings. Prior work trains MCI encoders but typically evaluates them via full fine-tuning, leaving probing with frozen pre-trained encoders comparatively underexplored. Existing studies that perform probing largely focus on improving representations, rather than how to best leverage fixed representations for downstream tasks. Although the latter problem has been studied in other domains, directly transferring those strategies to MCI yields weak results, even worse than training from scratch. We therefore propose Channel-Aware Probing (CAP), which exploits the intrinsic inter-channel diversity in MCI datasets by controlling feature flow at both the encoder and probe levels. CAP uses Independent Feature Encoding (IFE) to encode each channel separately, and Decoupled Pooling (DCP) to pool within channels before aggregating across channels. Across three MCI benchmarks, CAP consistently improves probing performance over the default probing protocol, matches fine-tuning from scratch, and largely reduces the gap to full fine-tuning from the same MCI pre-trained checkpoints. Code can be found in https://github.com/umarikkar/CAP.

</details>


### [28] [VimRAG: Navigating Massive Visual Context in Retrieval-Augmented Generation via Multimodal Memory Graph](https://arxiv.org/abs/2602.12735)
*Qiuchen Wang,Shihang Wang,Yu Zeng,Qiang Zhang,Fanrui Zhang,Zhuoning Guo,Bosi Zhang,Wenxuan Huang,Lin Chen,Zehui Chen,Pengjun Xie,Ruixue Ding*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Effectively retrieving, reasoning, and understanding multimodal information remains a critical challenge for agentic systems. Traditional Retrieval-augmented Generation (RAG) methods rely on linear interaction histories, which struggle to handle long-context tasks, especially those involving information-sparse yet token-heavy visual data in iterative reasoning scenarios. To bridge this gap, we introduce VimRAG, a framework tailored for multimodal Retrieval-augmented Reasoning across text, images, and videos. Inspired by our systematic study, we model the reasoning process as a dynamic directed acyclic graph that structures the agent states and retrieved multimodal evidence. Building upon this structured memory, we introduce a Graph-Modulated Visual Memory Encoding mechanism, with which the significance of memory nodes is evaluated via their topological position, allowing the model to dynamically allocate high-resolution tokens to pivotal evidence while compressing or discarding trivial clues. To implement this paradigm, we propose a Graph-Guided Policy Optimization strategy. This strategy disentangles step-wise validity from trajectory-level rewards by pruning memory nodes associated with redundant actions, thereby facilitating fine-grained credit assignment. Extensive experiments demonstrate that VimRAG consistently achieves state-of-the-art performance on diverse multimodal RAG benchmarks. The code is available at https://github.com/Alibaba-NLP/VRAG.

</details>


### [29] [SPRig: Self-Supervised Pose-Invariant Rigging from Mesh Sequences](https://arxiv.org/abs/2602.12740)
*Ruipeng Wang,Langkun Zhong,Miaowei Wang*

Main category: cs.CV

TL;DR: 提出SPRig框架，通过跨帧一致性损失学习姿态不变的绑定系统，解决现有方法在时序数据中的拓扑不一致问题


<details>
  <summary>Details</summary>
Motivation: 现有绑定方法基于标准休息姿势假设，但在缺少T-pose的时序数据(如动物运动捕捉)中无法保持姿态不变性，导致逐帧处理时产生拓扑不一致

Method: SPRig框架基于现有模型，通过强化跨帧一致性损失来学习姿态不变的绑定系统，并提出新的置换不变稳定性验证协议

Result: 实验证明具有最先进的时间稳定性，能够从挑战性序列中生成一致的绑定系统，显著减少基线方法中的伪影

Conclusion: SPRig能够有效解决时序数据中的绑定一致性问题，提升生成的稳定性

Abstract: State-of-the-art rigging methods assume a canonical rest pose--an assumption that fails for sequential data (e.g., animal motion capture or AIGC/video-derived mesh sequences) that lack the T-pose. Applied frame-by-frame, these methods are not pose-invariant and produce topological inconsistencies across frames. Thus We propose SPRig, a general fine-tuning framework that enforces cross-frame consistency losses to learn pose-invariant rigs on top of existing models. We validate our approach on rigging using a new permutation-invariant stability protocol. Experiments demonstrate SOTA temporal stability: our method produces coherent rigs from challenging sequences and dramatically reduces the artifacts that plague baseline methods. The code will be released publicly upon acceptance.

</details>


### [30] [Synthetic Craquelure Generation for Unsupervised Painting Restoration](https://arxiv.org/abs/2602.12742)
*Jana Cuch-Guillén,Antonio Agudo,Raül Pérez-Gonzalo*

Main category: cs.CV

TL;DR: 本文提出了一种基于合成裂纹和无监督学习的美术作品细裂纹检测与修复框架，无需像素级标注就能实现高性能的壁画修复。


<details>
  <summary>Details</summary>
Motivation: 文化遗产绘画修复需要非侵入式的数字方法，但现有方法面临细裂纹检测困难、像素级标注稀缺的问题，特别是在复杂笔触背景下识别和修复裂纹具有挑战性。

Method: 1. 基于贝塞尔轨迹的域特定合成裂纹生成器模拟真实分支和渐变裂纹几何结构；
2. 经典形态学检测器结合学习型精炼模块（基于SegFormer骨干网和LoRA适配）；
3. 检测器引导策略：将形态学图作为输入空间先验；
4. 掩码混合损失和对数调整约束训练专注于裂纹区域精炼；
5. 精炼后的掩码引导各向异性扩散修复阶段重建缺失内容。

Result: 实验结果表明，该方法在零样本设置下显著优于最先进的摄影修复模型，同时能够忠实保留原始画笔笔触。

Conclusion: 该框架通过完全无标注的方法，结合合成数据和检测器引导的学习策略，有效解决了壁画修复中的细裂纹检测与修复难题，为文化遗产数字保护提供了高质量的非侵入式解决方案。

Abstract: Cultural heritage preservation increasingly demands non-invasive digital methods for painting restoration, yet identifying and restoring fine craquelure patterns from complex brushstrokes remains challenging due to scarce pixel-level annotations. We propose a fully annotation-free framework driven by a domain-specific synthetic craquelure generator, which simulates realistic branching and tapered fissure geometry using Bézier trajectories. Our approach couples a classical morphological detector with a learning-based refinement module: a SegFormer backbone adapted via Low-Rank Adaptation (LoRA). Uniquely, we employ a detector-guided strategy, injecting the morphological map as an input spatial prior, while a masked hybrid loss and logit adjustment constrain the training to focus specifically on refining candidate crack regions. The refined masks subsequently guide an Anisotropic Diffusion inpainting stage to reconstruct missing content. Experimental results demonstrate that our pipeline significantly outperforms state-of-the-art photographic restoration models in zero-shot settings, while faithfully preserving the original paint brushwork.

</details>


### [31] [ReBA-Pred-Net: Weakly-Supervised Regional Brain Age Prediction on MRI](https://arxiv.org/abs/2602.12751)
*Shuai Shao,Yan Wang,Shu Jiang,Shiyuan Zhao,Xinzhe Luo,Di Yang,Jiangtao Wang,Yutong Bai,Jianguo Zhang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Brain age has become a prominent biomarker of brain health. Yet most prior work targets whole brain age (WBA), a coarse paradigm that struggles to support tasks such as disease characterization and research on development and aging patterns, because relevant changes are typically region-selective rather than brain-wide. Therefore, robust regional brain age (ReBA) estimation is critical, yet a widely generalizable model has yet to be established. In this paper, we propose the Regional Brain Age Prediction Network (ReBA-Pred-Net), a Teacher-Student framework designed for fine-grained brain age estimation. The Teacher produces soft ReBA to guide the Student to yield reliable ReBA estimates with a clinical-prior consistency constraint (regions within the same function should change similarly). For rigorous evaluation, we introduce two indirect metrics: Healthy Control Similarity (HCS), which assesses statistical consistency by testing whether regional brain-age-gap (ReBA minus chronological age) distributions align between training and unseen HC; and Neuro Disease Correlation (NDC), which assesses factual consistency by checking whether clinically confirmed patients show elevated brain-age-gap in disease-associated regions. Experiments across multiple backbones demonstrate the statistical and factual validity of our method.

</details>


### [32] [Towards reconstructing experimental sparse-view X-ray CT data with diffusion models](https://arxiv.org/abs/2602.12755)
*Nelas J. Thomsen,Xinyuan Wang,Felix Lucka,Ezgi Demircan-Tureyen*

Main category: cs.CV

TL;DR: 基于扩散的图像生成模型可作为稀疏视图X射线CT等不适定反问题的先验。研究通过物理体模实验发现，训练数据分布偏移（域偏移）和正向模型失配会影响实际应用性能，需要针对真实数据进行验证。


<details>
  <summary>Details</summary>
Motivation: 扩散模型作为先验在合成数据上显示出潜力，但训练数据与真实数据的分布差异（域偏移）以及正向模型不匹配是否会影响其在实际实验数据中的应用效果尚不清楚。

Method: 采用物理体模测量CT数据，训练不同程度的域偏移的扩散先验模型，通过分解扩散采样方案在难度递增的稀疏视图CT数据集上进行测试。

Result: 域偏移具有双重影响：严重失配会导致模型崩溃和幻觉，而多样化的先验优于匹配度高但范围窄的先验；正向模型失配会使采样偏离先验流形产生伪影，但可通过退火似然调度缓解。

Conclusion: 合成数据上的性能优势不能直接迁移到实验数据，未来研究需要在真实场景基准上进行验证。

Abstract: Diffusion-based image generators are promising priors for ill-posed inverse problems like sparse-view X-ray Computed Tomography (CT). As most studies consider synthetic data, it is not clear whether training data mismatch (``domain shift'') or forward model mismatch complicate their successful application to experimental data. We measured CT data from a physical phantom resembling the synthetic Shepp-Logan phantom and trained diffusion priors on synthetic image data sets with different degrees of domain shift towards it. Then, we employed the priors in a Decomposed Diffusion Sampling scheme on sparse-view CT data sets with increasing difficulty leading to the experimental data. Our results reveal that domain shift plays a nuanced role: while severe mismatch causes model collapse and hallucinations, diverse priors outperform well-matched but narrow priors. Forward model mismatch pulls the image samples away from the prior manifold, which causes artifacts but can be mitigated with annealed likelihood schedules that also increase computational efficiency. Overall, we demonstrate that performance gains do not immediately translate from synthetic to experimental data, and future development must validate against real-world benchmarks.

</details>


### [33] [Towards complete digital twins in cultural heritage with ART3mis 3D artifacts annotator](https://arxiv.org/abs/2602.12761)
*Dimitrios Karamatskos,Vasileios Arampatzakis,Vasileios Sevetlidis,Stavros Nousias,Athanasios Kalogeras,Christos Koulamas,Aris Lalos,George Pavlidis*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Archaeologists, as well as specialists and practitioners in cultural heritage, require applications with additional functions, such as the annotation and attachment of metadata to specific regions of the 3D digital artifacts, to go beyond the simplistic three-dimensional (3D) visualization. Different strategies addressed this issue, most of which are excellent in their particular area of application, but their capacity is limited to their design's purpose; they lack generalization and interoperability. This paper introduces ART3mis, a general-purpose, user-friendly, feature-rich, interactive web-based textual annotation tool for 3D objects. Moreover, it enables the communication, distribution, and reuse of information as it complies with the W3C Web Annotation Data Model. It is primarily designed to help cultural heritage conservators, restorers, and curators who lack technical expertise in 3D imaging and graphics, handle, segment, and annotate 3D digital replicas of artifacts with ease.

</details>


### [34] [PixelRush: Ultra-Fast, Training-Free High-Resolution Image Generation via One-step Diffusion](https://arxiv.org/abs/2602.12769)
*Hong-Phuc Lai,Phong Nguyen,Anh Tran*

Main category: cs.CV

TL;DR: PixelRush是一种无需调参的高分辨率文本到图像生成框架，通过改进的patch-based推理和seamless blending策略，在20秒内生成4K图像，相比现有方法提速10-35倍。


<details>
  <summary>Details</summary>
Motivation: 预训练扩散模型受限于其原生训练分辨率，现有的无需训练方法在生成高分辨率图像时计算开销过大（超过5分钟生成1张4K图像）。

Method: 基于patch-based推理范式，消除多轮反转和重生成的循环，在低步数机制下实现高效的patch-based去噪；提出无缝融合策略解决patch融合伪影；加入噪声注入机制缓解过平滑效应。

Result: 在约20秒内生成4K图像，相比最先进方法提速10-35倍，同时保持卓越的视觉保真度。

Conclusion: PixelRush是首个实用的无需调参的高分辨率文本到图像生成框架，通过高效的patch-based推理技术实现了数量级的速度提升和高质量输出。

Abstract: Pre-trained diffusion models excel at generating high-quality images but remain inherently limited by their native training resolution. Recent training-free approaches have attempted to overcome this constraint by introducing interventions during the denoising process; however, these methods incur substantial computational overhead, often requiring more than five minutes to produce a single 4K image. In this paper, we present PixelRush, the first tuning-free framework for practical high-resolution text-to-image generation. Our method builds upon the established patch-based inference paradigm but eliminates the need for multiple inversion and regeneration cycles. Instead, PixelRush enables efficient patch-based denoising within a low-step regime. To address artifacts introduced by patch blending in few-step generation, we propose a seamless blending strategy. Furthermore, we mitigate over-smoothing effects through a noise injection mechanism. PixelRush delivers exceptional efficiency, generating 4K images in approximately 20 seconds representing a 10$\times$ to 35$\times$ speedup over state-of-the-art methods while maintaining superior visual fidelity. Extensive experiments validate both the performance gains and the quality of outputs achieved by our approach.

</details>


### [35] [Bootstrapping MLLM for Weakly-Supervised Class-Agnostic Object Counting](https://arxiv.org/abs/2602.12774)
*Xiaowen Zhang,Zijie Yue,Yong Luo,Cairong Zhao,Qijun Chen,Miaojing Shi*

Main category: cs.CV

TL;DR: WS-COC是首个基于MLLM驱动的弱监督类别无关物体计数框架，通过在训练和测试中引入三种简单有效的策略，显著减少了标注成本，性能可媲美甚至超越许多全监督方法。


<details>
  <summary>Details</summary>
Motivation: 完全监督的物体计数方法需要昂贵的点级标注，而现有的弱监督方法通常只能计数单个类别。论文旨在开发一个更高效、成本更低的类无关物体计数框架。

Method: 提出三种核心策略：1) 分而辨对话调优：通过多轮对话逐步缩小物体数量范围；2) 比较排序计数优化：训练MLLM对多张图像按物体数量进行相对排序；3) 全局-局部计数增强：融合局部和全局预测以提升密集场景性能。

Result: 在FSC-147、CARPK、PUCPR+和ShanghaiTech等数据集上的实验表明，WS-COC在显著降低标注成本的同时，性能可匹配甚至超越许多最先进的全监督方法。

Conclusion: WS-COC首次证实了MLLM在类无关物体计数中的有效性，为弱监督物体计数提供了新范式，在减少标注成本的同时保持了高精度。

Abstract: Object counting is a fundamental task in computer vision, with broad applicability in many real-world scenarios. Fully-supervised counting methods require costly point-level annotations per object. Few weakly-supervised methods leverage only image-level object counts as supervision and achieve fairly promising results. They are, however, often limited to counting a single category, e.g. person. In this paper, we propose WS-COC, the first MLLM-driven weakly-supervised framework for class-agnostic object counting. Instead of directly fine-tuning MLLMs to predict object counts, which can be challenging due to the modality gap, we incorporate three simple yet effective strategies to bootstrap the counting paradigm in both training and testing: First, a divide-and-discern dialogue tuning strategy is proposed to guide the MLLM to determine whether the object count falls within a specific range and progressively break down the range through multi-round dialogue. Second, a compare-and-rank count optimization strategy is introduced to train the MLLM to optimize the relative ranking of multiple images according to their object counts. Third, a global-and-local counting enhancement strategy aggregates and fuses local and global count predictions to improve counting performance in dense scenes. Extensive experiments on FSC-147, CARPK, PUCPR+, and ShanghaiTech show that WS-COC matches or even surpasses many state-of-art fully-supervised methods while significantly reducing annotation costs. Code is available at https://github.com/viscom-tongji/WS-COC.

</details>


### [36] [Thinking Like a Radiologist: A Dataset for Anatomy-Guided Interleaved Vision Language Reasoning in Chest X-ray Interpretation](https://arxiv.org/abs/2602.12843)
*Yichen Zhao,Zelin Peng,Piao Yang,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Radiological diagnosis is a perceptual process in which careful visual inspection and language reasoning are repeatedly interleaved. Most medical large vision language models (LVLMs) perform visual inspection only once and then rely on text-only chain-of-thought (CoT) reasoning, which operates purely in the linguistic space and is prone to hallucination. Recent methods attempt to mitigate this issue by introducing visually related coordinates, such as bounding boxes. However, these remain a pseudo-visual solution: coordinates are still text and fail to preserve rich visual details like texture and density. Motivated by the interleaved nature of radiological diagnosis, we introduce MMRad-IVL-22K, the first large-scale dataset designed for natively interleaved visual language reasoning in chest X-ray interpretation. MMRad-IVL-22K reflects a repeated cycle of reasoning and visual inspection workflow of radiologists, in which visual rationales complement textual descriptions and ground each step of the reasoning process. MMRad-IVL-22K comprises 21,994 diagnostic traces, enabling systematic scanning across 35 anatomical regions. Experimental results on advanced closed-source LVLMs demonstrate that report generation guided by multimodal CoT significantly outperforms that guided by text-only CoT in clinical accuracy and report quality (e.g., 6\% increase in the RadGraph metric), confirming that high-fidelity interleaved vision language evidence is a non-substitutable component of reliable medical AI. Furthermore, benchmarking across seven state-of-the-art open-source LVLMs demonstrates that models fine-tuned on MMRad-IVL-22K achieve superior reasoning consistency and report quality compared with both general-purpose and medical-specific LVLMs. The project page is available at https://github.com/qiuzyc/thinking_like_a_radiologist.

</details>


### [37] [RoadscapesQA: A Multitask, Multimodal Dataset for Visual Question Answering on Indian Roads](https://arxiv.org/abs/2602.12877)
*Vijayasri Iyer,Maahin Rathinagiriswaran,Jyothikamalesh S*

Main category: cs.CV

TL;DR: Roadscapes是一个印度驾驶场景的多任务多模态数据集，包含9000张图像和标注，用于自动驾驶视觉场景理解研究。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要理解复杂的道路场景来辅助决策，特别是像印度这样的无序环境，现有数据集往往缺乏多样性和规模。

Method: 使用规则启发式方法自动生成问答对，涵盖对象定位、推理和场景理解等任务；数据集包含城市和乡村多种场景图像，配有手动验证的边界框标注。

Result: 提供了数据集详细统计和基线实验，展示了视觉语言模型在图像问答任务上的初步性能。

Conclusion: Roadscapes数据集能促进非结构化环境中视觉场景理解的研究，为自动驾驶提供更全面的评估基准。

Abstract: Understanding road scenes is essential for autonomous driving, as it enables systems to interpret visual surroundings to aid in effective decision-making. We present Roadscapes, a multitask multimodal dataset consisting of upto 9,000 images captured in diverse Indian driving environments, accompanied by manually verified bounding boxes. To facilitate scalable scene understanding, we employ rule-based heuristics to infer various scene attributes, which are subsequently used to generate question-answer (QA) pairs for tasks such as object grounding, reasoning, and scene understanding. The dataset includes a variety of scenes from urban and rural India, encompassing highways, service roads, village paths, and congested city streets, captured in both daytime and nighttime settings. Roadscapes has been curated to advance research on visual scene understanding in unstructured environments. In this paper, we describe the data collection and annotation process, present key dataset statistics, and provide initial baselines for image QA tasks using vision-language models.

</details>


### [38] [RADAR: Revealing Asymmetric Development of Abilities in MLLM Pre-training](https://arxiv.org/abs/2602.12892)
*Yunshuang Nie,Bingqian Lin,Minzhe Niu,Kun Xiang,Jianhua Han,Guowei Huang,Xingyue Quan,Hang Xu,Bokui Chen,Xiaodan Liang*

Main category: cs.CV

TL;DR: RADAR是一个用于评估预训练多模态大语言模型（MLLMs）中感知与推理能力不对称发展的高效评估框架，包含Soft Discrimination Score（SDS）度量方法和Multi-Modal Mixture Benchmark（MMMB）数据集，可在零样本下无需微调即进行全面评估。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法主要依赖监督微调后的测试，这带来了额外的训练和解码成本，且常见的预训练指标无法以解耦的方式量化模型的感知和推理能力。同时，现有的评估基准通常数据规模有限或与预训练目标不一致，缺乏高效的性能瓶颈诊断工具。

Method: RADAR框架包含两个关键组件：1）Soft Discrimination Score（SDS）：一种无需微调的鲁棒性度量指标，通过量化模型对正确答案相对于干扰项的偏好程度来追踪能力发展；2）Multi-Modal Mixture Benchmark（MMMB）：包含1.5万+样本的零样本评估基准，整合了权威基准数据集并收集新数据集，全面评估预训练MLLMs的感知和推理能力。

Result: 使用RADAR评估框架，全面揭示了预训练MLLMs在不同因素（包括数据量、模型规模和预训练策略）下感知和推理能力的不对称发展模式，为针对性干预提供了依据。

Conclusion: RADAR框架强调了分解视角看待预训练能力瓶颈的必要性，为高效推进MLLMs发展提供了有针对性的指导。该框架代码已在GitHub开源。

Abstract: Pre-trained Multi-modal Large Language Models (MLLMs) provide a knowledge-rich foundation for post-training by leveraging their inherent perception and reasoning capabilities to solve complex tasks. However, the lack of an efficient evaluation framework impedes the diagnosis of their performance bottlenecks. Current evaluation primarily relies on testing after supervised fine-tuning, which introduces laborious additional training and autoregressive decoding costs. Meanwhile, common pre-training metrics cannot quantify a model's perception and reasoning abilities in a disentangled manner. Furthermore, existing evaluation benchmarks are typically limited in scale or misaligned with pre-training objectives. Thus, we propose RADAR, an efficient ability-centric evaluation framework for Revealing Asymmetric Development of Abilities in MLLM pRe-training. RADAR involves two key components: (1) Soft Discrimination Score, a novel metric for robustly tracking ability development without fine-tuning, based on quantifying nuanced gradations of the model preference for the correct answer over distractors; and (2) Multi-Modal Mixture Benchmark, a new 15K+ sample benchmark for comprehensively evaluating pre-trained MLLMs' perception and reasoning abilities in a 0-shot manner, where we unify authoritative benchmark datasets and carefully collect new datasets, extending the evaluation scope and addressing the critical gaps in current benchmarks. With RADAR, we comprehensively reveal the asymmetric development of perceptual and reasoning capabilities in pretrained MLLMs across diverse factors, including data volume, model size, and pretraining strategy. Our RADAR underscores the need for a decomposed perspective on pre-training ability bottlenecks, informing targeted interventions to advance MLLMs efficiently. Our code is publicly available at https://github.com/Nieysh/RADAR.

</details>


### [39] [Robustness of Object Detection of Autonomous Vehicles in Adverse Weather Conditions](https://arxiv.org/abs/2602.12902)
*Fox Pettersen,Hong Zhu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As self-driving technology advances toward widespread adoption, determining safe operational thresholds across varying environmental conditions becomes critical for public safety. This paper proposes a method for evaluating the robustness of object detection ML models in autonomous vehicles under adverse weather conditions. It employs data augmentation operators to generate synthetic data that simulates different severance degrees of the adverse operation conditions at progressive intensity levels to find the lowest intensity of the adverse conditions at which the object detection model fails. The robustness of the object detection model is measured by the average first failure coefficients (AFFC) over the input images in the benchmark. The paper reports an experiment with four object detection models: YOLOv5s, YOLOv11s, Faster R-CNN, and Detectron2, utilising seven data augmentation operators that simulate weather conditions fog, rain, and snow, and lighting conditions of dark, bright, flaring, and shadow. The experiment data show that the method is feasible, effective, and efficient to evaluate and compare the robustness of object detection models in various adverse operation conditions. In particular, the Faster R-CNN model achieved the highest robustness with an overall average AFFC of 71.9% over all seven adverse conditions, while YOLO variants showed the AFFC values of 43%. The method is also applied to assess the impact of model training that targets adverse operation conditions using synthetic data on model robustness. It is observed that such training can improve robustness in adverse conditions but may suffer from diminishing returns and forgetting phenomena (i.e., decline in robustness) if overtrained.

</details>


### [40] [Reliable Thinking with Images](https://arxiv.org/abs/2602.12916)
*Haobin Li,Yutong Yang,Yijie Lin,Dai Xiang,Mouxing Yang,Xi Peng*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As a multimodal extension of Chain-of-Thought (CoT), Thinking with Images (TWI) has recently emerged as a promising avenue to enhance the reasoning capability of Multi-modal Large Language Models (MLLMs), which generates interleaved CoT by incorporating visual cues into the textual reasoning process. However, the success of existing TWI methods heavily relies on the assumption that interleaved image-text CoTs are faultless, which is easily violated in real-world scenarios due to the complexity of multimodal understanding. In this paper, we reveal and study a highly-practical yet under-explored problem in TWI, termed Noisy Thinking (NT). Specifically, NT refers to the imperfect visual cues mining and answer reasoning process. As the saying goes, ``One mistake leads to another'', erroneous interleaved CoT would cause error accumulation, thus significantly degrading the performance of MLLMs. To solve the NT problem, we propose a novel method dubbed Reliable Thinking with Images (RTWI). In brief, RTWI estimates the reliability of visual cues and textual CoT in a unified text-centric manner and accordingly employs robust filtering and voting modules to prevent NT from contaminating the final answer. Extensive experiments on seven benchmarks verify the effectiveness of RTWI against NT.

</details>


### [41] [EPRBench: A High-Quality Benchmark Dataset for Event Stream Based Visual Place Recognition](https://arxiv.org/abs/2602.12919)
*Xiao Wang,Xingxing Xiong,Jinfeng Gao,Xufeng Lou,Bo Jiang,Si-bao Chen,Yaowei Wang,Yonghong Tian*

Main category: cs.CV

TL;DR: EPRBench是一个专为基于事件流的视觉定位识别（VPR）设计的高质量基准数据集，包含10K个事件序列和65K个事件帧，涵盖多种现实场景，并提供LLM生成和人工修正的场景描述。该研究同时提出了一种新颖的多模态融合VPR框架，利用LLM从原始事件流生成文本描述，实现空间注意token选择、跨模态特征融合和多尺度表征学习，不仅提高了定位准确性，还增强了模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的可见光相机在低光照、过曝光和高速运动等挑战性条件下表现不稳定，而基于事件流的VPR技术为这些问题提供了有前景的解决方案。然而，目前该领域缺乏专用数据集，阻碍了相关研究的系统性发展。为了填补这一空白，并支持语义感知和语言集成的VPR研究，有必要构建一个高质量的基准数据集和评估框架。

Method: 研究首先构建了EPRBench数据集，包含手持和车载设备采集的10K事件序列和65K事件帧，覆盖多样化视角、天气和光照条件。同时提供LLM生成并经过人工修正的场景描述。在方法上，提出了一种新颖的多模态融合VPR框架：利用LLM从原始事件流生成文本场景描述，指导空间注意token选择、跨模态特征融合和多尺度表征学习。该方法还实现了15种最先进的VPR算法在EPRBench上的基准测试。

Result: EPRBench数据集为基于事件流的VPR研究提供了高质量资源。提出的多模态融合VPR框架不仅实现了高精度的定位识别，还生成了可解释的推理过程，显著提升了模型的透明度和可解释性。该框架在EPRBench上的表现为未来算法比较提供了强基准。

Conclusion: EPRBench填补了基于事件流VPR领域的数据集空白，为语义感知和语言集成的VPR研究奠定了基础。提出的多模态融合框架展示了将LLM整合到事件感知管道中的潜力，不仅提升了性能，还增强了模型的可解释性。这些贡献将推动事件型VPR技术的进一步发展。

Abstract: Event stream-based Visual Place Recognition (VPR) is an emerging research direction that offers a compelling solution to the instability of conventional visible-light cameras under challenging conditions such as low illumination, overexposure, and high-speed motion. Recognizing the current scarcity of dedicated datasets in this domain, we introduce EPRBench, a high-quality benchmark specifically designed for event stream-based VPR. EPRBench comprises 10K event sequences and 65K event frames, collected using both handheld and vehicle-mounted setups to comprehensively capture real-world challenges across diverse viewpoints, weather conditions, and lighting scenarios. To support semantic-aware and language-integrated VPR research, we provide LLM-generated scene descriptions, subsequently refined through human annotation, establishing a solid foundation for integrating LLMs into event-based perception pipelines. To facilitate systematic evaluation, we implement and benchmark 15 state-of-the-art VPR algorithms on EPRBench, offering a strong baseline for future algorithmic comparisons. Furthermore, we propose a novel multi-modal fusion paradigm for VPR: leveraging LLMs to generate textual scene descriptions from raw event streams, which then guide spatially attentive token selection, cross-modal feature fusion, and multi-scale representation learning. This framework not only achieves highly accurate place recognition but also produces interpretable reasoning processes alongside its predictions, significantly enhancing model transparency and explainability. The dataset and source code will be released on https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [42] [Beyond Benchmarks of IUGC: Rethinking Requirements of Deep Learning Methods for Intrapartum Ultrasound Biometry from Fetal Ultrasound Videos](https://arxiv.org/abs/2602.12922)
*Jieyun Bai,Zihao Zhou,Yitong Tang,Jie Gan,Zhuonan Liang,Jianan Fan,Lisa B. Mcguire,Jillian L. Clarke,Weidong Cai,Jacaueline Spurway,Yubo Tang,Shiye Wang,Wenda Shen,Wangwang Yu,Yihao Li,Philippe Zhang,Weili Jiang,Yongjie Li,Salem Muhsin Ali Binqahal Al Nasim,Arsen Abzhanov,Numan Saeed,Mohammad Yaqub,Zunhui Xian,Hongxing Lin,Libin Lan,Jayroop Ramesh,Valentin Bacher,Mark Eid,Hoda Kalabizadeh,Christian Rupprecht,Ana I. L. Namburete,Pak-Hei Yeung,Madeleine K. Wyburd,Nicola K. Dinsdale,Assanali Serikbey,Jiankai Li,Sung-Liang Chen,Zicheng Hu,Nana Liu,Yian Deng,Wei Hu,Cong Tan,Wenfeng Zhang,Mai Tuyet Nhi,Gregor Koehler,Rapheal Stock,Klaus Maier-Hein,Marawan Elbatel,Xiaomeng Li,Saad Slimani,Victor M. Campello,Benard Ohene-Botwe,Isaac Khobo,Yuxin Huang,Zhenyan Han,Hongying Hou,Di Qiu,Zheng Zheng,Gongning Luo,Dong Ni,Yaosheng Lu,Karim Lekadir,Shuo Li*

Main category: cs.CV

TL;DR: 产时超声挑战赛(IUGC)旨在通过AI多任务框架解决资源有限地区缺乏超声医师的问题，推进产时生物测量自动化。


<details>
  <summary>Details</summary>
Motivation: 45%的孕产妇、新生儿死亡和死产发生在分娩期，资源有限地区缺乏专业超声医师，阻碍了超声监测的普及。

Method: 引入临床导向的多任务自动测量框架，包括标准切面分类、胎头-耻骨联合分割和生物测量，并发布最大规模的多中心产时超声视频数据集(774个视频/68,106帧)。

Result: 分析了8个参赛团队的方法，在预处理、数据增强、学习策略、模型架构和后处理等五个维度进行评估。挑战赛已取得鼓舞性成果，但该领域仍处于早期阶段。

Conclusion: 自动产时超声生物测量需要更深入的探索才能大规模临床部署，所有基准解决方案和完整数据集已公开以促进可重复研究和持续进展。

Abstract: A substantial proportion (45\%) of maternal deaths, neonatal deaths, and stillbirths occur during the intrapartum phase, with a particularly high burden in low- and middle-income countries. Intrapartum biometry plays a critical role in monitoring labor progression; however, the routine use of ultrasound in resource-limited settings is hindered by a shortage of trained sonographers. To address this challenge, the Intrapartum Ultrasound Grand Challenge (IUGC), co-hosted with MICCAI 2024, was launched. The IUGC introduces a clinically oriented multi-task automatic measurement framework that integrates standard plane classification, fetal head-pubic symphysis segmentation, and biometry, enabling algorithms to exploit complementary task information for more accurate estimation. Furthermore, the challenge releases the largest multi-center intrapartum ultrasound video dataset to date, comprising 774 videos (68,106 frames) collected from three hospitals, providing a robust foundation for model training and evaluation. In this study, we present a comprehensive overview of the challenge design, review the submissions from eight participating teams, and analyze their methods from five perspectives: preprocessing, data augmentation, learning strategy, model architecture, and post-processing. In addition, we perform a systematic analysis of the benchmark results to identify key bottlenecks, explore potential solutions, and highlight open challenges for future research. Although encouraging performance has been achieved, our findings indicate that the field remains at an early stage, and further in-depth investigation is required before large-scale clinical deployment. All benchmark solutions and the complete dataset have been publicly released to facilitate reproducible research and promote continued advances in automatic intrapartum ultrasound biometry.

</details>


### [43] [Deep-Learning Atlas Registration for Melanoma Brain Metastases: Preserving Pathology While Enabling Cohort-Level Analyses](https://arxiv.org/abs/2602.12933)
*Nanna E. Wielenberg,Ilinca Popp,Oliver Blanck,Lucas Zander,Jan C. Peeken,Stephanie E. Combs,Anca-Ligia Grosu,Dimos Baltas,Tobias Fechter*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Melanoma brain metastases (MBM) are common and spatially heterogeneous lesions, complicating cohort-level analyses due to anatomical variability and differing MRI protocols. We propose a fully differentiable, deep-learning-based deformable registration framework that aligns individual pathological brains to a common atlas while preserving metastatic tissue without requiring lesion masks or preprocessing.
  Missing anatomical correspondences caused by metastases are handled through a forward-model similarity metric based on distance-transformed anatomical labels, combined with a volume-preserving regularization term to ensure deformation plausibility. Registration performance was evaluated using Dice coefficient (DSC), Hausdorff distance (HD), average symmetric surface distance (ASSD), and Jacobian-based measures. The method was applied to 209 MBM patients from three centres, enabling standardized mapping of metastases to anatomical, arterial, and perfusion atlases.
  The framework achieved high registration accuracy across datasets (DSC 0.89-0.92, HD 6.79-7.60 mm, ASSD 0.63-0.77 mm) while preserving metastatic volumes. Spatial analysis demonstrated significant over-representation of MBM in the cerebral cortex and putamen, under-representation in white matter, and consistent localization near the gray-white matter junction. No arterial territory showed increased metastasis frequency after volume correction.
  This approach enables robust atlas registration of pathological brain MRI without lesion masks and supports reproducible multi-centre analyses. Applied to MBM, it confirms and refines known spatial predilections, particularly preferential seeding near the gray-white matter junction and cortical regions. The publicly available implementation facilitates reproducible research and extension to other brain tumours and neurological pathologies.

</details>


### [44] [Training-Free Acceleration for Document Parsing Vision-Language Model with Hierarchical Speculative Decoding](https://arxiv.org/abs/2602.12957)
*Wenhui Liao,Hongliang Li,Pengyu Xie,Xinyu Cai,Yufan Shen,Yi Xin,Qi Qin,Shenglong Ye,Tianbin Li,Ming Hu,Junjun He,Yihao Liu,Wenhai Wang,Min Dou,Bin Fu,Botian Shi,Yu Qiao,Lianwen Jin*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练、高效的文档解析加速方法，利用轻量级解析流程作为草稿模型进行批量token预测，并由更准确的VLM并行验证，再结合文档布局分区实现并行解码。


<details>
  <summary>Details</summary>
Motivation: 现有的VLM端到端文档解析模型在处理长文档时存在推理延迟高的问题，需要自回归地生成长token序列。本文旨在解决这一问题，提高文档解析效率。

Method: 基于推测解码思想，采用轻量级文档解析流程作为草稿模型预测未来token批次，由更准确的VLM并行验证预测结果。同时利用文档的布局结构特点，将页面划分为独立区域进行并行解码，最后按自然阅读顺序组合预测结果。

Result: 在通用基准OmniDocBench上，该方法为dots.ocr模型提供了2.42倍的无损加速，在长文档解析任务上最高达到4.89倍加速。

Conclusion: 本文提出的训练免费加速方法能有效提高VLM文档解析模型的推理效率，特别是在处理长文档时效果显著，且保持无损解析质量。

Abstract: Document parsing is a fundamental task in multimodal understanding, supporting a wide range of downstream applications such as information extraction and intelligent document analysis. Benefiting from strong semantic modeling and robust generalization, VLM-based end-to-end approaches have emerged as the mainstream paradigm in recent years. However, these models often suffer from substantial inference latency, as they must auto-regressively generate long token sequences when processing long-form documents. In this work, motivated by the extremely long outputs and complex layout structures commonly found in document parsing, we propose a training-free and highly efficient acceleration method. Inspired by speculative decoding, we employ a lightweight document parsing pipeline as a draft model to predict batches of future tokens, while the more accurate VLM verifies these draft predictions in parallel. Moreover, we further exploit the layout-structured nature of documents by partitioning each page into independent regions, enabling parallel decoding of each region using the same draft-verify strategy. The final predictions are then assembled according to the natural reading order. Experimental results demonstrate the effectiveness of our approach: on the general-purpose OmniDocBench, our method provides a 2.42x lossless acceleration for the dots.ocr model, and achieves up to 4.89x acceleration on long-document parsing tasks. We will release our code to facilitate reproducibility and future research.

</details>


### [45] [Detecting Object Tracking Failure via Sequential Hypothesis Testing](https://arxiv.org/abs/2602.12983)
*Alejandro Monroy Muñoz,Rajeev Verma,Alexander Timans*

Main category: cs.CV

TL;DR: 本文提出将目标跟踪视为序贯假设检验，通过e-process累积跟踪失败证据，在控制假警报率的同时快速识别跟踪故障。


<details>
  <summary>Details</summary>
Motivation: 现有的实时视频目标跟踪系统缺乏形式化的安全保障，无法可靠判断跟踪何时有效、何时失败，通常只能依靠启发式置信度测量发出警报。

Method: 将目标跟踪定义为序贯假设检验，构建e-process渐进累积跟踪失败证据。该方法计算轻量、无需额外训练或微调，且具有模型无关性。提出了监督和无监督两种变体：监督版本利用真实标签，无监督版本仅使用内部跟踪信息。

Result: 在两个成熟跟踪模型和四个视频基准测试上验证了方法的有效性，证明能够快速识别跟踪失败，同时将假警报控制在期望比率内。

Conclusion: 序贯测试为实时跟踪系统提供了统计基础强、效率高的安全保证机制，能够限制昂贵的重新校准或干预步骤。

Abstract: Real-time online object tracking in videos constitutes a core task in computer vision, with wide-ranging applications including video surveillance, motion capture, and robotics. Deployed tracking systems usually lack formal safety assurances to convey when tracking is reliable and when it may fail, at best relying on heuristic measures of model confidence to raise alerts. To obtain such assurances we propose interpreting object tracking as a sequential hypothesis test, wherein evidence for or against tracking failures is gradually accumulated over time. Leveraging recent advancements in the field, our sequential test (formalized as an e-process) quickly identifies when tracking failures set in whilst provably containing false alerts at a desired rate, and thus limiting potentially costly re-calibration or intervention steps. The approach is computationally light-weight, requires no extra training or fine-tuning, and is in principle model-agnostic. We propose both supervised and unsupervised variants by leveraging either ground-truth or solely internal tracking information, and demonstrate its effectiveness for two established tracking models across four video benchmarks. As such, sequential testing can offer a statistically grounded and efficient mechanism to incorporate safety assurances into real-time tracking systems.

</details>


### [46] [MASAR: Motion-Appearance Synergy Refinement for Joint Detection and Trajectory Forecasting](https://arxiv.org/abs/2602.13003)
*Mohammed Amine Bencheikh Lehocine,Julian Schmidt,Frank Moosmann,Dikshant Gupta,Fabian Flohr*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Classical autonomous driving systems connect perception and prediction modules via hand-crafted bounding-box interfaces, limiting information flow and propagating errors to downstream tasks. Recent research aims to develop end-to-end models that jointly address perception and prediction; however, they often fail to fully exploit the synergy between appearance and motion cues, relying mainly on short-term visual features. We follow the idea of "looking backward to look forward", and propose MASAR, a novel fully differentiable framework for joint 3D detection and trajectory forecasting compatible with any transformer-based 3D detector. MASAR employs an object-centric spatio-temporal mechanism that jointly encodes appearance and motion features. By predicting past trajectories and refining them using guidance from appearance cues, MASAR captures long-term temporal dependencies that enhance future trajectory forecasting. Experiments conducted on the nuScenes dataset demonstrate MASAR's effectiveness, showing improvements of over 20% in minADE and minFDE while maintaining robust detection performance. Code and models are available at https://github.com/aminmed/MASAR.

</details>


### [47] [Towards Universal Video MLLMs with Attribute-Structured and Quality-Verified Instructions](https://arxiv.org/abs/2602.13013)
*Yunheng Li,Hengrui Zhang,Meng-Hao Guo,Wenzhao Gao,Shaoyong Jia,Shaohui Jiao,Qibin Hou,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Universal video understanding requires modeling fine-grained visual and audio information over time in diverse real-world scenarios. However, the performance of existing models is primarily constrained by video-instruction data that represents complex audiovisual content as single, incomplete descriptions, lacking fine-grained organization and reliable annotation. To address this, we introduce: (i) ASID-1M, an open-source collection of one million structured, fine-grained audiovisual instruction annotations with single- and multi-attribute supervision; (ii) ASID-Verify, a scalable data curation pipeline for annotation, with automatic verification and refinement that enforces semantic and temporal consistency between descriptions and the corresponding audiovisual content; and (iii) ASID-Captioner, a video understanding model trained via Supervised Fine-Tuning (SFT) on the ASID-1M. Experiments across seven benchmarks covering audiovisual captioning, attribute-wise captioning, caption-based QA, and caption-based temporal grounding show that ASID-Captioner improves fine-grained caption quality while reducing hallucinations and improving instruction following. It achieves state-of-the-art performance among open-source models and is competitive with Gemini-3-Pro.

</details>


### [48] [Multimodal Classification via Total Correlation Maximization](https://arxiv.org/abs/2602.13015)
*Feng Yu,Xiangyu Wu,Yang Yang,Jianfeng Lu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multimodal learning integrates data from diverse sensors to effectively harness information from different modalities. However, recent studies reveal that joint learning often overfits certain modalities while neglecting others, leading to performance inferior to that of unimodal learning. Although previous efforts have sought to balance modal contributions or combine joint and unimodal learning, thereby mitigating the degradation of weaker modalities with promising outcomes, few have examined the relationship between joint and unimodal learning from an information-theoretic perspective. In this paper, we theoretically analyze modality competition and propose a method for multimodal classification by maximizing the total correlation between multimodal features and labels. By maximizing this objective, our approach alleviates modality competition while capturing inter-modal interactions via feature alignment. Building on Mutual Information Neural Estimation (MINE), we introduce Total Correlation Neural Estimation (TCNE) to derive a lower bound for total correlation. Subsequently, we present TCMax, a hyperparameter-free loss function that maximizes total correlation through variational bound optimization. Extensive experiments demonstrate that TCMax outperforms state-of-the-art joint and unimodal learning approaches. Our code is available at https://github.com/hubaak/TCMax.

</details>


### [49] [DynaGuide: A Generalizable Dynamic Guidance Framework for Unsupervised Semantic Segmentation](https://arxiv.org/abs/2602.13020)
*Boujemaa Guermazi,Riadh Ksantini,Naimul Khan*

Main category: cs.CV

TL;DR: DynaGuide 是一种用于无监督图像分割的自适应框架，通过双引导策略结合全局伪标签和局部边界优化，无需目标领域真实标签，在多个数据集上取得 SOTA 结果。


<details>
  <summary>Details</summary>
Motivation: 无监督图像分割在标注数据稀缺的领域具有重要价值，但现有方法难以同时保证全局语义结构和精细边界准确性。

Method: 结合零样本模型(如DiffSeg/SegFormer)的全局伪标签与从头训练的轻量CNN进行局部边界优化，采用动态平衡的多组件损失函数(特征相似度、Huber平滑空间连续性、语义对齐)。

Result: 在BSD500、PASCAL VOC2012和COCO上实现SOTA性能，mIoU分别提升17.5%、3.1%和11.66%，无需目标域真实标签，支持即插即用引导源集成。

Conclusion: DynaGuide 通过模块化设计、强泛化能力和最小计算开销，为实际场景中的无监督分割提供了可扩展的实用解决方案。

Abstract: Unsupervised image segmentation is a critical task in computer vision. It enables dense scene understanding without human annotations, which is especially valuable in domains where labelled data is scarce. However, existing methods often struggle to reconcile global semantic structure with fine-grained boundary accuracy. This paper introduces DynaGuide, an adaptive segmentation framework that addresses these challenges through a novel dual-guidance strategy and dynamic loss optimization. Building on our previous work, DynaSeg, DynaGuide combines global pseudo-labels from zero-shot models such as DiffSeg or SegFormer with local boundary refinement using a lightweight CNN trained from scratch. This synergy allows the model to correct coarse or noisy global predictions and produce high-precision segmentations. At the heart of DynaGuide is a multi-component loss that dynamically balances feature similarity, Huber-smoothed spatial continuity, including diagonal relationships, and semantic alignment with the global pseudo-labels. Unlike prior approaches, DynaGuide trains entirely without ground-truth labels in the target domain and supports plug-and-play integration of diverse guidance sources. Extensive experiments on BSD500, PASCAL VOC2012, and COCO demonstrate that DynaGuide achieves state-of-the-art performance, improving mIoU by 17.5% on BSD500, 3.1% on PASCAL VOC2012, and 11.66% on COCO. With its modular design, strong generalization, and minimal computational footprint, DynaGuide offers a scalable and practical solution for unsupervised segmentation in real-world settings. Code available at: https://github.com/RyersonMultimediaLab/DynaGuide

</details>


### [50] [Learning Image-based Tree Crown Segmentation from Enhanced Lidar-based Pseudo-labels](https://arxiv.org/abs/2602.13022)
*Julius Pesonen,Stefan Rua,Josef Taher,Niko Koivumäki,Xiaowei Yu,Eija Honkavaara*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Mapping individual tree crowns is essential for tasks such as maintaining urban tree inventories and monitoring forest health, which help us understand and care for our environment. However, automatically separating the crowns from each other in aerial imagery is challenging due to factors such as the texture and partial tree crown overlaps. In this study, we present a method to train deep learning models that segment and separate individual trees from RGB and multispectral images, using pseudo-labels derived from aerial laser scanning (ALS) data. Our study shows that the ALS-derived pseudo-labels can be enhanced using a zero-shot instance segmentation model, Segment Anything Model 2 (SAM 2). Our method offers a way to obtain domain-specific training annotations for optical image-based models without any manual annotation cost, leading to segmentation models which outperform any available models which have been targeted for general domain deployment on the same task.

</details>


### [51] [Human-Aligned MLLM Judges for Fine-Grained Image Editing Evaluation: A Benchmark, Framework, and Analysis](https://arxiv.org/abs/2602.13028)
*Runzhou Liu,Hailey Weingord,Sejal Mittal,Prakhar Dungarwal,Anusha Nandula,Bo Ni,Samyadeep Basu,Hongjie Chen,Nesreen K. Ahmed,Li Li,Jiayi Zhang,Koustava Goswami,Subhojyoti Mukherjee,Branislav Kveton,Puneet Mathur,Franck Dernoncourt,Yue Zhao,Yu Wang,Ryan A. Rossi,Zhengzhong Tu,Hongru Du*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Evaluating image editing models remains challenging due to the coarse granularity and limited interpretability of traditional metrics, which often fail to capture aspects important to human perception and intent. Such metrics frequently reward visually plausible outputs while overlooking controllability, edit localization, and faithfulness to user instructions. In this work, we introduce a fine-grained Multimodal Large Language Model (MLLM)-as-a-Judge framework for image editing that decomposes common evaluation notions into twelve fine-grained interpretable factors spanning image preservation, edit quality, and instruction fidelity. Building on this formulation, we present a new human-validated benchmark that integrates human judgments, MLLM-based evaluations, model outputs, and traditional metrics across diverse image editing tasks. Through extensive human studies, we show that the proposed MLLM judges align closely with human evaluations at a fine granularity, supporting their use as reliable and scalable evaluators. We further demonstrate that traditional image editing metrics are often poor proxies for these factors, failing to distinguish over-edited or semantically imprecise outputs, whereas our judges provide more intuitive and informative assessments in both offline and online settings. Together, this work introduces a benchmark, a principled factorization, and empirical evidence positioning fine-grained MLLM judges as a practical foundation for studying, comparing, and improving image editing approaches.

</details>


### [52] [Implicit-Scale 3D Reconstruction for Multi-Food Volume Estimation from Monocular Images](https://arxiv.org/abs/2602.13041)
*Yuhao Chen,Gautham Vinod,Siddeshwar Raghavan,Talha Ibn Mahmud,Bruce Coburn,Jinge Ma,Fengqing Zhu,Jiangpeng He*

Main category: cs.CV

TL;DR: 该研究提出了一个用于单目多食物图像隐式尺度3D重建的基准数据集，旨在改进基于几何的食物分量估计方法


<details>
  <summary>Details</summary>
Motivation: 现有的饮食评估方法主要依赖单图像分析或外观推理，包括最近的视觉-语言模型，缺乏显式几何推理且对尺度模糊性敏感，难以应对真实用餐场景

Method: 将食物分量估计重构为单目观测下的隐式尺度3D重建问题，去除显式物理参考和度量标注，通过盘子和餐具等上下文物体提供隐含尺度线索

Result: 该基准在MetaFood 2025研讨会中作为挑战赛采纳，几何重建方法表现出色，最佳方法在体积估计上达到0.21 MAPE，在几何精度上达到5.7 L1 Chamfer距离

Conclusion: 基于几何的重建方法相比视觉-语言基线在食物分量估计中提供更高准确性和鲁棒性，证明了隐式尺度3D重建在该领域的价值

Abstract: We present Implicit-Scale 3D Reconstruction from Monocular Multi-Food Images, a benchmark dataset designed to advance geometry-based food portion estimation in realistic dining scenarios. Existing dietary assessment methods largely rely on single-image analysis or appearance-based inference, including recent vision-language models, which lack explicit geometric reasoning and are sensitive to scale ambiguity. This benchmark reframes food portion estimation as an implicit-scale 3D reconstruction problem under monocular observations. To reflect real-world conditions, explicit physical references and metric annotations are removed; instead, contextual objects such as plates and utensils are provided, requiring algorithms to infer scale from implicit cues and prior knowledge. The dataset emphasizes multi-food scenes with diverse object geometries, frequent occlusions, and complex spatial arrangements. The benchmark was adopted as a challenge at the MetaFood 2025 Workshop, where multiple teams proposed reconstruction-based solutions. Experimental results show that while strong vision--language baselines achieve competitive performance, geometry-based reconstruction methods provide both improved accuracy and greater robustness, with the top-performing approach achieving 0.21 MAPE in volume estimation and 5.7 L1 Chamfer Distance in geometric accuracy.

</details>


### [53] [Curriculum-DPO++: Direct Preference Optimization via Data and Model Curricula for Text-to-Image Generation](https://arxiv.org/abs/2602.13055)
*Florinel-Alin Croitoru,Vlad Hondru,Radu Tudor Ionescu,Nicu Sebe,Mubarak Shah*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Direct Preference Optimization (DPO) has been proposed as an effective and efficient alternative to reinforcement learning from human feedback (RLHF). However, neither RLHF nor DPO take into account the fact that learning certain preferences is more difficult than learning other preferences, rendering the optimization process suboptimal. To address this gap in text-to-image generation, we recently proposed Curriculum-DPO, a method that organizes image pairs by difficulty. In this paper, we introduce Curriculum-DPO++, an enhanced method that combines the original data-level curriculum with a novel model-level curriculum. More precisely, we propose to dynamically increase the learning capacity of the denoising network as training advances. We implement this capacity increase via two mechanisms. First, we initialize the model with only a subset of the trainable layers used in the original Curriculum-DPO. As training progresses, we sequentially unfreeze layers until the configuration matches the full baseline architecture. Second, as the fine-tuning is based on Low-Rank Adaptation (LoRA), we implement a progressive schedule for the dimension of the low-rank matrices. Instead of maintaining a fixed capacity, we initialize the low-rank matrices with a dimension significantly smaller than that of the baseline. As training proceeds, we incrementally increase their rank, allowing the capacity to grow until it converges to the same rank value as in Curriculum-DPO. Furthermore, we propose an alternative ranking strategy to the one employed by Curriculum-DPO. Finally, we compare Curriculum-DPO++ against Curriculum-DPO and other state-of-the-art preference optimization approaches on nine benchmarks, outperforming the competing methods in terms of text alignment, aesthetics and human preference. Our code is available at https://github.com/CroitoruAlin/Curriculum-DPO.

</details>


### [54] [A Calibrated Memorization Index (MI) for Detecting Training Data Leakage in Generative MRI Models](https://arxiv.org/abs/2602.13066)
*Yash Deo,Yan Jia,Toni Lassila,Victoria J Hodge,Alejandro F Frang,Chenghao Qian,Siyuan Kang,Ibrahim Habli*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Image generative models are known to duplicate images from the training data as part of their outputs, which can lead to privacy concerns when used for medical image generation. We propose a calibrated per-sample metric for detecting memorization and duplication of training data. Our metric uses image features extracted using an MRI foundation model, aggregates multi-layer whitened nearest-neighbor similarities, and maps them to a bounded \emph{Overfit/Novelty Index} (ONI) and \emph{Memorization Index} (MI) scores. Across three MRI datasets with controlled duplication percentages and typical image augmentations, our metric robustly detects duplication and provides more consistent metric values across datasets. At the sample level, our metric achieves near-perfect detection of duplicates.

</details>


### [55] [SIEFormer: Spectral-Interpretable and -Enhanced Transformer for Generalized Category Discovery](https://arxiv.org/abs/2602.13067)
*Chunming Li,Shidong Wang,Tong Xin,Haofeng Zhang*

Main category: cs.CV

TL;DR: 提出了SIEFormer方法，利用谱分析重新解释ViT注意力机制增强特征适应性，在广义类别发现任务上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 针对ViT在广义类别发现任务中的局限性，利用谱分析增强注意力机制的特征适应能力，提高模型对未标记类别的识别能力

Method: 包含隐式和显式双分支结构：隐式分支利用图拉普拉斯建模token局部结构，配合带自适应滤波层；显式分支通过傅里叶变换学习token全局依赖，在频域进行可学习参数调制

Result: 在多个图像识别数据集上取得state-of-the-art性能，消融实验和可视化验证了方法优越性

Conclusion: SIEFormer通过谱分析视角增强ViT，为广义类别发现任务提供了有效解决方案，谱滤波机制显著提升特征适应性

Abstract: This paper presents a novel approach, Spectral-Interpretable and -Enhanced Transformer (SIEFormer), which leverages spectral analysis to reinterpret the attention mechanism within Vision Transformer (ViT) and enhance feature adaptability, with particular emphasis on challenging Generalized Category Discovery (GCD) tasks. The proposed SIEFormer is composed of two main branches, each corresponding to an implicit and explicit spectral perspective of the ViT, enabling joint optimization. The implicit branch realizes the use of different types of graph Laplacians to model the local structure correlations of tokens, along with a novel Band-adaptive Filter (BaF) layer that can flexibly perform both band-pass and band-reject filtering. The explicit branch, on the other hand, introduces a Maneuverable Filtering Layer (MFL) that learns global dependencies among tokens by applying the Fourier transform to the input ``value" features, modulating the transformed signal with a set of learnable parameters in the frequency domain, and then performing an inverse Fourier transform to obtain the enhanced features. Extensive experiments reveal state-of-the-art performance on multiple image recognition datasets, reaffirming the superiority of our approach through ablation studies and visualizations.

</details>


### [56] [Universal Transformation of One-Class Classifiers for Unsupervised Anomaly Detection](https://arxiv.org/abs/2602.13091)
*Declan McIntosh,Alexandra Branzan Albu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Detecting anomalies in images and video is an essential task for multiple real-world problems, including industrial inspection, computer-assisted diagnosis, and environmental monitoring. Anomaly detection is typically formulated as a one-class classification problem, where the training data consists solely of nominal values, leaving methods built on this assumption susceptible to training label noise. We present a dataset folding method that transforms an arbitrary one-class classifier-based anomaly detector into a fully unsupervised method. This is achieved by making a set of key weak assumptions: that anomalies are uncommon in the training dataset and generally heterogeneous. These assumptions enable us to utilize multiple independently trained instances of a one-class classifier to filter the training dataset for anomalies. This transformation requires no modifications to the underlying anomaly detector; the only changes are algorithmically selected data subsets used for training. We demonstrate that our method can transform a wide variety of one-class classifier anomaly detectors for both images and videos into unsupervised ones. Our method creates the first unsupervised logical anomaly detectors by transforming existing methods. We also demonstrate that our method achieves state-of-the-art performance for unsupervised anomaly detection on the MVTec AD, ViSA, and MVTec Loco AD datasets. As improvements to one-class classifiers are made, our method directly transfers those improvements to the unsupervised domain, linking the domains.

</details>


### [57] [Realistic Face Reconstruction from Facial Embeddings via Diffusion Models](https://arxiv.org/abs/2602.13168)
*Dong Han,Yong Li,Joachim Denzler*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the advancement of face recognition (FR) systems, privacy-preserving face recognition (PPFR) systems have gained popularity for their accurate recognition, enhanced facial privacy protection, and robustness to various attacks. However, there are limited studies to further verify privacy risks by reconstructing realistic high-resolution face images from embeddings of these systems, especially for PPFR. In this work, we propose the face embedding mapping (FEM), a general framework that explores Kolmogorov-Arnold Network (KAN) for conducting the embedding-to-face attack by leveraging pre-trained Identity-Preserving diffusion model against state-of-the-art (SOTA) FR and PPFR systems. Based on extensive experiments, we verify that reconstructed faces can be used for accessing other real-word FR systems. Besides, the proposed method shows the robustness in reconstructing faces from the partial and protected face embeddings. Moreover, FEM can be utilized as a tool for evaluating safety of FR and PPFR systems in terms of privacy leakage. All images used in this work are from public datasets.

</details>


### [58] [LongStream: Long-Sequence Streaming Autoregressive Visual Geometry](https://arxiv.org/abs/2602.13172)
*Chong Cheng,Xianda Chen,Tao Xie,Wei Yin,Weiqiang Ren,Qian Zhang,Xiaoyuang Guo,Hao Wang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Long-sequence streaming 3D reconstruction remains a significant open challenge. Existing autoregressive models often fail when processing long sequences. They typically anchor poses to the first frame, which leads to attention decay, scale drift, and extrapolation errors. We introduce LongStream, a novel gauge-decoupled streaming visual geometry model for metric-scale scene reconstruction across thousands of frames. Our approach is threefold. First, we discard the first-frame anchor and predict keyframe-relative poses. This reformulates long-range extrapolation into a constant-difficulty local task. Second, we introduce orthogonal scale learning. This method fully disentangles geometry from scale estimation to suppress drift. Finally, we solve Transformer cache issues such as attention-sink reliance and long-term KV-cache contamination. We propose cache-consistent training combined with periodic cache refresh. This approach suppresses attention degradation over ultra-long sequences and reduces the gap between training and inference. Experiments show LongStream achieves state-of-the-art performance. It delivers stable, metric-scale reconstruction over kilometer-scale sequences at 18 FPS. Project Page: https://3dagentworld.github.io/longstream/

</details>


### [59] [Monocular Markerless Motion Capture Enables Quantitative Assessment of Upper Extremity Reachable Workspace](https://arxiv.org/abs/2602.13176)
*Seth Donahue,J. D. Peiffer,R. Tyler Richardson,Yishan Zhong,Shaun Q. Y. Tan,Benoit Marteau,Stephanie R. Russo,May D. Wang,R. James Cotton,Ross Chafetz*

Main category: cs.CV

TL;DR: 本研究验证了使用单目相机和AI驱动的无标记动作捕捉技术量化上肢可达工作空间的临床可行性，发现正面相机配置与传统标记系统具有高度一致性，技术简化有助于临床普及。


<details>
  <summary>Details</summary>
Motivation: 验证使用单目相机和AI驱动的无标记动作捕捉技术量化上肢可达工作空间（UERW）的临床可行性方法。传统标记式动作捕捉系统在临床应用上存在技术复杂性高、设备成本昂贵等障碍，限制了该评估方法的普及。

Method: 研究招募了9名无障碍成人参与者，执行标准化的UERW任务（在VR头显中显示虚拟球体上分布的目标点，参与者伸手接触目标点）。使用两套系统同步采集运动数据：1）传统的标记式动作捕捉系统（作为参照标准），包含8个FLIR相机；2）单目视频分析，从八个相机视角中选择两个进行单目视频分析（比较正面和偏移两种相机配置）。

Result: 正面相机配置与标记式参照系统表现出高度一致性，平均偏差极小（每八分区到达的百分比为$0.61 \pm 0.12$ % mean ± SD）。相比之下，偏移相机视角低估了到达的工作空间百分比（$-5.66 \pm 0.45$ %）。正面相机在前部工作空间评估方面与标记式动作捕捉的一致性最高。

Conclusion: 研究支持正面单目相机配置在UERW评估中的可行性，特别在前部工作空间评估方面表现最佳。该方法降低技术复杂度，为更广泛实施定量的上肢活动能力评估提供了临床实用潜力，是本领域首次对单目无标记动作捕捉系统在UERW任务评估中的验证研究。

Abstract: To validate a clinically accessible approach for quantifying the Upper Extremity Reachable Workspace (UERW) using a single (monocular) camera and Artificial Intelligence (AI)-driven Markerless Motion Capture (MMC) for biomechanical analysis. Objective assessment and validation of these techniques for specific clinically oriented tasks are crucial for their adoption in clinical motion analysis. AI-driven monocular MMC reduces the barriers to adoption in the clinic and has the potential to reduce the overhead for analysis of this common clinical assessment. Nine adult participants with no impairments performed the standardized UERW task, which entails reaching targets distributed across a virtual sphere centered on the torso, with targets displayed in a VR headset. Movements were simultaneously captured using a marker-based motion capture system and a set of eight FLIR cameras. We performed monocular video analysis on two of these video camera views to compare a frontal and offset camera configurations. The frontal camera orientation demonstrated strong agreement with the marker-based reference, exhibiting a minimal mean bias of $0.61 \pm 0.12$ \% reachspace reached per octanct (mean $\pm$ standard deviation). In contrast, the offset camera view underestimated the percent workspace reached ($-5.66 \pm 0.45$ \% reachspace reached). Conclusion: The findings support the feasibility of a frontal monocular camera configuration for UERW assessment, particularly for anterior workspace evaluation where agreement with marker-based motion capture was highest. The overall performance demonstrates clinical potential for practical, single-camera assessments. This study provides the first validation of monocular MMC system for the assessment of the UERW task. By reducing technical complexity, this approach enables broader implementation of quantitative upper extremity mobility assessment.

</details>


### [60] [FlexAM: Flexible Appearance-Motion Decomposition for Versatile Video Generation Control](https://arxiv.org/abs/2602.13185)
*Mingzhi Sheng,Zekai Gu,Peng Li,Cheng Lin,Hao-Xiang Guo,Ying-Cong Chen,Yuan Liu*

Main category: cs.CV

TL;DR: FlexAM是一个通过3D点云表示视频动态的统一框架，通过多频位置编码、深度感知编码和灵活控制信号有效解耦外观与运动，在多项视频编辑任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成中有效且泛化性强的控制仍然面临挑战，现有方法多依赖模糊或任务特定的信号，作者认为对'外观'和'运动'的基本解耦提供了更鲁棒和可扩展的解决方案。

Method: 提出了FlexAM框架，基于新型3D控制信号，将视频动态表示为点云，引入多频位置编码来区分细粒度运动、深度感知位置编码，以及平衡精度和生成质量的灵活控制信号。

Result: 在广泛实验中，FlexAM在所有评估任务上都取得了优越性能，能够有效解耦外观和运动，支持包括I2V/V2V编辑、相机控制和空间物体编辑在内的多种任务。

Conclusion: 通过3D点云表示和增强的位置编码技术，FlexAM为视频生成中的外观与运动解耦提供了有效且可扩展的解决方案，在各种控制任务中表现出优越性能。

Abstract: Effective and generalizable control in video generation remains a significant challenge. While many methods rely on ambiguous or task-specific signals, we argue that a fundamental disentanglement of "appearance" and "motion" provides a more robust and scalable pathway. We propose FlexAM, a unified framework built upon a novel 3D control signal. This signal represents video dynamics as a point cloud, introducing three key enhancements: multi-frequency positional encoding to distinguish fine-grained motion, depth-aware positional encoding, and a flexible control signal for balancing precision and generative quality. This representation allows FlexAM to effectively disentangle appearance and motion, enabling a wide range of tasks including I2V/V2V editing, camera control, and spatial object editing. Extensive experiments demonstrate that FlexAM achieves superior performance across all evaluated tasks.

</details>


### [61] [CoPE-VideoLM: Codec Primitives For Efficient Video Language Models](https://arxiv.org/abs/2602.13191)
*Sayan Deb Sarkar,Rémi Pautrat,Ondrej Miksik,Marc Pollefeys,Iro Armeni,Mahdi Rad,Mihai Dusmanu*

Main category: cs.CV

TL;DR: 本文提出利用视频编解码基元（运动向量和残差）来改进视频语言模型，减少计算开销并提高时间覆盖，在14个视频理解基准上保持或超越性能。


<details>
  <summary>Details</summary>
Motivation: 当前视频语言模型采用关键帧采样方法，由于稀疏的时间覆盖会遗漏宏观事件和微观细节，同时处理完整图像及其标记会带来巨大的计算开销。需要一种方法来编码视频冗余和稀疏性，而不需要对大多数帧进行昂贵的完整图像编码。

Method: 提出利用视频编解码基元（运动向量和残差），引入轻量级基于Transformer的编码器来聚合编解码基元，并通过预训练策略将其表示与图像编码器嵌入对齐，在端到端微调期间加速收敛。

Result: 与标准视频语言模型相比，该方法将首令牌生成时间减少高达86%，令牌使用量减少高达93%。通过调整关键帧和编解码基元密度，能够在14个多样化的视频理解基准上保持或超越性能，涵盖通用问答、时间推理、长形式理解和空间场景理解。

Conclusion: 通过利用视频编解码基元，提出的方法显著减少了计算开销，同时维持或改进了视频理解性能，为视频语言模型提供了一种高效且有效的替代方案。

Abstract: Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to the sparse temporal coverage. Furthermore, processing full images and their tokens for each frame incurs substantial computational overhead. To address these limitations, we propose to leverage video codec primitives (specifically motion vectors and residuals) which natively encode video redundancy and sparsity without requiring expensive full-image encoding for most frames. To this end, we introduce lightweight transformer-based encoders that aggregate codec primitives and align their representations with image encoder embeddings through a pre-training strategy that accelerates convergence during end-to-end fine-tuning. Our approach reduces the time-to-first-token by up to $86\%$ and token usage by up to $93\%$ compared to standard VideoLMs. Moreover, by varying the keyframe and codec primitive densities we are able to maintain or exceed performance on $14$ diverse video understanding benchmarks spanning general question answering, temporal reasoning, long-form understanding, and spatial scene understanding.

</details>


### [62] [Conversational Image Segmentation: Grounding Abstract Concepts with Scalable Supervision](https://arxiv.org/abs/2602.13195)
*Aadarsh Sahoo,Georgia Gkioxari*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Conversational image segmentation grounds abstract, intent-driven concepts into pixel-accurate masks. Prior work on referring image grounding focuses on categorical and spatial queries (e.g., "left-most apple") and overlooks functional and physical reasoning (e.g., "where can I safely store the knife?"). We address this gap and introduce Conversational Image Segmentation (CIS) and ConverSeg, a benchmark spanning entities, spatial relations, intent, affordances, functions, safety, and physical reasoning. We also present ConverSeg-Net, which fuses strong segmentation priors with language understanding, and an AI-powered data engine that generates prompt-mask pairs without human supervision. We show that current language-guided segmentation models are inadequate for CIS, while ConverSeg-Net trained on our data engine achieves significant gains on ConverSeg and maintains strong performance on existing language-guided segmentation benchmarks. Project webpage: https://glab-caltech.github.io/converseg/

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [63] [Generalizing UxV Network Control Optimization with Disruption Tolerant Networking](https://arxiv.org/abs/2602.12448)
*Quyen Dang,Geoffrey Xie*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Military and disaster relief operations increasingly rely on unmanned vehicles (UxVs). It is important to develop a network control system (NCS) that can continuously coordinate and optimize the movement of UxVs based on mission objectives. However, prior research on NCS aims to always maintain a connected network topology, which limits the utility of the resulting systems. In this paper, we present an approach to systematically increase the topology flexibility for an NCS by leveraging the well-studied concept of disruption-tolerant networking (DTN). We design a DTN-compatible communication utility model that, while allowing some nodes to temporarily disconnect from others, provides for a fine-grain specification of the minimum communication frequency and the maximum hops permitted for message delivery between each pair of nodes. As such, the model supports what-if analyses before a mission to determine the best communication parameters to use for a given set of UxVs. Furthermore, we incorporate our communication model into an existing NCS and evaluate its performance in a simulated scenario involving the use of five UxVs searching for an enemy ship. The results show that our model not only enables the NCS to find the enemy ship faster but also facilitates new capabilities, such as dividing the UxVs into multiple teams responsible for different search areas.

</details>


### [64] [Photonic Rails in ML Datacenters with Opus](https://arxiv.org/abs/2602.12521)
*Eric Ding,Barry Lyu,Bhaskar Kataria,Rachee Singh*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Rail-optimized network fabrics have become the de facto datacenter scale-out fabric for large-scale ML training. However, the use of high-radix electrical switches to provide all-to-all connectivity in rails imposes massive power and cost. We propose a rethinking of the rail abstraction by retaining its communication semantics, but realizing it using optical circuit switches. The key challenge is that optical switches support one-to-one connectivity at a time, limiting the fan-out of traffic in ML workloads using hybrid parallelisms. We overcome this through \emph{parallelism-driven rail reconfiguration}, which exploits the non-overlapping communication phases of different parallelism dimensions. This time-multiplexes a single set of physical ports across circuit configurations tailored to each phase within a training iteration. We design and implement Opus, a control plane that orchestrates this in-job reconfiguration of photonic rails at parallelism phase boundaries, and evaluate it on a physical OCS testbed, the Perlmutter supercomputer, and in simulation at up to 2,048 GPUs. Our results show that photonic rails can achieve over $23\times$ network power reduction and $4\times$ cost savings while incurring less than $6\%$ training overhead at production-relevant OCS reconfiguration latencies.

</details>


### [65] [Adaptive Meta-Aggregation Federated Learning for Intrusion Detection in Heterogeneous Internet of Things](https://arxiv.org/abs/2602.12541)
*Saadat Izadi,Mahmood Ahmadi*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid proliferation of the Internet of Things (IoT) has brought remarkable advancements to industries by enabling interconnected systems and intelligent automation. However, this exponential growth has also introduced significant security vulnerabilities, making IoT networks increasingly targets for sophisticated cyberattacks. The heterogeneity of IoT devices poses critical challenges for traditional intrusion detection systems. To address these challenges, this paper proposes an innovative method called Adaptive Meta-Aggregation Federated Learning (AMAFed), designed to enhance intrusion detection in heterogeneous IoT networks. By employing a dynamic weighting mechanism using meta-learning, AMAFed assigns adaptive importance to local models based on their data quality and contributions, enabling personalized yet collaborative learning across devices. The proposed method was evaluated on three benchmark IoT datasets: ToN-IoT, N-BaIoT, and BoT-IoT, representing diverse real-world scenarios. Experimental results demonstrate that AMAFed achieves detection accuracy up to 99.8% on ToN-IoT, with F1-scores exceeding 98% across all datasets. On the N-BaIoT dataset, it reaches 99.88% accuracy, and on BoT-IoT, it achieves 98.12% accuracy, consistently outperforming state-of-the-art approaches.

</details>


### [66] [Lightweight Cluster-Based Federated Learning for Intrusion Detection in Heterogeneous IoT Networks](https://arxiv.org/abs/2602.12543)
*Saadat Izadi,Mahmood Ahmadi*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rise of heterogeneous Internet of Things (IoT) devices has raised security concerns due to their vulnerability to cyberattacks. Intrusion Detection Systems (IDS) are crucial in addressing these threats. Federated Learning (FL) offers a privacy-preserving solution, but IoT heterogeneity and limited computational resources cause increased latency and reduced performance. This paper introduces a novel approach Cluster-based federated intrusion detection with lightweight networks for heterogeneous IoT designed to address these limitations. The proposed framework utilizes a hierarchical IoT architecture that encompasses edge, fog, and cloud layers. Intrusion detection clients operate at the fog layer, leveraging federated learning to enhance data privacy and distributed processing efficiency. To enhance efficiency, the method employs the lightweight MobileNet model alongside a hybrid loss function that integrates Gumbel-SoftMax and SoftMax, optimizing resource consumption while maintaining high detection accuracy. A key feature of this approach is clustering IoT devices based on hardware similarities, enabling more efficient model training and aggregation tailored to each cluster's computational capacity. This strategy not only simplifies the complexity of managing heterogeneous data and devices but also improves scalability and overall system performance. To validate the effectiveness of the proposed method, extensive experiments were conducted using the ToN-IoT and CICDDoS2019 datasets. Results demonstrate that the proposed approach reduces end-to-end training time by 2.47x compared to traditional FL methods, achieves 2.16x lower testing latency, and maintains exceptionally high detection accuracy of 99.22% and 99.02% on the ToN-IoT and CICDDoS2019 datasets, respectively.

</details>


### [67] [TENORAN: Automating Fine-grained Energy Efficiency Profiling in Open RAN Systems](https://arxiv.org/abs/2602.13085)
*Ravis Shirkhani,Stefano Maxenti,Leonardo Bonati,Niloofar Mohamadi,Maxime Elkael,Umair Hashmi,Jeebak Mitra,Michele Polese,Tommaso Melodia,Salvatore D'Oro*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The transition to disaggregated and interoperable Open Radio Access Network (RAN) architectures and the introduction of RAN Intelligent Controllers (RICs) in O-RAN creates new resource optimization opportunities and fine-grained tuning and configuration of network components to save energy while fulfilling service demand. However, unlocking this potential requires fine-grained and accurate energy measurements across heterogeneous deployments. Three factors make this particularly challenging [...]. To address these challenges, we design the TENORAN framework, an automated measurement scaffold for fine-grained energy efficiency profiling of O-RAN deployments, and prototype it on a heterogeneous OpenShift cluster. TENORAN instruments an end-to-end deployment based on high-level specifications (e.g., gNB software stack and split options, traffic profiles), and collects synchronized performance metrics and power measurements for individual RAN components while the network is under controlled workloads including over-the-air traffic. Our experimental results demonstrate energy profiling of end-to-end experiments with xApps in the loop, energy efficiency differences between two RAN stacks, OpenAirInterface and srsRAN, in uplink and downlink, and core network power consumption trends.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [68] [A Lightweight Cubature Kalman Filter for Attitude and Heading Reference Systems Using Simplified Prediction Equations](https://arxiv.org/abs/2602.12283)
*Shunsei Yamagishi,Lei Jing*

Main category: eess.SY

TL;DR: KCKF是一种改进的容积卡尔曼滤波器，在保持估计精度的同时降低了计算成本，相比CKF在高端计算机上减少约19%计算时间，在低成本单板计算机上减少约15%。


<details>
  <summary>Details</summary>
Motivation: AHRS系统需要可靠的姿态和运动感知，但现有CKF计算成本较高，希望开发一种保持精度但降低计算复杂度的改进算法

Method: 提出Kaisoku CKF(KCKF)，通过简化CKF方程，扩展求和项并进行简化，推导出轻量化的预测方程，保持等效数学关系的同时减少浮点操作数

Result: 实验表明KCKF比CKF减少浮点操作，高端计算机上计算时间减少约19%，低成本单板计算机上减少约15%，且保持了姿态估计精度

Conclusion: KCKF是一种有效降低计算成本而不损失精度的CKF改进算法，适用于AHRS等需要可靠方向感知的应用

Abstract: Attitude and Heading Reference Systems (AHRSs) are broadly applied wherever reliable orientation and motion sensing is required. In this paper, we present an improved Cubature Kalman Filter (CKF) with lower computational cost while maintaining estimation accuracy, which is named "Kaisoku Cubature Kalman Filter (KCKF)". The computationally efficient equations of the KCKF are derived by simplifying those of the CKF, while preserving equivalent mathematical relations. The lightweight prediction equations in the KCKF are derived by expanding the summation terms in the CKF and simplifying the result. This paper shows that the KCKF requires fewer floating-point operations (FLOPs) than the CKF. The controlled experimental results show that the KCKF reduces the computation time by approximately 19% compared to the CKF on a high-performance computer, whereas the KCKF reduces the computation time by approximately 15% compared to the CKF on a low-cost single-board computer. In addition, the KCKF maintains the attitude estimation accuracy of the CKF.

</details>


### [69] [Energy-Aware Reinforcement Learning for Robotic Manipulation of Articulated Components in Infrastructure Operation and Maintenance](https://arxiv.org/abs/2602.12288)
*Xiaowen Tao,Yinuo Wang,Haitao Ding,Yuanyang Qi,Ziyu Song*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the growth of intelligent civil infrastructure and smart cities, operation and maintenance (O&M) increasingly requires safe, efficient, and energy-conscious robotic manipulation of articulated components, including access doors, service drawers, and pipeline valves. However, existing robotic approaches either focus primarily on grasping or target object-specific articulated manipulation, and they rarely incorporate explicit actuation energy into multi-objective optimisation, which limits their scalability and suitability for long-term deployment in real O&M settings. Therefore, this paper proposes an articulation-agnostic and energy-aware reinforcement learning framework for robotic manipulation in intelligent infrastructure O&M. The method combines part-guided 3D perception, weighted point sampling, and PointNet-based encoding to obtain a compact geometric representation that generalises across heterogeneous articulated objects. Manipulation is formulated as a Constrained Markov Decision Process (CMDP), in which actuation energy is explicitly modelled and regulated via a Lagrangian-based constrained Soft Actor-Critic scheme. The policy is trained end-to-end under this CMDP formulation, enabling effective articulated-object operation while satisfying a long-horizon energy budget. Experiments on representative O&M tasks demonstrate 16%-30% reductions in energy consumption, 16%-32% fewer steps to success, and consistently high success rates, indicating a scalable and sustainable solution for infrastructure O&M manipulation.

</details>


### [70] [String-Level Ground Fault Localization for TN-Earthed Three-Phase Photovoltaic Systems](https://arxiv.org/abs/2602.12289)
*Yuanliang Li,Xun Gong,Reza Iravani,Bo Cao,Heng Liu,Ziming Chen*

Main category: eess.SY

TL;DR: 提出基于边缘AI的直流侧接地故障定位方法，用于三相TN接地光伏系统，通过轻量化变分信息瓶颈模型实现93%以上的定位准确率


<details>
  <summary>Details</summary>
Motivation: 直流侧接地故障对TN接地光伏系统危害大，故障电流会直接损坏逆变器和光伏组件，传统逐串人工排查方法耗时低效

Method: 1)建立包含光伏迟滞效应的PLECS仿真模型生成多种故障场景；2)在逆变器四阶段关机过程中提取基于相关性的特征；3)设计轻量化变分信息瓶颈定位模型训练

Result: 在典型采样率下实现超过93%的定位准确率，计算成本低，适合部署在资源受限的光伏逆变器上

Conclusion: 该方法能有效解决TN接地光伏系统的直流侧接地故障定位问题，具有实际部署潜力

Abstract: The DC-side ground fault (GF) poses significant risks to three-phase TN-earthed photovoltaic (PV) systems, as the resulting high fault current can directly damage both PV inverters and PV modules. Once a fault occurs, locating the faulty string through manual string-by-string inspection is highly time-consuming and inefficient. This work presents a comprehensive analysis of GF characteristics through fault-current analysis and a simulation-based case study covering multiple fault locations. Building on these insights, we propose an edge-AI-based GF localization approach tailored for three-phase TN-earthed PV systems. A PLECS-based simulation model that incorporates PV hysteresis effects is developed to generate diverse GF scenarios, from which correlation-based features are extracted throughout the inverter's four-stage shutdown sequence. Using the simulated dataset, a lightweight Variational Information Bottleneck (VIB)-based localization model is designed and trained, achieving over 93% localization accuracy at typical sampling rates with low computational cost, demonstrating strong potential for deployment on resource-constrained PV inverters.

</details>


### [71] [Interpolation-Inspired Closure Certificates](https://arxiv.org/abs/2602.12436)
*Mohammed Adib Oumer,Vishnu Murali,Majid Zamani*

Main category: eess.SY

TL;DR: 本文提出了一种基于插值思想的多闭包证书方法，用于验证具有ω-正则特性的动力系统，即使在固定模板下无法找到单个闭包证书时也能证明系统属性。


<details>
  <summary>Details</summary>
Motivation: 传统的闭包证书方法在固定模板（如特定次数的多项式）下可能无法找到合适的证书来验证系统属性，这限制了其在复杂系统验证中的应用。需要一种更灵活的方法来处理这种情况。

Method: 提出了插值启发的闭包证书概念，该证书由一组函数组成，通过考虑一步转移、两步转移等逐步逼近过渡不变量，直到获得完整的过渡不变量。使用SOS规划和场景规划方法来寻找这些函数集合。

Result: 在案例研究中证明了该方法能够有效验证持久性和一般ω-正则属性，即使在单个函数方法失败的情况下也能成功。

Conclusion: 插值启发的闭包证书提供了比传统单函数闭包证书更灵活和强大的验证框架，扩展了动力系统属性验证的能力范围。

Abstract: Barrier certificates, a form of state invariants, provide an automated approach to the verification of the safety of dynamical systems. Similarly to barrier certificates, recent works explore the notion of closure certificates, a form of transition invariants, to verify dynamical systems against $ω$-regular properties including safety. A closure certificate, defined over state pairs of a dynamical system, is a real-valued function whose zero superlevel set characterizes an inductive transition invariant of the system. The search for such a certificate can be effectively automated by assuming it to be within a specific template class, e.g. a polynomial of a fixed degree, and then using optimization techniques such as sum-of-squares (SOS) programming to find it. Unfortunately, one may not be able to find such a certificate for a fixed template. In such a case, one must change the template, e.g. increase the degree of the polynomial. In this paper, we consider a notion of multiple closure certificates dubbed interpolation-inspired closure certificates. An interpolation-inspired closure certificate consists of a set of functions which jointly over-approximate a transition invariant by first considering one-step transitions, then two, and so on until a transition invariant is obtained. The advantage of interpolation-inspired closure certificates is that they allow us to prove properties even when a single function for a fixed template cannot be found using standard approaches. We present SOS programming and a scenario program to find these sets of functions and demonstrate the effectiveness of our proposed method to verify persistence and general $ω$-regular specifications in some case studies.

</details>


### [72] [Implementation of a Directional Modulation Testbed for Reconfigurable Transmitters for Spatially Agile MIMO Systems](https://arxiv.org/abs/2602.12452)
*Jonathan E. Swindell,David W. Cox,Rebekah Edwards,Emma Lever,Adam C. Goad,Austin Egbert,Charles Baylis,Robert J. Marks*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper demonstrates the implementation and validation of a microwave testbed for directionally modulated transmission. Directional modulation enables multiple communication and/or radar signals to be transmitted in multiple directions simultaneously using a single phased array aperture, helping to relieve spectral congestion. A two-element transmitter array is driven by a Xilinx ZCU208 Radio Frequency System on a Chip (RFSoC). Our testbed provides a foundation for developing a fully reconfigurable array transmitter for multi-user multiple-input multiple-output (MU-MIMO) radar and communications, which will incorporate in-situ measurement, reconfigurable matching circuitry, and fast tuning algorithms for frequency and directional selectivity. This testbed enables development and validation of reconfigurable techniques for adaptive spectral and spatial coexistence.

</details>


### [73] [Dynamic Network Prices for Prosumer-aware Hosting Capacity Management](https://arxiv.org/abs/2602.12573)
*Jiawei Zhang,Gregor Verbic,Frederik Geth,Mohsen Aldaadi,Rahmat Heidari,Julio Braslavsky*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The fast uptake of distributed energy resources (DERs) presents increasing challenges for managing hosting capacity in distribution networks. Existing solutions include direct load control, operating envelopes, and price-based control through dynamic energy prices. Despite their effectiveness, these methods often rely on assumed prosumer behavioural patterns and overlook prosumers' desire to retain control over their devices. Additionally, current fixed or Time-of-Use (ToU) prices are based on spatial and temporal averages, having limited impact on network conditions and DER operation. To address these limitations, this paper proposes a bilevel optimisation framework that explicitly models prosumer decision-making in the design of dynamic network prices. The upper level represents the distribution system operator (DSO), setting network prices under cost-recovery and network constraints, while the lower level models prosumers optimising DER operation in response. The proposed framework preserves customer prerogative, enhances DER flexibility, and offers actionable insights for network hosting capacity management and the evolution of network tariff structures under high DER penetration.

</details>


### [74] [Curvature-Guided Safety Filters: State-Dependent Hessian-Weighted Projection with Provable Performance Bounds](https://arxiv.org/abs/2602.12603)
*Ziyan Lin,Liang Xu*

Main category: eess.SY

TL;DR: 提出了一种基于状态依赖、Hessian引导的加权投影安全滤波器，在保持凸性的同时改善长期性能


<details>
  <summary>Details</summary>
Motivation: 传统欧几里得投影忽视长期性能，而直接在安全集内优化动作价值函数非凸且计算成本高，需要一种既能保持凸性又能提升性能的投影方法

Method: 1. 提出基于动作价值函数曲率的加权投影矩阵，使修正偏向对价值更敏感的动作方向
2. 建立加权投影与最优安全动作之间的性能差距上界
3. 给出加权投影优于欧几里得投影的条件
4. 针对黑盒控制器，通过带二次特征块和正则化的迭代Q函数学习算法数据驱动构建投影矩阵

Result: 1. 理论上证明了加权投影的性能界限
2. 四旋翼跟踪规避任务的仿真表明，相比欧几里得投影，所提滤波器在保持安全性的同时减少了价值退化
3. 计算开销符合实时操作要求

Conclusion: 提出的Hessian引导加权投影安全滤波器在保持安全性的同时，能有效平衡计算效率与长期性能，为学习控制中的安全约束提供了实用解决方案

Abstract: Safety filters provide a lightweight mechanism for enforcing state and input safety in learning-enabled control. However, common Euclidean projections onto the safe set disregard long-term performance, while directly optimizing the action-value function within the safe set can be nonconvex and computationally prohibitive. This paper proposes a state-dependent, Hessian-guided projection for safety filtering that preserves convexity while improving performance. The key idea is to select a weighted projection matrix from the curvature of the action-value function, thereby biasing the correction toward action directions with higher value sensitivity. We establish (i) a uniform bound on the performance gap between the weighted projection and the safe value-optimal action, and (ii) a condition under which the weighted projection outperforms the Euclidean projection in long-term value. To support black-box controllers, we further present a data-driven construction of the weighted projection matrix via an iterative Q-function learning algorithm with quadratic feature blocks and regularization that enforces curvature dominance and bounded higher-order terms. Simulations on a quadrotor tracking-and-avoidance task indicate that the proposed filter maintains safety while reducing value degradation relative to Euclidean projection, with computational overhead compatible with real-time operation.

</details>


### [75] [When Environments Shift: Safe Planning with Generative Priors and Robust Conformal Prediction](https://arxiv.org/abs/2602.12616)
*Kaizer Rahaman,Jyotirmoy V. Deshmukh,Ashish R. Hota,Lars Lindemann*

Main category: eess.SY

TL;DR: 该论文提出了一种应对自主系统中分布偏移的鲁棒规划框架，通过在MPC中嵌入基于条件扩散模型生成合成数据构建的鲁棒符合预测区域来保证概率安全性。


<details>
  <summary>Details</summary>
Motivation: 自主系统在部署时会遭遇与训练环境不同的分布偏移问题，导致传统方法提供的安全保证失效。例如自动驾驶中，行人和其他车辆的行为会因交通密度、道路能见度等因素变化，使训练环境与部署环境不匹配。

Method: 1) 假设环境数据分布由可观测的干扰参数（如交通密度）参数化；2) 训练条件扩散模型捕捉干扰参数引起的分布偏移；3) 在线观测干扰参数并从扩散模型生成合成数据；4) 设计MPC控制器，嵌入基于合成数据构建的鲁棒符合预测区域。

Result: 在ORCA仿真器中进行的实验表明，该框架在多种分布偏移情况下实现了安全规划。相比使用单一静态训练数据的方法，本文方法能够提供概率安全保证。

Conclusion: 所提出的框架通过条件扩散模型处理分布偏移，结合鲁棒符合预测和MPC，为自主系统在动态变化环境中提供了可靠的概率安全保障，有效解决了训练-部署分布不匹配的问题。

Abstract: Autonomous systems operate in environments that may change over time. An example is the control of a self-driving vehicle among pedestrians and human-controlled vehicles whose behavior may change based on factors such as traffic density, road visibility, and social norms. Therefore, the environment encountered during deployment rarely mirrors the environment and data encountered during training -- a phenomenon known as distribution shift -- which can undermine the safety of autonomous systems. Conformal prediction (CP) has recently been used along with data from the training environment to provide prediction regions that capture the behavior of the environment with a desired probability. When embedded within a model predictive controller (MPC), one can provide probabilistic safety guarantees, but only when the deployment and training environments coincide. Once a distribution shift occurs, these guarantees collapse. We propose a planning framework that is robust under distribution shifts by: (i) assuming that the underlying data distribution of the environment is parameterized by a nuisance parameter, i.e., an observable, interpretable quantity such as traffic density, (ii) training a conditional diffusion model that captures distribution shifts as a function of the nuisance parameter, (iii) observing the nuisance parameter online and generating cheap, synthetic data from the diffusion model for the observed nuisance parameter, and (iv) designing an MPC that embeds CP regions constructed from such synthetic data. Importantly, we account for discrepancies between the underlying data distribution and the diffusion model by using robust CP. Thus, the plans computed using robust CP enjoy probabilistic safety guarantees, in contrast with plans obtained from a single, static set of training data. We empirically demonstrate safety under diverse distribution shifts in the ORCA simulator.

</details>


### [76] [Safe Controller Synthesis Using Lyapunov-based Barriers for Linear Hybrid Systems with Simplex Architecture](https://arxiv.org/abs/2602.12638)
*Sunandan Adhikary,Soumyajit Dey*

Main category: eess.SY

TL;DR: 提出了一种新的备份安全控制器 (BSC) 设计方法，该方法能确保最大安全区域的稳定性，并能在系统状态偏离正常行为时及时恢复，同时通过切换不同执行速率的BSC来最小化资源使用。


<details>
  <summary>Details</summary>
Motivation: 现代信息物理系统的两层设计中，主控制器通常是AI驱动的或基于特定成本函数优化的分析控制器。如果控制动作被认为不安全，则激活安全导向的备用控制器。现有备用控制器设计方法未考虑实时纠偏的截止时间，也未将最大化安全操作区域作为合成标准，导致安全保证仅局限于小区域。

Method: 1) 提出一种备份安全控制器设计方法，确保在安全状态空间中最大的不变区域，并提供及时恢复保证；2) 首次合成在确保最大安全性和及时恢复的同时，通过切换不同执行速率的BSC来最小化资源使用的安全控制器；3) 提出在线安全控制器激活策略，在BSC（和主最优控制器）之间切换，以优化控制计算的处理带宽。

Result: 在线性混合动力系统和预算带宽下，通过闭环评估所提出的安全控制器和激活策略的安全性和恢复时间，验证了该方法的有效性。

Conclusion: 该方法成功地解决了现有备用控制器设计中安全区域小、缺乏实时恢复保证的问题，实现了最大安全区域的稳定性保证，同时通过智能切换策略优化了资源使用效率。

Abstract: Modern cyber-physical systems often have a two-layered design, where the primary controller is AI-enabled or an analytical controller optimising some specific cost function. If the resulting control action is perceived as unsafe, a secondary safety-focused backup controller is activated. The existing backup controller design schemes do not consider a real-time deadline for the course correction of a potentially unsafe system trajectory or constrain maximisation of the safe operating region as a synthesis criterion. This essentially implies an eventual safety guarantee over a small operating region.
  This paper proposes a novel design method for backup safe controllers (BSCs) that ensure invariance across the largest possible region in the safe state space, along with a guarantee for timely recovery when the system states deviate from their usual behaviour. This is the first work to synthesise safe controllers that ensure maximal safety and timely recovery while aiming at minimal resource usage by switching between BSCs with different execution rates. An online safe controller activation policy is also proposed to switch between BSCs (and the primary optimal controller) to optimise processing bandwidth for control computation. To establish the efficacy of the proposed method, we evaluate the safety and recovery time of the proposed safe controllers, as well as the activation policy, in closed loops with linear hybrid dynamical systems under budgeted bandwidth.

</details>


### [77] [Dual-Channel Feature Fusion for Joint Prediction in Dynamic Signed Weighted Networks](https://arxiv.org/abs/2602.12663)
*Gaoxin Zhang,Ruixing Ren,Junhui Zhao,Xiaoke Sun*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Link prediction is central to unraveling social network evolution and node relationships, as well as understanding the characteristic mechanisms of complex networks. Currently, research on link prediction for complex dynamic networks integrating temporal evolution, relational polarity and edge weight information remains significantly underexplored, failing to meet practical demands. For dynamic signed-weighted networks, this paper proposes a tripartite joint prediction framework for unified forecasting of links, signs and weights. First, the dynamic network is decomposed into temporal snapshots, and node semantic embeddings are generated via sign-aware weighted random walks. We then design multi-hop structural balance and temporal difference features to capture the structural characteristics and dynamic evolution laws of the network, respectively. The model adopts a dual-channel feature decoupling mechanism: node semantic embeddings are used for link existence prediction, while relational sign features are fed into a Transformer encoder to model temporal dependencies. Finally, prediction results are output synergistically through a multi-task unit. Simulation experiments demonstrate that, compared with baseline methods, the proposed framework achieves an average 2%-4% improvement in the performance of link existence and relational sign prediction, and a significant 40%-50% reduction in edge weight prediction error.

</details>


### [78] [From Data $H(jω_i)$ to Balanced Truncation Family: A Projection-based Non-intrusive Approach](https://arxiv.org/abs/2602.12697)
*Umair Zulfiqar*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents data-driven implementations of balanced truncation and several of its generalizations that rely exclusively on transfer function samples on the imaginary axis. Rather than implicitly approximating the Gramians via numerical quadrature, the proposed approach approximates them implicitly through projection. This enables multiple members of the balanced truncation family to be implemented non-intrusively using practically measurable data, without requiring spectral factorizations. Using this projection-based framework, data-driven implementations are developed for standard balanced truncation, frequency-limited balanced truncation, time-limited balanced truncation, self-weighted balanced truncation, LQG balanced truncation, H-infinity balanced truncation, positive-real balanced truncation, bounded-real balanced truncation, and stochastic balanced truncation. Numerical results demonstrate that the proposed non-intrusive implementations achieve performance comparable to their intrusive counterparts and accurately capture the dominant Hankel singular values.

</details>


### [79] [Empirical Validation of a Dual-Defense Mechanism Reshaping Wholesale Electricity Price Dynamics in Singapore](https://arxiv.org/abs/2602.12782)
*Huang Zhenyu,Yuan Zhao*

Main category: eess.SY

TL;DR: 新加坡电力市场双重防御机制—Vesting Contracts (VC) 与临时价格上限(TPC)—能有效降低价格同时减少波动性，解决传统调控中抑制价格与市场流动性之间存在的权衡矛盾。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估新加坡电力市场独特的双重防御机制，探索其如何通过组合使用Vesting Contracts (VC) 与临时价格上限(TPC)来缓解价格波动，并分析该机制是否能克服传统电价调控中价格抑制与市场流动性之间的矛盾。

Method: 利用2021年至2024年的高频数据进行分析，采用量化模型评估VC数量(VCQ)与VC价格(VCP)的不同作用，识别2023年改革前后的结构性断点，并检验TPC阈值附近的策略性投标行为。

Result: 1) VC框架存在结构权衡：VCQ抑制平均价格但加剧波动性；VCP则在极端分位数处发挥尾部风险锚定作用。
2) 2023年改革导致价格动态重映射，报价比到结算价的正传递效应基本消失；TPC阈值附近未发现系统性的策略性投标行为。
3) 双重防御机制呈现协同效应：TPC逆转高VCQ的波动性惩罚，使条件波动弹性从破坏稳定的0.636转为稳定的-0.213，从而解决波动性权衡。

Conclusion: 新加坡的双重防御机制成功解耦价格抑制与流动性风险，在增强尾部风险控制的同时消除流动性相关的稳定性成本，实现了市场价格稳定性的最大化。

Abstract: While ex-ante screening and static price caps are global standards for mitigating price volatility, Singapore's electricity market employs a unique dual-defense mechanism integrating vesting contracts (VC) with a temporary price cap (TPC). Using high-frequency data from 2021 to 2024, this paper evaluates this mechanism and yields three primary findings. First, a structural trade-off exists within the VC framework: while VC quantity (VCQ) suppresses average prices, it paradoxically exacerbates instability via liquidity squeezes. Conversely, VC price (VCP) functions as a tail-risk anchor, dominating at extreme quantiles where VCQ efficacy wanes. Second, a structural break around the 2023 reform reveals a fundamental re-mapping of price dynamics; the previously positive pass-through from offer ratios to clearing prices was largely neutralized post-reform. Furthermore, diagnostics near the TPC threshold show no systematic evidence of strategic bid shading, confirming the TPC's operational integrity. Third, the dual-defense mechanism exhibits a critical synergy that resolves the volatility trade-off. The TPC reverses the volatility penalty of high VCQ, shifting the elasticity of conditional volatility from a destabilizing 0.636 to a stabilizing -0.213. This synergy enables the framework to enhance tail-risk control while eliminating liquidity-related stability costs. We conclude that this dual-defense mechanism successfully decouples price suppression from liquidity risks, thereby maximizing market stability.

</details>


### [80] [Data Augmentation and Attention for massive MIMO-based Indoor Localization in Changing Environments](https://arxiv.org/abs/2602.12954)
*Luisa Schuhmacher,Hazem Sallouha,Ihsane Gryech,Sofie Pollin*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The demand for high-precision indoor localization has grown significantly with the rise of smart environments, industrial automation, and location-aware applications. While massive Multiple-Input and Multiple-Output (MIMO) systems enable millimeter-level accuracy by leveraging rich Channel State Information (CSI), most existing solutions are optimized for static environments, where users or devices remain fixed during data collection and inference. Real-world applications, however, often require real-time localization in changing environments, where rapid movement, unpredictable blockages, and dynamic channel conditions pose significant challenges. To address these challenges, we introduce two data augmentation techniques designed to resemble blocked antennas, enhancing the generalizability of localization models to dynamic scenarios. Additionally, we enhance an existing Deep Learning (DL) model by incorporating attention modules, improving its ability to focus on relevant channel features and antennas. We train our model on data from a static scenario, augmented with the proposed techniques, and evaluate it on a dataset collected in changing scenarios. We investigate the performance enhancements achieved by the data augmentation techniques and the Attention modules, and observe a localization accuracy improvement from a mean error of 286 mm, when trained without Attention and without data augmentations, to 66 mm, when trained with Attention and data augmentation. This shows that high localization accuracy can be maintained in changing environments, even without training data from those scenarios.

</details>


### [81] [Bayesian Optimization Based Grid Point Allocation for LPV and Robust Control](https://arxiv.org/abs/2602.13009)
*E. Javier Olucha,Arash Sadeghzadeh,Amritam Das,Roland Tóth*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates systematic selection of optimal grid points for grid-based Linear Parameter-Varying (LPV) and robust controller synthesis. In both settings, the objective is to identify a set of local models such that the controller synthesized for these local models will satisfy global stability and performance requirements for the entire system. Here, local models correspond to evaluations of the LPV or uncertain plant at fixed values of the scheduling signal or realizations of the uncertainty set, respectively. Then, Bayesian optimization is employed to discover the most informative points that govern the closed-loop performance of the designed LPV or robust controller for the complete system until no significant further performance increase or a user specified limit is reached. Furthermore, when local model evaluations are computationally demanding or difficult to obtain, the proposed method is capable to minimize the number of evaluations and adjust the overall computational cost to the available budget. Lastly, the capabilities of the proposed method in automatically obtaining a sufficiently informative grid set are demonstrated on three case-studies: a robust controller design for an unbalanced disk, a multi-objective robust attitude controller design for a satellite with uncertain parameters and two flexible rotating solar arrays, and an LPV controller design for a robotic arm.

</details>


### [82] [Encoder initialisation methods in the model augmentation setting](https://arxiv.org/abs/2602.13108)
*J. H. Hoekstra,B. Györök,R. Töth,M. Schoukens*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Nonlinear system identification (NL-SI) has proven to be effective in obtaining accurate models for highly complex systems. Recent encoder-based methods for artificial neural network state-space (ANN-SS) models have shown state-of-the-art performance with improved computational efficiency, where the encoder is used to estimate the initial state allowing for batch optimisation methods. To address the lack of interpretability of these black-box ANN models, model augmentation approaches can be used. These combine prior available baseline models with the ANN learning components, resulting in faster convergence and more interpretable models. The combination of the encoder-based method with model augmentation has shown potential. Thus far, however, the encoder has still been treated as a black-box function in the overall estimation process, while additional information in the form of the baseline model is available to predict the model state from past input-output data. In this paper, we propose novel encoder initialisation approaches based on the available baseline model, resulting in improved noise robustness and faster convergence compared to black-box initialisation. The performance of these initialisation methods is demonstrated on a mass-spring-damper system.

</details>


### [83] [3-D Reconfigurable Intelligent Surface: From Reflection to Transmission and From Single Hemisphere to Full 3-D Coverage](https://arxiv.org/abs/2602.13150)
*Ruiqi Wang,Yiming Yang,Atif Shamim*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reconfigurable intelligent surfaces (RIS) are conventionally implemented as two-dimensional (2D) electromagnetic (EM) structures to steer incident waves toward desired reflection angles. This approach limits the reflection to a single hemisphere, and the beam-scanning range is relatively small. In this work, a novel three-dimensional (3D) RIS concept is proposed, where beam-scanning can be realized not only through reflection from the illuminated surface but also through controlled transmission toward adjacent surfaces, enabling near blind-spot-free coverage in the full 3D spatial domain. A cube-based 3D-RIS design operating at millimeter-wave (mm-Wave) frequencies and consisting of six interconnected RIS surfaces is presented. Each surface integrates reconfigurable receiving and reflecting arrays with orthogonal polarizations to ensure intrinsic EM isolation, while a reconfigurable feeding network supports dynamic operation. A subarray-based synthesis approach with binary amplitude gating and predefined phase offsets is developed through a unified theoretical model. This model, validated through full-wave simulations, enables efficient beam switching through a shared aperture. Based on this framework, an 8 x 12 element surface comprising six 4 x 4 subarrays is designed, with each surface covering an angular range from -30 deg to +30 deg. The experimental prototype has been characterized in the 24 to 30 GHz band, and the results demonstrate a gain enhancement of 14.7 dB for reflection, while 14.1 dB is achieved for transmission to the neighboring surface. Finally, wireless communication trials using the Pluto software-defined radio platform combined with frequency up/down converters confirm improved constellation quality and a 6-7 dB improvement in error vector magnitude (EVM) for both reflection and neighboring surface transmission scenarios.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [84] [Quantum walk inspired JPEG compression of images](https://arxiv.org/abs/2602.12306)
*Abhishek Verma,Sahil Tomar,Sandeep Kumar*

Main category: eess.IV

TL;DR: 提出一种受量子启发的自适应量化框架，通过量子行走优化算法学习优化量化表，在保持JPEG兼容性的同时提升图像压缩质量


<details>
  <summary>Details</summary>
Motivation: 传统JPEG压缩使用固定的量化表，无法根据图像内容自适应优化。为提高压缩效率与重建质量，需要一种能联合考虑率失真、同时保持解码器兼容性的智能量化方法

Method: 使用量子行走启发式优化算法在连续参数空间中搜索频率带缩放因子，学习优化量化表。采用统一的率失真目标函数，同时考虑重建保真度和压缩效率，框架保持JPEG兼容性

Result: 在MNIST、CIFAR10和ImageNet子集上测试，平均PSNR提升3-6 dB，更好地保留边缘、轮廓和亮度过渡结构，比特率降低，无需修改解码器即可部署

Conclusion: 提出的量子启发自适应量化框架能显著提升JPEG压缩性能，在保持解码兼容性的同时实现更好的率失真权衡，适合实际部署和研究使用

Abstract: This work proposes a quantum inspired adaptive quantization framework that enhances the classical JPEG compression by introducing a learned, optimized Qtable derived using a Quantum Walk Inspired Optimization (QWIO) search strategy. The optimizer searches a continuous parameter space of frequency band scaling factors under a unified rate distortion objective that jointly considers reconstruction fidelity and compression efficiency. The proposed framework is evaluated on MNIST, CIFAR10, and ImageNet subsets, using Peak Signal to Noise Ratio (PSNR), Structural Similarity Index (SSIM), Bits Per Pixel (BPP), and error heatmap visual analysis as evaluation metrics. Experimental results show average gains ranging from 3 to 6 dB PSNR, along with better structural preservation of edges, contours, and luminance transitions, without modifying decoder compatibility. The structure remains JPEG compliant and can be implemented using accessible scientific packages making it ideal for deployment and practical research use.

</details>


### [85] [Visible and Hyperspectral Imaging for Quality Assessment of Milk: Property Characterisation and Identification](https://arxiv.org/abs/2602.12313)
*Massimo Martinelli,Elena Tomassi,Nafiou Arouna,Morena Gabriele,Laryssa Perez Fabbri,Luisa Pozzo,Giuseppe Conte,Davide Moroni,Laura Pucci*

Main category: eess.IV

TL;DR: 可见光和超光谱成像结合机器学习，能快速、无损地评估牛奶品质，在区分新鲜度、抗生素处理和预测多项生化指标方面表现出高准确度。


<details>
  <summary>Details</summary>
Motivation: 传统的牛奶化学分析方法耗时且破坏性大，需要开发快速、无损、成本效益高的替代技术来确保牛奶的营养价值和食品安全。

Method: 采集52个牛奶样品的生化数据（多酚、抗氧化能力、脂肪酸）同时获取RGB图像和近红外超光谱数据，应用包括XGBoost、随机森林等多种机器学习算法建立图像特征与生化指标的关系模型。

Result: 可见光图像能100%准确区分新鲜与储藏样品、抗生素处理组和对照组；XGBoost模型能完美预测多酚含量和抗氧化能力；超光谱成像对多种脂肪酸的分类准确度超过95%，对处理组的分类准确率达94.8%。

Conclusion: 可见光和超光谱成像与机器学习相结合，是快速评估牛奶化学和营养成分的强大、非侵入性工具，在牛奶质量评估方面具有巨大潜力。

Abstract: Rapid and non-destructive assessment of milk quality is crucial to ensuring both nutritional value and food safety. In this study, we investigated the potential of visible and hyperspectral imaging as cost-effective and quick-response alternatives to conventional chemical analyses for characterizing key properties of cowś milk. A total of 52 milk samples were analysed to determine their biochemical composition (polyphenols, antioxidant capacity, and fatty acids) using spectrophotometer methods and standard gas-liquid and high-performance liquid chromatography (GLC/HPLC). Concurrently, visible (RGB) images were captured using a standard smartphone, and hyperspectral data were acquired in the near-infrared range. A comprehensive analytical framework, including eleven different machine learning algorithms, was employed to correlate imaging features with biochemical measurements. Analysis of visible images accurately distinguished between fresh samples and those stored for 12 days (100 percent accuracy) and achieved perfect discrimination between antibiotic-treated and untreated groups (100 percent accuracy). Moreover, image-derived features enabled perfect prediction of the polyphenols content and the antioxidant capacity using an XGBoost model. Hyperspectral imaging further achieved classification accuracies exceeding 95 percent for several individual fatty acids and 94.8 percent for treatment groups using a Random Forest model. These findings demonstrate that both visible and hyperspectral imaging, when coupled with machine learning, are powerful, non-invasive tools for the rapid assessment of milkś chemical and nutritional profiles, highlighting the strong potential of imaging-based approaches for milk quality assessment.

</details>


### [86] [Conference Proceedings of the Inaugural Conference of the International Society for Tractography (IST 2025 Bordeaux)](https://arxiv.org/abs/2602.12410)
*Flavio Dell Acqua,Maxime Descoteaux,Graham Little,Laurent Petit,Dogu Baran Aydogan,Stephanie Forkel,Alexander Leemans,Simona Schiavi,Michel Thiebaut de Schotten*

Main category: eess.IV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This collection comprises the abstracts presented during poster, power pitch and oral sessions at the Inaugural Conference of the International Society for Tractography (IST Conference 2025), held in Bordeaux, France, from October 13-16, 2025. The conference was designed to foster meaningful exchange and collaboration between disparate fields. The overall focus was on advancing research, innovation, and community in the common fields of interest: neuroanatomy, tractography methods and scientific/clinical applications of tractography. The included abstracts cover the latest advancements in tractography, Diffusion MRI, and related fields including new work on; neurological and psychiatric disorders, deep brain stimulation targeting, and brain development. This landmark event brought together world-leading experts to discuss critical challenges and chart the future direction of the field.

</details>


### [87] [Lung nodule classification on CT scan patches using 3D convolutional neural networks](https://arxiv.org/abs/2602.12750)
*Volodymyr Sydorskyi*

Main category: eess.IV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Lung cancer remains one of the most common and deadliest forms of cancer worldwide. The likelihood of successful treatment depends strongly on the stage at which the disease is diagnosed. Therefore, early detection of lung cancer represents a critical medical challenge. However, this task poses significant difficulties for thoracic radiologists due to the large number of studies to review, the presence of multiple nodules within the lungs, and the small size of many nodules, which complicates visual assessment. Consequently, the development of automated systems that incorporate highly accurate and computationally efficient lung nodule detection and classification modules is essential. This study introduces three methodological improvements for lung nodule classification: (1) an advanced CT scan cropping strategy that focuses the model on the target nodule while reducing computational cost; (2) target filtering techniques for removing noisy labels; (3) novel augmentation methods to improve model robustness. The integration of these techniques enables the development of a robust classification subsystem within a comprehensive Clinical Decision Support System for lung cancer detection, capable of operating across diverse acquisition protocols, scanner types, and upstream models (segmentation or detection). The multiclass model achieved a Macro ROC AUC of 0.9176 and a Macro F1-score of 0.7658, while the binary model reached a Binary ROC AUC of 0.9383 and a Binary F1-score of 0.8668 on the LIDC-IDRI dataset. These results outperform several previously reported approaches and demonstrate state-of-the-art performance for this task.

</details>


### [88] [3DLAND: 3D Lesion Abdominal Anomaly Localization Dataset](https://arxiv.org/abs/2602.12820)
*Mehran Advand,Zahra Dehghanian,Navid Faraji,Reza Barati,Seyed Amir Ahmad Safavi-Naini,Hamid R. Rabiee*

Main category: eess.IV

TL;DR: 提出了3DLAND大规模基准数据集，包含6000+增强CT扫描和20000+高质量3D病灶标注，覆盖七个腹部器官，旨在解决医学图像分析中三维标注不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有腹部CT数据集缺乏三维标注、多器官覆盖和精确的病灶-器官关联，限制了稳健表示学习和临床应用的进展。

Method: 采用三阶段流程：自动空间推理、提示优化的2D分割和记忆引导的3D传播，经过放射科医生验证，表面Dice分数超过0.75。

Result: 3DLAND数据集能够支持异常检测、定位和跨器官迁移学习的可扩展评估，为器官感知的三维分割模型建立了新基准。

Conclusion: 该数据集推动了医疗AI的发展，通过公开数据和代码促进可重复性和进一步研究。

Abstract: Existing medical imaging datasets for abdominal CT often lack three-dimensional annotations, multi-organ coverage, or precise lesion-to-organ associations, hindering robust representation learning and clinical applications. To address this gap, we introduce 3DLAND, a large-scale benchmark dataset comprising over 6,000 contrast-enhanced CT volumes with over 20,000 high-fidelity 3D lesion annotations linked to seven abdominal organs: liver, kidneys, pancreas, spleen, stomach, and gallbladder. Our streamlined three-phase pipeline integrates automated spatial reasoning, prompt-optimized 2D segmentation, and memory-guided 3D propagation, validated by expert radiologists with surface dice scores exceeding 0.75. By providing diverse lesion types and patient demographics, 3DLAND enables scalable evaluation of anomaly detection, localization, and cross-organ transfer learning for medical AI. Our dataset establishes a new benchmark for evaluating organ-aware 3D segmentation models, paving the way for advancements in healthcare-oriented AI. To facilitate reproducibility and further research, the 3DLAND dataset and implementation code are publicly available at https://mehrn79.github.io/3DLAND.

</details>


### [89] [Dual-Phase Cross-Modal Contrastive Learning for CMR-Guided ECG Representations for Cardiovascular Disease Assessment](https://arxiv.org/abs/2602.12883)
*Laura Alvarez-Florez,Angel Bujalance-Gomez,Femke Raijmakers,Samuel Ruiperez-Campillo,Maarten Z. H. Kolk,Jesse Wiers,Julia Vogt,Erik J. Bekkers,Ivana Išgum,Fleur V. Y. Tjong*

Main category: eess.IV

TL;DR: 本文提出了一种对比学习框架，利用配对的心电图-心脏磁共振数据，从心电图中提取更具临床意义的心脏表型，特别是在功能参数预测上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 心脏磁共振成像能详细评估心脏结构和功能，但普及性受限；心电图普及且廉价，但无法深入反映心脏结构和机械功能。为了解决这一矛盾，研究寻求通过深度学习整合两者的优势。

Method: 使用对比学习框架，将心电图表征与3D心脏磁共振数据（舒张末期和收缩末期）对齐，采用双相对比损失函数，在共享潜空间中将每个心电图与两个心脏相位联合锚定。

Result: 在英国生物库超过34,000对ECG-CMR数据上进行验证，结果显示在图像衍生表型提取方面有显著改进（功能参数预测提升9.2%），但临床结局预测改进有限（仅提升0.7%）。

Conclusion: 该方法能从心电图中可扩展且经济高效地提取图像衍生特征，有望扩大心脏成像表型的临床应用范围。

Abstract: Cardiac magnetic resonance imaging (CMR) offers detailed evaluation of cardiac structure and function, but its limited accessibility restricts use to selected patient populations. In contrast, the electrocardiogram (ECG) is ubiquitous and inexpensive, and provides rich information on cardiac electrical activity and rhythm, yet offers limited insight into underlying cardiac structure and mechanical function. To address this, we introduce a contrastive learning framework that improves the extraction of clinically relevant cardiac phenotypes from ECG by learning from paired ECG-CMR data. Our approach aligns ECG representations with 3D CMR volumes at end-diastole (ED) and end-systole (ES), with a dual-phase contrastive loss to anchor each ECG jointly with both cardiac phases in a shared latent space. Unlike prior methods limited to 2D CMR representations with or without a temporal component, our framework models 3D anatomy at both ED and ES phases as distinct latent representations, enabling flexible disentanglement of structural and functional cardiac properties. Using over 34,000 ECG-CMR pairs from the UK Biobank, we demonstrate improved extraction of image-derived phenotypes from ECG, particularly for functional parameters ($\uparrow$ 9.2\%), while improvements in clinical outcome prediction remained modest ($\uparrow$ 0.7\%). This strategy could enable scalable and cost-effective extraction of image-derived traits from ECG. The code for this research is publicly available.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [90] [GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory](https://arxiv.org/abs/2602.12316)
*Pepijn Cobben,Xuanqiang Angelo Huang,Thao Amelia Pham,Isabel Dahlgren,Terry Jingchen Zhang,Zhijing Jin*

Main category: cs.AI

TL;DR: 介绍了GT-HarmBench，一个评估多智能体高风险场景的基准，包含2009个基于囚徒困境等博弈论结构的场景。测试15个前沿模型，发现智能体仅在62%的情况下采取有益社会的行动，博弈论干预能将这一比例提升高达18%。


<details>
  <summary>Details</summary>
Motivation: 前沿AI系统愈发强大，并被部署到高风险的多智能体环境中。然而，现有的AI安全基准主要评估单智能体，导致对多智能体风险（如协调失败和冲突）的理解不足。

Method: 引入GT-HarmBench基准，包含2009个高风险场景，涵盖囚徒困境、猎鹿博弈和胆小鬼博弈等博弈论结构。场景来自MIT AI风险库中的现实风险情境。测试了15个前沿模型，测量其对博弈论提示框架和顺序的敏感性，并分析导致失败的原因推理模式。

Result: 智能体仅在62%的情况下选择了有益社会的行动，常常导致有害结果。研究表明，博弈论的干预方法可以将有益结果提升高达18%。基准测试结果揭示了显著的可靠性差距。

Conclusion: GT-HarmBench为多智能体环境中的对齐研究提供了一个全面的标准化测试平台，突显了现有的实质性可靠性差距，并展示了通过博弈论方法改善AI行为的潜力。基准和代码已开源。

Abstract: Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and conflict poorly understood. We introduce GT-HarmBench, a benchmark of 2,009 high-stakes scenarios spanning game-theoretic structures such as the Prisoner's Dilemma, Stag Hunt and Chicken. Scenarios are drawn from realistic AI risk contexts in the MIT AI Risk Repository. Across 15 frontier models, agents choose socially beneficial actions in only 62% of cases, frequently leading to harmful outcomes. We measure sensitivity to game-theoretic prompt framing and ordering, and analyze reasoning patterns driving failures. We further show that game-theoretic interventions improve socially beneficial outcomes by up to 18%. Our results highlight substantial reliability gaps and provide a broad standardized testbed for studying alignment in multi-agent environments. The benchmark and code are available at https://github.com/causalNLP/gt-harmbench.

</details>


### [91] [A Theoretical Framework for Adaptive Utility-Weighted Benchmarking](https://arxiv.org/abs/2602.12356)
*Philip Waggoner*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Benchmarking has long served as a foundational practice in machine learning and, increasingly, in modern AI systems such as large language models, where shared tasks, metrics, and leaderboards offer a common basis for measuring progress and comparing approaches. As AI systems are deployed in more varied and consequential settings, though, there is growing value in complementing these established practices with a more holistic conceptualization of what evaluation should represent. Of note, recognizing the sociotechnical contexts in which these systems operate invites an opportunity for a deeper view of how multiple stakeholders and their unique priorities might inform what we consider meaningful or desirable model behavior. This paper introduces a theoretical framework that reconceptualizes benchmarking as a multilayer, adaptive network linking evaluation metrics, model components, and stakeholder groups through weighted interactions. Using conjoint-derived utilities and a human-in-the-loop update rule, we formalize how human tradeoffs can be embedded into benchmark structure and how benchmarks can evolve dynamically while preserving stability and interpretability. The resulting formulation generalizes classical leaderboards as a special case and provides a foundation for building evaluation protocols that are more context aware, resulting in new robust tools for analyzing the structural properties of benchmarks, which opens a path toward more accountable and human-aligned evaluation.

</details>


### [92] [Evolving Beyond Snapshots: Harmonizing Structure and Sequence via Entity State Tuning for Temporal Knowledge Graph Forecasting](https://arxiv.org/abs/2602.12389)
*Siyuan Li,Yunjia Wu,Yiyong Xiao,Pingyang Huang,Peize Li,Ruitong Liu,Yan Wen,Te Sun,Fangyi Pei*

Main category: cs.AI

TL;DR: EST (Entity State Tuning) 框架，通过引入持续演化的实体状态来解决TKG预测中的长期依赖问题，在多个数据集上显著提升多种模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有时序知识图谱(TKG)预测方法大多是无状态的，需要在每个时间戳重新计算实体表示，导致长期依赖信息的快速衰减。

Method: 提出EST框架：包含全局状态缓冲区、拓扑感知状态感知器、统一时序上下文模块和双轨演化机制，形成闭环设计平衡可塑性与稳定性。

Result: 在多个基准测试中，EST能持续提升不同骨干模型性能，达到最先进水平，证明了状态持续性对长周期TKG预测的重要性。

Conclusion: 实体状态的持续演化对TKG预测至关重要，EST框架为解决长期依赖问题提供了有效方法。

Abstract: Temporal knowledge graph (TKG) forecasting requires predicting future facts by jointly modeling structural dependencies within each snapshot and temporal evolution across snapshots. However, most existing methods are stateless: they recompute entity representations at each timestamp from a limited query window, leading to episodic amnesia and rapid decay of long-term dependencies. To address this limitation, we propose Entity State Tuning (EST), an encoder-agnostic framework that endows TKG forecasters with persistent and continuously evolving entity states. EST maintains a global state buffer and progressively aligns structural evidence with sequential signals via a closed-loop design. Specifically, a topology-aware state perceiver first injects entity-state priors into structural encoding. Then, a unified temporal context module aggregates the state-enhanced events with a pluggable sequence backbone. Subsequently, a dual-track evolution mechanism writes the updated context back to the global entity state memory, balancing plasticity against stability. Experiments on multiple benchmarks show that EST consistently improves diverse backbones and achieves state-of-the-art performance, highlighting the importance of state persistence for long-horizon TKG forecasting. The code is published at https://github.com/yuanwuyuan9/Evolving-Beyond-Snapshots

</details>


### [93] [Scaling Web Agent Training through Automatic Data Generation and Fine-grained Evaluation](https://arxiv.org/abs/2602.12544)
*Lajanugen Logeswaran,Jaekyeom Kim,Sungryull Sohn,Creighton Glasscock,Honglak Lee*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a scalable pipeline for automatically generating high-quality training data for web agents. In particular, a major challenge in identifying high-quality training instances is trajectory evaluation - quantifying how much progress was made towards task completion. We introduce a novel constraint-based evaluation framework that provides fine-grained assessment of progress towards task completion. This enables us to leverage partially successful trajectories, which significantly expands the amount of usable training data. We evaluate our method on a new benchmark we propose called BookingArena, which consists of complex booking tasks across 20 popular websites, and demonstrate that our distilled student model outperforms open-source approaches and matches or exceeds commercial systems, while being a significantly smaller model. Our work addresses the challenge of efficiently creating diverse, realistic web interaction datasets and provides a systematic evaluation methodology for complex structured web tasks.

</details>


### [94] [To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2602.12566)
*Haoqing Wang,Xiang Long,Ziheng Li,Yilong Xu,Tingguang Li,Yehui Tang*

Main category: cs.AI

TL;DR: 该论文探讨了在多领域专家级模型训练中，混合多任务强化学习与验证奖励（RLVR）与分离训练后模型合并两种范式的比较与分析，发现跨领域RLVR相互干扰少，推理密集型领域存在相互促进效应。


<details>
  <summary>Details</summary>
Motivation: 当前多领域专家级模型的训练主要采用混合多任务RLVR和分离RLVR后模型合并两种范式，但缺乏对这两种范式的详细比较和分析。为了建立通用的多领域专家级模型，需要深入理解跨领域RLVR的协作机制。

Method: 选择数学、编程、科学和指令遵循等常用高级任务作为目标领域，使用开源数据集设计广泛的定性和定量实验，分析跨领域RLVR的相互干扰情况，并从权重空间几何、模型预测行为和信息约束等角度分析内部机制。

Result: 研究发现跨领域RLVR表现出很少的相互干扰，推理密集型领域之间存在相互促进的协同效应。通过权重空间几何、预测行为和信息约束的分析，揭示了这种相互增益的内部机制。

Conclusion: 该研究为多领域专家级模型的训练提供了重要见解，表明混合多任务训练与分离训练后合并两种范式在多领域RLVR中都表现良好，而推理密集型领域的协同效应尤为明显。项目命名为M2RL，意为混合多任务训练或分离训练后合并的强化学习。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) plays a key role in stimulating the explicit reasoning capability of Large Language Models (LLMs). We can achieve expert-level performance in some specific domains via RLVR, such as coding or math. When a general multi-domain expert-level model is required, we need to carefully consider the collaboration of RLVR across different domains. The current state-of-the-art models mainly employ two different training paradigms for multi-domain RLVR: mixed multi-task RLVR and separate RLVR followed by model merging. However, most of the works did not provide a detailed comparison and analysis about these paradigms. To this end, we choose multiple commonly used high-level tasks (e.g., math, coding, science, and instruction following) as our target domains and design extensive qualitative and quantitative experiments using open-source datasets. We find the RLVR across domains exhibits few mutual interferences, and reasoning-intensive domains demonstrate mutually synergistic effects. Furthermore, we analyze the internal mechanisms of mutual gains from the perspectives of weight space geometry, model prediction behavior, and information constraints. This project is named as M2RL that means Mixed multi-task training or separate training followed by model Merging for Reinforcement Learning, and the homepage is at https://github.com/mosAI25/M2RL

</details>


### [95] [Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models](https://arxiv.org/abs/2602.12586)
*Joshua Ong Jun Leang,Yu Zhao,Mihaela Cătălina Stoian,Wenda Li,Shay B. Cohen,Eleonora Giunchiglia*

Main category: cs.AI

TL;DR: McDiffuSE框架使用蒙特卡洛树搜索优化掩码扩散模型中槽位填充顺序，通过前瞻模拟评估部分完成结果，相比基线方法在MBPP和MATH500等数学与代码推理任务上取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 现有掩码扩散模型中的计划-填充解码方法在数学和代码推理任务中存在性能对填充顺序高度敏感的问题，导致输出方差大，需要系统化的顺序优化策略

Method: 提出McDiffuSE框架，将槽位选择建模为决策过程，使用蒙特卡洛树搜索优化填充顺序，通过前瞻模拟评估部分完成结果，在组合空间中进行系统性探索

Result: 相比自回归基线平均提升3.2%，相比基准计划-填充方法提升8.0%，在MBPP任务上提升19.5%，在MATH500任务上提升4.9%。研究发现更大探索常数而非更多模拟次数对克服模型置信度偏见和发现有效顺序是必要的

Conclusion: 基于MCTS的规划是增强掩码扩散模型生成质量的有效方法，虽然系统主要遵循顺序生成，但融入非顺序生成对最大化性能至关重要

Abstract: While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). McDiffuSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders. Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while McDiffuSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs.

</details>


### [96] [Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents](https://arxiv.org/abs/2602.12662)
*Ruihan Yang,Fanghua Ye,Xiang We,Ruoqing Zhao,Kang Luo,Xinbo Xu,Bo Zhao,Ruotian Ma,Shanyi Wang,Zhaopeng Tu,Xiaolong Li,Deqing Yang,Linus*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigidity is inefficient for long-horizon tasks, where cognitive demands vary significantly from step to step, with some requiring strategic planning and others only routine execution. In this paper, we introduce CogRouter, a framework that trains agents to dynamically adapt cognitive depth at each step. Grounded in ACT-R theory, we design four hierarchical cognitive levels ranging from instinctive responses to strategic planning. Our two-stage training approach includes Cognition-aware Supervised Fine-tuning (CoSFT) to instill stable level-specific patterns, and Cognition-aware Policy Optimization (CoPO) for step-level credit assignment via confidence-aware advantage reweighting. The key insight is that appropriate cognitive depth should maximize the confidence of the resulting action. Experiments on ALFWorld and ScienceWorld demonstrate that CogRouter achieves state-of-the-art performance with superior efficiency. With Qwen2.5-7B, it reaches an 82.3% success rate, outperforming GPT-4o (+40.3%), OpenAI-o3 (+18.3%), and GRPO (+14.0%), while using 62% fewer tokens.

</details>


### [97] [Evaluating Robustness of Reasoning Models on Parameterized Logical Problems](https://arxiv.org/abs/2602.12665)
*Naïm Es-sebbani,Esteban Marquer,Yakoub Salhi,Zied Bouraoui*

Main category: cs.AI

TL;DR: 该研究提出了一个针对2-SAT的诊断性基准测试，通过参数化结构公式集来评估LLM推理能力，能够分离表面难度与结构现象。


<details>
  <summary>Details</summary>
Motivation: 标准SAT基准测试常将表面难度与结构特性混淆，无法准确评估LLM推理的核心能力。需要建立能分离不同推理能力的诊断性基准。

Method: 设计了五类参数化2-CNF公式生成器：(1)矛盾循环不满足核心，(2)控制自由变量比例的满足实例，(3)预设骨干变量，(4)耦合单调区域的延迟桥接子句，(5)对称/重复结构变体。通过语义保持变换评估稳健性。

Result: 实验发现LLM推理器在保持表面统计量不变的情况下，对特定结构干预表现出剧烈性能变化，揭示了聚合SAT准确率无法发现的脆弱性区域。

Conclusion: 该诊断基准能有效揭示LLM推理的结构化能力缺陷，为理解推理机理提供新工具，证明表面难度指标不足评估真实推理能力。

Abstract: Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine satisfiability. We introduce a diagnostic benchmark for 2-SAT built from parameterized families of structured 2--CNF formulas, where satisfiability is characterized by the implication graph and can be tuned along interpretable axes. Our generators isolate distinct competencies and failure modes: (i) contradiction-cycle UNSAT cores with controllable size and imbalance, (ii) SAT instances with a prescribed fraction of free variables to control solution multiplicity, (iii) planted backbones that modulate propagation, (iv) late bridge clauses that couple otherwise monotone regions to probe sensitivity to ordering and revision, and (v) symmetry/duplication variants that test abstraction under renaming and redundant structure. We evaluate LLM-based reasoners on decision accuracy and assignment validity, and quantify robustness under semantics-preserving perturbations such as clause reordering, filler clauses, and variable renaming. Across models, we observe sharp performance transitions under targeted structural interventions even when surface statistics are held fixed, revealing brittleness regimes that are invisible to aggregate SAT accuracy.

</details>


### [98] [SkillsBench: Benchmarking How Well Agent Skills Work Across Diverse Tasks](https://arxiv.org/abs/2602.12670)
*Xiangyi Li,Wenbo Chen,Yimin Liu,Shenghan Zheng,Xiaokun Chen,Yifeng He,Yubo Li,Bingran You,Haotian Shen,Jiankai Sun,Shuyi Wang,Qunhong Zeng,Di Wang,Xuandong Zhao,Yuanli Wang,Roey Ben Chaim,Zonglin Di,Yipeng Gao,Junwei He,Yizhuo He,Liqiang Jing,Luyang Kong,Xin Lan,Jiachen Li,Songlin Li,Yijiang Li,Yueqian Lin,Xinyi Liu,Xuanqing Liu,Haoran Lyu,Ze Ma,Bowei Wang,Runhui Wang,Tianyu Wang,Wengao Ye,Yue Zhang,Hanwen Xing,Yiqi Xue,Steven Dillmann,Han-chung Lee*

Main category: cs.AI

TL;DR: 论文介绍了SkillsBench基准测试，用于系统性评估技能包（Agent Skills）对LLM智能体的影响。结果显示精心设计的技能包可显著提升任务通过率（平均+16.2pp），但效果存在领域差异，且模型难以自主生成有效技能。


<details>
  <summary>Details</summary>
Motivation: 当前技能包在LLM智能体中快速普及，但缺乏标准方法来衡量其实际效果。研究者希望建立系统化评估框架，量化技能包对智能体性能的真实影响。

Method: 开发SkillsBench基准：包含11个领域的86个任务，每个任务配备精心设计的技能包和确定性验证器。测试7种智能体-模型配置在3种条件下的表现（无技能、精心设计技能、自主生成技能），共分析7,308条执行轨迹。

Result: 1. 精心设计技能平均提升任务通过率16.2个百分点，但领域差异巨大（软件工程+4.5pp到医疗保健+51.9pp）；
2. 16/84任务出现负提升；
3. 自主生成技能无显著益处；
4. 2-3个模块的精简技能优于全面文档；
5. 带技能的小模型可匹敌无技能的大模型。

Conclusion: 技能包能有效增强LLM智能体性能，但其设计质量至关重要。模型难以自我生成有效技能，且精简的模块化技能设计更优。该研究为技能包的标准化评估提供了重要基准。

Abstract: Agent Skills are structured packages of procedural knowledge that augment LLM agents at inference time. Despite rapid adoption, there is no standard way to measure whether they actually help. We present SkillsBench, a benchmark of 86 tasks across 11 domains paired with curated Skills and deterministic verifiers. Each task is evaluated under three conditions: no Skills, curated Skills, and self-generated Skills. We test 7 agent-model configurations over 7,308 trajectories. Curated Skills raise average pass rate by 16.2 percentage points(pp), but effects vary widely by domain (+4.5pp for Software Engineering to +51.9pp for Healthcare) and 16 of 84 tasks show negative deltas. Self-generated Skills provide no benefit on average, showing that models cannot reliably author the procedural knowledge they benefit from consuming. Focused Skills with 2--3 modules outperform comprehensive documentation, and smaller models with Skills can match larger models without them.

</details>


### [99] [X-SYS: A Reference Architecture for Interactive Explanation Systems](https://arxiv.org/abs/2602.12748)
*Tobias Labarta,Nhi Hoang,Maximilian Dreyer,Jim Berend,Oleg Hein,Jackie Ma,Wojciech Samek,Sebastian Lapuschkin*

Main category: cs.AI

TL;DR: X-SYS：将可解释AI系统化的参考架构，解决交互式解释系统在部署中的技术要求。


<details>
  <summary>Details</summary>
Motivation: 当前XAI研究虽有许多技术方法，但将可解释性作为系统部署仍面临挑战：交互式解释系统需要兼顾合适的算法和系统能力，以在多轮查询、模型数据演化、治理约束下保持解释可用性。作者认为需要将可解释性视为信息系统问题，用户交互需求会引发特定系统要求。

Method: 提出X-SYS参考架构，围绕STAR四大质量属性（可扩展性、可追溯性、响应性、适应性），划分五个组件（XUI服务、解释服务、模型服务、数据服务、编排与治理），将交互模式映射到系统能力，解耦前端UI演进与后端计算。通过SemanticLens系统（用于视觉语言模型的语义搜索与激活控制）实现该架构。

Result: X-SYS为构建交互式解释系统提供了可复用的蓝图，并通过具体实例展示了如何通过基于契约的服务边界支持独立演进、离在线分离保障响应性、持久状态管理实现可追溯性。

Conclusion: 该工作提供了支持端到端设计且满足运营约束的交互式解释系统的通用架构和具体实现，为（X）AI研究者、开发者和从业者连接交互解释用户界面与系统能力提供了指导。

Abstract: The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system capabilities that maintain explanation usability across repeated queries, evolving models and data, and governance constraints. We argue that operationalizing XAI requires treating explainability as an information systems problem where user interaction demands induce specific system requirements. We introduce X-SYS, a reference architecture for interactive explanation systems, that guides (X)AI researchers, developers and practitioners in connecting interactive explanation user interfaces (XUI) with system capabilities. X-SYS organizes around four quality attributes named STAR (scalability, traceability, responsiveness, and adaptability), and specifies a five-component decomposition (XUI Services, Explanation Services, Model Services, Data Services, Orchestration and Governance). It maps interaction patterns to system capabilities to decouple user interface evolution from backend computation. We implement X-SYS through SemanticLens, a system for semantic search and activation steering in vision-language models. SemanticLens demonstrates how contract-based service boundaries enable independent evolution, offline/online separation ensures responsiveness, and persistent state management supports traceability. Together, this work provides a reusable blueprint and concrete instantiation for interactive explanation systems supporting end-to-end design under operational constraints.

</details>


### [100] [WebClipper: Efficient Evolution of Web Agents with Graph-based Trajectory Pruning](https://arxiv.org/abs/2602.12852)
*Junjie Wang,Zequn Xie,Dan Yang,Jie Feng,Yue Shen,Duolin Sun,Meixiu Long,Yihan Jiao,Zhehao Tan,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.AI

TL;DR: WebClipper框架通过图剪枝压缩网页智能体搜索轨迹，将搜索过程建模为状态图，将轨迹优化转化为最小必要有向无环图挖掘问题，减少约20%的工具调用轮次同时提升准确性。


<details>
  <summary>Details</summary>
Motivation: 现有开源网页智能体在复杂信息检索任务中表现出潜力，但搜索效率研究不足，常出现长工具调用轨迹、循环推理循环和无效分支探索等问题，需要提升效率同时保持准确性。

Method: 提出WebClipper框架：1）将智能体搜索过程建模为状态图；2）将轨迹优化转化为最小必要有向无环图挖掘问题；3）通过图剪枝压缩轨迹消除冗余步骤；4）在优化轨迹上持续训练智能体演化更高效搜索模式；5）引入新的度量标准F-AE Score平衡准确性和效率。

Result: 实验表明WebClipper在保持优秀性能的同时压缩工具调用轮次约20%，并提高准确性。新提出的F-AE Score能有效衡量模型在准确性和效率间的平衡表现。

Conclusion: WebClipper通过图剪枝方法优化网页智能体搜索轨迹，在减少20%工具调用轮次的同时提升准确性，为网页智能体设计中平衡效果和效率提供了实用见解。

Abstract: Deep Research systems based on web agents have shown strong potential in solving complex information-seeking tasks, yet their search efficiency remains underexplored. We observe that many state-of-the-art open-source web agents rely on long tool-call trajectories with cyclic reasoning loops and exploration of unproductive branches. To address this, we propose WebClipper, a framework that compresses web agent trajectories via graph-based pruning. Concretely, we model the agent's search process as a state graph and cast trajectory optimization as a minimum-necessary Directed Acyclic Graph (DAG) mining problem, yielding pruned trajectories that preserve essential reasoning while eliminating redundant steps. Continued training on these refined trajectories enables the agent to evolve toward more efficient search patterns and reduces tool-call rounds by about 20% while improving accuracy. Furthermore, we introduce a new metric called F-AE Score to measure the model's overall performance in balancing accuracy and efficiency. Experiments demonstrate that WebClipper compresses tool-call rounds under excellent performance, providing practical insight into balancing effectiveness and efficiency in web agent design.

</details>


### [101] [BrowseComp-$V^3$: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2602.12876)
*Huanyao Zhang,Jiepeng Zhou,Bo Li,Bowen Zhou,Yanzhe Dan,Haishan Lu,Zhiyong Cao,Jiaoyang Chen,Yuqian Han,Zinan Sheng,Zhengwei Tao,Hao Liang,Jialong Wu,Yang Shi,Yuanpeng He,Jiaye Lin,Qintong Zhang,Guochen Yan,Runhao Zhao,Zhengpin Li,Xiaohan Yu,Lang Mei,Chong Chen,Wentao Zhang,Bin Cui*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multimodal large language models (MLLMs), equipped with increasingly advanced planning and tool-use capabilities, are evolving into autonomous agents capable of performing multimodal web browsing and deep search in open-world environments. However, existing benchmarks for multimodal browsing remain limited in task complexity, evidence accessibility, and evaluation granularity, hindering comprehensive and reproducible assessments of deep search capabilities. To address these limitations, we introduce BrowseComp-$V^3$, a novel benchmark consisting of 300 carefully curated and challenging questions spanning diverse domains. The benchmark emphasizes deep, multi-level, and cross-modal multi-hop reasoning, where critical evidence is interleaved across textual and visual modalities within and across web pages. All supporting evidence is strictly required to be publicly searchable, ensuring fairness and reproducibility. Beyond final-answer accuracy, we incorporate an expert-validated, subgoal-driven process evaluation mechanism that enables fine-grained analysis of intermediate reasoning behaviors and systematic characterization of capability boundaries. In addition, we propose OmniSeeker, a unified multimodal browsing agent framework integrating diverse web search and visual perception tools. Comprehensive experiments demonstrate that even state-of-the-art models achieve only 36% accuracy on our benchmark, revealing critical bottlenecks in multimodal information integration and fine-grained perception. Our results highlight a fundamental gap between current model capabilities and robust multimodal deep search in real-world settings.

</details>


### [102] [Information-theoretic analysis of world models in optimal reward maximizers](https://arxiv.org/abs/2602.12963)
*Alfred Harwood,Jose Faustino,Alex Altair*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: An important question in the field of AI is the extent to which successful behaviour requires an internal representation of the world. In this work, we quantify the amount of information an optimal policy provides about the underlying environment. We consider a Controlled Markov Process (CMP) with $n$ states and $m$ actions, assuming a uniform prior over the space of possible transition dynamics. We prove that observing a deterministic policy that is optimal for any non-constant reward function then conveys exactly $n \log m$ bits of information about the environment. Specifically, we show that the mutual information between the environment and the optimal policy is $n \log m$ bits. This bound holds across a broad class of objectives, including finite-horizon, infinite-horizon discounted, and time-averaged reward maximization. These findings provide a precise information-theoretic lower bound on the "implicit world model'' necessary for optimality.

</details>


### [103] [Consistency of Large Reasoning Models Under Multi-Turn Attacks](https://arxiv.org/abs/2602.13093)
*Yubo Li,Ramayya Krishnan,Rema Padman*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.

</details>


### [104] [Constrained Assumption-Based Argumentation Frameworks](https://arxiv.org/abs/2602.13135)
*Emanuele De Angelis,Fabio Fioravanti,Maria Chiara Meo,Alberto Pettorossi,Maurizio Proietti,Francesca Toni*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Assumption-based Argumentation (ABA) is a well-established form of structured argumentation. ABA frameworks with an underlying atomic language are widely studied, but their applicability is limited by a representational restriction to ground (variable-free) arguments and attacks built from propositional atoms. In this paper, we lift this restriction and propose a novel notion of constrained ABA (CABA), whose components, as well as arguments built from them, may include constrained variables, ranging over possibly infinite domains. We define non-ground semantics for CABA, in terms of various notions of non-ground attacks. We show that the new semantics conservatively generalise standard ABA semantics.

</details>


### [105] [Optimal Take-off under Fuzzy Clearances](https://arxiv.org/abs/2602.13166)
*Hugo Henry,Arthur Tsai,Kelly Cohen*

Main category: cs.AI

TL;DR: 该研究提出了一种混合障碍物规避架构，结合了最优控制和模糊规则系统，用于无人机自适应约束处理，但在实验中发现软件兼容性问题导致约束无法正常执行。


<details>
  <summary>Details</summary>
Motivation: 经典最优控制在不确定性下的局限性以及航空安全关键系统对可解释决策的需求，促使研究者设计能根据监管标准自适应调整约束的框架。

Method: 采用三阶段Takagi-Sugeno-Kang模糊层来调节约束半径、紧急级别和激活决策，并将这些模糊导出的间距作为软约束融入最优控制问题，使用FALCON工具箱和IPOPT求解。

Result: 概念验证显示该方法能在单线程MATLAB环境中以每次迭代2-3秒生成最优轨迹，但发现FALCON和IPOPT最新版本存在软件不兼容问题，导致拉格朗日惩罚项恒为零，无法正常执行约束。

Conclusion: 该混合架构在理论上具有实时应用潜力，但当前受软件兼容性问题限制；未来工作包括验证软件回归问题、优化模糊隶属函数，以及扩展到更高保真度模型和随机障碍环境。

Abstract: This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limitations of classical optimal control under uncertainty and the need for interpretable decision making in safety critical aviation systems, we design a three stage Takagi Sugeno Kang fuzzy layer that modulates constraint radii, urgency levels, and activation decisions based on regulatory separation minima and airworthiness guidelines from FAA and EASA. These fuzzy-derived clearances are then incorporated as soft constraints into an optimal control problem solved using the FALCON toolbox and IPOPT. The framework aims to reduce unnecessary recomputations by selectively activating obstacle avoidance updates while maintaining compliance with aviation procedures. A proof of concept implementation using a simplified aircraft model demonstrates that the approach can generate optimal trajectories with computation times of 2,3 seconds per iteration in a single threaded MATLAB environment, suggesting feasibility for near real time applications. However, our experiments revealed a critical software incompatibility in the latest versions of FALCON and IPOPT, in which the Lagrangian penalty term remained identically zero, preventing proper constraint enforcement. This behavior was consistent across scenarios and indicates a solver toolbox regression rather than a modeling flaw. Future work includes validating this effect by reverting to earlier software versions, optimizing the fuzzy membership functions using evolutionary methods, and extending the system to higher fidelity aircraft models and stochastic obstacle environments.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [106] [OptiML: An End-to-End Framework for Program Synthesis and CUDA Kernel Optimization](https://arxiv.org/abs/2602.12305)
*Arijit Bhattacharjee,Heng Ping,Son Vu Le,Paul Bogdan,Nesreen K. Ahmed,Ali Jannesari*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Generating high-performance CUDA kernels remains challenging due to the need to navigate a combinatorial space of low-level transformations under noisy and expensive hardware feedback. Although large language models can synthesize functionally correct CUDA code, achieving competitive performance requires systematic exploration and verification of optimization choices. We present OptiML, an end-to-end framework that maps either natural-language intent or input CUDA code to performance-optimized CUDA kernels by formulating kernel optimization as search under verification. OptiML consists of two decoupled stages. When the input is natural language, a Mixture-of-Thoughts generator (OptiML-G) acts as a proposal policy over kernel implementation strategies, producing an initial executable program. A search-based optimizer (OptiML-X) then refines either synthesized or user-provided kernels using Monte Carlo Tree Search over LLM-driven edits, guided by a hardware-aware reward derived from profiler feedback. Each candidate transformation is compiled, verified, and profiled with Nsight Compute, and evaluated by a composite objective that combines runtime with hardware bottleneck proxies and guardrails against regressions. We evaluate OptiML in both synthesis-and-optimize and optimization-only settings on a diverse suite of CUDA kernels. Results show that OptiML consistently discovers verified performance improvements over strong LLM baselines and produces interpretable optimization trajectories grounded in profiler evidence.

</details>


### [107] [Abstractive Red-Teaming of Language Model Character](https://arxiv.org/abs/2602.12318)
*Nate Rahn,Allison Qi,Avery Griffin,Jonathan Michala,Henry Sleight,Erik Jones*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We want language model assistants to conform to a character specification, which asserts how the model should act across diverse user interactions. While models typically follow these character specifications, they can occasionally violate them in large-scale deployments. In this work, we aim to identify types of queries that are likely to produce such character violations at deployment, using much less than deployment-level compute. To do this, we introduce abstractive red-teaming, where we search for natural-language query categories, e.g. "The query is in Chinese. The query asks about family roles," that routinely elicit violations. These categories abstract over the many possible variants of a query which could appear in the wild. We introduce two algorithms for efficient category search against a character-trait-specific reward model: one based on reinforcement learning on a category generator LLM, and another which leverages a strong LLM to iteratively synthesize categories from high-scoring queries. Across a 12-principle character specification and 7 target models, we find that our algorithms consistently outperform baselines, and generate qualitatively interesting categories; for example, queries which ask Llama-3.1-8B-Instruct to predict the future lead to responses saying that AI will dominate humanity, and queries that ask GPT-4.1-Mini for essential prison survival items lead to enthusiastic recommendation of illegal weapons. Overall, we believe our results represent an important step towards realistic pre-deployment auditing of language model character.

</details>


### [108] [The Appeal and Reality of Recycling LoRAs with Adaptive Merging](https://arxiv.org/abs/2602.12323)
*Haokun Liu,Gyung Hyun Je,Marco Ciccone,Zhenlin Xu,Prasanth YSS,Colin Raffel*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The widespread availability of fine-tuned LoRA modules for open pre-trained models has led to an interest in methods that can adaptively merge LoRAs to improve performance. These methods typically include some way of selecting LoRAs from a pool and tune merging coefficients based on a task-specific dataset. While adaptive merging methods have demonstrated improvements in some settings, no past work has attempted to recycle LoRAs found "in the wild" on model repositories like the Hugging Face Hub. To address this gap, we consider recycling from a pool of nearly 1,000 user-contributed LoRAs trained from the Llama 3.1 8B-Instruct language model. Our empirical study includes a range of adaptive and non-adaptive merging methods in addition to a new method designed via a wide search over the methodological design space. We demonstrate that adaptive merging methods can improve performance over the base model but provide limited benefit over training a new LoRA on the same data used to set merging coefficients. We additionally find not only that the specific choice of LoRAs to merge has little importance, but that using LoRAs with randomly initialized parameter values yields similar performance. This raises the possibility that adaptive merging from recycled LoRAs primarily works via some kind of regularization effect, rather than by enabling positive cross-task transfer. To better understand why past work has proven successful, we confirm that positive transfer is indeed possible when there are highly relevant LoRAs in the pool. We release the model checkpoints and code online.

</details>


### [109] [Intrinsic Credit Assignment for Long Horizon Interaction](https://arxiv.org/abs/2602.12342)
*Ilze Amanda Auzina,Joschka Strüber,Sergio Hernández-Gutiérrez,Shashwat Goel,Ameya Prabhu,Matthias Bethge*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: How can we train agents to navigate uncertainty over long horizons? In this work, we propose ΔBelief-RL, which leverages a language model's own intrinsic beliefs to reward intermediate progress. Our method utilizes the change in the probability an agent assigns to the target solution for credit assignment. By training on synthetic interaction data, ΔBelief-RL teaches information-seeking capabilities that consistently outperform purely outcome-based rewards for Reinforcement Learning, with improvements generalizing to out-of-distribution applications ranging from customer service to personalization. Notably, the performance continues to improve as we scale test-time interactions beyond the training horizon, with interaction-efficiency increasing even on Pass@k metrics. Overall, our work introduces a scalable training strategy for navigating uncertainty over a long-horizon, by enabling credit assignment to intermediate actions via intrinsic ΔBelief rewards.

</details>


### [110] [Block-Sample MAC-Bayes Generalization Bounds](https://arxiv.org/abs/2602.12605)
*Matthias Frey,Jingge Zhu,Michael C. Gastpar*

Main category: cs.LG

TL;DR: 论文提出了新的块采样MAC-Bayes界，这种界约束期望泛化误差而非高概率下的泛化误差，通过只依赖训练数据子集的散度项可能显著改进传统界的紧致性，并通过实例验证了这一优势。


<details>
  <summary>Details</summary>
Motivation: 传统PAC-Bayes界在高概率下约束泛化误差，但可能较松，甚至在某些情况下无效；而期望泛化误差的MAC-Bayes界可提供更紧致的界，尤其当数据具有块结构时，引入只依赖数据子集的散度项有望改进界紧致性。

Method: 提出一族新颖的块采样MAC-Bayes界，这些界可视为已知PAC-Bayes界在期望形式下的推广；新界包含仅依赖训练数据块（子集）的散度项，通过选择合适块大小可得到有限界。

Result: 数值例子表明，传统PAC-Bayes界无论如何选择先验都是无效的，而新提出的块采样MAC-Bayes界在适当块大小下是有限的，且可能显著提高界紧致性；同时证明具有类似形式的高概率版本PAC-Bayes界不可能达到与MAC-Bayes界相同的收敛速率。

Conclusion: 块采样MAC-Bayes界在约束期望泛化误差方面优于传统PAC-Bayes界，能提供更紧致的界，但无法直接推广到高概率版本；这为机器学习理论分析提供了新的工具，尤其适合具有块结构数据的泛化分析。

Abstract: We present a family of novel block-sample MAC-Bayes bounds (mean approximately correct). While PAC-Bayes bounds (probably approximately correct) typically give bounds for the generalization error that hold with high probability, MAC-Bayes bounds have a similar form but bound the expected generalization error instead. The family of bounds we propose can be understood as a generalization of an expectation version of known PAC-Bayes bounds. Compared to standard PAC-Bayes bounds, the new bounds contain divergence terms that only depend on subsets (or \emph{blocks}) of the training data. The proposed MAC-Bayes bounds hold the promise of significantly improving upon the tightness of traditional PAC-Bayes and MAC-Bayes bounds. This is illustrated with a simple numerical example in which the original PAC-Bayes bound is vacuous regardless of the choice of prior, while the proposed family of bounds are finite for appropriate choices of the block size. We also explore the question whether high-probability versions of our MAC-Bayes bounds (i.e., PAC-Bayes bounds of a similar form) are possible. We answer this question in the negative with an example that shows that in general, it is not possible to establish a PAC-Bayes bound which (a) vanishes with a rate faster than $\mathcal{O}(1/\log n)$ whenever the proposed MAC-Bayes bound vanishes with rate $\mathcal{O}(n^{-1/2})$ and (b) exhibits a logarithmic dependence on the permitted error probability.

</details>


### [111] [Policy4OOD: A Knowledge-Guided World Model for Policy Intervention Simulation against the Opioid Overdose Crisis](https://arxiv.org/abs/2602.12373)
*Yijun Ma,Zehong Wang,Weixiang Sun,Zheyuan Zhang,Kaiwen Shi,Nitesh Chawla,Yanfang Ye*

Main category: cs.LG

TL;DR: 本文提出Policy4OOD知识引导的时空世界模型，用于阿片类药物政策评估的三项能力：预测、反事实推理和政策优化。


<details>
  <summary>Details</summary>
Motivation: 阿片类药物危机是美国严重的公共卫生问题，但政策干预评估困难：多种政策在动态系统中相互作用，针对一个风险路径可能无意中放大另一个。需要具备预测当前政策下未来结果、对过去替代决策进行反事实推理以及对候选干预措施进行优化的能力。

Method: 提出Policy4OOD知识引导时空世界模型，联合编码政策知识图谱、州级空间依赖关系和社会经济时间序列到政策条件Transformer中，预测未来阿片类药物结果。训练后的世界模型作为模拟器：预测只需前向传播，反事实分析在历史序列中替换替代政策编码，政策优化在学习的模拟器上使用蒙特卡洛树搜索。构建2019-2024年州级月度数据集，整合阿片类药物死亡率、社会经济指标和结构化政策编码。

Result: 实验表明空间依赖关系和结构化政策知识显著提高预测准确性，验证了每个架构组件和世界建模在数据驱动的公共卫生决策支持中的潜力。

Conclusion: Policy4OOD通过世界建模统一了阿片类药物政策评估的三项关键能力，为数据驱动的公共卫生决策支持提供了有效框架。

Abstract: The opioid epidemic remains one of the most severe public health crises in the United States, yet evaluating policy interventions before implementation is difficult: multiple policies interact within a dynamic system where targeting one risk pathway may inadvertently amplify another. We argue that effective opioid policy evaluation requires three capabilities -- forecasting future outcomes under current policies, counterfactual reasoning about alternative past decisions, and optimization over candidate interventions -- and propose to unify them through world modeling. We introduce Policy4OOD, a knowledge-guided spatio-temporal world model that addresses three core challenges: what policies prescribe, where effects manifest, and when effects unfold.Policy4OOD jointly encodes policy knowledge graphs, state-level spatial dependencies, and socioeconomic time series into a policy-conditioned Transformer that forecasts future opioid outcomes.Once trained, the world model serves as a simulator: forecasting requires only a forward pass, counterfactual analysis substitutes alternative policy encodings in the historical sequence, and policy optimization employs Monte Carlo Tree Search over the learned simulator. To support this framework, we construct a state-level monthly dataset (2019--2024) integrating opioid mortality, socioeconomic indicators, and structured policy encodings. Experiments demonstrate that spatial dependencies and structured policy knowledge significantly improve forecasting accuracy, validating each architectural component and the potential of world modeling for data-driven public health decision support.

</details>


### [112] [Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning](https://arxiv.org/abs/2602.12375)
*Abdul Wahab,Raksha Kumaraswamy,Martha White*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Optimistic value estimates provide one mechanism for directed exploration in reinforcement learning (RL). The agent acts greedily with respect to an estimate of the value plus what can be seen as a value bonus. The value bonus can be learned by estimating a value function on reward bonuses, propagating local uncertainties around rewards. However, this approach only increases the value bonus for an action retroactively, after seeing a higher reward bonus from that state and action. Such an approach does not encourage the agent to visit a state and action for the first time. In this work, we introduce an algorithm for exploration called Value Bonuses with Ensemble errors (VBE), that maintains an ensemble of random action-value functions (RQFs). VBE uses the errors in the estimation of these RQFs to design value bonuses that provide first-visit optimism and deep exploration. The key idea is to design the rewards for these RQFs in such a way that the value bonus can decrease to zero. We show that VBE outperforms Bootstrap DQN and two reward bonus approaches (RND and ACB) on several classic environments used to test exploration and provide demonstrative experiments that it can scale easily to more complex environments like Atari.

</details>


### [113] [Deep Doubly Debiased Longitudinal Effect Estimation with ICE G-Computation](https://arxiv.org/abs/2602.12379)
*Wenxin Chen,Weishen Pan,Kyra Gan,Fei Wang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Estimating longitudinal treatment effects is essential for sequential decision-making but is challenging due to treatment-confounder feedback. While Iterative Conditional Expectation (ICE) G-computation offers a principled approach, its recursive structure suffers from error propagation, corrupting the learned outcome regression models. We propose D3-Net, a framework that mitigates error propagation in ICE training and then applies a robust final correction. First, to interrupt error propagation during learning, we train the ICE sequence using Sequential Doubly Robust (SDR) pseudo-outcomes, which provide bias-corrected targets for each regression. Second, we employ a multi-task Transformer with a covariate simulator head for auxiliary supervision, regularizing representations against corruption by noisy pseudo-outcomes, and a target network to stabilize training dynamics. For the final estimate, we discard the SDR correction and instead use the uncorrected nuisance models to perform Longitudinal Targeted Minimum Loss-Based Estimation (LTMLE) on the original outcomes. This second-stage, targeted debiasing ensures robustness and optimal finite-sample properties. Comprehensive experiments demonstrate that our model, D3-Net, robustly reduces bias and variance across different horizons, counterfactuals, and time-varying confoundings, compared to existing state-of-the-art ICE-based estimators.

</details>


### [114] [Why Deep Jacobian Spectra Separate: Depth-Induced Scaling and Singular-Vector Alignment](https://arxiv.org/abs/2602.12384)
*Nathanaël Haas,Francçois Gatine,Augustin M Cosse,Zied Bouraoui*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Understanding why gradient-based training in deep networks exhibits strong implicit bias remains challenging, in part because tractable singular-value dynamics are typically available only for balanced deep linear models. We propose an alternative route based on two theoretically grounded and empirically testable signatures of deep Jacobians: depth-induced exponential scaling of ordered singular values and strong spectral separation. Adopting a fixed-gates view of piecewise-linear networks, where Jacobians reduce to products of masked linear maps within a single activation region, we prove the existence of Lyapunov exponents governing the top singular values at initialization, give closed-form expressions in a tractable masked model, and quantify finite-depth corrections. We further show that sufficiently strong separation forces singular-vector alignment in matrix products, yielding an approximately shared singular basis for intermediate Jacobians. Together, these results motivate an approximation regime in which singular-value dynamics become effectively decoupled, mirroring classical balanced deep-linear analyses without requiring balancing. Experiments in fixed-gates settings validate the predicted scaling, alignment, and resulting dynamics, supporting a mechanistic account of emergent low-rank Jacobian structure as a driver of implicit bias.

</details>


### [115] [Can Neural Networks Provide Latent Embeddings for Telemetry-Aware Greedy Routing?](https://arxiv.org/abs/2602.12798)
*Andreas Boltres,Niklas Freymuth,Gerhard Neumann*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Telemetry-Aware routing promises to increase efficacy and responsiveness to traffic surges in computer networks. Recent research leverages Machine Learning to deal with the complex dependency between network state and routing, but sacrifices explainability of routing decisions due to the black-box nature of the proposed neural routing modules. We propose \emph{Placer}, a novel algorithm using Message Passing Networks to transform network states into latent node embeddings. These embeddings facilitate quick greedy next-hop routing without directly solving the all-pairs shortest paths problem, and let us visualize how certain network events shape routing decisions.

</details>


### [116] [High-dimensional Level Set Estimation with Trust Regions and Double Acquisition Functions](https://arxiv.org/abs/2602.12391)
*Giang Ngo,Dat Phan Trong,Dang Nguyen,Sunil Gupta*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Level set estimation (LSE) classifies whether an unknown function's value exceeds a specified threshold for given inputs, a fundamental problem in many real-world applications. In active learning settings with limited initial data, we aim to iteratively acquire informative points to construct an accurate classifier for this task. In high-dimensional spaces, this becomes challenging where the search volume grows exponentially with increasing dimensionality. We propose TRLSE, an algorithm for high-dimensional LSE, which identifies and refines regions near the threshold boundary with dual acquisition functions operating at both global and local levels. We provide a theoretical analysis of TRLSE's accuracy and show its superior sample efficiency against existing methods through extensive evaluations on multiple synthetic and real-world LSE problems.

</details>


### [117] [Backdoor Attacks on Contrastive Continual Learning for IoT Systems](https://arxiv.org/abs/2602.13062)
*Alfous Tim,Kuniyilh Simi D*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Internet of Things (IoT) systems increasingly depend on continual learning to adapt to non-stationary environments. These environments can include factors such as sensor drift, changing user behavior, device aging, and adversarial dynamics. Contrastive continual learning (CCL) combines contrastive representation learning with incremental adaptation, enabling robust feature reuse across tasks and domains. However, the geometric nature of contrastive objectives, when paired with replay-based rehearsal and stability-preserving regularization, introduces new security vulnerabilities. Notably, backdoor attacks can exploit embedding alignment and replay reinforcement, enabling the implantation of persistent malicious behaviors that endure through updates and deployment cycles. This paper provides a comprehensive analysis of backdoor attacks on CCL within IoT systems. We formalize the objectives of embedding-level attacks, examine persistence mechanisms unique to IoT deployments, and develop a layered taxonomy tailored to IoT. Additionally, we compare vulnerabilities across various learning paradigms and evaluate defense strategies under IoT constraints, including limited memory, edge computing, and federated aggregation. Our findings indicate that while CCL is effective for enhancing adaptive IoT intelligence, it may also elevate long-lived representation-level threats if not adequately secured.

</details>


### [118] [Synthetic Interaction Data for Scalable Personalization in Large Language Models](https://arxiv.org/abs/2602.12394)
*Yuchen Ma,Yue Huang,Wenjie Wang,Xiaonan Luo,Xiangliang Zhang,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 提出了PersonaGym框架生成个性化交互数据，并开发了PPOpt方法来优化针对用户的提示，在任务性能、个性化质量和稳健性方面优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法主要关注任务层面，忽略用户特定偏好和个人约束，缺乏高质量、隐私敏感的个性化交互数据以及个体偏好的奖励信号。

Method: 1) PersonaGym通过智能LLM系统模拟动态偏好行为，生成高质量合成数据PersonaAtlas；2) PPOpt采用“推理-优化”范式，基于用户画像重写提示，结合监督先验和多目标强化学习训练。

Result: 实验表明该方法在任务性能、个性化质量和对抗噪声/稀疏偏好信号的稳健性方面均优于现有最先进基线。

Conclusion: PersonaGym和PPOpt为个性化提示优化提供了高质量数据生成和模型无关的优化框架，有效解决了已有方法的局限性。

Abstract: Personalized prompting offers large opportunities for deploying large language models (LLMs) to diverse users, yet existing prompt optimization methods primarily focus on task-level optimization while largely overlooking user-specific preferences and latent constraints of individual users. This gap is primarily due to (i) the absence of high-quality, privacy-sensitive data that capture personalized user-LLM interactions at scale, and (ii) the lack of robust reward signals for individual preferences. To overcome existing data limitations, we introduce a high-fidelity synthetic data generation framework called PersonaGym. Unlike prior work that treats personalization as static persona-preference pairs, PersonaGym models a dynamic preference process via an agentic LLM system to simulate realistic preference behaviors and semantic-aware noise in order to generate personalized multi-turn interaction trajectories. Using PersonaGym, we release PersonaAtlas, a large-scale, high-quality, and diverse synthetic dataset of high-fidelity multi-turn personalized interaction trajectories that closely mirror real-world preference expression and noise patterns. We further propose Personalized Prompt Optimization (PPOpt), a scalable and model-agnostic framework that optimizes user prompts based on interaction histories without modifying the deployed LLM. PPOpt adopts a reason-then-optimize paradigm that infers an explicit user profile and conditions prompt rewriting on the user profile to avoid reward hacking. Our training procedure for PPOpt integrates a cold-start supervised prior with outcome-driven multi-objective reinforcement learning. We present extensive experiments to demonstrate consistent improvements over state-of-the-art baselines in terms of task performance, personalization quality, and robustness to noisy as well as to sparse preference signals.

</details>


### [119] [AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning](https://arxiv.org/abs/2602.12402)
*Felicia B. Guo,Ken T. Ho,Andrei Vladimirescu,Borivoje Nikolic*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Analog and mixed-signal (AMS) integrated circuits (ICs) lie at the core of modern computing and communications systems. However, despite the continued rise in design complexity, advances in AMS automation remain limited. This reflects the central challenge in developing a generalized optimization method applicable across diverse circuit design spaces, many of which are distinct, constrained, and non-differentiable. To address this, our work casts circuit design as a graph generation problem and introduces a novel method of AMS synthesis driven by deep reinforcement learning (AstRL). Based on a policy-gradient approach, AstRL generates circuits directly optimized for user-specified targets within a simulator-embedded environment that provides ground-truth feedback during training. Through behavioral-cloning and discriminator-based similarity rewards, our method demonstrates, for the first time, an expert-aligned paradigm for generalized circuit generation validated in simulation. Importantly, the proposed approach operates at the level of individual transistors, enabling highly expressive, fine-grained topology generation. Strong inductive biases encoded in the action space and environment further drive structurally consistent and valid generation. Experimental results for three realistic design tasks illustrate substantial improvements in conventional design metrics over state-of-the-art baselines, with 100% of generated designs being structurally correct and over 90% demonstrating required functionality.

</details>


### [120] [Soft Contamination Means Benchmarks Test Shallow Generalization](https://arxiv.org/abs/2602.12413)
*Ari Spiesberger,Juan J. Vazquez,Nicky Pochinkov,Tomáš Gavenčiak,Peli Grietzer,Gavin Leech,Nandi Schoots*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: If LLM training data is polluted with benchmark test data, then benchmark performance gives biased estimates of out-of-distribution (OOD) generalization. Typical decontamination filters use n-gram matching which fail to detect semantic duplicates: sentences with equivalent (or near-equivalent) content that are not close in string space. We study this soft contamination of training data by semantic duplicates. Among other experiments, we embed the Olmo3 training corpus and find that: 1) contamination remains widespread, e.g. we find semantic duplicates for 78% of CodeForces and exact duplicates for 50% of ZebraLogic problems; 2) including semantic duplicates of benchmark data in training does improve benchmark performance; and 3) when finetuning on duplicates of benchmark datapoints, performance also improves on truly-held-out datapoints from the same benchmark. We argue that recent benchmark gains are thus confounded: the prevalence of soft contamination means gains reflect both genuine capability improvements and the accumulation of test data and effective test data in growing training corpora.

</details>


### [121] [Stabilizing Native Low-Rank LLM Pretraining](https://arxiv.org/abs/2602.12429)
*Paul Janson,Edouard Oyallon,Eugene Belilovsky*

Main category: cs.LG

TL;DR: 本研究提出了Spectron方法，通过动态限制权重更新矩阵的谱范数，实现了从头开始训练完全低秩分解的大型语言模型，并能达到与稠密模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 基础模型参数量快速增长带来了显著的计算和内存挑战，低秩分解为降低训练和推理成本提供了可行路径，但现有方法缺乏从头训练完全低秩权重模型且能匹配稠密模型性能的稳定方案。

Method: 提出Spectron方法：谱范数重正交化，根据当前因子谱范数动态限制权重更新矩阵的谱范数，从而解决原生低秩训练中的不稳定性和损失尖峰问题。

Result: 成功训练了所有非嵌入矩阵都使用低秩分解的全低秩大语言模型，无需先前方法所需的辅助'全秩'指导。建立了原生低秩变换器的计算最优缩放定律，展示了可预测的幂律行为和相对于稠密模型改进的推理效率。

Conclusion: Spectron方法能够稳定地进行端到端低秩因子化训练，仅带来可忽略的开销，为高效训练大型语言模型提供了新途径。

Abstract: Foundation models have achieved remarkable success, yet their growing parameter counts pose significant computational and memory challenges. Low-rank factorization offers a promising route to reduce training and inference costs, but the community lacks a stable recipe for training models from scratch using exclusively low-rank weights while matching the performance of the dense model. We demonstrate that Large Language Models (LLMs) can be trained from scratch using exclusively low-rank factorized weights for all non-embedding matrices without auxiliary "full-rank" guidance required by prior methods. While native low-rank training often suffers from instability and loss spikes, we identify uncontrolled growth in the spectral norm (largest singular value) of the weight matrix update as the dominant factor. To address this, we introduce Spectron: Spectral renormalization with orthogonalization, which dynamically bounds the resultant weight updates based on the current spectral norms of the factors. Our method enables stable, end-to-end factorized training with negligible overhead. Finally, we establish compute-optimal scaling laws for natively low-rank transformers, demonstrating predictable power-law behavior and improved inference efficiency relative to dense models.

</details>


### [122] [Safe Reinforcement Learning via Recovery-based Shielding with Gaussian Process Dynamics Models](https://arxiv.org/abs/2602.12444)
*Alexander W. Goodall,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 论文提出了一个基于恢复的屏蔽框架，用于为未知非线性连续动力系统实现具有可证明安全下限的安全强化学习。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在决策和控制方面很强大，但往往缺乏对安全关键应用的可证明安全保证，特别是在未知和非线性连续系统中。

Method: 该框架将备用策略（屏蔽）与强化学习智能体相结合，利用高斯过程的不确定性量化预测安全约束可能被违反的情况，仅在必要时动态恢复到安全轨迹。屏蔽智能体的经验用于构建GP模型，通过基于内部模型的采样进行策略优化。

Result: 经验证明，该方法在一系列连续控制环境中表现出强大的性能和严格的安全性合规。

Conclusion: 该方法使强化学习智能体能够在保持可证明安全约束的同时进行无限制探索和高效采样学习，实现了安全强化学习在实际应用中的可行性。

Abstract: Reinforcement learning (RL) is a powerful framework for optimal decision-making and control but often lacks provable guarantees for safety-critical applications. In this paper, we introduce a novel recovery-based shielding framework that enables safe RL with a provable safety lower bound for unknown and non-linear continuous dynamical systems. The proposed approach integrates a backup policy (shield) with the RL agent, leveraging Gaussian process (GP) based uncertainty quantification to predict potential violations of safety constraints, dynamically recovering to safe trajectories only when necessary. Experience gathered by the 'shielded' agent is used to construct the GP models, with policy optimization via internal model-based sampling - enabling unrestricted exploration and sample efficient learning, without compromising safety. Empirically our approach demonstrates strong performance and strict safety-compliance on a suite of continuous control environments.

</details>


### [123] [Computationally sufficient statistics for Ising models](https://arxiv.org/abs/2602.12449)
*Abhijith Jayakumar,Shreya Shukla,Marc Vuffray,Andrey Y. Lokhov,Sidhant Misra*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Learning Gibbs distributions using only sufficient statistics has long been recognized as a computationally hard problem. On the other hand, computationally efficient algorithms for learning Gibbs distributions rely on access to full sample configurations generated from the model. For many systems of interest that arise in physical contexts, expecting a full sample to be observed is not practical, and hence it is important to look for computationally efficient methods that solve the learning problem with access to only a limited set of statistics. We examine the trade-offs between the power of computation and observation within this scenario, employing the Ising model as a paradigmatic example. We demonstrate that it is feasible to reconstruct the model parameters for a model with $\ell_1$ width $γ$ by observing statistics up to an order of $O(γ)$. This approach allows us to infer the model's structure and also learn its couplings and magnetic fields. We also discuss a setting where prior information about structure of the model is available and show that the learning problem can be solved efficiently with even more limited observational power.

</details>


### [124] [Regularized Meta-Learning for Improved Generalization](https://arxiv.org/abs/2602.12469)
*Noor Islam S. Mohammad,Md Muntaqim Meherab*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep ensemble methods often improve predictive performance, yet they suffer from three practical limitations: redundancy among base models that inflates computational cost and degrades conditioning, unstable weighting under multicollinearity, and overfitting in meta-learning pipelines. We propose a regularized meta-learning framework that addresses these challenges through a four-stage pipeline combining redundancy-aware projection, statistical meta-feature augmentation, and cross-validated regularized meta-models (Ridge, Lasso, and ElasticNet). Our multi-metric de-duplication strategy removes near-collinear predictors using correlation and MSE thresholds ($τ_{\text{corr}}=0.95$), reducing the effective condition number of the meta-design matrix while preserving predictive diversity. Engineered ensemble statistics and interaction terms recover higher-order structure unavailable to raw prediction columns. A final inverse-RMSE blending stage mitigates regularizer-selection variance. On the Playground Series S6E1 benchmark (100K samples, 72 base models), the proposed framework achieves an out-of-fold RMSE of 8.582, improving over simple averaging (8.894) and conventional Ridge stacking (8.627), while matching greedy hill climbing (8.603) with substantially lower runtime (4 times faster). Conditioning analysis shows a 53.7\% reduction in effective matrix condition number after redundancy projection. Comprehensive ablations demonstrate consistent contributions from de-duplication, statistical meta-features, and meta-ensemble blending. These results position regularized meta-learning as a stable and deployment-efficient stacking strategy for high-dimensional ensemble systems.

</details>


### [125] [Designing RNAs with Language Models](https://arxiv.org/abs/2602.12470)
*Milan Gautam,Ning Dai,Tianshuo Zhou,Bowen Xie,David Mathews,Liang Huang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: RNA design, the task of finding a sequence that folds into a target secondary structure, has broad biological and biomedical impact but remains computationally challenging due to the exponentially large sequence space and exponentially many competing folds. Traditional approaches treat it as an optimization problem, relying on per-instance heuristics or constraint-based search. We instead reframe RNA design as conditional sequence generation and introduce a reusable neural approximator, instantiated as an autoregressive language model (LM), that maps target structures directly to sequences. We first train our model in a supervised setting on random-induced structure-sequence pairs, and then use reinforcement learning (RL) to optimize end-to-end metrics. We also propose methods to select a small subset for RL that greatly improves RL efficiency and quality. Across four datasets, our approach outperforms state-of-the-art systems on key metrics such as Boltzmann probability while being 1.7x faster, establishing conditional LM generation as a scalable, task-agnostic alternative to per-instance optimization for RNA design. Our code and data are available at https://github.com/KuNyaa/RNA-Design-LM.

</details>


### [126] [Tight Bounds for Logistic Regression with Large Stepsize Gradient Descent in Low Dimension](https://arxiv.org/abs/2602.12471)
*Michael Crawshaw,Mingrui Liu*

Main category: cs.LG

TL;DR: GD在二维可分离数据上进行逻辑回归时，通过精细分析振荡动力学，获得了更紧的时间上界，证明了GD在大学习率下能在有限时间内找到低损失解。


<details>
  <summary>Details</summary>
Motivation: 研究梯度下降优化可分离数据的逻辑回归损失问题，探索在大步长下GD非单调行为的动力学特征，特别是从振荡到收敛的过渡时间分析，以获得更精确的理论保证。

Method: 通过二维几何分析，将梯度下降的动力学分解到正交于最大间隔分类器的子空间上，精细分析其振荡动态，推导出从非稳定过渡到稳定的时间上界，并与下界匹配。

Result: 证明了当学习率足够大且迭代次数满足下界时，GD能找到损失小于O(1/(ηT))的解。得到了过渡时间τ的紧致界，与下界相差对数因子，展示了分析是紧致的。

Conclusion: 在二维数据下，通过更精确的振荡动力学分析，为梯度下降训练线性逻辑回归模型提供了更强的收敛保证，特别是在可分离数据和大步长设置下的理论改进。

Abstract: We consider the optimization problem of minimizing the logistic loss with gradient descent to train a linear model for binary classification with separable data. With a budget of $T$ iterations, it was recently shown that an accelerated $1/T^2$ rate is possible by choosing a large step size $η= Θ(γ^2 T)$ (where $γ$ is the dataset's margin) despite the resulting non-monotonicity of the loss. In this paper, we provide a tighter analysis of gradient descent for this problem when the data is two-dimensional: we show that GD with a sufficiently large learning rate $η$ finds a point with loss smaller than $\mathcal{O}(1/(ηT))$, as long as $T \geq Ω(n/γ+ 1/γ^2)$, where $n$ is the dataset size. Our improved rate comes from a tighter bound on the time $τ$ that it takes for GD to transition from unstable (non-monotonic loss) to stable (monotonic loss), via a fine-grained analysis of the oscillatory dynamics of GD in the subspace orthogonal to the max-margin classifier. We also provide a lower bound of $τ$ matching our upper bound up to logarithmic factors, showing that our analysis is tight.

</details>


### [127] [Geometric separation and constructive universal approximation with two hidden layers](https://arxiv.org/abs/2602.12482)
*Chanyoung Sung*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We give a geometric construction of neural networks that separate disjoint compact subsets of $\Bbb R^n$, and use it to obtain a constructive universal approximation theorem. Specifically, we show that networks with two hidden layers and either a sigmoidal activation (i.e., strictly monotone bounded continuous) or the ReLU activation can approximate any real-valued continuous function on an arbitrary compact set $K\subset\Bbb R^n$ to any prescribed accuracy in the uniform norm. For finite $K$, the construction simplifies and yields a sharp depth-2 (single hidden layer) approximation result.

</details>


### [128] [On Robustness and Chain-of-Thought Consistency of RL-Finetuned VLMs](https://arxiv.org/abs/2602.12506)
*Rosie Zhao,Anshul Shah,Xiaoyu Zhu,Xinke Deng,Zhongyu Jiang,Yang Yang,Joerg Liebelt,Arnab Mondal*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reinforcement learning (RL) fine-tuning has become a key technique for enhancing large language models (LLMs) on reasoning-intensive tasks, motivating its extension to vision language models (VLMs). While RL-tuned VLMs improve on visual reasoning benchmarks, they remain vulnerable to weak visual grounding, hallucinations, and over-reliance on textual cues. We show that simple, controlled textual perturbations--misleading captions or incorrect chain-of-thought (CoT) traces--cause substantial drops in robustness and confidence, and that these effects are more pronounced when CoT consistency is taken into account across open-source multimodal reasoning models. Entropy-based metrics further show that these perturbations reshape model uncertainty and probability mass on the correct option, exposing model-specific trends in miscalibration. To better understand these vulnerabilities, we further analyze RL fine-tuning dynamics and uncover an accuracy-faithfulness trade-off: fine-tuning raises benchmark accuracy, but can simultaneously erode the reliability of the accompanying CoT and its robustness to contextual shifts. Although adversarial augmentation improves robustness, it does not by itself prevent faithfulness drift. Incorporating a faithfulness-aware reward can restore alignment between answers and reasoning, but when paired with augmentation, training risks collapsing onto shortcut strategies and robustness remains elusive. Together, these findings highlight the limitations of accuracy-only evaluations and motivate training and assessment protocols that jointly emphasize correctness, robustness, and the faithfulness of visually grounded reasoning.

</details>


### [129] [Bench-MFG: A Benchmark Suite for Learning in Stationary Mean Field Games](https://arxiv.org/abs/2602.12517)
*Lorenzo Magnino,Jiacheng Shen,Matthieu Geist,Olivier Pietquin,Mathieu Laurière*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The intersection of Mean Field Games (MFGs) and Reinforcement Learning (RL) has fostered a growing family of algorithms designed to solve large-scale multi-agent systems. However, the field currently lacks a standardized evaluation protocol, forcing researchers to rely on bespoke, isolated, and often simplistic environments. This fragmentation makes it difficult to assess the robustness, generalization, and failure modes of emerging methods. To address this gap, we propose a comprehensive benchmark suite for MFGs (Bench-MFG), focusing on the discrete-time, discrete-space, stationary setting for the sake of clarity. We introduce a taxonomy of problem classes, ranging from no-interaction and monotone games to potential and dynamics-coupled games, and provide prototypical environments for each. Furthermore, we propose MF-Garnets, a method for generating random MFG instances to facilitate rigorous statistical testing. We benchmark a variety of learning algorithms across these environments, including a novel black-box approach (MF-PSO) for exploitability minimization. Based on our extensive empirical results, we propose guidelines to standardize future experimental comparisons. Code available at \href{https://github.com/lorenzomagnino/Bench-MFG}{https://github.com/lorenzomagnino/Bench-MFG}.

</details>


### [130] [Multi-Agent Model-Based Reinforcement Learning with Joint State-Action Learned Embeddings](https://arxiv.org/abs/2602.12520)
*Zhizun Wang,David Meger*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Learning to coordinate many agents in partially observable and highly dynamic environments requires both informative representations and data-efficient training. To address this challenge, we present a novel model-based multi-agent reinforcement learning framework that unifies joint state-action representation learning with imaginative roll-outs. We design a world model trained with variational auto-encoders and augment the model using the state-action learned embedding (SALE). SALE is injected into both the imagination module that forecasts plausible future roll-outs and the joint agent network whose individual action values are combined through a mixing network to estimate the joint action-value function. By coupling imagined trajectories with SALE-based action values, the agents acquire a richer understanding of how their choices influence collective outcomes, leading to improved long-term planning and optimization under limited real-environment interactions. Empirical studies on well-established multi-agent benchmarks, including StarCraft II Micro-Management, Multi-Agent MuJoCo, and Level-Based Foraging challenges, demonstrate consistent gains of our method over baseline algorithms and highlight the effectiveness of joint state-action learned embeddings within a multi-agent model-based paradigm.

</details>


### [131] [Constraint-Rectified Training for Efficient Chain-of-Thought](https://arxiv.org/abs/2602.12526)
*Qinhang Wu,Sen Lin,Ming Zhang,Yingbin Liang,Ness B. Shroff*

Main category: cs.LG

TL;DR: 作者提出了CRT（约束修正训练）框架，通过基于参考的约束优化来修剪推理长度，实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 为了解决长推理链带来的高推理成本和冗余步骤问题，同时避免现有方法中启发式设计的准确率下降和对超参数敏感的问题。

Method: CRT采用参考引导的约束优化框架，交替最小化推理长度并在性能低于参考时修正准确率。进一步采用两阶段训练方案：先发现最短可靠推理模式，然后在学习到的长度预算下优化准确率。

Result: 评估表明该框架能显著减少token使用同时保持答案质量。分析显示CRT不仅缩短响应长度，还减少了内部语言冗余，并自然产生了一系列保持正确性的中间检查点。

Conclusion: CRT提供了一个稳定且可解释的高效推理训练框架，能够在控制推理冗余的同时保持模型性能。

Abstract: Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), especially when combined with reinforcement learning (RL) based post-training methods. While longer reasoning traces can improve answer quality and unlock abilities such as self-correction, they also incur high inference costs and often introduce redundant steps, known as overthinking. Recent research seeks to develop efficient reasoning strategies that balance reasoning length and accuracy, either through length-aware reward design or prompt-based calibration. However, these heuristic-based approaches may suffer from severe accuracy drop and be very sensitive to hyperparameters. To address these problems, we introduce CRT (Constraint-Rectified Training), a principled post-training framework based on reference-guarded constrained optimization, yielding a more stable and interpretable formulation for efficient reasoning. CRT alternates between minimizing reasoning length and rectifying accuracy only when performance falls below the reference, enabling stable and effective pruning of redundant reasoning. We further extend CRT with a two-stage training scheme that first discovers the shortest reliable reasoning patterns and then refines accuracy under a learnt length budget, preventing the re-emergence of verbose CoT. Our comprehensive evaluation shows that this framework consistently reduces token usage while maintaining answer quality at a robust and reliable level. Further analysis reveals that CRT improves reasoning efficiency not only by shortening responses but also by reducing internal language redundancy, leading to a new evaluation metric. Moreover, CRT-based training naturally yields a sequence of intermediate checkpoints that span a spectrum of explanation lengths while preserving correctness, enabling fine-grained control over reasoning verbosity without retraining.

</details>


### [132] [Analytical Results for Two Exponential Family Distributions in Hierarchical Dirichlet Processes](https://arxiv.org/abs/2602.12527)
*Naiqi Li*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Hierarchical Dirichlet Process (HDP) provides a flexible Bayesian nonparametric framework for modeling grouped data with a shared yet unbounded collection of mixture components. While existing applications of the HDP predominantly focus on the Dirichlet-multinomial conjugate structure, the framework itself is considerably more general and, in principle, accommodates a broad class of conjugate prior-likelihood pairs. In particular, exponential family distributions offer a unified and analytically tractable modeling paradigm that encompasses many commonly used distributions. In this paper, we investigate analytic results for two important members of the exponential family within the HDP framework: the Poisson distribution and the normal distribution. We derive explicit closed-form expressions for the corresponding Gamma-Poisson and Normal-Gamma-Normal conjugate pairs under the hierarchical Dirichlet process construction. Detailed derivations and proofs are provided to clarify the underlying mathematical structure and to demonstrate how conjugacy can be systematically exploited in hierarchical nonparametric models. Our work extends the applicability of the HDP beyond the Dirichlet-multinomial setting and furnishes practical analytic results for researchers employing hierarchical Bayesian nonparametrics.

</details>


### [133] [Flow-Factory: A Unified Framework for Reinforcement Learning in Flow-Matching Models](https://arxiv.org/abs/2602.12529)
*Bowen Ping,Chengyou Jia,Minnan Luo,Hangwei Qian,Ivor Tsang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reinforcement learning has emerged as a promising paradigm for aligning diffusion and flow-matching models with human preferences, yet practitioners face fragmented codebases, model-specific implementations, and engineering complexity. We introduce Flow-Factory, a unified framework that decouples algorithms, models, and rewards through through a modular, registry-based architecture. This design enables seamless integration of new algorithms and architectures, as demonstrated by our support for GRPO, DiffusionNFT, and AWM across Flux, Qwen-Image, and WAN video models. By minimizing implementation overhead, Flow-Factory empowers researchers to rapidly prototype and scale future innovations with ease. Flow-Factory provides production-ready memory optimization, flexible multi-reward training, and seamless distributed training support. The codebase is available at https://github.com/X-GenGroup/Flow-Factory.

</details>


### [134] [AMPS: Adaptive Modality Preference Steering via Functional Entropy](https://arxiv.org/abs/2602.12533)
*Zihan Huang,Xintong Li,Rohan Surana,Tong Yu,Rui Wang,Julian McAuley,Jingbo Shang,Junda Wu*

Main category: cs.LG

TL;DR: 本文提出了实例感知的模态偏好调整方法，通过量化每个模态的信息贡献并推断样本特定的调整敏感性，实现更精细的模态偏好控制。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在显著的模态偏好问题，传统方法采用统一的调整强度会导致调整不足或影响标准推理效果，且不同多模态实例对调整的敏感性差异很大，单一全局强度难以校准。

Method: 提出了实例感知的诊断指标来量化每个模态的信息贡献，揭示样本特定的调整敏感性；在此基础上提出降低敏感样本调整强度的缩放策略，并通过可学习模块推断缩放模式，实现实例感知的模态偏好控制。

Result: 实验结果表明，实例感知调整在调节模态偏好方面优于传统方法，能有效调整偏好同时保持较低的生成错误率。

Conclusion: 实例感知的调整方法能够更精细地控制多模态大语言模型的模态偏好，在保持推理质量的同时实现有效调整，解决了传统方法调整强度难以校准的问题。

Abstract: Multimodal Large Language Models (MLLMs) often exhibit significant modality preference, which is a tendency to favor one modality over another. Depending on the input, they may over-rely on linguistic priors relative to visual evidence, or conversely over-attend to visually salient but facts in textual contexts. Prior work has applied a uniform steering intensity to adjust the modality preference of MLLMs. However, strong steering can impair standard inference and increase error rates, whereas weak steering is often ineffective. In addition, because steering sensitivity varies substantially across multimodal instances, a single global strength is difficult to calibrate. To address this limitation with minimal disruption to inference, we introduce an instance-aware diagnostic metric that quantifies each modality's information contribution and reveals sample-specific susceptibility to steering. Building on these insights, we propose a scaling strategy that reduces steering for sensitive samples and a learnable module that infers scaling patterns, enabling instance-aware control of modality preference. Experimental results show that our instance-aware steering outperforms conventional steering in modulating modality preference, achieving effective adjustment while keeping generation error rates low.

</details>


### [135] [Exploring Accurate and Transparent Domain Adaptation in Predictive Healthcare via Concept-Grounded Orthogonal Inference](https://arxiv.org/abs/2602.12542)
*Pengfei Hu,Chang Lu,Feifan Liu,Yue Ning*

Main category: cs.LG

TL;DR: 提出ExtraCare方法，将患者表征分解为不变和协变分量，通过监督和正交化训练提升跨领域临床事件预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 临床事件预测中，电子健康记录（EHR）模型在不同数据分布下性能下降，而现有的领域适应方法缺乏透明度，难以在临床实践中获得信任。

Method: 分解患者表示为不变分量和协变分量，通过监督学习和正交约束进行训练，并将稀疏潜在维度映射到医学概念以提供可解释性。

Result: 在多个领域划分设置的现实EHR数据集上验证，ExtraCare在预测准确性上优于多数特征对齐模型，并通过案例研究展示了其透明解释能力。

Conclusion: ExtraCare不仅能有效适应不同数据分布，还能提供人类可理解的解释，增强了临床事件预测模型的透明度和可信度。

Abstract: Deep learning models for clinical event prediction on electronic health records (EHR) often suffer performance degradation when deployed under different data distributions. While domain adaptation (DA) methods can mitigate such shifts, its "black-box" nature prevents widespread adoption in clinical practice where transparency is essential for trust and safety. We propose ExtraCare to decompose patient representations into invariant and covariant components. By supervising these two components and enforcing their orthogonality during training, our model preserves label information while exposing domain-specific variation at the same time for more accurate predictions than most feature alignment models. More importantly, it offers human-understandable explanations by mapping sparse latent dimensions to medical concepts and quantifying their contributions via targeted ablations. ExtraCare is evaluated on two real-world EHR datasets across multiple domain partition settings, demonstrating superior performance along with enhanced transparency, as evidenced by its accurate predictions and explanations from extensive case studies.

</details>


### [136] [SD-MoE: Spectral Decomposition for Effective Expert Specialization](https://arxiv.org/abs/2602.12556)
*Ruijun Huang,Fang Dong,Xin Zhang,Hengjie Cao,Zhendong Huang,Anrui Chen,Jixian Zhou,Mengyi Chen,Yifeng Yang,Mingzhi Dong,Yujiang Wang,Jinlong Hou,Qin Lv,Robert P. Dick,Yuan Cheng,Fan Yang,Tun Lu,Chun Zhang,Li Shang*

Main category: cs.LG

TL;DR: 该研究从谱分析角度揭示MoE架构中专家参数和梯度存在高度重叠的谱模式，提出了谱解耦方法来改进专家专业化


<details>
  <summary>Details</summary>
Motivation: 现有MoE架构在实际应用中存在专家专业化不足的问题，部分专家功能相似，部分充当共享专家，限制了模型的有效容量和性能

Method: 提出谱解耦MoE（SD-MoE），在谱空间中对参数和梯度进行分解，最小化额外计算量，可无缝集成到现有MoE架构

Result: SD-MoE在下游任务上提升了性能，实现了有效的专家专业化，可应用于Qwen和DeepSeek等架构

Conclusion: 从谱分析角度理解并解决MoE专家专业化不足问题是一个有效途径，谱解耦方法为改进MoE架构提供了新视角

Abstract: Mixture-of-Experts (MoE) architectures scale Large Language Models via expert specialization induced by conditional computation. In practice, however, expert specialization often fails: some experts become functionally similar, while others functioning as de facto shared experts, limiting the effective capacity and model performance. In this work, we analysis from a spectral perspective on parameter and gradient spaces, uncover that (1) experts share highly overlapping dominant spectral components in their parameters, (2) dominant gradient subspaces are strongly aligned across experts, driven by ubiquitous low-rank structure in human corpus, and (3) gating mechanisms preferentially route inputs along these dominant directions, further limiting specialization. To address this, we propose Spectral-Decoupled MoE (SD-MoE), which decomposes both parameter and gradient in the spectral space. SD-MoE improves performance across downstream tasks, enables effective expert specialization, incurring minimal additional computation, and can be seamlessly integrated into a wide range of existing MoE architectures, including Qwen and DeepSeek.

</details>


### [137] [Fractional Order Federated Learning for Battery Electric Vehicle Energy Consumption Modeling](https://arxiv.org/abs/2602.12567)
*Mohammad Partohaghighi,Roummel Marcia,Bruce J. West,YangQuan Chen*

Main category: cs.LG

TL;DR: FO-RI-FedAvg是一种针对电动汽车联邦学习的改进方法，通过客户端自适应粗糙度正则化和非整数阶优化来提升训练稳定性


<details>
  <summary>Details</summary>
Motivation: 电动汽车联邦学习面临间歇性连接、客户端参与变化以及工况差异导致的严重不稳定问题，传统FedAvg等方法在现实约束下存在过度的参数漂移和收敛退化

Method: 提出FO-RI-FedAvg方法，包含两个客户端机制：(1)基于本地损失函数粗糙度的自适应正则化，(2)利用短期记忆平滑更新方向的非整数阶本地优化，同时保持标准服务器聚合

Result: 在VED和eVED两个真实世界电动汽车能量预测数据集上的实验表明，FO-RI-FedAvg相比强基线方法实现了更高的准确性和更稳定的收敛，尤其在客户端参与度降低时表现更优

Conclusion: FO-RI-FedAvg作为FedAvg的轻量级模块化扩展，通过互补的客户端机制有效提升了电动汽车联邦学习在现实约束下的稳定性

Abstract: Federated learning on connected electric vehicles (BEVs) faces severe instability due to intermittent connectivity, time-varying client participation, and pronounced client-to-client variation induced by diverse operating conditions. Conventional FedAvg and many advanced methods can suffer from excessive drift and degraded convergence under these realistic constraints. This work introduces Fractional-Order Roughness-Informed Federated Averaging (FO-RI-FedAvg), a lightweight and modular extension of FedAvg that improves stability through two complementary client-side mechanisms: (i) adaptive roughness-informed proximal regularization, which dynamically tunes the pull toward the global model based on local loss-landscape roughness, and (ii) non-integer-order local optimization, which incorporates short-term memory to smooth conflicting update directions. The approach preserves standard FedAvg server aggregation, adds only element-wise operations with amortizable overhead, and allows independent toggling of each component. Experiments on two real-world BEV energy prediction datasets, VED and its extended version eVED, show that FO-RI-FedAvg achieves improved accuracy and more stable convergence compared to strong federated baselines, particularly under reduced client participation.

</details>


### [138] [VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via Confidence-Guided Variance Reduction](https://arxiv.org/abs/2602.12579)
*Xin-Qiang Cai,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 本文提出了一种不依赖外部验证器的课程强化学习框架VI-CuRL，通过利用模型的内在置信度构建课程，降低方差，提高训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的可验证奖励强化学习依赖外部验证器，限制了可扩展性。最近研究发现其主要通过激发潜在能力起作用，这推动了无验证器方法的发展。然而，现有方法面临破坏性梯度方差导致的训练崩溃问题。

Method: 通过利用语言模型的内在置信度构建课程，优先处理高置信度样本，管理偏差-方差权衡，特别关注减少动作和问题方差。提出了理论保证证明了估计器的渐近无偏性。

Result: 在六个带有/不带验证器的挑战性基准测试中，VI-CuRL表现稳定且持续优于无验证器基线方法。

Conclusion: VI-CuRL为无验证器强化学习中的方差管理提供了有效解决方案，证明了利用内在置信度构建课程的有效性。该方法避免了对外部验证器的依赖，提高了模型训练的可扩展性和稳定性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a dominant paradigm for enhancing Large Language Models (LLMs) reasoning, yet its reliance on external verifiers limits its scalability. Recent findings suggest that RLVR primarily functions by eliciting latent capabilities, motivating the development of verifier-free algorithms. However, in such settings, standard methods like Group Relative Policy Optimization face a critical challenge: destructive gradient variance that often leads to training collapse. To address this issue, we introduceVerifier-Independent Curriculum Reinforcement Learning (VI-CuRL), a framework that leverages the model's intrinsic confidence to construct a curriculum independent from external verifiers. By prioritizing high-confidence samples, VI-CuRL effectively manages the bias-variance trade-off, specifically targeting the reduction of action and problem variance. We provide a rigorous theoretical analysis, proving that our estimator guarantees asymptotic unbiasedness. Empirically, VI-CuRL promotes stability and consistently outperforms verifier-independent baselines across six challenging benchmarks with/without verifiers.

</details>


### [139] [Multi-Head Attention as a Source of Catastrophic Forgetting in MoE Transformers](https://arxiv.org/abs/2602.12587)
*Anrui Chen,Ruijun Huang,Xin Zhang,Fang Dong,Hengjie Cao,Zhendong Huang,Yifeng Yang,Mengyi Chen,Jixian Zhou,Mingzhi Dong,Yujiang Wang,Jinlong Hou,Qin Lv,Robert P. Dick,Yuan Cheng,Tun Lu,Fan Yang,Li Shang*

Main category: cs.LG

TL;DR: 多头注意力中的预路由瓶颈导致MoE Transformers在持续学习中仍会遗忘，提出MH-MoE通过头级别路由减少组合碰撞以缓解遗忘


<details>
  <summary>Details</summary>
Motivation: 现有的Mixture-of-Experts架构在持续学习中仍存在明显的遗忘问题，尽管稀疏路由理论上应该减少干扰。研究发现问题源于多头注意力中的预路由瓶颈：注意力头输出被拼接成单一的路由输入，导致路由只能基于特征组合而非可分离的头通道进行，这引发了路由碰撞问题。

Method: 提出MH-MoE方法，通过对子表示进行头级别路由来增加路由粒度。具体来说，不再将多头注意力的输出拼接成一个表示输入给路由器，而是让每个注意头的输出单独进行路由决策，从而更细致地区分不同的语义和结构特征组合。

Result: 在TRACE基准测试中，使用Qwen3-0.6B/8B模型，MH-MoE显著缓解了遗忘问题。对于Qwen3-0.6B模型，将BWT（反向迁移）从LoRAMoE的11.2%降低到4.5%。同时提出的有效组合数$N_{eff}$指标可以量化路由碰撞效应，更高的$N_{eff}$与持续学习后旧任务损失增加相关。

Conclusion: MoE Transformers在持续学习中的遗忘问题主要源于多头注意力的预路由瓶颈和路由碰撞效应。通过头级别路由的MH-MoE方法能够有效增加路由粒度，减少组合碰撞，从而显著缓解遗忘问题。这表明提升路由粒度对于MoE架构在持续学习中的应用至关重要。

Abstract: Mixture-of-Experts (MoE) architectures are often considered a natural fit for continual learning because sparse routing should localize updates and reduce interference, yet MoE Transformers still forget substantially even with sparse, well-balanced expert utilization. We attribute this gap to a pre-routing bottleneck: multi-head attention concatenates head-specific signals into a single post-attention router input, forcing routing to act on co-occurring feature compositions rather than separable head channels. We show that this router input simultaneously encodes multiple separately decodable semantic and structural factors with uneven head support, and that different feature compositions induce weakly aligned parameter-gradient directions; as a result, routing maps many distinct compositions to the same route. We quantify this collision effect via a route-wise effective composition number $N_{eff}$ and find that higher $N_{eff}$ is associated with larger old-task loss increases after continual training. Motivated by these findings, we propose MH-MoE, which performs head-wise routing over sub-representations to increase routing granularity and reduce composition collisions. On TRACE with Qwen3-0.6B/8B, MH-MoE effectively mitigates forgetting, reducing BWT on Qwen3-0.6B from 11.2% (LoRAMoE) to 4.5%.

</details>


### [140] [Vehicle behaviour estimation for abnormal event detection using distributed fiber optic sensing](https://arxiv.org/abs/2602.12591)
*Hemant Prasad,Daisuke Ikefuji,Shin Tominaga,Hitoshi Sakurai,Manabu Otani*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The distributed fiber-optic sensing (DFOS) system is a cost-effective wide-area traffic monitoring technology that utilizes existing fiber infrastructure to effectively detect traffic congestions. However, detecting single-lane abnormalities, that lead to congestions, is still a challenge. These single-lane abnormalities can be detected by monitoring lane change behaviour of vehicles, performed to avoid congestion along the monitoring section of a road. This paper presents a method to detect single-lane abnormalities by tracking individual vehicle paths and detecting vehicle lane changes along a section of a road. We propose a method to estimate the vehicle position at all time instances and fit a path using clustering techniques. We detect vehicle lane change by monitoring any change in spectral centroid of vehicle vibrations by tracking a reference vehicle along a highway. The evaluation of our proposed method with real traffic data showed 80% accuracy for lane change detection events that represent presence of abnormalities.

</details>


### [141] [HyperMLP: An Integrated Perspective for Sequence Modeling](https://arxiv.org/abs/2602.12601)
*Jiecheng Lu,Shihao Yang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Self-attention is often viewed as probabilistic query-key lookup, motivating designs that preserve normalized attention scores and fixed positional semantics. We advocate a simpler and more unified perspective: an autoregressive attention head can be viewed as a dynamic two-layer MLP whose weights are instantiated from the context history. From this view, attention scores form an ever-growing hidden representation, and standard MLP activations such as ReLU or GLU naturally implement input-conditioned selection over a context-dependent memory pool rather than a probability distribution. Based on this formulation, we introduce HyperMLP and HyperGLU, which learn dynamic mixing in both feature space and sequence space, using a reverse-offset (lag) layout to align temporal mixing with autoregressive semantics. We provide theoretical characterizations of the expressivity and implications of this structure, and empirically show that HyperMLP/HyperGLU consistently outperform strong softmax-attention baselines under matched parameter budgets.

</details>


### [142] [RelBench v2: A Large-Scale Benchmark and Repository for Relational Data](https://arxiv.org/abs/2602.12606)
*Justin Gu,Rishabh Ranjan,Charilaos Kanatsoulis,Haiming Tang,Martin Jurkovic,Valter Hudovernik,Mark Znidar,Pranshu Chaturvedi,Parth Shroff,Fengyu Li,Jure Leskovec*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Relational deep learning (RDL) has emerged as a powerful paradigm for learning directly on relational databases by modeling entities and their relationships across multiple interconnected tables. As this paradigm evolves toward larger models and relational foundation models, scalable and realistic benchmarks are essential for enabling systematic evaluation and progress. In this paper, we introduce RelBench v2, a major expansion of the RelBench benchmark for RDL. RelBench v2 adds four large-scale relational datasets spanning scholarly publications, enterprise resource planning, consumer platforms, and clinical records, increasing the benchmark to 11 datasets comprising over 22 million rows across 29 tables. We further introduce autocomplete tasks, a new class of predictive objectives that require models to infer missing attribute values directly within relational tables while respecting temporal constraints, expanding beyond traditional forecasting tasks constructed via SQL queries. In addition, RelBench v2 expands beyond its native datasets by integrating external benchmarks and evaluation frameworks: we translate event streams from the Temporal Graph Benchmark into relational schemas for unified relational-temporal evaluation, interface with ReDeLEx to provide uniform access to 70+ real-world databases suitable for pretraining, and incorporate 4DBInfer datasets and tasks to broaden multi-table prediction coverage. Experimental results demonstrate that RDL models consistently outperform single-table baselines across autocomplete, forecasting, and recommendation tasks, highlighting the importance of modeling relational structure explicitly.

</details>


### [143] [Coden: Efficient Temporal Graph Neural Networks for Continuous Prediction](https://arxiv.org/abs/2602.12613)
*Zulun Zhu,Siqiang Luo*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Temporal Graph Neural Networks (TGNNs) are pivotal in processing dynamic graphs. However, existing TGNNs primarily target one-time predictions for a given temporal span, whereas many practical applications require continuous predictions, that predictions are issued frequently over time. Directly adapting existing TGNNs to continuous-prediction scenarios introduces either significant computational overhead or prediction quality issues especially for large graphs. This paper revisits the challenge of { continuous predictions} in TGNNs, and introduces {\sc Coden}, a TGNN model designed for efficient and effective learning on dynamic graphs. {\sc Coden} innovatively overcomes the key complexity bottleneck in existing TGNNs while preserving comparable predictive accuracy. Moreover, we further provide theoretical analyses that substantiate the effectiveness and efficiency of {\sc Coden}, and clarify its duality relationship with both RNN-based and attention-based models. Our evaluations across five dynamic datasets show that {\sc Coden} surpasses existing performance benchmarks in both efficiency and effectiveness, establishing it as a superior solution for continuous prediction in evolving graph environments.

</details>


### [144] [Formalizing the Sampling Design Space of Diffusion-Based Generative Models via Adaptive Solvers and Wasserstein-Bounded Timesteps](https://arxiv.org/abs/2602.12624)
*Sangwoo Jo,Sungjoon Choi*

Main category: cs.LG

TL;DR: SDM 是一个基于几何视角的扩散生成模型采样框架，通过分析ODE动态特性，在早期高噪声阶段使用低阶求解器，后期高非线性阶段使用高阶求解器，并引入Wasserstein边界优化来自适应调整时间步长，在保证采样质量的同时显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 扩散生成模型在实际部署中常受限于高采样成本；现有研究主要关注训练目标或单个求解器，而采样过程的整体设计（求解器选择与调度）仍依赖静态启发式方法，需要更系统性的优化。

Method: 通过几何视角分析扩散轨迹的ODE动态特性，提出自适应求解器选择策略：早期高噪声阶段使用低阶求解器，后期复杂度增加时逐步使用高阶求解器。引入Wasserstein边界优化框架，系统推导自适应时间步长，显式限制局部离散化误差。无需额外训练或架构修改。

Result: 在标准基准测试中达到最先进性能：CIFAR-10的FID为1.93，FFHQ为2.41，AFHQv2为1.98，相比现有采样器减少了函数评估次数。

Conclusion: SDM框架通过将数值求解器与扩散轨迹的内在几何特性对齐，实现了高效且高质量的采样，为扩散生成模型的实用部署提供了有效的理论指导和实用解决方案。

Abstract: Diffusion-based generative models have achieved remarkable performance across various domains, yet their practical deployment is often limited by high sampling costs. While prior work focuses on training objectives or individual solvers, the holistic design of sampling, specifically solver selection and scheduling, remains dominated by static heuristics. In this work, we revisit this challenge through a geometric lens, proposing SDM, a principled framework that aligns the numerical solver with the intrinsic properties of the diffusion trajectory. By analyzing the ODE dynamics, we show that efficient low-order solvers suffice in early high-noise stages while higher-order solvers can be progressively deployed to handle the increasing non-linearity of later stages. Furthermore, we formalize the scheduling by introducing a Wasserstein-bounded optimization framework. This method systematically derives adaptive timesteps that explicitly bound the local discretization error, ensuring the sampling process remains faithful to the underlying continuous dynamics. Without requiring additional training or architectural modifications, SDM achieves state-of-the-art performance across standard benchmarks, including an FID of 1.93 on CIFAR-10, 2.41 on FFHQ, and 1.98 on AFHQv2, with a reduced number of function evaluations compared to existing samplers. Our code is available at https://github.com/aiimaginglab/sdm.

</details>


### [145] [Dual-Granularity Contrastive Reward via Generated Episodic Guidance for Efficient Embodied RL](https://arxiv.org/abs/2602.12636)
*Xin Liu,Yixuan Li,Yuhui Chen,Yuxing Qin,Haoran Li,Dongbin Zhao*

Main category: cs.LG

TL;DR: DEG框架通过生成式情景指导和双粒度对比奖励，无需人工标注或大量专家监督，为强化学习提供样本高效的密集奖励


<details>
  <summary>Details</summary>
Motivation: 现有密集奖励方法严重依赖高质量人工标注数据或大量专家监督，而轨迹成功率奖励虽然适合人工评估但稀疏性严重限制了RL样本效率。需要一种无需人工标注或大规模监督的密集奖励方案

Method: 提出DEG框架：1）仅需少量专家视频进行领域适应，利用大视频生成模型先验知识为每个RL情景生成专门的任务指导；2）设计平衡粗粒度探索和细粒度匹配的双粒度对比奖励，在对比自监督潜在空间引导智能体逐步逼近生成的指导视频

Result: 在仿真与真实世界的18个多样化任务上的广泛实验表明：1）DEG可作为高效探索刺激帮助智能体快速发现稀疏成功率奖励；2）能够独立引导有效的强化学习和稳定的策略收敛

Conclusion: DEG通过结合视频生成模型的先验知识和双粒度对比奖励机制，成功实现了无需人工标注或大量专家监督的样本高效密集奖励方案，显著提升了强化学习在具身操作任务中的性能

Abstract: Designing suitable rewards poses a significant challenge in reinforcement learning (RL), especially for embodied manipulation. Trajectory success rewards are suitable for human judges or model fitting, but the sparsity severely limits RL sample efficiency. While recent methods have effectively improved RL via dense rewards, they rely heavily on high-quality human-annotated data or abundant expert supervision. To tackle these issues, this paper proposes Dual-granularity contrastive reward via generated Episodic Guidance (DEG), a novel framework to seek sample-efficient dense rewards without requiring human annotations or extensive supervision. Leveraging the prior knowledge of large video generation models, DEG only needs a small number of expert videos for domain adaptation to generate dedicated task guidance for each RL episode. Then, the proposed dual-granularity reward that balances coarse-grained exploration and fine-grained matching, will guide the agent to efficiently approximate the generated guidance video sequentially in the contrastive self-supervised latent space, and finally complete the target task. Extensive experiments on 18 diverse tasks across both simulation and real-world settings show that DEG can not only serve as an efficient exploration stimulus to help the agent quickly discover sparse success rewards, but also guide effective RL and stable policy convergence independently.

</details>


### [146] [Uncovering spatial tissue domains and cell types in spatial omics through cross-scale profiling of cellular and genomic interactions](https://arxiv.org/abs/2602.12651)
*Rui Yan,Xiaohan Xing,Xun Wang,Zixia Zhou,Md Tauhidul Islam,Lei Xing*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Cellular identity and function are linked to both their intrinsic genomic makeup and extrinsic spatial context within the tissue microenvironment. Spatial transcriptomics (ST) offers an unprecedented opportunity to study this, providing in situ gene expression profiles at single-cell resolution and illuminating the spatial and functional organization of cells within tissues. However, a significant hurdle remains: ST data is inherently noisy, large, and structurally complex. This complexity makes it intractable for existing computational methods to effectively capture the interplay between spatial interactions and intrinsic genomic relationships, thus limiting our ability to discern critical biological patterns. Here, we present CellScape, a deep learning framework designed to overcome these limitations for high-performance ST data analysis and pattern discovery. CellScape jointly models cellular interactions in tissue space and genomic relationships among cells, producing comprehensive representations that seamlessly integrate spatial signals with underlying gene regulatory mechanisms. This technique uncovers biologically informative patterns that improve spatial domain segmentation and supports comprehensive spatial cellular analyses across diverse transcriptomics datasets, offering an accurate and versatile framework for deep analysis and interpretation of ST data.w

</details>


### [147] [SLA2: Sparse-Linear Attention with Learnable Routing and QAT](https://arxiv.org/abs/2602.12675)
*Jintao Zhang,Haoxu Wang,Kai Jiang,Kaiwen Zheng,Youhe Jiang,Ion Stoica,Jianfei Chen,Jun Zhu,Joseph E. Gonzalez*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Sparse-Linear Attention (SLA) combines sparse and linear attention to accelerate diffusion models and has shown strong performance in video generation. However, (i) SLA relies on a heuristic split that assigns computations to the sparse or linear branch based on attention-weight magnitude, which can be suboptimal. Additionally, (ii) after formally analyzing the attention error in SLA, we identify a mismatch between SLA and a direct decomposition into sparse and linear attention. We propose SLA2, which introduces (I) a learnable router that dynamically selects whether each attention computation should use sparse or linear attention, (II) a more faithful and direct sparse-linear attention formulation that uses a learnable ratio to combine the sparse and linear attention branches, and (III) a sparse + low-bit attention design, where low-bit attention is introduced via quantization-aware fine-tuning to reduce quantization error. Experiments show that on video diffusion models, SLA2 can achieve 97% attention sparsity and deliver an 18.6x attention speedup while preserving generation quality.

</details>


### [148] [Flow Matching from Viewpoint of Proximal Operators](https://arxiv.org/abs/2602.12683)
*Kenji Fukumizu,Wei Huang,Han Bao,Shuntuo Xu,Nisha Chandramoothy*

Main category: cs.LG

TL;DR: 本文重新表述了最优传输条件流匹配（OT-CFM），展示了即使目标分布没有密度，它也可以通过扩展的Brenier势能获得精确的近端形式化表述。


<details>
  <summary>Details</summary>
Motivation: 研究OT-CFM的数学基础，特别是在目标分布可能没有密度的情况下的理论性质，包括近端算子表达、批量方法的收敛性以及对流形支撑目标的动力学行为分析。

Method: 1. 将OT-CFM重新形式化为扩展Brenier势能的精确近端表述 2. 分析小批量OT-CFM随批量大小增加向总体公式的收敛性 3. 利用凸势能的第二半导数证明流形支撑目标下的终端法向双曲性

Result: 1. 证明了恢复目标点的映射恰好由近端算子给出，从而得到了向量场的显式近端表达式 2. 理论分析了小批量方法的收敛性 3. 证明了在流形支撑目标下，OT-CFM具有终端法向双曲性：经过时间重标度后，动力学在垂直于数据流形的方向上指数收缩，而在切向方向上保持中性

Conclusion: 该研究为OT-CFM提供了更坚实的理论基础，特别是通过近端表述使其不依赖于目标分布的密度假设，且为流形支撑目标下的动力学行为提供了精确的数学刻画，这对理解生成模型的几何性质具有重要意义。

Abstract: We reformulate Optimal Transport Conditional Flow Matching (OT-CFM), a class of dynamical generative models, showing that it admits an exact proximal formulation via an extended Brenier potential, without assuming that the target distribution has a density. In particular, the mapping to recover the target point is exactly given by a proximal operator, which yields an explicit proximal expression of the vector field. We also discuss the convergence of minibatch OT-CFM to the population formulation as the batch size increases. Finally, using second epi-derivatives of convex potentials, we prove that, for manifold-supported targets, OT-CFM is terminally normally hyperbolic: after time rescaling, the dynamics contracts exponentially in directions normal to the data manifold while remaining neutral along tangential directions.

</details>


### [149] [Trust the uncertain teacher: distilling dark knowledge via calibrated uncertainty](https://arxiv.org/abs/2602.12687)
*Jeonghyun Kim,SooKyung Kim,Richeng Xuan,Hyunsoo Cho*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The core of knowledge distillation lies in transferring the teacher's rich 'dark knowledge'-subtle probabilistic patterns that reveal how classes are related and the distribution of uncertainties. While this idea is well established, teachers trained with conventional cross-entropy often fail to preserve such signals. Their distributions collapse into sharp, overconfident peaks that appear decisive but are in fact brittle, offering little beyond the hard label or subtly hindering representation-level transfer. This overconfidence is especially problematic in high-cardinality tasks, where the nuances among many plausible classes matter most for guiding a compact student. Moreover, such brittle targets reduce robustness under distribution shift, leaving students vulnerable to miscalibration in real-world conditions. To address this limitation, we revisit distillation from a distributional perspective and propose Calibrated Uncertainty Distillation (CUD), a framework designed to make dark knowledge more faithfully accessible. Instead of uncritically adopting the teacher's overconfidence, CUD encourages teachers to reveal uncertainty where it is informative and guides students to learn from targets that are calibrated rather than sharpened certainty. By directly shaping the teacher's predictive distribution before transfer, our approach balances accuracy and calibration, allowing students to benefit from both confident signals on easy cases and structured uncertainty on hard ones. Across diverse benchmarks, CUD yields students that are not only more accurate, but also more calibrated under shift and more reliable on ambiguous, long-tail inputs.

</details>


### [150] [Leverage-Weighted Conformal Prediction](https://arxiv.org/abs/2602.12693)
*Shreyas Fadnavis*

Main category: cs.LG

TL;DR: 提出了LWCP方法，通过利用帽子矩阵的对角线（统计杠杆）对非一致性分数进行加权，实现对不同方差区域的适应性区间预测，同时保持了分布自由性和有限样本边际覆盖的特性。


<details>
  <summary>Details</summary>
Motivation: 传统的分割共形预测方法产生的常数宽度预测区间在低方差区域过度覆盖，在高方差区域覆盖不足。现有自适应方法需要训练辅助模型，增加了复杂性。

Method: LWCP通过使用统计杠杆（帽子矩阵的对角线）的加权函数对非一致性分数进行加权，利用设计矩阵的几何特性而不是辅助模型来获得适应性。

Result: LWCP保持了有限样本边际有效性；在异方差通过杠杆传递时，能以几乎无宽度成本实现渐近最优条件覆盖；在高斯假设下恢复经典预测区间的形式和宽度，同时保留分布自由保证。随机杠杆近似也能保持精确覆盖并控制宽度扰动。

Conclusion: LWCP提供了一种无需辅助模型、计算开销可忽略的自适应共形预测方法，能显著减少条件覆盖差异，在不同场景下都表现出优越性能。

Abstract: Split conformal prediction provides distribution-free prediction intervals with finite-sample marginal coverage, but produces constant-width intervals that overcover in low-variance regions and undercover in high-variance regions. Existing adaptive methods require training auxiliary models. We propose Leverage-Weighted Conformal Prediction (LWCP), which weights nonconformity scores by a function of the statistical leverage -- the diagonal of the hat matrix -- deriving adaptivity from the geometry of the design matrix rather than from auxiliary model fitting. We prove that LWCP preserves finite-sample marginal validity for any weight function; achieves asymptotically optimal conditional coverage at essentially no width cost when heteroscedasticity factors through leverage; and recovers the form and width of classical prediction intervals under Gaussian assumptions while retaining distribution-free guarantees. We further establish that randomized leverage approximations preserve coverage exactly with controlled width perturbation, and that vanilla CP suffers a persistent, sample-size-independent conditional coverage gap that LWCP eliminates. The method requires no hyperparameters beyond the choice of weight function and adds negligible computational overhead to vanilla CP. Experiments on synthetic and real data confirm the theoretical predictions, demonstrating substantial reductions in conditional coverage disparity across settings.

</details>


### [151] [SWING: Unlocking Implicit Graph Representations for Graph Random Features](https://arxiv.org/abs/2602.12703)
*Alessandro Manenti,Avinava Dubey,Arijit Sehanobish,Cesare Alippi,Krzysztof Choromanski*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose SWING: Space Walks for Implicit Network Graphs, a new class of algorithms for computations involving Graph Random Features on graphs given by implicit representations (i-graphs), where edge-weights are defined as bi-variate functions of feature vectors in the corresponding nodes. Those classes of graphs include several prominent examples, such as: $ε$-neighborhood graphs, used on regular basis in machine learning. Rather than conducting walks on graphs' nodes, those methods rely on walks in continuous spaces, in which those graphs are embedded. To accurately and efficiently approximate original combinatorial calculations, SWING applies customized Gumbel-softmax sampling mechanism with linearized kernels, obtained via random features coupled with importance sampling techniques. This algorithm is of its own interest. SWING relies on the deep connection between implicitly defined graphs and Fourier analysis, presented in this paper. SWING is accelerator-friendly and does not require input graph materialization. We provide detailed analysis of SWING and complement it with thorough experiments on different classes of i-graphs.

</details>


### [152] [Physics-Informed Laplace Neural Operator for Solving Partial Differential Equations](https://arxiv.org/abs/2602.12706)
*Heechang Kim,Qianying Cao,Hyomin Shin,Seungchul Lee,George Em Karniadakis,Minseok Choi*

Main category: cs.LG

TL;DR: PILNO通过结合物理约束和虚拟输入训练，显著提升了神经算子在数据稀缺和分布外场景下的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 纯数据驱动的神经算子泛化能力差，尤其是在数据量少和未见输入（分布外）的情况下。为了提升小数据能力和分布外泛化性能，研究者提出将物理信息嵌入到训练过程中。

Method: 提出PILNO（物理信息拉普拉斯神经算子），它基于改进的ALNO（高级LNO）主干，将稳态分支替换为FNO风格的傅里叶乘法器。PILNO采用虚拟输入（宽频谱的未标记输入函数集合）和时序因果加权（时间衰减的物理残差权重）策略，实现数据高效且鲁棒的物理信息训练。

Result: 在Burgers方程、达西流、反应扩散系统和强迫KdV方程四个典型基准测试中，PILNO在小数据设置下（如N_train≤27）显著提高了精度，降低了随机种子间的运行方差，并且相比纯数据驱动基线实现了更强的分布外泛化能力。

Conclusion: PILNO通过将物理先验嵌入神经算子架构和训练过程中，在数据稀缺和分布外场景下展现出优越的性能，为物理信息神经算子领域提供了高效且鲁棒的解决方案。

Abstract: Neural operators have emerged as fast surrogate solvers for parametric partial differential equations (PDEs). However, purely data-driven models often require extensive training data and can generalize poorly, especially in small-data regimes and under unseen (out-of-distribution) input functions that are not represented in the training data. To address these limitations, we propose the Physics-Informed Laplace Neural Operator (PILNO), which enhances the Laplace Neural Operator (LNO) by embedding governing physics into training through PDE, boundary condition, and initial condition residuals. To improve expressivity, we first introduce an Advanced LNO (ALNO) backbone that retains a pole-residue transient representation while replacing the steady-state branch with an FNO-style Fourier multiplier. To make physics-informed training both data-efficient and robust, PILNO further leverages (i) virtual inputs: an unlabeled ensemble of input functions spanning a broad spectral range that provides abundant physics-only supervision and explicitly targets out-of-distribution (OOD) regimes; and (ii) temporal-causality weighting: a time-decaying reweighting of the physics residual that prioritizes early-time dynamics and stabilizes optimization for time-dependent PDEs. Across four representative benchmarks -- Burgers' equation, Darcy flow, a reaction-diffusion system, and a forced KdV equation -- PILNO consistently improves accuracy in small-data settings (e.g., N_train <= 27), reduces run-to-run variability across random seeds, and achieves stronger OOD generalization than purely data-driven baselines.

</details>


### [153] [Mixture of Predefined Experts: Maximizing Data Usage on Vertical Federated Learning](https://arxiv.org/abs/2602.12708)
*Jon Irureta,Gorka Azkune,Jon Imaz,Aizea Lojo,Javier Fernandez-Marques*

Main category: cs.LG

TL;DR: Split-MoPE是一种新颖的垂直联邦学习框架，通过结合分裂学习与预定义专家混合架构，处理样本不对齐的实际情况，在单轮通信中实现高效训练。


<details>
  <summary>Details</summary>
Motivation: 现有垂直联邦学习大多基于样本完全对齐的理想假设，实际应用中罕见；需要开发能处理样本不对齐且减少通信开销的框架。

Method: 提出Split-MoPE框架，整合分裂学习与预定义专家混合架构，使用预定义专家处理特定数据对齐模式，利用预训练编码器，单轮通信即可完成训练。

Result: 在视觉和表格数据集上的评估表明，Split-MoPE在数据缺失严重的挑战性场景中优于LASER、Vertical SplitNN等现有方法，同时提供抗恶意参与者的鲁棒性和样本级可解释性。

Conclusion: Split-MoPE为解决垂直联邦学习中样本不对齐的实际问题提供了高效、鲁棒且可解释的解决方案，通信开销显著降低。

Abstract: Vertical Federated Learning (VFL) has emerged as a critical paradigm for collaborative model training in privacy-sensitive domains such as finance and healthcare. However, most existing VFL frameworks rely on the idealized assumption of full sample alignment across participants, a premise that rarely holds in real-world scenarios. To bridge this gap, this work introduces Split-MoPE, a novel framework that integrates Split Learning with a specialized Mixture of Predefined Experts (MoPE) architecture. Unlike standard Mixture of Experts (MoE), where routing is learned dynamically, MoPE uses predefined experts to process specific data alignments, effectively maximizing data usage during both training and inference without requiring full sample overlap. By leveraging pretrained encoders for target data domains, Split-MoPE achieves state-of-the-art performance in a single communication round, significantly reducing the communication footprint compared to multi-round end-to-end training. Furthermore, unlike existing proposals that address sample misalignment, this novel architecture provides inherent robustness against malicious or noisy participants and offers per-sample interpretability by quantifying each collaborator's contribution to each prediction. Extensive evaluations on vision (CIFAR-10/100) and tabular (Breast Cancer Wisconsin) datasets demonstrate that Split-MoPE consistently outperforms state-of-the-art systems such as LASER and Vertical SplitNN, particularly in challenging scenarios with high data missingness.

</details>


### [154] [GRAIL: Geometry-Aware Retrieval-Augmented Inference with LLMs over Hyperbolic Representations of Patient Trajectories](https://arxiv.org/abs/2602.12828)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Predicting future clinical events from longitudinal electronic health records (EHRs) is challenging due to sparse multi-type clinical events, hierarchical medical vocabularies, and the tendency of large language models (LLMs) to hallucinate when reasoning over long structured histories. We study next-visit event prediction, which aims to forecast a patient's upcoming clinical events based on prior visits. We propose GRAIL, a framework that models longitudinal EHRs using structured geometric representations and structure-aware retrieval. GRAIL constructs a unified clinical graph by combining deterministic coding-system hierarchies with data-driven temporal associations across event types, embeds this graph in hyperbolic space, and summarizes each visit as a probabilistic Central Event that denoises sparse observations. At inference time, GRAIL retrieves a structured set of clinically plausible future events aligned with hierarchical and temporal progression, and optionally refines their ranking using an LLM as a constrained inference-time reranker. Experiments on MIMIC-IV show that GRAIL consistently improves multi-type next-visit prediction and yields more hierarchy-consistent forecasts.

</details>


### [155] [ADEPT: RL-Aligned Agentic Decoding of Emotion via Evidence Probing Tools -- From Consensus Learning to Ambiguity-Driven Emotion Reasoning](https://arxiv.org/abs/2602.12714)
*Esther Sun,Bo-Hao Su,Abinay Reddy Naini,Shinji Watanabe,Carlos Busso*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Speech Large Language Models (SLLMs) enable high-level emotion reasoning but often produce ungrounded, text-biased judgments without verifiable acoustic evidence. In contrast, self-supervised speech encoders such as WavLM provide strong acoustic representations yet remain opaque discriminative models with limited interpretability. To bridge this gap, we introduce ADEPT (Agentic Decoding of Emotion via Evidence Probing Tools), a framework that reframes emotion recognition as a multi-turn inquiry process rather than a single-pass prediction. ADEPT transforms an SLLM into an agent that maintains an evolving candidate emotion set and adaptively invokes dedicated semantic and acoustic probing tools within a structured pipeline of candidate generation, evidence collection, and adjudication. Crucially, ADEPT enables a paradigm shift from consensus learning to ambiguity-driven emotion reasoning. Since human affect exhibits inherent complexity and frequent co-occurrence of emotions, we treat minority annotations as informative perceptual signals rather than discarding them as noise. Finally, we integrate Group Relative Policy Optimization (GRPO) with an Evidence Trust Gate to explicitly couple tool-usage behaviors with prediction quality and enforce evidence-grounded reasoning. Experiments show that ADEPT improves primary emotion accuracy in most settings while substantially improving minor emotion characterization, producing explanations grounded in auditable acoustic and semantic evidence.

</details>


### [156] [FLAC: Maximum Entropy RL via Kinetic Energy Regularized Bridge Matching](https://arxiv.org/abs/2602.12829)
*Lei Lv,Yunfei Li,Yu Luo,Fuchun Sun,Xiao Ma*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Iterative generative policies, such as diffusion models and flow matching, offer superior expressivity for continuous control but complicate Maximum Entropy Reinforcement Learning because their action log-densities are not directly accessible. To address this, we propose Field Least-Energy Actor-Critic (FLAC), a likelihood-free framework that regulates policy stochasticity by penalizing the kinetic energy of the velocity field. Our key insight is to formulate policy optimization as a Generalized Schrödinger Bridge (GSB) problem relative to a high-entropy reference process (e.g., uniform). Under this view, the maximum-entropy principle emerges naturally as staying close to a high-entropy reference while optimizing return, without requiring explicit action densities. In this framework, kinetic energy serves as a physically grounded proxy for divergence from the reference: minimizing path-space energy bounds the deviation of the induced terminal action distribution. Building on this view, we derive an energy-regularized policy iteration scheme and a practical off-policy algorithm that automatically tunes the kinetic energy via a Lagrangian dual mechanism. Empirically, FLAC achieves superior or comparable performance on high-dimensional benchmarks relative to strong baselines, while avoiding explicit density estimation.

</details>


### [157] [Adaptive Structured Pruning of Convolutional Neural Networks for Time Series Classification](https://arxiv.org/abs/2602.12744)
*Javidan Abdullayev,Maxime Devanne,Cyril Meyer,Ali Ismail-Fawaz,Jonathan Weber,Germain Forestier*

Main category: cs.LG

TL;DR: DSP是一个自动结构化剪枝框架，针对卷积时序分类模型，无需预设剪枝比例即可显著压缩模型，同时保持分类精度


<details>
  <summary>Details</summary>
Motivation: 解决基于深度学习的时序分类模型在资源受限设备上部署时的计算和内存瓶颈问题，现有方法依赖手动调参，缺乏跨数据集的通用性

Method: 引入实例级稀疏损失，在训练过程中诱导通道级稀疏；结合全局激活分析，自动识别并剪枝冗余滤波器，无需预定义剪枝比例

Result: 在128个UCR数据集上验证，LITETime平均压缩58%，InceptionTime平均压缩75%，且分类精度得以保持；冗余分析证实DSP能生成紧凑且信息丰富的表示

Conclusion: DSP为可扩展且高效的深度时序分类模型部署提供了实用路径，实现了完全自动化的结构化剪枝

Abstract: Deep learning models for Time Series Classification (TSC) have achieved strong predictive performance but their high computational and memory requirements often limit deployment on resource-constrained devices. While structured pruning can address these issues by removing redundant filters, existing methods typically rely on manually tuned hyperparameters such as pruning ratios which limit scalability and generalization across datasets. In this work, we propose Dynamic Structured Pruning (DSP), a fully automatic, structured pruning framework for convolution-based TSC models. DSP introduces an instance-wise sparsity loss during training to induce channel-level sparsity, followed by a global activation analysis to identify and prune redundant filters without needing any predefined pruning ratio. This work tackles computational bottlenecks of deep TSC models for deployment on resource-constrained devices. We validate DSP on 128 UCR datasets using two different deep state-of-the-art architectures: LITETime and InceptionTime. Our approach achieves an average compression of 58% for LITETime and 75% for InceptionTime architectures while maintaining classification accuracy. Redundancy analyses confirm that DSP produces compact and informative representations, offering a practical path for scalable and efficient deep TSC deployment.

</details>


### [158] [TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming Electronic Health Records (EHRs)](https://arxiv.org/abs/2602.12833)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) encode extensive medical knowledge but struggle to apply it reliably to longitudinal patient trajectories, where evolving clinical states, irregular timing, and heterogeneous events degrade performance over time. Existing adaptation strategies rely on fine-tuning or retrieval-based augmentation, which introduce computational overhead, privacy constraints, or instability under long contexts. We introduce TRACE (Temporal Reasoning via Agentic Context Evolution), a framework that enables temporal clinical reasoning with frozen LLMs by explicitly structuring and maintaining context rather than extending context windows or updating parameters. TRACE operates over a dual-memory architecture consisting of a static Global Protocol encoding institutional clinical rules and a dynamic Individual Protocol tracking patient-specific state. Four agentic components, Router, Reasoner, Auditor, and Steward, coordinate over this structured memory to support temporal inference and state evolution. The framework maintains bounded inference cost via structured state compression and selectively audits safety-critical clinical decisions. Evaluated on longitudinal clinical event streams from MIMIC-IV, TRACE significantly improves next-event prediction accuracy, protocol adherence, and clinical safety over long-context and retrieval-augmented baselines, while producing interpretable and auditable reasoning traces.

</details>


### [159] [Hierarchical Successor Representation for Robust Transfer](https://arxiv.org/abs/2602.12753)
*Changmin Yu,Máté Lengyel*

Main category: cs.LG

TL;DR: 提出分层后继表示(HSR)，通过引入时间抽象机制解决经典后继表示的政策依赖性和谱扩散问题，实现了稳定、稀疏的状态表示，支持高效的任务迁移和探索


<details>
  <summary>Details</summary>
Motivation: 经典后继表示(SR)存在两个主要局限：1) 高度依赖特定政策，当政策因学习、环境非平稳性或任务需求变化而改变时，预测表示会过时；2) 在拓扑复杂环境中会出现谱扩散，导致特征密集重叠且难以扩展

Method: 提出分层后继表示(HSR)，将时间抽象整合到预测表示构建中。对HSR应用非负矩阵分解(NMF)获得稀疏低秩状态表示。该方法结合多分区环境支持高效任务迁移

Result: HSR-NMF生成稳定且不受任务引发的政策变化影响的状态特征，在多分区环境中实现样本高效的迁移学习。进一步分析显示该方法能发现可解释的拓扑结构，提供政策无关的分层地图

Conclusion: HSR成功结合了无模型最优性和基于模型灵活性的优势，不仅为任务迁移提供有用基础，其时间扩展的预测结构还能驱动高效探索，可扩展到大规模程序生成环境

Abstract: The successor representation (SR) provides a powerful framework for decoupling predictive dynamics from rewards, enabling rapid generalisation across reward configurations. However, the classical SR is limited by its inherent policy dependence: policies change due to ongoing learning, environmental non-stationarities, and changes in task demands, making established predictive representations obsolete. Furthermore, in topologically complex environments, SRs suffer from spectral diffusion, leading to dense and overlapping features that scale poorly. Here we propose the Hierarchical Successor Representation (HSR) for overcoming these limitations. By incorporating temporal abstractions into the construction of predictive representations, HSR learns stable state features which are robust to task-induced policy changes. Applying non-negative matrix factorisation (NMF) to the HSR yields a sparse, low-rank state representation that facilitates highly sample-efficient transfer to novel tasks in multi-compartmental environments. Further analysis reveals that HSR-NMF discovers interpretable topological structures, providing a policy-agnostic hierarchical map that effectively bridges model-free optimality and model-based flexibility. Beyond providing a useful basis for task-transfer, we show that HSR's temporally extended predictive structure can also be leveraged to drive efficient exploration, effectively scaling to large, procedurally generated environments.

</details>


### [160] [Amortized Reasoning Tree Search: Decoupling Proposal and Decision in Large Language Models](https://arxiv.org/abs/2602.12846)
*Zesheng Hong,Jiadong Yu,Hui Pan*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has established itself as the dominant paradigm for instilling rigorous reasoning capabilities in Large Language Models. While effective at amplifying dominant behaviors, we identify a critical pathology in this alignment process: the systematic suppression of valid but rare (low-likelihood under the base model distribution) reasoning paths. We theoretically characterize this phenomenon as a "Normalization Squeeze," where the interplay between mode-seeking policy gradients and finite sampling acts as a high-pass likelihood filter, driving the probability of rare correct traces to statistical extinction. To counteract this collapse without discarding the base model's latent diversity, we propose Amortized Reasoning Tree Search (ARTS). Unlike standard approaches that force internalization via parameter updates, ARTS prioritizes deliberation by decoupling generation from verification. We introduce a Flow Matching objective that repurposes the verifier to estimate the conservation of probability flow, enabling robust navigation through sparse, high-entropy search spaces where traditional discriminative objectives fail. Extensive experiments on the MATH-500 benchmark demonstrate that ARTS achieves a performance of 74.6% (BoN@16), effectively matching fully fine-tuned policies (74.7%) without modifying the generative backbone. Crucially, on the long-tail subset where coupled RL optimization collapses to 0% pass@k, ARTS uniquely recovers significant performance, suggesting that disentangling verification from generation offers a more robust pathway for solving complex reasoning tasks.

</details>


### [161] [Closing the Loop: A Control-Theoretic Framework for Provably Stable Time Series Forecasting with LLMs](https://arxiv.org/abs/2602.12756)
*Xingyu Zhang,Hanyun Du,Zeen Song,Jianqi Zhang,Changwen Zheng,Wenwen Qiang*

Main category: cs.LG

TL;DR: 本文提出F-LLM框架，通过控制理论中的闭环机制解决LLM在时间序列预测中的误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM时间序列预测方法采用简单的自回归生成策略，在推断阶段以开环方式运行，消耗自身生成的输出，导致微小误差在长时程中累积并引发显著轨迹漂移（暴露偏差）。

Method: 提出F-LLM（反馈驱动LLM）框架：1）将自回归预测重新表述为控制理论问题；2）通过可学习的残差估计器（Observer）和反馈控制器实现闭环机制；3）在基础模型满足局部Lipschitz约束条件下，理论保证误差有界。

Result: 大量实验表明F-LLM能显著减轻误差传播，在时间序列基准测试中获得良好性能。

Conclusion: F-LLM框架通过控制理论中的闭环机制有效解决了LLM在时间序列预测中的误差累积问题，为长时程预测提供了更稳定的解决方案。

Abstract: Large Language Models (LLMs) have recently shown exceptional potential in time series forecasting, leveraging their inherent sequential reasoning capabilities to model complex temporal dynamics. However, existing approaches typically employ a naive autoregressive generation strategy. We identify a critical theoretical flaw in this paradigm: during inference, the model operates in an open-loop manner, consuming its own generated outputs recursively. This leads to inevitable error accumulation (exposure bias), where minor early deviations cascade into significant trajectory drift over long horizons. In this paper, we reformulate autoregressive forecasting through the lens of control theory, proposing \textbf{F-LLM} (Feedback-driven LLM), a novel closed-loop framework. Unlike standard methods that passively propagate errors, F-LLM actively stabilizes the trajectory via a learnable residual estimator (Observer) and a feedback controller. Furthermore, we provide a theoretical guarantee that our closed-loop mechanism ensures uniformly bounded error, provided the base model satisfies a local Lipschitz constraint. Extensive experiments demonstrate that F-LLM significantly mitigates error propagation, achieving good performance on time series benchmarks.

</details>


### [162] [X-VORTEX: Spatio-Temporal Contrastive Learning for Wake Vortex Trajectory Forecasting](https://arxiv.org/abs/2602.12869)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: X-VORTEX通过时空对比学习框架，从无标签的LiDAR点云序列中学习物理感知的表征，解决了飞机尾涡追踪中传感器稀疏性和动态变化的核心挑战。


<details>
  <summary>Details</summary>
Motivation: 尾涡会对航空安全管理造成挑战，但由于扫描稀疏、涡流特征随大气湍流减弱、逐点标注成本高昂，现有的监督分割方法无法有效处理大规模未标注数据。

Method: 基于增强重叠理论的时空对比学习框架，通过弱扰动和强增强序列构建配对输入，使用时间分布式几何编码器和顺序聚合器建模涡流状态演化。

Result: 在超过一百万LiDAR扫描的真实数据集上，仅使用监督基线1%的标注数据就实现了优越的涡流中心定位，学到的表征支持准确轨迹预测。

Conclusion: X-VORTEX能够从无标签序列中学习物理感知表征，显著减少标注需求，为尾涡追踪提供可扩展的解决方案。

Abstract: Wake vortices are strong, coherent air turbulences created by aircraft, and they pose a major safety and capacity challenge for air traffic management. Tracking how vortices move, weaken, and dissipate over time from LiDAR measurements is still difficult because scans are sparse, vortex signatures fade as the flow breaks down under atmospheric turbulence and instabilities, and point-wise annotation is prohibitively expensive. Existing approaches largely treat each scan as an independent, fully supervised segmentation problem, which overlooks temporal structure and does not scale to the vast unlabeled archives collected in practice. We present X-VORTEX, a spatio-temporal contrastive learning framework grounded in Augmentation Overlap Theory that learns physics-aware representations from unlabeled LiDAR point cloud sequences. X-VORTEX addresses two core challenges: sensor sparsity and time-varying vortex dynamics. It constructs paired inputs from the same underlying flight event by combining a weakly perturbed sequence with a strongly augmented counterpart produced via temporal subsampling and spatial masking, encouraging the model to align representations across missing frames and partial observations. Architecturally, a time-distributed geometric encoder extracts per-scan features and a sequential aggregator models the evolving vortex state across variable-length sequences. We evaluate on a real-world dataset of over one million LiDAR scans. X-VORTEX achieves superior vortex center localization while using only 1% of the labeled data required by supervised baselines, and the learned representations support accurate trajectory forecasting.

</details>


### [163] [Transporting Task Vectors across Different Architectures without Training](https://arxiv.org/abs/2602.12952)
*Filippo Rinaldi,Aniello Panariello,Giacomo Salici,Angelo Porrello,Simone Calderara*

Main category: cs.LG

TL;DR: Theseus是一种无需训练的方法，可在不同宽度的异质模型之间传输任务特定的参数更新，通过函数匹配来表征任务更新对中间表示的影响。


<details>
  <summary>Details</summary>
Motivation: 大型预训练模型迁移到下游任务时会产生昂贵的任务特定参数更新，目前虽然可以在相同架构模型间传输这类更新，但在不同宽度模型间的传输尚未被充分探索。

Method: 将任务向量传输形式化为在观察到的激活上的函数匹配问题，通过正交Procrustes对齐表示空间后，获得稳定的闭式解来保持更新几何结构。

Result: 在视觉和语言模型的不同宽度架构上评估Theseus，相比基线方法有明显提升且无需额外训练或反向传播。

Conclusion: 当任务标识以函数方式而非参数方式定义时，任务更新可以在不同架构之间有意义的传输。

Abstract: Adapting large pre-trained models to downstream tasks often produces task-specific parameter updates that are expensive to relearn for every model variant. While recent work has shown that such updates can be transferred between models with identical architectures, transferring them across models of different widths remains largely unexplored. In this work, we introduce Theseus, a training-free method for transporting task-specific updates across heterogeneous models. Rather than matching parameters directly, we characterize a task update by the functional effect it induces on intermediate representations. We formalize task-vector transport as a functional matching problem on observed activations and show that, after aligning representation spaces via orthogonal Procrustes analysis, it admits a stable closed-form solution that preserves the geometry of the update. We evaluate Theseus on vision and language models across different widths, showing consistent improvements over strong baselines without additional training or backpropagation. Our results show that task updates can be meaningfully transferred across architectures when task identity is defined functionally rather than parametrically.

</details>


### [164] [Extending confidence calibration to generalised measures of variation](https://arxiv.org/abs/2602.12975)
*Andrew Thompson,Vivek Desai*

Main category: cs.LG

TL;DR: 论文提出了Variation Calibration Error (VCE)用于评估机学习分类器的校准性能，这是对Expected Calibration Error (ECE)的扩展，能够评估全概率分布的变异性而不仅仅是最大概率/置信度。


<details>
  <summary>Details</summary>
Motivation: 现有的校准评估指标（如ECE）主要关注最大概率/置信度的准确性，缺乏对整个概率分布变异性的评估。其他基于变异性度量的校准指标（如熵相关指标）在实践中可能无法满足校准评估的理论要求。

Method: 将ECE的框架扩展到任何变异性度量中，提出了Variation Calibration Error (VCE)作为评估概率分布变异性校准的统一方法。通过分析VCE的理论性质，并使用完美校准的合成数据进行数值实验验证其性能。

Result: 数值实验表明，对于完美校准的合成预测数据，随着样本数量的增加，VCE值趋近于零，具备理想校准度量应有的渐近性质。相比之下，文献中提出的另一种基于熵的校准指标（UCE）无法满足这一要求。

Conclusion: Variation Calibration Error (VCE)提供了一个有效的框架来评估分类器全概率分布的校准性能，解决了现有指标只能评估置信度校准的局限，在理论上和实践上都具有明显优势。

Abstract: We propose the Variation Calibration Error (VCE) metric for assessing the calibration of machine learning classifiers. The metric can be viewed as an extension of the well-known Expected Calibration Error (ECE) which assesses the calibration of the maximum probability or confidence. Other ways of measuring the variation of a probability distribution exist which have the advantage of taking into account the full probability distribution, for example the Shannon entropy. We show how the ECE approach can be extended from assessing confidence calibration to assessing the calibration of any metric of variation. We present numerical examples upon synthetic predictions which are perfectly calibrated by design, demonstrating that, in this scenario, the VCE has the desired property of approaching zero as the number of data samples increases, in contrast to another entropy-based calibration metric (the UCE) which has been proposed in the literature.

</details>


### [165] [Drift-Aware Variational Autoencoder-based Anomaly Detection with Two-level Ensembling](https://arxiv.org/abs/2602.12976)
*Jin Li,Kleanthis Malialis,Christos G. Panayiotou,Marios M. Polycarpou*

Main category: cs.LG

TL;DR: 提出VAE++ESDD方法，结合增量学习和双重集成技术，用于处理非平稳环境下的流数据异常检测


<details>
  <summary>Details</summary>
Motivation: 数字世界中，大量流数据无标签，且存在概念漂移问题，传统异常检测方法效果受限

Method: 使用变分自编码器（VAE）集成进行异常预测，结合统计式概念漂移检测器，采用增量学习框架

Result: 在真实和合成数据集（特别是极端低异常率场景）的实验中，表现显著优于基准和最先进方法

Conclusion: VAE++ESDD能有效应对概念漂移，在流数据异常检测中具有优越性能

Abstract: In today's digital world, the generation of vast amounts of streaming data in various domains has become ubiquitous. However, many of these data are unlabeled, making it challenging to identify events, particularly anomalies. This task becomes even more formidable in nonstationary environments where model performance can deteriorate over time due to concept drift. To address these challenges, this paper presents a novel method, VAE++ESDD, which employs incremental learning and two-level ensembling: an ensemble of Variational AutoEncoder(VAEs) for anomaly prediction, along with an ensemble of concept drift detectors. Each drift detector utilizes a statistical-based concept drift mechanism. To evaluate the effectiveness of VAE++ESDD, we conduct a comprehensive experimental study using real-world and synthetic datasets characterized by severely or extremely low anomalous rates and various drift characteristics. Our study reveals that the proposed method significantly outperforms both strong baselines and state-of-the-art methods.

</details>


### [166] [Prior-Guided Symbolic Regression: Towards Scientific Consistency in Equation Discovery](https://arxiv.org/abs/2602.13021)
*Jing Xiao,Xinhai Chen,Jiaming Peng,Qinglin Wang,Menghan Jia,Zhiquan Lai,Guangping Yu,Dongsheng Li,Tiejun Li,Jie Liu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Symbolic Regression (SR) aims to discover interpretable equations from observational data, with the potential to reveal underlying principles behind natural phenomena. However, existing approaches often fall into the Pseudo-Equation Trap: producing equations that fit observations well but remain inconsistent with fundamental scientific principles. A key reason is that these approaches are dominated by empirical risk minimization, lacking explicit constraints to ensure scientific consistency. To bridge this gap, we propose PG-SR, a prior-guided SR framework built upon a three-stage pipeline consisting of warm-up, evolution, and refinement. Throughout the pipeline, PG-SR introduces a prior constraint checker that explicitly encodes domain priors as executable constraint programs, and employs a Prior Annealing Constrained Evaluation (PACE) mechanism during the evolution stage to progressively steer discovery toward scientifically consistent regions. Theoretically, we prove that PG-SR reduces the Rademacher complexity of the hypothesis space, yielding tighter generalization bounds and establishing a guarantee against pseudo-equations. Experimentally, PG-SR outperforms state-of-the-art baselines across diverse domains, maintaining robustness to varying prior quality, noisy data, and data scarcity.

</details>


### [167] [Look Inward to Explore Outward: Learning Temperature Policy from LLM Internal States via Hierarchical RL](https://arxiv.org/abs/2602.13035)
*Yixiao Zhou,Yang Li,Dongzhou Cheng,Hehe Fan,Yu Cheng*

Main category: cs.LG

TL;DR: RLVR框架中采样温度作为学习参数，提出分层强化学习方法让LLM在生成过程中自主控制温度，在数学推理任务中优于固定和启发式基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用静态温度或启发式调整，与任务奖励解耦，无法动态适应推理过程中的不确定性，限制了探索-利用权衡的效果。

Method: 提出Introspective LLM分层强化学习框架：1) 在解码步骤根据隐藏状态选择温度；2) 从温度调节的分布中采样下一个token；3) 使用坐标上升方案联合优化温度和token策略。

Result: 在数学推理基准测试中，学习到的温度策略优于固定和启发式基线，并展现出与推理不确定性一致的可解释探索行为。

Conclusion: 将采样温度作为可学习参数能更有效地控制探索-利用权衡，提高LLM在复杂推理任务中的性能，该方法为动态生成策略提供了新思路。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) trains large language models (LLMs) from sampled trajectories, making decoding strategy a core component of learning rather than a purely inference-time choice. Sampling temperature directly controls the exploration--exploitation trade-off by modulating policy entropy, yet existing methods rely on static values or heuristic adaptations that are decoupled from task-level rewards. We propose Introspective LLM, a hierarchical reinforcement learning framework that learns to control sampling temperature during generation. At each decoding step, the model selects a temperature based on its hidden state and samples the next token from the resulting distribution. Temperature and token policies are jointly optimized from downstream rewards using a coordinate ascent scheme. Experiments on mathematical reasoning benchmarks show that learned temperature policies outperform fixed and heuristic baselines, while exhibiting interpretable exploration behaviors aligned with reasoning uncertainty.

</details>


### [168] [Multi-Dimensional Visual Data Recovery: Scale-Aware Tensor Modeling and Accelerated Randomized Computation](https://arxiv.org/abs/2602.12982)
*Wenjin Qin,Hailin Wang,Jiangjun Peng,Jianjun Wang,Tingwen Huang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The recently proposed fully-connected tensor network (FCTN) decomposition has demonstrated significant advantages in correlation characterization and transpositional invariance, and has achieved notable achievements in multi-dimensional data processing and analysis. However, existing multi-dimensional data recovery methods leveraging FCTN decomposition still have room for further enhancement, particularly in computational efficiency and modeling capability. To address these issues, we first propose a FCTN-based generalized nonconvex regularization paradigm from the perspective of gradient mapping. Then, reliable and scalable multi-dimensional data recovery models are investigated, where the model formulation is shifted from unquantized observations to coarse-grained quantized observations. Based on the alternating direction method of multipliers (ADMM) framework, we derive efficient optimization algorithms with convergence guarantees to solve the formulated models. To alleviate the computational bottleneck encountered when processing large-scale multi-dimensional data, fast and efficient randomized compression algorithms are devised in virtue of sketching techniques in numerical linear algebra. These dimensionality-reduction techniques serve as the computational acceleration core of our proposed algorithm framework. Theoretical results on approximation error upper bounds and convergence analysis for the proposed method are derived. Extensive numerical experiments illustrate the effectiveness and superiority of the proposed algorithm over other state-of-the-art methods in terms of quantitative metrics, visual quality, and running time.

</details>


### [169] [Geometric Manifold Rectification for Imbalanced Learning](https://arxiv.org/abs/2602.13045)
*Xubin Wang,Qing Li,Weijia Jia*

Main category: cs.LG

TL;DR: 本文提出GMR框架，通过几何置信度估计和非对称清洗处理不平衡分类问题，在基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统欠采样方法(如ENN)使用对称清洗规则和均匀投票，难以捕捉局部流形结构，且可能误删有信息的少数类样本。从不平衡分类的几何视角看，核心困难在于多数类流形对少数类流形的拓扑侵入，这模糊了真实决策边界。

Method: 提出GMR框架，包含两个关键技术：1)几何置信度估计：使用自适应距离度量的反距离加权kNN投票来捕捉局部可靠性；2)非对称清洗：对多数类样本采用严格清洗，同时通过设置保护上限来保守保护少数类样本。

Result: 在多个基准数据集上的大量实验表明，GMR与强大的采样基准方法具有竞争力。

Conclusion: GMR框架通过利用局部几何先验，能够稳健地处理不平衡结构化数据，有效解决传统方法在捕捉局部流形结构和保护有信息少数类样本方面的不足。

Abstract: Imbalanced classification presents a formidable challenge in machine learning, particularly when tabular datasets are plagued by noise and overlapping class boundaries. From a geometric perspective, the core difficulty lies in the topological intrusion of the majority class into the minority manifold, which obscures the true decision boundary. Traditional undersampling techniques, such as Edited Nearest Neighbours (ENN), typically employ symmetric cleaning rules and uniform voting, failing to capture the local manifold structure and often inadvertently removing informative minority samples. In this paper, we propose GMR (Geometric Manifold Rectification), a novel framework designed to robustly handle imbalanced structured data by exploiting local geometric priors. GMR makes two contributions: (1) Geometric confidence estimation that uses inverse-distance weighted kNN voting with an adaptive distance metric to capture local reliability; and (2) asymmetric cleaning that is strict on majority samples while conservatively protecting minority samples via a safe-guarding cap on minority removal. Extensive experiments on multiple benchmark datasets show that GMR is competitive with strong sampling baselines.

</details>


### [170] [Uncertainty in Federated Granger Causality: From Origins to Systemic Consequences](https://arxiv.org/abs/2602.13004)
*Ayush Mohanty,Nazal Mohamed,Nagi Gebraeel*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Granger Causality (GC) provides a rigorous framework for learning causal structures from time-series data. Recent federated variants of GC have targeted distributed infrastructure applications (e.g., smart grids) with distributed clients that generate high-dimensional data bound by data-sovereignty constraints. However, Federated GC algorithms only yield deterministic point estimates of causality and neglect uncertainty. This paper establishes the first methodology for rigorously quantifying uncertainty and its propagation within federated GC frameworks. We systematically classify sources of uncertainty, explicitly differentiating aleatoric (data noise) from epistemic (model variability) effects. We derive closed-form recursions that model the evolution of uncertainty through client-server interactions and identify four novel cross-covariance components that couple data uncertainties with model parameter uncertainties across the federated architecture. We also define rigorous convergence conditions for these uncertainty recursions and obtain explicit steady-state variances for both server and client model parameters. Our convergence analysis demonstrates that steady-state variances depend exclusively on client data statistics, thus eliminating dependence on initial epistemic priors and enhancing robustness. Empirical evaluations on synthetic benchmarks and real-world industrial datasets demonstrate that explicitly characterizing uncertainty significantly improves the reliability and interpretability of federated causal inference.

</details>


### [171] [Machine Learning-Based Classification of Jhana Advanced Concentrative Absorption Meditation (ACAM-J) using 7T fMRI](https://arxiv.org/abs/2602.13008)
*Puneet Kumar,Winson F. Z. Yang,Alakhsimar Singh,Xiaobai Li,Matthew D. Sacchet*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Jhana advanced concentration absorption meditation (ACAM-J) is related to profound changes in consciousness and cognitive processing, making the study of their neural correlates vital for insights into consciousness and well-being. This study evaluates whether functional MRI-derived regional homogeneity (ReHo) can be used to classify ACAM-J using machine-learning approaches. We collected group-level fMRI data from 20 advanced meditators to train the classifiers, and intensive single-case data from an advanced practitioner performing ACAM-J and control tasks to evaluate generalization. ReHo maps were computed, and features were extracted from predefined brain regions of interest. We trained multiple machine learning classifiers using stratified cross-validation to evaluate whether ReHo patterns distinguish ACAM-J from non-meditative states. Ensemble models achieved 66.82% (p < 0.05) accuracy in distinguishing ACAM-J from control conditions. Feature-importance analysis indicated that prefrontal and anterior cingulate areas contributed most to model decisions, aligning with established involvement of these regions in attentional regulation and metacognitive processes. Moreover, moderate agreement reflected in Cohen's kappa supports the feasibility of using machine learning to distinguish ACAM-J from non-meditative states. These findings advocate machine-learning's feasibility in classifying advanced meditation states, future research on neuromodulation and mechanistic models of advanced meditation.

</details>


### [172] [Diverging Flows: Detecting Extrapolations in Conditional Generation](https://arxiv.org/abs/2602.13061)
*Constantinos Tsakonas,Serena Ivaldi,Jean-Baptiste Mouret*

Main category: cs.LG

TL;DR: Diverging Flows是一种新方法，通过在单一模型中同时执行条件生成和原生外推检测来解决流匹配模型在安全关键部署中的外推风险问题，实现可靠部署。


<details>
  <summary>Details</summary>
Motivation: 流匹配模型在复杂条件分布建模方面表现出色，但在安全关键场景部署中面临外推风险：由于平滑性偏差，模型即使对偏离流形分布的条件也能产生看似合理的输出，导致难以区分的静默故障。

Method: 提出Diverging Flows方法，通过结构上为偏离流形输入强制实施低效传输，使单一模型能够同时执行条件生成和原生外推检测。

Result: 在合成流形、跨域风格迁移和天气温度预测任务上的评估表明，该方法能有效检测外推，同时不损害预测精度或推理延迟。

Conclusion: Diverging Flows为可信赖的流模型提供了稳健解决方案，为医疗、机器人、气候科学等领域的可靠部署铺平了道路。

Abstract: The ability of Flow Matching (FM) to model complex conditional distributions has established it as the state-of-the-art for prediction tasks (e.g., robotics, weather forecasting). However, deployment in safety-critical settings is hindered by a critical extrapolation hazard: driven by smoothness biases, flow models yield plausible outputs even for off-manifold conditions, resulting in silent failures indistinguishable from valid predictions. In this work, we introduce Diverging Flows, a novel approach that enables a single model to simultaneously perform conditional generation and native extrapolation detection by structurally enforcing inefficient transport for off-manifold inputs. We evaluate our method on synthetic manifolds, cross-domain style transfer, and weather temperature forecasting, demonstrating that it achieves effective detection of extrapolations without compromising predictive fidelity or inference latency. These results establish Diverging Flows as a robust solution for trustworthy flow models, paving the way for reliable deployment in domains such as medicine, robotics, and climate science.

</details>


### [173] [Probabilistic Wind Power Forecasting with Tree-Based Machine Learning and Weather Ensembles](https://arxiv.org/abs/2602.13010)
*Max Bruninx,Diederik van Binsbergen,Timothy Verstraeten,Ann Nowé,Jan Helsen*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate production forecasts are essential to continue facilitating the integration of renewable energy sources into the power grid. This paper illustrates how to obtain probabilistic day-ahead forecasts of wind power generation via gradient boosting trees using an ensemble of weather forecasts. To this end, we perform a comparative analysis across three state-of-the-art probabilistic prediction methods-conformalised quantile regression, natural gradient boosting and conditional diffusion models-all of which can be combined with tree-based machine learning. The methods are validated using four years of data for all wind farms present within the Belgian offshore zone. Additionally, the point forecasts are benchmarked against deterministic engineering methods, using either the power curve or an advanced approach incorporating a calibrated analytical wake model. The experimental results show that the machine learning methods improve the mean absolute error by up to 53% and 33% compared to the power curve and the calibrated wake model. Considering the three probabilistic prediction methods, the conditional diffusion model is found to yield the best overall probabilistic and point estimate of wind power generation. Moreover, the findings suggest that the use of an ensemble of weather forecasts can improve point forecast accuracy by up to 23%.

</details>


### [174] [Bus-Conditioned Zero-Shot Trajectory Generation via Task Arithmetic](https://arxiv.org/abs/2602.13071)
*Shuai Liu,Ning Cao,Yile Chen,Yue Jiang,Gao Cong*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Mobility trajectory data provide essential support for smart city applications. However, such data are often difficult to obtain. Meanwhile, most existing trajectory generation methods implicitly assume that at least a subset of real mobility data from target city is available, which limits their applicability in data-inaccessible scenarios. In this work, we propose a new problem setting, called bus-conditioned zero-shot trajectory generation, where no mobility trajectories from a target city are accessible. The generation process relies solely on source city mobility data and publicly available bus timetables from both cities. Under this setting, we propose MobTA, the first approach to introduce task arithmetic into trajectory generation. MobTA models the parameter shift from bus-timetable-based trajectory generation to mobility trajectory generation in source city, and applies this shift to target city through arithmetic operations on task vectors. This enables trajectory generation that reflects target-city mobility patterns without requiring any real mobility data from it. Furthermore, we theoretically analyze MobTA's stability across base and instruction-tuned LLMs. Extensive experiments show that MobTA significantly outperforms existing methods, and achieves performance close to models finetuned using target city mobility trajectories.

</details>


### [175] [EXCODER: EXplainable Classification Of DiscretE time series Representations](https://arxiv.org/abs/2602.13087)
*Yannik Hahn,Antonin Königsfeld,Hasan Tercan,Tobias Meisen*

Main category: cs.LG

TL;DR: 离散潜在表示（如VQ-VAE和DVAE）不仅保持时间序列分类性能，还能增强可解释性，通过压缩数据减少冗余，使XAI方法生成更简洁、结构化的解释。论文还提出了SSA指标来量化评估XAI识别特征与训练数据标签分布的一致性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在时间序列分类中表现出色，但模型缺乏可解释性是一个主要挑战。现有的XAI方法在处理高维、噪声的原始时间序列数据时效果有限。本文探讨通过将时间序列转换为离散潜在表示是否能增强可解释性，同时保持分类性能。

Method: 使用VQ-VAE和DVAE将时间序列转换为离散潜在表示，然后在这些压缩表示上应用XAI方法生成解释。提出了新的评估指标Similar Subsequence Accuracy (SSA)，用于量化XAI识别的重要子序列与训练数据标签分布之间的一致性。

Result: 研究表明，离散潜在表示不仅保留了分类所需的关键特征，还能产生更紧凑、可解释且计算高效的XAI解释。SSA指标能有效验证XAI方法突出显示的feature是否真正代表了学习到的分类模式。

Conclusion: 离散潜在表示为时间序列分析提供了既能保持分类性能，又能增强可解释性的有效途径。这种方法通过减少数据冗余，使XAI解释更加简洁和结构化，SSA指标则为评估解释质量提供了系统化的量化方法。

Abstract: Deep learning has significantly improved time series classification, yet the lack of explainability in these models remains a major challenge. While Explainable AI (XAI) techniques aim to make model decisions more transparent, their effectiveness is often hindered by the high dimensionality and noise present in raw time series data. In this work, we investigate whether transforming time series into discrete latent representations-using methods such as Vector Quantized Variational Autoencoders (VQ-VAE) and Discrete Variational Autoencoders (DVAE)-not only preserves but enhances explainability by reducing redundancy and focusing on the most informative patterns. We show that applying XAI methods to these compressed representations leads to concise and structured explanations that maintain faithfulness without sacrificing classification performance. Additionally, we propose Similar Subsequence Accuracy (SSA), a novel metric that quantitatively assesses the alignment between XAI-identified salient subsequences and the label distribution in the training data. SSA provides a systematic way to validate whether the features highlighted by XAI methods are truly representative of the learned classification patterns. Our findings demonstrate that discrete latent representations not only retain the essential characteristics needed for classification but also offer a pathway to more compact, interpretable, and computationally efficient explanations in time series analysis.

</details>


### [176] [Resource-Efficient Gesture Recognition through Convexified Attention](https://arxiv.org/abs/2602.13030)
*Daniel Schwartz,Dario Salvucci,Yusuf Osmanlioglu,Richard Vallett,Genevieve Dion,Ali Shokoufandeh*

Main category: cs.LG

TL;DR: 该论文提出了一种用于可穿戴电子织物界面的凸化注意力机制，通过非扩张单纯形投影和凸损失函数动态加权特征，在极低参数需求（120-360个参数）下实现了100%的手势识别准确率。


<details>
  <summary>Details</summary>
Motivation: 可穿戴电子织物界面需要手势识别功能，但面临功耗、计算能力和尺寸的严格限制，传统深度学习方法在这些约束下不实用。现有的轻量级架构仍需要数千参数，难以部署在织物集成平台上。

Method: 通过使用欧几里得投影到概率单纯形和多类别铰链损失代替传统的非凸softmax操作，设计了凸化注意力机制。该方法在仅四个连接点的纺织电容传感器上实现，通过保持凸性确保全局收敛性。

Result: 在点击手势和滑动手势上均获得100.00%准确率，参数需求减少97%（仅120-360个参数），推理时间亚毫秒级（290-296μs），存储需求小于7KB。在单用户数据集和受控实验室条件下的评估表明基础手势交互的可行性。

Conclusion: 凸优化方法能为纺织界面实现高效的端侧机器学习，但真实环境部署需要更多用户、环境条件和复杂手势词汇的验证。

Abstract: Wearable e-textile interfaces require gesture recognition capabilities but face severe constraints in power consumption, computational capacity, and form factor that make traditional deep learning impractical. While lightweight architectures like MobileNet improve efficiency, they still demand thousands of parameters, limiting deployment on textile-integrated platforms. We introduce a convexified attention mechanism for wearable applications that dynamically weights features while preserving convexity through nonexpansive simplex projection and convex loss functions. Unlike conventional attention mechanisms using non-convex softmax operations, our approach employs Euclidean projection onto the probability simplex combined with multi-class hinge loss, ensuring global convergence guarantees. Implemented on a textile-based capacitive sensor with four connection points, our approach achieves 100.00\% accuracy on tap gestures and 100.00\% on swipe gestures -- consistent across 10-fold cross-validation and held-out test evaluation -- while requiring only 120--360 parameters, a 97\% reduction compared to conventional approaches. With sub-millisecond inference times (290--296$μ$s) and minimal storage requirements ($<$7KB), our method enables gesture interfaces directly within e-textiles without external processing. Our evaluation, conducted in controlled laboratory conditions with a single-user dataset, demonstrates feasibility for basic gesture interactions. Real-world deployment would require validation across multiple users, environmental conditions, and more complex gesture vocabularies. These results demonstrate how convex optimization can enable efficient on-device machine learning for textile interfaces.

</details>


### [177] [TCRL: Temporal-Coupled Adversarial Training for Robust Constrained Reinforcement Learning in Worst-Case Scenarios](https://arxiv.org/abs/2602.13040)
*Wentao Xu,Zhongming Yao,Weihao Li,Zhenghang Song,Yumeng Song,Tianyi Li,Yushuai Li*

Main category: cs.LG

TL;DR: 提出了TCRL框架，针对现有CRL方法缺乏对时间耦合扰动鲁棒性的问题，通过最坏情况感知成本约束和双约束防御机制，提升了在时间耦合攻击下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒CRL方法主要关注单步扰动和时间独立对抗模型，缺乏对时间耦合扰动的显式建模，这限制了在安全关键领域的实际应用。

Method: TCRL框架包含：1. 最坏情况感知成本约束函数，用于估计时间耦合扰动下的安全成本；2. 奖励上的双约束防御机制，对抗时间耦合对手同时保持奖励不可预测性

Result: 实验结果显示，TCRL在各种CRL任务中，对时间耦合扰动攻击的鲁棒性持续优于现有方法。

Conclusion: TCRL框架有效解决了当前CRL方法处理时间耦合扰动能力的不足，为安全关键领域的决策优化提供了更可靠的鲁棒约束强化学习方法。

Abstract: Constrained Reinforcement Learning (CRL) aims to optimize decision-making policies under constraint conditions, making it highly applicable to safety-critical domains such as autonomous driving, robotics, and power grid management. However, existing robust CRL approaches predominantly focus on single-step perturbations and temporally independent adversarial models, lacking explicit modeling of robustness against temporally coupled perturbations. To tackle these challenges, we propose TCRL, a novel temporal-coupled adversarial training framework for robust constrained reinforcement learning (TCRL) in worst-case scenarios. First, TCRL introduces a worst-case-perceived cost constraint function that estimates safety costs under temporally coupled perturbations without the need to explicitly model adversarial attackers. Second, TCRL establishes a dual-constraint defense mechanism on the reward to counter temporally coupled adversaries while maintaining reward unpredictability. Experimental results demonstrate that TCRL consistently outperforms existing methods in terms of robustness against temporally coupled perturbation attacks across a variety of CRL tasks.

</details>


### [178] [GPTZero: Robust Detection of LLM-Generated Texts](https://arxiv.org/abs/2602.13042)
*George Alexandru Adam,Alexander Cui,Edwin Thomas,Emily Napier,Nazar Shmatko,Jacob Schnell,Jacob Junqi Tian,Alekhya Dronavalli,Edward Tian,Dongwon Lee*

Main category: cs.LG

TL;DR: GPTZero 是一个先进的AI文本检测解决方案，专门用于区分人类撰写与AI生成的文本，解决由大型语言模型引发的文本真实性挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的普及，AI生成文本带来了新的挑战，包括影响技能评估、产生低质量内容以及传播错误信息，需要可靠工具来区分人类与AI生成的文本。

Method: 采用分层多任务架构，支持灵活的人类与AI文本分类；通过多层级自动化红队测试提高对抗攻击和改写文本的鲁棒性；提供可解释的检测结果。

Result: 在多种领域的文本上实现了最先进的检测准确性，能够提供细粒度预测，并且在对抗攻击和文本改写方面表现出卓越的鲁棒性。

Conclusion: GPTZero 是一个准确且可解释的AI检测工具，能够教育和引导用户负责任地使用，确保文本评估的公平性和透明度，为解决AI生成文本带来的挑战提供了有效方案。

Abstract: While historical considerations surrounding text authenticity revolved primarily around plagiarism, the advent of large language models (LLMs) has introduced a new challenge: distinguishing human-authored from AI-generated text. This shift raises significant concerns, including the undermining of skill evaluations, the mass-production of low-quality content, and the proliferation of misinformation. Addressing these issues, we introduce GPTZero a state-of-the-art industrial AI detection solution, offering reliable discernment between human and LLM-generated text. Our key contributions include: introducing a hierarchical, multi-task architecture enabling a flexible taxonomy of human and AI texts, demonstrating state-of-the-art accuracy on a variety of domains with granular predictions, and achieving superior robustness to adversarial attacks and paraphrasing via multi-tiered automated red teaming. GPTZero offers accurate and explainable detection, and educates users on its responsible use, ensuring fair and transparent assessment of text.

</details>


### [179] [Quantization-Aware Collaborative Inference for Large Embodied AI Models](https://arxiv.org/abs/2602.13052)
*Zhonghao Lyu,Ming Xiao,Mikael Skoglund,Merouane Debbah,H. Vincent Poor*

Main category: cs.LG

TL;DR: 该论文研究了面向具身AI系统的大规模AI模型量化感知协同推理问题，通过量化诱导推理失真的近似方法、率失真边界理论分析，以及联合量化比特宽与计算频率优化设计，实现了在资源受限边缘设备上平衡推理质量、延迟和能耗的目标。


<details>
  <summary>Details</summary>
Motivation: 大规模AI模型作为具身AI应用的核心智能引擎，其庞大的参数量和高计算需求给资源受限的具身智能体带来了重大挑战。为解决这一问题，研究量化感知的协同推理方法具有重要意义。

Method: 1）开发了量化诱导推理失真的可处理近似方法
2）推导了率失真函数的上下界，刻画其与LAIM统计特性和量化比特宽的关系
3）在延迟和能量约束下，构建了联合量化比特宽和计算频率优化问题，以最小化失真上界并通过对应下界确保紧致性

Result: 广泛评估验证了所提出的失真近似方法、推导的率失真边界以及联合设计的有效性。仿真和真实测试平台实验均证明该联合设计能在边缘具身AI系统中有效平衡推理质量、延迟和能耗。

Conclusion: 该研究为资源受限的具身AI系统提供了一种有效的量化感知协同推理解决方案，通过理论分析和优化设计实现了大规模AI模型在边缘设备上的高效部署与应用。

Abstract: Large artificial intelligence models (LAIMs) are increasingly regarded as a core intelligence engine for embodied AI applications. However, the massive parameter scale and computational demands of LAIMs pose significant challenges for resource-limited embodied agents. To address this issue, we investigate quantization-aware collaborative inference (co-inference) for embodied AI systems. First, we develop a tractable approximation for quantization-induced inference distortion. Based on this approximation, we derive lower and upper bounds on the quantization rate-inference distortion function, characterizing its dependence on LAIM statistics, including the quantization bit-width. Next, we formulate a joint quantization bit-width and computation frequency design problem under delay and energy constraints, aiming to minimize the distortion upper bound while ensuring tightness through the corresponding lower bound. Extensive evaluations validate the proposed distortion approximation, the derived rate-distortion bounds, and the effectiveness of the proposed joint design. Particularly, simulations and real-world testbed experiments demonstrate the effectiveness of the proposed joint design in balancing inference quality, latency, and energy consumption in edge embodied AI systems.

</details>


### [180] [Memory-Efficient Structured Backpropagation for On-Device LLM Fine-Tuning](https://arxiv.org/abs/2602.13069)
*Juneyoung Park,Yuri Hong,Seongwan Kim,Jaeho Lee*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: On-device fine-tuning enables privacy-preserving personalization of large language models, but mobile devices impose severe memory constraints, typically 6--12GB shared across all workloads. Existing approaches force a trade-off between exact gradients with high memory (MeBP) and low memory with noisy estimates (MeZO). We propose Memory-efficient Structured Backpropagation (MeSP), which bridges this gap by manually deriving backward passes that exploit LoRA's low-rank structure. Our key insight is that the intermediate projection $h = xA$ can be recomputed during backward at minimal cost since rank $r \ll d_{in}$, eliminating the need to store it. MeSP achieves 49\% average memory reduction compared to MeBP on Qwen2.5 models (0.5B--3B) while computing mathematically identical gradients. Our analysis also reveals that MeZO's gradient estimates show near-zero correlation with true gradients (cosine similarity $\approx$0.001), explaining its slow convergence. MeSP reduces peak memory from 361MB to 136MB for Qwen2.5-0.5B, enabling fine-tuning scenarios previously infeasible on memory-constrained devices.

</details>


### [181] [LCSB: Layer-Cyclic Selective Backpropagation for Memory-Efficient On-Device LLM Fine-Tuning](https://arxiv.org/abs/2602.13073)
*Juneyoung Park,Eunbeen Yoon,Seongwan Kim. Jaeho Lee*

Main category: cs.LG

TL;DR: 提出Layer-Cyclic Selective Backpropagation（LCSB）方法，通过每步仅计算部分层的梯度来加速内存高效的反向传播，并在4位量化设置中表现出更好的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的内存高效反向传播（MeBP）虽然能在小于1GB内存的移动设备上微调大语言模型，但需要在每一步通过所有Transformer层进行反向计算，其中权重解压就占了反向传播时间的32-42%，效率仍有提升空间。

Method: 基于残差连接保证恒等路径的梯度流以及AdamW动量对非选择层提供隐式更新这一关键洞察，提出LCSB方法，将其解释为LoRA参数空间上的块坐标下降，并通过实验验证了其有效性。

Result: 在五个模型和三个任务上的实验表明，LCSB实现了最高1.40倍的加速，且质量下降不到2%。在4位量化设置中，一个3B模型在全反向传播中完全发散，而使用LCSB却能平稳收敛，显示出选择性梯度计算具有隐式正则化效果。

Conclusion: LCSB不仅显著提升了反向传播效率，还在4位量化等低精度环境中展现出了优于全反向传播的稳定性，这为大语言模型在资源受限设备上的高效微调提供了有价值的改进思路。

Abstract: Memory-efficient backpropagation (MeBP) has enabled first-order fine-tuning of large language models (LLMs) on mobile devices with less than 1GB memory. However, MeBP requires backward computation through all transformer layers at every step, where weight decompression alone accounts for 32--42% of backward time. We propose Layer-Cyclic Selective Backpropagation (LCSB), which computes gradients for only a subset of layers per step. Our key insight is that residual connections guarantee gradient flow through identity paths, while AdamW momentum provides implicit updates for non-selected layers. We interpret LCSB as Block Coordinate Descent on the LoRA parameter space, providing theoretical justification for convergence. LCSB achieves up to 1.40$\times$ speedup with less than 2\% quality degradation across five models and three tasks. Surprisingly, in 4-bit quantized settings, LCSB exhibits superior stability: a 3B model that completely diverges under full backpropagation converges smoothly with LCSB, suggesting an implicit regularization effect from selective gradient computation.

</details>


### [182] [Unified Multi-Domain Graph Pre-training for Homogeneous and Heterogeneous Graphs via Domain-Specific Expert Encoding](https://arxiv.org/abs/2602.13075)
*Chundong Liang,Yongqi Huang,Dongxiao He,Peiyuan Li,Yawen Li,Di Jin,Weixiong Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Graph pre-training has achieved remarkable success in recent years, delivering transferable representations for downstream adaptation. However, most existing methods are designed for either homogeneous or heterogeneous graphs, thereby hindering unified graph modeling across diverse graph types. This separation contradicts real-world applications, where mixed homogeneous and heterogeneous graphs are ubiquitous, and distribution shifts between upstream pre-training and downstream deployment are common. In this paper, we empirically demonstrate that a balanced mixture of homogeneous and heterogeneous graph pre-training benefits downstream tasks and propose a unified multi-domain \textbf{G}raph \textbf{P}re-training method across \textbf{H}omogeneous and \textbf{H}eterogeneous graphs ($\mathbf{GPH^{2}}$). To address the lack of a unified encoder for homogeneous and heterogeneous graphs, we propose a Unified Multi-View Graph Construction that simultaneously encodes both without explicit graph-type-specific designs. To cope with the increased cross-domain distribution discrepancies arising from mixed graphs, we introduce domain-specific expert encoding. Each expert is independently pre-trained on a single graph to capture domain-specific knowledge, thereby shielding the pre-training encoder from the adverse effects of cross-domain discrepancies. For downstream tasks, we further design a Task-oriented Expert Fusion Strategy that adaptively integrates multiple experts based on their discriminative strengths. Extensive experiments on mixed graphs demonstrate that $\text{GPH}^{2}$ enables stable transfer across graph types and domains, significantly outperforming existing graph pre-training methods.

</details>


### [183] [R-Diverse: Mitigating Diversity Illusion in Self-Play LLM Training](https://arxiv.org/abs/2602.13103)
*Gengsheng Li,Jinghan He,Shijie Wang,Dan Zhang,Ruiqi Liu,Renrui Zhang,Zijun Yao,Junfeng Fang,Haiyun Guo,Jinqiao Wang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Self-play bootstraps LLM reasoning through an iterative Challenger-Solver loop: the Challenger is trained to generate questions that target the Solver's capabilities, and the Solver is optimized on the generated data to expand its reasoning skills. However, existing frameworks like R-Zero often exhibit non-sustained improvement, where early gains degrade as self-play continues. We identify a key failure mode, Diversity Illusion, where the Solver's training signals appear diverse yet collapse into recurring underlying patterns. It manifests as (1) Local Diversity Illusion, where diversity is enforced only within-batch, inducing cross-iteration mode cycling; and (2) Surface Diversity Illusion, where questions vary superficially but require near-identical reasoning skills. To mitigate them, we propose R-Diverse with two aligned innovations: Memory-Augmented Penalty (MAP), which uses a persistent memory bank to discourage recycling across iterations, and Skill-Aware Measurement (SAM), which evaluates diversity by the reasoning skills exercised rather than surface variation of questions. Across 10 math and general reasoning benchmarks, R-Diverse sustains gains over more iterations and consistently outperforms prior self-play methods. Code is available at https://github.com/Gengsheng-Li/R-Diverse.

</details>


### [184] [Order Matters in Retrosynthesis: Structure-aware Generation via Reaction-Center-Guided Discrete Flow Matching](https://arxiv.org/abs/2602.13136)
*Chenguang Wang,Zihan Zhou,Lei Bai,Tianshu Yu*

Main category: cs.LG

TL;DR: 这篇论文提出了一个基于结构感知的无模板逆合成框架，利用原子位置编码的归纳偏置来提升学习效率，在USPTO数据集上实现了SOTA性能，且模型参数量远小于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统无模板方法将逆合成为黑箱序列生成，学习效率低；半模板方法依赖刚性反应库，泛化能力受限。研究发现的原子排列顺序在神经表示中的重要性为解决这一瓶颈提供了新思路。

Method: 提出结构感知的无模板框架，将化学反应的两阶段特性编码为位置归纳偏置，使反应中心原子位于序列头部。采用带有旋转位置嵌入的图变换器（RetroDiT）作为主干，结合离散流匹配实现快速生成（20-50步 vs 传统扩散方法的500步）。

Result: 在USPTO-50k上达到61.2% top-1准确率（USPTO-Full为51.3%）；使用真实反应中心时分别提升至71.1%和63.4%，超越基于百亿反应训练的基础模型。消融实验显示结构先验优于暴力扩增：28万参数模型通过合理排序即可达到6500万参数无序模型的性能。

Conclusion: 化学结构先验（特别是原子排序）能显著提升逆合成模型的效率与性能，为数据高效学习提供了新范式，证实了合理利用化学先验比单纯扩大模型规模更有效。

Abstract: Template-free retrosynthesis methods treat the task as black-box sequence generation, limiting learning efficiency, while semi-template approaches rely on rigid reaction libraries that constrain generalization. We address this gap with a key insight: atom ordering in neural representations matters. Building on this insight, we propose a structure-aware template-free framework that encodes the two-stage nature of chemical reactions as a positional inductive bias. By placing reaction center atoms at the sequence head, our method transforms implicit chemical knowledge into explicit positional patterns that the model can readily capture. The proposed RetroDiT backbone, a graph transformer with rotary position embeddings, exploits this ordering to prioritize chemically critical regions. Combined with discrete flow matching, our approach decouples training from sampling and enables generation in 20--50 steps versus 500 for prior diffusion methods. Our method achieves state-of-the-art performance on both USPTO-50k (61.2% top-1) and the large-scale USPTO-Full (51.3% top-1) with predicted reaction centers. With oracle centers, performance reaches 71.1% and 63.4% respectively, surpassing foundation models trained on 10 billion reactions while using orders of magnitude less data. Ablation studies further reveal that structural priors outperform brute-force scaling: a 280K-parameter model with proper ordering matches a 65M-parameter model without it.

</details>


### [185] [FlashSchNet: Fast and Accurate Coarse-Grained Neural Network Molecular Dynamics](https://arxiv.org/abs/2602.13140)
*Pingzhi Li,Hongxuan Li,Zirui Liu,Xingcheng Lin,Tianlong Chen*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Graph neural network (GNN) potentials such as SchNet improve the accuracy and transferability of molecular dynamics (MD) simulation by learning many-body interactions, but remain slower than classical force fields due to fragmented kernels and memory-bound pipelines that underutilize GPUs. We show that a missing principle is making GNN-MD IO-aware, carefully accounting for reads and writes between GPU high-bandwidth memory (HBM) and on-chip SRAM. We present FlashSchNet, an efficient and accurate IO-aware SchNet-style GNN-MD framework built on four techniques: (1) flash radial basis, which fuses pairwise distance computation, Gaussian basis expansion, and cosine envelope into a single tiled pass, computing each distance once and reusing it across all basis functions; (2) flash message passing, which fuses cutoff, neighbor gather, filter multiplication, and reduction to avoid materializing edge tensors in HBM; (3) flash aggregation, which reformulates scatter-add via CSR segment reduce, reducing atomic writes by a factor of feature dimension and enabling contention-free accumulation in both forward and backward passes; (4) channel-wise 16-bit quantization that exploits the low per-channel dynamic range in SchNet MLP weights to further improve throughput with negligible accuracy loss. On a single NVIDIA RTX PRO 6000, FlashSchNet achieves 1000 ns/day aggregate simulation throughput over 64 parallel replicas on coarse-grained (CG) protein containing 269 beads (6.5x faster than CGSchNet baseline with 80% reduction of peak memory), surpassing classical force fields (e.g. MARTINI) while retaining SchNet-level accuracy and transferability.

</details>


### [186] [Quantization-Robust LLM Unlearning via Low-Rank Adaptation](https://arxiv.org/abs/2602.13151)
*João Vitor Boer Abitante,Joana Meneguzzo Pasquali,Luan Fonseca Garcia,Ewerton de Oliveira,Thomas da Silva Paula,Rodrigo C. Barros,Lucas S. Kupssinskü*

Main category: cs.LG

TL;DR: LLM忘记学习后进行低比特量化会掩盖遗忘更新的效果，导致模型恢复原始行为；使用LoRA进行量化鲁棒的遗忘学习能保持有效更新，提高量化后模型的实用性和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 大语言模型遗忘学习旨在移除特定知识，但实际部署需要后训练量化以提高推理效率。然而，激进的低比特量化会掩盖或抹除遗忘更新，导致量化模型恢复未遗忘前的行为。标准全参数微调产生的参数变化太小，在4位量化下难以保留。

Method: 提出基于低秩适配器（LoRA）的量化鲁棒遗忘学习方法：冻结基础模型，将遗忘学习集中在可训练适配器中，确保有效更新在量化后得以保留。在Llama-2-7B模型上使用MUSE数据集进行评估。

Result: 在BOOKS和NEWS数据集上，LoRA将4位量化的效用最多提高了7.93个点。同时显著减少了4位量化后的隐私泄漏，使隐私指标更接近理想值0，同时保持良好的遗忘效果。

Conclusion: 在需要量化部署的场景中，使用LoRA进行机器遗忘学习是有益的，能够保持量化后的实用性和隐私保护效果。

Abstract: Large Language Model (LLM) unlearning aims to remove targeted knowledge from a trained model, but practical deployments often require post-training quantization (PTQ) for efficient inference. However, aggressive low-bit PTQ can mask or erase unlearning updates, causing quantized models to revert to pre-unlearning behavior. We show that standard full-parameter fine-tuning often induce parameter changes that are too small to survive 4-bit quantization. We propose quantization-robust unlearning via low-rank adaptation (LoRA): we freeze the base model and concentrate unlearning into trainable adapters so that the effective update is preserved after quantization. On Llama-2-7B evaluated with MUSE dataset (BOOKS and NEWS), LoRA improves 4-bit utility by up to 7.93 points (NPO+GDR on BOOKS: 50.17 to 58.10) and yields higher 4-bit utility on NEWS for GA+GDR (40.06 to 44.82, increase of 4.76). LoRA also substantially reduces privacy leakage under 4-bit PTQ, e.g., for GA+KLR on BOOKS, PrivLeak moves from -25.68 to -5.86 (closer to ideal 0), while maintaining strong forgetting (VerMem and KnowMem near 0). Thus, using LoRA for Machine Unlearning is beneficial for scenarios where quantization is necessary for model deployment.

</details>


### [187] [Learning to Approximate Uniform Facility Location via Graph Neural Networks](https://arxiv.org/abs/2602.13155)
*Chendi Qian,Christopher Morris,Stefanie Jegelka,Christian Sohler*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: There has been a growing interest in using neural networks, especially message-passing neural networks (MPNNs), to solve hard combinatorial optimization problems heuristically. However, existing learning-based approaches for hard combinatorial optimization tasks often rely on supervised training data, reinforcement learning, or gradient estimators, leading to significant computational overhead, unstable training, or a lack of provable performance guarantees. In contrast, classical approximation algorithms offer such performance guarantees under worst-case inputs but are non-differentiable and unable to adaptively exploit structural regularities in natural input distributions. We address this dichotomy with the fundamental example of Uniform Facility Location (UniFL), a variant of the combinatorial facility location problem with applications in clustering, data summarization, logistics, and supply chain design. We develop a fully differentiable MPNN model that embeds approximation-algorithmic principles while avoiding the need for solver supervision or discrete relaxations. Our approach admits provable approximation and size generalization guarantees to much larger instances than seen during training. Empirically, we show that our approach outperforms standard non-learned approximation algorithms in terms of solution quality, closing the gap with computationally intensive integer linear programming approaches. Overall, this work provides a step toward bridging learning-based methods and approximation algorithms for discrete optimization.

</details>


### [188] [Learning functional components of PDEs from data using neural networks](https://arxiv.org/abs/2602.13174)
*Torkel E. Loman,Yurij Salmaniw,Antonio Leon Villares,Jose A. Carrillo,Ruth E. Baker*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Partial differential equations often contain unknown functions that are difficult or impossible to measure directly, hampering our ability to derive predictions from the model. Workflows for recovering scalar PDE parameters from data are well studied: here we show how similar workflows can be used to recover functions from data. Specifically, we embed neural networks into the PDE and show how, as they are trained on data, they can approximate unknown functions with arbitrary accuracy. Using nonlocal aggregation-diffusion equations as a case study, we recover interaction kernels and external potentials from steady state data. Specifically, we investigate how a wide range of factors, such as the number of available solutions, their properties, sampling density, and measurement noise, affect our ability to successfully recover functions. Our approach is advantageous because it can utilise standard parameter-fitting workflows, and in that the trained PDE can be treated as a normal PDE for purposes such as generating system predictions.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [189] [Channel Gain Map Reconstruction Based on Virtual Scatterer Model](https://arxiv.org/abs/2602.12602)
*He Sun,Lipeng Zhu,Jie Xu,Rui Zhang*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes an efficient method for modeling and reconstructing the channel gain map (CGM) based on virtual scatterers. Specifically, we develop a virtual scatterer model to characterize the channel power gain distribution in three-dimensional (3D) space, by capturing the multi-path propagation environment structure and exploiting the angular-domain spatial correlation of scatterer response. In this model, the CGM is represented as a function over a set of tunable parameters for virtual scatterers, including their number, positions, and scatterer response coefficients (SRCs), which can be estimated from a limited number of channel power gain measurements at a given set of locations within the region of interest. This new representation offers a flexible and scalable modeling framework for efficient and accurate CGM reconstruction. Furthermore, we propose a progressive estimation algorithm to acquire the scatterers' parameters. In this algorithm, we gradually increase the number of virtual scatterers to balance the computational complexity and estimation accuracy. In addition, by exploiting the spatial correlation of scatterer response, we propose a Gaussian process regression (GPR)-based inference method to predict the SRCs that cannot be directly estimated. Finally, ray-tracing-based simulation results under realistic physical environments validate the effectiveness of the proposed method, demonstrating that it achieves higher reconstruction accuracy compared to conventional CGM estimation approaches.

</details>


### [190] [Secure Beamforming for ISAC Systems Under Communication Eavesdropper and Sensing Eavesdropper](https://arxiv.org/abs/2602.12614)
*Tian Zhang,Zhirong Su,Yueyi Dong*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Due to great efficiency improvement in resource and hardware space, integrated sensing and communication (ISAC) has gained much attention. In the paper, the physical layer security (PLS) of ISAC system under communication eavesdropper together with sensing eavesdropper is investigated. The system secrecy rate is maximized by transmit beamforming design of communication and sensing signals when taking sensing security, sensing performance and transmit power constraint into consideration. To deal with the formulated non-convex optimization problem, the successive convex approximation (SCA) together with the first-order Taylor expansion and semidefinite relaxation (SDR) is utilized. Additionally, it is theoretically validated that the SDR does not yield sub-optimality in the paper. Thereafter, an iterated joint secure beamforming algorithm against communication and sensing eavesdroppers is proposed. Simulation results validate the effectiveness and advance of the proposed scheme.

</details>


### [191] [Secrecy Capacity Analysis and Beamforming Optimization for MIMO-VLC Wiretap Channels](https://arxiv.org/abs/2602.12720)
*Sufang Yang,Longguang Li,Jintao Wang,Ya Li,Liang Xia,Hongjun He,Qixing Wang,Guangyi Liu*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates a multiple-input multipleoutput (MIMO) visible light communication (VLC) wiretap channel consisting of a transmitter, a legitimate receiver, and an eavesdropper. The optical input is subject to both peakand average-intensity constraints. By applying the generalized entropy-power inequality to truncated exponential inputs, we derive a novel closed-form expression for the achievable secrecy rate for general MIMO VLC configurations. To enhance transmission confidentiality, a fully-connected beamforming scheme is proposed, along with a low-complexity sub-connected alternative. Although the resulting beamforming design problems are nonconvex, they are efficiently addressed by transforming them into a sequence of convex subproblems solvable via the successive convex approximation framework. Numerical results demonstrate that the proposed schemes achieve significant secrecy performance improvements compared with the benchmark scheme.

</details>


### [192] [Construction of MRD Codes Based on Circular-Shift Operations](https://arxiv.org/abs/2602.12766)
*Zhe Zhai,Sheng Jin,Qifu Tyler Sun,Zongpeng Li*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Most well-known constructions of $(N \times n, q^{Nk}, d)$ maximum rank distance (MRD) codes rely on the arithmetic of $\mathbb{F}_{q^N}$, whose increasing complexity with larger $N$ hinders parameter selection and practical implementation. In this work, based on circular-shift operations, we present a construction of $(J \times n, q^{Jk}, d)$ MRD codes with efficient encoding, where $J$ equals to the Euler's totient function of a defined $L$ subject to $\gcd(q, L) = 1$. The proposed construction is performed entirely over $\mathbb{F}_q$ and avoids the arithmetic of $\mathbb{F}_{q^J}$. We further characterize the constructed MRD codes, Gabidulin codes and twisted Gabidulin codes using a set of $q$-linearized polynomials over the row vector space $\mathbb{F}_{q}^N$, and clarify their inherent difference and connection. For the case $J \neq m_L$, where $m_L$ denotes the multiplicative order of $q$ modulo $L$, we show that the proposed MRD codes, in a family of settings, are different from any Gabidulin code and any twisted Gabidulin code. For the case $J = m_L$, we prove that every constructed $(J \times n, q^{Jk}, d)$ MRD code coincides with a $(J \times n, q^{Jk}, d)$ Gabidulin code, yielding an equivalent circular-shift-based construction that operates directly over $\mathbb{F}_q$. In addition, we prove that under some parameter settings, the constructed MRD codes are equivalent to a generalization of Gabidulin codes obtained by summing and concatenating several $(m_L \times n, q^{m_Lk}, d)$ Gabidulin codes. When $q=2$, $L$ is prime and $n\leq m_L$, it is analyzed that generating a codeword of the proposed $((L-1) \times n, 2^{(L-1)k}, d)$ MRD codes requires $O(nkL)$ exclusive OR (XOR) operations, while generating a codeword of $((L-1) \times n, 2^{(L-1)k}, d)$ Gabidulin codes, based on customary construction, requires $O(nkL^2)$ XOR operations.

</details>


### [193] [FPNet: Joint Wi-Fi Beamforming Matrix Feedback and Anomaly-Aware Indoor Positioning](https://arxiv.org/abs/2602.12799)
*Ran Tao,Jiajia Guo,Yiming Cui,Xiangyi Li,Chao-Kai Wen,Shi Jin*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Channel State Information (CSI) provides a detailed description of the wireless channel and has been widely adopted for Wi-Fi sensing, particularly for high-precision indoor positioning. However, complete CSI is rarely available in real-world deployments due to hardware constraints and the high communication overhead required for feedback. Moreover, existing positioning models lack mechanisms to detect when users move outside their trained regions, leading to unreliable estimates in dynamic environments. In this paper, we present FPNet, a unified deep learning framework that jointly addresses channel feedback compression, accurate indoor positioning, and robust anomaly detection (AD). FPNet leverages the beamforming feedback matrix (BFM), a compressed CSI representation natively supported by IEEE 802.11ac/ax/be protocols, to minimize feedback overhead while preserving critical positioning features. To enhance reliability, we integrate ADBlock, a lightweight AD module trained on normal BFM samples, which identifies out-of-distribution scenarios when users exit predefined spatial regions. Experimental results using standard 2.4 GHz Wi-Fi hardware show that FPNet achieves positioning accuracy above 97% with only 100 feedback bits, boosts net throughput by up to 22.92%, and attains AD accuracy over 99% with a false alarm rate below 1.5%. These results demonstrate FPNet's ability to deliver efficient, accurate, and reliable indoor positioning on commodity Wi-Fi devices.

</details>


### [194] [Concatenated Codes for Short-Molecule DNA Storage with Sequencing Channels of Positive Zero-Undetected-Error Capacity](https://arxiv.org/abs/2602.12800)
*Ran Tamir,Nir Weinberger,Albert Guillén i Fàbregas*

Main category: cs.IT

TL;DR: 研究DNA存储系统中在噪声测序条件下的可靠信息存储容量，采用级联编码方案，外码处理随机采样，内码处理测序噪声，推导出可靠存储信息位数的可达边界。


<details>
  <summary>Details</summary>
Motivation: DNA作为存储介质具有高密度和长期保存潜力，但测序过程中的随机采样和噪声会影响可靠存储容量。本研究旨在量化在噪声测序条件下DNA存储系统能够可靠存储的信息量。

Method: 采用级联编码方案：外码处理DNA分子的随机采样，内码处理测序通道的随机噪声。假设测序通道对称，内码使用线性分组码结合零未检测错误解码器。通过最大似然解码器进行可分析性推导。

Result: 推导出可靠存储信息位数的可达边界缩放规律。独立证明：随机线性分组码在零未检测错误解码下的平均错误概率随块长指数收敛到零，只要编码率不超过作为零未检测错误容量下界的临界值。

Conclusion: 提出的级联编码方案为DNA存储系统的容量分析提供理论框架，证明了线性码在特定解码方案下的性能界限，为实际DNA存储系统设计提供理论基础。

Abstract: We study the amount of reliable information that can be stored in a DNA-based storage system with noisy sequencing, where each codeword is composed of short DNA molecules. We analyze a concatenated coding scheme, where the outer code is designed to handle the random sampling, while the inner code is designed to handle the random sequencing noise. We assume that the sequencing channel is symmetric and choose the inner coding scheme to be composed by a linear block code and a zero-undetected-error decoder. As a byproduct, the resulting optimal maximum-likelihood decoder land itself for an amenable analysis, and we are able to derive an achievability bound for the scaling of the number of information bits that can be reliably stored. As a result of independent interest, we prove that the average error probability of random linear block codes under zero-undetected-error decoding converges to zero exponentially fast with the block length, as long as its coding rate does not exceed some critical value, which is known to serve as a lower bound to the zero-undetected-error capacity.

</details>


### [195] [EARL: Energy-Aware Adaptive Antenna Control with Reinforcement Learning in O-RAN Cell-Free Massive MIMO Networks](https://arxiv.org/abs/2602.12841)
*Zilin Ge,Ozan Alp Topal,Irshad Ahmad Meer,Pei Xiao,Cicek Cavdar*

Main category: cs.IT

TL;DR: EARL是一个基于强化学习的能量感知自适应天线控制框架，用于减少MIMO系统中的能量消耗。


<details>
  <summary>Details</summary>
Motivation: 分布式大规模MIMO系统虽然提供高性能，但能耗较高，需要通过智能控制减少能量消耗。

Method: 采用强化学习动态配置天线元素，结合O-RAN资源共享能力，优化无线电、光前传和云端处理功耗。

Result: 相比全功率和启发式基准方法，分别实现高达81%和50%的节能，RL方法在220ms内完成，满足O-RAN近实时要求。

Conclusion: EARL能有效减少MIMO系统能耗，同时满足用户体验需求，贪婪优化能在更长时间内进一步减半功耗。

Abstract: Cell-free massive multi-input multi-output (MIMO) promises uniform high performance across the network, but also brings a high energy cost due to joint transmission from distributed radio units (RUs) and centralized processing in the cloud. Leveraging the resource-sharing capabilities of Open Radio Access Network (O-RAN), we propose EARL, an energy-aware adaptive antenna control framework based on reinforcement learning. EARL dynamically configures antenna elements in RUs to minimize radio, optical fronthaul, and cloud processing power consumption while meeting user spectral efficiency demands. Numerical results show power savings of up to 81% and 50% over full-on and heuristic baselines, respectively. The RL-based approach operates within 220 ms, satisfying O-RAN's near-real-time limit, and a greedy refinement further halves power consumption at a 2 s runtime.

</details>


### [196] [Model-Aware Rate-Distortion Limits for Task-Oriented Source Coding](https://arxiv.org/abs/2602.12866)
*Andriy Enttsel,Vincent Corlay*

Main category: cs.IT

TL;DR: 本文通过间接率失真理论，重新审视了任务导向信源编码在机器推理系统中的基本极限，发现现有率失真界限在现实场景中存在局限性，并提出了考虑任务模型次优性和架构约束的新界限。


<details>
  <summary>Details</summary>
Motivation: 传统的面向机器的率失真界限通常依赖于任务可辨识性的强假设，忽视了实际部署任务模型的影响，这导致理论界限与实际情况存在差距，需要更贴合实际系统的分析方法。

Method: 采用间接率失真理论框架，分析单任务TOSC的基本极限；提出考虑任务模型次优性和架构约束的新率失真界限；在标准分类基准上进行实验验证。

Result: 实验证实当前学习型TOSC方案与这些界限存在显著差距，揭示了发射端的计算复杂度是主要瓶颈；现有率失真界限在实际场景中难以实现。

Conclusion: 研究强调了在任务导向编码系统中考虑任务模型特性的重要性，发现了当前方法与理论极限的差距，并提出发射端复杂度是未来优化需要关注的关键方向。

Abstract: Task-Oriented Source Coding (TOSC) has emerged as a paradigm for efficient visual data communication in machine-centric inference systems, where bitrate, latency, and task performance must be jointly optimized under resource constraints. While recent works have proposed rate-distortion bounds for coding for machines, these results often rely on strong assumptions on task identifiability and neglect the impact of deployed task models. In this work, we revisit the fundamental limits of single-TOSC through the lens of indirect rate-distortion theory. We highlight the conditions under which existing rate-distortion bounds are achievable and show their limitations in realistic settings. We then introduce task model-aware rate-distortion bounds that account for task model suboptimality and architectural constraints. Experiments on standard classification benchmarks confirm that current learned TOSC schemes operate far from these limits, highlighting transmitter-side complexity as a key bottleneck.

</details>
