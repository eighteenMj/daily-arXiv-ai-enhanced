<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [DocLens : A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding](https://arxiv.org/abs/2511.11552)
*Dawei Zhu,Rui Meng,Jiefeng Chen,Sujian Li,Tomas Pfister,Jinsung Yoon*

Main category: cs.CV

TL;DR: DocLens是一个用于理解长视觉文档的增强多智能体框架，通过从整文档导航到具体视觉元素来解决证据定位问题，在多个基准测试中表现优异，甚至超越人类专家。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在处理跨多页文本和视觉元素的长文档时，面临证据定位的根本挑战：难以检索相关页面且忽略视觉元素中的细粒度细节，导致性能有限和模型幻觉。

Method: 提出DocLens工具增强多智能体框架，它通过"放大"证据来解决定位问题：首先从完整文档导航到相关页面上的具体视觉元素，然后采用采样-裁决机制生成单一可靠答案。

Result: 与Gemini-2.5-Pro配对后，DocLens在MMLongBench-Doc和FinRAGBench-V上实现了最先进的性能，甚至超越了人类专家，在视觉中心和不可回答的问题上表现尤为突出。

Conclusion: DocLens通过增强的定位能力展示了其强大性能，特别是在处理视觉中心查询和不可回答问题时，证明了其框架在长视觉文档理解方面的有效性。

Abstract: Comprehending long visual documents, where information is distributed across extensive pages of text and visual elements, is a critical but challenging task for modern Vision-Language Models (VLMs). Existing approaches falter on a fundamental challenge: evidence localization. They struggle to retrieve relevant pages and overlook fine-grained details within visual elements, leading to limited performance and model hallucination. To address this, we propose DocLens, a tool-augmented multi-agent framework that effectively ``zooms in'' on evidence like a lens. It first navigates from the full document to specific visual elements on relevant pages, then employs a sampling-adjudication mechanism to generate a single, reliable answer. Paired with Gemini-2.5-Pro, DocLens achieves state-of-the-art performance on MMLongBench-Doc and FinRAGBench-V, surpassing even human experts. The framework's superiority is particularly evident on vision-centric and unanswerable queries, demonstrating the power of its enhanced localization capabilities.

</details>
