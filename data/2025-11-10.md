<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 48]
- [cs.NI](#cs.NI) [Total: 3]
- [eess.IV](#eess.IV) [Total: 2]
- [cs.LG](#cs.LG) [Total: 56]
- [eess.SY](#eess.SY) [Total: 6]
- [cs.IT](#cs.IT) [Total: 2]
- [cs.AI](#cs.AI) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs](https://arxiv.org/abs/2511.04727)
*Ali Faraz,Akash,Shaharukh Khan,Raja Kolla,Akshat Patidar,Suranjan Goswami,Abhinav Ravi,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: 提出了一种新的基准测试IndicVisionBench，专门针对印度次大陆的多语言和多文化环境，以评估视觉-语言模型(VLM)的表现。该基准包括OCR、多模态翻译和视觉问答任务，涵盖了13个文化相关主题，提供了独特的语言文化偏见分析资源，并揭示了现有VLM在这类文化多样性环境中的性能限制。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型的评估基准大多集中于西方的文化背景，缺乏对多语言和多文化环境下的性能评估。本文旨在填补这一空白，通过建立IndicVisionBench基准测试来更好地理解这些模型在印度次大陆的文化和多语言环境中的表现情况。

Method: IndicVisionBench是一个多模态任务的评估基准，涉及OCR、多模态翻译和视觉问答，涵盖13个文化相关主题，并提供跨10种印度语的平行注释语料库，用以分析视觉-语言模型中的语言和文化偏差。

Result: 通过对8个模型的实验评估，发现这些模型在印度次大陆的文化多样性环境中存在显著的性能差距，揭示了现有VLM在此类环境中的局限性。

Conclusion: 通过聚焦于文化和语言多样性，IndicVisionBench建立了一个可重复的评估框架，为多模态研究的包容性发展提供了新的途径。

Abstract: Vision-language models (VLMs) have demonstrated impressive generalization
across multimodal tasks, yet most evaluation benchmarks remain Western-centric,
leaving open questions about their performance in culturally diverse and
multilingual settings. To address this gap, we introduce IndicVisionBench, the
first large-scale benchmark centered on the Indian subcontinent. Covering
English and 10 Indian languages, our benchmark spans 3 multimodal tasks,
including Optical Character Recognition (OCR), Multimodal Machine Translation
(MMT), and Visual Question Answering (VQA), covering 6 kinds of question types.
Our final benchmark consists of a total of ~5K images and 37K+ QA pairs across
13 culturally grounded topics. In addition, we release a paired parallel corpus
of annotations across 10 Indic languages, creating a unique resource for
analyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum
of 8 models, from proprietary closed-source systems to open-weights medium and
large-scale models. Our experiments reveal substantial performance gaps,
underscoring the limitations of current VLMs in culturally diverse contexts. By
centering cultural diversity and multilinguality, IndicVisionBench establishes
a reproducible evaluation framework that paves the way for more inclusive
multimodal research.

</details>


### [2] [CPO: Condition Preference Optimization for Controllable Image Generation](https://arxiv.org/abs/2511.04753)
*Zonglin Lyu,Ming Li,Xinxin Liu,Chen Chen*

Main category: cs.CV

TL;DR: 本文提出了Condition Preference Optimization (CPO) 方法，通过优选控制信号而非生成图像来优化模型的可控性，从而减少混淆因素，降低训练目标方差。实验表明，CPO 在多种控制类型上显著优于当前最佳的ControlNet++，尤其是在分割、人体姿态、边缘和深度图上。


<details>
  <summary>Details</summary>
Motivation: 传统的文本到图像生成模型在可控性上存在不足，ControlNet引入了基于图像的控制信号来提升控制力，但ControlNet++优化时忽略了高噪声时间步带来的贡献，并引入了额外的近似误差。直接偏好优化（DPO）则难以保证生成图像对的可控性差异，因此提出了基于控制条件的偏好学习方法CPO，以减少混淆因素。

Method: 通过构造胜者和败者控制信号$f{c}^{w}$和$f{c}^{l}$来训练模型偏好于胜者信号，这种方法比DPO降低了对比损失的方差，减少数据整理所需计算和存储资源，并且改善了可控性。

Result: 实验证明，CPO 在多个控制类型上显著改进了模型的可控性，例如在分割上错误率降低了$10	extbackslash	extbackslash%$以上，在人体姿态上提高了$70	extbackslash	extbackslash%--80	extbackslash	extbackslash%$，同时在边缘和深度图上保持了$2	extbackslash	extbackslash%--5	extbackslash	extbackslash%$的持续降低。

Conclusion: CPO 方法通过优选控制信号而非生成图像极大提升了模型的可控性，证明了模型在多个控制类型上的优越性，并且与DPO 相比降低了计算资源的需求和数据整理成本。

Abstract: To enhance controllability in text-to-image generation, ControlNet introduces
image-based control signals, while ControlNet++ improves pixel-level cycle
consistency between generated images and the input control signal. To avoid the
prohibitive cost of back-propagating through the sampling process, ControlNet++
optimizes only low-noise timesteps (e.g., $t < 200$) using a single-step
approximation, which not only ignores the contribution of high-noise timesteps
but also introduces additional approximation errors. A straightforward
alternative for optimizing controllability across all timesteps is Direct
Preference Optimization (DPO), a fine-tuning method that increases model
preference for more controllable images ($I^{w}$) over less controllable ones
($I^{l}$). However, due to uncertainty in generative models, it is difficult to
ensure that win--lose image pairs differ only in controllability while keeping
other factors, such as image quality, fixed. To address this, we propose
performing preference learning over control conditions rather than generated
images. Specifically, we construct winning and losing control signals,
$\mathbf{c}^{w}$ and $\mathbf{c}^{l}$, and train the model to prefer
$\mathbf{c}^{w}$. This method, which we term \textit{Condition Preference
Optimization} (CPO), eliminates confounding factors and yields a low-variance
training objective. Our approach theoretically exhibits lower contrastive loss
variance than DPO and empirically achieves superior results. Moreover, CPO
requires less computation and storage for dataset curation. Extensive
experiments show that CPO significantly improves controllability over the
state-of-the-art ControlNet++ across multiple control types: over $10\%$ error
rate reduction in segmentation, $70$--$80\%$ in human pose, and consistent
$2$--$5\%$ reductions in edge and depth maps.

</details>


### [3] [DARN: Dynamic Adaptive Regularization Networks for Efficient and Robust Foundation Model Adaptation](https://arxiv.org/abs/2511.04766)
*Dhenenjay Yadav,Rohan Sawai*

Main category: cs.CV

TL;DR: 本文提出了DARN，一种新型解码器架构，用于地理空间分析中的基础模型适应。它通过任务复杂性预测器、自适应丢弃率调制和动态容量门控提高模型性能。实验显示，在多种适应范式下，DARN均有显著效果提升，尤其是在少数类上的表现得到了增强。


<details>
  <summary>Details</summary>
Motivation: 现有关于基础模型适应技术多采用固定正则化策略，无法很好应对卫星图像中显著的异质性。这项研究旨在通过引入DARN解决这个问题，以实现更好的适应性和泛化性能。

Method: DARN整合了三个核心创新：1、一个轻量级的任务复杂性预测器，用于估计每个样本的难度；2、适应性丢弃率调制，根据预测的复杂性动态调整丢弃率；3、动态容量门控，用于调节通道激活。我们还提供了理论证明，将优化与稳定点收敛联系起来，并将机制与自适应信息瓶颈关联起来。

Result: 实验结果表明，无论是全模型微调还是高效适应，DARN都达到了新的SOTA性能。在全微调模式下，DARN在多任务GeoBench基准测试中取得了新SOTA性能(86.66% mIoU)，提高了5.56个百分点。在高效适应模式下，它既达到了SOTA兼容的准确率(90.5% mIoU)，又显著提升了迁移性能和其他关键指标，包括少类样本的识别能力。

Conclusion: DARN提供了一种更加智能、强壮、高效的策略，用于在关键地理空间应用程序中有效使用基础模型。

Abstract: Foundation models (FMs) offer powerful representations for geospatial
analysis, but adapting them effectively remains challenging. Standard
adaptation methods, whether full fine-tuning or efficient frozen-backbone
approaches, typically employ decoders with fixed regularization strategies,
failing to account for the significant heterogeneity in satellite imagery. We
introduce Dynamic Adaptive Regularization Networks (DARN), a novel decoder
architecture designed to address this limitation. DARN integrates three key
innovations: (1) a lightweight Task Complexity Predictor (TCP) that estimates
per-sample difficulty, (2) Adaptive Dropout Modulation (ADM), dynamically
adjusting dropout rates (from 0.1 to 0.5) based on predicted complexity, and
(3) Dynamic Capacity Gating (DCG) that modulates channel activation. We provide
theoretical justifications linking DARN's optimization to stationary point
convergence and its mechanism to adaptive information bottlenecks. Empirically,
DARN demonstrates exceptional performance across both major adaptation
paradigms. In full fine-tuning (unfrozen backbone), DARN achieves a new
state-of-the-art on the multi-task GeoBench benchmark (86.66% mIoU, +5.56 pp
over prior SOTA). In efficient adaptation (frozen backbone), DARN achieves
SOTA-competitive accuracy (90.5% mIoU on Sen1Floods11) while delivering
substantial advantages crucial for real-world deployment: superior
out-of-distribution (OOD) generalization (+9.5 pp mIoU on AI4SmallFarms),
enhanced robustness (17% relative reduction in corruption error), and improved
performance on minority classes. DARN offers a more intelligent, robust, and
efficient approach to leveraging FMs in critical geospatial applications.

</details>


### [4] [Global 3D Reconstruction of Clouds & Tropical Cyclones](https://arxiv.org/abs/2511.04773)
*Shirin Ermis,Cesar Aybar,Lilli Freischem,Stella Girtsou,Kyriaki-Margarita Bintsi,Emiliano Diaz Salas-Porras,Michael Eisinger,William Jones,Anna Jungbluth,Benoit Tremblay*

Main category: cs.CV

TL;DR: 该论文提出了一种基于预训练-微调流水线的新框架，利用全球覆盖的多卫星数据将2D卫星图像转换为3D云图，为预测热带气旋的结构和强度提供重要支持。


<details>
  <summary>Details</summary>
Motivation: 当前卫星观测对热带气旋结构的探测有限，难以精确预测；现有的机器学习方法在云重建方面局限性明显，不适用于频繁出现热带气旋的区域。因此，本文动机在于提出一种方法，用以改进3D云结构重建，特别是在飓风频发地区。

Method: 提出了一个基于预训练-微调流水线的新框架，该框架能利用全球覆盖的多卫星数据将2D卫星图像转换为包含了关键云属性的3D云图。此框架适用于频繁发生热带气旋的区域，有助于对飓风的结构进行精确重建。

Result: 论文首次能够在全球范围内即时创建3D云图，并能准确地重建强热带气旋的结构；此外，该模型在观测数据缺失时仍能提供关键云属性的估计。这些贡献有助于增进对热带气旋强度变化的理解，并有望改进预测准确性。

Conclusion: 文章所提方法可以有效解决现有技术在热带气旋预测中的局限性，提供了改进的技术手段以提高风暴强度预测的准确性，同时对于缺乏观测数据的情况也能提供有效的云属性估计。

Abstract: Accurate forecasting of tropical cyclones (TCs) remains challenging due to
limited satellite observations probing TC structure and difficulties in
resolving cloud properties involved in TC intensification. Recent research has
demonstrated the capabilities of machine learning methods for 3D cloud
reconstruction from satellite observations. However, existing approaches have
been restricted to regions where TCs are uncommon, and are poorly validated for
intense storms. We introduce a new framework, based on a
pre-training--fine-tuning pipeline, that learns from multiple satellites with
global coverage to translate 2D satellite imagery into 3D cloud maps of
relevant cloud properties. We apply our model to a custom-built TC dataset to
evaluate performance in the most challenging and relevant conditions. We show
that we can - for the first time - create global instantaneous 3D cloud maps
and accurately reconstruct the 3D structure of intense storms. Our model not
only extends available satellite observations but also provides estimates when
observations are missing entirely. This is crucial for advancing our
understanding of TC intensification and improving forecasts.

</details>


### [5] [Automatic segmentation of colorectal liver metastases for ultrasound-based navigated resection](https://arxiv.org/abs/2511.05253)
*Tiziano Natali,Karin A. Olthof,Niels F. M. Kok,Koert F. D. Kuhlmann,Theo J. M. Ruers,Matteo Fusaglia*

Main category: cs.CV

TL;DR: 本文介绍了一种用于自动分割结直肠肝转移瘤(CRLM)的3D U-Net模型，采用了nnU-Net框架并在不同的3D体内超声(iUS)数据集上进行了验证。实验结果显示，该模型尤其在裁剪肿瘤周围区域的数据上训练，比在完整体数据上训练的表现优秀，能够在保证精度的同时大幅提高处理速度，适用于实时的手术引导。这种方法为肝脏手术提供了一种高效的基于超声导航方案，且大幅减少了操作者的劳动，并缩短了手术时间。对实时手术中的精度和效率都达到了临床可接受的标准，可以作为专家级水平的手术辅助工具使用。


<details>
  <summary>Details</summary>
Motivation: 在手术过程中准确鉴定结直肠肝转移瘤(CRLM)对于实现无菌切缘至关重要，但是使用体内超声(iUS)时由于对比度低、噪声大和操作者依赖性问题，使得准确鉴定仍然具有挑战性。因此，自动分割可能提高基于超声导航工作的精度和效率。

Method: 该研究使用85名CRLM患者的85个追踪3D iUS体来训练和评估3D U-Net模型，且通过nnU-Net框架实现。比较了两个变体：一个是在完整iUS体上训练，另一个是在肿瘤周围的裁剪区域上。利用Dice Similarity Coefficient (DSC)，Hausdorff Distance (HDist.)和 Relative Volume Difference (RVD)度量分割精度，并在回顾和前瞻性数据集上进行评估。该流程被整合进3D Slicer，以便于实时的手术过程中使用。

Result: 在所有度量标准下，裁剪体积的模型训练显著优于完整体积模型的训练结果（AUC-ROC = 0.898 vs 0.718）。它达到了中位DSC = 0.74，召回率 = 0.79，HDist. = 17.1 mm的精度，与半自动分割相仿，但是执行速度约快四倍（约1分钟）。前瞻性手术中的实时测试确认了模型的性能稳健且一致性，准确度达到了临床上可接受的标准，适用于即时手术引导。

Conclusion: 该研究基于iUS的自动3D分割CRLM提供了可靠、接近实时的结果，需要极少的操作者输入。该方法允许高效的、基于超声的导航用于肝脏手术，达到专家级别的精确度，同时大幅减少了手动工作量和程序时间。

Abstract: Introduction: Accurate intraoperative delineation of colorectal liver
metastases (CRLM) is crucial for achieving negative resection margins but
remains challenging using intraoperative ultrasound (iUS) due to low contrast,
noise, and operator dependency. Automated segmentation could enhance precision
and efficiency in ultrasound-based navigation workflows.
  Methods: Eighty-five tracked 3D iUS volumes from 85 CRLM patients were used
to train and evaluate a 3D U-Net implemented via the nnU-Net framework. Two
variants were compared: one trained on full iUS volumes and another on cropped
regions around tumors. Segmentation accuracy was assessed using Dice Similarity
Coefficient (DSC), Hausdorff Distance (HDist.), and Relative Volume Difference
(RVD) on retrospective and prospective datasets. The workflow was integrated
into 3D Slicer for real-time intraoperative use.
  Results: The cropped-volume model significantly outperformed the full-volume
model across all metrics (AUC-ROC = 0.898 vs 0.718). It achieved median DSC =
0.74, recall = 0.79, and HDist. = 17.1 mm comparable to semi-automatic
segmentation but with ~4x faster execution (~ 1 min). Prospective
intraoperative testing confirmed robust and consistent performance, with
clinically acceptable accuracy for real-time surgical guidance.
  Conclusion: Automatic 3D segmentation of CRLM in iUS using a cropped 3D U-Net
provides reliable, near real-time results with minimal operator input. The
method enables efficient, registration-free ultrasound-based navigation for
hepatic surgery, approaching expert-level accuracy while substantially reducing
manual workload and procedure time.

</details>


### [6] [3D Gaussian Point Encoders](https://arxiv.org/abs/2511.04797)
*Jim James,Ben Wilson,Simon Lucey,James Hays*

Main category: cs.CV

TL;DR: 我们介绍了3D高斯点编码器，这是一种基于学习的3D高斯混合的显式点嵌入，性能优于传统的PointNet。通过基于自然梯度和以PointNet为教师的知识蒸馏方法，我们开发了优化技术以找到重构PointNet激活的高斯基。该编码器比传统PointNet更快、更高效。我们还展示了3D高斯点编码器作为Mamba3D组件的有效性，以及使用过滤技术实现的性能改进。此外，这些编码器在CPU设备上可以实现较高的帧率。


<details>
  <summary>Details</summary>
Motivation: 现有的3D识别任务中，通常采用隐式表示方法如PointNet，而本文提出了显式的3D高斯点编码器，以提供更好的性能和效率。作者希望找到一种更有效的3D点表示方式，特别是在参数效率和计算效率方面。

Method: 我们开发了基于自然梯度和PointNet蒸馏的方法，构建了3D高斯点编码器。该方法利用了计算几何学的启发式技术，以加速编码器，并通过过滤技术进一步优化了性能。

Result: 实验表明，3D高斯点编码器比传统的PointNet更快，参数更少，内存消耗更低，计算量更小。在Mamba3D中，编码器的性能也得到验证，包括速度和计算资源的节省。此外，该编码器在CPU设备上能够提供较高的帧率。

Conclusion: 我们提出了一种新的3D点编码方式，即3D高斯点编码器，它在参数效率和计算效率上都优于传统的PointNet，并且这种方法可以应用于更广泛的3D识别任务中以实现更好的性能。

Abstract: In this work, we introduce the 3D Gaussian Point Encoder, an explicit
per-point embedding built on mixtures of learned 3D Gaussians. This explicit
geometric representation for 3D recognition tasks is a departure from widely
used implicit representations such as PointNet. However, it is difficult to
learn 3D Gaussian encoders in end-to-end fashion with standard optimizers. We
develop optimization techniques based on natural gradients and distillation
from PointNets to find a Gaussian Basis that can reconstruct PointNet
activations. The resulting 3D Gaussian Point Encoders are faster and more
parameter efficient than traditional PointNets. As in the 3D reconstruction
literature where there has been considerable interest in the move from implicit
(e.g., NeRF) to explicit (e.g., Gaussian Splatting) representations, we can
take advantage of computational geometry heuristics to accelerate 3D Gaussian
Point Encoders further. We extend filtering techniques from 3D Gaussian
Splatting to construct encoders that run 2.7 times faster as a comparable
accuracy PointNet while using 46% less memory and 88% fewer FLOPs. Furthermore,
we demonstrate the effectiveness of 3D Gaussian Point Encoders as a component
in Mamba3D, running 1.27 times faster and achieving a reduction in memory and
FLOPs by 42% and 54% respectively. 3D Gaussian Point Encoders are lightweight
enough to achieve high framerates on CPU-only devices.

</details>


### [7] [Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose](https://arxiv.org/abs/2511.04803)
*Shuo Zhao,Jianxu Chen*

Main category: cs.CV

TL;DR: 该研究通过Cellpose模型系统性地分析了生物医学图像分割中数据冗余度和跨域迁移对模型维持的影响，发现仅使用10%的数据可以达到性能饱和，通过特定的数据选择策略可以在少量数据中捕捉到更多的特征多样性。同时，在跨域微调中，他们提出选择性数据重播策略可以有效恢复源领域的性能，而不会有损目标领域的适应性。研究结果表明，高效训练需要数据中心化设计、保持意识的学习策略以及了解领域的顺序性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨细胞分割模型的数据冗余度和跨域迁移对模型性能的影响，通过Cellpose模型进行具体分析，以期优化生物医学图像分割的模型训练过程。

Method: 首先，该研究提出了一种简单且有效的数据量化策略，用于构建紧凑又具多样性的训练子集，并通过实验分析得出其优越性。其次，通过跨域微调实验，探索了模型在不同领域之间迁移时对源领域性能的破坏，进而提出选择性数据重播解决策略。研究还发现，训练领域序列的优化可以改善模型的泛化能力和减轻遗忘现象。

Result: 实验表明，仅使用10%的数据就可以达到图像分割性能的饱和，且选择性数据重播策略可以有效恢复源领域的性能，而不会影响目标领域的适应性。此外，优化训练领域序列可以改善模型的泛化能力和减轻遗忘现象。

Conclusion: 研究结果强调了数据中心化设计、保留意识的学习策略和领域顺序性对生物医学图像分割模型训练的重要性，这将为后续的数据高效训练提供重要的参考。

Abstract: Generalist biomedical image segmentation models such as Cellpose are
increasingly applied across diverse imaging modalities and cell types. However,
two critical challenges remain underexplored: (1) the extent of training data
redundancy and (2) the impact of cross domain transfer on model retention. In
this study, we conduct a systematic empirical analysis of these challenges
using Cellpose as a case study. First, to assess data redundancy, we propose a
simple dataset quantization (DQ) strategy for constructing compact yet diverse
training subsets. Experiments on the Cyto dataset show that image segmentation
performance saturates with only 10% of the data, revealing substantial
redundancy and potential for training with minimal annotations. Latent space
analysis using MAE embeddings and t-SNE confirms that DQ selected patches
capture greater feature diversity than random sampling. Second, to examine
catastrophic forgetting, we perform cross domain finetuning experiments and
observe significant degradation in source domain performance, particularly when
adapting from generalist to specialist domains. We demonstrate that selective
DQ based replay reintroducing just 5-10% of the source data effectively
restores source performance, while full replay can hinder target adaptation.
Additionally, we find that training domain sequencing improves generalization
and reduces forgetting in multi stage transfer. Our findings highlight the
importance of data centric design in biomedical image segmentation and suggest
that efficient training requires not only compact subsets but also retention
aware learning strategies and informed domain ordering. The code is available
at https://github.com/MMV-Lab/biomedseg-efficiency.

</details>


### [8] [Geometry Denoising with Preferred Normal Vectors](https://arxiv.org/abs/2511.04848)
*Manuel Weiß,Lukas Baumgärtner,Roland Herzog,Stephan Schmidt*

Main category: cs.CV

TL;DR: 该论文提出了一种新的几何去噪方法，利用表面法向量的先验知识来去除几何数据中的噪声，并结合分割问题对类似法向量的区域进行分段处理，同时使用总变差正则化和分叉Bregman（ADMM）方法来求解优化问题。在顶点更新步骤中应用了二阶形体微积分。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在通过引入先验知识（即预定义的法向量标签），来改善几何去噪的效果，结合分割技术以提高算法的局部适应性和效果。这种基于法向量相似性的分段处理，可以帮助更好地维持几何结构的特征。

Method: 文中提出了使用预定义的法向量标签集来指导去噪过程，结合总变差正则化方法，通过分叉Bregman（ADMM）算法优化去噪效果。采用了基于二阶形体微积分的顶点更新步骤，以精细调整每个顶点的位置，从而实现更精确的去噪和形状优化。

Result: 该方法可以在去除几何噪声的同时，保持几何结构的重要特征，通过实验验证，该方法在保持细节和维护结构形状完整性方面表现出色。

Conclusion: 通过使用法向量的先验知识和细化的优化算法，该方法能够有效地去除几何数据的噪声，同时保持关键的几何特征，证明这种方法在几何数据处理领域具有较高的应用价值。

Abstract: We introduce a new paradigm for geometry denoising using prior knowledge
about the surface normal vector. This prior knowledge comes in the form of a
set of preferred normal vectors, which we refer to as label vectors. A
segmentation problem is naturally embedded in the denoising process. The
segmentation is based on the similarity of the normal vector to the elements of
the set of label vectors. Regularization is achieved by a total variation term.
We formulate a split Bregman (ADMM) approach to solve the resulting
optimization problem. The vertex update step is based on second-order shape
calculus.

</details>


### [9] [Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications](https://arxiv.org/abs/2511.04871)
*Gabriel Girard,Manon Edde,Félix Dumais,Yoan David,Matthieu Dumont,Guillaume Theaud,Jean-Christophe Houde,Arnaud Boré,Maxime Descoteaux,Pierre-Marc Jodoin*

Main category: cs.CV

TL;DR: 提出了一种名为Clinical-ComBAT的新方法，用于在实际临床环境中对来自多个采集站点的DW-MRI数据进行校准。该方法解决了ComBAT方法在临床应用中的局限性，如线性协变量关系、人口同质性、固定站点数量等。Clinical-ComBAT通过独立校准每个站点，提高了数据的可适用性和适应性，并且能够在小样本量的情况下使用。


<details>
  <summary>Details</summary>
Motivation: ComBAT方法虽然被广泛应用于减少研究中的站点效应，但其局限性限制了它在临床环境中的应用。因此，本文提出了一种新的方法Clinical-ComBAT，以克服这些限制，使DW-MRI数据在实际临床环境中更加灵活和实用。

Method: Clinical-ComBAT采用非线性多项式数据模型、特定于站点的校准以及可调整的小样本量协方差先验。它引入了超参数调整和校准质量度量，用于评估校准效果。这种方法旨在提高不同站点间数据的对齐程度和标准化建模的适用性。

Result: 该方法在模拟数据和实际数据中都表现出了明显的优势，能够有效提高扩散指标的一致性和标准化建模的应用性。从而证明Clinical-ComBAT在临床环境中的应用价值和有效性。

Conclusion: 提出了Clinical-ComBAT，一种为临床环境量身定做的DW-MRI数据校准方法，解决了先前ComBAT方法在实际应用中的局限性，提高了数据的兼容性和临床应用性。

Abstract: Diffusion-weighted magnetic resonance imaging (DW-MRI) derived scalar maps
are effective for assessing neurodegenerative diseases and microstructural
properties of white matter in large number of brain conditions. However, DW-MRI
inherently limits the combination of data from multiple acquisition sites
without harmonization to mitigate scanner-specific biases. While the widely
used ComBAT method reduces site effects in research, its reliance on linear
covariate relationships, homogeneous populations, fixed site numbers, and well
populated sites constrains its clinical use. To overcome these limitations, we
propose Clinical-ComBAT, a method designed for real-world clinical scenarios.
Clinical-ComBAT harmonizes each site independently, enabling flexibility as new
data and clinics are introduced. It incorporates a non-linear polynomial data
model, site-specific harmonization referenced to a normative site, and variance
priors adaptable to small cohorts. It further includes hyperparameter tuning
and a goodness-of-fit metric for harmonization assessment. We demonstrate its
effectiveness on simulated and real data, showing improved alignment of
diffusion metrics and enhanced applicability for normative modeling.

</details>


### [10] [A benchmark multimodal oro-dental dataset for large vision-language models](https://arxiv.org/abs/2511.04948)
*Haoxin Lv,Ijazul Haq,Jin Du,Jiaxin Ma,Binnian Zhu,Xiaobing Dang,Chaoan Liang,Ruxu Du,Yingjie Zhang,Muhammad Saqib*

Main category: cs.CV

TL;DR: 研究提出了一个口腔健康领域的多模态数据集，包含8775次牙科检查的数据，用于提升AI在口腔医疗中的应用。通过测试Qwen-VL等模型在口腔异常分类和诊断报告生成任务上的表现，验证了该数据集的有效性，并促进了AI在口腔医疗领域的研究和应用。


<details>
  <summary>Details</summary>
Motivation: 由于口腔医疗领域的复杂性，需要大规模的多模态数据集。该研究旨在为人工智能在口腔医疗中的应用提供这样的数据集，并通过实验证明其有效性。

Method: 研究团队创建了一个包含8775次牙科检查的数据集，包括图像、X光片和文本记录。使用这个数据集对Qwen-VL等模型进行了微调，并在两个任务上评估了它们的表现：口腔异常分类和诊断报告生成。

Result: 微调后的模型表现优于基准模型，表明该数据集有效支持了人工智能在口腔医疗中的研究和应用。

Conclusion: 研究提供了重要的公开资源，用于推进人工智能在口腔医疗领域的研究。

Abstract: The advancement of artificial intelligence in oral healthcare relies on the
availability of large-scale multimodal datasets that capture the complexity of
clinical practice. In this paper, we present a comprehensive multimodal
dataset, comprising 8775 dental checkups from 4800 patients collected over
eight years (2018-2025), with patients ranging from 10 to 90 years of age. The
dataset includes 50000 intraoral images, 8056 radiographs, and detailed textual
records, including diagnoses, treatment plans, and follow-up notes. The data
were collected under standard ethical guidelines and annotated for
benchmarking. To demonstrate its utility, we fine-tuned state-of-the-art large
vision-language models, Qwen-VL 3B and 7B, and evaluated them on two tasks:
classification of six oro-dental anomalies and generation of complete
diagnostic reports from multimodal inputs. We compared the fine-tuned models
with their base counterparts and GPT-4o. The fine-tuned models achieved
substantial gains over these baselines, validating the dataset and underscoring
its effectiveness in advancing AI-driven oro-dental healthcare solutions. The
dataset is publicly available, providing an essential resource for future
research in AI dentistry.

</details>


### [11] [DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning](https://arxiv.org/abs/2511.04949)
*Tharindu Fernando,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: 本文提出了一种新的深度学习框架，利用高维潜在空间表示和对抗性强化学习方法，发展了一种鲁棒且适应性强的水印技术用于深伪图像检测。该框架在CelebA和CelebA-HQ数据集上表现优于现有最佳方法超过4.5%和5.3%.


<details>
  <summary>Details</summary>
Motivation: 随着生成AI的快速发展，深伪图像越来越逼真，为法律执行和大众信任带来了挑战。现有被动的深伪检测器难以应对新类型的伪造图像，主动的使用水印检测虽然是一种解决方案，但是很难在对良性失真的鲁棒性与对恶意篡改的敏感性之间找到平衡。因此，提出了新的框架以求获得更好的检测效果和更高的鲁棒性.

Method: 本文开发了一个可学习的水印嵌入器，其工作在高维潜在空间，能够精确地控制消息的编码和提取。利用对抗性强化学习框架来对抗模拟的良性和恶意图像操作，以寻找最佳的鲁棒性和脆弱性平衡点.

Result: 在CelebA和CelebA-HQ基准测试上，该方法优于现有最佳方法4.5%和5.3%以上，特别是在困难的操作情况下表现更佳.

Conclusion: 通过高维潜在空间表示和对抗性强化学习方法的结合，该论文提出了一种新的鲁棒性和适应性强的水印技术以更好地区分真实与合成的图像

Abstract: Rapid advances in generative AI have led to increasingly realistic deepfakes,
posing growing challenges for law enforcement and public trust. Existing
passive deepfake detectors struggle to keep pace, largely due to their
dependence on specific forgery artifacts, which limits their ability to
generalize to new deepfake types. Proactive deepfake detection using watermarks
has emerged to address the challenge of identifying high-quality synthetic
media. However, these methods often struggle to balance robustness against
benign distortions with sensitivity to malicious tampering. This paper
introduces a novel deep learning framework that harnesses high-dimensional
latent space representations and the Multi-Agent Adversarial Reinforcement
Learning (MAARL) paradigm to develop a robust and adaptive watermarking
approach. Specifically, we develop a learnable watermark embedder that operates
in the latent space, capturing high-level image semantics, while offering
precise control over message encoding and extraction. The MAARL paradigm
empowers the learnable watermarking agent to pursue an optimal balance between
robustness and fragility by interacting with a dynamic curriculum of benign and
malicious image manipulations simulated by an adversarial attacker agent.
Comprehensive evaluations on the CelebA and CelebA-HQ benchmarks reveal that
our method consistently outperforms state-of-the-art approaches, achieving
improvements of over 4.5% on CelebA and more than 5.3% on CelebA-HQ under
challenging manipulation scenarios.

</details>


### [12] [CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting](https://arxiv.org/abs/2511.04951)
*Hexu Zhao,Xiwen Min,Xiaoteng Liu,Moonjun Gong,Yiming Li,Ang Li,Saining Xie,Jinyang Li,Aurojit Panda*

Main category: cs.CV

TL;DR: CLM是一种系统，它允许使用单个消费级GPU（例如：RTX4090）来渲染大型场景。通过将高斯元数据从GPU内存转移到CPU内存并按需加载，CLM解决了3DGS在大型场景渲染时内存过大导致的问题。CLM通过优化的通信策略减少计算开销，并通过观察访问模式减少通信量，实现在单个RTX4090上渲染需要100万高斯元数据的大场景，同时保持高质量的重建效果。


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting (3DGS)因其快速渲染和高质量输出而变得越来越受欢迎，但其在大型或复杂场景下的内存需求过高，通常超过了大多数GPU的内存容量。因此，本研究为了克服这个问题，提出了CLM系统，以降低内存需求并使3DGS在大场景下也能正常工作。

Method: CLM通过将高斯数据从GPU内存转移到CPU内存来降低内存需求，并通过在需要时才加载高斯数据到GPU内存，优化了渲染过程。为了避免此过程中的性能和通信开销，CLM还运用了新颖的卸载策略，通过了解3DGS的内存访问模式来进行流水线处理，从而对接管的计算和CPU的计算进行了重叠处理。另外，CLM还根据访问模式进一步减少了通信的数据量，进一步优化了系统的性能与效率。

Result: 经过评估，CLM能够在单个RTX4090上渲染需要1亿个高斯元数据的大场景，并且保持高质量的重建效果，结果表明这种实施可以实现实时渲染的效果，同时达到了最先进的重建质量标准。

Conclusion: 通过CLM系统的研发，本研究解决了3DGS在大型场景的渲染问题并实现了高精度的重建效果，提高了渲染效率并且满足了实时性要求。

Abstract: 3D Gaussian Splatting (3DGS) is an increasingly popular novel view synthesis
approach due to its fast rendering time, and high-quality output. However,
scaling 3DGS to large (or intricate) scenes is challenging due to its large
memory requirement, which exceed most GPU's memory capacity. In this paper, we
describe CLM, a system that allows 3DGS to render large scenes using a single
consumer-grade GPU, e.g., RTX4090. It does so by offloading Gaussians to CPU
memory, and loading them into GPU memory only when necessary. To reduce
performance and communication overheads, CLM uses a novel offloading strategy
that exploits observations about 3DGS's memory access pattern for pipelining,
and thus overlap GPU-to-CPU communication, GPU computation and CPU computation.
Furthermore, we also exploit observation about the access pattern to reduce
communication volume. Our evaluation shows that the resulting implementation
can render a large scene that requires 100 million Gaussians on a single
RTX4090 and achieve state-of-the-art reconstruction quality.

</details>


### [13] [GSE: Evaluating Sticker Visual Semantic Similarity via a General Sticker Encoder](https://arxiv.org/abs/2511.04977)
*Heng Er Metilda Chee,Jiayin Wang,Zhiqiang Guo,Weizhi Ma,Min Zhang*

Main category: cs.CV

TL;DR: 本文定义了贴纸语义相似性任务，并提出了Triple-S基准数据集和轻量级的通用贴纸编码器GSE模型，解决了现有模型难以捕捉贴纸的复杂语义的问题。GSE模型在未见贴纸上的性能表现良好，并且在下游任务中也取得了较好的结果。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理高度多样和象征性的贴纸内容时难以捕捉其复杂的语义关系，因此本文旨在解决这一挑战，提出了一个新的任务定义和基准数据集并开发了一个新的模型来提升对贴纸理解和检索的能力。

Method: 提出定义“贴纸语义相似性任务”，构建了Triple-S基准数据集，提出了通用轻量级的贴纸编码器模型GSE，使用Triple-S及其他数据集进行学习以获得鲁棒的贴纸嵌入。

Result: GSE模型在未见过的贴纸任务中取得了优越的表现，并在情绪分类和贴纸到贴纸检索等下游任务上表现良好。证实了该模型的泛化能力和实用性。

Conclusion: 通过提出全新的任务定义、基准数据集以及鲁棒的嵌入模型GSE，本文为未来的贴纸理解和检索研究提供了标准化的评价工具和模型支持。

Abstract: Stickers have become a popular form of visual communication, yet
understanding their semantic relationships remains challenging due to their
highly diverse and symbolic content. In this work, we formally {define the
Sticker Semantic Similarity task} and introduce {Triple-S}, the first benchmark
for this task, consisting of 905 human-annotated positive and negative sticker
pairs. Through extensive evaluation, we show that existing pretrained vision
and multimodal models struggle to capture nuanced sticker semantics. To address
this, we propose the {General Sticker Encoder (GSE)}, a lightweight and
versatile model that learns robust sticker embeddings using both Triple-S and
additional datasets. GSE achieves superior performance on unseen stickers, and
demonstrates strong results on downstream tasks such as emotion classification
and sticker-to-sticker retrieval. By releasing both Triple-S and GSE, we
provide standardized evaluation tools and robust embeddings, enabling future
research in sticker understanding, retrieval, and multimodal content
generation. The Triple-S benchmark and GSE have been publicly released and are
available here.

</details>


### [14] [Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings](https://arxiv.org/abs/2511.05017)
*Aakriti Agrawal,Gouthaman KV,Rohith Aralikatti,Gauri Jagatap,Jiaxin Yuan,Vijay Kamarshi,Andrea Fanelli,Furong Huang*

Main category: cs.CV

TL;DR: 本工作识别出现有LVLM架构对语言模式存在的固有偏差，并提出一种通过整合平均池化的视觉特征来改进文本嵌入的方法，显著减少了幻觉现象并提升了视觉定位能力。


<details>
  <summary>Details</summary>
Motivation: 现有LVLM架构由于常见的将视觉嵌入简单附加到输入文本序列的做法，存在对语言模式的固有偏差。此研究旨在解决这一问题，减少在现有基准上出现的幻觉现象，提升视觉定位能力。

Method: 通过整合平均池化的视觉特征来改进文本嵌入，以此来缓解视觉和语言模式之间的失衡问题。具体而言，这种改进使得视觉信息能够更有效地融入文本理解中，克服了传统方法中对视觉信息利用不足的问题。

Result: 这种方法显著减少了幻觉现象，在视觉定位任务上表现出明显的优势。同时，也显示出这种方法在融合视觉信息和提升跨模态对齐上的潜力。然而，作者也指出，更高级的融合策略可能进一步增强这一效果，这是未来工作的探索方向。

Conclusion: 通过对现有LVLM架构中语言模式偏向问题的识别，并通过创新的方法来整合视觉信息，本研究成功证明了改进文本嵌入能够显著减少幻觉现象并提升视觉定位能力。研究结果表明，现有技术仍有一定的改进空间，未来的工作可以进一步探索视觉信息和文本信息之间的更有效融合策略。

Abstract: In this work, we identify an inherent bias in prevailing LVLM architectures
toward the language modality, largely resulting from the common practice of
simply appending visual embeddings to the input text sequence. To address this,
we propose a simple yet effective method that refines textual embeddings by
integrating average-pooled visual features. Our approach demonstrably improves
visual grounding and significantly reduces hallucinations on established
benchmarks. While average pooling offers a straightforward, robust, and
efficient means of incorporating visual information, we believe that more
sophisticated fusion methods could further enhance visual grounding and
cross-modal alignment. Given that the primary focus of this work is to
highlight the modality imbalance and its impact on hallucinations -- and to
show that refining textual embeddings with visual information mitigates this
issue -- we leave exploration of advanced fusion strategies for future work.

</details>


### [15] [Dynamic Residual Encoding with Slide-Level Contrastive Learning for End-to-End Whole Slide Image Representation](https://arxiv.org/abs/2511.05034)
*Jing Jin,Xu Liu,Te Gao,Zhihong Shi,Yixiong Liang,Ruiqing Zheng,Hulin Kuang,Min Zeng,Shichao Kan*

Main category: cs.CV

TL;DR: 提出了一种基于动态残差编码和滑片级别对比学习的WSI表示方法（DRE-SLCL），用于癌症分型、癌症识别和突变预测。该方法利用内存库存储所有WSI的数据碎片特征，并通过滑片级别对比损失函数进行训练，实验结果验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决WSI表示中由于数据量巨大无法在一个小批次中计算所有数据块梯度的问题，提出一种新的WSI表示学习方法。动机是在处理大规模数据时提高模型训练速度和准确度。

Method: 利用内存库存储所有WSI的数据碎片特征，每次训练时随机抽样一部分数据块，并通过滑片级别的对比学习损失函数指导模型学习。具体技术包括随机采样数据块特征、内存库中提取特征及残差编码等。

Result: 实验结果表明，所提出的方法在癌症分型、癌症识别和突变预测任务中均表现良好，验证了该方法的有效性。

Conclusion: 本文提出了一种新的WSI表示学习方法，能够有效解决大规模数据的训练问题，并在癌症相关任务中取得良好性能。

Abstract: Whole Slide Image (WSI) representation is critical for cancer subtyping,
cancer recognition and mutation prediction.Training an end-to-end WSI
representation model poses significant challenges, as a standard gigapixel
slide can contain tens of thousands of image tiles, making it difficult to
compute gradients of all tiles in a single mini-batch due to current GPU
limitations. To address this challenge, we propose a method of dynamic residual
encoding with slide-level contrastive learning (DRE-SLCL) for end-to-end WSI
representation. Our approach utilizes a memory bank to store the features of
tiles across all WSIs in the dataset. During training, a mini-batch usually
contains multiple WSIs. For each WSI in the batch, a subset of tiles is
randomly sampled and their features are computed using a tile encoder. Then,
additional tile features from the same WSI are selected from the memory bank.
The representation of each individual WSI is generated using a residual
encoding technique that incorporates both the sampled features and those
retrieved from the memory bank. Finally, the slide-level contrastive loss is
computed based on the representations and histopathology reports ofthe WSIs
within the mini-batch. Experiments conducted over cancer subtyping, cancer
recognition, and mutation prediction tasks proved the effectiveness of the
proposed DRE-SLCL method.

</details>


### [16] [Pressure2Motion: Hierarchical Motion Synthesis from Ground Pressure with Text Guidance](https://arxiv.org/abs/2511.05038)
*Zhengxuan Li,Qinhui Yang,Yiyu Zhuang,Chuan Guo,Xinxin Zuo,Xiaoxiao Long,Yao Yao,Xun Cao,Qiu Shen,Hao Zhu*

Main category: cs.CV

TL;DR: Pressure2Motion 是一种从地面压力序列和文本提示中合成人体运动的新型动作捕捉算法，适用于隐私保护、低光照和低成本的动作捕捉场景。该算法利用压力特征和文本提示作为高级指导约束，指导动作生成。实验表明，该方法生成了高度逼真且物理上合理的运动，为这一任务建立了新的基准。


<details>
  <summary>Details</summary>
Motivation: 传统动作捕捉方法需要复杂的设备并与成本、布置和隐私保护相关的问题。为了解决这些问题，作者提出了Pressure2Motion，它可以利用简单的地面压力序列和文本提示，实现高质量的动作捕捉，适用于各种需要隐私保护、低光照和低成本的场景。

Method: Pressure2Motion 使用双层特征提取器，准确地解释压力数据，并利用分层扩散模型来识别大规模运动轨迹和细微姿势调整。该方法结合了来自压力序列的物理线索和从描述性文本中获得的语义指导来引导动作生成。

Result: 实验表明，Pressure2Motion 方法能够生成高度逼真且物理上合理的动作，为这一任务建立了一个新的基准。该方法优于之前的最佳效果。代码和基准将发表时公开发布。

Conclusion: Pressure2Motion 是一种创新的使用压力数据和语言先验生成动作的方法，为需要隐私保护、低光照和低成本的动作捕捉场景提供了一个可靠的解决方案。

Abstract: We present Pressure2Motion, a novel motion capture algorithm that synthesizes
human motion from a ground pressure sequence and text prompt. It eliminates the
need for specialized lighting setups, cameras, or wearable devices, making it
suitable for privacy-preserving, low-light, and low-cost motion capture
scenarios. Such a task is severely ill-posed due to the indeterminate nature of
the pressure signals to full-body motion. To address this issue, we introduce
Pressure2Motion, a generative model that leverages pressure features as input
and utilizes a text prompt as a high-level guiding constraint. Specifically,
our model utilizes a dual-level feature extractor that accurately interprets
pressure data, followed by a hierarchical diffusion model that discerns
broad-scale movement trajectories and subtle posture adjustments. Both the
physical cues gained from the pressure sequence and the semantic guidance
derived from descriptive texts are leveraged to guide the motion generation
with precision. To the best of our knowledge, Pressure2Motion is a pioneering
work in leveraging both pressure data and linguistic priors for motion
generation, and the established MPL benchmark is the first benchmark for this
task. Experiments show our method generates high-fidelity, physically plausible
motions, establishing a new state-of-the-art for this task. The codes and
benchmarks will be publicly released upon publication.

</details>


### [17] [Medical Referring Image Segmentation via Next-Token Mask Prediction](https://arxiv.org/abs/2511.05044)
*Xinyu Chen,Yiran Wang,Gaoyang Pang,Jiafu Hao,Chentao Yue,Luping Zhou,Yonghui Li*

Main category: cs.CV

TL;DR: NTP-MRISeg 是一种新的自动回归下一个标记预测框架，用于医学图像分割，通过统一的多模态序列实现端到端训练。它提出了三项新策略，包括下一个k个标记预测，标记对比学习和基于记忆的困难标记优化策略，能有效减少错误累积和提升边界敏感度。实验表明，NTP-MRISeg 在QaTa-COV19 和MosMedData+ 数据集上取得了最新的SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分割方法通常涉及复杂的多模态融合或多个阶段解码器设计，这导致模型设计复杂。此方案旨在简化模型设计，支持统一架构的端到端训练，并提出新策略来解决当前方法的局限性。

Method: NTP-MRISeg 将医学图像分割重构成一个自动回归下一个标记预测任务，使用统一的多模态序列来简化模型设计并支持端到端训练。新策略包括下一个k个标记预测，标记对比学习和基于记忆的困难标记优化策略，这些问题有助于减少累积预测错误，提升边界敏感度，克服长尾分布的影响。

Result: 实验显示，NTP-MRISeg 在QaTa-COV19 和MosMedData+ 数据集中达到了最新的SOTA结果，证明了该方法的有效性。此工作提供了基于医学图像描述的分割任务的一种新的高效的替代方案。

Conclusion: 我们提出了NTP-MRISeg，这是一种新型框架，将医学图像分割重构成一个自动回归下一个标记预测任务，解决了现有方法中的复杂模型设计问题，并引入了针对新框架挑战的三项新策略。实验证明了该模型的有效性和效率，为医学图像分割任务提供了一种新的高效解决方案。

Abstract: Medical Referring Image Segmentation (MRIS) involves segmenting target
regions in medical images based on natural language descriptions. While
achieving promising results, recent approaches usually involve complex design
of multimodal fusion or multi-stage decoders. In this work, we propose
NTP-MRISeg, a novel framework that reformulates MRIS as an autoregressive
next-token prediction task over a unified multimodal sequence of tokenized
image, text, and mask representations. This formulation streamlines model
design by eliminating the need for modality-specific fusion and external
segmentation models, supports a unified architecture for end-to-end training.
It also enables the use of pretrained tokenizers from emerging large-scale
multimodal models, enhancing generalization and adaptability. More importantly,
to address challenges under this formulation-such as exposure bias, long-tail
token distributions, and fine-grained lesion edges-we propose three novel
strategies: (1) a Next-k Token Prediction (NkTP) scheme to reduce cumulative
prediction errors, (2) Token-level Contrastive Learning (TCL) to enhance
boundary sensitivity and mitigate long-tail distribution effects, and (3) a
memory-based Hard Error Token (HET) optimization strategy that emphasizes
difficult tokens during training. Extensive experiments on the QaTa-COV19 and
MosMedData+ datasets demonstrate that NTP-MRISeg achieves new state-of-the-art
performance, offering a streamlined and effective alternative to traditional
MRIS pipelines.

</details>


### [18] [Role-SynthCLIP: A Role Play Driven Diverse Synthetic Data Approach](https://arxiv.org/abs/2511.05057)
*Yuanxiang Huangfu,Chaochao Wang,Weilei Wang*

Main category: cs.CV

TL;DR: 提出了Role-SynthCLIP，一个创新的数据合成框架，它通过角色扮演提示来引导生成语义多样化的描述，这种方法不增加数据总量的情况下提高了描述的表达力和准确性，并通过实验验证了其有效性与效率。


<details>
  <summary>Details</summary>
Motivation: 传统的合成数据生成方法主要关注增加数据量，但往往导致语义多样性不足，冗余或浅层描述。为了解决这个问题，提出了一种新方法，可以生成从不同视角出发的多样化描述。

Method: 通过角色扮演提示引导多模态语言模型生成多样化的描述，不增加数据总量，以提升描述的语义多样性和细粒度的图像-文本对齐。

Result: 实验结果表明，这种方法有效且高效，一个训练在仅1百万Role-SynthCLIP对的CLIP-B/16模型在MS COCO验证集上的Recall@1达到了64.1%，超过了最佳合成数据基线（训练在5百万对上）2.8个百分点。

Conclusion: 通过角色扮演提示生成的多样化描述，在不增加数据总量的情况下，提高了描述的表达力和准确性，改进了图像-文本对齐，并且证明了其有效性。

Abstract: The effectiveness of Contrastive Language-Image Pre-training (CLIP) models
critically depends on the semantic diversity and quality of their training
data. However, while existing synthetic data generation methods primarily focus
on increasing data volume, such emphasis often leads to limited semantic
diversity and redundant or shallow captions. To address this limitation, we
propose Role-SynthCLIP, a novel data synthesis framework that leverages
multi-perspective role-playing prompts (e.g., a compositional analyst, an
interpreter of image context) to guide Multimodal Large Language Models (MLLMs)
in generating semantically diverse captions from distinct viewpoints. This
mechanism enhances the semantic diversity and fine-grained image-text alignment
of synthetic pairs, thereby improving caption expressiveness and accuracy while
keeping the total number of image-text pairs unchanged. Experimental results
demonstrate the effectiveness and efficiency of our method. A CLIP-B/16 model
trained on only 1 million Role-SynthCLIP pairs achieves a Recall@1 of 64.1% on
the MS COCO validation set, surpassing the best existing synthetic data
baseline (trained on 5M pairs) by 2.8 percentage points. The code and trained
models are released at https://github.com/huangfu170/Role-SynthCLIP.

</details>


### [19] [Real-World Adverse Weather Image Restoration via Dual-Level Reinforcement Learning with High-Quality Cold Start](https://arxiv.org/abs/2511.05095)
*Fuyang Liu,Jiaqi Xu,Xiaowei Hu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于强化学习的框架，用于改善在恶劣天气条件下视觉感知的效果。框架首先构建了一个高保真的模拟天气数据库，并设计了两级强化学习系统，其中每一级别都有专门的任务。该框架可以连续适应真实世界的情况，并在多种不良天气场景下都取得了当前最佳的效果。


<details>
  <summary>Details</summary>
Motivation: 现实中的恶劣天气严重损害了视觉感知，而现有的基于合成数据训练的视觉模型难以泛化到复杂的退化情况中。因此，论文希望通过构建一个高保真的天气模拟数据库，并设计一种新的框架来改善在恶劣天气中的视觉性能。

Method: 该论文设计了一种物理驱动、高保真的数据库HFLS-Weather来模拟各种天气现象，并在此基础上提出了一个两级强化学习框架，包括局部层次的奖励驱动的学习和全局层次的模型选择和执行顺序的动态调整。这个框架利用了HFLS-Weather进行冷启动学习，从而能够在真实的恶劣天气条件下运行并且能够自我适应。

Result: 实验结果表明，该方法在广泛的恶劣天气条件下实现了当前最佳的效果，并且连续适应真实世界的情况，提高了在真实世界视觉感知中的泛化能力。

Conclusion: 本文提出了一个新的框架，通过构建高保真的天气模拟数据库并利用强化学习进行训练，在真实世界恶劣天气条件下能够实现最佳的视觉感知效果。

Abstract: Adverse weather severely impairs real-world visual perception, while existing
vision models trained on synthetic data with fixed parameters struggle to
generalize to complex degradations. To address this, we first construct
HFLS-Weather, a physics-driven, high-fidelity dataset that simulates diverse
weather phenomena, and then design a dual-level reinforcement learning
framework initialized with HFLS-Weather for cold-start training. Within this
framework, at the local level, weather-specific restoration models are refined
through perturbation-driven image quality optimization, enabling reward-based
learning without paired supervision; at the global level, a meta-controller
dynamically orchestrates model selection and execution order according to scene
degradation. This framework enables continuous adaptation to real-world
conditions and achieves state-of-the-art performance across a wide range of
adverse weather scenarios. Code is available at
https://github.com/xxclfy/AgentRL-Real-Weather

</details>


### [20] [SnowyLane: Robust Lane Detection on Snow-covered Rural Roads Using Infrastructural Elements](https://arxiv.org/abs/2511.05108)
*Jörg Gamerdinger,Benedict Wetzel,Patrick Schulz,Sven Teufel,Oliver Bringmann*

Main category: cs.CV

TL;DR: 本文提出了一种在雪地环境中通过检测路边标志杆来间接实现车道检测的新方法，这种方法不依赖于传统的车道线。同时引入了一种新的合成数据集SnowyLane，以支持在恶劣天气条件下的训练和评估。该方法在有严重雪覆盖的情况下比现有最佳系统显示出更强的鲁棒性，为冬季可靠车道检测奠定了坚实的基础，


<details>
  <summary>Details</summary>
Motivation: 在雪覆盖的环境中，由于车道标线经常消失或被遮挡，自主驾驶的车道检测仍然是一个重大挑战。传统的车道检测方法依赖于车道线，而在雪地环境中，这种依赖性变得不可靠。因此，需要一种新的方法，能够在雪覆盖的环境中可靠地检测车道，同时无需依赖传统的车道线

Method: 该方法首先感知路边的标志杆，然后使用参数化的贝塞尔曲线模型拟合平滑的车道轨迹，利用空间连续性和道路几何形状。这种方法与传统的车道检测方法不同，因为它不依赖于车道线，而是依赖于路边的标志杆作为间接的车道指示器

Result: 与现有的最佳车道检测系统相比，该方法在有严重雪覆盖的情况下表现出更强的鲁棒性。通过使用新的合成数据集SnowyLane，在这些具有挑战性的场景中支持训练和评估，提高了车道检测的鲁棒性

Conclusion: 该工作为冬季可靠车道检测奠定了坚实的基础，并为未来在所有天气条件下的自主驾驶研究提供了一个有价值的资源。

Abstract: Lane detection for autonomous driving in snow-covered environments remains a
major challenge due to the frequent absence or occlusion of lane markings. In
this paper, we present a novel, robust and realtime capable approach that
bypasses the reliance on traditional lane markings by detecting roadside
features,specifically vertical roadside posts called delineators, as indirect
lane indicators. Our method first perceives these posts, then fits a smooth
lane trajectory using a parameterized Bezier curve model, leveraging spatial
consistency and road geometry. To support training and evaluation in these
challenging scenarios, we introduce SnowyLane, a new synthetic dataset
containing 80,000 annotated frames capture winter driving conditions, with
varying snow coverage, and lighting conditions. Compared to state-of-the-art
lane detection systems, our approach demonstrates significantly improved
robustness in adverse weather, particularly in cases with heavy snow occlusion.
This work establishes a strong foundation for reliable lane detection in winter
scenarios and contributes a valuable resource for future research in
all-weather autonomous driving. The dataset is available at
https://ekut-es.github.io/snowy-lane

</details>


### [21] [From Linear Probing to Joint-Weighted Token Hierarchy: A Foundation Model Bridging Global and Cellular Representations in Biomarker Detection](https://arxiv.org/abs/2511.05150)
*Jingsong Liu,Han Li,Nassir Navab,Peter J. Schüffler*

Main category: cs.CV

TL;DR: JWTH模型通过大规模的自监督预训练和以细胞为中心的后期调整及注意力池化，将局部和全局标记融合，提高了AI基生物标志物检测的可解释性和鲁棒性，性能优于先前的模型。


<details>
  <summary>Details</summary>
Motivation: 大多数病理基础模型（PFMs）依赖于全局补丁级别的嵌入，并忽略了细胞级别的形态。因此，本文提出了JWTH模型，以解决这一问题，提高AI基生物标志物检测的性能。

Method: JWTH模型采用大规模自监督预训练、细胞中心后期调整和注意力池化，从而将局部和全局标记融合。

Result: 在四个任务中，JWTH模型的性能优于先前的PFMs，其达到的平衡准确率和平均改善分别增加了8.3%和1.2%。

Conclusion: JWTH模型通过融合局部和全局标记，提高了AI基生物标志物检测的可解释性和鲁棒性，是在数字病理学中推动可解释和稳健的AI生物标志物检测的先进模型。

Abstract: AI-based biomarkers can infer molecular features directly from hematoxylin &
eosin (H&E) slides, yet most pathology foundation models (PFMs) rely on global
patch-level embeddings and overlook cell-level morphology. We present a PFM
model, JWTH (Joint-Weighted Token Hierarchy), which integrates large-scale
self-supervised pretraining with cell-centric post-tuning and attention pooling
to fuse local and global tokens. Across four tasks involving four biomarkers
and eight cohorts, JWTH achieves up to 8.3% higher balanced accuracy and 1.2%
average improvement over prior PFMs, advancing interpretable and robust
AI-based biomarker detection in digital pathology.

</details>


### [22] [Splatography: Sparse multi-view dynamic Gaussian Splatting for filmmaking challenges](https://arxiv.org/abs/2511.05152)
*Adrian Azzarelli,Nantheera Anantrasirichai,David R Bull*

Main category: cs.CV

TL;DR: 提出了一种改进的动态三维重建方法，通过将前景和背景的高斯分布和变形场分开训练，从而在稀疏摄像机配置下实现高质量重建，尤其在复杂动态特征的捕捉上表现更优。这种方法不仅在定量和定性上都达到了最先进的水平，并且无需密集掩码监督就能生成透明和动态纹理的分割重建。


<details>
  <summary>Details</summary>
Motivation: 针对电影制作中因预算限制造成的稀疏摄像机配置问题，需要一种改进的方法来捕捉复杂的动态特征。当前方法在稀疏数据情况下效果欠佳，特别是对于前景中复杂的动态变化和背景中静止元素的区分不显著。因此，提出了一种新的方法来应对这些挑战。

Method: 该方法引入了将前景和背景分开的方法：通过在时间t=0时使用稀疏的掩码分割前景和背景的高斯分布与变形场；各自进行单独训练；用不同的损失函数进行预训练；动态训练则分别对两个变形场进行参数建模；针对前景动态特性的学习包含颜色、位置和旋转的变化；而针对背景典型的是较暗且动态变化较少，只学习位置变化。这种方法可以在稀疏摄像机配置下产生高质量的重建效果。

Result: 实验结果表明，该方法在定性和定量方面都达到了最先进的水平，特别是在3D场景下可以实现高达3 PSNR的提高，同时模型大小减少了超过50%。此外，这种方法可以在没有密集掩码监督的情况下产生包含透明和动态纹理的分割重建。

Conclusion: 与最先进的方法相比，该方法不仅在稀疏摄像机配置下进行了改进，还可以处理透明和动态纹理，生成高质量的三维重建，无需密集掩码监督。

Abstract: Deformable Gaussian Splatting (GS) accomplishes photorealistic dynamic 3-D
reconstruction from dense multi-view video (MVV) by learning to deform a
canonical GS representation. However, in filmmaking, tight budgets can result
in sparse camera configurations, which limits state-of-the-art (SotA) methods
when capturing complex dynamic features. To address this issue, we introduce an
approach that splits the canonical Gaussians and deformation field into
foreground and background components using a sparse set of masks for frames at
t=0. Each representation is separately trained on different loss functions
during canonical pre-training. Then, during dynamic training, different
parameters are modeled for each deformation field following common filmmaking
practices. The foreground stage contains diverse dynamic features so changes in
color, position and rotation are learned. While, the background containing
film-crew and equipment, is typically dimmer and less dynamic so only changes
in point position are learned. Experiments on 3-D and 2.5-D entertainment
datasets show that our method produces SotA qualitative and quantitative
results; up to 3 PSNR higher with half the model size on 3-D scenes. Unlike the
SotA and without the need for dense mask supervision, our method also produces
segmented dynamic reconstructions including transparent and dynamic textures.
Code and video comparisons are available online:
https://interims-git.github.io/

</details>


### [23] [Another BRIXEL in the Wall: Towards Cheaper Dense Features](https://arxiv.org/abs/2511.05168)
*Alexander Lappe,Martin A. Giese*

Main category: cs.CV

TL;DR: BRIXEL是一种简单有效的知识蒸馏方法，通过让学生模型以更高的分辨率复现特征图，从而在下游任务上显著超越原版DINOv3模型，并且以较小的计算成本生成与教师模型非常相似的特征图。


<details>
  <summary>Details</summary>
Motivation: 解决DINOv3等视觉基础模型在生成特征图时需要高分辨率输入和大量计算的问题，从而降低计算成本和提高性能。 

Method: BRIXEL通过知识蒸馏让学生模型在更高的分辨率下复现它们自身的特征图，从而提高特征图的质量和效率。

Result: BRIXEL在下游任务上的表现大大超过了原始的DINOv3模型。此外，BRIXEL生成的特征图与教师模型非常相似，但计算成本仅是原模型的一部分。

Conclusion: BRIXEL不仅优化了计算成本，还在性能上超越了原有的DINOv3模型，适用于各种视觉任务。

Abstract: Vision foundation models achieve strong performance on both global and
locally dense downstream tasks. Pretrained on large images, the recent DINOv3
model family is able to produce very fine-grained dense feature maps, enabling
state-of-the-art performance. However, computing these feature maps requires
the input image to be available at very high resolution, as well as large
amounts of compute due to the squared complexity of the transformer
architecture. To address these issues, we propose BRIXEL, a simple knowledge
distillation approach that has the student learn to reproduce its own feature
maps at higher resolution. Despite its simplicity, BRIXEL outperforms the
baseline DINOv3 models by large margins on downstream tasks when the resolution
is kept fixed. Moreover, it is able to produce feature maps that are very
similar to those of the teacher at a fraction of the computational cost. Code
and model weights are available at https://github.com/alexanderlappe/BRIXEL.

</details>


### [24] [4D3R: Motion-Aware Neural Reconstruction and Rendering of Dynamic Scenes from Monocular Videos](https://arxiv.org/abs/2511.05229)
*Mengqi Guo,Bo Xu,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

TL;DR: 我们提出了一种新的动态场景神经渲染框架4D3R，它能够在未知相机姿态的情况下，从单目视频中合成新颖视角，适用于动态场景。该框架通过一个两阶段方法，分别处理静态和动态成分，并引入了两个关键技术革新：用于准确相机姿态校准的动态感知捆包校正模块和一个用于高效建模动态运动的运动感知高斯点积化表示方法。实验结果表明，相比于现有方法，我们的方法在真实世界的动态数据集中表现更好，尤其是在有大量动态物体的挑战性场景中。


<details>
  <summary>Details</summary>
Motivation: 传统的静态场景表示方法如NeRF和3DGS难以处理动态场景，且通常需要预计算的相机姿态。因此，设计一种能够处理未知相机姿态的动态场景神经渲染框架很有意义。目的在于以更高效、更准确的方式处理视频中的动态场景，合成新颖视角。

Method: 我们的方法4D3R包含两个主要部分：（1）一个动态感知捆包校正（MA-BA）模块，该模块结合了Transformer学习的先验知识和SAM2，用于动态物体的分割，使得相机姿态校准更准确。（2）一个运动感知高斯点积化（MA-GS）表示，使用带有变形场MLP和线性混合皮肤的控制点来减少计算成本，同时保持高质量的重建。此外，我们还利用了3D基础模型来进行初始相机姿态和几何估计，随后进行运动感知的细化。

Result: 实验在真实动态数据集上进行。结果显示，相比于现有方法，我们的方法在具有大量动态物体的复杂场景中，PSNR指标提升了最多1.8dB。同时，计算资源需求降低到了其他动态场景表示方法的1/5。

Conclusion: 我们的方法能够有效地处理未标明相机姿态的动态场景，特别是在复杂动态场景中性能表现最佳，这为动态场景的视频理解和合成领域提供了新的技术方法和可能性。

Abstract: Novel view synthesis from monocular videos of dynamic scenes with unknown
camera poses remains a fundamental challenge in computer vision and graphics.
While recent advances in 3D representations such as Neural Radiance Fields
(NeRF) and 3D Gaussian Splatting (3DGS) have shown promising results for static
scenes, they struggle with dynamic content and typically rely on pre-computed
camera poses. We present 4D3R, a pose-free dynamic neural rendering framework
that decouples static and dynamic components through a two-stage approach. Our
method first leverages 3D foundational models for initial pose and geometry
estimation, followed by motion-aware refinement. 4D3R introduces two key
technical innovations: (1) a motion-aware bundle adjustment (MA-BA) module that
combines transformer-based learned priors with SAM2 for robust dynamic object
segmentation, enabling more accurate camera pose refinement; and (2) an
efficient Motion-Aware Gaussian Splatting (MA-GS) representation that uses
control points with a deformation field MLP and linear blend skinning to model
dynamic motion, significantly reducing computational cost while maintaining
high-quality reconstruction. Extensive experiments on real-world dynamic
datasets demonstrate that our approach achieves up to 1.8dB PSNR improvement
over state-of-the-art methods, particularly in challenging scenarios with large
dynamic objects, while reducing computational requirements by 5x compared to
previous dynamic scene representations.

</details>


### [25] [MUSE: Multi-Scale Dense Self-Distillation for Nucleus Detection and Classification](https://arxiv.org/abs/2511.05170)
*Zijiang Yang,Hanqing Chao,Bokai Zhao,Yelin Yang,Yunshuo Zhang,Dongmei Fu,Junping Zhang,Le Lu,Ke Yan,Dakai Jin,Minfeng Xu,Yun Bian,Hui Jiang*

Main category: cs.CV

TL;DR: 提出了一种名为MUSE的新方法，用于细胞核检测和分类（NDC）。MUSE是一种自监督学习方法，可以利用未标记的数据来优化模型，从而提升细胞核级别的表示。实验显示该方法在基准测试中表现优异，胜过现有的监督模型和基础病理学模型。


<details>
  <summary>Details</summary>
Motivation: 当前的方法在处理大规模无标签数据时，难以充分利用这些数据来学习具有区分性的细胞核表示，且高度依赖于耗时的手工细胞核级别注解。为了解决这些问题，提出了MUSE方法。

Method: MUSE主要由NuLo机制和简单有效的编码-解码器架构组成。NuLo机制允许基于预测的细胞核位置进行灵活的局部自我蒸馏，从而解锁模型的精细细胞核表示的能力。同时，MUSE采用跨尺度对齐来最大化无标签病理图像的价值。

Result: 实验结果表明，MUSE方法有效地解决了组织病理学NDC的核心问题，不仅超越了现有的监督基线模型，还超过了通用的病理学基础模型。

Conclusion: 通过自监督学习方法MUSE，我们使模型能更好地利用大规模无标签数据来提高细胞核级别的表示能力，从而提高了NDC的性能。

Abstract: Nucleus detection and classification (NDC) in histopathology analysis is a
fundamental task that underpins a wide range of high-level pathology
applications. However, existing methods heavily rely on labor-intensive
nucleus-level annotations and struggle to fully exploit large-scale unlabeled
data for learning discriminative nucleus representations. In this work, we
propose MUSE (MUlti-scale denSE self-distillation), a novel self-supervised
learning method tailored for NDC. At its core is NuLo (Nucleus-based Local
self-distillation), a coordinate-guided mechanism that enables flexible local
self-distillation based on predicted nucleus positions. By removing the need
for strict spatial alignment between augmented views, NuLo allows critical
cross-scale alignment, thus unlocking the capacity of models for fine-grained
nucleus-level representation. To support MUSE, we design a simple yet effective
encoder-decoder architecture and a large field-of-view semi-supervised
fine-tuning strategy that together maximize the value of unlabeled pathology
images. Extensive experiments on three widely used benchmarks demonstrate that
MUSE effectively addresses the core challenges of histopathological NDC. The
resulting models not only surpass state-of-the-art supervised baselines but
also outperform generic pathology foundation models.

</details>


### [26] [Walk the Lines 2: Contour Tracking for Detailed Segmentation](https://arxiv.org/abs/2511.05210)
*André Peter Kelm,Max Braeschke,Emre Gülsoylu,Simone Frintrop*

Main category: cs.CV

TL;DR: Walk the Lines 2 (WtL2) 是一种改进的轮廓跟踪算法，适用于红外（IR）船只和RGB图像中各种物体的详细分割。它扩展了原始的 WtL，可以处理更复杂的物体轮廓，提高精确度和细节。


<details>
  <summary>Details</summary>
Motivation: 开发 WtL2 的动机在于解决标准非极大值抑制（NMS）方法的局限性，通过使用轮廓跟踪技术来细化物体轮廓，并能处理红外和RGB图像中的多类物体，从而在详细分割方面提供更高的精度和细节。

Method: WtL2 采用轮廓跟踪算法来替代传统的非极大值抑制方法，通过处理更复杂的物体轮廓，在获得精确的1像素宽闭合形状后进行二值化，从而实现前景背景场景中的可分割区域的生成。该方法通过适应红外船只的轮廓检测器和对RGB图像中广泛类型的物体进行处理得到了增强。

Result: WtL2在实现关闭物体轮廓的精细分割时，超越了当前最佳的基于轮廓的方法，同时在峰值交并比（IoU）上也表现得非常出色。

Conclusion: WtL2作为一种专门的应用于对细节分割有高要求或需要高质量样本的方法，为视觉分割的几个利基领域的发展提供了加速。

Abstract: This paper presents Walk the Lines 2 (WtL2), a unique contour tracking
algorithm specifically adapted for detailed segmentation of infrared (IR) ships
and various objects in RGB.1 This extends the original Walk the Lines (WtL)
[12], which focused solely on detailed ship segmentation in color. These
innovative WtLs can replace the standard non-maximum suppression (NMS) by using
contour tracking to refine the object contour until a 1-pixel-wide closed shape
can be binarized, forming a segmentable area in foreground-background
scenarios. WtL2 broadens the application range of WtL beyond its original
scope, adapting to IR and expanding to diverse objects within the RGB context.
To achieve IR segmentation, we adapt its input, the object contour detector, to
IR ships. In addition, the algorithm is enhanced to process a wide range of RGB
objects, outperforming the latest generation of contour-based methods when
achieving a closed object contour, offering high peak Intersection over Union
(IoU) with impressive details. This positions WtL2 as a compelling method for
specialized applications that require detailed segmentation or high-quality
samples, potentially accelerating progress in several niche areas of image
segmentation.

</details>


### [27] [OregairuChar: A Benchmark Dataset for Character Appearance Frequency Analysis in My Teen Romantic Comedy SNAFU](https://arxiv.org/abs/2511.05263)
*Qi Sun,Dingju Zhou,Lina Zhang*

Main category: cs.CV

TL;DR: OregairuChar 是一个用于分析动漫中角色出镜频率的基准数据集，包含来自《我的青春恋爱物语果然有问题》第三季的1600个手动选择的帧，标注了11个主要角色的2860个边界框。数据集用于评估对象检测模型并进行细致的具体集分析，揭示角色在叙事中的出镜模式及演变。


<details>
  <summary>Details</summary>
Motivation: 为了理解叙事结构、角色重要性及故事发展，需分析角色在动漫中的出镜频率，为此设计了OregairuChar数据集以支持基于出现频率的计算叙事研究和角色为中心的故事叙述探索。

Method: 创建包含第三季共计1600个帧的数据集，标注了11个主要角色的出镜情况，通过评估对象检测模型并利用模型预测对每个集进行细致分析。

Result: 该方法能揭示出角色随时间推移的出镜模式及其在故事情节中的演变。数据集反映出客体检测模型在此类任务上的表现，并为计算叙事研究提供了有价值的资源。

Conclusion: 通过强调出镜频率，OregairuChar能有效助力动漫中角色的叙事演绎研究，为计算叙事动力学和以角色为核心的叙述方式研究提供了坚实的基础。

Abstract: The analysis of character appearance frequency is essential for understanding
narrative structure, character prominence, and story progression in anime. In
this work, we introduce OregairuChar, a benchmark dataset designed for
appearance frequency analysis in the anime series My Teen Romantic Comedy
SNAFU. The dataset comprises 1600 manually selected frames from the third
season, annotated with 2860 bounding boxes across 11 main characters.
OregairuChar captures diverse visual challenges, including occlusion, pose
variation, and inter-character similarity, providing a realistic basis for
appearance-based studies. To enable quantitative research, we benchmark several
object detection models on the dataset and leverage their predictions for
fine-grained, episode-level analysis of character presence over time. This
approach reveals patterns of character prominence and their evolution within
the narrative. By emphasizing appearance frequency, OregairuChar serves as a
valuable resource for exploring computational narrative dynamics and
character-centric storytelling in stylized media.

</details>


### [28] [FreeControl: Efficient, Training-Free Structural Control via One-Step Attention Extraction](https://arxiv.org/abs/2511.05219)
*Jiang Lin,Xinyu Chen,Song Wu,Zhiqiu Zhang,Jizhi Zhang,Ye Wang,Qiang Tang,Qian Wang,Jian Yang,Zili Yi*

Main category: cs.CV

TL;DR: FreeControl 是一种无需训练即可在扩散模型中进行语义结构控制的框架，通过一步注意提取和分解潜在条件来实现高效的结构引导。它提高了图像生成时的质量和稳定性，同时保持了成本效益和灵活性，可以应用于现代扩散模型，并且支持通过参考图像进行组合控制，从而实现直观的场景布局设计和强大的提示对齐。


<details>
  <summary>Details</summary>
Motivation: 现存的方法如ControlNet方法依赖于手工设计的条件图和重新训练，限制了其灵活性和通用性。而基于反向映射的方法虽然提供了更高的对齐度，但由于需要双路径去噪，推断成本较高。因此，这项工作提出了无需训练的FreeControl框架来解决这些问题，提供更灵活和通用的语义结构控制方法。

Method: FreeControl 不同于从前的方法通过在多个时间步长中抽取注意力的方式，而是在一个单选的最优化时间步进行一次性的注意力抽取，并在整个去噪过程中复用这个注意力。为了进一步提高质量和稳定性，引入了潜在条件分解（LCD），通过这种方式将关键时间步和用于注意力抽取的噪声潜变量分离，从而更精细地控制注意力的质量并消除结构伪影。此外，FreeControl还支持通过参照图像进行组合控制，从而实现直观场景布局设计和强大的提示对齐。

Result: FreeControl提供了一种新的测试时间控制的范式，可以在几乎没有增加额外成本的情况下，直接从原始图像生成结构上和语义上对齐，视觉连贯的图像，并且具备直观的组合设计能力以及与现代扩散模型的兼容性。

Conclusion: FreeControl为无需训练的语义结构控制提供了一条新路径，它的高效性、通用性和灵活性使其适用于多种场景下的图像生成任务，具有重要的研究和应用价值。

Abstract: Controlling the spatial and semantic structure of diffusion-generated images
remains a challenge. Existing methods like ControlNet rely on handcrafted
condition maps and retraining, limiting flexibility and generalization.
Inversion-based approaches offer stronger alignment but incur high inference
cost due to dual-path denoising. We present FreeControl, a training-free
framework for semantic structural control in diffusion models. Unlike prior
methods that extract attention across multiple timesteps, FreeControl performs
one-step attention extraction from a single, optimally chosen key timestep and
reuses it throughout denoising. This enables efficient structural guidance
without inversion or retraining. To further improve quality and stability, we
introduce Latent-Condition Decoupling (LCD): a principled separation of the key
timestep and the noised latent used in attention extraction. LCD provides finer
control over attention quality and eliminates structural artifacts. FreeControl
also supports compositional control via reference images assembled from
multiple sources - enabling intuitive scene layout design and stronger prompt
alignment. FreeControl introduces a new paradigm for test-time control,
enabling structurally and semantically aligned, visually coherent generation
directly from raw images, with the flexibility for intuitive compositional
design and compatibility with modern diffusion models at approximately 5
percent additional cost.

</details>


### [29] [ADPretrain: Advancing Industrial Anomaly Detection via Anomaly Representation Pretraining](https://arxiv.org/abs/2511.05245)
*Xincheng Yao,Yan Luo,Zefeng Qian,Chongyang Zhang*

Main category: cs.CV

TL;DR: 提出了一个专门用于工业异常检测的预训练表示学习框架，该框架通过角度和范数导向的对比损失来学习健壮且具有区分性的预训练表示，避免了自然图像向异常检测图像的分布偏移问题。并展示了该预训练表示在五个数据集上的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的主流异常检测方法依赖于ImageNet预训练，但这并不完美匹配异常检测的目标，且自然图像和工业图像数据之间存在分布偏移，这可能导致ImageNet预训练特征对异常检测任务不够理想。目标是为异常检测任务设计专门的预训练表示，提高异常检测领域的进展。

Method: 提出了一个专门用于工业异常检测的预训练表示学习框架，通过角度和范数导向的对比损失来最大化正常和异常特征之间的角度大小和范数差异，同时在大规模AD数据集上进行预训练，以防止分布偏移问题。采用类一般化的表示，即残差特征，来学习预训练的异常检测表示。

Result: 实验结果表明，该预训练表示在五个嵌入式异常检测方法和五个基线上的五个AD数据集中表现优越。

Conclusion: 提出了一种专门用于工业异常检测的预训练表示学习框架，展示了在避免自然图像偏移到异常检测图像分布的问题上，新的预训练表示的优越性。

Abstract: The current mainstream and state-of-the-art anomaly detection (AD) methods
are substantially established on pretrained feature networks yielded by
ImageNet pretraining. However, regardless of supervised or self-supervised
pretraining, the pretraining process on ImageNet does not match the goal of
anomaly detection (i.e., pretraining in natural images doesn't aim to
distinguish between normal and abnormal). Moreover, natural images and
industrial image data in AD scenarios typically have the distribution shift.
The two issues can cause ImageNet-pretrained features to be suboptimal for AD
tasks. To further promote the development of the AD field, pretrained
representations specially for AD tasks are eager and very valuable. To this
end, we propose a novel AD representation learning framework specially designed
for learning robust and discriminative pretrained representations for
industrial anomaly detection. Specifically, closely surrounding the goal of
anomaly detection (i.e., focus on discrepancies between normals and anomalies),
we propose angle- and norm-oriented contrastive losses to maximize the angle
size and norm difference between normal and abnormal features simultaneously.
To avoid the distribution shift from natural images to AD images, our
pretraining is performed on a large-scale AD dataset, RealIAD. To further
alleviate the potential shift between pretraining data and downstream AD
datasets, we learn the pretrained AD representations based on the
class-generalizable representation, residual features. For evaluation, based on
five embedding-based AD methods, we simply replace their original features with
our pretrained representations. Extensive experiments on five AD datasets and
five backbones consistently show the superiority of our pretrained features.
The code is available at https://github.com/xcyao00/ADPretrain.

</details>


### [30] [LiveStar: Live Streaming Assistant for Real-World Online Video Understanding](https://arxiv.org/abs/2511.05299)
*Zhenyu Yang,Kairui Zhang,Yuhang Hu,Bing Wang,Shengsheng Qian,Bin Wen,Fan Yang,Tingting Gao,Weiming Dong,Changsheng Xu*

Main category: cs.CV

TL;DR: LiveStar 是一种新型的实时视频语言模型，能够实现连续帧处理和最佳响应时间确定，提高实时响应和叙事连贯性。它通过增量视频语言对齐、响应静默解析框架和内存感知加速，实现了在线视频理解的先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有在线视频语言模型（Video-LLMs）在处理连续帧输入和确定最佳响应时间方面存在不足，影响了实时响应和叙事连贯性。为解决这些问题，研发了一种新的在线视频助手LiveStar。

Method: LiveStar 方法包括：1）一种允许对不同长度视频流进行增量视频语言对齐的训练策略；2）一种通过单次前向传递验证来确定最佳响应时机的响应静默解码框架；3）峰值末尾内存压缩和流式键值缓存相结合的内存感知加速方式，提高在线推理速度。同时构建了包含15种现实场景和5种评估任务的OmniStar数据集，用于训练和基准测试。

Result: 通过在三个基准数据集上进行的广泛实验，LiveStar 达到了比现有在线视频语言模型（Video-LLMs）高19.5%的语义正确率，并将响应时间差异减少了18.1%，同时在所有五项OmniStar任务中将帧率提高了12.0%。这些性能显示了LiveStar作为在线视频理解和互动助手的领先性能。

Conclusion: LiveStar 通过改进实时视频理解技术，展现了其在在线视频语言模型中的优势和潜力，这一成果对于在线视频互动平台的发展具有重要意义。

Abstract: Despite significant progress in Video Large Language Models (Video-LLMs) for
offline video understanding, existing online Video-LLMs typically struggle to
simultaneously process continuous frame-by-frame inputs and determine optimal
response timing, often compromising real-time responsiveness and narrative
coherence. To address these limitations, we introduce LiveStar, a pioneering
live streaming assistant that achieves always-on proactive responses through
adaptive streaming decoding. Specifically, LiveStar incorporates: (1) a
training strategy enabling incremental video-language alignment for
variable-length video streams, preserving temporal consistency across
dynamically evolving frame sequences; (2) a response-silence decoding framework
that determines optimal proactive response timing via a single forward pass
verification; (3) memory-aware acceleration via peak-end memory compression for
online inference on 10+ minute videos, combined with streaming key-value cache
to achieve 1.53x faster inference. We also construct an OmniStar dataset, a
comprehensive dataset for training and benchmarking that encompasses 15 diverse
real-world scenarios and 5 evaluation tasks for online video understanding.
Extensive experiments across three benchmarks demonstrate LiveStar's
state-of-the-art performance, achieving an average 19.5% improvement in
semantic correctness with 18.1% reduced timing difference compared to existing
online Video-LLMs, while improving FPS by 12.0% across all five OmniStar tasks.
Our model and dataset can be accessed at https://github.com/yzy-bupt/LiveStar.

</details>


### [31] [Rethinking Metrics and Diffusion Architecture for 3D Point Cloud Generation](https://arxiv.org/abs/2511.05308)
*Matteo Bastico,David Ryckelynck,Laurent Corté,Yannick Tillier,Etienne Decencière*

Main category: cs.CV

TL;DR: 本文指出了常用基于Chamfer Distance的点云生成模型评估指标的局限性，并提出了一种新的基于表面法向量一致性的度量标准(Surface Normal Concordance, SNC)，提出了一个新的生成高保真三维结构的Diffusion Point Transformer架构，实验证明该方法在生成点云的质量上超越了之前的方法，达到了新的SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 当前对于3D点云生成模型的评估存在局限性，尤其是Chamfer Distance作为质量指标时，缺乏鲁棒性而且无法准确捕捉几何保真度和局部形状一致性。因此，研究新的评估方法及其与现有模型的结合使用，以期提高生成模型的质量评价水平。同时，提出新的高保真3D结构生成模型以实现更高质量的点云生成。

Method: 引入点云对齐步骤改进现有的Chamfer Distance度量；提出了一种基于表面法向量的一致性度量标准（SNC）；基于序列化补丁注意力机制的最新进展提出了一个新的生成算法Diffusion Point Transformer。

Result: 通过在ShapeNet数据集上的实验，证明了所提出的模型和度量标准在评估和生成高质量点云方面明显优于之前的解决方案，达到了新的SOTA水平。

Conclusion: 通过克服现有度量标准的局限性，并结合新的序列化补丁注意力机制提出的架构，可以实现更高的点云生成质量和更可靠的评估体系。

Abstract: As 3D point clouds become a cornerstone of modern technology, the need for
sophisticated generative models and reliable evaluation metrics has grown
exponentially. In this work, we first expose that some commonly used metrics
for evaluating generated point clouds, particularly those based on Chamfer
Distance (CD), lack robustness against defects and fail to capture geometric
fidelity and local shape consistency when used as quality indicators. We
further show that introducing samples alignment prior to distance calculation
and replacing CD with Density-Aware Chamfer Distance (DCD) are simple yet
essential steps to ensure the consistency and robustness of point cloud
generative model evaluation metrics. While existing metrics primarily focus on
directly comparing 3D Euclidean coordinates, we present a novel metric, named
Surface Normal Concordance (SNC), which approximates surface similarity by
comparing estimated point normals. This new metric, when combined with
traditional ones, provides a more comprehensive evaluation of the quality of
generated samples. Finally, leveraging recent advancements in transformer-based
models for point cloud analysis, such as serialized patch attention , we
propose a new architecture for generating high-fidelity 3D structures, the
Diffusion Point Transformer. We perform extensive experiments and comparisons
on the ShapeNet dataset, showing that our model outperforms previous solutions,
particularly in terms of quality of generated point clouds, achieving new
state-of-the-art. Code available at
https://github.com/matteo-bastico/DiffusionPointTransformer.

</details>


### [32] [AI Assisted AR Assembly: Object Recognition and Computer Vision for Augmented Reality Assisted Assembly](https://arxiv.org/abs/2511.05394)
*Alexander Htet Kyaw,Haotian Ma,Sasa Zivkovic,Jenny Sabin*

Main category: cs.CV

TL;DR: 本文提出了一种使用深度学习进行物体识别的AI辅助增强现实装配流程，该流程可以显示每个装配步骤的具体指导，减少人工搜索和排序的工作量，通过一个乐高雕塑装配案例展示了该方法的可行性


<details>
  <summary>Details</summary>
Motivation: 传统的装配流程需要人工搜索、排序和标记不同的组件，耗时耗力，因此提出了使用AI和AR技术来提高装配效率和准确性

Method: 提出了基于深度学习的物体识别技术，通过AR技术将装配步骤的指导与实际组件的位置相结合，从而实现了智能装配流程

Result: 通过乐高雕塑装配案例验证了这种方法的可行性，结果显示使用该方法可以显著提高装配效率和准确性

Conclusion: 该研究通过将深度学习和AR技术结合，实现了一种智能化的装配流程，未来可以应用于各种复杂装配任务中

Abstract: We present an AI-assisted Augmented Reality assembly workflow that uses deep
learning-based object recognition to identify different assembly components and
display step-by-step instructions. For each assembly step, the system displays
a bounding box around the corresponding components in the physical space, and
where the component should be placed. By connecting assembly instructions with
the real-time location of relevant components, the system eliminates the need
for manual searching, sorting, or labeling of different components before each
assembly. To demonstrate the feasibility of using object recognition for
AR-assisted assembly, we highlight a case study involving the assembly of LEGO
sculptures.

</details>


### [33] [What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs](https://arxiv.org/abs/2511.05292)
*Jiaxi Yin,Pengcheng Wang,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: CuisineSense是一个通过整合智能手表的手部动作线索和智能眼镜的头部动态来分类中国食品种类的系统，旨在解决传统自我报告方法和现有穿戴设备方法的局限性，提供一种无扰且准确的膳食监测方案。


<details>
  <summary>Details</summary>
Motivation: 传统自我报告饮食监测方法容易产生回忆偏差，而基于摄像头的方法又引起了隐私问题。此外，现有的穿戴式设备方法主要关注汉堡和比萨等有限种类的食物，无法满足中国菜肴多样性的需求。CuisineSense旨在解决这些问题，提供一个无扰的、准确的饮食监测方案，特别针对中国的饮食习惯和菜肴多样性。

Method: CuisineSense结合了智能手表中的手部运动线索和智能眼镜中的头部动态信息，采用了一种两阶段的检测流程。第一阶段通过识别手部和头部运动的特征模式来识别进食行为，第二阶段则通过捕获的具体进食动作来进行更详细的食品分类。

Result: 实验表明，CuisineSense系统在进食状态检测和食品分类上都取得了高的准确率。建立的数据集包含了27.5小时的IMU记录，包含了11种食品类别和10位参与者的数据。

Conclusion: CuisineSense是一项创新的工作，为无扰式饮食监测提供了可行的解决方案，特别适用于有中国特色的饮食场景。

Abstract: Accurate food intake detection is vital for dietary monitoring and chronic
disease prevention. Traditional self-report methods are prone to recall bias,
while camera-based approaches raise concerns about privacy. Furthermore,
existing wearable-based methods primarily focus on a limited number of food
types, such as hamburgers and pizza, failing to address the vast diversity of
Chinese cuisine. To bridge this gap, we propose CuisineSense, a system that
classifies Chinese food types by integrating hand motion cues from a smartwatch
with head dynamics from smart glasses. To filter out irrelevant daily
activities, we design a two-stage detection pipeline. The first stage
identifies eating states by distinguishing characteristic temporal patterns
from non-eating behaviors. The second stage then conducts fine-grained food
type recognition based on the motions captured during food intake. To evaluate
CuisineSense, we construct a dataset comprising 27.5 hours of IMU recordings
across 11 food categories and 10 participants. Experiments demonstrate that
CuisineSense achieves high accuracy in both eating state detection and food
classification, offering a practical solution for unobtrusive, wearable-based
dietary monitoring.The system code is publicly available at
https://github.com/joeeeeyin/CuisineSense.git.

</details>


### [34] [Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments](https://arxiv.org/abs/2511.05404)
*Laura Alejandra Encinar Gonzalez,John Folkesson,Rudolph Triebel,Riccardo Giubilato*

Main category: cs.CV

TL;DR: MPRF是一种基于多模态的管道，利用transformer为基础模型在视觉和LiDAR模态中实现SLAM在无结构环境中的鲁棒回环闭合检测。它结合了DINOv2和SALAD特征用于候选筛选，SONATA用于几何验证，提高了在低纹理区域的位置估计鲁棒性，优于其他最先进的回环检测方法。


<details>
  <summary>Details</summary>
Motivation: 视觉回环检测和LiDAR回环检测在SLAM中都面临各自的挑战，视觉回环检测在无纹理和对称环境中难以区分不同的地方，而LiDAR回环检测由于数据稀疏和不对称性导致误检，需要一种结合两种方法优点的新方法来实现鲁棒回环闭合检测。MPRF结合了视觉和LiDAR的特征和描述符，解决了这个问题并提高了准确性、效率和可靠性。

Method: MPRF采用两阶段策略，首先使用DINOv2和SALAD特征进行视觉特征检索，然后使用SONATA描述符进行几何验证。这种方法结合了高效检索和几何一致性验证，提高了SLAM回环闭合检测的准确性。

Result: 实验表明，MPRF在新的S3LI和S3LI Vulcano数据集上优于其他最先进的方法，尤其是在低纹理区域的位置估计鲁棒性得到了极大的提高。

Conclusion: MPRF展示了使用通用模型统一地点识别和姿态估计的前景，通过结合不同的视觉和LiDAR特征和描述符，提供了解释性对应点和姿态估计，这对SLAM后端很有用。

Abstract: Robust loop closure detection is a critical component of Simultaneous
Localization and Mapping (SLAM) algorithms in GNSS-denied environments, such as
in the context of planetary exploration. In these settings, visual place
recognition often fails due to aliasing and weak textures, while LiDAR-based
methods suffer from sparsity and ambiguity. This paper presents MPRF, a
multimodal pipeline that leverages transformer-based foundation models for both
vision and LiDAR modalities to achieve robust loop closure in severely
unstructured environments. Unlike prior work limited to retrieval, MPRF
integrates a two-stage visual retrieval strategy with explicit 6-DoF pose
estimation, combining DINOv2 features with SALAD aggregation for efficient
candidate screening and SONATA-based LiDAR descriptors for geometric
verification. Experiments on the S3LI dataset and S3LI Vulcano dataset show
that MPRF outperforms state-of-the-art retrieval methods in precision while
enhancing pose estimation robustness in low-texture regions. By providing
interpretable correspondences suitable for SLAM back-ends, MPRF achieves a
favorable trade-off between accuracy, efficiency, and reliability,
demonstrating the potential of foundation models to unify place recognition and
pose estimation. Code and models will be released at github.com/DLR-RM/MPRF.

</details>


### [35] [$\mathbf{S^2LM}$: Towards Semantic Steganography via Large Language Models](https://arxiv.org/abs/2511.05319)
*Huanqi Wu,Huangbiao Xu,Runfeng Xie,Jiaxin Cai,Kaixin Zhang,Xiao Ke*

Main category: cs.CV

TL;DR: 本文提出了Sentence-to-Image Steganography任务，利用大规模语言模型在图像中隐藏句子级别的信息，并开发了Semantic Steganographic Language Model (S^2LM) 方法，该方法通过一个新的管道设计，使大规模语言模型在整个过程中发挥作用，展示了新的语义隐藏能力。


<details>
  <summary>Details</summary>
Motivation: 随着AIGC时代的到来，对图像隐藏语义信息的能力提出了更高的要求。现有的隐写技术在句子层级的信息嵌入方面存在不足。因此，开发一种新的语义隐写方法来应对这些挑战是很有必要的。

Method: 提出了Sentence-to-Image Steganography任务，建立了Invisible Text (IVT) 基准，开发了利用大规模语言模型嵌入图像的Semantic Steganographic Language Model (S^2LM) 方法。S^2LM 方法设计了一个新的管道，使大规模语言模型在整个过程中发挥作用。

Result: 实验结果表明，S^2LM 方法能够有效地隐藏句子层级的文本信息，并具备新的语义隐藏能力。方法很好地解决了现有隐写技术在句子层级信息嵌入的不足。

Conclusion: S^2LM 方法为大规模语言模型在图像中的语义隐藏能力提供了新的途径，具有重要的理论意义和实用价值。

Abstract: Although steganography has made significant advancements in recent years, it
still struggles to embed semantically rich, sentence-level information into
carriers. However, in the era of AIGC, the capacity of steganography is more
critical than ever. In this work, we present Sentence-to-Image Steganography,
an instance of Semantic Steganography, a novel task that enables the hiding of
arbitrary sentence-level messages within a cover image. Furthermore, we
establish a benchmark named Invisible Text (IVT), comprising a diverse set of
sentence-level texts as secret messages for evaluation. Finally, we present
$\mathbf{S^2LM}$: Semantic Steganographic Language Model, which utilizes large
language models (LLMs) to embed high-level textual information, such as
sentences or even paragraphs, into images. Unlike traditional bit-level
counterparts, $\mathrm{S^2LM}$ enables the integration of semantically rich
content through a newly designed pipeline in which the LLM is involved
throughout the entire process. Both quantitative and qualitative experiments
demonstrate that our method effectively unlocks new semantic steganographic
capabilities for LLMs. The source code will be released soon.

</details>


### [36] [Canonical Space Representation for 4D Panoptic Segmentation of Articulated Objects](https://arxiv.org/abs/2511.05356)
*Manuel Gomes,Bogdan Raducanu,Miguel Oliveira*

Main category: cs.CV

TL;DR: 我们提出了一个新的数据集Artic4D和一个新的4D全景分割框架CanonSeg4D，该框架通过估计每个帧的偏移量，将观察到的对象部分映射到一个学习到的规范空间中，从而增强了部分水平的分割，提高了复杂场景下4D连贯物体感知的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的连贯物体感知方法没有充分利用4D时间数据，导致其性能不足。因此，我们通过提出新的数据集Artic4D和4D全景分割框架CanonSeg4D来解决这个问题，从而提高连贯物体感知准确性和处理复杂场景的能力。

Method: CanonSeg4D通过估计每个帧的偏移量，将观察到的对象部分映射到一个学习到的规范空间中，从而增强了部分水平的分割，提高了对象部分在连续帧间的对齐一致性。

Result: 在新的数据集Artic4D的全面实验表明，提出的CanonSeg4D框架在更复杂的场景中比现有方法更有优势，特别是在4D连贯物体感知的全景分割准确性上表现更佳。

Conclusion: 这些发现强调了在动态物体理解中，时间建模和规范对齐的重要性，为未来在4D连贯物体感知中的进步铺平了道路。

Abstract: Articulated object perception presents significant challenges in computer
vision, particularly because most existing methods ignore temporal dynamics
despite the inherently dynamic nature of such objects. The use of 4D temporal
data has not been thoroughly explored in articulated object perception and
remains unexamined for panoptic segmentation. The lack of a benchmark dataset
further hurt this field. To this end, we introduce Artic4D as a new dataset
derived from PartNet Mobility and augmented with synthetic sensor data,
featuring 4D panoptic annotations and articulation parameters. Building on this
dataset, we propose CanonSeg4D, a novel 4D panoptic segmentation framework.
This approach explicitly estimates per-frame offsets mapping observed object
parts to a learned canonical space, thereby enhancing part-level segmentation.
The framework employs this canonical representation to achieve consistent
alignment of object parts across sequential frames. Comprehensive experiments
on Artic4D demonstrate that the proposed CanonSeg4D outperforms state of the
art approaches in panoptic segmentation accuracy in more complex scenarios.
These findings highlight the effectiveness of temporal modeling and canonical
alignment in dynamic object understanding, and pave the way for future advances
in 4D articulated object perception.

</details>


### [37] [TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning](https://arxiv.org/abs/2511.05489)
*Junwen Pan,Qizhe Zhang,Rui Zhang,Ming Lu,Xin Wan,Yuan Zhang,Chang Liu,Qi She*

Main category: cs.CV

TL;DR: 本文提出了TimeSearch-R，结合强化学习（RL）和完整性自验证（CSV），改进了长视频理解中的时间搜索方法。该方法通过自我验证搜索到的视频帧来提高视频推理完整性，并构建了特定的训练数据集以增强任务难度和搜索能力。实验显示，TimeSearch-R在多个基准测试中表现出了显著提升，特别是在LongVideoBench上建立了新的最佳状态。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有时间搜索方法依赖手工制作的搜索过程，缺乏端到端的优化，从而限制了学习最优搜索策略的能力。因此，本文旨在通过结合强化学习和其他技术创新，提供一个更加智能化和自动化的解决方案，以改进时间搜索和视频理解。

Method: 方法包括将时间搜索重构为文本-视频思考的交递过程，并结合强化学习进行。引入了GRPO-CSV，通过使用同一政策模型验证搜索到的视频帧的完整性，加强了视频推理的完成度。此外，还设置了专门的数据集来提升模型训练的难度和搜索任务的准确性。

Result: 实验表明，TimeSearch-R在时间搜索标准（如Haystack-LVBench，Haystack-Ego4D）和视频理解标准（如VideoMME，MLVU）上都有所改进，并且在LongVideoBench上，相较于基础模型Qwen2.5-VL和视频推理模型Video-R1，都会有显著提升（4.1%和2.0%）。

Conclusion: 本文提出的方法提供了一种新的时间搜索方法论，特别是在优化视频推理的完整性和提供更准确的时间搜索能力方面，取得了显著的进展。

Abstract: Temporal search aims to identify a minimal set of relevant frames from tens
of thousands based on a given query, serving as a foundation for accurate
long-form video understanding. Existing works attempt to progressively narrow
the search space. However, these approaches typically rely on a hand-crafted
search process, lacking end-to-end optimization for learning optimal search
strategies. In this paper, we propose TimeSearch-R, which reformulates temporal
search as interleaved text-video thinking, seamlessly integrating searching
video clips into the reasoning process through reinforcement learning (RL).
However, applying RL training methods, such as Group Relative Policy
Optimization (GRPO), to video reasoning can result in unsupervised intermediate
search decisions. This leads to insufficient exploration of the video content
and inconsistent logical reasoning. To address these issues, we introduce GRPO
with Completeness Self-Verification (GRPO-CSV), which gathers searched video
frames from the interleaved reasoning process and utilizes the same policy
model to verify the adequacy of searched frames, thereby improving the
completeness of video reasoning. Additionally, we construct datasets
specifically designed for the SFT cold-start and RL training of GRPO-CSV,
filtering out samples with weak temporal dependencies to enhance task
difficulty and improve temporal search capabilities. Extensive experiments
demonstrate that TimeSearch-R achieves significant improvements on temporal
search benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as
long-form video understanding benchmarks like VideoMME and MLVU. Notably,
TimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1%
improvement over the base model Qwen2.5-VL and 2.0% over the advanced video
reasoning model Video-R1. Our code is available at
https://github.com/Time-Search/TimeSearch-R.

</details>


### [38] [Dense Motion Captioning](https://arxiv.org/abs/2511.05369)
*Shiyao Xu,Benedetta Liberatori,Gül Varol,Paolo Rota*

Main category: cs.CV

TL;DR: 本文介绍了一种新的任务——密集动作注释（Dense Motion Captioning），该任务旨在对3D人体运动序列中的动作进行时间定位和注释。为此，作者提出复杂的运动数据集（CompMo）以及一个名为DEMO的模型。DEMO结合了大型语言模型和简单的运动适配器，用于生成密集的、时间接地的注释。实验结果表明，DEMO在CompMo和改编的基准测试上显著优于现有方法，为未来3D运动理解和注释的研究奠定了坚实基础。


<details>
  <summary>Details</summary>
Motivation: 现有的3D人类动作和语言集成研究主要集中在文本到动作的生成，而对动作理解的任务研究较少。本文旨在通过密集动作注释这一新任务来解决这一问题，并克服现有数据集在时间注释详细程度和动作序列复杂性上的不足。

Method: 作者提出了复杂运动数据集（CompMo），该数据集包含60,000个运动序列，每个序列包含至少两个到十个动作，并精确标注其时间范围。此外，作者还提出DEMO模型，该模型结合了大型语言模型和简单运动适配器，用于生成密集的时间接地注释。

Result: 实验结果显示，DEMO在CompMo数据集和改编的基准测试上显著优于现有方法。DEMO的性能优越性展示了其在3D运动理解和注释方面的有效性。

Conclusion: DEMO模型通过在复杂运动数据集（CompMo）上的实验验证了其先进的性能，确立了在3D动作理解和注释领域中的高强度基准。

Abstract: Recent advances in 3D human motion and language integration have primarily
focused on text-to-motion generation, leaving the task of motion understanding
relatively unexplored. We introduce Dense Motion Captioning, a novel task that
aims to temporally localize and caption actions within 3D human motion
sequences. Current datasets fall short in providing detailed temporal
annotations and predominantly consist of short sequences featuring few actions.
To overcome these limitations, we present the Complex Motion Dataset (CompMo),
the first large-scale dataset featuring richly annotated, complex motion
sequences with precise temporal boundaries. Built through a carefully designed
data generation pipeline, CompMo includes 60,000 motion sequences, each
composed of multiple actions ranging from at least two to ten, accurately
annotated with their temporal extents. We further present DEMO, a model that
integrates a large language model with a simple motion adapter, trained to
generate dense, temporally grounded captions. Our experiments show that DEMO
substantially outperforms existing methods on CompMo as well as on adapted
benchmarks, establishing a robust baseline for future research in 3D motion
understanding and captioning.

</details>


### [39] [PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Visual Quality Assessment via Preference-Response Disentangled Policy Optimization](https://arxiv.org/abs/2511.05393)
*Zehui Feng,Tian Qiu,Tong Wu,Junxuan Li,Huayuan Xu,Ting Han*

Main category: cs.CV

TL;DR: 提出了一种新的视觉质量评估框架PreResQ-R1，该框架结合了绝对分数回归和相对排名一致性，并引入了双分支奖励机制，能够实现更细粒度、更稳定且可解释性强的推理过程。此外，针对视频质量评估，设计了一种全局-时间域数据流策略。在多种图像和视频质量评估基准测试中，PreResQ-R1表现出色，优于现有方法，并生成与人类感知一致的推理路径。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉质量评估方法主要依赖监督微调或仅排名目标，导致浅层推理、分数不准确和跨领域泛化能力差。为了应对这些问题，研究者设计了PreResQ-R1框架，旨在通过强化学习实现更深层次的推理过程和更准确的分数预估，同时保持跨领域泛化能力。

Method: PreResQ-R1采用了一种偏好-响应分离的强化学习框架，优化了绝对分数回归和相对排名一致性。引入了双分支奖励机制，以独立建模样本内部响应一致性与样本间偏好对齐，采用组相对策略优化进行优化。此外，为了适应视频质量评估，设计了全局-时间域与局部空域相结合的数据流策略。使用6K图像和28K视频进行了有限量的强化学习微调实验。

Result: PreResQ-R1框架在多种图像和视频质量评估基准测试中分别取得了5.30%和2.15%的两倍优于现有方法的性能提升。并且能够生成与人类感知一致的推理路径，揭示了质量评估背后的感知线索。该框架利用有限的数据量，在多个评测标准中均获得了最先进的性能。

Conclusion: 该研究提出了一种新的视觉质量评估框架，通过结合绝对分数回归和相对排名一致性，利用偏好-响应分离的强化学习方法，不仅提高了准确性，还增强了跨领域泛化能力。该方法不仅在多个图像和视频质量评估基准中表现优异，还在解释人类感知方面取得了突破。

Abstract: Visual Quality Assessment (QA) seeks to predict human perceptual judgments of
visual fidelity. While recent multimodal large language models (MLLMs) show
promise in reasoning about image and video quality, existing approaches mainly
rely on supervised fine-tuning or rank-only objectives, resulting in shallow
reasoning, poor score calibration, and limited cross-domain generalization. We
propose PreResQ-R1, a Preference-Response Disentangled Reinforcement Learning
framework that unifies absolute score regression and relative ranking
consistency within a single reasoning-driven optimization scheme. Unlike prior
QA methods, PreResQ-R1 introduces a dual-branch reward formulation that
separately models intra-sample response coherence and inter-sample preference
alignment, optimized via Group Relative Policy Optimization (GRPO). This design
encourages fine-grained, stable, and interpretable chain-of-thought reasoning
about perceptual quality. To extend beyond static imagery, we further design a
global-temporal and local-spatial data flow strategy for Video Quality
Assessment. Remarkably, with reinforcement fine-tuning on only 6K images and
28K videos, PreResQ-R1 achieves state-of-the-art results across 10 IQA and 5
VQA benchmarks under both SRCC and PLCC metrics, surpassing by margins of 5.30%
and textbf2.15% in IQA task, respectively. Beyond quantitative gains, it
produces human-aligned reasoning traces that reveal the perceptual cues
underlying quality judgments. Code and model are available.

</details>


### [40] [PALM: A Dataset and Baseline for Learning Multi-subject Hand Prior](https://arxiv.org/abs/2511.05403)
*Zicong Fan,Edoardo Remelli,David Dimond,Fadime Sener,Liuhao Ge,Bugra Tekin,Cem Keskin,Shreyas Hampali*

Main category: cs.CV

TL;DR: 本文介绍了一个名为PALM的大规模手部数据集，包含13k高质量的手部扫描和90k多视角图片，旨在支持真实、可重光的单图像手部角色个性化创建。


<details>
  <summary>Details</summary>
Motivation: 创建高质量个性化手部模型的挑战包括复杂的几何结构、外观以及姿态，尤其是在不受约束的光照和有限视角的情况下。现有数据集缺乏准确的三维几何结构、高分辨率多视角图像以及多样化的受试人群。这项研究旨在通过创建一个新的大型数据集来解决这些问题。

Method: 研究人员建立了PALM数据集，包含来自263个受试者的手部扫描和多视角图像，展示了皮肤颜色、年龄和几何结构等方面的丰富变化，并使用基于物理的逆向渲染技术学习了手部几何结构和材料属性的多受试者先验，提出了PALM-Net作为基线模型，以实现真实、可重光的单图像手部角色个性化创建。

Result: 实验结果表明，PALM数据集及其基线模型PALM-Net能够支持高质量的手部建模和个性化，并且这些结果在现实世界的手部模拟和研究中具有明显的优势。

Conclusion: PALM数据集提供了大量的高质量手部扫描和多视角图像，并且它所支持的基于物理的逆向渲染技术为手部角色个性化提供了新方法，使得单图像手部角色个性化变得更加简单且实用。

Abstract: The ability to grasp objects, signal with gestures, and share emotion through
touch all stem from the unique capabilities of human hands. Yet creating
high-quality personalized hand avatars from images remains challenging due to
complex geometry, appearance, and articulation, particularly under
unconstrained lighting and limited views. Progress has also been limited by the
lack of datasets that jointly provide accurate 3D geometry, high-resolution
multiview imagery, and a diverse population of subjects. To address this, we
present PALM, a large-scale dataset comprising 13k high-quality hand scans from
263 subjects and 90k multi-view images, capturing rich variation in skin tone,
age, and geometry. To show its utility, we present a baseline PALM-Net, a
multi-subject prior over hand geometry and material properties learned via
physically based inverse rendering, enabling realistic, relightable
single-image hand avatar personalization. PALM's scale and diversity make it a
valuable real-world resource for hand modeling and related research.

</details>


### [41] [Sharing the Learned Knowledge-base to Estimate Convolutional Filter Parameters for Continual Image Restoration](https://arxiv.org/abs/2511.05421)
*Aupendu Kar,Krishnendu Ghosh,Prabir Kumar Biswas*

Main category: cs.CV

TL;DR: 提出了一个简单的方法来修改卷积层，使模型能够从之前的图像恢复任务中吸收知识，而不需要对主要的骨干架构进行任何结构性修改，从而实现了连续学习中图像恢复任务的无缝适应。实验验证表明，新任务可以被引入而不牺牲现有任务的性能，并且新的恢复任务的性能可以通过适应由之前的恢复任务创建的知识库而提高。


<details>
  <summary>Details</summary>
Motivation: 图像恢复领域中的连续学习由于处理大图像尺寸和各种退化类型存在独特挑战，现有的工作需要大量的架构修改，导致了显著的计算开销。因此，开发了一种不改变主架构的方式来进行连续学习是必要的，以解决这些问题。

Method: 通过简单地修改卷积层适应来自先前恢复任务的知识，而不对主要的骨干架构进行任何结构修改。这使得它可以无缝应用于任何深度架构中，而且可以增加可训练参数的数量，而不会显著增加计算开销或推理时间。

Result: 研究实验表明，该方法能够在引入新恢复任务的同时保持现有任务的表现，而且新任务的表现可以通过适应由前期任务创建的知识库提高。

Conclusion: 在不断学习领域，特别是图像恢复任务，通过提供简单的卷积层修改，可以实现没有明显的计算开销的无缝适应。实验结果验证了该方法的有效性。

Abstract: Continual learning is an emerging topic in the field of deep learning, where
a model is expected to learn continuously for new upcoming tasks without
forgetting previous experiences. This field has witnessed numerous
advancements, but few works have been attempted in the direction of image
restoration. Handling large image sizes and the divergent nature of various
degradation poses a unique challenge in the restoration domain. However,
existing works require heavily engineered architectural modifications for new
task adaptation, resulting in significant computational overhead.
Regularization-based methods are unsuitable for restoration, as different
restoration challenges require different kinds of feature processing. In this
direction, we propose a simple modification of the convolution layer to adapt
the knowledge from previous restoration tasks without touching the main
backbone architecture. Therefore, it can be seamlessly applied to any deep
architecture without any structural modifications. Unlike other approaches, we
demonstrate that our model can increase the number of trainable parameters
without significantly increasing computational overhead or inference time.
Experimental validation demonstrates that new restoration tasks can be
introduced without compromising the performance of existing tasks. We also show
that performance on new restoration tasks improves by adapting the knowledge
from the knowledge base created by previous restoration tasks. The code is
available at https://github.com/aupendu/continual-restore.

</details>


### [42] [Shared Latent Representation for Joint Text-to-Audio-Visual Synthesis](https://arxiv.org/abs/2511.05432)
*Dogucan Yaman,Seymanur Akti,Fevziye Irem Eyiokur,Alexander Waibel*

Main category: cs.CV

TL;DR: 提出了一种基于HierSpeech++的文本到面部动画合成框架，通过Wav2Vec2嵌入将文本转换为语音和面部生成的条件。采用两阶段训练方法，提升了音视频对齐和视觉真实性。


<details>
  <summary>Details</summary>
Motivation: 解决干净语音和TTS预测特征之间的分布偏移问题，从而改进文本到语音合成的音视频对齐和自然表达能力。

Method: 通过Text-to-Vec模块生成Wav2Vec2嵌入，将其用作语音和面部生成的条件。采用两阶段训练框架：在Wav2Vec2嵌入上进行预训练，然后在TTS输出上进行微调。

Result: 实验结果表明，通过条件设置TTS生成的潜在特征比简单的级联管道更为高效，提升了唇形同步和视觉真实性。

Conclusion: 该方法能够生成自然且富有表现力的语音和同步的面部动作，无需真实的语音录入，在保持说话者身份的同时，实现了音视频的紧密对齐。

Abstract: We propose a text-to-talking-face synthesis framework leveraging latent
speech representations from HierSpeech++. A Text-to-Vec module generates
Wav2Vec2 embeddings from text, which jointly condition speech and face
generation. To handle distribution shifts between clean and TTS-predicted
features, we adopt a two-stage training: pretraining on Wav2Vec2 embeddings and
finetuning on TTS outputs. This enables tight audio-visual alignment, preserves
speaker identity, and produces natural, expressive speech and synchronized
facial motion without ground-truth audio at inference. Experiments show that
conditioning on TTS-predicted latent features outperforms cascaded pipelines,
improving both lip-sync and visual realism.

</details>


### [43] [How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?](https://arxiv.org/abs/2511.05449)
*Tuan Anh Tran,Duy M. H. Nguyen,Hoai-Chau Tran,Michael Barz,Khoa D. Doan,Roger Wattenhofer,Ngo Anh Vien,Mathias Niepert,Daniel Sonntag,Paul Swoboda*

Main category: cs.CV

TL;DR: 介绍了一种名为gitmerge3D的方法，该方法通过减少冗余的tokens来提高3D点云变换器的计算效率，同时保持了竞争力的性能。此发现挑战了更多的tokens就必然产生更好性能的假设，推动了3D基础架构的发展。


<details>
  <summary>Details</summary>
Motivation: 现有3D点云变换器模型因依赖密集的token表示而导致高计算和内存成本，且过度设计了tokens。这些模型在可扩展性方面存在不足，因此需要开发出计算效率更高同时性能竞争力的模型，这促使作者研究出gitmerge3D方法。

Method: gitmerge3D方法通过引入全局信息的图token合并来降低token数，最多可减少90-95%，同时保持性能的竞争力。这种方法消除了token越多性能越好的错误假设，推进了3D基础架构的效率。

Result: 此方法在多个3D视觉任务上的表现均展示了计算效率的显著提升，具有广泛的应用前景。

Conclusion: gitmerge3D方法是首个评估大规模3D变换器模型中多余性的研究，为开发更加高效的3D基础架构提供重要见解。

Abstract: Recent advances in 3D point cloud transformers have led to state-of-the-art
results in tasks such as semantic segmentation and reconstruction. However,
these models typically rely on dense token representations, incurring high
computational and memory costs during training and inference. In this work, we
present the finding that tokens are remarkably redundant, leading to
substantial inefficiency. We introduce gitmerge3D, a globally informed graph
token merging method that can reduce the token count by up to 90-95% while
maintaining competitive performance. This finding challenges the prevailing
assumption that more tokens inherently yield better performance and highlights
that many current models are over-tokenized and under-optimized for
scalability. We validate our method across multiple 3D vision tasks and show
consistent improvements in computational efficiency. This work is the first to
assess redundancy in large-scale 3D transformer models, providing insights into
the development of more efficient 3D foundation architectures. Our code and
checkpoints are publicly available at https://gitmerge3d.github.io

</details>


### [44] [The Potential of Copernicus Satellites for Disaster Response: Retrieving Building Damage from Sentinel-1 and Sentinel-2](https://arxiv.org/abs/2511.05461)
*Olivier Dietrich,Merlin Alfredsson,Emilia Arens,Nando Metzger,Torben Peters,Linus Scheibenreif,Jan Dirk Wegner,Konrad Schindler*

Main category: cs.CV

TL;DR: 研究者使用来自Copernicus计划的中分辨率地球观测图像进行建筑物灾害损失评估，并介绍了xBD-S12数据集，发现即使在10米的地面采样距离下，对灾害损失的检测和地图绘制仍然可以很好地完成。研究还表明，复杂的模型架构在泛化到未知灾害时效果不佳，地理基础模型带来的实用效益有限。


<details>
  <summary>Details</summary>
Motivation: 研究目的是探讨是否存在可以支持建筑物损毁评估的中分辨率地球观测图像，并且可以补充通常有限可用性的非常高分辨率图像，特别是在自然灾害发生后进行快速损害评估的场景中，以指导人道主义救援。而xBD-S12数据集的初衷在于提供此类信息，以支持快速、大面积损害评估。这项研究的动机在于促进对灾害后快速损害评估的技术手段的进一步发展。

Method: 构造了xBD-S12数据集，该数据集由来自Sentinel-1和Sentinel-2的10,315对灾害前后图像组成，这些图像在空间和时间上与现有的xBD基准进行对齐。进行了几个实验，证明建筑损毁可以通过这些图像有效地检测和制图。同时研究了复杂模型架构在泛化到未见灾害时的表现，并探索了地理基础模型的实际效益。

Result: 实验结果显示，即使对于较为简陋的模型架构，也可以在各种灾害场景中很好地完成建筑损毁的检测与地图绘制。复杂的模型架构在泛化到新的、未见过的灾害时，往往表现较差，地理基础模型在该任务上的实用效益不大。总体来说，研究证明了Copernicus卫星图像可以作为一种有效的快速、大面积损害评估的数据来源，可以与非常高的分辨率图像并行使用。该研究还发布了数据集、代码和训练好的模型，支持后续研究。

Conclusion: 研究表明，中分辨率卫星图像能够很好地用于灾害后的建筑物损害评估，这些图像可以作为快速、大面积损害评估的重要数据源。通过广泛的数据分享，该研究提供了可能促进灾害评估技术进一步发展的有价值资源。

Abstract: Natural disasters demand rapid damage assessment to guide humanitarian
response. Here, we investigate whether medium-resolution Earth observation
images from the Copernicus program can support building damage assessment,
complementing very-high resolution imagery with often limited availability. We
introduce xBD-S12, a dataset of 10,315 pre- and post-disaster image pairs from
both Sentinel-1 and Sentinel-2, spatially and temporally aligned with the
established xBD benchmark. In a series of experiments, we demonstrate that
building damage can be detected and mapped rather well in many disaster
scenarios, despite the moderate 10$\,$m ground sampling distance. We also find
that, for damage mapping at that resolution, architectural sophistication does
not seem to bring much advantage: more complex model architectures tend to
struggle with generalization to unseen disasters, and geospatial foundation
models bring little practical benefit. Our results suggest that Copernicus
images are a viable data source for rapid, wide-area damage assessment and
could play an important role alongside VHR imagery. We release the xBD-S12
dataset, code, and trained models to support further research.

</details>


### [45] [Photo Dating by Facial Age Aggregation](https://arxiv.org/abs/2511.05464)
*Jakub Paplham,Vojtech Franc*

Main category: cs.CV

TL;DR: 该研究提出了一种通过分析照片中人脸信息来估计照片拍摄年份的新方法，并公开发布了CSFD-1.6M数据集，包含超过160万张带注释的面部图像。研究采用概率框架将现代人脸识别和年龄估计模型的视觉证据与职业时间先验相结合，以推断照片拍摄年份。实验证明，从多张人脸中聚合证据可以显著提高性能，特别是在包含多个可识别个体的照片中表现优于场景基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前存在大量的未标记年代信息的历史照片，本文提出的方法可以用于给这些照片估算拍摄年份，具有重要的研究和应用价值。

Method: 研究提出了一种基于概率框架的方法，该框架结合了现代人脸识别和年龄估计模型的视觉证据以及基于职业的职业时间先验来推断照片拍摄年份。通过进行多张人脸信息的聚合以提高准确度。

Result: 实验结果显示，该方法在包含多个可识别个体的照片上显著优于传统的基于场景的基准方法，证明了从多张人脸中聚合证据的有效性。

Conclusion: 该研究提出了一种新颖的方法来估计照片拍摄年份，并通过公开发布的大型数据集验证了该方法的效果。未来可进一步研究如何提高模型在更复杂场景下的鲁棒性。

Abstract: We introduce a novel method for Photo Dating which estimates the year a
photograph was taken by leveraging information from the faces of people present
in the image. To facilitate this research, we publicly release CSFD-1.6M, a new
dataset containing over 1.6 million annotated faces, primarily from movie
stills, with identity and birth year annotations. Uniquely, our dataset
provides annotations for multiple individuals within a single image, enabling
the study of multi-face information aggregation. We propose a probabilistic
framework that formally combines visual evidence from modern face recognition
and age estimation models, and career-based temporal priors to infer the photo
capture year. Our experiments demonstrate that aggregating evidence from
multiple faces consistently improves the performance and the approach
significantly outperforms strong, scene-based baselines, particularly for
images containing several identifiable individuals.

</details>


### [46] [EventFlow: Real-Time Neuromorphic Event-Driven Classification of Two-Phase Boiling Flow Regimes](https://arxiv.org/abs/2511.05467)
*Sanghyeon Chang,Srikar Arani,Nishant Sai Nuthalapati,Youngjoon Suh,Nicholas Choi,Siavash Khodakarami,Md Rakibul Hasan Roni,Nenad Miljkovic,Aparna Chandramowlishwaran,Yoonjin Won*

Main category: cs.CV

TL;DR: 文章提出了一种基于神经形态传感器信号的实时流动状态分类框架，通过使用事件数据的模型，特别是在基于事件的长短期记忆模型中达到97.6%的准确率和0.28毫秒的处理时间，解决了常规光学成像方法在时间和计算需求上的限制，实现了对流动热管理系统的高效实时监控和智能管理


<details>
  <summary>Details</summary>
Motivation: 流动沸腾作为一种高效的热交换机制，存在突然的流态转换可能导致热管理系统的可靠性和性能下降问题。鉴于传统光学成像方法在计算需求和时间分辨率方面的局限性，研究提出了一种新的解决方案

Method: 该研究使用神经形态传感器来检测亮度变化，进而识别流动状态，开发了利用传统图像数据和基于事件数据的五种分类模型, 其中基于事件的长短期记忆模型表现最好

Result: 基于事件的长短期记忆模型实现了97.6%的分类准确率和0.28毫秒的处理时间；所提出的异步处理流水线能够支持连续的低延迟预测，并通过多数投票机制提供稳定的输出

Conclusion: 该研究提出了一种新颖的方法，采用神经形态传感器进行实时流动状态分类，有效地解决了传统光学成像方法的局限性，为实现高效、智能的热管理系统提供了强有力的支持

Abstract: Flow boiling is an efficient heat transfer mechanism capable of dissipating
high heat loads with minimal temperature variation, making it an ideal thermal
management method. However, sudden shifts between flow regimes can disrupt
thermal performance and system reliability, highlighting the need for accurate
and low-latency real-time monitoring. Conventional optical imaging methods are
limited by high computational demands and insufficient temporal resolution,
making them inadequate for capturing transient flow behavior. To address this,
we propose a real-time framework based on signals from neuromorphic sensors for
flow regime classification. Neuromorphic sensors detect changes in brightness
at individual pixels, which typically correspond to motion at edges, enabling
fast and efficient detection without full-frame reconstruction, providing
event-based information. We develop five classification models using both
traditional image data and event-based data, demonstrating that models
leveraging event data outperform frame-based approaches due to their
sensitivity to dynamic flow features. Among these models, the event-based long
short-term memory model provides the best balance between accuracy and speed,
achieving 97.6% classification accuracy with a processing time of 0.28 ms. Our
asynchronous processing pipeline supports continuous, low-latency predictions
and delivers stable output through a majority voting mechanisms, enabling
reliable real-time feedback for experimental control and intelligent thermal
management.

</details>


### [47] [GroupKAN: Rethinking Nonlinearity with Grouped Spline-based KAN Modeling for Efficient Medical Image Segmentation](https://arxiv.org/abs/2511.05477)
*Guojie Li,Anwar P. P. Abdul Majeed,Muhammad Ateeq,Anh Nguyen,Fan Zhang*

Main category: cs.CV

TL;DR: U-KAN 使用 Kolmogorov-Arnold Networks 解决了医学图像分割中的几个挑战，但其 O(C^2) 复杂度限制了其可扩展性。为克服这一限制，提出了 GroupKAN，采用分组 KAN 变换和激活模块，平均 IoU 达到了 79.80%，参数量仅 3.02M，且具有更好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 在医学图像分割中，需要准确、轻量且可解释的模型。Convolutional 和 Transformer 架构分别在适应性非线性和透明决策方面存在不足，U-KAN 通过使用 Kolmogorov-Arnold Networks 部分解决了这些问题，但 O(C^2) 复杂度限制了其可扩展性，因此，作者提出了 GroupKAN 来进一步改善这些问题。

Method: GroupKAN 引入了 Grouped KAN Transform 和 Grouped KAN Activation 两个新型模块。前者将通道分为 G 组，进行多变量样条映射，将复杂度降为 O(C^2/G)；后者在每个通道组中应用共享样条映射，实现高效、逐令牌的非线性。

Result: 在 BUSI、GlaS 和 CVC 三个医学基准测试上，GroupKAN 实现了 79.80% 的平均 IoU，超过了 U-KAN +1.11 百分点，而且参数量仅为 U-KAN 的 47.6%，即 3.02M vs 6.35M。此外，GroupKAN 还表现出更好的可解释性。

Conclusion: 研究提出GroupKAN，通过采用分组KAN变换和激活来改善医学图像分割模型的复杂度问题，同时保持甚至提高了准确性、轻量化以及可解释性。

Abstract: Medical image segmentation requires models that are accurate, lightweight,
and interpretable. Convolutional architectures lack adaptive nonlinearity and
transparent decision-making, whereas Transformer architectures are hindered by
quadratic complexity and opaque attention mechanisms. U-KAN addresses these
challenges using Kolmogorov-Arnold Networks, achieving higher accuracy than
both convolutional and attention-based methods, fewer parameters than
Transformer variants, and improved interpretability compared to conventional
approaches. However, its O(C^2) complexity due to full-channel transformations
limits its scalability as the number of channels increases. To overcome this,
we introduce GroupKAN, a lightweight segmentation network that incorporates two
novel, structured functional modules: (1) Grouped KAN Transform, which
partitions channels into G groups for multivariate spline mappings, reducing
complexity to O(C^2/G), and (2) Grouped KAN Activation, which applies shared
spline-based mappings within each channel group for efficient, token-wise
nonlinearity. Evaluated on three medical benchmarks (BUSI, GlaS, and CVC),
GroupKAN achieves an average IoU of 79.80 percent, surpassing U-KAN by +1.11
percent while requiring only 47.6 percent of the parameters (3.02M vs 6.35M),
and shows improved interpretability.

</details>


### [48] [Visual Spatial Tuning](https://arxiv.org/abs/2511.05491)
*Rui Yang,Ziyu Zhu,Yanwei Li,Jingjia Huang,Shen Yan,Siyuan Zhou,Zhe Liu,Xiangtai Li,Shuangye Li,Wenqian Wang,Yi Lin,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 提出了一种增强视觉语言模型空间能力的框架Visual Spatial Tuning (VST)，通过两个大规模数据集和一个训练流程来提升模型的空间感知和推理能力，同时保持其通用能力不受影响，并在多个基准测试中实现了最优结果，为更物理化的AI研究奠定了基础


<details>
  <summary>Details</summary>
Motivation: 为了增强视觉语言模型（VLMs）的空间感知能力和推理能力，同时保持其通用能力不受影响，从而使其具备更接近人类的视觉空间技能

Method: 构建了两个大规模数据集，VST-P 用于增强空间感知，VST-R 用于空间推理；采用了监督微调和强化学习相结合的训练流程来提升模型性能

Result: 在多个空间基准测试中实现了最优结果，尤其是$34.8	extbackslash	extbackslash%$和$61.2	extbackslash	extbackslash%$的分别在MMSI-Bench和VSIBench上的表现，表明该框架有效

Conclusion: 提出的VST框架为提升视觉语言-动作模型的空间能力提供了一种有效的方法，促进了更物理化的AI研究

Abstract: Capturing spatial relationships from visual inputs is a cornerstone of
human-like general intelligence. Several previous studies have tried to enhance
the spatial awareness of Vision-Language Models (VLMs) by adding extra expert
encoders, which brings extra overhead and usually harms general capabilities.
To enhance the spatial ability in general architectures, we introduce Visual
Spatial Tuning (VST), a comprehensive framework to cultivate VLMs with
human-like visuospatial abilities, from spatial perception to reasoning. We
first attempt to enhance spatial perception in VLMs by constructing a
large-scale dataset termed VST-P, which comprises 4.1 million samples spanning
19 skills across single views, multiple images, and videos. Then, we present
VST-R, a curated dataset with 135K samples that instruct models to reason in
space. In particular, we adopt a progressive training pipeline: supervised
fine-tuning to build foundational spatial knowledge, followed by reinforcement
learning to further improve spatial reasoning abilities. Without the
side-effect to general capabilities, the proposed VST consistently achieves
state-of-the-art results on several spatial benchmarks, including $34.8\%$ on
MMSI-Bench and $61.2\%$ on VSIBench. It turns out that the
Vision-Language-Action models can be significantly enhanced with the proposed
spatial tuning paradigm, paving the way for more physically grounded AI.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [49] [AWARE: Evaluating PriorityFresh Caching for Offline Emergency Warning Systems](https://arxiv.org/abs/2511.05022)
*Charles Melvin,N. Rich Nguyen*

Main category: cs.NI

TL;DR: PriorityFresh是一种为离线紧急预警系统设计的语义化、行动优先的缓存策略，在AWARE系统的仿真环境中优化了在连接受限条件下保留和展示哪些警报，实验表明这提高了行动优先性能，而不会影响效率。此外，还有一个用于合成现实警报序列的Priority Forecasting模型，仅用于受控实验，不参与缓存或推送决策。


<details>
  <summary>Details</summary>
Motivation: 提出PriorityFresh的动机是为了在离线紧急预警系统中，在有限的连接环境下，优化警报的缓存和展示，使其更有利于行动执行，从而提高应急响应的效率和效果。

Method: PriorityFresh基于语义分析和行动优先的目标，设计了一种新的缓存策略，该策略在AWARE系统仿真环境中测试，并通过实验验证其性能。同时，还开发了一个Priority Forecasting模型用于生成现实的警报序列，以进行受控实验比较。

Result: 实验结果表明，PriorityFresh可以在不降低效率的情况下提高行动优先性能，这意味着警报可以更快地被用户定位并采取行动。

Conclusion: 这项工作展示了如何通过行动优先的缓存策略（PriorityFresh）优化紧急预警信息的处理，进而提高应急响应的效率和效果。

Abstract: PriorityFresh is a semantic, actionability-first caching policy designed for
offline emergency warning systems. Within the AWARE system's simulation
environment, PriorityFresh optimizes which alerts to retain and surface under
constrained connectivity. Experiments indicate improved actionability-first
performance without harming efficiency. A separate Priority Forecasting model
is used only to synthesize realistic alert sequences for controlled experiments
and does not influence caching or push decisions.

</details>


### [50] [EPFL-REMNet: Efficient Personalized Federated Digital Twin Towards 6G Heterogeneous Radio Environme](https://arxiv.org/abs/2511.05238)
*Peide Li,Liu Cao,Lyutianyang Zhang,Dongyu Wei,Ye Hu,Qipeng Xie*

Main category: cs.NI

TL;DR: 提出了一种高效个人化的联邦学习框架EPFL-REMNet，用于构建6G异构无线环境的高保真数字孪生。在数据分布不独立不等概率（Non-IID）的情况下，EPFL-REMNet能同时提高数字孪生的保真度并减少上行传输开销，优于标准FedAvg和其他最新方法。


<details>
  <summary>Details</summary>
Motivation: 在5G向B5G/6G过渡的阶段，标准的联邦学习遇到精度和通信效率降低的问题，特别是在数据分布不独立不等概率的环境下。为了应对这一挑战，提出一种新的联邦学习框架来解决构建高保真度数字孪生的问题。

Method: EPFL-REMNet采用“共享主体+轻量化个性化头部”的模型，在服务器和客户端之间只传输压缩后的共享主体，个性化头部在客户端本地保持。数据地理分区后，构建了三种不同程度的Non-IID场景进行测试。

Result: 实验表明，EPFL-REMNet在所有Non-IID场景下同时提高了数字孪生的保真度并降低了上行传输开销，相比于标准FedAvg和其他最新方法具有明显优势。特别是在长尾客户端上，其局部地图精度有显著提升。

Conclusion: EPFL-REMNet有效解决了在数据分布不独立不等概率环境下，构建高效和高保真度数字孪生的问题。

Abstract: Radio Environment Map (REM) is transitioning from 5G homogeneous environments
to B5G/6G heterogeneous landscapes. However, standard Federated Learning (FL),
a natural fit for this distributed task, struggles with performance degradation
in accuracy and communication efficiency under the non-independent and
identically distributed (Non-IID) data conditions inherent to these new
environments. This paper proposes EPFL-REMNet, an efficient personalized
federated framework for constructing a high-fidelity digital twin of the 6G
heterogeneous radio environment. The proposed EPFL-REMNet employs a"shared
backbone + lightweight personalized head" model, where only the compressed
shared backbone is transmitted between the server and clients, while each
client's personalized head is maintained locally. We tested EPFL-REMNet by
constructing three distinct Non-IID scenarios (light, medium, and heavy) based
on radio environment complexity, with data geographically partitioned across 90
clients. Experimental results demonstrate that EPFL-REMNet simultaneously
achieves higher digital twin fidelity (accuracy) and lower uplink overhead
across all Non-IID settings compared to standard FedAvg and recent
state-of-the-art methods. Particularly, it significantly reduces performance
disparities across datasets and improves local map accuracy for long-tail
clients, enhancing the overall integrity of digital twin.

</details>


### [51] [A Formal Model for Path Set Attribute Calculation in Network Systems](https://arxiv.org/abs/2511.05334)
*Giovanni Fiaschi,Carlo Vitucci,Thomas Westerbäck,Daniel Sundmark,Thomas Nolte*

Main category: cs.NI

TL;DR: 本文提出了一个数学方法来描述路径集合的特征，强调路径的特征取决于所考虑的属性。这个功能模型可以很好地适用于一般路径集的描述，并且展示了如何将特定属性整合到该模型中。



<details>
  <summary>Details</summary>
Motivation: 先前研究对单个路径的评估是全面的，但在考虑路径集合时，这种详细程度不足。本文指出路径特性强烈依赖于所考虑的属性，而将属性纳入路径集合的评估至关重要。


Method: 本文提出了一种数学方法，该方法定义了一个功能性模型，可以很好地描述路径集的一般性质，并具体展示了如何调整该模型以整合特定属性。


Result: 本文展示了如何使用功能性模型来描述路径集的特性，并强调该模型可以适应不同的属性。


Conclusion: 通过提出的功能性模型，本文成功地解决了路径集合特性描述的问题，该模型可以根据不同的属性灵活调整，为未来该领域的研究奠定了基础。

Abstract: In graph theory and its practical networking applications, e.g.,
telecommunications and transportation, the problem of finding paths has
particular importance. Selecting paths requires giving scores to the
alternative solutions to drive a choice. While previous studies have provided
comprehensive evaluation of single-path solutions, the same level of detail is
lacking when considering sets of paths. This paper emphasizes that the path
characterization strongly depends on the properties under consideration. While
property-based characterization is also valid for single paths, it becomes
crucial to analyse multiple path sets. From the above consideration, this paper
proposes a mathematical approach, defining a functional model that lends itself
well to characterizing the path set in its general formulation. The paper shows
how the functional model contextualizes specific attributes.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [52] [LG-NuSegHop: A Local-to-Global Self-Supervised Pipeline For Nuclei Instance Segmentation](https://arxiv.org/abs/2511.04892)
*Vasileios Magoulianitis,Catherine A. Alexander,Jiaxin Yang,C. -C. Jay Kuo*

Main category: eess.IV

TL;DR: 本文提出了一种名为LG-NuSegHop的自我监督流水线，用于解决核分割任务中的挑战。该方法通过局部操作生成伪标签，结合新的数据驱动特征提取模型NuSegHop和全局操作，提高了对不同数据集的泛化性能，并保持了透明和可解释性。


<details>
  <summary>Details</summary>
Motivation: 由于不同器官组织和采集过程中的核变异性和数据标注的昂贵性，现有的自动核分割技术面临挑战。本文旨在开发一种无需手动标注训练数据的自我监督方法，以提高在不同数据集上的泛化性能和医生可解释性。

Method: 提出的方法LG-NuSegHop包含三个模块：局部处理以生成伪标签，新的数据驱动特征提取模型NuSegHop，以及用于完善预测的全局操作。此方法在三个公开数据集上的实验均显示其性能优越。

Result: 实验结果表明，即使没有使用手动标注的训练数据，LG-NuSegHop在各个公开数据集上也保持了良好的泛化性能，并且能够超越其他自我监督和弱监督方法，并在完全监督方法中具有竞争力。

Conclusion: LG-NuSegHop作为一个透明且可解释的自我监督流水线，展示了在处理不同组织和数据集的核分割任务中的强大能力，为未来的生物医学图像分析提供了新的方向。

Abstract: Nuclei segmentation is the cornerstone task in histology image reading,
shedding light on the underlying molecular patterns and leading to disease or
cancer diagnosis. Yet, it is a laborious task that requires expertise from
trained physicians. The large nuclei variability across different organ tissues
and acquisition processes challenges the automation of this task. On the other
hand, data annotations are expensive to obtain, and thus, Deep Learning (DL)
models are challenged to generalize to unseen organs or different domains. This
work proposes Local-to-Global NuSegHop (LG-NuSegHop), a self-supervised
pipeline developed on prior knowledge of the problem and molecular biology.
There are three distinct modules: (1) a set of local processing operations to
generate a pseudolabel, (2) NuSegHop a novel data-driven feature extraction
model and (3) a set of global operations to post-process the predictions of
NuSegHop. Notably, even though the proposed pipeline uses { no manually
annotated training data} or domain adaptation, it maintains a good
generalization performance on other datasets. Experiments in three publicly
available datasets show that our method outperforms other self-supervised and
weakly supervised methods while having a competitive standing among fully
supervised methods. Remarkably, every module within LG-NuSegHop is transparent
and explainable to physicians.

</details>


### [53] [J-SGFT: Joint Spatial and Graph Fourier Domain Learning for Point Cloud Attribute Deblocking](https://arxiv.org/abs/2511.05047)
*Muhammad Talha,Qi Yang,Zhu Li,Anique Akhtar,Geert Van Der Auwera*

Main category: eess.IV

TL;DR: 提出了一种新的多尺度后处理框架，用于消除重建点云中的块状伪影，通过融合图傅里叶潜在属性表示和稀疏卷积以及通道注意力，实现了显著的视觉质量改进，特别是在Y通道和联合YUV通道上的BD率降低分别为18.81％和18.14％。


<details>
  <summary>Details</summary>
Motivation: 点云对于AR/VR和自动驾驶非常重要，但给压缩方案带来了挑战，现有的MPEG GPCC方法虽然在降低比特率方面取得了成功，但在重建的点云中引入了显著的块状伪影，因此需要改进以实现更高的视觉质量。

Method: 提出了一种新的多尺度后处理框架，利用图傅里叶潜在属性表示，结合稀疏卷积和通道注意力，来高效地消除重建点云中的块状伪影。该方法通过融合编码后的点云属性，来提高视觉质量而不增加显著的计算开销。

Result: 与GPCC TMC13v14基线相比，在8iVFBv2数据集上，该方法在Y通道和联合YUV通道上分别实现了18.81％和18.14％的BD率降低，表明该方法在减少伪影的同时保持了压缩效率。

Conclusion: 本文提出的新方法为重建点云中的块状伪影消除了有效的解决方案，展示了其在减少BD率和提高视觉质量方面的卓越表现。

Abstract: Point clouds (PC) are essential for AR/VR and autonomous driving but
challenge compression schemes with their size, irregular sampling, and
sparsity. MPEG's Geometry-based Point Cloud Compression (GPCC) methods
successfully reduce bitrate; however, they introduce significant blocky
artifacts in the reconstructed point cloud. We introduce a novel multi-scale
postprocessing framework that fuses graph-Fourier latent attribute
representations with sparse convolutions and channel-wise attention to
efficiently deblock reconstructed point clouds. Against the GPCC TMC13v14
baseline, our approach achieves BD-rate reduction of 18.81\% in the Y channel
and 18.14\% in the joint YUV on the 8iVFBv2 dataset, delivering markedly
improved visual fidelity with minimal overhead.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [54] [Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity](https://arxiv.org/abs/2511.04686)
*Pratik Poudel*

Main category: cs.LG

TL;DR: 本文探讨了大型语言模型（LLM）在多轮互动场景中KV缓存管理策略的重要性，发现在模型训练上下文窗口接近或超出缓存累积量时，生成质量会急剧下降。实验表明，简单地保留连续上下文块比复杂或破坏位置结构的策略能产生更多连贯的输出。这强调了在考虑缓存健康时，保留位置结构的重要性，而不仅仅关注缓存大小。


<details>
  <summary>Details</summary>
Motivation: 尽管KV缓存对大型语言模型的自动回归推断效率至关重要，但它在多轮状态场景中无限制的增长带来了巨大挑战。本文探讨了KV缓存管理策略、模型架构限制以及位置编码完整性的相互作用。通过实证分析和一个有一定状态的基准测试框架，我们展示了当累积的KV缓存达到或超过模型的训练上下文窗口大小时，LLM的生成质量会显著下降，这一模式与其他GPU内存耗尽的故障模式不同。

Method: 通过使用一个有状态评估框架，文章研究了各种KeyValuePair缓存管理策略和其对生成质量的影响。特别是关注了普通的驱逐策略（如基于注意机制Top策略）如果破坏了位置一致性，即使保持了高保留率，也会导致性能下降。另外，提出了简单策略，即保留连续的上下文区块（如保留初始“摘要”）可以比复杂或破坏位置的策略产生更连贯的生成。

Result: 结果表明，随着积累的KV缓存接近或超过模型的训练上下文窗口大小，LLM生成的质量明显下降。常见的驱逐策略，即使是在保持高缓存量的情况下，如果破坏了位置一致性，也会导致性能下降。相比之下，简单策略如保留连续的上下文区块，能产生更连贯的生成效果。这突显了在处理“缓存健康”的时候，需要关注位置结构，而不仅仅是缓存大小。

Conclusion: 主要结论是，有效的KV缓存管理应该根据模型的架构限制，保持位置的一致性，并且超越单纯缓存大小，从整体视角评估'缓存健康'。基于上下文保持完整性的驱逐策略是实现认证高质量生成的关键。

Abstract: The Key-Value (KV) cache is integral to efficient autoregressive inference in
large language models (LLMs), yet its unbounded growth in stateful multi-turn
scenarios presents major challenges. This paper examines the interplay between
KV cache management strategies, the architectural context limits of models like
meta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of
positional encodings. Through empirical analysis using a stateful benchmarking
framework, we show that LLM generation quality degrades sharply when the
accumulated KV cache approaches or exceeds the model's trained context window
(e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory
exhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via
AttentionTop), can worsen performance if they disrupt positional coherence.
Because LLMs rely on consistent positional signals (e.g., RoPE), compacting a
cache by removing non-contiguous tokens can scramble these signals and lead to
degenerative outputs. We further show that simple strategies preserving
contiguous context blocks (e.g., keeping an initial "gist") can yield more
coherent generations than complex or positionally disruptive ones. We advocate
for eviction techniques that respect architectural limits, preserve positional
structure, and view "cache health" holistically beyond mere size.

</details>


### [55] [Ada-FCN: Adaptive Frequency-Coupled Network for fMRI-Based Brain Disorder Classification](https://arxiv.org/abs/2511.04718)
*Yue Xun,Jiaxing Xu,Wenbo Gao,Chen Yang,Shujun Wang*

Main category: cs.LG

TL;DR: 提出了一种新的框架，使用自适应级联分解和频率耦合连接学习，以提高对特定频率带的神经疾病检测的敏感性和特异性。该框架还引入了统一的GCN，以提高诊断预测的准确性。实验结果表明，与现有方法相比，该方法在ADNI和ABIDE数据集上的性能更优越。


<details>
  <summary>Details</summary>
Motivation: 现有的模型在分析BOLD信号时，忽略了神经振荡的多频率特性，而忽略了神经疾病通常在特定频率带中表现异常的重要事实，限制了诊断的敏感性和特异性。为了解决这个问题，提出了一种新的框架，旨在提高神经疾病检测的敏感性和特异性。

Method: 新框架包括自适应级联分解，学习任务相关的频率子带；频率耦合连接学习，捕捉在同一频率带内和跨频率带之间的细微相互作用；以及统一的GCN，生成用于诊断预测的细化节点表示。

Result: 实验结果表明，该方法在ADNI和ABIDE数据集上的性能优于现有方法。

Conclusion: 新框架能够捕获特定频率带的微妙变化，有助于提高神经疾病的诊断准确性，是一种有潜力的方法。

Abstract: Resting-state fMRI has become a valuable tool for classifying brain disorders
and constructing brain functional connectivity networks
  by tracking BOLD signals across brain regions. However, existing mod els
largely neglect the multi-frequency nature of neuronal oscillations,
  treating BOLD signals as monolithic time series. This overlooks the cru cial
fact that neurological disorders often manifest as disruptions within
  specific frequency bands, limiting diagnostic sensitivity and specificity.
  While some methods have attempted to incorporate frequency informa tion, they
often rely on predefined frequency bands, which may not be
  optimal for capturing individual variability or disease-specific alterations.
  To address this, we propose a novel framework featuring Adaptive Cas cade
Decomposition to learn task-relevant frequency sub-bands for each
  brain region and Frequency-Coupled Connectivity Learning to capture
  both intra- and nuanced cross-band interactions in a unified functional
  network. This unified network informs a novel message-passing mecha nism
within our Unified-GCN, generating refined node representations
  for diagnostic prediction. Experimental results on the ADNI and ABIDE
  datasets demonstrate superior performance over existing methods. The
  code is available at https://github.com/XXYY20221234/Ada-FCN.

</details>


### [56] [Temporal convolutional and fusional transformer model with Bi-LSTM encoder-decoder for multi-time-window remaining useful life prediction](https://arxiv.org/abs/2511.04723)
*Mohamadreza Akbari Pour,Mohamad Sadeq Karimi,Amir Hossein Mazloumi*

Main category: cs.LG

TL;DR: 提出了一种结合Temporal Convolutional Networks (TCNs) 和改进的Temporal Fusion Transformer (TFT) 的新框架，用于改善剩余使用寿命 (RUL) 预测，提高了预测的准确性


<details>
  <summary>Details</summary>
Motivation: 现有的RUL预测模型难以捕捉细微的时间依赖关系，并且无法在动态的时间段中优先处理关键特征

Method: 提出一种结合TCNs和改进的TFT的新型框架，通过Bi-LSTM编码器-解码器加强该架构，以有效连接短期和长期依赖性，同时强调显着的时间模式，采用多时间窗口方法以增强不同操作条件下的适应性

Result: 实验表明，该模型与最先进方法相比，平均RMSE降低了5.5%，提高了预测精度

Conclusion: 该框架填补了现有方法的空白，提高了工业预测系统的有效性，并突显了高级时间序列变换器在RUL预测中的潜力

Abstract: Health prediction is crucial for ensuring reliability, minimizing downtime,
and optimizing maintenance in industrial systems. Remaining Useful Life (RUL)
prediction is a key component of this process; however, many existing models
struggle to capture fine-grained temporal dependencies while dynamically
prioritizing critical features across time for robust prognostics. To address
these challenges, we propose a novel framework that integrates Temporal
Convolutional Networks (TCNs) for localized temporal feature extraction with a
modified Temporal Fusion Transformer (TFT) enhanced by Bi-LSTM encoder-decoder.
This architecture effectively bridges short- and long-term dependencies while
emphasizing salient temporal patterns. Furthermore, the incorporation of a
multi-time-window methodology improves adaptability across diverse operating
conditions. Extensive evaluations on benchmark datasets demonstrate that the
proposed model reduces the average RMSE by up to 5.5%, underscoring its
improved predictive accuracy compared to state-of-the-art methods. By closing
critical gaps in current approaches, this framework advances the effectiveness
of industrial prognostic systems and highlights the potential of advanced
time-series transformers for RUL prediction.

</details>


### [57] [Regularized GLISp for sensor-guided human-in-the-loop optimization](https://arxiv.org/abs/2511.04751)
*Matteo Cercola,Michele Lomuscio,Dario Piga,Simone Formentin*

Main category: cs.LG

TL;DR: 本文提出了一种基于传感器信息的GLISp方法的扩展，通过注入灰盒结构，结合主观反馈与定量传感器信息，提高了偏好学习中的搜索效率和最终解决方案的质量。


<details>
  <summary>Details</summary>
Motivation: 现有偏好学习方法如Preferential Bayesian Optimization或GLISp方法在人类参与校准中有效，但这些方法忽略了传感器测量提供的信息，不利于实际应用的优化。因此，本文提出结合主观反馈与定量传感器信息的新方法，以提高校准效率和最终解的质量。

Method: 提出了一种结合物理信息假设函数和最小二乘正则化项的改进GLISp方法，该方法将感官测量的描述符融入偏好学习迭代中，形成灰盒结构，同时保持偏好学习搜索的灵活性。

Result: 新方法在人工校准汽车悬架优化问题中的数值评估表明，该方法相比基准GLISp方法具有更快的收敛速度和更好的最终解。

Conclusion: 该研究证明了将感官测量信息与偏好学习相结合的有效性，不仅能提高校准效率，也改善了最终解的质量。

Abstract: Human-in-the-loop calibration is often addressed via preference-based
optimization, where algorithms learn from pairwise comparisons rather than
explicit cost evaluations. While effective, methods such as Preferential
Bayesian Optimization or Global optimization based on active preference
learning with radial basis functions (GLISp) treat the system as a black box
and ignore informative sensor measurements. In this work, we introduce a
sensor-guided regularized extension of GLISp that integrates measurable
descriptors into the preference-learning loop through a physics-informed
hypothesis function and a least-squares regularization term. This injects
grey-box structure, combining subjective feedback with quantitative sensor
information while preserving the flexibility of preference-based search.
Numerical evaluations on an analytical benchmark and on a human-in-the-loop
vehicle suspension tuning task show faster convergence and superior final
solutions compared to baseline GLISp.

</details>


### [58] [When Data Falls Short: Grokking Below the Critical Threshold](https://arxiv.org/abs/2511.04760)
*Vaibhav Singh,Eugene Belilovsky,Rahaf Aljundi*

Main category: cs.LG

TL;DR: 本文研究了在数据稀缺情况下，知识蒸馏(KD)如何促进模型的grokking现象，并加速模型在新分布下的泛化能力，尤其是在数据量低于关键阈值时仍然可以实现泛化。此外，本文还探讨了在持续预训练设置中，KD如何加速泛化并减轻灾难性遗忘。这表明KD在小数据集和分布变化场景中具有重要作用。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺和分布变化的情况下，研究模型在新数据分布上的泛化能力，尤其是在有限数据条件下，探索知识蒸馏（KD）在促进模型泛化上的作用。

Method: 首先通过在不同数据分布之间使用知识蒸馏从一个已过拟合的模型加速另一个模型的grokking的过程来研究KD的作用。然后研究在联合分布上训练的效果。最后研究在连续预训练设置中，通过KD加速泛化和减少灾难性遗忘的情况。

Result: 本文展示了在数据稀缺条件下使用知识蒸馏（KD）可以加速模型的grokking过程，并提高了模型泛化能力，即使数据量低于关键阈值。具体来说，在存在分布迁移（distribution shift）的数据稀缺场景中，通过知识蒸馏可以加速模型向新分布泛化，即使原始训练数据不足以使模型独立泛化。此外，还证明了在连续预训练场景中，KD可在数据量仅为10%的情况下，仍然实现了优秀性能，同时减少了灾难性遗忘。

Conclusion: 本文的研究结果表明，知识蒸馏（KD）在帮助模型克服数据稀缺和分布变化的情况下的泛化有着重要作用，尤其是在基于小数据集和不断变化的数据分布上，这强调了KD在这些场景中的核心作用。

Abstract: In this paper, we investigate the phenomenon of grokking, where models
exhibit delayed generalization following overfitting on training data. We focus
on data-scarce regimes where the number of training samples falls below the
critical threshold, making grokking unobservable, and on practical scenarios
involving distribution shift. We first show that Knowledge Distillation (KD)
from a model that has already grokked on a distribution (p1) can induce and
accelerate grokking on a different distribution (p2), even when the available
data lies below the critical threshold. This highlights the value of KD for
deployed models that must adapt to new distributions under limited data. We
then study training on the joint distribution (p1, p2) and demonstrate that
while standard supervised training fails when either distribution has
insufficient data, distilling from models grokked on the individual
distributions enables generalization. Finally, we examine a continual
pretraining setup, where a grokked model transitions from p1 to p2, and find
that KD both accelerates generalization and mitigates catastrophic forgetting,
achieving strong performance even with only 10% of the data. Together, our
results provide new insights into the mechanics of grokking under knowledge
transfer and underscore the central role of KD in enabling generalization in
low-data and evolving distribution settings.

</details>


### [59] [FuseFlow: A Fusion-Centric Compilation Framework for Sparse Deep Learning on Streaming Dataflow](https://arxiv.org/abs/2511.04768)
*Rubens Lacouture,Nathan Zhang,Ritvik Sharma,Marco Siracusa,Fredrik Kjolstad,Kunle Olukotun,Olivia Hsu*

Main category: cs.LG

TL;DR: 本文提出了FuseFlow，一个将稀疏机器学习模型从PyTorch转换为融合稀疏数据流图的编译器，以适应可重新配置的数据流架构。FuseFlow能够进行跨表达式的稀疏操作融合，并且支持计算并行化、数据流排序和稀疏性阻塞等优化，通过设计空间探索证明全融合并非总是最优选择，并给出了亚优化配置的识别和剪枝的启发式方法。实验显示FuseFlow对GPT-3的性能提升超过2.7倍。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型的规模不断增大，稀疏计算和专用数据流硬件已成为提高效率的强大解决方案，而当前的稀疏计算编译器不能很好地支持跨表达式的稀疏操作融合，因此本文提出了FuseFlow。

Method: FuseFlow将稀疏的机器学习模型从PyTorch转换为融合稀疏数据流图，支持跨表达式的稀疏操作融合和并行化等优化，并使用微架构仿真器进行模拟。

Result: FuseFlow通过实验展示了设计空间探索的结果，证明了对于稀疏模型来说，并不是全融合（整个跨表达式融合整个模型）总是最优的，而全融合的性能提升是明显的，如对GPT-3模型的提升超过2.7倍。

Conclusion: FuseFlow是一个高度灵活的稀疏计算编译器，它自动地识别并执行最适合的融合策略，提升了模型训练的性能。

Abstract: As deep learning models scale, sparse computation and specialized dataflow
hardware have emerged as powerful solutions to address efficiency. We propose
FuseFlow, a compiler that converts sparse machine learning models written in
PyTorch to fused sparse dataflow graphs for reconfigurable dataflow
architectures (RDAs). FuseFlow is the first compiler to support general
cross-expression fusion of sparse operations. In addition to fusion across
kernels (expressions), FuseFlow also supports optimizations like
parallelization, dataflow ordering, and sparsity blocking. It targets a
cycle-accurate dataflow simulator for microarchitectural analysis of fusion
strategies. We use FuseFlow for design-space exploration across four real-world
machine learning applications with sparsity, showing that full fusion (entire
cross-expression fusion across all computation in an end-to-end model) is not
always optimal for sparse models-fusion granularity depends on the model
itself. FuseFlow also provides a heuristic to identify and prune suboptimal
configurations. Using Fuseflow, we achieve performance improvements, including
a ~2.7x speedup over an unfused baseline for GPT-3 with BigBird block-sparse
attention.

</details>


### [60] [Causal Structure and Representation Learning with Biomedical Applications](https://arxiv.org/abs/2511.04790)
*Caroline Uhler,Jiaqi Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种结合表示学习和因果推断的方法，利用多模态数据进行因果结构和表示学习，以解决因果发现的问题。


<details>
  <summary>Details</summary>
Motivation: 表示学习在预测任务中表现出色，但并不总是适用于因果任务（如预测干预效果）。随着多模态数据的增多，迫切需要一种方法来高效使用这些信息进行因果发现和表示学习。

Method: 利用多模态数据（包括观测数据和扰动数据），提出了一个新的统计和计算框架，以解决因果变量的发现和表示问题。此外，还包含设计最优干预以增强因果发现的能力的方法。

Result: 该框架能够有效结合多模态数据并实现因果结构和表示的综合学习，尤其是在生物医学领域具有重大意义。

Conclusion: 通过多模态数据构建因果结构并促进表示学习是解决复杂因果问题的有效途径。

Abstract: Massive data collection holds the promise of a better understanding of
complex phenomena and, ultimately, better decisions. Representation learning
has become a key driver of deep learning applications, as it allows learning
latent spaces that capture important properties of the data without requiring
any supervised annotations. Although representation learning has been hugely
successful in predictive tasks, it can fail miserably in causal tasks including
predicting the effect of a perturbation/intervention. This calls for a marriage
between representation learning and causal inference. An exciting opportunity
in this regard stems from the growing availability of multi-modal data
(observational and perturbational, imaging-based and sequencing-based, at the
single-cell level, tissue-level, and organism-level). We outline a statistical
and computational framework for causal structure and representation learning
motivated by fundamental biomedical questions: how to effectively use
observational and perturbational data to perform causal discovery on observed
causal variables; how to use multi-modal views of the system to learn causal
variables; and how to design optimal perturbations.

</details>


### [61] [Learning Dynamics from Input-Output Data with Hamiltonian Gaussian Processes](https://arxiv.org/abs/2511.05330)
*Jan-Hendrik Ewering,Robin E. Herrmann,Niklas Wahlström,Thomas B. Schön,Thomas Seel*

Main category: cs.LG

TL;DR: 本文提出了一种使用非保守哈密顿GP的方法，从输入输出数据中学习动力学，解决了在缺少速度或动量数据的实际问题场景下的建模难题。同时提供了一个全贝叶斯方案来估计未知隐藏状态、GP超参数以及结构超参数的概率密度。该方法利用减少秩的GP近似以提高计算效率，并已在非线性仿真案例研究中进行评估，与依赖动量测量的最先进技术进行比较。 


<details>
  <summary>Details</summary>
Motivation: 将非限制性先验知识（例如能量守恒定律）嵌入到基于学习的方法中，这对于从有限数据中构建物理一致的模型是关键动机，这种模型在基于模型的控制中是相关的。然而，现有基于哈密顿动力学的GP回归方法依赖于速度或动量数据，而在实践中这些数据通常不可用。因此，研究动力学学习的新方法是必要的，该方法可以处理仅利用输入输出数据的情况。 

Method: 本文提出了一种非保守哈密顿GP方法，用于从输入输出数据中学习动力学，并提供了一个全贝叶斯方案来估计概率密度。同时，借助减少秩的GP近似来提高计算效率。 

Result: 所提出的方法在非线性仿真案例研究中进行了评估，并且该方法的性能优于依赖动量测量的最先进技术。 

Conclusion: 本文展示了从输入输出数据中学习动力学的新途径，且有效利用非保守哈密顿GP模型，并通过测试证明了该方法的有效性。

Abstract: Embedding non-restrictive prior knowledge, such as energy conservation laws,
in learning-based approaches is a key motive to construct physically consistent
models from limited data, relevant for, e.g., model-based control. Recent work
incorporates Hamiltonian dynamics into Gaussian Process (GP) regression to
obtain uncertainty-quantifying models that adhere to the underlying physical
principles. However, these works rely on velocity or momentum data, which is
rarely available in practice. In this paper, we consider dynamics learning with
non-conservative Hamiltonian GPs, and address the more realistic problem
setting of learning from input-output data. We provide a fully Bayesian scheme
for estimating probability densities of unknown hidden states, of GP
hyperparameters, as well as of structural hyperparameters, such as damping
coefficients. Considering the computational complexity of GPs, we take
advantage of a reduced-rank GP approximation and leverage its properties for
computationally efficient prediction and training. The proposed method is
evaluated in a nonlinear simulation case study and compared to a
state-of-the-art approach that relies on momentum measurements.

</details>


### [62] [PuzzleMoE: Efficient Compression of Large Mixture-of-Experts Models via Sparse Expert Merging and Bit-packed inference](https://arxiv.org/abs/2511.04805)
*Yushu Zhao,Zheng Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: 本文介绍了一种名为PuzzleMoE的压缩方法，该方法通过稀疏专家合并和一种新的比特打包编码方案来压缩混合专家模型。该方法不仅可以压缩模型，还能保持模型的准确性，并且提高推理效率。实验结果表明，PuzzleMoE可以在50%压缩率下保持模型准确率，并在某些任务上表现出更好的压缩效果与1.28倍的推理速度提升。


<details>
  <summary>Details</summary>
Motivation: 过去的研究尝试通过剔除或合并专家来解决存储所有专家参数造成的大内存开销。然而效果不佳，特别是当压缩比过高时。为了解决这一问题，本文提出PuzzleMoE，旨在通过训练无损的方式来压缩混合专家模型，同时保持模型精度和推理效率。

Method: PuzzleMoE通过稀疏专家合并技术来识别权重冗余和专业化，使用双掩码同时捕捉共享和专家特定参数。此外，为了减少二进制掩码和符号存储的开销，PuzzleMoE引入了一种新的通过复用未充分利用的指数位来实现的有效压缩方案。

Result: 实验结果表明，PuzzleMoE能够在保持高精度的同时将混合专家模型最多压缩50%。对比现有最佳方法，PuzzleMoE在50%压缩比下可在MMLU数据集上最多提升16.7%的准确率，并且实现最多1.28倍的推理加速。

Conclusion: 本文提出了一种新的混合专家模型压缩方法PuzzleMoE，它通过识别权重冗余和专业化的稀疏专家合并技术以及高效的比特打包编码方案来实现高效的模型压缩和加速，最终在保持高精度的情况下实现了显著的压缩率和推理效率提升。

Abstract: Mixture-of-Experts (MoE) models have shown strong potential in scaling
language models efficiently by activating only a small subset of experts per
input. However, their widespread deployment remains limited due to the high
memory overhead associated with storing all expert parameters, particularly as
the number of experts increases. To address this challenge, prior works have
explored expert dropping and merging strategies, yet they often suffer from
performance drop at high compression ratios. In this paper, we introduce
PuzzleMoE, a training-free MoE compression method that achieves both high
accuracy and efficient inference through two key innovations: First, PuzzleMoE
performs sparse expert merging by identifying element-wise weight redundancy
and specialization. It uses a dual-mask to capture both shared and
expert-specific parameters. Second, to avoid the overhead of storing binary
masks and signs, PuzzleMoE introduces a bit-packed encoding scheme that reuses
underutilized exponent bits, enabling efficient MoE inference on GPUs.
Extensive experiments demonstrate that PuzzleMoE can compress MoE models by up
to 50% while maintaining accuracy across various tasks. Specifically, it
outperforms prior MoE compression methods by up to 16.7% on MMLU at 50%
compression ratio, and achieves up to 1.28\times inference speedup.

</details>


### [63] [SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning](https://arxiv.org/abs/2511.05355)
*Tzu-Yuan Huang,Armin Lederer,Dai-Jie Wu,Xiaobing Dai,Sihua Zhang,Stefan Sosnowski,Shao-Hua Sun,Sandra Hirche*

Main category: cs.LG

TL;DR: 提出了一种新的框架SAD-Flower，用于生成安全，合法和动态一致的轨迹，解决了现有的流匹配（FM）计划程序在确保状态和动作约束以及动态一致性方面存在不足的问题。SAD-Flower在不重新训练的情况下工作，并且在约束满足方面优于许多生成模型基线。


<details>
  <summary>Details</summary>
Motivation: 现有的FM规划器缺乏形式上的保证，无法确保状态和动作约束。这些约束对于计划轨迹的安全性至关重要。但是，现有的FM规划器不能保证动态一致性，这可能导致不可执行的轨迹。因此，提出了SAD-Flower，以解决这些问题并提供正式的保证。 

Method: SAD-Flower通过增加虚拟控制输入来增强流，利用非线性控制理论的技术来获得原则性的指导，从而提供了状态约束，动作约束和动态一致性的正式保证。该方法通过不重新训练在测试时间满足未见过的约束。 

Result: 通过多种任务的广泛实验，显示SAD-Flower在确保约束满足方面优于多种生成模型基线。 

Conclusion: SAD-Flower解决了现有的流匹配（FM）规划器在确保状态和动作约束方面存在的问题，同时保证动态一致性和不重新训练的情况下满足未见过的约束。

Abstract: Flow matching (FM) has shown promising results in data-driven planning.
However, it inherently lacks formal guarantees for ensuring state and action
constraints, whose satisfaction is a fundamental and crucial requirement for
the safety and admissibility of planned trajectories on various systems.
Moreover, existing FM planners do not ensure the dynamical consistency, which
potentially renders trajectories inexecutable. We address these shortcomings by
proposing SAD-Flower, a novel framework for generating Safe, Admissible, and
Dynamically consistent trajectories. Our approach relies on an augmentation of
the flow with a virtual control input. Thereby, principled guidance can be
derived using techniques from nonlinear control theory, providing formal
guarantees for state constraints, action constraints, and dynamic consistency.
Crucially, SAD-Flower operates without retraining, enabling test-time
satisfaction of unseen constraints. Through extensive experiments across
several tasks, we demonstrate that SAD-Flower outperforms various
generative-model-based baselines in ensuring constraint satisfaction.

</details>


### [64] [Autoencoding Dynamics: Topological Limitations and Capabilities](https://arxiv.org/abs/2511.04807)
*Matthew D. Kvalheim,Eduardo D. Sontag*

Main category: cs.LG

TL;DR: 论文探讨了自编码器的拓扑限制和能力，以及它对具有不变流形M的动力系统的编码能力。自编码器由一个编码器$E$和一个解码器$D$组成，它们位于数据流形$M$和潜在空间$	ext{R}^	ext{	ext{	ext{	ext{l}}}}$之间，其目标是使得从$M$上的点出发经过编码和解码后的数据点能够尽可能接近原始点。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究自编码器在搜索过程中的固有拓扑限制和能力，以及它如何应用于具有$M$作为不变流形的动力系统中。这些研究能够帮助我们更好地理解自编码器的内在行为和局限性。

Method: 通过理论推导和分析，系统地探讨了自编码器的拓扑限制和能力，以及它在编码动力系统的角色。对于具有$M$作为不变流形的动力系统，讨论了其在自编码器环境下的行为特性。

Result: 发现了自编码器存在的某些固有拓扑限制和能力，这些新发现对于理解自编码器如何在不同的应用场景中表现至关重要。特别地，关注了自编码器能够有效地处理具有不变流形的数据流形的能力。

Conclusion: 总的来说，该研究展示了自编码器在处理具有不变流形的动力系统方面的有限和能力。这些发现提出了对于其它相关领域的潜在应用，表明自编码器在理解和编码复杂数据结构方面具有强大的潜力。

Abstract: Given a "data manifold" $M\subset \mathbb{R}^n$ and "latent space"
$\mathbb{R}^\ell$, an autoencoder is a pair of continuous maps consisting of an
"encoder" $E\colon \mathbb{R}^n\to \mathbb{R}^\ell$ and "decoder" $D\colon
\mathbb{R}^\ell\to \mathbb{R}^n$ such that the "round trip" map $D\circ E$ is
as close as possible to the identity map $\mbox{id}_M$ on $M$. We present
various topological limitations and capabilites inherent to the search for an
autoencoder, and describe capabilities for autoencoding dynamical systems
having $M$ as an invariant manifold.

</details>


### [65] [Adversarially Robust Multitask Adaptive Control](https://arxiv.org/abs/2511.05444)
*Kasra Fallah,Leonardo F. Toso,James Anderson*

Main category: cs.LG

TL;DR: 我们研究了多任务自适应线性二次控制下的对抗鲁棒性，即在模型不确定性和对抗性干扰下，多个系统协同学习控制策略。提出了一个集群多任务方法，整合了聚类、系统识别和鲁棒聚合，以减轻损坏的模型更新的影响。分析表明集群准确性、簇内异质性和对抗行为如何影响每个LQR任务的确定性等价控制的预期遗憾。我们建立了非渐近界，表明遗憾与每个簇内的诚实系统数量呈逆变关系，并且即使在每个簇内有一部分对抗系统的情况下，这种减轻效果仍然保持不变。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决在模型不确定性和对抗干扰的情况下，多任务自适应线性二次控制系统在学习控制策略时遇到的问题。通过集群多任务方法，提出一种新的策略来应对这些挑战，特别是如何减轻受损模型更新的影响，提高控制策略的准确性与鲁棒性。

Method: 通过将系统划分为具有相似性的集群，并结合系统识别与鲁棒聚合的方法，提出了一种能够有效减少对抗行为影响的多任务自适应线性二次控制方案。该方法通过对集群的准确性和簇内异质性的分析来建立对遗憾的预期控制，从而改善了模型更新过程中的鲁棒性。

Result: 研究表明，通过提出的方法，预期遗憾随簇内诚实系统的数量增加而减少，即使存在对抗行为，在一定程度上依然能保持这个优势。此外，通过理论分析，建立了一系列非渐近界，表明在特定条件下的优越性。

Conclusion: 研究提供了对抗鲁棒性强的多任务自适应线性二次控制策略，特别是在存在模型不确定性和对抗干扰的情况下，该策略有助于提高系统的准确性和鲁棒性，通过精确的分析和绩效评估，展示了这一方法的有效性。

Abstract: We study adversarially robust multitask adaptive linear quadratic control; a
setting where multiple systems collaboratively learn control policies under
model uncertainty and adversarial corruption. We propose a clustered multitask
approach that integrates clustering and system identification with resilient
aggregation to mitigate corrupted model updates. Our analysis characterizes how
clustering accuracy, intra-cluster heterogeneity, and adversarial behavior
affect the expected regret of certainty-equivalent (CE) control across LQR
tasks. We establish non-asymptotic bounds demonstrating that the regret
decreases inversely with the number of honest systems per cluster and that this
reduction is preserved under a bounded fraction of adversarial systems within
each cluster.

</details>


### [66] [Sharp Minima Can Generalize: A Loss Landscape Perspective On Data](https://arxiv.org/abs/2511.04808)
*Raymond Fan,Bryce Sandlund,Lin Myat Ko*

Main category: cs.LG

TL;DR: 本文挑战了深度学习有效性的‘平坦谷假设’，指出大量的训练数据在其中扮演了重要角色。通过不同规模训练数据下极小值体积的测量，发现同样的模型在数据量增加时，那些原本体积小但具有泛化能力的极小值变得相对较大，从而改变了损失景观，使得平坦谷假设不再能全面解释深度学习的有效性。


<details>
  <summary>Details</summary>
Motivation: 动机在于探讨是否大量训练数据真正影响了深度学习模型泛化能力的‘平坦谷假设’的有效性，发现虽然平坦谷假设有一定道理，但大量数据在其中扮演了关键角色，使得原本体积小但具有泛化能力的极小值变得显著，从而挑战了原始假设。 

Method: 通过改变训练数据的大小来测量损失景观中的极小值体积，比较不同数据量下极小值的特性和体积变化，从而确定大量数据在模型泛化能力中的作用。 

Result: 研究结果表明，即使极小值的平坦度对于模型的泛化能力有重要的影响，但是大量训练数据的存在改变了解决方案的空间结构，使得某些原本体积小但具有良好泛化的极小值变得相对较大。这表明深度学习的有效性不仅仅是‘平坦谷假设’中的平坦度控制，而是与大量的训练数据对模型泛化性的影响密切相关。

Conclusion: 结论是虽然平坦谷假设依然解释了一些深层学习模型的泛化性能，但是大量训练数据在模型优化中扮演了更重要的角色，它影响了损失景观的结构和极小值的分布，从而影响了模型的容错能力和泛化能力。

Abstract: The volume hypothesis suggests deep learning is effective because it is
likely to find flat minima due to their large volumes, and flat minima
generalize well. This picture does not explain the role of large datasets in
generalization. Measuring minima volumes under varying amounts of training data
reveals sharp minima which generalize well exist, but are unlikely to be found
due to their small volumes. Increasing data changes the loss landscape, such
that previously small generalizing minima become (relatively) large.

</details>


### [67] [A Standardized Benchmark for Multilabel Antimicrobial Peptide Classification](https://arxiv.org/abs/2511.04814)
*Sebastian Ojeda,Rafael Velasquez,Nicolás Aparicio,Juanita Puentes,Paula Cárdenas,Nicolás Andrade,Gabriel González,Sergio Rincón,Carolina Muñoz-Camargo,Pablo Arbeláez*

Main category: cs.LG

TL;DR: 研究提出了一种评估抗菌肽的框架ESCAPE，结合了超过80,000个肽段，用于预测肽的功能活动，改进了现有方法的性能，提升了抗菌肽的研究进展。


<details>
  <summary>Details</summary>
Motivation: 目前抗菌肽数据集碎片化、注释不一致、缺乏标准化基准的问题阻碍了计算方法的发展，从而减缓了新候选肽的发现。本研究开发了一个全面且可重现的评估框架ESCAPE来解决这些问题，推进人工智能驱动的抗菌肽研究。 

Method: 利用ESCAPE数据库，研究提出了一种基于变换器的模型，整合了序列和结构信息来预测肽的多功能活动。

Result: 该方法在多标签肽分类任务中，平均准确度比现有最佳方法提升了2.56％，建立了新的技术水平。

Conclusion: ESCAPE框架为综合和可重复评估抗菌肽提供了途径，极大地促进了人工智能驱动的抗菌肽研究。

Abstract: Antimicrobial peptides have emerged as promising molecules to combat
antimicrobial resistance. However, fragmented datasets, inconsistent
annotations, and the lack of standardized benchmarks hinder computational
approaches and slow down the discovery of new candidates. To address these
challenges, we present the Expanded Standardized Collection for Antimicrobial
Peptide Evaluation (ESCAPE), an experimental framework integrating over 80.000
peptides from 27 validated repositories. Our dataset separates antimicrobial
peptides from negative sequences and incorporates their functional annotations
into a biologically coherent multilabel hierarchy, capturing activities across
antibacterial, antifungal, antiviral, and antiparasitic classes. Building on
ESCAPE, we propose a transformer-based model that leverages sequence and
structural information to predict multiple functional activities of peptides.
Our method achieves up to a 2.56% relative average improvement in mean Average
Precision over the second-best method adapted for this task, establishing a new
state-of-the-art multilabel peptide classification. ESCAPE provides a
comprehensive and reproducible evaluation framework to advance AI-driven
antimicrobial peptide research.

</details>


### [68] [Prompt-Based Safety Guidance Is Ineffective for Unlearned Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.04834)
*Jiwoo Shin,Byeonghu Na,Mina Kang,Wonhyeok Choi,Il-chul Moon*

Main category: cs.LG

TL;DR: 这项工作提出了一个简单而有效的改进方法，通过用隐式负向嵌入替换训练自由法中的负向提示，增强了对有害内容生成的防御，且无需修改现存的方法或管道。实验表明其在保持输入提示核心语义的同时，显著提升了防御成功率。


<details>
  <summary>Details</summary>
Motivation: 解决现有防御方法组合使用时，因范式不兼容导致防御效果不佳的问题，旨在提高文本到图像模型生成有害内容的防御性能。

Method: 通过概念反转获得隐式负向嵌入，取代训练自由法中的显式负向提示，提升了防御效率。该方法可以无缝集成到现有的图像生成系统中。

Result: 实验表明，该方法在防止生成包含色情和暴力内容方面更加有效，相比单一使用隐式或显式负向提示时有更好的实际效果，同时保持了输入语义的核心部分。

Conclusion: 提出了一个能有效改善文本到图像模型防御曲线的简单方法，通过这种方式为提高模型在防御恶意输入上的能力提供了新的思路。

Abstract: Recent advances in text-to-image generative models have raised concerns about
their potential to produce harmful content when provided with malicious input
text prompts. To address this issue, two main approaches have emerged: (1)
fine-tuning the model to unlearn harmful concepts and (2) training-free
guidance methods that leverage negative prompts. However, we observe that
combining these two orthogonal approaches often leads to marginal or even
degraded defense performance. This observation indicates a critical
incompatibility between two paradigms, which hinders their combined
effectiveness. In this work, we address this issue by proposing a conceptually
simple yet experimentally robust method: replacing the negative prompts used in
training-free methods with implicit negative embeddings obtained through
concept inversion. Our method requires no modification to either approach and
can be easily integrated into existing pipelines. We experimentally validate
its effectiveness on nudity and violence benchmarks, demonstrating consistent
improvements in defense success rate while preserving the core semantics of
input prompts.

</details>


### [69] [Sublinear iterations can suffice even for DDPMs](https://arxiv.org/abs/2511.04844)
*Matthew S. Zhang,Stephen Huan,Jerry Huang,Nicholas M. Boffi,Sitan Chen,Sinho Chewi*

Main category: cs.LG

TL;DR: 基于SDE的方法如去噪扩散概率模型（DDPM）在现实世界的样本生成任务中表现出色。该研究通过'偏移合成规则'分析了一种名为DDRaM的新积分器，证明了在适当光滑性假设下，该方法具有优势，首次实现了纯DDPM采样的亚线性复杂度。实验验证了新方法在实践中效果良好，尤其是在预训练的图像合成模型上。


<details>
  <summary>Details</summary>
Motivation: 通过对去噪扩散采样方法的先前研究主要集中在指数Euler离散化方法上的观察，本文受到对数凹采样研究的启发，推出了一种新的积分器——DDRaM，以更好的近似SDE，从而提升样本生成的效率和准确性。

Method: 采用最近开发的分析框架——'偏移合成规则'，分析去噪扩散随机中点法（DDRaM），并展示了其在适当平滑性假设下的优越离散化属性，保证亚线性复杂度的收敛。同时，进行了实验验证。

Result: 该方法在适当平滑性假设下需要的评分评估次数为	ilde{O}(t{d})。与先前的工作相比，无论是纯DDPM采样还是经过修改的采样器，该方法都是首个实现亚线性复杂度的，同时保持实用性能良好，实验验证其在实践中优于其他方法。

Conclusion: 通过'偏移合成规则'的应用，首次实现了去噪扩散方法的亚线性复杂度。实验结果表明，新方法DDRaM在预训练的图像合成模型中表现出色，优于其他方法。

Abstract: SDE-based methods such as denoising diffusion probabilistic models (DDPMs)
have shown remarkable success in real-world sample generation tasks. Prior
analyses of DDPMs have been focused on the exponential Euler discretization,
showing guarantees that generally depend at least linearly on the dimension or
initial Fisher information. Inspired by works in log-concave sampling (Shen and
Lee, 2019), we analyze an integrator -- the denoising diffusion randomized
midpoint method (DDRaM) -- that leverages an additional randomized midpoint to
better approximate the SDE. Using a recently-developed analytic framework
called the "shifted composition rule", we show that this algorithm enjoys
favorable discretization properties under appropriate smoothness assumptions,
with sublinear $\widetilde{O}(\sqrt{d})$ score evaluations needed to ensure
convergence. This is the first sublinear complexity bound for pure DDPM
sampling -- prior works which obtained such bounds worked instead with
ODE-based sampling and had to make modifications to the sampler which deviate
from how they are used in practice. We also provide experimental validation of
the advantages of our method, showing that it performs well in practice with
pre-trained image synthesis models.

</details>


### [70] [Investigating U.S. Consumer Demand for Food Products with Innovative Transportation Certificates Based on Stated Preferences and Machine Learning Approaches](https://arxiv.org/abs/2511.04845)
*Jingchen Bi,Rodrigo Mesa-Arango*

Main category: cs.LG

TL;DR: 本文利用机器学习模型估计了美国具有创新运输证书的食品产品的消费者行为。研究发现，消费者对安全和能量证书在运输领域有明显的偏好，并提出了改进食品供应链系统的数据驱动建议。


<details>
  <summary>Details</summary>
Motivation: 基于之前的供应链追溯性研究，识别出运输因素在消费者食品采购决策中的重要意义。提出了五个创新的运输证书，以进一步研究消费者对该领域的具体偏好。

Method: 应用了机器学习模型，并结合实验控制了产品特定和决策者因素的影响，来估计消费者偏好和购买决策。

Result: 研究发现，美国食品供应链中的运输领域，消费者对安全和能量证书有明显的偏好，并探索了价格，产品类型，证书和决策者因素对购买决策的影响。

Conclusion: 提出了数据驱动的建议，以改进美国食品供应链系统。

Abstract: This paper utilizes a machine learning model to estimate the consumer's
behavior for food products with innovative transportation certificates in the
U.S. Building on previous research that examined demand for food products with
supply chain traceability using stated preference analysis, transportation
factors were identified as significant in consumer food purchasing choices.
Consequently, a second experiment was conducted to pinpoint the specific
transportation attributes valued by consumers. A machine learning model was
applied, and five innovative certificates related to transportation were
proposed: Transportation Mode, Internet of Things (IoT), Safety measures,
Energy Source, and Must Arrive By Dates (MABDs). The preference experiment also
incorporated product-specific and decision-maker factors for control purposes.
The findings reveal a notable inclination toward safety and energy certificates
within the transportation domain of the U.S. food supply chain. Additionally,
the study examined the influence of price, product type, certificates, and
decision-maker factors on purchasing choices. Ultimately, the study offers
data-driven recommendations for improving food supply chain systems.

</details>


### [71] [You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models](https://arxiv.org/abs/2511.04902)
*Shuvendu Roy,Hossein Hajimirsadeghi,Mengyao Zhai,Golnoosh Samei*

Main category: cs.LG

TL;DR: 研究探讨了无监督强化学习方法在不同规模和推理能力的语言模型中的表现，发现其依赖于模型原有的推理能力。提出了一种利用课程学习和掩码无多数投票训练的方法来提高小型模型的性能，并发布了相关的代码和数据生成流程以促进研究发展。


<details>
  <summary>Details</summary>
Motivation: 旨在研究无监督的强化学习方法在规模较小且推理能力受限的语言模型上的应用效果与限制，并寻找可能的改进方案，使模型在资源受限的情况下仍能提高推理能力。

Method: 采取了无监督的强化学习与课程学习相结合的方法，引入更难的任务，并在训练过程中屏蔽无多数投票的结果，同时设计了一个数据生成流程以控制训练数据的难度。

Result: 这种改进的方法在所有模型大小和推理能力上均表现出改进，显示了在资源受限情况下增强模型自监督学习能力的潜力。

Conclusion: 提出的方法提供了一条改进无监督强化学习技术的路径，使小型模型在资源受限的情况下也能自提升推理能力，此路径具有广泛的适用性和重要研究价值。

Abstract: Recent advances in large language models have demonstrated the promise of
unsupervised reinforcement learning (RL) methods for enhancing reasoning
capabilities without external supervision. However, the generalizability of
these label-free RL approaches to smaller base models with limited reasoning
capabilities remains unexplored. In this work, we systematically investigate
the performance of label-free RL methods across different model sizes and
reasoning strengths, from 0.5B to 7B parameters. Our empirical analysis reveals
critical limitations: label-free RL is highly dependent on the base model's
pre-existing reasoning capability, with performance often degrading below
baseline levels for weaker models. We find that smaller models fail to generate
sufficiently long or diverse chain-of-thought reasoning to enable effective
self-reflection, and that training data difficulty plays a crucial role in
determining success. To address these challenges, we propose a simple yet
effective method for label-free RL that utilizes curriculum learning to
progressively introduce harder problems during training and mask no-majority
rollouts during training. Additionally, we introduce a data curation pipeline
to generate samples with predefined difficulty. Our approach demonstrates
consistent improvements across all model sizes and reasoning capabilities,
providing a path toward more robust unsupervised RL that can bootstrap
reasoning abilities in resource-constrained models. We make our code available
at https://github.com/BorealisAI/CuMa

</details>


### [72] [A Dual Perspective on Decision-Focused Learning: Scalable Training via Dual-Guided Surrogates](https://arxiv.org/abs/2511.04909)
*Paula Rodriguez-Diaz,Kirk Bansak Elisabeth Paulson*

Main category: cs.LG

TL;DR: 提出了Dual-Guided Loss(DGL), 一个简单、可扩展的目标函数，它在减少对解算器依赖的同时保持决策一致性。该方法适用于组合选择问题，并通过交替的解算器调用和使用简单的可微损失函数进行训练，从而降低训练成本。DGL在决策后悔方面有渐进性减少，且在实验中与现有最佳决策聚焦学习(DFL)方法相比，使用更少的解算器调用和更少的训练时间就达到了相似或更好的效果。


<details>
  <summary>Details</summary>
Motivation: 解决在不确定性条件下进行决策时的预测-优化难题，尤其是在面对组合问题时，如何减少对昂贵的解算器调用的需求，同时保持决策一致性（即预测值对于解优化问题有效）

Method: 设计了一种新型的损失函数Dual-Guided Loss (DGL)，以及与此损失函数相关的训练方案，包括交替进行解算器调用和平常训练过程，以直接和间接的方式利用稀疏的,dual信息来指导学习过程。此外，该方法还可以通过设置解算器调用的频率，来调整模型在性能与训练成本之间的权衡，使得训练成本趋于标准监督学习水平，同时保持决策一致性。DGL不仅适用于匹配、背包问题和最短路径等具有自然约束条件的问题，也能帮助实际应用中的决策任务得到更好的解。

Result: 通过实验，验证了DGL在保持决策一致性的同时，提供了比现行最佳DFL方法更少的解算器调用次数和更少的训练时间。在两个问题类别中，DGL的表现要么与最佳的DFL方法相当，要么优于它们。证明了DGL具有渐进的决策后悔减少特性，并分析了其运行时复杂度。此外，源代码已发布以供进一步研究使用。该方法显示了在决策聚焦学习中的巨大潜力。

Conclusion: 提出了DGL，这是一个适用于组合选择问题的新方法，它通过减少对解算器的依赖，为大规模问题提供了更有效的训练框架，为实际应用中的决策任务提供了改进的解决方案。

Abstract: Many real-world decisions are made under uncertainty by solving optimization
problems using predicted quantities. This predict-then-optimize paradigm has
motivated decision-focused learning, which trains models with awareness of how
the optimizer uses predictions, improving the performance of downstream
decisions. Despite its promise, scaling is challenging: state-of-the-art
methods either differentiate through a solver or rely on task-specific
surrogates, both of which require frequent and expensive calls to an optimizer,
often a combinatorial one. In this paper, we leverage dual variables from the
downstream problem to shape learning and introduce Dual-Guided Loss (DGL), a
simple, scalable objective that preserves decision alignment while reducing
solver dependence. We construct DGL specifically for combinatorial selection
problems with natural one-of-many constraints, such as matching, knapsack, and
shortest path. Our approach (a) decouples optimization from gradient updates by
solving the downstream problem only periodically; (b) between refreshes, trains
on dual-adjusted targets using simple differentiable surrogate losses; and (c)
as refreshes become less frequent, drives training cost toward standard
supervised learning while retaining strong decision alignment. We prove that
DGL has asymptotically diminishing decision regret, analyze runtime complexity,
and show on two problem classes that DGL matches or exceeds state-of-the-art
DFL methods while using far fewer solver calls and substantially less training
time. Code is available at https://github.com/paularodr/Dual-Guided-Learning.

</details>


### [73] [SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3) Diffusion](https://arxiv.org/abs/2511.04854)
*Alvaro Prat,Leo Zhang,Charlotte M. Deane,Yee Whye Teh,Garrett M. Morris*

Main category: cs.LG

TL;DR: SigmaDock 是一种新的分子对接生成方法，通过将配体分解为刚体片段并使用 SE(3) Riemannian 扩散模型生成结合位姿，解决了传统方法中存在的化学不合理性、泛化能力差和计算成本高的问题。实验结果表明，SigmaDock 在 PoseBusters 数据集上的 Top-1 成功率为 79.9%，显著优于其他深度学习方法，并且是首个在 PB 分离验证中超越经典物理方法的深度学习方法，标志着深度学习在分子建模中的可靠性和可行性的一大进步。


<details>
  <summary>Details</summary>
Motivation: 现有的分子对接生成方法受限于化学上不可靠的输出、泛化能力差和高昂的计算成本，作者提出了一种新的技术方案SigmaDock，以解决这些问题。

Method: SigmaDock 使用了一种新颖的分子分解策略，将配体分解为刚体片段，然后运用 SE(3) Riemannian 扩散模型生成结合位姿。这种方法建立在已知的结构化学先验知识之上，改进了扩散进程的复杂性和训练过程的稳定性。

Result: 实验结果显示，SigmaDock 达到了前所未有的性能水平，特别是在PoseBusters数据集上的Top-1成功率超过了79.9%，这与其它深度学习方法的12.7-30.8%形成了显著对比，同时进一步证实了SigmaDock具备良好的泛化能力，适用于未见过的蛋白质。

Conclusion: SigmaDock 成为了首个超过经典物理方法的深度学习分子对接工具，这一成果象征着深度学习在分子建模中的可靠性和可行性正迈向了一个新的高度。

Abstract: Determining the binding pose of a ligand to a protein, known as molecular
docking, is a fundamental task in drug discovery. Generative approaches promise
faster, improved, and more diverse pose sampling than physics-based methods,
but are often hindered by chemically implausible outputs, poor
generalisability, and high computational cost. To address these challenges, we
introduce a novel fragmentation scheme, leveraging inductive biases from
structural chemistry, to decompose ligands into rigid-body fragments. Building
on this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion
model that generates poses by learning to reassemble these rigid bodies within
the binding pocket. By operating at the level of fragments in SE(3), SigmaDock
exploits well-established geometric priors while avoiding overly complex
diffusion processes and unstable training dynamics. Experimentally, we show
SigmaDock achieves state-of-the-art performance, reaching Top-1 success rates
(RMSD<2 & PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8%
reported by recent deep learning approaches, whilst demonstrating consistent
generalisation to unseen proteins. SigmaDock is the first deep learning
approach to surpass classical physics-based docking under the PB train-test
split, marking a significant leap forward in the reliability and feasibility of
deep learning for molecular modelling.

</details>


### [74] [Quantum Boltzmann Machines for Sample-Efficient Reinforcement Learning](https://arxiv.org/abs/2511.04856)
*Thore Gerlach,Michael Schenk,Verena Kain*

Main category: cs.LG

TL;DR: 本文提出了理论上基础的连续半量子玻尔兹曼机（CSQBM），用于支持连续动作的强化学习。该模型结合指数家族的先验和量子玻尔兹曼分布，减少量子位需求的同时保持强大的表达能力。通过允许连续变量的解析梯度计算，可以直接将其集成到Actor-Critic算法中。进一步，提出了一个连续Q学习的框架，采用CSQBM抽样而非全局最大化的策略，从而解决了连续控制中的不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 在强化学习领域，连续动作设置通常具有挑战性，主要是由于计算复杂度和稳定性问题。本文的动机是设计一种能够有效处理连续空间动作的强化学习算法，并提高其稳定性。通过引入CSQBM模型，可以结合量子计算的优势来解决这些问题。

Method: CSQBM结合了指数族的无条件概率先验和量子玻尔兹曼分布，可以用于计算连续变量的梯度，并可以直接集成到Actor-Critic算法中。连续Q学习框架通过CSQBM的抽样方法来处理连续的动作空间，从而提高了算法的稳定性。

Result: 该研究成功设计了CSQBM，展示了如何计算连续变量的梯度，并通过Actor-Critic框架验证了其有效性。此外，提出的连续Q学习框架使用CSQBM进行采样，展示了稳定性和性能的显著提升。这些创新为连续动作设置中的强化学习提供了实用的方法。

Conclusion: 本文的研究表明，CSQBM模型能够有效地处理连续动作的强化学习问题，通过结合指数族先验和量子玻尔兹曼分布，降低了量子资源的需求并改进了计算效率。连续Q学习框架的提出，为解决持续控制中的稳定性和复杂性问题提供了新的途径。

Abstract: We introduce theoretically grounded Continuous Semi-Quantum Boltzmann
Machines (CSQBMs) that supports continuous-action reinforcement learning. By
combining exponential-family priors over visible units with quantum Boltzmann
distributions over hidden units, CSQBMs yield a hybrid quantum-classical model
that reduces qubit requirements while retaining strong expressiveness.
Crucially, gradients with respect to continuous variables can be computed
analytically, enabling direct integration into Actor-Critic algorithms.
Building on this, we propose a continuous Q-learning framework that replaces
global maximization by efficient sampling from the CSQBM distribution, thereby
overcoming instability issues in continuous control.

</details>


### [75] [FoodRL: A Reinforcement Learning Ensembling Framework For In-Kind Food Donation Forecasting](https://arxiv.org/abs/2511.04865)
*Esha Sharma,Lauren Davis,Julie Ivy,Min Chi*

Main category: cs.LG

TL;DR: 提出了一种基于强化学习的框架FoodRL，用于预测食品银行的捐赠波动，相比传统方法在受到自然灾害影响期间表现更优，每年能额外提供约170万份餐食的预测准确性


<details>
  <summary>Details</summary>
Motivation: 传统预测模型在预测食品银行不可预测的捐赠波动时准确性不足，特别是在自然灾害发生期间。提出FoodRL来改善这一情况，特别是在飓风和野火等不可预见事件的影响下，提高预测准确性，确保资源分配的公平和效率

Method: FoodRL是一个基于强化学习的元学习框架，通过聚类和动态加权不同的预测模型来应对不确定性，它会根据最近的表现和上下文信息来调整各模型的权重

Result: 在受到不同类型自然灾难影响的两个食品银行的真实数据集上，FoodRL相比于基准方法显示出更优的预测效果，特别是在预测波动期，能够提供更可靠和适应性的预测

Conclusion: FoodRL不仅展现了对社会的潜在重大影响，而且展示了强化学习在人道主义供应链中的适应性集成学习方面的潜力

Abstract: Food banks are crucial for alleviating food insecurity, but their
effectiveness hinges on accurately forecasting highly volatile in-kind
donations to ensure equitable and efficient resource distribution. Traditional
forecasting models often fail to maintain consistent accuracy due to
unpredictable fluctuations and concept drift driven by seasonal variations and
natural disasters such as hurricanes in the Southeastern U.S. and wildfires in
the West Coast. To address these challenges, we propose FoodRL, a novel
reinforcement learning (RL) based metalearning framework that clusters and
dynamically weights diverse forecasting models based on recent performance and
contextual information. Evaluated on multi-year data from two structurally
distinct U.S. food banks-one large regional West Coast food bank affected by
wildfires and another state-level East Coast food bank consistently impacted by
hurricanes, FoodRL consistently outperforms baseline methods, particularly
during periods of disruption or decline. By delivering more reliable and
adaptive forecasts, FoodRL can facilitate the redistribution of food equivalent
to 1.7 million additional meals annually, demonstrating its significant
potential for social impact as well as adaptive ensemble learning for
humanitarian supply chains.

</details>


### [76] [BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records](https://arxiv.org/abs/2511.04998)
*Daniel S. Lee,Mayra S. Haedo-Cruz,Chen Jiang,Oshin Miranda,LiRong Wang*

Main category: cs.LG

TL;DR: 提出了一种名为BiPETE的模型，用于使用电子健康记录进行单病种预测，该模型使用旋转位置嵌入和正弦位置嵌入来编码相对就诊时间和保持就诊顺序。在抑郁症和PTSD的数据集上，BiPETE比基线模型在AUPRC上分别提高了34％和50％。通过集成梯度方法解释模型预测，识别出与ASUD风险和保护相关的关键临床特征，并提供了对风险评估过程的深刻理解以及规避潜在风险的有价值线索。


<details>
  <summary>Details</summary>
Motivation: 使用电子健康记录(EHRs)的Transformer-based深度学习模型在疾病风险预测方面展示了前景，但由于不规则的就诊间隔和结构不统一，建模时间依赖性仍然是一个关键挑战。提出了BiPETE模型，以解决这个问题。

Method: BiPETE模型将旋转位置嵌入和正弦位置嵌入结合，以编码相对就医时间和保持就医顺序。在两个精神健康队列-抑郁症和创伤后应激障碍(PTSD)的数据上，训练BiPETE模型以预测酒精和物质使用障碍(ASUD)的风险。此外，通过集成梯度方法解释模型预测。

Result: 在抑郁症和PTSD的数据集上，BiPETE模型在AUPRC上分别提高了34％和50％，这比基线模型表现更好。

Conclusion: 我们的研究提出了一种实用且易于解释的框架，可以利用EHR数据进行疾病风险预测，并且可以实现强大的性能。

Abstract: Transformer-based deep learning models have shown promise for disease risk
prediction using electronic health records(EHRs), but modeling temporal
dependencies remains a key challenge due to irregular visit intervals and lack
of uniform structure. We propose a Bi-Positional Embedding Transformer Encoder
or BiPETE for single-disease prediction, which integrates rotary positional
embeddings to encode relative visit timing and sinusoidal embeddings to
preserve visit order. Without relying on large-scale pretraining, BiPETE is
trained on EHR data from two mental health cohorts-depressive disorder and
post-traumatic stress disorder (PTSD)-to predict the risk of alcohol and
substance use disorders (ASUD). BiPETE outperforms baseline models, improving
the area under the precision-recall curve (AUPRC) by 34% and 50% in the
depression and PTSD cohorts, respectively. An ablation study further confirms
the effectiveness of the dual positional encoding strategy. We apply the
Integrated Gradients method to interpret model predictions, identifying key
clinical features associated with ASUD risk and protection, such as abnormal
inflammatory, hematologic, and metabolic markers, as well as specific
medications and comorbidities. Overall, these key clinical features identified
by the attribution methods contribute to a deeper understanding of the risk
assessment process and offer valuable clues for mitigating potential risks. In
summary, our study presents a practical and interpretable framework for disease
risk prediction using EHR data, which can achieve strong performance.

</details>


### [77] [Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale](https://arxiv.org/abs/2511.04904)
*Bassel Al Omari,Michael Matthews,Alexander Rutherford,Jakob Nicolaus Foerster*

Main category: cs.LG

TL;DR: 提出了Craftax-MA和Craftax-Coop两个新的多智能体强化学习基准，以评估现有算法在长期依赖性和泛化能力方面的挑战。Craftax-MA是一个多智能体版本的Craftax环境，而Craftax-Coop则引入了异质智能体、交易等机制，要求智能体之间进行复杂合作。现有算法难以处理这些基准中的长期收益分配、探索和合作问题，可以推动长期的MARL研究。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习基准往往过于局限于短期挑战，不足以评估智能体的长期依赖性和泛化能力。为了弥补这一不足，研究者提出了新的基准来测试这些能力。

Method: 介绍了Craftax-MA和Craftax-Coop两个环境的设计。其中，Craftax-MA是多智能体版本的Craftax环境，而Craftax-Coop则加了额外的复杂机制，以测试智能体的合作能力。这两个环境都是用JAX实现的，运行效率非常高。

Result: 分析表明，现有的算法在这些新基准上不容易取得成功，尤其是在长期收益分配、探索和合作方面存在问题。研究成果表明了新基准的有效性，并显示了其在推动未来MARL研究中的潜力。

Conclusion: 新的基准可以作为评估现有算法在多智能体强化学习方面的有效工具，并能推动未来该领域的研究。

Abstract: Progress in multi-agent reinforcement learning (MARL) requires challenging
benchmarks that assess the limits of current methods. However, existing
benchmarks often target narrow short-horizon challenges that do not adequately
stress the long-term dependencies and generalization capabilities inherent in
many multi-agent systems. To address this, we first present
\textit{Craftax-MA}: an extension of the popular open-ended RL environment,
Craftax, that supports multiple agents and evaluates a wide range of general
abilities within a single environment. Written in JAX, \textit{Craftax-MA} is
exceptionally fast with a training run using 250 million environment
interactions completing in under an hour. To provide a more compelling
challenge for MARL, we also present \textit{Craftax-Coop}, an extension
introducing heterogeneous agents, trading and more mechanics that require
complex cooperation among agents for success. We provide analysis demonstrating
that existing algorithms struggle with key challenges in this benchmark,
including long-horizon credit assignment, exploration and cooperation, and
argue for its potential to drive long-term research in MARL.

</details>


### [78] [Multi-agent Coordination via Flow Matching](https://arxiv.org/abs/2511.05005)
*Dongsu Lee,Daehee Lee,Amy Zhang*

Main category: cs.LG

TL;DR: MAC-Flow是一个用于多智能体协调的框架，通过学习联合行为的流基表示，并将其提炼为去中心化的一步策略，实现了复杂协调能力和实时执行速度的平衡。其推理速度比之前的基于扩散的方法快14.5倍，同时保持了良好的性能，并且与基于高斯策略的方法具有相似的推理速度。


<details>
  <summary>Details</summary>
Motivation: 研究表明，有效的多智能体协调需要能够表达多样的联合行为和实现实时操作。然而，现有的方法常常无法同时满足这两个要求。因此，本文提出MAC-Flow来解决这一问题。

Method: MAC-Flow首先学习联合行为的流基表示，然后将其提炼为去中心化的一步策略，从而在保持复杂协调能力的同时实现了较快的执行速度。

Result: 在四个不同的基准测试上，使用了12个环境和34个数据集，MAC-Flow减少了性能和计算成本之间的折衷，比基于扩散的MARL方法快14.5倍，同时保持了较好的性能。

Conclusion: MAC-Flow通过平衡复杂协调能力和实时执行速度，解决了现有方法中存在的矛盾，证明了其在多智能体协调任务中的有效性。

Abstract: This work presents MAC-Flow, a simple yet expressive framework for
multi-agent coordination. We argue that requirements of effective coordination
are twofold: (i) a rich representation of the diverse joint behaviors present
in offline data and (ii) the ability to act efficiently in real time. However,
prior approaches often sacrifice one for the other, i.e., denoising
diffusion-based solutions capture complex coordination but are computationally
slow, while Gaussian policy-based solutions are fast but brittle in handling
multi-agent interaction. MAC-Flow addresses this trade-off by first learning a
flow-based representation of joint behaviors, and then distilling it into
decentralized one-step policies that preserve coordination while enabling fast
execution. Across four different benchmarks, including $12$ environments and
$34$ datasets, MAC-Flow alleviates the trade-off between performance and
computational cost, specifically achieving about $\boldsymbol{\times14.5}$
faster inference compared to diffusion-based MARL methods, while maintaining
good performance. At the same time, its inference speed is similar to that of
prior Gaussian policy-based offline multi-agent reinforcement learning (MARL)
methods.

</details>


### [79] [Efficient Swap Multicalibration of Elicitable Properties](https://arxiv.org/abs/2511.04907)
*Lunjia Hu,Haipeng Luo,Spandan Senapati,Vatsal Sharan*

Main category: cs.LG

TL;DR: 本文扩展了多校准的概念，将其从群体成员函数推广到任意有界假设类，并引入了更强的概念——交换多校准。提出了一种基于在线无偏学习器的高效算法，该算法能够达到$T^{1/(r+1)}$ $	extit{l}_r$-交换多校准误差，并证明了当$r=2$时，该算法能实现$T^{1/3}$ $	extit{l}_2$-交换多校准误差，这显著改进了之前的工作。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是将多校准的概念推广到更一般的假设类，并实现更高效的多校准算法，解决在线学习中的公平性问题。通过引入交换多校准的概念，提出了一种能够在一定条件下实现高效多校准的算法，改进了现有成果，特别是在$	extit{l}_2$-多校准误差方面的计算效率。

Method: 首先，本文将多校准的概念从群体成员函数推广到了任意有界假设类，并引入了更严格的交换多校准定义。然后，提出了一个基于在线无偏学习器的算法，能够在给定条件下实现$	extit{l}_r$-交换多校准误差，考虑了特殊情况下的具体实现方法，特别是当误差度量为$	extit{l}_2$时，该算法依然有效。

Result: 本文的主要结果是提出一种算法，能够在满足特定条件下，显著降低多校准的误差（具体是$	extit{l}_r$-交换多校准误差），尤其是在$	extit{l}_2$-交换多校准情况下，实现了$T^{1/3}$的误差度量，这是第一个在渐近意义上优于$	extit{l}_2$-多校准的在线算法。这改进了之前的工作，并完全解决了GJRR24年提出的问题。

Conclusion: 通过扩展多校准到一般假设类并引入交换多校准，本文提出了一种新的算法，展示出改进的误差性能。这对于解决在线学习中的公平性问题，特别是多校准应用，具有非常重要的意义，对未来的研究提供了新的技术路线。

Abstract: Multicalibration [HJKRR18] is an algorithmic fairness perspective that
demands that the predictions of a predictor are correct conditional on
themselves and membership in a collection of potentially overlapping subgroups
of a population. The work of [NR23] established a surprising connection between
multicalibration for an arbitrary property $\Gamma$ (e.g., mean or median) and
property elicitation: a property $\Gamma$ can be multicalibrated if and only if
it is elicitable, where elicitability is the notion that the true property
value of a distribution can be obtained by solving a regression problem over
the distribution. In the online setting, [NR23] proposed an inefficient
algorithm that achieves $\sqrt T$ $\ell_2$-multicalibration error for a
hypothesis class of group membership functions and an elicitable property
$\Gamma$, after $T$ rounds of interaction between a forecaster and adversary.
  In this paper, we generalize multicalibration for an elicitable property
$\Gamma$ from group membership functions to arbitrary bounded hypothesis
classes and introduce a stronger notion -- swap multicalibration, following
[GKR23]. Subsequently, we propose an oracle-efficient algorithm which, when
given access to an online agnostic learner, achieves $T^{1/(r+1)}$
$\ell_r$-swap multicalibration error with high probability (for $r\ge2$) for a
hypothesis class with bounded sequential Rademacher complexity and an
elicitable property $\Gamma$. For the special case of $r=2$, this implies an
oracle-efficient algorithm that achieves $T^{1/3}$ $\ell_2$-swap
multicalibration error, which significantly improves on the previously
established bounds for the problem [NR23, GMS25, LSS25a], and completely
resolves an open question raised in [GJRR24] on the possibility of an
oracle-efficient algorithm that achieves $\sqrt{T}$ $\ell_2$-mean
multicalibration error by answering it in a strongly affirmative sense.

</details>


### [80] [OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data](https://arxiv.org/abs/2511.05028)
*Dongjin Park,Hasung Yeo,Joon-Woo Lee*

Main category: cs.LG

TL;DR: 提出了OvA-LP框架，在联邦微调（FFT）中通过抑制异构客户端分布造成的偏移（drift），保持预训练特征的几何结构，使模型在数据不独立同分布（non-IID）的情况下仍能保持较高精度，同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦微调方法在面对非独立同分布的数据时容易出现局部偏移问题，导致全局模型的系统偏差和方差增加，而且大多数现有方法都是后发式修正局部偏移，效果较差。因此，本文提出一种新的方法来抑制偏移的源头，使联邦微调在非独立同分布的数据下更稳定。

Method: OvA-LP框架使用冻结的编码器进行线性探测并结合一对一的头部，通过两阶段过程来保持预训练的特征几何结构，并防止导致信息放大的机制。

Result: 在CIFAR-100数据集上，通过三种不同的数据划分方法，OvA-LP保持了95.9%的独立同分布（IID）准确性，而最先进的FFT基准方法只有10.1%和34.5%，同时在面对标签噪声情况下也展示了较高的鲁棒性。此外，预计算编码器特征使得每一轮的成本几乎与编码器大小无关。

Conclusion: 结果表明，OvA-LP框架在异构性和non-IID数据下提供了稳健的联邦微调解决方案，是一种合理而有效的基础。

Abstract: Federated fine-tuning (FFT) adapts foundation models to decentralized data
but remains fragile under heterogeneous client distributions due to local
drift, i.e., client-level update divergences that induce systematic bias and
amplified variance in the global model. Existing aggregation and
personalization methods largely correct drift post hoc, which proves brittle
under extreme non-IID conditions. We introduce OvA-LP, a minimalist framework
that is, to our knowledge, the first explicitly designed to suppress drift at
its source within the PEFT-based FFT paradigm. OvA-LP combines linear probing
on a frozen encoder with a one-vs-all head and a simple two-stage procedure,
preserving pretrained feature geometry and decoupling logits to prevent the
mechanisms that amplify drift. On CIFAR-100 with 100 clients, averaged over
shard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of
its IID accuracy, whereas state-of-the-art FFT baselines retain only 10.1%
(PFPT) and 34.5% (FFT-MoE) under the same conditions. OvA-LP further maintains
resilience under both symmetric and asymmetric label noise. In addition,
precomputing encoder features makes per-round cost nearly independent of
encoder size. Together, these results demonstrate that OvA-LP provides a
principled and efficient basis for robust FFT under heterogeneity.

</details>


### [81] [Machine Learning Algorithms in Statistical Modelling Bridging Theory and Application](https://arxiv.org/abs/2511.04918)
*A. Ganapathi Rao,Sathish Krishna Anumula,Aditya Kumar Singh,Renukhadevi M,Y. Jeevan Nagendra Kumar,Tammineni Rama Tulasi*

Main category: cs.LG

TL;DR: 该研究探讨了机器学习算法与传统统计模型之间的关系，展示了一种新型的整合方式，它提升了传统模型的性能、扩展性、灵活性和鲁棒性，构建的混合模型在预测准确度、鲁棒性和可解释性方面有显著提高。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探索机器学习算法如何改进传统的统计模型，希望通过新型的整合方式，提高模型的整体性能和应用效果。

Method: 文中没有具体提到所使用的方法，但可以推测使用了较为先进的机器学习算法与传统统计模型相结合的方法。

Result: 研究表明，通过引入新的机器学习算法，传统模型的性能、扩展性、灵活性和鲁棒性得到显著提高，同时混合模型增强了预测准确度、鲁棒性和可解释性。

Conclusion: 研究得出结论，将现代机器学习算法与传统统计模型相融合，能够显著提升模型的性能，是一种值得推广的新型数据分析方法。

Abstract: It involves the completely novel ways of integrating ML algorithms with
traditional statistical modelling that has changed the way we analyze data, do
predictive analytics or make decisions in the fields of the data. In this
paper, we study some ML and statistical model connections to understand ways in
which some modern ML algorithms help 'enrich' conventional models; we
demonstrate how new algorithms improve performance, scale, flexibility and
robustness of the traditional models. It shows that the hybrid models are of
great improvement in predictive accuracy, robustness, and interpretability

</details>


### [82] [Leak@$k$: Unlearning Does Not Make LLMs Forget Under Probabilistic Decoding](https://arxiv.org/abs/2511.04934)
*Hadi Reisizadeh,Jiajun Ruan,Yiwei Chen,Soumyadeep Pal,Sijia Liu,Mingyi Hong*

Main category: cs.LG

TL;DR: 本文展示了大多数现有的大语言模型的解学方法在实践中并不能实现真正的删除知识目标。引入了一种新的评估指标\texttt{leak@$k$}，用于量化知识泄露的可能性，并通过大规模实验证明了知识泄露持续存在，表明当前的技术并未达到真正删除知识的效果，亟需更加稳健的解学方法。


<details>
  <summary>Details</summary>
Motivation: 为了满足监管合规性要求，并构建能够避免产生私人、有毒、非法或受版权保护内容的道德生成性AI系统，大语言模型解学成为了关键问题。但是现有的大多数解学方法在实践中并没有实现真正的知识遗忘，因此研究者需要对解学方法的有效性进行全面评估，以解决这个问题。引入\texttt{leak@$k$}指标逐项分析多种解学方法的有效性。

Method: 提出了一个新的评估指标\texttt{leak@$k$}，用于量化在真实的解码策略下生成$k$个样本时，先前已删除的知识重新出现的可能性。通过大规模实验证明了知识泄露存在于不同解学方法和任务中。该实验采用三种广泛接受的基准TOFU, MUSE,和WMDP进行评估。

Result: 研究结果表明，尽管在确定性解码评估中的知识删除看起来是成功的，但实际上，当采用标准概率解码时，敏感信息会重新出现。使用新的\texttt{leak@$k$}指标，已完整证明了现有的大多数解学方法没有实现真正的知识遗忘。知识泄露现象在不同的解学方法和任务中普遍存在，表明当下的最优解学技术效果未达实际需求。

Conclusion: 由此可以看出，目前状态下，现有的解学方法的效果需要提高，才能更好地处理知识遗忘的问题。本文呼吁进一步开发更加可靠、有效的技术来处理大规模语言模型的解学问题。

Abstract: Unlearning in large language models (LLMs) is critical for regulatory
compliance and for building ethical generative AI systems that avoid producing
private, toxic, illegal, or copyrighted content. Despite rapid progress, in
this work we show that \textit{almost all} existing unlearning methods fail to
achieve true forgetting in practice. Specifically, while evaluations of these
`unlearned' models under deterministic (greedy) decoding often suggest
successful knowledge removal using standard benchmarks (as has been done in the
literature), we show that sensitive information reliably resurfaces when models
are sampled with standard probabilistic decoding. To rigorously capture this
vulnerability, we introduce \texttt{leak@$k$}, a new meta-evaluation metric
that quantifies the likelihood of forgotten knowledge reappearing when
generating $k$ samples from the model under realistic decoding strategies.
Using three widely adopted benchmarks, TOFU, MUSE, and WMDP, we conduct the
first large-scale, systematic study of unlearning reliability using our newly
defined \texttt{leak@$k$} metric. Our findings demonstrate that knowledge
leakage persists across methods and tasks, underscoring that current
state-of-the-art unlearning techniques provide only limited forgetting and
highlighting the urgent need for more robust approaches to LLM unlearning.

</details>


### [83] [Structural Properties, Cycloid Trajectories and Non-Asymptotic Guarantees of EM Algorithm for Mixed Linear Regression](https://arxiv.org/abs/2511.04937)
*Zhankun Luo,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: 该工作探讨了EM算法在未知混合权重和回归参数的两组分混合线性回归(2MLR)中的结构性质、旋轮线轨迹和非渐近收敛保证。在无噪声和高信噪比情况下，最近的研究已经建立了2MLR的全局收敛性，但在完全未知的情况下，EM的轨迹和收敛阶数仍然不清楚。我们推导了2MLR在所有SNR中的EM更新表达式，并证明了噪声条件下回归参数的轨迹呈旋轮线，高信噪比下则有不同的偏离。分析表明当EM估计与真实参数几乎正交时收敛速度是线性的，两者之间角度很小的时候收敛速度为二次。这一工作提供了一个新的基于轨迹的EM分析框架。


<details>
  <summary>Details</summary>
Motivation: 深入理解EM算法在未知条件下两组分混合线性回归（2MLR）中的表现，特别是在噪声和不同信噪比（SNR）下的收敛特性和轨迹。

Method: 推导了2MLR中的EM更新公式，分析了轨迹的结构特性，并通过统计误差界限的精确化来提供非渐近的收敛保证。

Result: 研究揭示了EM算法在2MLR中的新性质，包括噪声的情况下回归参数轨迹呈旋轮线，高SNR时偏离旋轮线的程度，并证明了初始化条件下的任意全局收敛性。

Conclusion: 该研究提供了一个新的基于轨迹的EM算法分析框架，特别是在未知混合权重和回归参数条件下的2MLR中的新见解。

Abstract: This work investigates the structural properties, cycloid trajectories, and
non-asymptotic convergence guarantees of the Expectation-Maximization (EM)
algorithm for two-component Mixed Linear Regression (2MLR) with unknown mixing
weights and regression parameters. Recent studies have established global
convergence for 2MLR with known balanced weights and super-linear convergence
in noiseless and high signal-to-noise ratio (SNR) regimes. However, the
theoretical behavior of EM in the fully unknown setting remains unclear, with
its trajectory and convergence order not yet fully characterized. We derive
explicit EM update expressions for 2MLR with unknown mixing weights and
regression parameters across all SNR regimes and analyze their structural
properties and cycloid trajectories. In the noiseless case, we prove that the
trajectory of the regression parameters in EM iterations traces a cycloid by
establishing a recurrence relation for the sub-optimality angle, while in high
SNR regimes we quantify its discrepancy from the cycloid trajectory. The
trajectory-based analysis reveals the order of convergence: linear when the EM
estimate is nearly orthogonal to the ground truth, and quadratic when the angle
between the estimate and ground truth is small at the population level. Our
analysis establishes non-asymptotic guarantees by sharpening bounds on
statistical errors between finite-sample and population EM updates, relating
EM's statistical accuracy to the sub-optimality angle, and proving convergence
with arbitrary initialization at the finite-sample level. This work provides a
novel trajectory-based framework for analyzing EM in Mixed Linear Regression.

</details>


### [84] [Risk Prediction of Cardiovascular Disease for Diabetic Patients with Machine Learning and Deep Learning Techniques](https://arxiv.org/abs/2511.04971)
*Esha Chowdhury*

Main category: cs.LG

TL;DR: 该研究提出了一种使用机器学习和混合深度学习方法的心血管疾病风险预测模型，针对糖尿病患者。通过对BRFSS数据集进行预处理，使用了XGBoost和LSTM等模型进行研究，实现了高达0.9050的准确率和完美召回率，展示了机器学习和深度学习模型在心血管疾病风险预测中的有效性，有助于提高个性化风险管理和预防策略。


<details>
  <summary>Details</summary>
Motivation: 研究旨在应对糖尿病患者心血管疾病风险预测的挑战，通过提出高效的预测模型来提高医疗机构的风险管理水平，促进更个性化的治疗和预防策略。

Method: 研究采用了机器学习和深度学习方法，包括XGBoost、LSTM等算法，并应用了主成分分析进行特征提取。同时，对BRFSS数据集进行了预处理，去除了重复项，处理了缺失值，识别了类别和数值特征。

Result: 实验结果显示，XGBoost和LSTM等模型实现了高达0.9050的准确率和完美召回率。这表明所提出的模型在心血管疾病风险预测中具有很高效率和精准度。

Conclusion: 研究结论显示，机器学习和深度学习模型在预测糖尿病患者心血管疾病风险方面非常有效，可以自动化并改善临床决策过程，提高风险管理和预防措施的效果与个性化水平。

Abstract: Accurate prediction of cardiovascular disease (CVD) risk is crucial for
healthcare institutions. This study addresses the growing prevalence of
diabetes and its strong link to heart disease by proposing an efficient CVD
risk prediction model for diabetic patients using machine learning (ML) and
hybrid deep learning (DL) approaches. The BRFSS dataset was preprocessed by
removing duplicates, handling missing values, identifying categorical and
numerical features, and applying Principal Component Analysis (PCA) for feature
extraction. Several ML models, including Decision Trees (DT), Random Forest
(RF), k-Nearest Neighbors (KNN), Support Vector Machine (SVM), AdaBoost, and
XGBoost, were implemented, with XGBoost achieving the highest accuracy of
0.9050. Various DL models, such as Artificial Neural Networks (ANN), Deep
Neural Networks (DNN), Recurrent Neural Networks (RNN), Convolutional Neural
Networks (CNN), Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), and
Gated Recurrent Unit (GRU), as well as hybrid models combining CNN with LSTM,
BiLSTM, and GRU, were also explored. Some of these models achieved perfect
recall (1.00), with the LSTM model achieving the highest accuracy of 0.9050.
Our research highlights the effectiveness of ML and DL models in predicting CVD
risk among diabetic patients, automating and enhancing clinical
decision-making. High accuracy and F1 scores demonstrate these models'
potential to improve personalized risk management and preventive strategies.

</details>


### [85] [Less Is More: Generating Time Series with LLaMA-Style Autoregression in Simple Factorized Latent Spaces](https://arxiv.org/abs/2511.04973)
*Siyuan Li,Yifan Sun,Lei Cheng,Lewen Wang,Yang Liu,Weiqing Liu,Jianlong Li,Jiang Bian,Shikai Fang*

Main category: cs.LG

TL;DR: 提出了FAR-TS框架，该框架结合了分解因子化和自回归Transformer，用于生成具有任意长度的时间序列数据，解决了现有扩散方法速度慢且局限于固定长度窗口的问题，并保持了跨通道相关性和可解释的潜在空间，从而实现了高质量和灵活的时间序列合成


<details>
  <summary>Details</summary>
Motivation: 当前最先进的基于扩散的时间序列生成方法速度慢并且局限于固定长度的窗口，而真实世界的时间序列数据往往需要生成任意长度的数据。因此，需要一个快速且不受长度限制的时间序列生成方法来解决这些问题

Method: FAR-TS框架采用了数据自适应的基础上将时间序列分解成静态跨通道相关性捕捉分解因子化和对时间系数进行向量量化以生成离散标记。随后使用LLaMA样式的自回归Transformer来建模这些标记序列，从而实现了时间序列的快速生成

Result: FAR-TS框架在生成速度上比Diffusion-TS快了多个数量级，同时保持了跨通道相关性和可解释的潜在空间，可以生成高质量和灵活的时间序列数据

Conclusion: FAR-TS通过结合分解因子化和自回归Transformer，实现了效率高且不受长度限制的时间序列生成，解决了现有扩散方法的局限性，提供了高质量和灵活的时间序列合成解决方案

Abstract: Generative models for multivariate time series are essential for data
augmentation, simulation, and privacy preservation, yet current
state-of-the-art diffusion-based approaches are slow and limited to
fixed-length windows. We propose FAR-TS, a simple yet effective framework that
combines disentangled factorization with an autoregressive Transformer over a
discrete, quantized latent space to generate time series. Each time series is
decomposed into a data-adaptive basis that captures static cross-channel
correlations and temporal coefficients that are vector-quantized into discrete
tokens. A LLaMA-style autoregressive Transformer then models these token
sequences, enabling fast and controllable generation of sequences with
arbitrary length. Owing to its streamlined design, FAR-TS achieves
orders-of-magnitude faster generation than Diffusion-TS while preserving
cross-channel correlations and an interpretable latent space, enabling
high-quality and flexible time series synthesis.

</details>


### [86] [Model Merging Improves Zero-Shot Generalization in Bioacoustic Foundation Models](https://arxiv.org/abs/2511.05171)
*Davide Marincione,Donato Crisostomi,Roberto Dessi,Emanuele Rodolà,Emanuele Rossi*

Main category: cs.LG

TL;DR: 本论文研究了NatureLM在生物声学任务中的表现，发现其在跨指令操作上灵活性不足，通过简单模型合并策略提高其指令跟随能力，最终实现零样本泛化性能的显著提升，达到了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 本论文研究了NatureLM在生物声学任务中的表现，并尝试解决其在跨指令操作上的灵活性问题，以提高其在跨物种和任务上的泛化能力。

Method: 论文通过模型合并策略，将NatureLM与基础语言模型进行插值，以恢复其指令跟随能力，同时保持领域专业知识。

Result: 合并后的模型在零样本泛化能力上显示出显著的提高，特别是在封闭集零样本分类未见过的物种上的相对提高超过了200%，设定了新的最先进水平。

Conclusion: 该合并策略成功提高了NatureLM的指令跟随灵活性及其零样本泛化性能，为生物声学任务中的模型应用打开了新的前景。

Abstract: Foundation models capable of generalizing across species and tasks represent
a promising new frontier in bioacoustics, with NatureLM being one of the most
prominent examples. While its domain-specific fine-tuning yields strong
performance on bioacoustic benchmarks, we observe that it also introduces
trade-offs in instruction-following flexibility. For instance, NatureLM
achieves high accuracy when prompted for either the common or scientific name
individually, but its accuracy drops significantly when both are requested in a
single prompt. We address this by applying a simple model merging strategy that
interpolates NatureLM with its base language model, recovering
instruction-following capabilities with minimal loss of domain expertise.
Finally, we show that the merged model exhibits markedly stronger zero-shot
generalization, achieving over a 200% relative improvement and setting a new
state-of-the-art in closed-set zero-shot classification of unseen species.

</details>


### [87] [Scaling Up ROC-Optimizing Support Vector Machines](https://arxiv.org/abs/2511.04979)
*Gimun Bae,Seung Jun Shin*

Main category: cs.LG

TL;DR: 提出了一种可扩展的ROC-SVM变体，通过利用不完整的U统计量来大幅降低计算复杂度，并通过低秩核近似扩展到非线性分类，实现在复现核希尔伯特空间中的高效训练。理论分析建立了错误界限，证明了提出的近似方法，并通过合成和真实数据集的实验结果表明该方法与原始的ROC-SVM相比，实现了相当的AUC性能，但训练时间大大减少。


<details>
  <summary>Details</summary>
Motivation: 原有的ROC-SVM虽然在处理类别不平衡问题上表现出色，但由于其高计算成本，在实际应用中的适用性受到限制。因此，提出了一种改进的方法，以克服这一限制。

Method: 通过利用不完整的U统计量来简化计算，并采用低秩核近似应用于非线性分类，从而实现了计算成本的大幅降低。

Result: 理论分析证明了提出的近似方法的正确性，实验结果表明该方法的AUC表现与原始的ROC-SVM相当，但训练时间显著减少。

Conclusion: 该研究提供了一种有效减少ROC-SVM训练时间的方法，使得其在处理大规模数据集时更具可扩展性。

Abstract: The ROC-SVM, originally proposed by Rakotomamonjy, directly maximizes the
area under the ROC curve (AUC) and has become an attractive alternative of the
conventional binary classification under the presence of class imbalance.
However, its practical use is limited by high computational cost, as training
involves evaluating all $O(n^2)$. To overcome this limitation, we develop a
scalable variant of the ROC-SVM that leverages incomplete U-statistics, thereby
substantially reducing computational complexity. We further extend the
framework to nonlinear classification through a low-rank kernel approximation,
enabling efficient training in reproducing kernel Hilbert spaces. Theoretical
analysis establishes an error bound that justifies the proposed approximation,
and empirical results on both synthetic and real datasets demonstrate that the
proposed method achieves comparable AUC performance to the original ROC-SVM
with drastically reduced training time.

</details>


### [88] [Unlocking the Black Box: A Five-Dimensional Framework for Evaluating Explainable AI in Credit Risk](https://arxiv.org/abs/2511.04980)
*Rongbin Ye,Jiaqi Chen*

Main category: cs.LG

TL;DR: 该论文旨在解决金融行业中高度预测性但缺乏解释性的机器学习模型和银行监管之间的矛盾，通过对比并应用LIME和SHAP等框架，提出了一个五维度评估模型可解释性的方法，使复杂模型能够在保持高预测精度的同时满足监管要求，并提出了一种评价模型性能与可解释性的权衡方法论。


<details>
  <summary>Details</summary>
Motivation: 在金融行业中，利用机器学习模型进行风险建模和预测面临着挑战，即如何在提高预测准确性的同时满足监管机构对解释性的要求。论文研究目的是填补用“黑盒子”模型这种高级机器学习模型和可解释性框架之间的应用差距，推动高度预测性的模型能够在受到监管的金融环境中应用。

Method: 该研究应用了LIME和SHAP等可解释性框架，并提出了一种五维度的评估模型方法，用来评价模型的内置解释性、全局解释性、本地解释性、一致性等。此外，还对LIME和SHAP的性能进行了对比和讨论。

Result: 结果表明，复杂模型在保持较高精度的同时也能满足监管机构的解释性需求，并提出了一种平衡模型性能与可解释性的评价方法论，证明了在监管性的金融环境中使用复杂的、高性能的机器学习模型是可行的。

Conclusion: 论文通过现代化的可解释性技术的应用，使复杂模型能够在保持高预测精度的同时满足监管要求，并提出了一种评价模型性能与可解释性的权衡方法论，实现了模型解释性和预测精度之间的平衡。

Abstract: The financial industry faces a significant challenge modeling and risk
portfolios: balancing the predictability of advanced machine learning models,
neural network models, and explainability required by regulatory entities (such
as Office of the Comptroller of the Currency, Consumer Financial Protection
Bureau). This paper intends to fill the gap in the application between these
"black box" models and explainability frameworks, such as LIME and SHAP.
Authors elaborate on the application of these frameworks on different models
and demonstrates the more complex models with better prediction powers could be
applied and reach the same level of the explainability, using SHAP and LIME.
Beyond the comparison and discussion of performances, this paper proposes a
novel five dimensional framework evaluating Inherent Interpretability, Global
Explanations, Local Explanations, Consistency, and Complexity to offer a
nuanced method for assessing and comparing model explainability beyond simple
accuracy metrics. This research demonstrates the feasibility of employing
sophisticated, high performing ML models in regulated financial environments by
utilizing modern explainability techniques and provides a structured approach
to evaluate the crucial trade offs between model performance and
interpretability.

</details>


### [89] [Deep Progressive Training: scaling up depth capacity of zero/one-layer models](https://arxiv.org/abs/2511.04981)
*Zhiqi Bu*

Main category: cs.LG

TL;DR: 本文通过优化理论和特征学习研究了大型模型的深度扩展，提出了zero/one-layer渐进式训练方法，以实现计算与损失之间的最优权衡。例如，与完全训练的60层模型相比，zero/one-layer渐进式训练的GPT2可以节省约80%的计算量，或提高约5倍的速度，同时保持几乎相同的损失值。


<details>
  <summary>Details</summary>
Motivation: 深度学习中模型的深度是一把双刃剑。深度模型虽然可以达到更高的准确率，但需要更高的计算成本。有效策略是在训练过程中通过逐步增加模型能力来进行渐进式训练，从而大幅降低计算成本而几乎没有性能损失。因此，本文旨在研究大模型中的深度扩展问题，提出新的渐进式训练策略，以实现计算与损失之间的最优权衡。 

Method: 通过优化理论和特征学习的角度研究了大型模型的深度扩展。提出了zero/one-layer渐进式训练方法，讨论了新层的初始化、超参数传递、学习率计划以及模型扩展时间点的选择。 

Result: zero/one-layer渐进式训练可以使GPT2模型在计算量减少约80%，或加速约5倍的情况下，同时保持几乎相同的损失值，比完全训练的60层模型更具优势。这项研究为大型模型的训练提供了一种新的评估方式和方法论。 

Conclusion: 通过优化理论和特征学习研究大模型中的深度扩展问题，本文提出了zero/one-layer渐进式训练方法，证明了这种方法在减少计算量的同时保持了几乎相同的损失值，为大模型的训练提供了新的方式。

Abstract: Model depth is a double-edged sword in deep learning: deeper models achieve
higher accuracy but require higher computational cost. To efficiently train
models at scale, an effective strategy is the progressive training, which
scales up model capacity during training, hence significantly reducing
computation with little to none performance degradation. In this work, we study
the depth expansion of large models through the lens of optimization theory and
feature learning, offering insights on the initialization of new layers,
hyperparameter transfer, learning rate schedule, and timing of model expansion.
Specifically, we propose zero/one-layer progressive training for the optimal
tradeoff between computation and loss. For example, zero/one-layer progressive
training on GPT2 can save $\approx 80\%$ compute, or equivalently accelerate
$\approx 5\times$ while achieving almost the same loss, compared to to a fully
trained 60-layer model with 7B parameters.

</details>


### [90] [Carbon Price Forecasting with Structural Breaks: A Comparative Study of Deep Learning Models](https://arxiv.org/abs/2511.04988)
*Runsheng Ren,Jing Li,Yanxiu Li,Shixun Huang,Jun Shen,Wanqing Li,John Le,Sheng Wang*

Main category: cs.LG

TL;DR: 本文提出了一种综合混合框架，结合了结构断裂检测、小波去噪和三种先进的深度学习模型，用于碳价格的预测，并且实验结果表明该方法的准确性较现有模型有显著提高。


<details>
  <summary>Details</summary>
Motivation: 目前准确预测碳价格面临困难，主要是因为结构性断裂和高频噪音的影响。现有模型通常将去噪和建模过程分开处理，并缺乏对先进深度学习架构的系统性评估。为了解决这些问题，提出了一个综合混合框架。

Method: 该框架结合了Bai-Perron，ICSS，PELT算法的结构断裂检测，小波信号去噪，以及LSTM，GRU，TCN三种最先进的深度学习模型，使用欧盟配额交易价格和外生特征构建数据集进行对比评估。

Result: 实验结果表明，所提出的方法在预测准确性上比现有的基准模型有明显提升，RMSE和MAE分别减少了22.35%和18.63%。并且比原始LSTM模型的降低70.55%和74.42%。

Conclusion: 这些发现强调了将结构意识和多尺度分解集成到深度学习架构中的价值，提高了碳价格预测和其他非平稳金融时间序列的准确性和可解释性。

Abstract: Accurately forecasting carbon prices is essential for informed energy market
decision-making, guiding sustainable energy planning, and supporting effective
decarbonization strategies. However, it remains challenging due to structural
breaks and high-frequency noise caused by frequent policy interventions and
market shocks. Existing studies, including the most recent baseline approaches,
have attempted to incorporate breakpoints but often treat denoising and
modeling as separate processes and lack systematic evaluation across advanced
deep learning architectures, limiting the robustness and the generalization
capability. To address these gaps, this paper proposes a comprehensive hybrid
framework that integrates structural break detection (Bai-Perron, ICSS, and
PELT algorithms), wavelet signal denoising, and three state-of-the-art deep
learning models (LSTM, GRU, and TCN). Using European Union Allowance (EUA) spot
prices from 2007 to 2024 and exogenous features such as energy prices and
policy indicators, the framework constructs univariate and multivariate
datasets for comparative evaluation. Experimental results demonstrate that our
proposed PELT-WT-TCN achieves the highest prediction accuracy, reducing
forecasting errors by 22.35% in RMSE and 18.63% in MAE compared to the
state-of-the-art baseline model (Breakpoints with Wavelet and LSTM), and by
70.55% in RMSE and 74.42% in MAE compared to the original LSTM without
decomposition from the same baseline study. These findings underscore the value
of integrating structural awareness and multiscale decomposition into deep
learning architectures to enhance accuracy and interpretability in carbon price
forecasting and other nonstationary financial time series.

</details>


### [91] [An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones](https://arxiv.org/abs/2511.05265)
*Taihelong Zeng,Yun Lin,Yuhe Shi,Yan Li,Zhiqing Wei,Xuanru Ji*

Main category: cs.LG

TL;DR: 研究提出了一种层次化Actor-Critic深度强化学习框架来解决带有无人机的旅行商问题(TSP-D)，该框架在不同规模的测试集上展示了优于传统启发式算法和现有的强化学习方法的性能，并且在训练效率上也有显著提升。


<details>
  <summary>Details</summary>
Motivation: 经典的路由优化问题在引入了同步车辆协调后变得更为复杂且更具挑战性。该研究希望通过深度强化学习及其自监督策略学习和自适应决策制定来解决这些挑战。

Method: 研究提出了一种包含Transformer编码器和Minimal Gated Unit解码器的层次化Actor-Critic深度强化学习框架。该框架利用优化后的k-最近邻稀疏注意力机制，以关注重要的空间关系，并结合全局节点特征，用于有效生成解决序列。

Result: 实验结果表明，提出的模型在与高性能的启发式算法和现有的强化学习方法相比时，在短平均计算时间内可以取得具有竞争力甚至更好的解决方案。此外，算法框架还展示了减少总体训练时间的优势，同时获得了更好的最终性能。

Conclusion: 创新的强化学习框架在解决带有无人机的旅行商问题上展示出显著的性能提升和效率优势。

Abstract: The emergence of truck-drone collaborative systems in last-mile logistics has
positioned the Traveling Salesman Problem with Drones (TSP-D) as a pivotal
extension of classical routing optimization, where synchronized vehicle
coordination promises substantial operational efficiency and reduced
environmental impact, yet introduces NP-hard combinatorial complexity beyond
the reach of conventional optimization paradigms. Deep reinforcement learning
offers a theoretically grounded framework to address TSP-D's inherent
challenges through self-supervised policy learning and adaptive
decision-making. This study proposes a hierarchical Actor-Critic deep
reinforcement learning framework for solving the TSP-D problem. The
architecture consists of two primary components: a Transformer-inspired encoder
and an efficient Minimal Gated Unit decoder. The encoder incorporates a novel,
optimized k-nearest neighbors sparse attention mechanism specifically for
focusing on relevant spatial relationships, further enhanced by the integration
of global node features. The Minimal Gated Unit decoder processes these encoded
representations to efficiently generate solution sequences. The entire
framework operates within an asynchronous advantage actor-critic paradigm.
Experimental results show that, on benchmark TSP-D instances of various scales
(N=10 to 100), the proposed model can obtain competitive or even superior
solutions in shorter average computation times compared to high-performance
heuristic algorithms and existing reinforcement learning methods. Moreover,
compared to advanced reinforcement learning algorithm benchmarks, the proposed
framework significantly reduces the total training time required while
achieving superior final performance, highlighting its notable advantage in
training efficiency.

</details>


### [92] [Usando LLMs para Programar Jogos de Tabuleiro e Variações](https://arxiv.org/abs/2511.05114)
*Álvaro Guglielmin Becker,Lana Bertoldo Rossato,Anderson Rocha Tavares*

Main category: cs.LG

TL;DR: 本文提出了一种方法，用于测试大型语言模型(LLMs)在创建棋盘游戏代码方面的能力，特别是Claude、DeepSeek和ChatGPT。


<details>
  <summary>Details</summary>
Motivation: 创建表示棋盘游戏的程序通常是一项耗时的任务。大型语言模型(LLMs)由于能够从简单的上下文信息中高效生成代码而成为加速此过程的有吸引力的工具。

Method: 本文提出了一种方法，用于测试三个大型语言模型(Claude，DeepSeek和ChatGPT)在创建棋盘游戏代码方面的表现，包括现有游戏的新变体。

Result: 未具体说明。需进一步实验来确定这些模型的表现。

Conclusion: 通过评估大型语言模型在生成棋盘游戏代码方面的表现，可以更好地理解这些模型的能力，以及它们在实际应用中的潜力。

Abstract: Creating programs to represent board games can be a time-consuming task.
Large Language Models (LLMs) arise as appealing tools to expedite this process,
given their capacity to efficiently generate code from simple contextual
information. In this work, we propose a method to test how capable three LLMs
(Claude, DeepSeek and ChatGPT) are at creating code for board games, as well as
new variants of existing games.

</details>


### [93] [QuAnTS: Question Answering on Time Series](https://arxiv.org/abs/2511.05124)
*Felix Divo,Maurice Kraus,Anh Q. Nguyen,Hao Xue,Imran Razzak,Flora D. Salim,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.LG

TL;DR: 文章提出了一种新的时间序列问答数据集QuAnTS，以解决时间序列问答领域研究不足的问题，通过对人类动作时间序列数据进行广泛的问题和答案设定，为时间序列的问答应用提供了一个全面的数据集和实验基础，并鼓励未来对时间序列模型中的文本交互研究，以改善决策和透明度系统。


<details>
  <summary>Details</summary>
Motivation: 文本提供了获取信息的直观方式，特别是可以补充数值时间序列的密度，从而改善与时间序列模型的交互，提高可访问性和决策制定。然而，大多数研究集中在视觉和文本上的问答任务，对于时间序列的问答任务则关注较少。为解决这种不平衡，我们提出了一个新的问答时间序列数据集QuAnTS。

Method: 通过对人类运动轨迹的广泛问题和答案设定，提出了一个新的大型时间和问答数据集QuAnTS。对数据集进行了全面的实验，验证其合理性和全面性。评估了现有和新提出的基准模型，为深度探索时间序列问答模型打下了基础。此外，还提供了人类性能作为模型实用性的关键参照。

Result: 通过数据集的构建和模型评估实验，证明了QuAnTS的数据集是合理且全面的，并为时间序列问答模型提供了一定的性能基准，同时也证明了该数据集在鼓励时间序列领域的文本交互研究方面的潜力。

Conclusion: QuAnTS 数据集的引入，为时间和问答领域提供了一个新的研究视角，即通过文本的方式与时间序列模型进行互动。我们希望QuAnTS 数据集能够为未来的研究提供基础，促进更好的决策制定和透明度系统的开发。

Abstract: Text offers intuitive access to information. This can, in particular,
complement the density of numerical time series, thereby allowing improved
interactions with time series models to enhance accessibility and
decision-making. While the creation of question-answering datasets and models
has recently seen remarkable growth, most research focuses on question
answering (QA) on vision and text, with time series receiving minute attention.
To bridge this gap, we propose a challenging novel time series QA (TSQA)
dataset, QuAnTS, for Question Answering on Time Series data. Specifically, we
pose a wide variety of questions and answers about human motion in the form of
tracked skeleton trajectories. We verify that the large-scale QuAnTS dataset is
well-formed and comprehensive through extensive experiments. Thoroughly
evaluating existing and newly proposed baselines then lays the groundwork for a
deeper exploration of TSQA using QuAnTS. Additionally, we provide human
performances as a key reference for gauging the practical usability of such
models. We hope to encourage future research on interacting with time series
models through text, enabling better decision-making and more transparent
systems.

</details>


### [94] [Consecutive Preferential Bayesian Optimization](https://arxiv.org/abs/2511.05163)
*Aras Erarslan,Carlos Sevilla Salcedo,Ville Tanskanen,Anni Nisov,Eero Päiväkumpu,Heikki Aisala,Kaisu Honkapää,Arto Klami,Petrus Mikkola*

Main category: cs.LG

TL;DR: 这项研究提出了一种新的贝叶斯优化方法，即连续偏好贝叶斯优化（Consecutive Preferential Bayesian Optimization），该方法考虑了候选解决方案的生成成本，并引入感知阈值来处理反馈的感知模糊性，提高了在高生产成本或具有冷漠反馈情况下的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统偏好贝叶斯优化方法往往忽略了候选解决方案的生成成本，而这项研究将直接面对此问题，通过引入连续偏好贝叶斯优化来降低生成成本，并且考虑到人类反馈中存在的感知模糊性，更准确地捕捉人类偏好。

Method: 该方法引入了Just-Noticeable Difference阈值来处理反馈的感知模糊性，并使用信息理论的获取策略来选择最有信息量的新配置，从而在偏好模型中捕捉到小的效用差异所带来的无差异反馈。

Result: 实验结果显示，在高生产成本或具有冷漠反馈的情况下，连续偏好贝叶斯优化方法的准确性得到了显著提高。

Conclusion: 连续偏好贝叶斯优化是一种更加高效且精确的优化方法，它能够有效地处理候选解决方案的生成成本，同时更准确地捕捉人类反馈中的无差异性。

Abstract: Preferential Bayesian optimization allows optimization of objectives that are
either expensive or difficult to measure directly, by relying on a minimal
number of comparative evaluations done by a human expert. Generating candidate
solutions for evaluation is also often expensive, but this cost is ignored by
existing methods. We generalize preference-based optimization to explicitly
account for production and evaluation costs with Consecutive Preferential
Bayesian Optimization, reducing production cost by constraining comparisons to
involve previously generated candidates. We also account for the perceptual
ambiguity of the oracle providing the feedback by incorporating a
Just-Noticeable Difference threshold into a probabilistic preference model to
capture indifference to small utility differences. We adapt an
information-theoretic acquisition strategy to this setting, selecting new
configurations that are most informative about the unknown optimum under a
preference model accounting for the perceptual ambiguity. We empirically
demonstrate a notable increase in accuracy in setups with high production costs
or with indifference feedback.

</details>


### [95] [Multimodal Deep Learning for Prediction of Progression-Free Survival in Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor Radionuclide Therapy](https://arxiv.org/abs/2511.05169)
*Simon Baur,Tristan Ruhwedel,Ekin Böke,Zuzanna Kobus,Gergana Lishkova,Christoph Wetz,Holger Amthauer,Christoph Roderburg,Frank Tacke,Julian M. Rogasch,Wojciech Samek,Henning Jann,Jackie Ma,Johannes Eschrich*

Main category: cs.LG

TL;DR: 本研究评估了实验室检测、影像学和多模态深度学习模型在预测PRRT治疗的神经内分泌肿瘤患者无进展生存期（PFS）方面的表现。使用多模态融合方法的模型性能最佳，准确率（AUROC）达到0.72。初步表明多模态深度学习对于PRRT后PFS的预测优于单模态方法。


<details>
  <summary>Details</summary>
Motivation: 预测PRRT治疗的神经内分泌肿瘤患者的无进展生存期，以支持个体化治疗计划制定；

Method: 收集了116名接受177Lu-DOTATOC治疗的神经内分泌肿瘤患者的数据，包括临床特征、实验室值和治疗前的正电子发射断层扫描/计算机断层扫描（SR-PET/CT）。使用了七种不同模型方法，包括单模态以及多模态融合方法；

Result: 最佳模型是多模态融合模型，这一模型结合了实验室值、SR-PET和CT，准确率（AUROC）达到0.72。使用单模态方法如实验室数据，或SR-PET/CT，结果均不及多模态融合模型；

Conclusion: 本研究表明，结合多模态数据的深度学习方法在预测PRRT后无进展生存期方面优于单模态方法。这种模型在外部验证和支持个体化随访策略方面具有潜在的应用前景。

Abstract: Peptide receptor radionuclide therapy (PRRT) is an established treatment for
metastatic neuroendocrine tumors (NETs), yet long-term disease control occurs
only in a subset of patients. Predicting progression-free survival (PFS) could
support individualized treatment planning. This study evaluates laboratory,
imaging, and multimodal deep learning models for PFS prediction in PRRT-treated
patients. In this retrospective, single-center study 116 patients with
metastatic NETs undergoing 177Lu-DOTATOC were included. Clinical
characteristics, laboratory values, and pretherapeutic somatostatin receptor
positron emission tomography/computed tomographies (SR-PET/CT) were collected.
Seven models were trained to classify low- vs. high-PFS groups, including
unimodal (laboratory, SR-PET, or CT) and multimodal fusion approaches.
Explainability was evaluated by feature importance analysis and gradient maps.
Forty-two patients (36%) had short PFS (< 1 year), 74 patients long PFS (>1
year). Groups were similar in most characteristics, except for higher baseline
chromogranin A (p = 0.003), elevated gamma-GT (p = 0.002), and fewer PRRT
cycles (p < 0.001) in short-PFS patients. The Random Forest model trained only
on laboratory biomarkers reached an AUROC of 0.59 +- 0.02. Unimodal
three-dimensional convolutional neural networks using SR-PET or CT performed
worse (AUROC 0.42 +- 0.03 and 0.54 +- 0.01, respectively). A multimodal fusion
model laboratory values, SR-PET, and CT -augmented with a pretrained CT branch
- achieved the best results (AUROC 0.72 +- 0.01, AUPRC 0.80 +- 0.01).
Multimodal deep learning combining SR-PET, CT, and laboratory biomarkers
outperformed unimodal approaches for PFS prediction after PRRT. Upon external
validation, such models may support risk-adapted follow-up strategies.

</details>


### [96] [ProDER: A Continual Learning Approach for Fault Prediction in Evolving Smart Grids](https://arxiv.org/abs/2511.05420)
*Emad Efatinasab,Nahal Azadi,Davide Dalle Pezze,Gian Antonio Susto,Chuadhry Mujeeb Ahmed,Mirco Rampazzo*

Main category: cs.LG

TL;DR: 本文提出了一种在智能电网环境下适应模型和环境协同演变的持续学习（CL）框架。为了模拟电网条件的演变，设计了四个基于类增量和领域增量学习的真实评估场景。引入了一种统一的回放方法—基于原型的黑暗经验重放（ProDER），它可以实现最高性能，仅在故障类型预测中有0.045的准确率下降，在故障区域预测中有0.015的准确率下降。这表明CL技术对于智能电网中可扩展的、实用的故障预测具有实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 现有的基于AI的故障预测模型在不断变化的环境中适应新区域和新故障类型的能力不足，本文旨在提出一种能够适应电网环境变化的持续学习框架，提升模型在智能电网中的故障预测能力。

Method: 本文设计了一种基于原型的黑暗经验重放（ProDER）模型，该模型将原型基特征正则化、logit蒸馏和原型引导重放缓冲区集成在一起，用来解决不断变化环境中的故障预测问题。同时，设计了四个基于真实场景的评估，包括两类增量学习和领域增量学习，以此来检验方法的有效性。

Result: 通过实验，基于原型的黑暗经验重放（ProDER）框架在类增量学习和领域增量学习的评估下表现最佳，仅比基准案例在故障类型预测中有0.045的准确率下降，在故障区域预测中有0.015的准确率下降。

Conclusion: 实验结果表明，持续学习框架下的ProDER方法，可以在不断变化的电网环境下有效地进行故障预测，为智能电网的大规模实际故障预测提供了可能。

Abstract: As smart grids evolve to meet growing energy demands and modern operational
challenges, the ability to accurately predict faults becomes increasingly
critical. However, existing AI-based fault prediction models struggle to ensure
reliability in evolving environments where they are required to adapt to new
fault types and operational zones. In this paper, we propose a continual
learning (CL) framework in the smart grid context to evolve the model together
with the environment. We design four realistic evaluation scenarios grounded in
class-incremental and domain-incremental learning to emulate evolving grid
conditions. We further introduce Prototype-based Dark Experience Replay
(ProDER), a unified replay-based approach that integrates prototype-based
feature regularization, logit distillation, and a prototype-guided replay
memory. ProDER achieves the best performance among tested CL techniques, with
only a 0.045 accuracy drop for fault type prediction and 0.015 for fault zone
prediction. These results demonstrate the practicality of CL for scalable,
real-world fault prediction in smart grids.

</details>


### [97] [APP: Accelerated Path Patching with Task-Specific Pruning](https://arxiv.org/abs/2511.05442)
*Frauke Andersen,William Rudman,Ruochen Zhang,Carsten Eickhoff*

Main category: cs.LG

TL;DR: 该研究提出了加速路径修补（APP）方法，通过新颖的对比注意力头修剪方法，大幅减少了电路发现方法的搜索空间，实现了显著的计算效率提升。尽管APP自身找到的电路较大，但通过第一阶段应用对比FLAP修剪和第二阶段应用传统路径修补，成功实现了性能与效率的双重优化。与传统路径修补相比，APP在保持相似性能的同时，计算速度快了59.63%至93.27%。


<details>
  <summary>Details</summary>
Motivation: 当前的电路发现方法，如路径修补，计算成本高且对于较小模型的深层次电路分析有限。该研究旨在寻找一种更有效的方法来加速电路发现过程，同时保持电路分析的准确性。

Method: 该研究提出了加速路径修补（APP）方法。首先通过对比FLAP修剪方法大幅减少搜索空间，然后在剩余注意力头中应用传统路径修补方法，从而使整个电路发现过程大大加速。对比FLAP修剪算法使用因果中介分析技术，为特定任务的注意力头分配更高的修剪分数，从而生成性能更高的稀疏模型。

Result: 实验结果表明，对比FLAP修剪方法成功地保留了特定任务所需的头部，这些头部在低稀疏度比下被现有的修剪算法移除。APP相比直接对稠密模型应用路径修补方法，加速了59.63%至93.27%。获得的电路显示出与传统的路径修补电路有显著的重叠和相似的性能。

Conclusion: 该研究成功地提出了加速路径修补（APP）方法，通过结合对比FLAP修剪和传统路径修补，实现了电路发现过程的显著加速，同时保持了电路分析的准确性。

Abstract: Circuit discovery is a key step in many mechanistic interpretability
pipelines. Current methods, such as Path Patching, are computationally
expensive and have limited in-depth circuit analysis for smaller models. In
this study, we propose Accelerated Path Patching (APP), a hybrid approach
leveraging our novel contrastive attention head pruning method to drastically
reduce the search space of circuit discovery methods. Our Contrastive-FLAP
pruning algorithm uses techniques from causal mediation analysis to assign
higher pruning scores to task-specific attention heads, leading to higher
performing sparse models compared to traditional pruning techniques. Although
Contrastive-FLAP is successful at preserving task-specific heads that existing
pruning algorithms remove at low sparsity ratios, the circuits found by
Contrastive-FLAP alone are too large to satisfy the minimality constraint
required in circuit analysis. APP first applies Contrastive-FLAP to reduce the
search space on required for circuit discovery algorithms by, on average, 56\%.
Next, APP, applies traditional Path Patching on the remaining attention heads,
leading to a speed up of 59.63\%-93.27\% compared to Path Patching applied to
the dense model. Despite the substantial computational saving that APP
provides, circuits obtained from APP exhibit substantial overlap and similar
performance to previously established Path Patching circuits

</details>


### [98] [Associative Poisoning to Generative Machine Learning](https://arxiv.org/abs/2511.05177)
*Mathias Lundteigen Mohus,Jingyue Li,Zhirong Yang*

Main category: cs.LG

TL;DR: 本文介绍了一种新的数据投毒技术——关联投毒，可以在不控制训练过程的情况下操纵生成数据中的具体特征关联。研究结果显示，这种攻击可以有效地操纵特征关联，同时保持目标特征的边际分布和高质量输出，从而逃避视觉检测。现有的防御策略对此类攻击效果有限，因此本文还提出了一个新的防御策略。


<details>
  <summary>Details</summary>
Motivation: 现有投毒攻击通常会导致生成数据的广泛降级，或需要控制训练过程，限制了其在真实场景中的应用。本文提出了一个新的投毒技术，可以在不控制训练过程的情况下，操纵生成数据中的特定特征关联，使其在实际场景中更容易实现，并且难以被检测。

Method: 提出了关联投毒方法，这种方法通过仅更改训练数据，改变生成输出中特定特征对的统计联系，而不需要控制训练过程。并提供了该攻击的正式数学描述，证明了其理论可行性和难以被检测的特性。

Result: 实证评估表明，关联投毒可以在保持高输出质量的同时，操纵特征关联，而且逃避了视觉检测。这表明常用的生成系统在图像合成、合成数据集生成和自然语言处理方面容易受到这种微妙且难以检测的操纵。

Conclusion: 现有防御策略在这种类型攻击面前效果有限，因此提出了一个新的防御策略来应对关联投毒攻击带来的风险。这项研究强调了需要更加强大的防御措施来保护生成系统的统计完整性。

Abstract: The widespread adoption of generative models such as Stable Diffusion and
ChatGPT has made them increasingly attractive targets for malicious
exploitation, particularly through data poisoning. Existing poisoning attacks
compromising synthesised data typically either cause broad degradation of
generated data or require control over the training process, limiting their
applicability in real-world scenarios. In this paper, we introduce a novel data
poisoning technique called associative poisoning, which compromises
fine-grained features of the generated data without requiring control of the
training process. This attack perturbs only the training data to manipulate
statistical associations between specific feature pairs in the generated
outputs. We provide a formal mathematical formulation of the attack and prove
its theoretical feasibility and stealthiness. Empirical evaluations using two
state-of-the-art generative models demonstrate that associative poisoning
effectively induces or suppresses feature associations while preserving the
marginal distributions of the targeted features and maintaining high-quality
outputs, thereby evading visual detection. These results suggest that
generative systems used in image synthesis, synthetic dataset generation, and
natural language processing are susceptible to subtle, stealthy manipulations
that compromise their statistical integrity. To address this risk, we examine
the limitations of existing defensive strategies and propose a novel
countermeasure strategy.

</details>


### [99] [On Flow Matching KL Divergence](https://arxiv.org/abs/2511.05480)
*Maojiang Su,Jerry Yao-Chieh Hu,Sophia Pi,Han Liu*

Main category: cs.LG

TL;DR: 该研究得出流匹配分布近似Kullback-Leibler (KL)散度的一个确定性、非渐近上界，表明流匹配在估计平滑分布方面的统计效率几乎达到了最优，并且在Total Variation (TV)距离下与扩散模型的统计效率相当。


<details>
  <summary>Details</summary>
Motivation: 研究流匹配分布近似的Kullback-Leibler (KL)散度的上界，以评估流匹配在估计数据分布时的统计效率，特别是在Total Variation (TV)距离下的表现。

Method: 通过分析$L_2$流匹配损失与KL散度之间的关系，推导出KL散度的一个上界，并通过数值研究验证理论结果。

Result: 流匹配在估计平滑分布方面的统计效率接近最优，且其统计效率在Total Variation (TV)距离下与扩散模型相当。数值研究支持了这一理论结果。

Conclusion: 该研究展示了流匹配在估计平滑分布时的统计效率，表明其在Total Variation (TV)距离下接近最佳，与扩散模型的统计效率相当。

Abstract: We derive a deterministic, non-asymptotic upper bound on the Kullback-Leibler
(KL) divergence of the flow-matching distribution approximation. In particular,
if the $L_2$ flow-matching loss is bounded by $\epsilon^2 > 0$, then the KL
divergence between the true data distribution and the estimated distribution is
bounded by $A_1 \epsilon + A_2 \epsilon^2$. Here, the constants $A_1$ and $A_2$
depend only on the regularities of the data and velocity fields. Consequently,
this bound implies statistical convergence rates of Flow Matching Transformers
under the Total Variation (TV) distance. We show that, flow matching achieves
nearly minimax-optimal efficiency in estimating smooth distributions. Our
results make the statistical efficiency of flow matching comparable to that of
diffusion models under the TV distance. Numerical studies on synthetic and
learned velocities corroborate our theory.

</details>


### [100] [DGTN: Graph-Enhanced Transformer with Diffusive Attention Gating Mechanism for Enzyme DDG Prediction](https://arxiv.org/abs/2511.05483)
*Abigail Lin*

Main category: cs.LG

TL;DR: DGTN is a new architecture that co-learns GNN weights for structural priors and transformer attention through a diffusion mechanism, achieving state-of-the-art performance in predicting amino acid mutations on enzyme thermodynamic stability.


<details>
  <summary>Details</summary>
Motivation: Current deep learning approaches for predicting the impact of amino acid mutations on enzyme stability process sequence and structure information independently, unable to capture the complex interplay between local structural geometry and global sequential patterns. This work aims to bridge this gap.

Method: DGTN (Diffused Graph-Transformer Network) combines graph neural networks and transformers using a bidirectional diffusion process. This includes GNN-derived structural embeddings guiding transformer attention and transformer representations refining GNN message passing.

Result: On benchmarks (ProTherm and SKEMPI), DGTN achieved state-of-the-art performance with metrics of Pearson Rho = 0.87 and RMSE = 1.21 kcal/mol, showing 6.2% improvement over the best previous methods.

Conclusion: The work introduces DGTN, which proves beneficial for the prediction of effects from amino acid mutations on enzyme stability by integrating heterogeneous protein information.

Abstract: Predicting the effect of amino acid mutations on enzyme thermodynamic
stability (DDG) is fundamental to protein engineering and drug design. While
recent deep learning approaches have shown promise, they often process sequence
and structure information independently, failing to capture the intricate
coupling between local structural geometry and global sequential patterns. We
present DGTN (Diffused Graph-Transformer Network), a novel architecture that
co-learns graph neural network (GNN) weights for structural priors and
transformer attention through a diffusion mechanism. Our key innovation is a
bidirectional diffusion process where: (1) GNN-derived structural embeddings
guide transformer attention via learnable diffusion kernels, and (2)
transformer representations refine GNN message passing through
attention-modulated graph updates. We provide rigorous mathematical analysis
showing this co-learning scheme achieves provably better approximation bounds
than independent processing. On ProTherm and SKEMPI benchmarks, DGTN achieves
state-of-the-art performance (Pearson Rho = 0.87, RMSE = 1.21 kcal/mol), with
6.2% improvement over best baselines. Ablation studies confirm the diffusion
mechanism contributes 4.8 points to correlation. Our theoretical analysis
proves the diffused attention converges to optimal structure-sequence coupling,
with convergence rate O(1/sqrt(T) ) where T is diffusion steps. This work
establishes a principled framework for integrating heterogeneous protein
representations through learnable diffusion.

</details>


### [101] [ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy](https://arxiv.org/abs/2511.05221)
*David Bertram,Anja Ophey,Sinah Röttgen,Konstantin Kuffer,Gereon R. Fink,Elke Kalbe,Clint Hansen,Walter Maetzler,Maximilian Kapsecker,Lara M. Reimer,Stephan Jonas,Andreas T. Damgaard,Natasha B. Bertelsen,Casper Skjaerbaek,Per Borghammer,Karolien Groenewald,Pietro-Luca Ratti,Michele T. Hu,No émie Moreau,Michael Sommerauer,Katarzyna Bozek*

Main category: cs.LG

TL;DR: 这个研究提出了ActiTect，一种全自动的开源机器学习工具，用于从活动记录中识别REM睡眠行动障碍（RBD），并通过多项验证证明了其准确性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: REM睡眠行为紊乱是一种预警帕金森病等疾病的症状，但现有的腕部活动监护仪缺少可靠的分析流程。因此，开发了一个全自动的机器学习工具来检测RBD，以提高大规模筛查的效率和准确性。

Method: 该工具基于对78名个体的样本开发，并采用了交叉验证方法，包括稳健的数据预处理、自动睡眠醒来识别功能来保持多设备数据的同质性。通过对多种外部数据集进行测试，展示了工具的泛化能力和鲁棒性。

Result: 在内部验证中，工具的AUROC值达到了0.95，在外部验证中也表现出了良好的预测能力（AUROC分别为0.84和0.94）。此外，工具还具有可移植性和稳定性，支持不同数据集间的迁移和独立验证。

Conclusion: ActiTect是一个开源的全自动机器学习工具，它通过一种可重复和泛化的模型来识别RBD，推动了利用可穿戴设备进行RBD检测领域的进展。

Abstract: Isolated rapid eye movement sleep behavior disorder (iRBD) is a major
prodromal marker of $\alpha$-synucleinopathies, often preceding the clinical
onset of Parkinson's disease, dementia with Lewy bodies, or multiple system
atrophy. While wrist-worn actimeters hold significant potential for detecting
RBD in large-scale screening efforts by capturing abnormal nocturnal movements,
they become inoperable without a reliable and efficient analysis pipeline. This
study presents ActiTect, a fully automated, open-source machine learning tool
to identify RBD from actigraphy recordings. To ensure generalizability across
heterogeneous acquisition settings, our pipeline includes robust preprocessing
and automated sleep-wake detection to harmonize multi-device data and extract
physiologically interpretable motion features characterizing activity patterns.
Model development was conducted on a cohort of 78 individuals, yielding strong
discrimination under nested cross-validation (AUROC = 0.95). Generalization was
confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two
independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To
assess real-world robustness, leave-one-dataset-out cross-validation across the
internal and external cohorts demonstrated consistent performance (AUROC range
= 0.84-0.89). A complementary stability analysis showed that key predictive
features remained reproducible across datasets, supporting the final pooled
multi-center model as a robust pre-trained resource for broader deployment. By
being open-source and easy to use, our tool promotes widespread adoption and
facilitates independent validation and collaborative improvements, thereby
advancing the field toward a unified and generalizable RBD detection model
using wearable devices.

</details>


### [102] [The Causal Round Trip: Generating Authentic Counterfactuals by Eliminating Information Loss](https://arxiv.org/abs/2511.05236)
*Rui Wu,Lizheng Wang,Yongjun Li*

Main category: cs.LG

TL;DR: 介绍了一种名为BELM-MDCM的新框架，解决了SCM中反事实推理中存在的信息损失问题，使现代生成模型与经典因果理论相统一，达到更严格的因果推理标准


<details>
  <summary>Details</summary>
Motivation: Judea Pearl提出的结构因果模型（SCMs）需要精确推断隐变量，扩散模型的功能强大但也引入了信息损失，导致推断不准确。为此，新框架需要解决这一挑战

Method: 提出了因果信息守恒(CIC)原则，以此为理论基础设计了BELM-MDCM框架，并引入了定向建模策略和混合训练目标以实现这一框架

Result: 实验表明，该框架在精度上达到最佳，同时也支持高保真度个体级别的反事实推理

Conclusion: 该工作提供了一个基础蓝图，将现代生成模型与经典因果理论相结合，为这一新兴领域确立了更严格的因果推理标准

Abstract: Judea Pearl's vision of Structural Causal Models (SCMs) as engines for
counterfactual reasoning hinges on faithful abduction: the precise inference of
latent exogenous noise. For decades, operationalizing this step for complex,
non-linear mechanisms has remained a significant computational challenge. The
advent of diffusion models, powerful universal function approximators, offers a
promising solution. However, we argue that their standard design, optimized for
perceptual generation over logical inference, introduces a fundamental flaw for
this classical problem: an inherent information loss we term the Structural
Reconstruction Error (SRE). To address this challenge, we formalize the
principle of Causal Information Conservation (CIC) as the necessary condition
for faithful abduction. We then introduce BELM-MDCM, the first diffusion-based
framework engineered to be causally sound by eliminating SRE by construction
through an analytically invertible mechanism. To operationalize this framework,
a Targeted Modeling strategy provides structural regularization, while a Hybrid
Training Objective instills a strong causal inductive bias. Rigorous
experiments demonstrate that our Zero-SRE framework not only achieves
state-of-the-art accuracy but, more importantly, enables the high-fidelity,
individual-level counterfactuals required for deep causal inquiries. Our work
provides a foundational blueprint that reconciles the power of modern
generative models with the rigor of classical causal theory, establishing a new
and more rigorous standard for this emerging field.

</details>


### [103] [Embedding-Space Data Augmentation to Prevent Membership Inference Attacks in Clinical Time Series Forecasting](https://arxiv.org/abs/2511.05289)
*Marius Fracarolli,Michael Staniek,Stefan Riezler*

Main category: cs.LG

TL;DR: 本研究探讨了数据增强在减轻时间序列预测模型中成员推断攻击上效果，特别采用了零阶优化和通过主成分分析约束的零阶优化等方法，实验结果表明ZOO-PCA方法可以在不牺牲模型性能的情况下，减少成员推断攻击的真正正率与假正率的比率，提高模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了平衡电子健康记录数据增强的强隐私保护与高预测性能，研究如何通过数据增强来减少时间序列预测模型面临的成员推断攻击，从而保护患者隐私的同时保证预测准确性。

Method: 本研究测试了多种数据增强策略，包括零阶优化(ZOO)、零阶优化与主成分分析约束的结合(ZOO-PCA)，以及混合上采样(MixUp)，以提高TSF模型的安全性和可泛化性。

Result: 实验结果表明，ZOO-PCA策略在减少成员推断攻击的真正正率与假正率比率方面优于其他策略，并且能够保持模型的预测性能。

Conclusion: 通过适当的合成数据生成策略，能够有效增强时间序列预测模型对于成员推断攻击的安全性。ZOO-PCA是提高模型鲁棒性同时保有预测准确性的有效方法。

Abstract: Balancing strong privacy guarantees with high predictive performance is
critical for time series forecasting (TSF) tasks involving Electronic Health
Records (EHR). In this study, we explore how data augmentation can mitigate
Membership Inference Attacks (MIA) on TSF models. We show that retraining with
synthetic data can substantially reduce the effectiveness of loss-based MIAs by
reducing the attacker's true-positive to false-positive ratio. The key
challenge is generating synthetic samples that closely resemble the original
training data to confuse the attacker, while also introducing enough novelty to
enhance the model's ability to generalize to unseen data. We examine multiple
augmentation strategies - Zeroth-Order Optimization (ZOO), a variant of ZOO
constrained by Principal Component Analysis (ZOO-PCA), and MixUp - to
strengthen model resilience without sacrificing accuracy. Our experimental
results show that ZOO-PCA yields the best reductions in TPR/FPR ratio for MIA
attacks without sacrificing performance on test data.

</details>


### [104] [Attention and Compression is all you need for Controllably Efficient Language Models](https://arxiv.org/abs/2511.05313)
*Jatin Prakash,Aahlad Puli,Rajesh Ranganath*

Main category: cs.LG

TL;DR: 介绍了一种称为Compress & Attend Transformer (CAT)的新架构，它结合了密集注意和压缩机制，在减少计算和内存使用的同时保持了较高的质量。CAT在训练过程中可以使用多个块大小，允许在测试时直接控制质量-计算权衡，而无需重新训练。实验表明，单个CAT模型在各种计算-内存预算下优于现有的高效基线，包括混合架构，在语言建模方面与密集变压器相当，但速度快1.4-3倍，且内存使用量减少2-9倍。


<details>
  <summary>Details</summary>
Motivation: 当前的高效变压器变体（如稀疏注意力、滑动窗口注意力、卷积和线性注意力）虽然在计算和内存效率方面有了显著改进，但在上下文回忆性能等方面仍面临质量损失的问题。固定的质量-计算权衡在某些应用场景中表现不佳，且这些方法依赖于启发式的注意力限制和复杂的状態更新规则。为解决这些问题，提出了CAT架构。

Method: CAT架构采用了两个简单的组件：密集注意力和压缩机制。它通过注意压缩后的序列来解码词块，从而从减少的序列长度中解码，达到计算和内存的节省。选择特定的块大小可以在质量与效率之间进行权衡。此外，CAT可以同时训练多个块大小，允许在测试时直接控制质量-计算权衡，而无需重新训练。这种方法提供了一种单一灵活的架构。

Result: 在多项实验中，单个CAT模型在总共的计算-内存预算下均优于现有的高效基线，以及混合架构。在语言建模方面，它与密集变压器相当，但速度更快，内存使用量更少。这表明CAT架构在平衡质量与计算效率方面表现出色。

Conclusion: CAT是一种新的方法，它可以有效地解决当前高效变压器在质量与计算效率之间的权衡问题，提供了一种灵活且适应性强的解决方案。

Abstract: The quadratic cost of attention in transformers motivated the development of
efficient approaches: namely sparse and sliding window attention, convolutions
and linear attention. Although these approaches result in impressive reductions
in compute and memory, they often trade-off with quality, specifically
in-context recall performance. Moreover, apriori fixing this quality-compute
tradeoff means being suboptimal from the get-go: some downstream applications
require more memory for in-context recall, while others require lower latency
and memory. Further, these approaches rely on heuristic choices that
artificially restrict attention, or require handcrafted and complex recurrent
state update rules, or they must be carefully composed with attention at
specific layers to form a hybrid architecture that complicates the design
process, especially at scale. To address above issues, we propose Compress &
Attend Transformer (CAT), a conceptually simple architecture employing two
simple ingredients only: dense attention and compression. CAT decodes chunks of
tokens by attending to compressed chunks of the sequence so far. Compression
results in decoding from a reduced sequence length that yields compute and
memory savings, while choosing a particular chunk size trades-off quality for
efficiency. Moreover, CAT can be trained with multiple chunk sizes at once,
unlocking control of quality-compute trade-offs directly at test-time without
any retraining, all in a single adaptive architecture. In exhaustive
evaluations on common language modeling tasks, in-context recall, and
long-context understanding, a single adaptive CAT model outperforms existing
efficient baselines, including hybrid architectures, across different
compute-memory budgets. Further, a single CAT matches dense transformer in
language modeling across model scales while being 1.4-3x faster and requiring
2-9x lower total memory usage.

</details>


### [105] [Turning Adversaries into Allies: Reversing Typographic Attacks for Multimodal E-Commerce Product Retrieval](https://arxiv.org/abs/2511.05325)
*Janet Jenq,Hongda Shen*

Main category: cs.LG

TL;DR: 通过在产品图像上直接渲染相关文本内容（例如标题、描述）来执行图像-文本压缩，增强图像-文本对齐并提高多模态产品检索性能。在三个垂直特定的电子商务数据集上进行的实验展示了跨类别和模型家族的一致改进。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（如CLIP）容易受到排版攻击的影响，误导性或不相关的文本嵌入图片中会扭曲模型预测，因此提出一种新方法来增强图像-文本对齐，提高多模态产品检索性能。

Method: 提出了一种将相关文本内容（例如标题、描述）直接渲染至产品图像中的方法，用以执行图像-文本压缩，并评估该方法在六个最先进的视觉基础模型和三个垂直特定的电子商务数据集上的效果。

Result: 实验展示了一系列跨类别和模型家族的一致改进，表明视觉渲染产品元数据是一类简单有效增强电子商务应用零样本多模态检索的手段。

Conclusion: 文章提出了一种将产品相关信息直接呈现于图像之中的方法，证实了新模式可靠性和有效性进而推动多模态检索在电商中的应用。

Abstract: Multimodal product retrieval systems in e-commerce platforms rely on
effectively combining visual and textual signals to improve search relevance
and user experience. However, vision-language models such as CLIP are
vulnerable to typographic attacks, where misleading or irrelevant text embedded
in images skews model predictions. In this work, we propose a novel method that
reverses the logic of typographic attacks by rendering relevant textual content
(e.g., titles, descriptions) directly onto product images to perform
vision-text compression, thereby strengthening image-text alignment and
boosting multimodal product retrieval performance. We evaluate our method on
three vertical-specific e-commerce datasets (sneakers, handbags, and trading
cards) using six state-of-the-art vision foundation models. Our experiments
demonstrate consistent improvements in unimodal and multimodal retrieval
accuracy across categories and model families. Our findings suggest that
visually rendering product metadata is a simple yet effective enhancement for
zero-shot multimodal retrieval in e-commerce applications.

</details>


### [106] [Diffusion-Based Electromagnetic Inverse Design of Scattering Structured Media](https://arxiv.org/abs/2511.05357)
*Mikhail Tsukerman,Konstantin Grotov,Pavel Ginzburg*

Main category: cs.LG

TL;DR: 我们提出了一种条件扩散模型，该模型可以直接从目标差异散射横截面轮廓生成结构介质几何形状，从而绕过了昂贵的迭代优化过程。我们的1D U-Net架构通过特征线性调制学习将所需的散射模式映射到2x2介质球结构，能够在不到19％的中位数MPE误差下生成未见过的目标，远超CMA-ES优化方法，并将设计时间从数小时减少到几秒，从而加速下一代光子和无线通信系统的发展。模型代码可从GitHub获取。


<details>
  <summary>Details</summary>
Motivation: 本文提出了一种条件扩散模型，用于电磁逆向设计问题，其目标是从目标差异散射横截面轮廓生成结构介质几何形状，从而提高设计效率，减少设计时间。同时解决逆向问题中设计非唯一性的困扰。这种方法避免了费时费力的迭代优化过程，提供了更快更精确的设计工具。

Method: 采用1D U-Net架构，利用特征线性调制，训练模型将目标散射横截面轮廓映射到2x2介质球结构。训练数据包含11,000个模拟元表面的数据，该模型能够处理逆向问题中的非唯一性，通过采样生成多个有效的设计方案。

Result: 该模型在目标测试集上表现优秀，精度显著优于CMA-ES优化方法，将设计时间从数小时大幅减少至数秒，证明了扩散模型在电磁逆向设计领域具有显著潜力。模型的MPE误差中位数低于19%，最高达到1.39%。

Conclusion: 本研究证明了扩散模型在电磁逆向设计中的有效性，为下一代光子和无线通信系统的设计提供了新的工具和方法，能够在较短时间内生成高质量的设计方案。此成果为进行复杂的元表面架构研究提供了新的方向，并加速了相关领域的发展。

Abstract: We present a conditional diffusion model for electromagnetic inverse design
that generates structured media geometries directly from target differential
scattering cross-section profiles, bypassing expensive iterative optimization.
Our 1D U-Net architecture with Feature-wise Linear Modulation learns to map
desired angular scattering patterns to 2x2 dielectric sphere structure,
naturally handling the non-uniqueness of inverse problems by sampling diverse
valid designs. Trained on 11,000 simulated metasurfaces, the model achieves
median MPE below 19% on unseen targets (best: 1.39%), outperforming CMA-ES
evolutionary optimization while reducing design time from hours to seconds.
These results demonstrate that employing diffusion models is promising for
advancing electromagnetic inverse design research, potentially enabling rapid
exploration of complex metasurface architectures and accelerating the
development of next-generation photonic and wireless communication systems. The
code is publicly available at
https://github.com/mikzuker/inverse_design_metasurface_generation.

</details>


### [107] [Synapse: Adaptive Arbitration of Complementary Expertise in Time Series Foundational Models](https://arxiv.org/abs/2511.05460)
*Sarkar Snigdha Sarathi Das,Palash Goyal,Mihir Parmar,Yiwen Song,Long T. Le,Lesly Miculicich,Jinsung Yoon,Rui Zhang,Hamid Palangi,Tomas Pfister*

Main category: cs.LG

TL;DR: 本文提出了一种新的混合时间序列预训练模型的方法，称为Synapse，它可以根据上下文动态调整各个模型的预测权重，从而生成更准确的时间序列预测结果。实验结果表明，Synapse比其他流行的混合方法和单一时间序列预训练模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 尽管时间序列预训练模型（TSFM）具有广泛的适用性，但由于不同的训练协议和数据源，它们在不同时间序列预测任务中的表现千差万别。为了利用这些模型的互补优势，本文提出了通过协调现有TSFM输出的策略，来提升时间序列预测的准确性。

Method: 本文提出了Synapse框架，该框架通过动态调整预训练模型的预测权重来协同生成预测结果。模型权重的调整基于各个模型在特定上下文下的相对表现，采样输出的概率分布构建最终预测结果。

Result: 实验结果表明，Synapse框架能够有效整合不同TSFM模型的强项，显著优于单独使用单一TSFM模型以及常用的集成方法。

Conclusion: 本文研究了通过协调不同TSFM模型输出的方法来提升时间序列预测的准确性，并提出了一种新的框架Synapse。实验结果证明了该方法的有效性。

Abstract: Pre-trained Time Series Foundational Models (TSFMs) represent a significant
advance, capable of forecasting diverse time series with complex
characteristics, including varied seasonalities, trends, and long-range
dependencies. Despite their primary goal of universal time series forecasting,
their efficacy is far from uniform; divergent training protocols and data
sources cause individual TSFMs to exhibit highly variable performance across
different forecasting tasks, domains, and horizons. Leveraging this
complementary expertise by arbitrating existing TSFM outputs presents a
compelling strategy, yet this remains a largely unexplored area of research. In
this paper, we conduct a thorough examination of how different TSFMs exhibit
specialized performance profiles across various forecasting settings, and how
we can effectively leverage this behavior in arbitration between different time
series models. We specifically analyze how factors such as model selection and
forecast horizon distribution can influence the efficacy of arbitration
strategies. Based on this analysis, we propose Synapse, a novel arbitration
framework for TSFMs. Synapse is designed to dynamically leverage a pool of
TSFMs, assign and adjust predictive weights based on their relative,
context-dependent performance, and construct a robust forecast distribution by
adaptively sampling from the output quantiles of constituent models.
Experimental results demonstrate that Synapse consistently outperforms other
popular ensembling techniques as well as individual TSFMs, demonstrating
Synapse's efficacy in time series forecasting.

</details>


### [108] [SiamMM: A Mixture Model Perspective on Deep Unsupervised Learning](https://arxiv.org/abs/2511.05462)
*Xiaodong Wang,Jing Huang,Kevin J Liang*

Main category: cs.LG

TL;DR: 该工作建立了无监督聚类方法与统计学中的经典混合模型之间的联系，提出了一种名为SiamMM的新模型，在多个无监督学习基准上达到了最先进的性能，并揭示了潜在的标签错误情况。


<details>
  <summary>Details</summary>
Motivation: 现有的基于聚类的方法在自我监督和无监督学习中显示出有效性，但应用通常是启发式的，最佳方法尚不清楚。此工作试图解决这一问题，通过连接无监督聚类方法和统计学中的经典混合模型。

Method: 通过建立无监督聚类方法与经典混合模型之间的联系，开发了一个名为SiamMM的新模型。此模型在多个无监督学习基准上进行了测试，并在性能上取得了显著提升。

Result: 新模型SiamMM在多个自我监督学习基准上达到了最先进的性能，并通过检查学习到的聚类，揭示了与未见过的真实标签之间的强相似性，进而揭示了潜在的标签错误情况。

Conclusion: 此研究通过连接无监督聚类方法和经典混合模型，开发了SiamMM模型，不仅提高了多个基准上的性能，还揭示了潜在的标签错误情况，具有重要的实践价值。

Abstract: Recent studies have demonstrated the effectiveness of clustering-based
approaches for self-supervised and unsupervised learning. However, the
application of clustering is often heuristic, and the optimal methodology
remains unclear. In this work, we establish connections between these
unsupervised clustering methods and classical mixture models from statistics.
Through this framework, we demonstrate significant enhancements to these
clustering methods, leading to the development of a novel model named SiamMM.
Our method attains state-of-the-art performance across various self-supervised
learning benchmarks. Inspection of the learned clusters reveals a strong
resemblance to unseen ground truth labels, uncovering potential instances of
mislabeling.

</details>


### [109] [SoilX: Calibration-Free Comprehensive Soil Sensing Through Contrastive Cross-Component Learning](https://arxiv.org/abs/2511.05482)
*Kang Yang,Yuanlin Yang,Yuning Chen,Sikai Yang,Xinyu Zhang,Wan Du*

Main category: cs.LG

TL;DR: SoilX 是一种无需校准的土壤监测系统，它可以同时测量土壤水分、氮、磷、钾、有机碳和铝。该系统通过联合学习解决了跨成分干扰问题，并且设计了一种新型的四角棱柱天线阵列，可独立于设备放置位置地测量土壤介电常数。实验表明，与基准方法相比，错误估计率降低了23.8%至31.5%。


<details>
  <summary>Details</summary>
Motivation: 由于土壤质地的不一致性和有机碳含量的变化，当前的无线土壤传感解决方案往往需要重新校准，这限制了其实际应用。因此，为了实现持续且准确地监测这些重要参数，防止资源浪费并优化产量，研究人员开发了SoilX系统。

Method: 该文描述了一种智能的土壤传感系统-SoilX，这是首个通过集成对比交叉成分学习和使用了一个独特的四角棱柱天线阵列来有效降低土壤成分间干扰的系统，从而能够独立、准确地测量包括有机碳和铝在内的六个关键土壤成分的电介质特性。

Result: 实验结果表明，与现有技术相比，SoilX系统在不同土壤类型中的错误估计率降低了23.8%到31.5%，并且具有良好的泛化能力。这说明SoilX在土壤监测方面具有更高的精度和实用性。

Conclusion: SoilX成功地提供了一种无需额外校准的、经济高效的土壤监测解决方案，它不仅能增加农民的农作物产量，而且能够提高水资源和养分的有效利用，助力精准农业的发展。

Abstract: Precision agriculture demands continuous and accurate monitoring of soil
moisture (M) and key macronutrients, including nitrogen (N), phosphorus (P),
and potassium (K), to optimize yields and conserve resources. Wireless soil
sensing has been explored to measure these four components; however, current
solutions require recalibration (i.e., retraining the data processing model) to
handle variations in soil texture, characterized by aluminosilicates (Al) and
organic carbon (C), limiting their practicality. To address this, we introduce
SoilX, a calibration-free soil sensing system that jointly measures six key
components: {M, N, P, K, C, Al}. By explicitly modeling C and Al, SoilX
eliminates texture- and carbon-dependent recalibration. SoilX incorporates
Contrastive Cross-Component Learning (3CL), with two customized terms: the
Orthogonality Regularizer and the Separation Loss, to effectively disentangle
cross-component interference. Additionally, we design a novel tetrahedral
antenna array with an antenna-switching mechanism, which can robustly measure
soil dielectric permittivity independent of device placement. Extensive
experiments demonstrate that SoilX reduces estimation errors by 23.8% to 31.5%
over baselines and generalizes well to unseen fields.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [110] [Computationally Efficient Spline-Based Modeling of DER Dynamics for Voltage Stability in Active Distribution Networks](https://arxiv.org/abs/2511.04917)
*Shadrack T. Asiedu,Tara Aryal,Zongjie Wang,Hossein Moradi Rekabdarkolaee,Timothy M. Hansen*

Main category: eess.SY

TL;DR: 本文提出了一种基于B样条的数据驱动方法，用于简化分布式能源资源（DERs）动态行为的建模，相比传统方法，该方法计算成本更低且更适用于实时应用。实验结果表明，该方法的拟合度为98.74%，并且速度比传统SysID方法快4.8倍。 


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源资源（DERs）在电力系统中的集成度提高，需要在输电层面上准确表示其动态行为。然而，传统电磁暂态建模（EMT）和数据驱动方法（如系统识别（SysID））面临着计算成本和实时操作的挑战。因此，研究新型数据驱动方法来解决这些问题。 

Method: 本文提出的方法利用B样条将离散系统数据转换成连续可微函数，以便通过简单线性回归估计低阶线性普通微分方程，从而降低计算成本。此外，还通过反向欧拉方法对所提取的动态方程进行离散化，使其可以集成到离散时间电力调度模型中。

Result: 实验结果表明，该方法的拟合度为98.74%，略低于SysID方法的99.03%，但是其执行速度快4.8倍。该方法的执行时间少于1分钟，更适合于电力系统操作中的实时应用。 

Conclusion: 所提出的方法提供了一种更实时、计算成本更低的DERs动态建模方案，能够在确保精度的同时，满足实时操作的需求。

Abstract: The increasing integration of Distributed Energy Resources (DERs) into power
systems necessitates the accurate representation of their dynamic behavior at
the transmission level. Traditional electromagnetic transient models (EMT),
while effective, face scalability challenges due to their reliance on detailed
system information. Data-driven approaches, such as System Identification
(SysID), offer a promising alternative by modeling system dynamics without
detailed system knowledge. However, SysID and similar methods are
computationally intensive, requiring the computation of complex ordinary
differential equations (ODEs) or transfer functions estimation. This makes them
less effective for real-time operation. We therefore propose a novel
data-driven approach that simplifies the modeling of DERs dynamics by
leveraging B-splines to transform discrete system data into continuous
differentiable functions. This enables the estimation of lower order linear
ordinary differential equations with simple linear regression to represent the
underlying dynamics at a very low computational cost. Furthermore, the
extracted dynamic equations are discretized by the backward Euler method for
potential integration into discrete-time power dispatch models. Validation
results indicate a goodness-of-fit (GoF) of 98.74%, comparable to the 99.03%
GoF of the SysID method, yet, 4.8 times faster. Our proposed model's execution
time of less than one minute makes it more suitable for real-time applications
in power system operations.

</details>


### [111] [IoT and Predictive Maintenance in Industrial Engineering: A Data-Driven Approach](https://arxiv.org/abs/2511.04923)
*P. Vijaya Bharati,J. S. V. Siva Kumar,Sathish K Anumula,P Vamshi Krishna,Sangam Malla*

Main category: eess.SY

TL;DR: 本论文探讨了物联网和预测性维护在工业工程中的结合，强调了构成集成的技术、方法以及数据分析技术。结果表明，通过系统性的数据收集、处理和预测建模，可以提高运营效率、减少停机时间和节省成本，这是为什么现代行业应该实施预测性维护的良好论据。


<details>
  <summary>Details</summary>
Motivation: 第四次工业革命带来了智能制造的新时代，其中，物联网和数据驱动方法正在改变传统的维护方式。利用物联网的实时数据和机器学习算法，预测性维护使工业系统能够预测故障并优化机器使用寿命。论文旨在探讨物联网和预测性维护在工业工程中的结合，强调构成该集成的技术、方法和数据分析技术的重要性。

Method: 论文讨论了系统性的数据收集、处理、预测建模技术。这些技术包括使用物联网的实时数据以及机器学习模型进行故障预测和优化机器使用。

Result: 研究表明，通过此方法可以提高运营效率，减少停机时间和节省成本。这为现代行业实施预测性维护提供了强有力的支持依据。

Conclusion: 该论文强调，利用物联网和预测性维护技术，可以显著提高工业系统的运营效率，降低停机时间，同时节省成本。因此，现代行业应该积极采纳这些技术。

Abstract: Fourth Industrial Revolution has brought in a new era of smart manufacturing,
wherein, application of Internet of Things , and data-driven methodologies is
revolutionizing the conventional maintenance. With the help of real-time data
from the IoT and machine learning algorithms, predictive maintenance allows
industrial systems to predict failures and optimize machines life. This paper
presents the synergy between the Internet of Things and predictive maintenance
in industrial engineering with an emphasis on the technologies, methodologies,
as well as data analytics techniques, that constitute the integration. A
systematic collection, processing, and predictive modeling of data is
discussed. The outcomes emphasize greater operational efficiency, decreased
downtime, and cost-saving, which makes a good argument as to why predictive
maintenance should be implemented in contemporary industries.

</details>


### [112] [Voltage-Independent Active-Power Droop Coefficient for Enhanced Andronov-Hopf Oscillator Grid-Forming Inverters](https://arxiv.org/abs/2511.05252)
*Hamed Rezazadeh,Mohammad Monfared,Meghdad Fazeli,Saeed Golestan*

Main category: eess.SY

TL;DR: 本文提出了一种增强版的安德罗诺夫-霍普夫振荡器（EAHO）策略，旨在改进电网形成型（GFM）逆变器的控制效果。EAHO通过使主动功率下垂系数不再依赖于电压幅值，确保了准确的功率分享，并在各种电网条件下提供了稳定和改进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 传统安德罗诺夫-霍普夫振荡器（AHO）的下垂系数依赖于振荡电压的幅值，这限制了它们在扰动情况下保持一致电网支持的能力，导致功率分享不准确。因此，本文提出了增强版的AHO策略。

Method: 提出了一种主动功率下垂系数不再依赖电压幅值的增强版安德罗诺夫-霍普夫振荡器(EAHO)策略，从而提高了频率和电压的支持能力，确保了与其它GFM逆变器在并网和孤岛模式下的准确功率共享，通过详尽的比较和小信号分析，以及在2.5 kVA单相逆变器上的实验验证了EAHO在各种电网条件下的稳定性和性能改善。

Result: 实验证明，EAHO策略相较于传统AHO策略，在稳态性能、主动及无功功率支撑和多种电网条件下的稳定运行方面都有显著提高。

Conclusion: 提出的EAHO策略在解决传统AHO系统中存在的依赖电压幅值的问题上具有明显优势，其不仅保持了传统AHO的优点，而且在多种电网条件下提升了性能表现出色。

Abstract: In recent years, virtual oscillator control, particularly the Andronov-Hopf
oscillator (AHO), has received widespread attention for controlling
grid-forming (GFM) inverters due to their superior dynamic response. However,
traditional AHO systems feature droop coefficients that are dependent on the
oscillator voltage amplitude, limiting their ability to maintain consistent
grid support during disturbances and resulting in power-sharing inaccuracies.
This paper presents an enhanced AHO (EAHO) strategy, where the active power
droop coefficient is no longer a function of the voltage amplitude and retains
the key dynamic benefits of the original AHO. The EAHO improves both frequency
and voltage support and ensures accurate power sharing with other GFM inverters
in grid-connected and stand-alone modes. Extensive comparative and small-signal
analyses, alongside experimental validation on 2.5 kVA single-phase inverters,
confirm the EAHO's improved steady-state performance, enhanced active and
reactive power support, and stable operation under varying grid conditions.

</details>


### [113] [Privacy-Preserving Cramér-Rao Lower Bound](https://arxiv.org/abs/2511.05327)
*Jieming Ke,Jimin Wang,Ji-Feng Zhang*

Main category: eess.SY

TL;DR: 提出了一种隐私保护下的Cramér-Rao下界理论，阐述了隐私约束下识别精度的基本界限，并推广到多传感器多测量系统，同时提供有效的识别算法。数值例证了该理论的有效性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探索隐私约束下识别精度的基本界限，从而提供有效的算法来平衡精度和隐私保护。提出了隐私保护下的Cramér-Rao下界理论，并进一步推广到了多传感器多测量系统中。动机在于定义隐私保护下的识别精度界限，并为系统提供可行的算法以达到该界限。

Method: 使用Fisher信息矩阵作为隐私度量，推导出识别标准。在可识别的情况下，建立隐私保护下的Cramér-Rao下界，并显示了其可实现性，同时提出分布式识别算法，能够实现上述理论。最后通过数值例证了理论的有效性及算法的实际效果。

Result: 结果表明，隐私保护下的Cramér-Rao下界理论对于多传感器多测量系统是适用的。通过Fisher信息矩阵的加法原理，可以建立子系统与整体系统的隐私保护下界之间的关系。进一步的分布式识别算法被提出并验证了其有效性。

Conclusion: 该项研究引入了隐私保护下的Cramér-Rao下界理论，并成功应用于多传感器多测量系统中，提出了可行的算法达到了该理论界限。这一理论和算法对于隐私保护下的系统识别具有重要的理论和实际意义。

Abstract: This paper establishes the privacy-preserving Cram\'er-Rao (CR) lower bound
theory, characterizing the fundamental limit of identification accuracy under
privacy constraint. An identifiability criterion under privacy constraint is
derived by using Fisher information matrix as the privacy metric. In the
identifiable case, the privacy-preserving CR lower bound is established and its
attainability is demonstrated, thereby ensuring the existence of the
privacy-preserving Fisher information matrix with explicit expression. Then,
the privacy-preserving CR lower bound theory is extended to the multi-sensor
multi-measurement system. Specifically, the additivity principle of
privacy-preserving Fisher information matrices across both spatial and temporal
dimensions is established, building a relationship between privacy-preserving
CR lower bounds for the multi-sensor multi-measurement system and its
subsystems. Using this additivity principle, distributed identification
algorithms capable of achieving the privacy-preserving CR lower bound are
further proposed. Numerical examples are provided to demonstrate the
privacy-preserving CR lower bound and show the effectiveness of the proposed
algorithms.

</details>


### [114] [Coherency Control in Power Systems](https://arxiv.org/abs/2511.05391)
*Rodrigo Bernal,Ignacio Ponce,Federico Milano*

Main category: eess.SY

TL;DR: 本文提出了一种基于注入电流复频率相等定义的协同控制策略，使得逆变资源能够与电力系统中的其他设备保持一致的动态行为，改善系统阻尼和整体动态表现。该方法对技术是通用的，并通过实验验证了其实用性，包括延迟和噪声敏感性以及振荡抑制与干扰传播的权衡。


<details>
  <summary>Details</summary>
Motivation: 逆变资源日益重要，但管理其与电力系统其他设备的同步存在挑战。作者旨在发展一种技术无关的控制策略，以提高这些设备间的协同性，从而改善系统的稳定性。

Method: 基于电流复频率相等的定义，控制策略通过实施相对于基准的输出电流（与参考信号具有恒定相位差和比例系数）来强制执行协同性。该方法通过两个案例研究（两个区域和IEEE 39节点系统）进行了验证，同时评估了其实际应用中的延迟/噪声敏感性和振荡控制与干扰传播之间的权衡。

Result: 对照组研究表明，该方法能够显著提高系统的阻尼能力和整体动态表现。该策略对于各种类型资源都是有效的，显示出了较高的实用价值和普适性。此外，还证明了这种控制策略可以有效减轻振动并控制干扰传播。

Conclusion: 此研究成功将协同性确立为现代电力系统中逆变资源的直接控制目标之一，表明这种方法在提高系统稳定性方面具有广泛的应用前景。

Abstract: This paper proposes a coherency control strategy for Inverter-Based Resources
(IBRs) to establish coherence among power system devices. Using the equivalence
of the Complex Frequency (CF) of the injected currents as the definition for
coherency among devices, the control enforces an output current with a
proportional magnitude and a constant phase shift relative to a reference. This
formulation makes the control technology-agnostic, enabling coherency with any
type of resource. Case studies based on the two-area and IEEE 39-bus systems
demonstrate the controller's potential to improve damping and overall dynamic
behavior. The paper further evaluates practical implementation aspects
including delay/noise sensitivity and the trade-off between oscillation
mitigation and disturbance propagation. This work establishes coherency as a
viable direct control objective for IBRs in modern power systems.

</details>


### [115] [A Tilting-Rotor Enhanced Quadcopter Fault-Tolerant Control Based on Non-Linear Model Predictive Control](https://arxiv.org/abs/2511.05445)
*Yanchao Wang,Xu You,Mehdi Baghdadi*

Main category: eess.SY

TL;DR: 该论文提出了一种基于倾转旋翼四旋翼原型的故障容错控制策略，利用非线性模型预测控制在旋翼故障的情况下保持姿态和位置的稳定性。研究通过仿真验证了该方法的有效性，并将其与其他传统四旋翼和无观测器的倾转旋翼进行了比较，结果表明提出的倾转旋翼四旋翼在无牺牲偏航稳定性的情况下能够保持位置控制的能力，而传统四旋翼却不能。


<details>
  <summary>Details</summary>
Motivation: 论文旨在提出一种故障容错控制策略，以解决四旋翼飞行器在发生旋翼故障时继续维持控制的问题，特别是在需要保持姿态和位置稳定性且不牺牲偏航稳定性的场景中。通过引入非线性模型预测控制和扩展状态观测器，使四旋翼在故障情况下仍能自主进行控制调整，保持稳定。研究对比了一般的四旋翼和无观测器的倾转旋翼，展示了所提方法的独特优势。

Method: 该方法采用了非线性模型预测控制（NMPC）结合扩展状态观测器（ESO）的控制策略。在发生故障时，ESO预测模型偏差，并在下一个时间步骤调整原模型，从而实现主动故障容错控制。该方法在仿真中进行了评估并与传统四旋翼和无观测器的倾斜旋翼在相同条件下进行了对比。

Result: 研究结果表明，提出的故障容错控制策略能够在模拟故障条件下有效地保持倾转旋翼四旋翼的姿态和位置稳定性，而传统四旋翼不能同时保持位置控制和偏航稳定性。

Conclusion: 提出的基于非线性模型预测控制和扩展状态观测器的故障容错控制策略展示了在四旋翼飞行器故障情况下的控制能力，能够同时维持位置和姿态控制，尤其在保持偏航稳定性的方面表现优于传统四旋翼。

Abstract: This paper proposes a fault-tolerant control strategy based on a tilt-rotor
quadcopter prototype, utilizing nonlinear model predictive control to maintain
both attitude and position stability in the event of rotor failure. The control
strategy employs an extended state observer to predict model deviations
following a fault and adjusts the original model in the subsequent time step,
thereby achieving active fault-tolerant control. The proposed method is
evaluated through simulations and compared to both traditional quadcopter and
tilt-rotor quadcopter without observer under identical conditions. The results
demonstrate that the tilt-rotor quadcopter can maintain position control
without sacrificing yaw stability, unlike traditional quadcopters.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [116] [Adjoint and duality for rank-metric codes in a skew polynomial framework](https://arxiv.org/abs/2511.05084)
*José Gómez-Torrecillas,F. J. Lobillo,Gabriel Navarro,Paolo Santonastaso*

Main category: cs.IT

TL;DR: 本文系统研究了斜多项式环商中的转置和对偶操作，并对Sheekey等人最近提出的MRD码家族的伴随码和对偶码进行了显式斜多项式描述，计算了这些码的核参数，并证明了在一组新的无限参数集下，许多这些MRD码与文献中已知的构造不等价


<details>
  <summary>Details</summary>
Motivation: 探讨斜多项式环商中的转置和对偶操作，为理解MRD码提供新的视角

Method: 通过斜多项式描述转置和对偶码的构造，计算核参数

Result: 确定了Sheekey等人最近提出的MRD码家族的伴随码和对偶码，证明了这些MRD码的新特性

Conclusion: 研究结果扩展了对MRD码的理解，证明了这些码的新特性和与已知构造的区别

Abstract: Skew polynomial rings provide a fundamental example of noncommutative
principal ideal domains. Special quotients of these rings yield matrix algebras
that play a central role in the theory of rank-metric codes. Recent
breakthroughs have shown that specific subsets of these quotients produce the
largest known families of maximum rank distance (MRD) codes. In this work, we
present a systematic study of transposition and duality operations within
quotients of skew polynomial rings. We develop explicit skew-polynomial
descriptions of the transpose and dual code constructions, enabling us to
determine the adjoint and dual codes associated with the MRD code families
recently introduced by Sheekey et al. Building on these results, we compute the
nuclear parameters of these codes, and prove that, for a new infinite set of
parameters, many of these MRD codes are inequivalent to previously known
constructions in the literature.

</details>


### [117] [Shortest self-orthogonal embeddings of binary linear codes](https://arxiv.org/abs/2511.05440)
*Junmin An,Nathan Kaplan,Jon-Lark Kim,Jinquan Luo,Guodong Wang*

Main category: cs.IT

TL;DR: 本文通过线性码的外壳特性来确定任何二进制线性码的最短自正交嵌入长度，重点研究了汉明码和里德-穆勒码的例子，并提出了从汉明码构建自对偶码的两种算法，从而构建出一些具有新参数的最优自正交码。


<details>
  <summary>Details</summary>
Motivation: 由于许多二进制线性码是最优的自正交码，因此研究其最短自正交嵌入长度具有重要意义。

Method: 本文利用线性码的外壳特性，提出了确定任何二进制线性码最短自正交嵌入长度的方法，并通过汉明码研究了该方法的有效性，提出了从汉明码构建自对偶码的两种算法，通过这些算法，从二进制汉明码构建了自对偶码。

Result: 本文通过该方法构建了多个具有新参数的最优自正交码，包括$[91, 8, 42], [98, 8, 46], [114, 8, 54]$和$[191, 8, 94]$等。

Conclusion: 本文提出了新的方法用于构建最短自正交嵌入，并通过具体实例展示了该方法的有效性，成功构建出多个具有新参数的最优自正交码。

Abstract: There has been recent interest in the study of shortest self-orthogonal
embeddings of binary linear codes, since many such codes are optimal
self-orthogonal codes. Several authors have studied the length of a shortest
self-orthogonal embedding of a given binary code $\mathcal C$, or equivalently,
the minimum number of columns that must be added to a generator matrix of
$\mathcal C$ to form a generator matrix of a self-orthogonal code. In this
paper, we use properties of the hull of a linear code to determine the length
of a shortest self-orthogonal embedding of any binary linear code. We focus on
the examples of Hamming codes and Reed-Muller codes. We show that a shortest
self-orthogonal embedding of a binary Hamming code is self-dual, and propose
two algorithms to construct self-dual codes from Hamming codes $\mathcal H_r$.
Using these algorithms, we construct a self-dual $[22, 11, 6]$ code, called the
shortened Golay code, from the binary $[15, 11, 3]$ Hamming code $\mathcal
H_4$, and construct a self-dual $[52, 26, 8]$ code from the binary $[31, 26,
3]$ Hamming code $\mathcal H_5$. We use shortest SO embeddings of linear codes
to obtain many inequivalent optimal self-orthogonal codes of dimension $7$ and
$8$ for several lengths. Four of the codes of dimension $8$ that we construct
are codes with new parameters such as $[91, 8, 42],\, [98, 8, 46],\,[114, 8,
54]$, and $[191, 8, 94]$.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [118] [A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024](https://arxiv.org/abs/2511.04685)
*Daniela Guericke,Rolf van der Hulst,Asal Karimpour,Ieke Schrader,Matthias Walter*

Main category: cs.AI

TL;DR: 本文介绍了Team Twente在Integrated Healthcare Timetabling Competition 2024中所提交的方法和结果，该方法结合了混合整数规划、约束规划和模拟退火，并分享了对基准实例最优解下界的见解以及可进一步改进的问题。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是通过结合不同的优化方法来解决综合医疗排班问题，并在竞赛中取得良好成绩，同时分享对问题的深入理解和可能的改进方向。

Method: 本文提出的方法结合了混合整数规划、约束规划和模拟退火，通过三个阶段的解决方案过程来分解和解决子问题。

Result: 比赛结果表明，提出的三阶段混合方法在Integrated Healthcare Timetabling Competition 2024中排名第三。

Conclusion: 文章提出了对基准问题的优化方法，不仅在比赛中取得了好成绩，还提供了对问题更深层次的理解，包括潜在改进的方向。

Abstract: We report about the algorithm, implementation and results submitted to the
Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored
third in the competition. Our approach combines mixed-integer programming,
constraint programming and simulated annealing in a 3-phase solution approach
based on decomposition into subproblems. Next to describing our approach and
describing our design decisions, we share our insights and, for the first time,
lower bounds on the optimal solution values for the benchmark instances. We
finally highlight open problems for which we think that addressing them could
improve our approach even further.

</details>


### [119] [Epistemic Reject Option Prediction](https://arxiv.org/abs/2511.04855)
*Vojtech Franc,Jakub Paplham*

Main category: cs.AI

TL;DR: 本文介绍了epistemic拒绝选项预测器，该预测器在数据不足导致的认知不确定性较高时拒绝预测。它基于贝叶斯学习，将最优预测器定义为使预期后悔最小化的预测器，并且当给定输入的后悔超过指定拒绝成本时拒绝预测。这是首个能够识别由于培训数据不足而无法做出可靠决策的输入的学习预测器的理论框架。


<details>
  <summary>Details</summary>
Motivation: 传统的方法未充分考虑认知不确定性，而认知不确定性在数据有限的情况下变得尤为重要。因此，需要一种新的机制来使模型在认知不确定性高的情况下拒绝预测。

Method: 基于贝叶斯方法，将最优预测器定义为期望后悔最小化的预测器。通过计算给定输入的后悔值与设定的拒绝成本比较，决定是否拒绝预测。

Result: 提出了epistemic拒绝选项预测器，该方法可以通过考虑认知不确定性，使模型能够更准确地识别对于给定输入做出可靠决策所需的数据是否足够。

Conclusion: 该方法提供了一个实用且理论支持的方法来量化和处理认知不确定性，并且能够使模型在认知不确定性高的情况下避免做出预测，从而提高了模型决策的可靠性和性能。

Abstract: In high-stakes applications, predictive models must not only produce accurate
predictions but also quantify and communicate their uncertainty. Reject-option
prediction addresses this by allowing the model to abstain when prediction
uncertainty is high. Traditional reject-option approaches focus solely on
aleatoric uncertainty, an assumption valid only when large training data makes
the epistemic uncertainty negligible. However, in many practical scenarios,
limited data makes this assumption unrealistic. This paper introduces the
epistemic reject-option predictor, which abstains in regions of high epistemic
uncertainty caused by insufficient data. Building on Bayesian learning, we
redefine the optimal predictor as the one that minimizes expected regret -- the
performance gap between the learned model and the Bayes-optimal predictor with
full knowledge of the data distribution. The model abstains when the regret for
a given input exceeds a specified rejection cost. To our knowledge, this is the
first principled framework that enables learning predictors capable of
identifying inputs for which the training data is insufficient to make reliable
decisions.

</details>


### [120] [DMA: Online RAG Alignment with Human Feedback](https://arxiv.org/abs/2511.04880)
*Yu Bai,Yukai Miao,Dawei Wang,Li Chen,Fei Long,Rundi Zhai,Dan Li,Yanyu Ren,Tianfeng Liu,Hongtao Xie,Ce Yang,Xuhui Cai*

Main category: cs.AI

TL;DR: 介绍了一种名为Dynamic Memory Alignment (DMA) 的在线学习框架，该框架通过系统地整合多粒度的人类反馈来解决检索增强生成系统依赖静态检索的问题，提高其适应性。DMA 包含三个级别的信号组织（文档级、列表级和响应级），并采取双轨评估协议来验证其效果，显示了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成系统依赖于静态检索，难以适应意图的变化和内容漂移，且没有充分利用人类反馈来提升其性能。为了克服这些问题，提出了一个在线学习框架，利用多粒度的人类反馈来改进排名流程，使之适应于互动场景和内容的变化。

Method: DMA 将文档级、列表级和响应级信号整合到一个学习流程中，包括点对点和列表级排序器的监督学习，响应级别偏好驱动的策略优化，以及知识蒸馏到轻量级评分器以实现低延迟服务。采用工业部署与大型在线A/B 消融研究以及少样本离线测试相结合的方式进行评估。

Result: 在线评估表明，DMA 能显著提高人类的参与度。离线评估显示，DMA 保持了基础检索能力的同时，在对话问答领域获得了显著提升。这些结果凸显了DMA 作为一个基于反馈的、实时适应检索增强生成系统的原则性方法.

Conclusion: DMA 是一种通过整合多粒度人类反馈，实现检索增强生成系统实时调整的框架，它不仅提高了系统与用户互动的质量，还保持了基本检索功能的竞争力。

Abstract: Retrieval-augmented generation (RAG) systems often rely on static retrieval,
limiting adaptation to evolving intent and content drift. We introduce Dynamic
Memory Alignment (DMA), an online learning framework that systematically
incorporates multi-granularity human feedback to align ranking in interactive
settings. DMA organizes document-, list-, and response-level signals into a
coherent learning pipeline: supervised training for pointwise and listwise
rankers, policy optimization driven by response-level preferences, and
knowledge distillation into a lightweight scorer for low-latency serving.
Throughout this paper, memory refers to the model's working memory, which is
the entire context visible to the LLM for In-Context Learning.
  We adopt a dual-track evaluation protocol mirroring deployment: (i)
large-scale online A/B ablations to isolate the utility of each feedback
source, and (ii) few-shot offline tests on knowledge-intensive benchmarks.
Online, a multi-month industrial deployment further shows substantial
improvements in human engagement. Offline, DMA preserves competitive
foundational retrieval while yielding notable gains on conversational QA
(TriviaQA, HotpotQA). Taken together, these results position DMA as a
principled approach to feedback-driven, real-time adaptation in RAG without
sacrificing baseline capability.

</details>


### [121] [Autonomous generation of different courses of action in mechanized combat operations](https://arxiv.org/abs/2511.05182)
*Johan Schubert,Patrik Hansen,Pontus Hörling,Ronnie Johansson*

Main category: cs.AI

TL;DR: 本文提出了一种支持地面战斗阶段决策的方法，生成并评估针对机械化步兵团的各种行动方案，并根据对手状态和行动进行评估，以确定更好的行动方案。该方法能够在战斗过程中动态生成和评估方案，以帮助决策者做出最佳决策。


<details>
  <summary>Details</summary>
Motivation: 军事地面战斗行动决策的重要性及其复杂性，需要一种系统的、基于行动评估的方法来辅助决策。本文提出的方法可生成多种可能的行动方案，并在战斗中不断更新，以适应变化的战场情况。

Method: 该方法首先生成一系列可能的行动方案，并根据预期结果进行初次评估。然后，通过考虑到对手的状态和行动、部队构成、兵力比例、攻击与防御类型等因素，进行深入的评估，选出最优方案。这种方法在生成和评估过程中同步运行，支持根据已评估的行动生成新行动方案。

Result: 该方法能够生成大量行动方案，根据不断变化的战场条件进行即时更新，并选出最佳的行动方案，为决策者提供支持。

Conclusion: 提出的方法为军事地面战斗中的决策提供了有力的支持，通过动态生成和评估行动方案，能够帮助决策者在复杂的战场上做出最佳决策。

Abstract: In this paper, we propose a methodology designed to support decision-making
during the execution phase of military ground combat operations, with a focus
on one's actions. This methodology generates and evaluates recommendations for
various courses of action for a mechanized battalion, commencing with an
initial set assessed by their anticipated outcomes. It systematically produces
thousands of individual action alternatives, followed by evaluations aimed at
identifying alternative courses of action with superior outcomes. These
alternatives are appraised in light of the opponent's status and actions,
considering unit composition, force ratios, types of offense and defense, and
anticipated advance rates. Field manuals evaluate battle outcomes and
advancement rates. The processes of generation and evaluation work
concurrently, yielding a variety of alternative courses of action. This
approach facilitates the management of new course generation based on
previously evaluated actions. As the combat unfolds and conditions evolve,
revised courses of action are formulated for the decision-maker within a
sequential decision-making framework.

</details>
